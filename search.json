[{"path":[]},{"path":"https://schalkdaniel.github.io/compboost/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"interest fostering open welcoming environment, contributors maintainers pledge making participation project community harassment-free experience everyone, regardless age, body size, disability, ethnicity, gender identity expression, level experience, nationality, personal appearance, race, religion, sexual identity orientation.","code":""},{"path":"https://schalkdaniel.github.io/compboost/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes creating positive environment include: Using welcoming inclusive language respectful differing viewpoints experiences Gracefully accepting constructive criticism Focusing best community Showing empathy towards community members Examples unacceptable behavior participants include: use sexualized language imagery unwelcome sexual attention advances Trolling, insulting/derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical electronic address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://schalkdaniel.github.io/compboost/CODE_OF_CONDUCT.html","id":"our-responsibilities","dir":"","previous_headings":"","what":"Our Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Project maintainers responsible clarifying standards acceptable behavior expected take appropriate fair corrective action response instances unacceptable behavior. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, ban temporarily permanently contributor behaviors deem inappropriate, threatening, offensive, harmful.","code":""},{"path":"https://schalkdaniel.github.io/compboost/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within project spaces public spaces individual representing project community. Examples representing project community include using official project e-mail address, posting via official social media account, acting appointed representative online offline event. Representation project may defined clarified project maintainers.","code":""},{"path":"https://schalkdaniel.github.io/compboost/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported contacting project team contact@danielschalk.com. project team review investigate complaints, respond way deems appropriate circumstances. project team obligated maintain confidentiality regard reporter incident. details specific enforcement policies may posted separately. Project maintainers follow enforce Code Conduct good faith may face temporary permanent repercussions determined members project’s leadership.","code":""},{"path":"https://schalkdaniel.github.io/compboost/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 1.4, available http://contributor-covenant.org/version/1/4","code":""},{"path":"https://schalkdaniel.github.io/compboost/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to compboost development","title":"Contributing to compboost development","text":", authors compboost R package, use guide used contributing development popular ggplot2 R package. document simply formal re-statement fact. goal guide help get contributing compboost quickly possible. guide divided two main pieces: Filing bug report feature request issue. Suggesting change via pull request.","code":""},{"path":"https://schalkdaniel.github.io/compboost/CONTRIBUTING.html","id":"issues","dir":"","previous_headings":"","what":"Issues","title":"Contributing to compboost development","text":"filing issue, important thing include minimal reproducible example can quickly verify problem, figure fix . three things need include make example reproducible: required packages, data, code. Packages loaded top script, ’s easy see ones example needs. easiest way include data use dput() generate R code recreate . example, recreate mtcars dataset R, ’d perform following steps: Run dput(mtcars) R Copy output reproducible script, type mtcars <- paste. even better can create data.frame() just handful rows columns still illustrates problem. Spend little bit time ensuring code easy others read: make sure ’ve used spaces variable names concise, informative use comments indicate problem lies best remove everything related problem. shorter code , easier understand. can check actually made reproducible example starting fresh R session pasting script . (Unless ’ve specifically asked , please don’t include output sessionInfo().)","code":""},{"path":"https://schalkdaniel.github.io/compboost/CONTRIBUTING.html","id":"pull-requests","dir":"","previous_headings":"","what":"Pull requests","title":"Contributing to compboost development","text":"contribute change compboost, follow steps: Create branch git make changes. Push branch github issue pull request (PR). Discuss pull request. Iterate either accept PR decide ’s good fit compboost. steps described detail . might feel overwhelming first time get set , gets easier practice. ’re familiar git GitHub, please start reading http://r-pkgs..co.nz/git.html Pull requests evaluated checklist: Motivation. pull request clearly concisely motivates need change. Plesae describe problem PR addresses show pull request solves concisely possible. Also include motivation NEWS new release compboost comes ’s easy users see ’s changed. Add item top file use markdown formatting. news item end (@yourGithubUsername, #the_issue_number). related changes. submit pull request, please check make sure haven’t accidentally included unrelated changes. make harder see exactly ’s changed, evaluate unexpected side effects. PR corresponds git branch, expect submit multiple changes make sure create multiple branches. multiple changes depend , start first one don’t submit others first one processed. ’re adding new parameters new function, ’ll also need document roxygen. Make sure re-run devtools::document() code submitting. seems like lot work don’t worry pull request isn’t perfect. ’s learning process. pull request process, unless ’ve submitted past ’s unlikely pull request accepted . Please don’t submit pull requests change existing behaviour. Instead, think can add new feature minimally invasive way.","code":""},{"path":"https://schalkdaniel.github.io/compboost/CONTRIBUTORS.html","id":null,"dir":"","previous_headings":"","what":"Contributors of compboost","title":"Contributors of compboost","text":"Committers people made substantial contribution project granted write access project. Daniel creator maintainer project. Janek gives feedback/guidance package design structure implements initial R API. Bernd gives feedback/guidance package design structure initiated project.","code":""},{"path":"https://schalkdaniel.github.io/compboost/articles/adv-extending-losses.html","id":"before-starting","dir":"Articles","previous_headings":"","what":"Before Starting","title":"Extending compboost with losses","text":"Read use-case site get know define Compboost object using R6 interface","code":""},{"path":"https://schalkdaniel.github.io/compboost/articles/adv-extending-losses.html","id":"what-is-needed","dir":"Articles","previous_headings":"","what":"What is Needed","title":"Extending compboost with losses","text":"compboost designed provide component-wise boosting framework maximal flexibility. vignette gives overview define custom losses R well C++ without recompiling whole package. custom losses can used training model /logging mechanisms. loss function boosting must differentiable. Hence, need define loss function gradient. , boosting initialized loss optimal constant. capture , define loss optimal constant function response vector. three components, quite easy define custom losses. showcase, rebuilding two different loss functions: quadratic loss easy example C++ Poisson loss counting data sophisticated loss example R","code":""},{"path":"https://schalkdaniel.github.io/compboost/articles/adv-extending-losses.html","id":"define-a-new-loss-with-r","dir":"Articles","previous_headings":"","what":"Define a New Loss With R","title":"Extending compboost with losses","text":"example using VonBort dataset provided package vcd: “Data von Bortkiewicz (1898), given Andrews & Herzberg (1985), number deaths horse mule kicks 14 corps Prussian army.” like model deaths using Poisson regression boosting. means define proper loss function, gradient, constant initialization. scheme loss, gradient, constant initialization specify function following form: loss: function (truth, response) gradient: function (truth, response) constant initializer: function (truth)","code":"data(VonBort, package = \"vcd\")"},{"path":"https://schalkdaniel.github.io/compboost/articles/adv-extending-losses.html","id":"the-loss-function","dir":"Articles","previous_headings":"Define a New Loss With R","what":"The loss function","title":"Extending compboost with losses","text":"\\[L(y,f) = -\\log\\left( \\exp(f)^y \\exp(\\exp(f)) \\right) - \\log(y!)\\]","code":"lossPoisson = function (truth, response) {   return(-log(exp(response)^truth * exp(-exp(response))) - gamma(truth + 1)) }"},{"path":"https://schalkdaniel.github.io/compboost/articles/adv-extending-losses.html","id":"the-gradient-of-the-loss-function","dir":"Articles","previous_headings":"Define a New Loss With R","what":"The gradient of the loss function","title":"Extending compboost with losses","text":"\\[\\frac{\\partial}{\\partial f} L(y,f) = \\exp(f) - y\\]","code":"gradPoisson = function (truth, response) {   return(exp(response) - truth) }"},{"path":"https://schalkdaniel.github.io/compboost/articles/adv-extending-losses.html","id":"the-constant-initialization","dir":"Articles","previous_headings":"Define a New Loss With R","what":"The constant initialization","title":"Extending compboost with losses","text":"\\[\\mathsf{arg min}_{c\\\\mathbb{R}} \\sum_{= 1}^n L\\left(y^{()}, c\\right) = \\log(\\bar{y})\\]","code":"constInitPoisson = function (truth) {   return(log(mean(truth))) }"},{"path":"https://schalkdaniel.github.io/compboost/articles/adv-extending-losses.html","id":"define-the-loss","dir":"Articles","previous_headings":"Define a New Loss With R","what":"Define the loss","title":"Extending compboost with losses","text":"Finally, three components allows define LossCustom object:","code":"# Define custom loss: my_poisson_loss = LossCustom$new(lossPoisson, gradPoisson, constInitPoisson)"},{"path":"https://schalkdaniel.github.io/compboost/articles/adv-extending-losses.html","id":"train-a-model","dir":"Articles","previous_headings":"Define a New Loss With R","what":"Train a model","title":"Extending compboost with losses","text":"loss object can used task requires loss object:","code":"cboost = Compboost$new(VonBort, \"deaths\", loss = my_poisson_loss) cboost$addBaselearner(\"year\", \"spline\", BaselearnerPSpline) cboost$train(100, trace = 0)"},{"path":"https://schalkdaniel.github.io/compboost/articles/adv-extending-losses.html","id":"define-a-new-loss-with-c","dir":"Articles","previous_headings":"","what":"Define a New Loss With C++","title":"Extending compboost with losses","text":"example, keep simple, using iris dataset Sepal.Length target. aim replicate quadratic loss. achieved exposing external pointers R hold function definition passed constructor LossCustomCpp class. general advise write .cpp file contains whole definition. file needs sourced Rcpp::sourceCpp(). declare head first able expose functions: type definition already indicates, C++ functions require following signature: loss: arma::mat lossFun (const arma::mat& truth, const arma::mat& response) gradient: arma::mat gradFun (const arma::mat& truth, const arma::mat& response) constant initializer: constInitFun (const arma::mat& true_value)","code":"// [[Rcpp::depends(RcppArmadillo)]] #include <RcppArmadillo.h>  typedef arma::mat (*lossFunPtr) (const arma::mat& true_value, const arma::mat& prediction); typedef arma::mat (*gradFunPtr) (const arma::mat& true_value, const arma::mat& prediction); typedef double (*constInitFunPtr) (const arma::mat& true_value);"},{"path":"https://schalkdaniel.github.io/compboost/articles/adv-extending-losses.html","id":"the-loss-function-1","dir":"Articles","previous_headings":"Define a New Loss With C++","what":"The loss function","title":"Extending compboost with losses","text":"\\[L(y,f) = -0.5 \\left(y - f\\right)^2\\]","code":"arma::mat lossFun (const arma::mat& true_value, const arma::mat& prediction) {   return arma::pow(true_value - prediction, 2) / 2; }"},{"path":"https://schalkdaniel.github.io/compboost/articles/adv-extending-losses.html","id":"the-gradient-of-the-loss-function-1","dir":"Articles","previous_headings":"Define a New Loss With C++","what":"The gradient of the loss function","title":"Extending compboost with losses","text":"\\[\\frac{\\partial}{\\partial f} L(y,f) = f - y\\]","code":"arma::mat gradFun (const arma::mat& true_value, const arma::mat& prediction) {   return prediction - true_value; }"},{"path":"https://schalkdaniel.github.io/compboost/articles/adv-extending-losses.html","id":"the-constant-initialization-1","dir":"Articles","previous_headings":"Define a New Loss With C++","what":"The constant initialization","title":"Extending compboost with losses","text":"\\[\\mathsf{arg min}_{c\\\\mathbb{R}} \\sum_{= 1}^n L\\left(y^{()}, c\\right) = \\bar{y}\\]","code":"double constInitFun (const arma::mat& true_value) {   return arma::accu(true_value) / true_value.size(); }"},{"path":"https://schalkdaniel.github.io/compboost/articles/adv-extending-losses.html","id":"exposing-external-pointer","dir":"Articles","previous_headings":"Define a New Loss With C++","what":"Exposing external pointer","title":"Extending compboost with losses","text":"functions exposed XPtr. stores pointer function can used parameter LossCustomCpp. Note necessary export upper functions, exporting pointer goal.","code":"// [[Rcpp::export]] Rcpp::XPtr<lossFunPtr> lossFunSetter () {   return Rcpp::XPtr<lossFunPtr> (new lossFunPtr (&lossFun)); }  // [[Rcpp::export]] Rcpp::XPtr<gradFunPtr> gradFunSetter () {   return Rcpp::XPtr<gradFunPtr> (new gradFunPtr (&gradFun)); }  // [[Rcpp::export]] Rcpp::XPtr<constInitFunPtr> constInitFunSetter () {   return Rcpp::XPtr<constInitFunPtr> (new constInitFunPtr (&constInitFun)); }"},{"path":"https://schalkdaniel.github.io/compboost/articles/adv-extending-losses.html","id":"define-the-loss-1","dir":"Articles","previous_headings":"Define a New Loss With C++","what":"Define the loss","title":"Extending compboost with losses","text":"can get pointer function exposing : Now, can pass pointer LossCustomCpp class:","code":"lossFunSetter() gradFunSetter() constInitFunSetter() my_cpp_loss = LossCustomCpp$new(lossFunSetter(), gradFunSetter(), constInitFunSetter())"},{"path":"https://schalkdaniel.github.io/compboost/articles/adv-extending-losses.html","id":"train-a-model-1","dir":"Articles","previous_headings":"Define a New Loss With C++","what":"Train a model","title":"Extending compboost with losses","text":"Finally, use custom loss train model:","code":"cboost = boostSplines(data = iris, target = \"Sepal.Length\",   loss = my_cpp_loss, trace = 25)"},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-early-stopping.html","id":"before-starting","dir":"Articles","previous_headings":"","what":"Before Starting","title":"Early Stopping","text":"Read use-case get know define Compboost object using R6 interface","code":""},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-early-stopping.html","id":"data-titanic-passenger-survival-data-set","dir":"Articles","previous_headings":"","what":"Data: Titanic Passenger Survival Data Set","title":"Early Stopping","text":"use titanic dataset binary classification Survived. First store train test data two data frames remove rows contains missing values (NAs): later stopping split dataset train test:","code":"# Store train and test data: df = na.omit(titanic::titanic_train) df$Survived = factor(df$Survived, labels = c(\"no\", \"yes\")) set.seed(123) idx_train = sample(seq_len(nrow(df)), size = nrow(df) * 0.8) idx_test = setdiff(seq_len(nrow(df)), idx_train)"},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-early-stopping.html","id":"defining-the-model","dir":"Articles","previous_headings":"","what":"Defining the Model","title":"Early Stopping","text":"define model use-case just train index without specifying --bag fraction:","code":"cboost = Compboost$new(data = df[idx_train, ], target = \"Survived\")  cboost$addBaselearner(\"Age\", \"spline\", BaselearnerPSpline) cboost$addBaselearner(\"Fare\", \"spline\", BaselearnerPSpline) cboost$addBaselearner(\"Sex\", \"ridge\", BaselearnerCategoricalRidge)"},{"path":[]},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-early-stopping.html","id":"how-does-it-work","dir":"Articles","previous_headings":"Early Stopping in Compboost","what":"How does it work?","title":"Early Stopping","text":"early stopping compboost done using logger objects. Logger executed iteration stores class dependent data runtime risk. Additionally, logger can declared stopper setting use_as_stopper = TRUE. declaring logger stopper, used stop algorithm logger-specific criteria reached. example, LoggerTime stop algorithm pre-defined runtime reached.","code":""},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-early-stopping.html","id":"example-with-runtime-stopping","dir":"Articles","previous_headings":"Early Stopping in Compboost","what":"Example with runtime stopping","title":"Early Stopping","text":"Now time define logger track runtime. mentioned , set use_as_stopper = TRUE. setting max_time define long want train model, 50000 microseconds: can see, fittings stopped early 629 train full 2000 iterations. logger data can accessed calling $getLoggerData():","code":"cboost$addLogger(logger = LoggerTime, use_as_stopper = TRUE, logger_id = \"time\",   max_time = 50000, time_unit = \"microseconds\")  cboost$train(2000, trace = 250) #>    1/2000   risk = 0.67  time = 0    #>  250/2000   risk = 0.5  time = 18367    #>  500/2000   risk = 0.48  time = 38777    #>  #>  #> Train 629 iterations in 0 Seconds. #> Final risk based on the train set: 0.48 cboost #>  #>  #> Component-Wise Gradient Boosting #>  #> Target variable: Survived #> Number of base-learners: 3 #> Learning rate: 0.05 #> Iterations: 629 #>  #> Offset: 0.423 #>  #> LossBinomial: L(y,x) = log(1 + exp(-2yf(x)) tail(cboost$getLoggerData()) #>     _iterations  time baselearner train_risk #> 625         624 49641  Age_spline  0.4782018 #> 626         625 49726   Sex_ridge  0.4781720 #> 627         626 49816  Age_spline  0.4781521 #> 628         627 49907 Fare_spline  0.4781271 #> 629         628 49998  Age_spline  0.4781073 #> 630         629 50089  Age_spline  0.4780877"},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-early-stopping.html","id":"loss-based-early-stopping","dir":"Articles","previous_headings":"","what":"Loss-Based Early Stopping","title":"Early Stopping","text":"machine learning, often like stop best model performance. need either tuning early stopping determine good number iterations \\(m\\). well-known procedure log --bag (oob) behavior model stop model performance starts get worse. required parameters logger loss \\(L\\) used stopping: \\[\\mathcal{R}_{\\text{emp}}^{[m]} = \\frac{1}{n}\\sum_{=1}^n L\\left(y^{()}, f^{[m]}(x^{()})\\right)\\] percentage performance increase lower boundary increase: \\[\\text{err}^{[m]} = \\frac{\\mathcal{R}_{\\text{emp}}^{[m- 1]} - \\mathcal{R}_{\\text{emp}}^{[m]}}{\\mathcal{R}_{\\text{emp}}^{[m - 1]}}\\]","code":""},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-early-stopping.html","id":"define-the-risk-logger","dir":"Articles","previous_headings":"Loss-Based Early Stopping","what":"Define the risk logger","title":"Early Stopping","text":"Since interested oob behavior, necessary prepare oob data response compboost. Therefore, possible use $prepareResponse() $prepareData() member functions create suitable objects: objects can add oob risk logger, declare stopper, train model: Note: use eps_for_break = 0 hard constrain stop training oob risk starts increase. Taking look logger data tells us stopped exactly first five differences bigger zero (oob risk iterations bigger previous ones):  Taking look 2000 iterations shows stopped quite good:  Note: can happen model’s oob behavior increases locally iterations starts decrease . capture , need “patience” parameter waits , let’s say, 5 iterations stops algorithm improvement 5 iterations smaller criteria. Setting parameter one can lead unstable results:","code":"oob_response = cboost$prepareResponse(df$Survived[idx_test]) oob_data = cboost$prepareData(df[idx_test,]) cboost$addLogger(logger = LoggerOobRisk, use_as_stopper = TRUE, logger_id = \"oob\",   used_loss = LossBinomial$new(), eps_for_break = 0, patience = 5, oob_data = oob_data,   oob_response = oob_response)  cboost$train(2000, trace = 250) #>    1/2000   risk = 0.67  oob = 0.68    #>  250/2000   risk = 0.5  oob = 0.49    #>  500/2000   risk = 0.48  oob = 0.48    #>  #>  #> Train 543 iterations in 0 Seconds. #> Final risk based on the train set: 0.48 tail(cboost$getLoggerData(), n = 10) #>     _iterations       oob baselearner train_risk #> 535         534 0.4784209   Sex_ridge  0.4806872 #> 536         535 0.4784327  Age_spline  0.4806586 #> 537         536 0.4784332 Fare_spline  0.4806242 #> 538         537 0.4784450  Age_spline  0.4805959 #> 539         538 0.4783287   Sex_ridge  0.4805564 #> 540         539 0.4783405  Age_spline  0.4805284 #> 541         540 0.4783415 Fare_spline  0.4804943 #> 542         541 0.4783534  Age_spline  0.4804666 #> 543         542 0.4783547 Fare_spline  0.4804330 #> 544         543 0.4783665  Age_spline  0.4804054 diff(tail(cboost$getLoggerData()$oob, n = 10)) #> [1]  1.180302e-05  5.400260e-07  1.179882e-05 -1.163699e-04  1.187324e-05 #> [6]  9.532968e-07  1.186647e-05  1.321357e-06  1.185917e-05 library(ggplot2)  ggplot(data = cboost$getLoggerData(), aes(x = `_iterations`, y = oob)) +   geom_line() +   xlab(\"Iteration\") +   ylab(\"Empirical Risk\") #> Warning: Removed 1 row containing missing values (`geom_line()`). cboost$train(2000, trace = 0) #>  #> You have already trained 543 iterations. #> Train 1457 additional iterations.  ggplot(data = cboost$getLoggerData(), aes(x = `_iterations`, y = oob)) +   geom_line() +   xlab(\"Iteration\") +   ylab(\"Empirical Risk\") #> Warning: Removed 1 row containing missing values (`geom_line()`). df = na.omit(titanic::titanic_train) df$Survived = factor(df$Survived, labels = c(\"no\", \"yes\"))  set.seed(123) idx_train = sample(seq_len(nrow(df)), size = nrow(df) * 0.8) idx_test = setdiff(seq_len(nrow(df)), idx_train)  cboost = Compboost$new(data = df[idx_train, ], target = \"Survived\", loss = LossBinomial$new())  cboost$addBaselearner(\"Age\", \"spline\", BaselearnerPSpline) cboost$addBaselearner(\"Fare\", \"spline\", BaselearnerPSpline) cboost$addBaselearner(\"Sex\", \"ridge\", BaselearnerCategoricalRidge)  oob_response = cboost$prepareResponse(df$Survived[idx_test]) oob_data = cboost$prepareData(df[idx_test,])  cboost$addLogger(logger = LoggerOobRisk, use_as_stopper = TRUE, logger_id = \"oob\",   used_loss = LossBinomial$new(), eps_for_break = 0, patience = 1, oob_data = oob_data,   oob_response = oob_response)  cboost$train(2000, trace = 0) #> Train 320 iterations in 0 Seconds. #> Final risk based on the train set: 0.49   library(ggplot2) ggplot(data = cboost$getLoggerData(), aes(x = `_iterations`, y = oob)) +   geom_line() +   xlab(\"Iteration\") +   ylab(\"Empirical Risk\") #> Warning: Removed 1 row containing missing values (`geom_line()`)."},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-early-stopping.html","id":"further-comments-on-risk-logging","dir":"Articles","previous_headings":"Loss-Based Early Stopping","what":"Further comments on risk logging","title":"Early Stopping","text":"Since can define many logger like, possible define multiple risk logger regarding different loss functions. also possible log performance measures risk logging mechanism. covered advanced topic.","code":""},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-early-stopping.html","id":"some-remarks","dir":"Articles","previous_headings":"","what":"Some remarks","title":"Early Stopping","text":"locally (): algorithm stops first stopping criteria logger reached globally (): algorithm stops stopping criteria reached arguments ignored logger set stopper, e.g. max_time time logger logger functionality summarized ","code":""},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-obj-refs.html","id":"response-class","dir":"Articles","previous_headings":"","what":"Response Class","title":"Reference based objects","text":"target variable represented object inherits Response class. Depending target type like different transformations internally predicted scores. instance, binary classification task score \\(\\hat{f}(x) \\\\mathbb{R}\\) transformed \\([0,1]\\) scale using logistic function: \\[ \\hat{\\pi}(x) = \\frac{1}{1 + \\exp(-\\hat{f}(x))} \\] show references work , first define ResponseBinaryClassif object. Therefore, use mtcars dataset create new binary target variable fast \\(\\text{qsec} < 17\\) slow \\(\\text{qsec} \\geq 17\\) cars create response object: access underlying representation response class (binary variable) one can use $getResponse(). initialization new response object, prediction \\(\\hat{f} \\\\mathbb{R}\\) initialized zeros. can also use response object calculate transformed predictions \\(\\hat{\\pi} \\[0,1]\\): case binary classification, can use response object calculate predictions label basis using specified threshold \\(\\): \\[ \\hat{y} = 1 \\ \\ \\text{} \\ \\ \\hat{\\pi}(x) \\geq \\] default threshold 0.5: setting threshold 0.6 observe now class predicted negative: behavior nothing references moment. fitting component-wise boosting model, predictions adjusted Compboost object. reference comes : look predictions shows difference values training. fitting process, predictions response object updated model:","code":"df = mtcars[, c(\"mpg\", \"disp\", \"hp\", \"drat\", \"wt\")] df$qsec_cat = ifelse(mtcars$qsec < 17, \"fast\", \"slow\")  obj_response = ResponseBinaryClassif$new(\"qsec_cat\", \"fast\", df$qsec_cat) obj_response #>  #> Binary classification response of target \"qsec_cat\" and threshold 0.5 #> ResponseBinaryClassifPrinter knitr::kable(head(data.frame(   target = df$qsec_cat,   target_representation = obj_response$getResponse(),   prediction_initialization = obj_response$getPrediction(),   prediction_transformed = obj_response$getPredictionTransform() ))) obj_response$getThreshold() #> [1] 0.5 head(obj_response$getPredictionResponse()) #>      [,1] #> [1,]    1 #> [2,]    1 #> [3,]    1 #> [4,]    1 #> [5,]    1 #> [6,]    1 obj_response$setThreshold(0.6) head(obj_response$getPredictionResponse()) #>      [,1] #> [1,]   -1 #> [2,]   -1 #> [3,]   -1 #> [4,]   -1 #> [5,]   -1 #> [6,]   -1 cboost = boostSplines(data = df, target = obj_response,   iterations = 2000L, trace = 500L) #>    1/2000   risk = 0.59  time = 0    #>  500/2000   risk = 0.22  time = 12524    #> 1000/2000   risk = 0.15  time = 33032    #> 1500/2000   risk = 0.12  time = 61677    #> 2000/2000   risk = 0.1  time = 98480    #>  #>  #> Train 2000 iterations in 0 Seconds. #> Final risk based on the train set: 0.1 knitr::kable(head(data.frame(   target = df$qsec_cat,   prediction = obj_response$getPrediction(),   prediction_transformed = obj_response$getPredictionTransform(),   prediction_response = obj_response$getPredictionResponse() )))"},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-robust-reg.html","id":"how-does-it-work","dir":"Articles","previous_headings":"","what":"How does it work?","title":"Quantile/Robust regression","text":"Predicting quantiles controlled choice loss function. Quantile regression originally motivated general additive/linear models (see ). use define following loss function: \\[ L(y, f(x)) = h|y - f(x)| \\] \\[ h = \\left\\{ \\begin{array}{ccc} 2q       & \\ \\ \\text{} \\ \\ & y - f(x) > 0 \\\\ 2(1 - q) & \\ \\ \\text{} \\ \\ & \\text{otherwise} \\end{array} \\right. \\] \\(q\\) q-quantile. Visualizing loss \\(y - f(x)\\) shows , e.g., boosting 90 % quantile punishes residuals harder residuals smaller zeros leads optimization 90 % quantile:","code":""},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-robust-reg.html","id":"simulate-data","dir":"Articles","previous_headings":"","what":"Simulate data","title":"Quantile/Robust regression","text":"show effect quantile/robust regression simulate data follows sinus curve 20 outliers:","code":"nsim = 1000 noutlier = 20 outlier_mean = 1e6  x = runif(nsim, 0, 10) y = 3 + 2 * sin(x) + rnorm(nsim, 0, 1)  outlier_idx = sample(nsim, noutlier) y[outlier_idx] = sample(x = c(-1, 1), size = noutlier, replace = TRUE) * rnorm(noutlier, outlier_mean, 1)  df = data.frame(x = x, y = y) #> Warning: Removed 20 rows containing missing values (`geom_point()`)."},{"path":[]},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-robust-reg.html","id":"boosting-the-median","dir":"Articles","previous_headings":"How to use","what":"Boosting the median","title":"Quantile/Robust regression","text":"need use LossQuantile class generator. example, boost median (50 % quantile) pass 0.5 constructor: little side note: Boosting median 50 % quantile equivalent conduct boosting absolute loss. loss_quantile90 loss object can now used define train new Compboost object: Using quantiles, absolute loss median, also known robust regression. visualize effect outliers regression, also train model QuadraticLoss:  Boosting quadratic loss quite sensitive outliers. course, example exaggerated show effect boosting median.","code":"loss_quantile50 = LossQuantile$new(0.5) loss_quantile50 #> LossQuantile: L(y,x) = h|y - f(x)| #>  #> h = 2q        if  y - f(x) > 0 #>   h = 2(1 - q)  otherwise #>  #>   with quantile q = 0.5 cboost_quantile50 = boostSplines(data = df, target = \"y\", loss = loss_quantile50, iterations = 1000L, trace = 200L) #>    1/1000   risk = 2e+04  time = 0    #>  200/1000   risk = 2e+04  time = 12156    #>  400/1000   risk = 2e+04  time = 25264    #>  600/1000   risk = 2e+04  time = 39565    #>  800/1000   risk = 2e+04  time = 55115    #> 1000/1000   risk = 2e+04  time = 72084    #>  #>  #> Train 1000 iterations in 0 Seconds. #> Final risk based on the train set: 2e+04 cboost_mean = boostSplines(data = df, target = \"y\", iterations = 1000L, trace = 0) #> Train 1000 iterations in 0 Seconds. #> Final risk based on the train set: 9.8e+09  df_plot = data.frame(   feature = rep(x, times = 2),   preds = c(cboost_mean$predict(), cboost_quantile50$predict()),   estimator = rep(c(\"mean\", \"median\"), each = length(x)) )  library(ggsci)  gg1 = ggplot() +   geom_point(data = df, aes(x = x, y = y), show.legend = FALSE, alpha = 0.5) +   geom_line(data = df_plot, aes(x = feature, y = preds, color = estimator), size = 1.2) +   ggtitle(\"Full target range (with outliers)\") #> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. #> ℹ Please use `linewidth` instead.  gg2 = ggplot() +   geom_point(data = df, aes(x = x, y = y), show.legend = FALSE, alpha = 0.5) +   geom_line(data = df_plot, aes(x = feature, y = preds, color = estimator), size = 1.2) +   ggtitle(\"Real target range (without outliers)\") +   ylim(-2, 8)  (gg1 | gg2) +   plot_layout(guides = \"collect\") &   theme(legend.position = \"bottom\") &   theme_tufte() &   scale_color_jama() #> Warning: Removed 20 rows containing missing values (`geom_point()`). #> Warning: Removed 1000 rows containing missing values (`geom_line()`)."},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-robust-reg.html","id":"boosting-arbitrary-quantiles","dir":"Articles","previous_headings":"How to use","what":"Boosting arbitrary quantiles","title":"Quantile/Robust regression","text":"Instead boosting median can boost quantile like. following example, boost 10 % 90 % quantile get “kind confidence interval”. careful using term confidence interval . predictions estimated independently may tighten boundaries:","code":"cboost = boostSplines(data = df, target = \"y\", iterations = 1000, trace = 0) #> Train 1000 iterations in 0 Seconds. #> Final risk based on the train set: 9.8e+09 cboost_10 = boostSplines(data = df, target = \"y\", loss = LossQuantile$new(0.1), iterations = 1000, trace = 0) #> Train 1000 iterations in 0 Seconds. #> Final risk based on the train set: 2.2e+04 cboost_50 = boostSplines(data = df, target = \"y\", loss = LossQuantile$new(0.5), iterations = 1000, trace = 0) #> Train 1000 iterations in 0 Seconds. #> Final risk based on the train set: 2e+04 cboost_90 = boostSplines(data = df, target = \"y\", loss = LossQuantile$new(0.9), iterations = 1000, trace = 0) #> Train 1000 iterations in 0 Seconds. #> Final risk based on the train set: 1.8e+04  df_pred = data.frame(   feat = rep(x, 4),   target = rep(y, 4),   pred = c(cboost$predict(), cboost_10$predict(), cboost_50$predict(), cboost_90$predict()),   estimator = rep(c(\"Mean\", \"10% Quantile\", \"Median\", \"90% Quantile\"), each = 1000L))  gg1 = ggplot() +   geom_point(data = df_pred, aes(x = feat, y = target), alpha = 0.2) +   geom_line(data = df_pred, aes(x = feat, y = pred, color = estimator), size = 1.2) +   xlab(\"Feature\") +   ylab(\"Target\") +   ggtitle(\"Full target range (with outliers)\")  gg2 = ggplot() +   geom_point(data = df_pred, aes(x = feat, y = target), alpha = 0.2) +   geom_line(data = df_pred, aes(x = feat, y = pred, color = estimator), size = 1.2) +   ylim(-2, 8) +   xlab(\"Feature\") +   ylab(\"\") +   ggtitle(\"Real target range (without outliers)\")  (gg1 | gg2) +   plot_layout(guides = \"collect\") &   theme_tufte() &   theme(legend.position = \"bottom\") &   scale_color_aaas() #> Warning: Removed 80 rows containing missing values (`geom_point()`). #> Warning: Removed 1000 rows containing missing values (`geom_line()`)."},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-robust-reg.html","id":"comments","dir":"Articles","previous_headings":"","what":"Comments","title":"Quantile/Robust regression","text":"Boosting median technique get robust model. Nevertheless, boosting mean nice estimation properties. variance estimators introduced use quantile loss. get precise predictions, need data reduce variance. Another loss superior terms variance Huber loss LossHuber$new() uses quadratic approximation around zero linear extrapolation threshold \\(\\delta\\).","code":""},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-use-case.html","id":"data-titanic-passenger-survival-data-set","dir":"Articles","previous_headings":"","what":"Data: Titanic Passenger Survival Data Set","title":"Use-case","text":"use titanic dataset binary classification survived. First store train test data two data frames remove rows contains NAs: next step transform response factor intuitive levels:","code":"# Store train and test data: df_train = na.omit(titanic::titanic_train)  str(df_train) #> 'data.frame':    714 obs. of  12 variables: #>  $ PassengerId: int  1 2 3 4 5 7 8 9 10 11 ... #>  $ Survived   : int  0 1 1 1 0 0 0 1 1 1 ... #>  $ Pclass     : int  3 1 3 1 3 1 3 3 2 3 ... #>  $ Name       : chr  \"Braund, Mr. Owen Harris\" \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\" \"Heikkinen, Miss. Laina\" \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\" ... #>  $ Sex        : chr  \"male\" \"female\" \"female\" \"female\" ... #>  $ Age        : num  22 38 26 35 35 54 2 27 14 4 ... #>  $ SibSp      : int  1 1 0 1 0 0 3 0 1 1 ... #>  $ Parch      : int  0 0 0 0 0 0 1 2 0 1 ... #>  $ Ticket     : chr  \"A/5 21171\" \"PC 17599\" \"STON/O2. 3101282\" \"113803\" ... #>  $ Fare       : num  7.25 71.28 7.92 53.1 8.05 ... #>  $ Cabin      : chr  \"\" \"C85\" \"\" \"C123\" ... #>  $ Embarked   : chr  \"S\" \"C\" \"S\" \"S\" ... #>  - attr(*, \"na.action\")= 'omit' Named int [1:177] 6 18 20 27 29 30 32 33 37 43 ... #>   ..- attr(*, \"names\")= chr [1:177] \"6\" \"18\" \"20\" \"27\" ... df_train$Survived = factor(df_train$Survived, labels = c(\"no\", \"yes\"))"},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-use-case.html","id":"initializing-model","dir":"Articles","previous_headings":"","what":"Initializing Model","title":"Use-case","text":"Due R6 API necessary create new class object gets data, target character, used loss. Note important give initialized loss object: Use initialized object loss gives opportunity use loss initialized custom offset.","code":"cboost = Compboost$new(data = df_train, target = \"Survived\", oob_fraction = 0.3)"},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-use-case.html","id":"adding-base-learner","dir":"Articles","previous_headings":"","what":"Adding Base-Learner","title":"Use-case","text":"Adding new base-learners also done giving character indicate feature. second argument important name identifier factory since can define multiple base-learner source.","code":""},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-use-case.html","id":"numerical-features","dir":"Articles","previous_headings":"Adding Base-Learner","what":"Numerical Features","title":"Use-case","text":"instance, can define spline linear base-learner feature: Additional arguments can specified naming base-learner. complete list see functionality project page:","code":"# Spline base-learner of age: cboost$addBaselearner(\"Age\", \"spline\", BaselearnerPSpline)  # Linear base-learner of age (degree = 1 with intercept is default): cboost$addBaselearner(\"Age\", \"linear\", BaselearnerPolynomial) # Spline base-learner of fare: cboost$addBaselearner(\"Fare\", \"spline\", BaselearnerPSpline, degree = 2,   n_knots = 14, penalty = 10, differences = 2)"},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-use-case.html","id":"categorical-features","dir":"Articles","previous_headings":"Adding Base-Learner","what":"Categorical Features","title":"Use-case","text":"adding categorical features use dummy coded representation ridge penalty: Finally, can check factories registered:","code":"cboost$addBaselearner(\"Sex\", \"categorical\", BaselearnerCategoricalRidge) cboost$getBaselearnerNames() #> [1] \"Age_spline\"      \"Age_linear\"      \"Fare_spline\"     \"Sex_categorical\""},{"path":[]},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-use-case.html","id":"time-logger","dir":"Articles","previous_headings":"Define Logger","what":"Time logger","title":"Use-case","text":"logger logs elapsed time. time unit can one microseconds, seconds minutes. logger stops max_time reached. use logger stopper :","code":"cboost$addLogger(logger = LoggerTime, use_as_stopper = FALSE, logger_id = \"time\",   max_time = 0, time_unit = \"microseconds\")"},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-use-case.html","id":"train-model-and-access-elements","dir":"Articles","previous_headings":"","what":"Train Model and Access Elements","title":"Use-case","text":"Objects Compboost class member functions getCoef(), getInbagRisk() predict() access results: obtain vector selected base learners use getSelectedBaselearner(): can also access predictions directly response object cboost$response cboost$response_oob. Note $response_oob created automatically defining oob_fraction within constructor:","code":"cboost$train(2000, trace = 250) #>    1/2000   risk = 0.68  oob_risk = 0.65   time = 0    #>  250/2000   risk = 0.5  oob_risk = 0.51   time = 18617    #>  500/2000   risk = 0.47  oob_risk = 0.5   time = 39433    #>  750/2000   risk = 0.47  oob_risk = 0.5   time = 62294    #> 1000/2000   risk = 0.46  oob_risk = 0.5   time = 87397    #> 1250/2000   risk = 0.46  oob_risk = 0.51   time = 115570    #> 1500/2000   risk = 0.46  oob_risk = 0.51   time = 145200    #> 1750/2000   risk = 0.46  oob_risk = 0.51   time = 177829    #> 2000/2000   risk = 0.46  oob_risk = 0.51   time = 211500    #>  #>  #> Train 2000 iterations in 0 Seconds. #> Final risk based on the train set: 0.46 cboost #>  #>  #> Component-Wise Gradient Boosting #>  #> Target variable: Survived #> Number of base-learners: 4 #> Learning rate: 0.05 #> Iterations: 2000 #>  #> Offset: 0.2982 #>  #> LossBinomial: L(y,x) = log(1 + exp(-2yf(x)) str(cboost$getCoef()) #> List of 4 #>  $ Age_spline     : num [1:24, 1] -1.51 -1.02 -2.1 2.34 1.11 ... #>   ..- attr(*, \"blclass\")= chr \"Rcpp_BaselearnerPSpline\" #>  $ Fare_spline    : num [1:17, 1] 1.122 0.239 -0.582 -1.2 -1.028 ... #>   ..- attr(*, \"blclass\")= chr \"Rcpp_BaselearnerPSpline\" #>  $ Sex_categorical: num [1:2, 1] -1.487 0.963 #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:2] \"female\" \"male\" #>   .. ..$ : NULL #>   ..- attr(*, \"blclass\")= chr \"Rcpp_BaselearnerCategoricalRidge\" #>  $ offset         : num 0.298 str(cboost$getInbagRisk()) #>  num [1:2001] 0.682 0.678 0.675 0.671 0.668 ... str(cboost$predict()) #>  num [1:500, 1] -1.952 -0.864 -2.055 1.465 1.221 ... table(cboost$getSelectedBaselearner()) #>  #>      Age_spline     Fare_spline Sex_categorical  #>            1317             344             339 oob_label = cboost$response_oob$getResponse() oob_pred = cboost$response_oob$getPredictionResponse() table(true_label = oob_label, predicted = oob_pred) #>           predicted #> true_label  -1   1 #>         -1  47  30 #>         1   22 115"},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-use-case.html","id":"retrain-the-model","dir":"Articles","previous_headings":"","what":"Retrain the Model","title":"Use-case","text":"continue training set whole model another iteration simply re-call train():","code":"cboost$train(3000) #>  #> You have already trained 2000 iterations. #> Train 1000 additional iterations. #>  #> 2025/3000   risk = 0.46  oob_risk = 0.51   time = 215231    #> 2100/3000   risk = 0.46  oob_risk = 0.51   time = 225805    #> 2175/3000   risk = 0.46  oob_risk = 0.51   time = 236492    #> 2250/3000   risk = 0.46  oob_risk = 0.51   time = 247657    #> 2325/3000   risk = 0.45  oob_risk = 0.51   time = 258818    #> 2400/3000   risk = 0.45  oob_risk = 0.51   time = 270515    #> 2475/3000   risk = 0.45  oob_risk = 0.52   time = 281941    #> 2550/3000   risk = 0.45  oob_risk = 0.52   time = 293591    #> 2625/3000   risk = 0.45  oob_risk = 0.52   time = 305380    #> 2700/3000   risk = 0.45  oob_risk = 0.52   time = 317558    #> 2775/3000   risk = 0.45  oob_risk = 0.52   time = 329800    #> 2850/3000   risk = 0.45  oob_risk = 0.52   time = 342136    #> 2925/3000   risk = 0.45  oob_risk = 0.52   time = 354700    #> 3000/3000   risk = 0.45  oob_risk = 0.52   time = 367486  str(cboost$getCoef()) #> List of 4 #>  $ Age_spline     : num [1:24, 1] -2.13 -0.721 -2.485 2.731 0.931 ... #>   ..- attr(*, \"blclass\")= chr \"Rcpp_BaselearnerPSpline\" #>  $ Fare_spline    : num [1:17, 1] 1.159 0.263 -0.618 -1.313 -1.079 ... #>   ..- attr(*, \"blclass\")= chr \"Rcpp_BaselearnerPSpline\" #>  $ Sex_categorical: num [1:2, 1] -1.526 0.988 #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:2] \"female\" \"male\" #>   .. ..$ : NULL #>   ..- attr(*, \"blclass\")= chr \"Rcpp_BaselearnerCategoricalRidge\" #>  $ offset         : num 0.298 str(cboost$getInbagRisk()) #>  num [1:3001] 0.682 0.678 0.675 0.671 0.668 ... table(cboost$getSelectedBaselearner()) #>  #>      Age_spline     Fare_spline Sex_categorical  #>            2133             467             400"},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-use-case.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next steps","title":"Use-case","text":"look visualization capabilities package. See loss functions effect model training.","code":""},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-viz.html","id":"fit-compboost","dir":"Articles","previous_headings":"","what":"Fit compboost","title":"Visualizing a compboost model","text":"data set use mpg: want model miles per gallon (mpg). features include linear centered spline hp, wt, qsec. Additionally, add categorical base learner number cylinders cyl:","code":"mtcars$cyl = as.factor(mtcars$cyl)  set.seed(31415) cboost = Compboost$new(data = mtcars, target = \"mpg\", learning_rate = 0.02, oob_fraction = 0.2)  cboost$addComponents(\"hp\", df = 3) cboost$addComponents(\"wt\", df = 3) cboost$addComponents(\"qsec\", df = 3) cboost$addBaselearner(\"cyl\", \"ridge\", BaselearnerCategoricalRidge, df = 3)  cboost$train(500L, trace = 100L) #>   1/500   risk = 17  oob_risk = 17    #> 100/500   risk = 3  oob_risk = 2.8    #> 200/500   risk = 2.4  oob_risk = 3.2    #> 300/500   risk = 2.3  oob_risk = 3.2    #> 400/500   risk = 2.3  oob_risk = 3.1    #> 500/500   risk = 2.2  oob_risk = 3.1    #>  #>  #> Train 500 iterations in 0 Seconds. #> Final risk based on the train set: 2.2"},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-viz.html","id":"visualize-risk-feature-importance-and-selection-traces","dir":"Articles","previous_headings":"","what":"Visualize risk, feature importance, and selection traces","title":"Visualizing a compboost model","text":"starting point analyzing component-wise boosting model take look train validation risk:  can see, best validation risk iteration 98. Hence, set model iteration: Next, interested important base learners/features:  last thing can get better overview model look features/base learners included model:","code":"plotRisk(cboost) m_optimal = which.min(cboost$getLoggerData()[[\"oob_risk\"]]) cboost$train(m_optimal) plotFeatureImportance(cboost) plotBaselearnerTraces(cboost)"},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-viz.html","id":"visualize-base-learner-and-partial-effects","dir":"Articles","previous_headings":"","what":"Visualize base learner and partial effects","title":"Visualizing a compboost model","text":"Next, want deep dive effects individual features, .e, effect base learners. end, plot partial effects important feature wt:  observe clear negative trend, meaning increasing weight indicates lower mpg. Additionally, can visualize individual base learners. example categorical feature cyl:  , observe 4 cylinder indicates positive contribution mpg 6 8 cylinder reducing .","code":"plotPEUni(cboost, \"wt\") plotBaselearner(cboost, \"cyl_ridge\")"},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-viz.html","id":"visualizing-individual-predictions","dir":"Articles","previous_headings":"","what":"Visualizing individual predictions","title":"Visualizing a compboost model","text":"predictions also want get idea specific contribution feature predicted score. Therefore, take look first observation validation data set:  can see, prediction dominated offset. remove figure set offset = FALSE:  wt hp positive contribution predicted score. means car requires less fuel 6 cylinder slightly increases mpg prediction.","code":"plotIndividualContribution(cboost, newdata = cboost$data_oob[1, ]) plotIndividualContribution(cboost, newdata = cboost$data_oob[1, ], offset = FALSE)"},{"path":"https://schalkdaniel.github.io/compboost/articles/basic-viz.html","id":"visualizing-tensor-products","dir":"Articles","previous_headings":"","what":"Visualizing tensor products","title":"Visualizing a compboost model","text":"last visualization convenience wrapper illustrate interactions included tensors. Therefore, add tensors model: Depending feature combination (numeric - numeric, numeric - categorical, categorical - categorical) different visualization technique used:","code":"mtcars$vs = as.factor(mtcars$vs) mtcars$gear = as.factor(mtcars$gear)  set.seed(31415) cboost = Compboost$new(data = mtcars, target = \"mpg\", oob_fraction = 0.2)  cboost$addTensor(\"wt\", \"qsec\", df = 2) cboost$addTensor(\"hp\", \"cyl\", df = 2) cboost$addTensor(\"gear\", \"vs\", df = 2)  cboost$train(500L, trace = 100L) #>   1/500   risk = 16  oob_risk = 16    #> 100/500   risk = 2.4  oob_risk = 4    #> 200/500   risk = 2.2  oob_risk = 4.4    #> 300/500   risk = 2.1  oob_risk = 4.4    #> 400/500   risk = 2.1  oob_risk = 4.5    #> 500/500   risk = 2  oob_risk = 4.5    #>  #>  #> Train 500 iterations in 0 Seconds. #> Final risk based on the train set: 2 table(cboost$getSelectedBaselearner()) #>  #> gear_vs_tensor  hp_cyl_tensor wt_qsec_tensor  #>            258            181             61 library(ggplot2)  gg1 = plotTensor(cboost, \"wt_qsec_tensor\") + ggtitle(\"Num - Num\") gg2 = plotTensor(cboost, \"hp_cyl_tensor\") + ggtitle(\"Num - Cat\") gg3 = plotTensor(cboost, \"gear_vs_tensor\") + ggtitle(\"Cat - Cat\")  library(patchwork)  gg1 | gg2 | gg3"},{"path":"https://schalkdaniel.github.io/compboost/articles/fct-baselearner.html","id":"baselearnerpolynomial","dir":"Articles","previous_headings":"","what":"BaselearnerPolynomial","title":"Base learner functionality","text":"see help page.","code":""},{"path":"https://schalkdaniel.github.io/compboost/articles/fct-baselearner.html","id":"baselearnerpsplinefactory","dir":"Articles","previous_headings":"","what":"BaselearnerPSplineFactory","title":"Base learner functionality","text":"see help page.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://schalkdaniel.github.io/compboost/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel Schalk. Author, maintainer. Janek Thomas. Author. Bernd Bischl. Author.","code":""},{"path":"https://schalkdaniel.github.io/compboost/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Schalk D, Thomas J, Bischl B (2018). “compboost: Modular Framework Component-Wise Boosting.” JOSS, 3(30), 967. doi:10.21105/joss.00967, https://doi.org/10.21105/joss.00967.","code":"@Article{,   author = {Daniel Schalk and Janek Thomas and Bernd Bischl},   title = {compboost: Modular Framework for Component-Wise Boosting},   doi = {10.21105/joss.00967},   url = {https://doi.org/10.21105/joss.00967},   year = {2018},   publisher = {Journal of Open Source Software},   volume = {3},   number = {30},   pages = {967},   journal = {JOSS}, }"},{"path":"https://schalkdaniel.github.io/compboost/index.html","id":"compboost-fast-and-flexible-component-wise-boosting-framework-","dir":"","previous_headings":"","what":"C++ Implementation of Component-Wise Boosting","title":"C++ Implementation of Component-Wise Boosting","text":"Documentation | Contributors | Release Notes","code":""},{"path":"https://schalkdaniel.github.io/compboost/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"C++ Implementation of Component-Wise Boosting","text":"Component-wise boosting applies boosting framework statistical models, e.g., general additive models using component-wise smoothing splines. Boosting kinds models maintains interpretability enables unbiased model selection high dimensional feature spaces. R package compboost alternative implementation component-wise boosting written C++ obtain high runtime performance full memory control. main idea provide modular class system can extended without editing source code. Therefore, possible use R functions well C++ functions custom base-learners, losses, logging mechanisms stopping criteria. introduction overview functionality visit project page.","code":""},{"path":[]},{"path":"https://schalkdaniel.github.io/compboost/index.html","id":"cran-version","dir":"","previous_headings":"Installation","what":"CRAN version:","title":"C++ Implementation of Component-Wise Boosting","text":"","code":"install.packages(\"compboost\")"},{"path":"https://schalkdaniel.github.io/compboost/index.html","id":"developer-version","dir":"","previous_headings":"Installation","what":"Developer version:","title":"C++ Implementation of Component-Wise Boosting","text":"","code":"devtools::install_github(\"schalkdaniel/compboost\")"},{"path":"https://schalkdaniel.github.io/compboost/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"C++ Implementation of Component-Wise Boosting","text":"examples rendered using compboost 0.1.1. fastest way train Compboost model use wrapper functions boostLinear() boostSplines():  extensive examples use R6 interface visit project page.","code":"cboost = boostSplines(data = iris, target = \"Sepal.Length\",   oob_fraction = 0.3, iterations = 500L, trace = 100L)  ggrisk = plotRisk(cboost) ggpe = plotPEUni(cboost, \"Petal.Length\") ggicont =  plotIndividualContribution(cboost, iris[70, ], offset = FALSE)  library(patchwork)  ggrisk + ggpe + ggicont"},{"path":"https://schalkdaniel.github.io/compboost/index.html","id":"save-and-load-models","dir":"","previous_headings":"","what":"Save and load models","title":"C++ Implementation of Component-Wise Boosting","text":"usage C++ objects backend, possible use Rs save() method save models. Instead, use $saveToJson(\"mymodel.json\") save model mymodel.json Compboost$new(file = \"mymodel.json\") load model:","code":"cboost = boostSplines(iris, \"Sepal.Width\") cboost$saveToJson(\"mymodel.json\")  cboost_new = Compboost$new(file = \"mymodel.json\")"},{"path":"https://schalkdaniel.github.io/compboost/index.html","id":"benchmark","dir":"","previous_headings":"","what":"Benchmark","title":"C++ Implementation of Component-Wise Boosting","text":"small benchmark conducted compare compboost mboost. purpose, runtime behavior memory consumption two packages compared. results benchmark can read . bigger benchmark adaptions increase runtime memory efficiency can found .","code":""},{"path":"https://schalkdaniel.github.io/compboost/index.html","id":"citing","dir":"","previous_headings":"","what":"Citing","title":"C++ Implementation of Component-Wise Boosting","text":"cite compboost publications, please use: Schalk et al., (2018). compboost: Modular Framework Component-Wise Boosting. Journal Open Source Software, 3(30), 967, https://doi.org/10.21105/joss.00967","code":"@article{schalk2018compboost,   author = {Daniel Schalk, Janek Thomas, Bernd Bischl},   title = {compboost: Modular Framework for Component-Wise Boosting},   URL = {https://doi.org/10.21105/joss.00967},   year = {2018},   publisher = {Journal of Open Source Software},   volume = {3},   number = {30},   pages = {967},   journal = {JOSS} }"},{"path":[]},{"path":"https://schalkdaniel.github.io/compboost/index.html","id":"on-your-local-machine","dir":"","previous_headings":"Testing","what":"On your local machine","title":"C++ Implementation of Component-Wise Boosting","text":"order test package functionality can use devtools test package local machine:","code":"devtools::test()"},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCategoricalBinary.html","id":null,"dir":"Reference","previous_headings":"","what":"Base learner factory for categorical feature on a binary base learner basis — BaselearnerCategoricalBinary","title":"Base learner factory for categorical feature on a binary base learner basis — BaselearnerCategoricalBinary","text":"BaselearnerCategoricalBinary can used estimate effects one category categorical feature. base learner gets data index vector observations assigned group. example, vector (, , b, b, , b), index vector (1, 2, 5) group . reduces memory load fasten fitting process.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCategoricalBinary.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Base learner factory for categorical feature on a binary base learner basis — BaselearnerCategoricalBinary","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCategoricalBinary.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Base learner factory for categorical feature on a binary base learner basis — BaselearnerCategoricalBinary","text":"","code":"BaselearnerCategoricalBinary$new(data_source, list(n_obs))"},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCategoricalBinary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"arguments","title":"Base learner factory for categorical feature on a binary base learner basis — BaselearnerCategoricalBinary","text":"data_source data object data object class CategoricalData contains source data.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCategoricalBinary.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Base learner factory for categorical feature on a binary base learner basis — BaselearnerCategoricalBinary","text":"class contain public fields.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCategoricalBinary.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Base learner factory for categorical feature on a binary base learner basis — BaselearnerCategoricalBinary","text":"getData() Get data matrix target data used modeling. summarizeFactory() Summarize base learner factory object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCategoricalBinary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Base learner factory for categorical feature on a binary base learner basis — BaselearnerCategoricalBinary","text":"","code":"x = sample(c(\"one\",\"two\"), 20, TRUE) ds = CategoricalDataRaw$new(x, \"cat\") bl = BaselearnerCategoricalRidge$new(ds, \"one\")  bl$getData() #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] #> [1,]    1    0    0    0    0    1    1    0    1     0     0     1     0     1 #> [2,]    0    1    1    1    1    0    0    1    0     1     1     0     1     0 #>      [,15] [,16] [,17] [,18] [,19] [,20] #> [1,]     1     0     1     0     0     1 #> [2,]     0     1     0     1     1     0 bl$summarizeFactory() #> Categorical base learner of category cat"},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCategoricalRidge.html","id":null,"dir":"Reference","previous_headings":"","what":"Base learner factory for categorical feature using Ridge penalty — BaselearnerCategoricalRidge","title":"Base learner factory for categorical feature using Ridge penalty — BaselearnerCategoricalRidge","text":"BaselearnerCategoricalRidge can used estimate effects  categorical features. categories included linear model using binary matrix. Ridge penalty enables unbiased feature selection setting penalty corresponding degree freedoms.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCategoricalRidge.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Base learner factory for categorical feature using Ridge penalty — BaselearnerCategoricalRidge","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCategoricalRidge.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Base learner factory for categorical feature using Ridge penalty — BaselearnerCategoricalRidge","text":"","code":"BaselearnerCategoricalRidge$new(data_source, list(df))"},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCategoricalRidge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"arguments","title":"Base learner factory for categorical feature using Ridge penalty — BaselearnerCategoricalRidge","text":"data_source data object data object contains source data.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCategoricalRidge.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Base learner factory for categorical feature using Ridge penalty — BaselearnerCategoricalRidge","text":"class contain public fields.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCategoricalRidge.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Base learner factory for categorical feature using Ridge penalty — BaselearnerCategoricalRidge","text":"getData() Get data matrix target data used modeling. summarizeFactory() Summarize base learner factory object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCategoricalRidge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Base learner factory for categorical feature using Ridge penalty — BaselearnerCategoricalRidge","text":"","code":"x = sample(c(\"one\",\"two\"), 20, TRUE) ds = CategoricalDataRaw$new(x, \"cat\") bl = BaselearnerCategoricalRidge$new(ds, list(df = 1))  bl$getData() #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] #> [1,]    1    0    0    1    0    1    0    0    0     0     1     0     0     0 #> [2,]    0    1    1    0    1    0    1    1    1     1     0     1     1     1 #>      [,15] [,16] [,17] [,18] [,19] [,20] #> [1,]     0     1     0     0     1     1 #> [2,]     1     0     1     1     0     0 bl$summarizeFactory() #> Categorical base learner of category cat"},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCentered.html","id":null,"dir":"Reference","previous_headings":"","what":"Base learner factory to make regression using centered base learner — BaselearnerCentered","title":"Base learner factory to make regression using centered base learner — BaselearnerCentered","text":"BaselearnerCentered creates base learner factory centered using another base learner.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCentered.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Base learner factory to make regression using centered base learner — BaselearnerCentered","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustom.html","id":null,"dir":"Reference","previous_headings":"","what":"Create custom base learner factory by using R functions. — BaselearnerCustom","title":"Create custom base learner factory by using R functions. — BaselearnerCustom","text":"BaselearnerCustom creates custom base learner factory setting custom R functions. factory object can registered within base learner list used training.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustom.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Create custom base learner factory by using R functions. — BaselearnerCustom","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustom.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create custom base learner factory by using R functions. — BaselearnerCustom","text":"","code":"BaselearnerCustom$new(data_source, list(instantiate_fun,   train_fun, predict_fun, param_fun))"},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create custom base learner factory by using R functions. — BaselearnerCustom","text":"data_source Data Object Data object contains source data. instantiate_fun function R function transform source data. details see Details. train_fun function R function train base learner target data. details see Details. predict_fun function R function predict object returned train. details see Details. param_fun function R function extract parameter object returned train. details see Details.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustom.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create custom base learner factory by using R functions. — BaselearnerCustom","text":"function must following structure: instantiateData(X) { ... return (X_trafo) } matrix argument X matrix return object. train(y, X) { ... return (SEXP) } vector argument y matrix argument X. target data used X y contains response. function can return R object stored within SEXP. predict(model, newdata) { ... return (prediction) } returned object train function passed model argument newdata contains new matrix used predicting. extractParameter() { ... return (parameters) } , model contains object returned train. returned object must matrix containing estimated parameter. parameter estimated one can return NA. example see Examples.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustom.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Create custom base learner factory by using R functions. — BaselearnerCustom","text":"class contain public fields.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustom.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Create custom base learner factory by using R functions. — BaselearnerCustom","text":"getData() Get data matrix target data used modeling. summarizeFactory() Summarize base learner factory object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create custom base learner factory by using R functions. — BaselearnerCustom","text":"","code":"# Sample data: data_mat = cbind(1, 1:10) y = 2 + 3 * 1:10  # Create new data object: data_source = InMemoryData$new(data_mat, \"my_data_name\")  instantiateDataFun = function (X) {   return(X) } # Ordinary least squares estimator: trainFun = function (y, X) {   return(solve(t(X) %*% X) %*% t(X) %*% y) } predictFun = function (model, newdata) {   return(as.matrix(newdata %*% model)) } extractParameter = function (model) {   return(as.matrix(model)) }  # Create new custom linear base learner factory: custom_lin_factory = BaselearnerCustom$new(data_source,   list(instantiate_fun = instantiateDataFun, train_fun = trainFun,     predict_fun = predictFun, param_fun = extractParameter))  # Get the transformed data: custom_lin_factory$getData() #>       [,1] [,2] #>  [1,]    1    1 #>  [2,]    1    2 #>  [3,]    1    3 #>  [4,]    1    4 #>  [5,]    1    5 #>  [6,]    1    6 #>  [7,]    1    7 #>  [8,]    1    8 #>  [9,]    1    9 #> [10,]    1   10  # Summarize factory: custom_lin_factory$summarizeFactory() #> Custom base learner Factory: #> \t- Name of the used data: my_data_name #> \t- Factory creates the following base learner: custom"},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustomCpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Create custom cpp base learner factory by using cpp functions and external\npointer. — BaselearnerCustomCpp","title":"Create custom cpp base learner factory by using cpp functions and external\npointer. — BaselearnerCustomCpp","text":"BaselearnerCustomCpp creates custom base learner factory setting custom C++ functions. factory object can registered within base learner list used training.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustomCpp.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Create custom cpp base learner factory by using cpp functions and external\npointer. — BaselearnerCustomCpp","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustomCpp.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create custom cpp base learner factory by using cpp functions and external\npointer. — BaselearnerCustomCpp","text":"","code":"BaselearnerCustomCpp$new(data_source, list(instantiate_ptr,   train_ptr, predict_ptr))"},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustomCpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create custom cpp base learner factory by using cpp functions and external\npointer. — BaselearnerCustomCpp","text":"data_source Data Object Data object contains source data. instantiate_ptr externalptr External pointer C++ instantiate data function. train_ptr externalptr External pointer C++ train function. predict_ptr externalptr External pointer C++ predict function.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustomCpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create custom cpp base learner factory by using cpp functions and external\npointer. — BaselearnerCustomCpp","text":"example see extending compboost vignette function getCustomCppExample.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustomCpp.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Create custom cpp base learner factory by using cpp functions and external\npointer. — BaselearnerCustomCpp","text":"class contain public fields.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustomCpp.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Create custom cpp base learner factory by using cpp functions and external\npointer. — BaselearnerCustomCpp","text":"getData() Get data matrix target data used modeling. summarizeFactory() Summarize base learner factory object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerCustomCpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create custom cpp base learner factory by using cpp functions and external\npointer. — BaselearnerCustomCpp","text":"","code":"if (FALSE) { # Sample data: data_mat = cbind(1, 1:10) y = 2 + 3 * 1:10  # Create new data object: data_source = InMemoryData$new(data_mat, \"my_data_name\")  # Source the external pointer exposed by using XPtr: Rcpp::sourceCpp(code = getCustomCppExample(silent = TRUE))  # Create new linear base learner: custom_cpp_factory = BaselearnerCustomCpp$new(data_source,   list(instantiate_ptr = dataFunSetter(), train_ptr = trainFunSetter(),     predict_ptr = predictFunSetter()))  # Get the transformed data: custom_cpp_factory$getData()  # Summarize factory: custom_cpp_factory$summarizeFactory() }"},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPSpline.html","id":null,"dir":"Reference","previous_headings":"","what":"Non-parametric B or P-spline base learner — BaselearnerPSpline","title":"Non-parametric B or P-spline base learner — BaselearnerPSpline","text":"BaselearnerPSpline creates spline base learner object. object calculates B-spline basis functions case P-splines also penalty. Instead defining penalty term directly, one consider restrict flexibility setting degrees freedom.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPSpline.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Non-parametric B or P-spline base learner — BaselearnerPSpline","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPSpline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Non-parametric B or P-spline base learner — BaselearnerPSpline","text":"data_source (InMemoryData)  Data object contains raw data (see ?InMemoryData). blearner_type (character(1))  Type base learner (specified, blearner_type = \"spline\" used). unique id base learner defined appending blearner_type feature name: paste0(data_source$getIdentifier(), \"_\", blearner_type) degree (integer(1)) Degree piecewise polynomial (default degree = 3 cubic splines). n_knots (integer(1)) Number inner knots (default n_knots = 20). inner knots expanded degree - 1 additional knots side prevent unstable behavior edges. penalty (numeric(1)) Penalty term P-splines (default penalty = 2). Set zero B-splines. differences (integer(1)) number differences penalized. higher value leads smoother curves. bin_root (integer(1)) binning root reduce data \\(n^{1/\\text{bin_root}}\\)$ data points (default bin_root = 1, means binning applied). value bin_root = 2 suggested best approximation error (cf. Wood et al. (2017) Generalized additive models gigadata: modeling UK black smoke network daily data).","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPSpline.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Non-parametric B or P-spline base learner — BaselearnerPSpline","text":"","code":"BaselearnerPSpline$new(data_source, list(degree, n_knots, penalty, differences, df, bin_root)) BaselearnerPSpline$new(data_source, blearner_type, list(degree, n_knots, penalty, differences, df, bin_root))"},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPSpline.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Non-parametric B or P-spline base learner — BaselearnerPSpline","text":"class contain public fields.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPSpline.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Non-parametric B or P-spline base learner — BaselearnerPSpline","text":"$summarizeFactory(): () -> () $transfromData(newdata): list(InMemoryData) -> matrix() $getMeta(): () -> list()","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPSpline.html","id":"inherited-methods-from-baselearner","dir":"Reference","previous_headings":"","what":"Inherited methods from Baselearner","title":"Non-parametric B or P-spline base learner — BaselearnerPSpline","text":"$getData(): () -> matrix() $getDF(): () -> integer() $getPenalty(): () -> numeric() $getPenaltyMat(): () -> matrix() $getFeatureName(): () -> character() $getModelName(): () -> character()","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPSpline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Non-parametric B or P-spline base learner — BaselearnerPSpline","text":"data matrix instantiated transposed sparse matrix due performance reasons. member function $getData() accounts  $transformData() returns raw data matrix p x n matrix.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPSpline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Non-parametric B or P-spline base learner — BaselearnerPSpline","text":"","code":"# Sample data: x = runif(100, 0, 10) y = sin(x) + rnorm(100, 0, 0.2) dat = data.frame(x, y)  # S4 wrapper  # Create new data object, a matrix is required as input: data_mat = cbind(x) data_source = InMemoryData$new(data_mat, \"my_data_name\")  # Create new linear base learner factory: bl_sp_df2 = BaselearnerPSpline$new(data_source,   list(n_knots = 10, df = 2, bin_root = 2)) bl_sp_df5 = BaselearnerPSpline$new(data_source,   list(n_knots = 15, df = 5))  # Get the transformed data: dim(bl_sp_df2$getData()) #> [1] 14 10 dim(bl_sp_df5$getData()) #> [1]  19 100  # Summarize factory: bl_sp_df2$summarizeFactory() #> Spline factory of degree 3 #> \t- Name of the used data: my_data_name #> \t- Factory creates the following base learner: spline_degree_3  # Get full meta data such as penalty term or matrix as well as knots: str(bl_sp_df2$getMeta()) #> List of 8 #>  $ df         : num 2 #>  $ penalty    : num 1142446 #>  $ penalty_mat: num [1:14, 1:14] 1 -2 1 0 0 0 0 0 0 0 ... #>  $ degree     : num 3 #>  $ n_knots    : num 10 #>  $ differences: num 2 #>  $ bin_root   : num 0 #>  $ knots      : num [1:18, 1] -2.545 -1.651 -0.757 0.137 1.031 ... bl_sp_df2$getPenalty() #>         [,1] #> [1,] 1142446 bl_sp_df5$getPenalty() # The penalty here is smaller due to more flexibility #>          [,1] #> [1,] 51.35188  # Transform \"new data\": newdata = list(InMemoryData$new(cbind(rnorm(5)), \"my_data_name\")) bl_sp_df2$transformData(newdata) #> $design #> 5 x 14 sparse Matrix of class \"dgCMatrix\" #>                                                                    #> [1,] 0.16666667 0.6666667 0.1666667 .          . . . . . . . . . . #> [2,] 0.16666667 0.6666667 0.1666667 .          . . . . . . . . . . #> [3,] 0.04440328 0.5622081 0.3858347 0.00755389 . . . . . . . . . . #> [4,] 0.16666667 0.6666667 0.1666667 .          . . . . . . . . . . #> [5,] 0.16666667 0.6666667 0.1666667 .          . . . . . . . . . . #>  bl_sp_df5$transformData(newdata) #> $design #> 5 x 19 sparse Matrix of class \"dgCMatrix\" #>                                                                              #> [1,] 0.16666667 0.6666667 0.1666667 .          . . . . . . . . . . . . . . . #> [2,] 0.16666667 0.6666667 0.1666667 .          . . . . . . . . . . . . . . . #> [3,] 0.01859346 0.4674568 0.4907035 0.02324623 . . . . . . . . . . . . . . . #> [4,] 0.16666667 0.6666667 0.1666667 .          . . . . . . . . . . . . . . . #> [5,] 0.16666667 0.6666667 0.1666667 .          . . . . . . . . . . . . . . . #>   # R6 wrapper  cboost_df2 = Compboost$new(dat, \"y\") cboost_df2$addBaselearner(\"x\", \"sp\", BaselearnerPSpline, n_knots = 10, df = 2, bin_root = 2) cboost_df2$train(200, 0) #> Train 200 iterations in 0 Seconds. #> Final risk based on the train set: 0.25 #>   cboost_df5 = Compboost$new(dat, \"y\") cboost_df5$addBaselearner(\"x\", \"sp\", BaselearnerPSpline, n_knots = 15, df = 5) cboost_df5$train(200, 0) #> Train 200 iterations in 0 Seconds. #> Final risk based on the train set: 0.015 #>   # Access base learner directly from the API (n = sqrt(100) = 10 with binning): str(cboost_df2$baselearner_list$x_sp$factory$getData()) #>  num [1:14, 1:10] 0.167 0.667 0.167 0 0 ... str(cboost_df5$baselearner_list$x_sp$factory$getData()) #>  num [1:19, 1:100] 0 0 0 0 0 0 0 0 0 0 ...  gg_df2 = plotPEUni(cboost_df2, \"x\") gg_df5 = plotPEUni(cboost_df5, \"x\")  library(ggplot2) library(patchwork)  (gg_df2 | gg_df5) &   geom_point(data = dat, aes(x = x, y = y - c(cboost_df2$offset)), alpha = 0.2)"},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPolynomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Polynomial base learner — BaselearnerPolynomial","title":"Polynomial base learner — BaselearnerPolynomial","text":"[BaselearnerPolynomial] creates polynomial base learner object. base learner takes one feature calculates polynomials (intercept) \\(1 + x + x^2 + \\dots + x^d\\) given degree \\(d\\).","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPolynomial.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Polynomial base learner — BaselearnerPolynomial","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPolynomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Polynomial base learner — BaselearnerPolynomial","text":"data_source (InMemoryData)  Data object contains raw data (see ?InMemoryData). blearner_type (character(1))  Type base learner (specified, blearner_type = paste0(\"poly\", d) used). unique id base learner defined appending blearner_type feature name: paste0(data_source$getIdentifier(), \"_\", blearner_type) degree (integer(1)) Polynomial degree. intercept (logical(1)) Polynomial degree. bin_root (integer(1)) binning root reduce data \\(n^{1/\\text{bin_root}}\\)$ data points (default bin_root = 1, means binning applied). value bin_root = 2 suggested best approximation error (cf. Wood et al. (2017) Generalized additive models gigadata: modeling UK black smoke network daily data).","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPolynomial.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Polynomial base learner — BaselearnerPolynomial","text":"","code":"BaselearnerPolynomial$new(data_source, list(degree, intercept, bin_root)) BaselearnerPolynomial$new(data_source, blearner_type, list(degree, intercept, bin_root))"},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPolynomial.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Polynomial base learner — BaselearnerPolynomial","text":"class contain public fields.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPolynomial.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Polynomial base learner — BaselearnerPolynomial","text":"$summarizeFactory(): () -> () $transfromData(newdata): list(InMemoryData) -> matrix() $getMeta(): () -> list()","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPolynomial.html","id":"inherited-methods-from-baselearner","dir":"Reference","previous_headings":"","what":"Inherited methods from Baselearner","title":"Polynomial base learner — BaselearnerPolynomial","text":"$getData(): () -> matrix() $getDF(): () -> integer() $getPenalty(): () -> numeric() $getPenaltyMat(): () -> matrix() $getFeatureName(): () -> character() $getModelName(): () -> character()","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerPolynomial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Polynomial base learner — BaselearnerPolynomial","text":"","code":"# Sample data: x = runif(100) y = 1 + 2*x + rnorm(100, 0, 0.2) dat = data.frame(x, y)  # S4 wrapper  # Create new data object, a matrix is required as input: data_mat = cbind(x) data_source = InMemoryData$new(data_mat, \"my_data_name\")  # Create new linear base learner factory: bl_lin = BaselearnerPolynomial$new(data_source,   list(degree = 1)) bl_cub = BaselearnerPolynomial$new(data_source,   list(intercept = FALSE, degree = 3, bin_root = 2))  # Get the transformed data: head(bl_lin$getData()) #>      [,1]      [,2] #> [1,]    1 0.7283356 #> [2,]    1 0.4816843 #> [3,]    1 0.9445998 #> [4,]    1 0.9924025 #> [5,]    1 0.3934672 #> [6,]    1 0.1075365 head(bl_cub$getData()) #>            [,1]         [,2]         [,3] #> [1,] 0.01265871 0.0001602428 2.028467e-06 #> [2,] 0.12151913 0.0147668983 1.794461e-03 #> [3,] 0.23037955 0.0530747365 1.222733e-02 #> [4,] 0.33923997 0.1150837575 3.904101e-02 #> [5,] 0.44810039 0.2007939613 8.997585e-02 #> [6,] 0.55696081 0.3102053480 1.727722e-01  # Summarize factory: bl_lin$summarizeFactory() #> Linear base learner factory: #> \t- Name of the used data: my_data_name #> \t- Factory creates the following base learner: poly1  # Transform \"new data\": newdata = list(InMemoryData$new(cbind(rnorm(5)), \"my_data_name\")) bl_lin$transformData(newdata) #> $design #>      [,1]       [,2] #> [1,]    1  0.1225220 #> [2,]    1  0.6644897 #> [3,]    1 -0.1166489 #> [4,]    1 -0.1729345 #> [5,]    1 -0.3499879 #>  bl_cub$transformData(newdata) #> $design #>            [,1]       [,2]         [,3] #> [1,]  0.1225220 0.01501165  0.001839258 #> [2,]  0.6644897 0.44154654  0.293403116 #> [3,] -0.1166489 0.01360697 -0.001587238 #> [4,] -0.1729345 0.02990636 -0.005171842 #> [5,] -0.3499879 0.12249154 -0.042870561 #>   # R6 wrapper  cboost_lin = Compboost$new(dat, \"y\") cboost_lin$addBaselearner(\"x\", \"lin\", BaselearnerPolynomial, degree = 1) cboost_lin$train(100, 0) #> Train 100 iterations in 0 Seconds. #> Final risk based on the train set: 0.018 #>   cboost_cub = Compboost$new(dat, \"y\") cboost_cub$addBaselearner(\"x\", \"cubic\", BaselearnerPolynomial, intercept = FALSE, degree = 3, bin_root = 2) cboost_cub$train(100, 0) #> Train 100 iterations in 0 Seconds. #> Final risk based on the train set: 0.055 #>   # Access base learner directly from the API (n = sqrt(100) = 10 with binning): head(cboost_lin$baselearner_list$x_lin$factory$getData()) #>      [,1]      [,2] #> [1,]    1 0.7283356 #> [2,]    1 0.4816843 #> [3,]    1 0.9445998 #> [4,]    1 0.9924025 #> [5,]    1 0.3934672 #> [6,]    1 0.1075365 cboost_cub$baselearner_list$x_cubic$factory$getData() #>             [,1]         [,2]         [,3] #>  [1,] 0.01265871 0.0001602428 2.028467e-06 #>  [2,] 0.12151913 0.0147668983 1.794461e-03 #>  [3,] 0.23037955 0.0530747365 1.222733e-02 #>  [4,] 0.33923997 0.1150837575 3.904101e-02 #>  [5,] 0.44810039 0.2007939613 8.997585e-02 #>  [6,] 0.55696081 0.3102053480 1.727722e-01 #>  [7,] 0.66582124 0.4433179174 2.951705e-01 #>  [8,] 0.77468166 0.6001316696 4.649110e-01 #>  [9,] 0.88354208 0.7806466047 6.897341e-01 #> [10,] 0.99240250 0.9848627225 9.773802e-01  gg_lin = plotPEUni(cboost_lin, \"x\") gg_cub = plotPEUni(cboost_cub, \"x\")  library(ggplot2) library(patchwork)  (gg_lin | gg_cub) &   geom_point(data = dat, aes(x = x, y = y - c(cboost_lin$offset)), alpha = 0.2)"},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerTensor.html","id":null,"dir":"Reference","previous_headings":"","what":"Base learner factory to make regression using tensor products — BaselearnerTensor","title":"Base learner factory to make regression using tensor products — BaselearnerTensor","text":"BaselearnerTensor creates combined base learner factory object can registered within base learner list used training.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BaselearnerTensor.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Base learner factory to make regression using tensor products — BaselearnerTensor","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BlearnerFactoryList.html","id":null,"dir":"Reference","previous_headings":"","what":"Base learner factory list to define the set of base learners — BlearnerFactoryList","title":"Base learner factory list to define the set of base learners — BlearnerFactoryList","text":"BlearnerFactoryList creates object base learner factories can registered. object can passed compboost set base learner used optimizer get new best base learner.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BlearnerFactoryList.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Base learner factory list to define the set of base learners — BlearnerFactoryList","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BlearnerFactoryList.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Base learner factory list to define the set of base learners — BlearnerFactoryList","text":"","code":"BlearnerFactoryList$new()"},{"path":"https://schalkdaniel.github.io/compboost/reference/BlearnerFactoryList.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Base learner factory list to define the set of base learners — BlearnerFactoryList","text":"class contain public fields.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BlearnerFactoryList.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Base learner factory list to define the set of base learners — BlearnerFactoryList","text":"registerFactory(BaselearnerFactory) Takes object class BaseLearnerFactory adds factory set base learner. printRegisteredFactories() Get registered factories. clearRegisteredFactories() Remove registered factories. Note factories deleted, just removed map. getModelFrame() Get target data matrix parsed one big matrix. getNumberOfRegisteredFactories() Get number registered factories.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/BlearnerFactoryList.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Base learner factory list to define the set of base learners — BlearnerFactoryList","text":"","code":"# Sample data: data_mat = cbind(1:10)  # Create new data object: data_source = InMemoryData$new(data_mat, \"my_data_name\")  lin_factory = BaselearnerPolynomial$new(data_source,   list(degree = 1, intercept = TRUE)) poly_factory = BaselearnerPolynomial$new(data_source,   list(degree = 2, intercept = TRUE))  # Create new base learner list: my_bl_list = BlearnerFactoryList$new()  # Register factories: my_bl_list$registerFactory(lin_factory) my_bl_list$registerFactory(poly_factory)  # Get registered factories: my_bl_list$printRegisteredFactories() #> Registered base-learner: #> \t- my_data_name_poly1 #> \t- my_data_name_poly2  # Get all target data matrices in one big matrix: my_bl_list$getModelFrame() #> $colnames #> [1] \"my_data_name_poly1x11\" \"my_data_name_poly1x12\" \"my_data_name_poly2x11\" #> [4] \"my_data_name_poly2x12\" \"my_data_name_poly2x13\" #>  #> $model_frame #>       [,1] [,2] [,3] [,4] [,5] #>  [1,]    1    1    1    1    1 #>  [2,]    1    2    1    2    4 #>  [3,]    1    3    1    3    9 #>  [4,]    1    4    1    4   16 #>  [5,]    1    5    1    5   25 #>  [6,]    1    6    1    6   36 #>  [7,]    1    7    1    7   49 #>  [8,]    1    8    1    8   64 #>  [9,]    1    9    1    9   81 #> [10,]    1   10    1   10  100 #>   # Clear list: my_bl_list$clearRegisteredFactories()  # Get number of registered factories: my_bl_list$getNumberOfRegisteredFactories() #> [1] 0"},{"path":"https://schalkdaniel.github.io/compboost/reference/CategoricalDataRaw.html","id":null,"dir":"Reference","previous_headings":"","what":"Data class for categorical variables\n\nCategoricalDataRaw creates an data object which can be used as source\nobject to instantiate categorical base learner. In contrast to CategoricalData\nthe data are stored as raw categorical vector. CategoricalData can be compared\nto a factor class with an integer encoding and a hash map for reassignment. — CategoricalDataRaw","title":"Data class for categorical variables\n\nCategoricalDataRaw creates an data object which can be used as source\nobject to instantiate categorical base learner. In contrast to CategoricalData\nthe data are stored as raw categorical vector. CategoricalData can be compared\nto a factor class with an integer encoding and a hash map for reassignment. — CategoricalDataRaw","text":"Data class categorical variables CategoricalDataRaw creates data object can used source object instantiate categorical base learner. contrast CategoricalData data stored raw categorical vector. CategoricalData can compared factor class integer encoding hash map reassignment.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/CategoricalDataRaw.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data class for categorical variables\n\nCategoricalDataRaw creates an data object which can be used as source\nobject to instantiate categorical base learner. In contrast to CategoricalData\nthe data are stored as raw categorical vector. CategoricalData can be compared\nto a factor class with an integer encoding and a hash map for reassignment. — CategoricalDataRaw","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/CategoricalDataRaw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data class for categorical variables\n\nCategoricalDataRaw creates an data object which can be used as source\nobject to instantiate categorical base learner. In contrast to CategoricalData\nthe data are stored as raw categorical vector. CategoricalData can be compared\nto a factor class with an integer encoding and a hash map for reassignment. — CategoricalDataRaw","text":"x (character()) Categorical vector.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/CategoricalDataRaw.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data class for categorical variables\n\nCategoricalDataRaw creates an data object which can be used as source\nobject to instantiate categorical base learner. In contrast to CategoricalData\nthe data are stored as raw categorical vector. CategoricalData can be compared\nto a factor class with an integer encoding and a hash map for reassignment. — CategoricalDataRaw","text":"","code":"CategoricalDataRaw$new(x, data_identifier)"},{"path":"https://schalkdaniel.github.io/compboost/reference/CategoricalDataRaw.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Data class for categorical variables\n\nCategoricalDataRaw creates an data object which can be used as source\nobject to instantiate categorical base learner. In contrast to CategoricalData\nthe data are stored as raw categorical vector. CategoricalData can be compared\nto a factor class with an integer encoding and a hash map for reassignment. — CategoricalDataRaw","text":"class contain public fields.","code":""},{"path":[]},{"path":"https://schalkdaniel.github.io/compboost/reference/CategoricalDataRaw.html","id":"inherited-methods-from-data","dir":"Reference","previous_headings":"","what":"Inherited methods from Data","title":"Data class for categorical variables\n\nCategoricalDataRaw creates an data object which can be used as source\nobject to instantiate categorical base learner. In contrast to CategoricalData\nthe data are stored as raw categorical vector. CategoricalData can be compared\nto a factor class with an integer encoding and a hash map for reassignment. — CategoricalDataRaw","text":"$getDataType(): () -> character(1)","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/CategoricalDataRaw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data class for categorical variables\n\nCategoricalDataRaw creates an data object which can be used as source\nobject to instantiate categorical base learner. In contrast to CategoricalData\nthe data are stored as raw categorical vector. CategoricalData can be compared\nto a factor class with an integer encoding and a hash map for reassignment. — CategoricalDataRaw","text":"","code":"# Sample data: x = sample(c(\"one\",\"two\", \"three\"), 20, TRUE)  # Create new data object: data_obj = CategoricalDataRaw$new(x, \"cat_raw\")  # Get data and identifier: data_obj$getRawData() #>  [1] \"two\"   \"two\"   \"one\"   \"two\"   \"one\"   \"three\" \"one\"   \"one\"   \"one\"   #> [10] \"one\"   \"one\"   \"two\"   \"two\"   \"three\" \"three\" \"three\" \"one\"   \"two\"   #> [19] \"three\" \"one\"   data_obj$getIdentifier() #> [1] \"cat_raw\""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":null,"dir":"Reference","previous_headings":"","what":"Component-wise boosting — Compboost","title":"Component-wise boosting — Compboost","text":"class wraps S4 class system exposed Rcpp fit component-wise boosting model. two convenient wrapper boostLinear() boostSplines() also creating objects class. Visualizing internals see plotBaselearnerTraces(), plotBaselearner(), plotFeatureImportance(), plotPEUni(), plotTensor(), plotRisk(). Visualizing contribution one new observation see plotIndividualContribution().","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Component-wise boosting — Compboost","text":"data (data.frame) data used training model. Note: oob_fraction set, input data split data data_oob. Hence, data contains subset input data train model. data_oob (data.frame) --bag data set used risk logging early stopping. data_oob split input data (see data field). oob_fraction (numeric(1)) fraction nrow(input data) defining number observations data_oob. response (ResponseRegr | ResponseBinaryClassif) S4 response object. See ?ResponseRegr ?ResponseBinaryClassif help. object holds current prediction, pseudo residuals functions transform scores. Note: response corresponds data field holds predictions data.frame. response_oob (ResponseRegr | ResponseBinaryClassif) S4 response object. See ?ResponseRegr ?ResponseBinaryClassif help. response data_oob. target (character(1)) Name target variable data. id (character(1)) Name data object defined $new(data, ...). optimizer (OptimizerCoordinateDescent | OptimizerCoordinateDescentLineSearch | OptimizerAGBM | OptimizerCosineAnnealing) initialized S4 optimizer object (requires call Optimizer*$new(..). See respective help page information. loss (LossQuadratic | LossBinomial | LossHuber | LossAbsolute | LossQuantile) initialized S4 loss object (requires call Loss*$new(...)). See respective help page information. learning_rate (numeric(1)) learning rate model. Note: optimizer dynamically vary learning rate. model (Compboost_internal) internal Compboost object exported Rcpp. See ?Compboost_internal details. bl_factory_list ([BlearnerFactoryList) container base learners. See ?BlearnerFactoryList details. positive (character(1)) positive class case binary classification. stop_all (logical(1)) Indicator whether stopper must return TRUE early stop algorithm. Comparable () stop_all = TRUE () stop_all = FALSE. early_stop (logical(1)) Indicator whether early stopping used .","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"active-bindings","dir":"Reference","previous_headings":"","what":"Active bindings","title":"Component-wise boosting — Compboost","text":"offset (numeric()) Offset estimated model. baselearner_list (list()) Named list names $getBaselearnerNames(). elements contains \"feature\" (character(1)): name feature data. \"factory\" (Baselearner*): raw base learner  factoryobject. See ?Baselearner* details. boost_intercept (logical(1)) Logical value indicating whether intercept base learner added $addIntercept() . logs (data.frame) Basic information risk, selected base learner etc. iteration. oob_data set, information validation/oob risk also logged. applies time logging etc. Note: Using field logs internally set updated call $getLoggerData(). Hence, cashes logged data set instead recalculating data set done $getLoggerData(). idx_oob (integer()) index vector used split data data = data[idx_train, ] data_oob = data[idx_oob, ]. Note: oob_fraction ignored argument set. idx_train (integer()) index vector used split data data = data[idx_train, ] data_oob = data[idx_oob, ]. Note: oob_fraction ignored argument set.","code":""},{"path":[]},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Component-wise boosting — Compboost","text":"Compboost$new() Compboost$addLogger() Compboost$getCurrentIteration() Compboost$addIntercept() Compboost$addBaselearner() Compboost$rmBaselearner() Compboost$addTensor() Compboost$addComponents() Compboost$train() Compboost$prepareData() Compboost$prepareResponse() Compboost$predict() Compboost$predictIndividual() Compboost$transformData() Compboost$getInbagRisk() Compboost$getSelectedBaselearner() Compboost$print() Compboost$getCoef() Compboost$getEstimatedCoef() Compboost$getBaselearnerNames() Compboost$getLoggerData() Compboost$calculateFeatureImportance() Compboost$saveToJson() Compboost$clone()","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Component-wise boosting — Compboost","text":"Creates new instance R6 class.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$new(   data = NULL,   target = NULL,   optimizer = NULL,   loss = NULL,   learning_rate = 0.05,   positive = NULL,   oob_fraction = NULL,   early_stop = FALSE,   idx_oob = NULL,   stop_args = list(eps_for_break = 0, patience = 10L),   file = NULL )"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"data (data.frame) data set build object. Note: data set completely used training .null(idx_oob). Otherwise, data set split data = data[idx_train, ] data_oob = data[idx_oob, ]. target (character(1)) Character indicating name target variable. optimizer (OptimizerCoordinateDescent | OptimizerCoordinateDescentLineSearch | OptimizerAGBM | OptimizerCosineAnnealing) initialized S4 optimizer object (requires call Optimizer*.new(..). See respective help page information. loss (LossQuadratic | LossBinomial | LossHuber | LossAbsolute | LossQuantile) initialized S4 loss object (requires call Loss*$new(...)). See respective help page information. learning_rate (numeric(1)) Learning rate model (default 0.05). positive (character(1)) name positive class (case binary classification). oob_fraction (numeric(1)) fraction nrow(input data) defining number observations data_oob. argument ignored idx_oob set. early_stop (logical(1)) Indicator whether early stopping used . idx_oob (integer()) index vector used split data data = data[idx_train, ] data_oob = data[idx_oob, ]. Note: oob_fraction ignored argument set. stop_args (list(integer(1), integer(1)))list containing two elements patience eps_for_break used early stopping. file (character(1) File model loaded. NULL, data target must defined.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-addlogger-","dir":"Reference","previous_headings":"","what":"Method addLogger()","title":"Component-wise boosting — Compboost","text":"Add logger model.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$addLogger(logger, use_as_stopper = FALSE, logger_id, ...)"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"logger (LoggerIteration | LoggerTime | LoggerInbagRisk | LoggerOobRisk) uninitialized logger. use_as_stopper (logical(1)) Indicator defining logger stopper considering early stopping. logger_id (character(1)) id logger. allows define two logger type (e.g. risk logging) different arguments. ... Additional arguments passed loger$new(logger_id, use_as_stopper, ...).","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-getcurrentiteration-","dir":"Reference","previous_headings":"","what":"Method getCurrentIteration()","title":"Component-wise boosting — Compboost","text":"Get number current iteration.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$getCurrentIteration()"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Component-wise boosting — Compboost","text":"integer(1) value.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-addintercept-","dir":"Reference","previous_headings":"","what":"Method addIntercept()","title":"Component-wise boosting — Compboost","text":"functions adds base learner adjusts intercept (selected). Adding intercept base learner may necessary, e.g., adding linear effects without intercept.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$addIntercept(id = \"intercept\", data_source = InMemoryData)"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"id (character(1)) id base learner (default \"intercept\"). data_source (InMemoryData) Uninitialized data object used store meta data. Note: moment, just memory storing supported, see ?InMemorydata details. data_source (InMemoryData) Uninitialized data object used store meta data. Note: moment, just memory storing supported, see ?InMemorydata details.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-addbaselearner-","dir":"Reference","previous_headings":"","what":"Method addBaselearner()","title":"Component-wise boosting — Compboost","text":"Add base learner one feature model considered iteration. Using $addBaselearner() just allows including univariate features. See $addTensor() bivariate effect modelling $addComponents() effect decomposition.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$addBaselearner(   feature,   id,   bl_factory,   data_source = InMemoryData,   ... )"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"feature (character(1)) Name feature, must column data. feature (character(1)) Name feature, must column data. id (character(1)) name base learner. bl_factory (BaselearnerPolynomial | BaselearnerPSpline | BaselearnerCategoricalBinary | BaselearnerCategoricalRidge) Uninitialized base learner class. See respective help page details. data_source (InMemoryData) Uninitialized data object used store meta data. Note: moment, just memory storing supported, see ?InMemorydata details. data_source (InMemoryData) Uninitialized data object used store meta data. Note: moment, just memory storing supported, see ?InMemorydata details. ... argument spassed $new(...) constructor bl_factory.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-rmbaselearner-","dir":"Reference","previous_headings":"","what":"Method rmBaselearner()","title":"Component-wise boosting — Compboost","text":"Remove base learner model.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$rmBaselearner(blname)"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"blname (character(1)) Name base learner removed. Must element $getBaselearnerNames().","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-addtensor-","dir":"Reference","previous_headings":"","what":"Method addTensor()","title":"Component-wise boosting — Compboost","text":"Add row-wise tensor product features. Note: base learner pre-defined type feature. Numerical features uses BaselearnerPSpline categorical features included using BaselearnerCategoricalRidge base learner. include arbitrary tensor product requires use S4 API using BaselearnerTensor two base learners type.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$addTensor(   feature1,   feature2,   df = NULL,   df1 = NULL,   df2 = NULL,   isotrop = FALSE,   ... )"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"feature1 (character(1)) Name first feature. Must element names(data). feature2 (character(1)) Name second feature. Must element names(data). df (numeric(1)) degrees freedom used base learner (parameter overwrites df1 df2). df1 (numeric(1)) degrees freedom used first base learner. df2 (numeric(1)) degrees freedom used first base learner. isotrop (logical(1)) Indicator two penalties combined, isotrop == TRUE, total degrees freedom uniformly distributed dimensions isotrop == FALSE allows define strong two dimensions penalized. ... Additional arguments passed $new() constructor BaselearnerPSpline class.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-addcomponents-","dir":"Reference","previous_headings":"","what":"Method addComponents()","title":"Component-wise boosting — Compboost","text":"Add effect individual components. linear term added well non-linear term without linear effect. ensures linear component selected prior non-linear effect. non-linear effect included deviation linear effect required. Note: Internally, BaselearnerPolynomial degree one BaselearnerCentered added. Centering base learner makes design matrix dense hence memory filled fast. Considering binning may option reduce memory consumption.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-7","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$addComponents(feature, ...)"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments-6","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"feature (character(1)) Name feature, must column data. feature (character(1)) Name feature, must column data. ... Additional arguments passed $new() constructor BaselearnerPSpline class.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-train-","dir":"Reference","previous_headings":"","what":"Method train()","title":"Component-wise boosting — Compboost","text":"Start fitting model.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-8","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$train(iteration = 100, trace = -1)"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments-7","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"iteration (integer(1)) maximal number iteration. algorithm can stopped earlier early stopping active. trace (integer(1)) number integers status fitting printed screen. default trace = -1 internally uses trace = round(iteration / 40). silently fit model use trace = 0.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-preparedata-","dir":"Reference","previous_headings":"","what":"Method prepareData()","title":"Component-wise boosting — Compboost","text":"Internally, base learner build InMemoryData object. methods (e.g. adding LoggerOobRisk) requires pass data list(InMemoryData | CategoricalDataRaw) data objects elements. function converts given data.frame format.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-9","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$prepareData(newdata)"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments-8","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"newdata (data.frame) New data set structure data. newdata (data.frame) New data set structure data. newdata (data.frame) New data set structure data. newdata (data.frame) New data set structure data.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"Component-wise boosting — Compboost","text":"list(InMemoryData | CategoricalDataRaw) data container elements. Numeric features wrapped InMemoryData categorical features included CategoricalDataRaw.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-prepareresponse-","dir":"Reference","previous_headings":"","what":"Method prepareResponse()","title":"Component-wise boosting — Compboost","text":"$prepareData() response. Internally, vectorToResponse() used generate ResponseRegr ResponseBinaryClassif object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-10","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$prepareResponse(response)"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments-9","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"response (vector()) vector type numberic categorical transformed response object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"returns-2","dir":"Reference","previous_headings":"","what":"Returns","title":"Component-wise boosting — Compboost","text":"ResponseRegr | ResponseBinaryClassif object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-predict-","dir":"Reference","previous_headings":"","what":"Method predict()","title":"Component-wise boosting — Compboost","text":"Calculate predictions.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-11","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$predict(newdata = NULL, as_response = FALSE)"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments-10","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"newdata (data.frame) New data set structure data. newdata (data.frame) New data set structure data. newdata (data.frame) New data set structure data. newdata (data.frame) New data set structure data. as_response (logical(1)) case binary classification, as_response = TRUE returns predictions response, .e. classes.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"returns-3","dir":"Reference","previous_headings":"","what":"Returns","title":"Component-wise boosting — Compboost","text":"Vector predictions.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-predictindividual-","dir":"Reference","previous_headings":"","what":"Method predictIndividual()","title":"Component-wise boosting — Compboost","text":"$predict() returns sum base learner predictions, function returns list predictions base learner.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-12","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$predictIndividual(newdata)"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments-11","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"newdata (data.frame) New data set structure data. newdata (data.frame) New data set structure data. newdata (data.frame) New data set structure data. newdata (data.frame) New data set structure data.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"returns-4","dir":"Reference","previous_headings":"","what":"Returns","title":"Component-wise boosting — Compboost","text":"Named list() included base learner names names base learner predictions elements.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-transformdata-","dir":"Reference","previous_headings":"","what":"Method transformData()","title":"Component-wise boosting — Compboost","text":"Get design matrices (subset) base learners new data.frame.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-13","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$transformData(newdata, blnames = NULL)"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments-12","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"newdata (data.frame) New data set structure data. newdata (data.frame) New data set structure data. newdata (data.frame) New data set structure data. newdata (data.frame) New data set structure data. blnames (character()) Names base learners design matrices returned. .null(blnames), compboost tries guess base learners constructed based feature names newdata.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"returns-5","dir":"Reference","previous_headings":"","what":"Returns","title":"Component-wise boosting — Compboost","text":"list(matrix | Matrix::Matrix) matrices elements.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-getinbagrisk-","dir":"Reference","previous_headings":"","what":"Method getInbagRisk()","title":"Component-wise boosting — Compboost","text":"Return training risk iteration.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-14","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$getInbagRisk()"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"returns-6","dir":"Reference","previous_headings":"","what":"Returns","title":"Component-wise boosting — Compboost","text":"numeric() vector risk values NULL $train() called previously.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-getselectedbaselearner-","dir":"Reference","previous_headings":"","what":"Method getSelectedBaselearner()","title":"Component-wise boosting — Compboost","text":"Get vector name selected base learner iteration.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-15","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$getSelectedBaselearner()"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"returns-7","dir":"Reference","previous_headings":"","what":"Returns","title":"Component-wise boosting — Compboost","text":"character() vector base learner names.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-print-","dir":"Reference","previous_headings":"","what":"Method print()","title":"Component-wise boosting — Compboost","text":"Printer object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-16","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$print()"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"returns-8","dir":"Reference","previous_headings":"","what":"Returns","title":"Component-wise boosting — Compboost","text":"Invisibly returns object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-getcoef-","dir":"Reference","previous_headings":"","what":"Method getCoef()","title":"Component-wise boosting — Compboost","text":"Get estimated coefficients.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-17","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$getCoef()"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"returns-9","dir":"Reference","previous_headings":"","what":"Returns","title":"Component-wise boosting — Compboost","text":"list(pars, offset) estimated coefficients/parameters intercept/offset.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-getestimatedcoef-","dir":"Reference","previous_headings":"","what":"Method getEstimatedCoef()","title":"Component-wise boosting — Compboost","text":"DEPRICATED use $getCoef() instead. Get estimated coefficients.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-18","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$getEstimatedCoef()"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"returns-10","dir":"Reference","previous_headings":"","what":"Returns","title":"Component-wise boosting — Compboost","text":"list(pars, offset) estimated coefficients/parameters intercept/offset.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-getbaselearnernames-","dir":"Reference","previous_headings":"","what":"Method getBaselearnerNames()","title":"Component-wise boosting — Compboost","text":"Get names registered base learners.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-19","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$getBaselearnerNames()"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"returns-11","dir":"Reference","previous_headings":"","what":"Returns","title":"Component-wise boosting — Compboost","text":"charcter() base learner names.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-getloggerdata-","dir":"Reference","previous_headings":"","what":"Method getLoggerData()","title":"Component-wise boosting — Compboost","text":"Get logged information.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-20","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$getLoggerData()"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"returns-12","dir":"Reference","previous_headings":"","what":"Returns","title":"Component-wise boosting — Compboost","text":"data.frame logging information.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-calculatefeatureimportance-","dir":"Reference","previous_headings":"","what":"Method calculateFeatureImportance()","title":"Component-wise boosting — Compboost","text":"Calculate feature important based training risk. Note early stopping used get adequate importance measures.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-21","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$calculateFeatureImportance(   num_feats = NULL,   aggregate_bl_by_feat = FALSE )"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments-13","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"num_feats (integer(1)) number considered features, num_feats important feature names respective value returned. aggregate_bl_by_feat (logical(1)) Indicator whether importance aggregated based feature level. example, adding components included two different base learners feature. aggregate_bl_by_feat == TRUE, importance two base learners aggregated instead considering individually.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"returns-13","dir":"Reference","previous_headings":"","what":"Returns","title":"Component-wise boosting — Compboost","text":"Named numeric() vector length num_feats (least num_feats selected) importance values elements.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-savetojson-","dir":"Reference","previous_headings":"","what":"Method saveToJson()","title":"Component-wise boosting — Compboost","text":"Save Compboost object JSON file. underlying C++ objects, possible use R's native load save methods.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-22","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$saveToJson(file)"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments-14","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"file (character(1)) Name/path file.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Component-wise boosting — Compboost","text":"objects class cloneable method.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"usage-23","dir":"Reference","previous_headings":"","what":"Usage","title":"Component-wise boosting — Compboost","text":"","code":"Compboost$clone(deep = FALSE)"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"arguments-15","dir":"Reference","previous_headings":"","what":"Arguments","title":"Component-wise boosting — Compboost","text":"deep Whether make deep clone.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Component-wise boosting — Compboost","text":"","code":"cboost = Compboost$new(mtcars, \"mpg\", loss = LossQuadratic$new(), oob_fraction = 0.3) cboost$addBaselearner(\"hp\", \"spline\", BaselearnerPSpline, degree = 3,   n_knots = 10, df = 3, differences = 2) cboost$addBaselearner(\"wt\", \"spline\", BaselearnerPSpline) cboost$train(1000) #>    1/1000   risk = 16  oob_risk = 16    #>   25/1000   risk = 3.5  oob_risk = 4.2    #>   50/1000   risk = 1.9  oob_risk = 2.3    #>   75/1000   risk = 1.6  oob_risk = 2    #>  100/1000   risk = 1.5  oob_risk = 1.9    #>  125/1000   risk = 1.5  oob_risk = 1.9    #>  150/1000   risk = 1.4  oob_risk = 2    #>  175/1000   risk = 1.4  oob_risk = 2.1    #>  200/1000   risk = 1.3  oob_risk = 2.2    #>  225/1000   risk = 1.3  oob_risk = 2.3    #>  250/1000   risk = 1.3  oob_risk = 2.4    #>  275/1000   risk = 1.2  oob_risk = 2.5    #>  300/1000   risk = 1.2  oob_risk = 2.6    #>  325/1000   risk = 1.2  oob_risk = 2.7    #>  350/1000   risk = 1.2  oob_risk = 2.7    #>  375/1000   risk = 1.1  oob_risk = 2.8    #>  400/1000   risk = 1.1  oob_risk = 2.9    #>  425/1000   risk = 1.1  oob_risk = 3    #>  450/1000   risk = 1.1  oob_risk = 3    #>  475/1000   risk = 1.1  oob_risk = 3.1    #>  500/1000   risk = 1  oob_risk = 3.2    #>  525/1000   risk = 1  oob_risk = 3.3    #>  550/1000   risk = 1  oob_risk = 3.3    #>  575/1000   risk = 1  oob_risk = 3.4    #>  600/1000   risk = 1  oob_risk = 3.4    #>  625/1000   risk = 0.98  oob_risk = 3.5    #>  650/1000   risk = 0.97  oob_risk = 3.6    #>  675/1000   risk = 0.96  oob_risk = 3.6    #>  700/1000   risk = 0.95  oob_risk = 3.7    #>  725/1000   risk = 0.94  oob_risk = 3.7    #>  750/1000   risk = 0.93  oob_risk = 3.8    #>  775/1000   risk = 0.92  oob_risk = 3.8    #>  800/1000   risk = 0.91  oob_risk = 3.9    #>  825/1000   risk = 0.91  oob_risk = 3.9    #>  850/1000   risk = 0.9  oob_risk = 4    #>  875/1000   risk = 0.89  oob_risk = 4    #>  900/1000   risk = 0.88  oob_risk = 4    #>  925/1000   risk = 0.88  oob_risk = 4.1    #>  950/1000   risk = 0.87  oob_risk = 4.1    #>  975/1000   risk = 0.86  oob_risk = 4.2    #> 1000/1000   risk = 0.86  oob_risk = 4.2    #>  #>  #> Train 1000 iterations in 0 Seconds. #> Final risk based on the train set: 0.86 #>   table(cboost$getSelectedBaselearner()) #>  #> hp_spline wt_spline  #>       256       744  head(cboost$logs) #>   _iterations oob_risk baselearner train_risk #> 1           0       NA   intercept   17.68057 #> 2           1 16.10564   wt_spline   16.26712 #> 3           2 14.94743   wt_spline   14.98966 #> 4           3 13.88978   wt_spline   13.83499 #> 5           4 12.92362   wt_spline   12.79118 #> 6           5 12.04069   wt_spline   11.84748 names(cboost$baselearner_list) #> [1] \"hp_spline\" \"wt_spline\"  # Access information about the a base learner in the list: cboost$baselearner_list$hp_spline$factory$getDF() #>      [,1] #> [1,]    3 cboost$baselearner_list$hp_spline$factory$getPenalty() #>          [,1] #> [1,] 73.35067"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost_internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Main Compboost Class — Compboost_internal","title":"Main Compboost Class — Compboost_internal","text":"class collects parts factory list used logger passes C++. C++ side main algorithm.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost_internal.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Main Compboost Class — Compboost_internal","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost_internal.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Main Compboost Class — Compboost_internal","text":"","code":"Compboost$new(response, learning_rate, stop_if_all_stopper_fulfilled,   factory_list, loss, logger_list, optimizer)"},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost_internal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Main Compboost Class — Compboost_internal","text":"response numeric Vector true values modeled. learning_rate numeric(1) learning rate used shrink parameter iteration. stop_if_all_stopper_fulfilled logical(1) Boolean indicate stopping strategy used. TRUE algorithm stops registered logger stopper fulfilled. factory_list BlearnerFactoryList object List base learner factories one base learner selected iteration using loss Loss object loss used calculate pseudo residuals iteration. logger_list LoggerList object list registered logger used track algorithm. optimizer Optimizer object optimizer used select iteration one good base learner.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost_internal.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Main Compboost Class — Compboost_internal","text":"class contain public fields.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost_internal.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Main Compboost Class — Compboost_internal","text":"train(trace) Initial training model. integer argument trace indicates logger progress printed trace indicates iterations printed. continueTraining(trace, logger_list) Continue training using additional logger_list. retraining stopped first logger says algorithm stopped. getPrediction() Get inbag prediction done fitting process. getSelectedBaselearner() Returns character vector base learner selected. getLoggerData() Returns list logged data. algorithm retrained, list contains training one element. getEstimatedParameter() Returns list estimated parameter base learner selected least . getParameterAtIteration(k) Calculates prediction iteration k. getParameterMatrix() Calculates matrix row includes parameter iteration . many rows done iterations. isTrained() function returns just boolean value indicates initial training already done. predict(newdata) Prediction new data organized within list source data objects. important names source data objects matches one used define factories. predictAtIteration(newdata, k) Prediction new data using another iteration k. setToIteration(k) Set whole model another iteration k. calling function elements parameters prediction calculated corresponding k. summarizeCompboost() Summarize Compboost object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/Compboost_internal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Main Compboost Class — Compboost_internal","text":"","code":"# Some data: df = mtcars df$mpg_cat = ifelse(df$mpg > 20, \"high\", \"low\")  # # Create new variable to check the polynomial base learner with degree 2: # df$hp2 = df[[\"hp\"]]^2  # Data for the baselearner are matrices: X_hp = as.matrix(df[[\"hp\"]]) X_wt = as.matrix(df[[\"wt\"]])  # Target variable: response = ResponseBinaryClassif$new(\"mpg_cat\", \"high\", df[[\"mpg_cat\"]])  data_source_hp = InMemoryData$new(X_hp, \"hp\") data_source_wt = InMemoryData$new(X_wt, \"wt\")  # List for oob logging: oob_data = list(data_source_hp, data_source_wt)  # List to test prediction on newdata: test_data = oob_data  # Factories: linear_factory_hp = BaselearnerPolynomial$new(data_source_hp,   list(degree = 1, intercept = TRUE)) linear_factory_wt = BaselearnerPolynomial$new(data_source_wt,   list(degree = 1, intercept = TRUE)) quadratic_factory_hp = BaselearnerPolynomial$new(data_source_hp,   list(degree = 2, intercept = TRUE)) spline_factory_wt = BaselearnerPSpline$new(data_source_wt,   list(degree = 3, n_knots = 10, penalty = 2, differences = 2))  # Create new factory list: factory_list = BlearnerFactoryList$new()  # Register factories: factory_list$registerFactory(linear_factory_hp) factory_list$registerFactory(linear_factory_wt) factory_list$registerFactory(quadratic_factory_hp) factory_list$registerFactory(spline_factory_wt)  # Define loss: loss_bin = LossBinomial$new()  # Define optimizer: optimizer = OptimizerCoordinateDescent$new()  ## Logger  # Define logger. We want just the iterations as stopper but also track the # time, inbag risk and oob risk: log_iterations  = LoggerIteration$new(\" iteration_logger\", TRUE, 500) log_time        = LoggerTime$new(\"time_logger\", FALSE, 500, \"microseconds\")  # Define new logger list: logger_list = LoggerList$new()  # Register the logger: logger_list$registerLogger(log_iterations) logger_list$registerLogger(log_time)  # Run compboost: # --------------  # Initialize object: cboost = Compboost_internal$new(   response      = response,   learning_rate = 0.05,   stop_if_all_stopper_fulfilled = FALSE,   factory_list = factory_list,   loss         = loss_bin,   logger_list  = logger_list,   optimizer    = optimizer )  # Train the model (we want to print the trace): cboost$train(trace = 50) #>   1/500   risk = 0.68  time_logger = 0    #>  50/500   risk = 0.42  time_logger = 501    #> 100/500   risk = 0.31  time_logger = 1050    #> 150/500   risk = 0.25  time_logger = 1674    #> 200/500   risk = 0.21  time_logger = 2374    #> 250/500   risk = 0.19  time_logger = 3172    #> 300/500   risk = 0.17  time_logger = 4041    #> 350/500   risk = 0.16  time_logger = 4993    #> 400/500   risk = 0.15  time_logger = 6014    #> 450/500   risk = 0.14  time_logger = 7134    #> 500/500   risk = 0.13  time_logger = 8333    #>  #>  #> Train 500 iterations in 0 Seconds. #> Final risk based on the train set: 0.13 #>  cboost #>  #> Compboost object with: #> \t- Learning Rate: 0.05 #> \t- Are all logger used as stopper: 0 #> \t- Model is already trained with 500 iterations/fitted baselearner #> \t- Actual state is at iteration 500 #>  #>  #>   # Get estimated parameter: cboost$getEstimatedParameter() #> $hp_poly2 #>               [,1] #> [1,]  6.0660349854 #> [2,] -0.0645193461 #> [3,]  0.0001267875 #>  #> $wt_spline_degree_3 #>             [,1] #>  [1,]  1.9370515 #>  [2,]  1.8485620 #>  [3,]  1.8081122 #>  [4,]  1.8647942 #>  [5,]  1.7149991 #>  [6,]  1.0827258 #>  [7,] -0.4203328 #>  [8,] -1.8130157 #>  [9,] -2.0641036 #> [10,] -2.0050272 #> [11,] -1.8182042 #> [12,] -1.5569128 #> [13,] -1.2730290 #> [14,] -0.9904981 #>   # Get trace of selected base learner: cboost$getSelectedBaselearner() #>   [1] \"wt_spline_degree_3\" \"wt_spline_degree_3\" \"wt_spline_degree_3\" #>   [4] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #>   [7] \"hp_poly2\"           \"wt_spline_degree_3\" \"wt_spline_degree_3\" #>  [10] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #>  [13] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #>  [16] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #>  [19] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #>  [22] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #>  [25] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #>  [28] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #>  [31] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #>  [34] \"wt_spline_degree_3\" \"wt_spline_degree_3\" \"hp_poly2\"           #>  [37] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #>  [40] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #>  [43] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #>  [46] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #>  [49] \"wt_spline_degree_3\" \"wt_spline_degree_3\" \"hp_poly2\"           #>  [52] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #>  [55] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #>  [58] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #>  [61] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #>  [64] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #>  [67] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #>  [70] \"wt_spline_degree_3\" \"wt_spline_degree_3\" \"hp_poly2\"           #>  [73] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #>  [76] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #>  [79] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #>  [82] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #>  [85] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #>  [88] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #>  [91] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #>  [94] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #>  [97] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [100] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [103] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [106] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [109] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [112] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [115] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [118] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [121] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [124] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [127] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [130] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [133] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [136] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [139] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [142] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [145] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [148] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [151] \"wt_spline_degree_3\" \"hp_poly2\"           \"hp_poly2\"           #> [154] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [157] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [160] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [163] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [166] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [169] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [172] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [175] \"hp_poly2\"           \"hp_poly2\"           \"wt_spline_degree_3\" #> [178] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [181] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [184] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [187] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [190] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [193] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [196] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [199] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [202] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [205] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [208] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [211] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [214] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [217] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [220] \"hp_poly2\"           \"hp_poly2\"           \"wt_spline_degree_3\" #> [223] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [226] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [229] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [232] \"wt_spline_degree_3\" \"hp_poly2\"           \"hp_poly2\"           #> [235] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [238] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [241] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [244] \"hp_poly2\"           \"hp_poly2\"           \"wt_spline_degree_3\" #> [247] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [250] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [253] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [256] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [259] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [262] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [265] \"wt_spline_degree_3\" \"hp_poly2\"           \"hp_poly2\"           #> [268] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [271] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [274] \"wt_spline_degree_3\" \"hp_poly2\"           \"hp_poly2\"           #> [277] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [280] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [283] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [286] \"hp_poly2\"           \"hp_poly2\"           \"wt_spline_degree_3\" #> [289] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [292] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [295] \"hp_poly2\"           \"hp_poly2\"           \"wt_spline_degree_3\" #> [298] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [301] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [304] \"hp_poly2\"           \"hp_poly2\"           \"wt_spline_degree_3\" #> [307] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [310] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [313] \"hp_poly2\"           \"hp_poly2\"           \"wt_spline_degree_3\" #> [316] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [319] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [322] \"hp_poly2\"           \"hp_poly2\"           \"wt_spline_degree_3\" #> [325] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [328] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [331] \"hp_poly2\"           \"hp_poly2\"           \"wt_spline_degree_3\" #> [334] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [337] \"wt_spline_degree_3\" \"hp_poly2\"           \"hp_poly2\"           #> [340] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [343] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [346] \"wt_spline_degree_3\" \"hp_poly2\"           \"hp_poly2\"           #> [349] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [352] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [355] \"wt_spline_degree_3\" \"hp_poly2\"           \"hp_poly2\"           #> [358] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [361] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [364] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [367] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [370] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [373] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [376] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [379] \"hp_poly2\"           \"hp_poly2\"           \"wt_spline_degree_3\" #> [382] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [385] \"wt_spline_degree_3\" \"hp_poly2\"           \"hp_poly2\"           #> [388] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [391] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [394] \"wt_spline_degree_3\" \"hp_poly2\"           \"hp_poly2\"           #> [397] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [400] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [403] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [406] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [409] \"hp_poly2\"           \"hp_poly2\"           \"wt_spline_degree_3\" #> [412] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [415] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [418] \"hp_poly2\"           \"hp_poly2\"           \"wt_spline_degree_3\" #> [421] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [424] \"wt_spline_degree_3\" \"hp_poly2\"           \"hp_poly2\"           #> [427] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [430] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [433] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [436] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [439] \"hp_poly2\"           \"hp_poly2\"           \"wt_spline_degree_3\" #> [442] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [445] \"wt_spline_degree_3\" \"hp_poly2\"           \"hp_poly2\"           #> [448] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [451] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [454] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [457] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [460] \"hp_poly2\"           \"hp_poly2\"           \"wt_spline_degree_3\" #> [463] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [466] \"wt_spline_degree_3\" \"hp_poly2\"           \"hp_poly2\"           #> [469] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [472] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [475] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [478] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [481] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [484] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [487] \"wt_spline_degree_3\" \"hp_poly2\"           \"wt_spline_degree_3\" #> [490] \"hp_poly2\"           \"hp_poly2\"           \"wt_spline_degree_3\" #> [493] \"hp_poly2\"           \"wt_spline_degree_3\" \"hp_poly2\"           #> [496] \"wt_spline_degree_3\" \"hp_poly2\"           \"hp_poly2\"           #> [499] \"wt_spline_degree_3\" \"hp_poly2\"            # Set to iteration 200: cboost$setToIteration(200, 30)  # Get new parameter values: cboost$getEstimatedParameter() #> $hp_poly2 #>               [,1] #> [1,]  3.649127e+00 #> [2,] -3.820112e-02 #> [3,]  7.376905e-05 #>  #> $wt_spline_degree_3 #>             [,1] #>  [1,]  1.3479210 #>  [2,]  1.3418629 #>  [3,]  1.3528398 #>  [4,]  1.3714923 #>  [5,]  1.2096167 #>  [6,]  0.7153452 #>  [7,] -0.2712226 #>  [8,] -1.1840205 #>  [9,] -1.4335470 #> [10,] -1.4475909 #> [11,] -1.3450002 #> [12,] -1.1727850 #> [13,] -0.9769323 #> [14,] -0.7809478 #>"},{"path":"https://schalkdaniel.github.io/compboost/reference/InMemoryData.html","id":null,"dir":"Reference","previous_headings":"","what":"Store data in RAM — InMemoryData","title":"Store data in RAM — InMemoryData","text":"data container stores vector RAM makes accessible Compboost.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/InMemoryData.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Store data in RAM — InMemoryData","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/InMemoryData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Store data in RAM — InMemoryData","text":"data_mat (matrix()) data matrix. data_identifier (character(1)) Data id, e.g. feature name.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/InMemoryData.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Store data in RAM — InMemoryData","text":"","code":"InMemoryData$new() InMemoryData$new(data_mat, data_identifier) InMemoryData$new(data_mat, data_identifier, use_sparse)"},{"path":"https://schalkdaniel.github.io/compboost/reference/InMemoryData.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Store data in RAM — InMemoryData","text":"class contain public fields.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/InMemoryData.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Store data in RAM — InMemoryData","text":"$getData(): () -> matrix() $getIdentifier(): () -> character(1)","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/InMemoryData.html","id":"inherited-methods-from-data","dir":"Reference","previous_headings":"","what":"Inherited methods from Data","title":"Store data in RAM — InMemoryData","text":"$getDataType(): () -> character(1)","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/InMemoryData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Store data in RAM — InMemoryData","text":"","code":"# Sample data: data_mat = cbind(rnorm(10))  # Create new data object: data_obj = InMemoryData$new(data_mat, \"my_data_name\")  # Get data and identifier: data_obj$getData() #>              [,1] #>  [1,] -1.45242127 #>  [2,]  0.98391578 #>  [3,] -0.08988764 #>  [4,]  1.47002068 #>  [5,] -0.59099266 #>  [6,]  0.92218188 #>  [7,] -0.44805001 #>  [8,]  2.42882616 #>  [9,]  2.80829560 #> [10,] -2.14393376 data_obj$getIdentifier() #> [1] \"my_data_name\""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerInbagRisk.html","id":null,"dir":"Reference","previous_headings":"","what":"Logger class to log the inbag risk — LoggerInbagRisk","title":"Logger class to log the inbag risk — LoggerInbagRisk","text":"class logs inbag risk specific loss function. also possible use custom losses log performance measures. details see use case extending compboost vignette.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerInbagRisk.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Logger class to log the inbag risk — LoggerInbagRisk","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerInbagRisk.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logger class to log the inbag risk — LoggerInbagRisk","text":"","code":"LoggerInbagRisk$new(logger_id, use_as_stopper, used_loss, eps_for_break, patience)"},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerInbagRisk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logger class to log the inbag risk — LoggerInbagRisk","text":"logger_id character(1) Unique identifier logger. use_as_stopper logical(1) Boolean indicate logger also used stopper. used_loss Loss object loss used calculate empirical risk taking mean returned defined loss within loss object. eps_for_break numeric(1) argument used loss also used stopper. relative improvement logged inbag risk falls boundary stopper returns TRUE.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerInbagRisk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Logger class to log the inbag risk — LoggerInbagRisk","text":"logger computes risk given training data \\(\\mathcal{D} = \\{(x^{()},\\ y^{()})\\ |\\ \\\\{1, \\dots, n\\}\\}\\) stores vector. empirical risk \\(\\mathcal{R}\\) iteration \\(m\\) calculated : $$   \\mathcal{R}_\\mathrm{emp}^{[m]} = \\frac{1}{n}\\sum\\limits_{= 1}^n L(y^{()}, \\hat{f}^{[m]}(x^{()})) $$ Note: \\(m=0\\) \\(\\hat{f}\\) just offset. implementation calculate \\(\\mathcal{R}_\\mathrm{emp}^{[m]}\\) done two steps: Calculate vector risk_temp losses every observation given response \\(y^{()}\\) prediction \\(\\hat{f}^{[m]}(x^{()})\\). procedure ensures, possible e.g. use AUC arbitrary performance measure risk logging. gives just one value risk_temp therefore average equals loss function. just value (like AUC) value returned. FieldsThis class contain public fields. Methods summarizeLogger() Summarize logger object. # Used loss: log_bin = LossBinomial$new()# Define logger: log_inbag_risk = LoggerInbagRisk$new(\"inbag\", FALSE, log_bin, 0.05, 5)# Summarize logger: log_inbag_risk$summarizeLogger()","code":"\\item      Average over \\code{risk_temp}.  }"},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerIteration.html","id":null,"dir":"Reference","previous_headings":"","what":"Logger class to log the current iteration — LoggerIteration","title":"Logger class to log the current iteration — LoggerIteration","text":"Logger class log current iteration","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerIteration.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Logger class to log the current iteration — LoggerIteration","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerIteration.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logger class to log the current iteration — LoggerIteration","text":"","code":"LoggerIterationWrapper$new(logger_id, use_as_stopper, max_iterations)"},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerIteration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logger class to log the current iteration — LoggerIteration","text":"logger_id character(1) Unique identifier logger. use_as_stopper logical(1) Boolean indicate logger also used stopper. max_iterations integer(1) logger used stopper argument defines maximal iterations.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerIteration.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Logger class to log the current iteration — LoggerIteration","text":"class contain public fields.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerIteration.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Logger class to log the current iteration — LoggerIteration","text":"summarizeLogger() Summarize logger object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerIteration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logger class to log the current iteration — LoggerIteration","text":"","code":"# Define logger: log_iters = LoggerIteration$new(\"iterations\", FALSE, 100)  # Summarize logger: log_iters$summarizeLogger() #> Iteration logger: #> \t- Maximal iterations: 100 #> \t- Use logger as stopper: 0"},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerList.html","id":null,"dir":"Reference","previous_headings":"","what":"Logger list class to collect all loggers — LoggerList","title":"Logger list class to collect all loggers — LoggerList","text":"class meant define logger used track progress algorithm.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerList.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Logger list class to collect all loggers — LoggerList","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerList.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logger list class to collect all loggers — LoggerList","text":"","code":"LoggerList$new()"},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerList.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Logger list class to collect all loggers — LoggerList","text":"class contain public fields.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerList.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Logger list class to collect all loggers — LoggerList","text":"clearRegisteredLogger() Removes registered logger list. used logger deleted, just removed map. getNamesOfRegisteredLogger() Returns registered logger names character vector. getNumberOfRegisteredLogger() Returns number registered logger integer. printRegisteredLogger() Prints registered logger. registerLogger(logger) Includes new logger logger list logger_id key.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerList.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logger list class to collect all loggers — LoggerList","text":"","code":"# Define logger: log_iters = LoggerIteration$new(\"iteration\", TRUE, 100) log_time = LoggerTime$new(\"time\", FALSE, 20, \"minutes\")  # Create logger list: logger_list = LoggerList$new()  # Register new loggeR: logger_list$registerLogger(log_iters) logger_list$registerLogger(log_time)  # Print registered logger: logger_list$printRegisteredLogger() #> Registered Logger: #> \t>>iteration<< Logger #> \t>>time<< Logger  # Remove all logger: logger_list$clearRegisteredLogger()  # Get number of registered logger: logger_list$getNumberOfRegisteredLogger() #> [1] 0"},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerOobRisk.html","id":null,"dir":"Reference","previous_headings":"","what":"Logger class to log the out of bag risk — LoggerOobRisk","title":"Logger class to log the out of bag risk — LoggerOobRisk","text":"class logs bag risk specific loss function. also possible use custom losses log performance measures. details see use case extending compboost vignette.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerOobRisk.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Logger class to log the out of bag risk — LoggerOobRisk","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerOobRisk.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logger class to log the out of bag risk — LoggerOobRisk","text":"","code":"LoggerOobRisk$new(logger_id, use_as_stopper, used_loss, eps_for_break,   patience, oob_data, oob_response)"},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerOobRisk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logger class to log the out of bag risk — LoggerOobRisk","text":"logger_id character(1) Unique identifier logger. use_as_stopper logical(1) Boolean indicate logger also used stopper. used_loss Loss object loss used calculate empirical risk taking mean returned defined loss within loss object. eps_for_break numeric(1) argument used loss also used stopper. relative improvement logged inbag risk falls boundary stopper returns TRUE. oob_data list list contains data source objects corresponds source data registered factory. source data objects contain bag data. data used calculate prediction step. oob_response numeric Vector contains response bag data given within list.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerOobRisk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Logger class to log the out of bag risk — LoggerOobRisk","text":"logger computes risk given new dataset \\(\\mathcal{D}_\\mathrm{oob} = \\{(x^{()},\\ y^{()})\\ |\\ \\I_\\mathrm{oob}\\}\\) stores vector. OOB risk \\(\\mathcal{R}_\\mathrm{oob}\\) iteration \\(m\\) calculated : $$   \\mathcal{R}_\\mathrm{oob}^{[m]} = \\frac{1}{|\\mathcal{D}_\\mathrm{oob}|}\\sum\\limits_{(x,y) \\\\mathcal{D}_\\mathrm{oob}}   L(y, \\hat{f}^{[m]}(x)) $$ Note: \\(m=0\\) \\(\\hat{f}\\) just offset. implementation calculate \\(\\mathcal{R}_\\mathrm{emp}^{[m]}\\) done two steps:  procedure ensures, possible e.g. use AUC arbitrary performance measure risk logging. gives just one value \\(risk_temp\\) therefore average equals loss function. just value (like AUC) value returned. FieldsThis class contain public fields. Methods summarizeLogger() Summarize logger object. # Define data: X1 = cbind(1:10) X2 = cbind(10:1) data_source1 = InMemoryData$new(X1, \"x1\") data_source2 = InMemoryData$new(X2, \"x2\")oob_list = list(data_source1, data_source2)set.seed(123) y_oob = rnorm(10)# Used loss: log_bin = LossBinomial$new()# Define response object oob data: oob_response = ResponseRegr$new(\"oob_response\", .matrix(y_oob))# Define logger: log_oob_risk = LoggerOobRisk$new(\"oob\", FALSE, log_bin, 0.05, 5, oob_list, oob_response)# Summarize logger: log_oob_risk$summarizeLogger()","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerTime.html","id":null,"dir":"Reference","previous_headings":"","what":"Logger class to log the elapsed time — LoggerTime","title":"Logger class to log the elapsed time — LoggerTime","text":"class just logs elapsed time. handy one wants run algorithm just 2 hours see far comes within time. three time units available logging: minutes seconds microseconds","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerTime.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Logger class to log the elapsed time — LoggerTime","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerTime.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logger class to log the elapsed time — LoggerTime","text":"","code":"LoggerTime$new(logger_id, use_as_stopper, max_time, time_unit)"},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerTime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logger class to log the elapsed time — LoggerTime","text":"logger_id character(1) Unique identifier logger. use_as_stopper logical(1) Boolean indicate logger also used stopper. max_time integer(1) logger used stopper argument contains maximal time available train model. time_unit character(1) Character specify time unit. Possible choices minutes, seconds microseconds","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerTime.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Logger class to log the elapsed time — LoggerTime","text":"class contain public fields.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerTime.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Logger class to log the elapsed time — LoggerTime","text":"summarizeLogger() Summarize logger object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LoggerTime.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logger class to log the elapsed time — LoggerTime","text":"","code":"# Define logger: log_time = LoggerTime$new(\"time_minutes\", FALSE, 20, \"minutes\")  # Summarize logger: log_time$summarizeLogger() #> Time logger: #> \t- Tracked time unit: minutes"},{"path":"https://schalkdaniel.github.io/compboost/reference/LossAbsolute.html","id":null,"dir":"Reference","previous_headings":"","what":"Absolute loss for regression tasks. — LossAbsolute","title":"Absolute loss for regression tasks. — LossAbsolute","text":"loss can used regression \\(y \\\\mathrm{R}\\).","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossAbsolute.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Absolute loss for regression tasks. — LossAbsolute","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossAbsolute.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Absolute loss for regression tasks. — LossAbsolute","text":"Loss Function: $$   L(y, f(x)) = | y - f(x)| $$ Gradient: $$   \\frac{\\delta}{\\delta f(x)}\\ L(y, f(x)) = -\\mathrm{sign}(y - f(x)) $$ Initialization: $$   \\hat{f}^{[0]}(x) = \\mathrm{arg~min}_{c\\R}\\ \\frac{1}{n}\\sum\\limits_{=1}^n   L(y^{()}, c) = \\mathrm{median}(y) $$","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossAbsolute.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Absolute loss for regression tasks. — LossAbsolute","text":"","code":"LossAbsolute$new() LossAbsolute$new(offset)"},{"path":"https://schalkdaniel.github.io/compboost/reference/LossAbsolute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Absolute loss for regression tasks. — LossAbsolute","text":"offset numeric(1) Numerical value can used set custom offset. , value returned instead loss optimal initialization.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossAbsolute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Absolute loss for regression tasks. — LossAbsolute","text":"","code":"# Create new loss object: absolute_loss = LossAbsolute$new() absolute_loss #> LossAbsolute: L(y,x) = |y - f(x)| #>"},{"path":"https://schalkdaniel.github.io/compboost/reference/LossBinomial.html","id":null,"dir":"Reference","previous_headings":"","what":"0-1 Loss for binary classification derived of the binomial distribution — LossBinomial","title":"0-1 Loss for binary classification derived of the binomial distribution — LossBinomial","text":"loss can used binary classification. coding chosen acts \\(y \\\\{-1, 1\\}\\).","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossBinomial.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"0-1 Loss for binary classification derived of the binomial distribution — LossBinomial","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossBinomial.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"0-1 Loss for binary classification derived of the binomial distribution — LossBinomial","text":"Loss Function: $$   L(y, f(x)) = \\log(1 + \\mathrm{exp}(-2yf(x))) $$ Gradient: $$   \\frac{\\delta}{\\delta f(x)}\\ L(y, f(x)) = - \\frac{y}{1 + \\mathrm{exp}(2yf)} $$ Initialization: $$   \\hat{f}^{[0]}(x) = \\frac{1}{2}\\mathrm{log}(p / (1 - p)) $$ $$   p = \\frac{1}{n}\\sum\\limits_{=1}^n\\mathrm{1}_{\\{y^{()} = 1\\}} $$","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossBinomial.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"0-1 Loss for binary classification derived of the binomial distribution — LossBinomial","text":"","code":"LossBinomial$new() LossBinomial$new(offset)"},{"path":"https://schalkdaniel.github.io/compboost/reference/LossBinomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"0-1 Loss for binary classification derived of the binomial distribution — LossBinomial","text":"offset numeric(1) Numerical value can used set custom offset. , value returned instead loss optimal initialization.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossBinomial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"0-1 Loss for binary classification derived of the binomial distribution — LossBinomial","text":"","code":"# Create new loss object: bin_loss = LossBinomial$new() bin_loss #> LossBinomial: L(y,x) = log(1 + exp(-2yf(x)) #>"},{"path":"https://schalkdaniel.github.io/compboost/reference/LossCustom.html","id":null,"dir":"Reference","previous_headings":"","what":"Create LossCustom by using R functions. — LossCustom","title":"Create LossCustom by using R functions. — LossCustom","text":"LossCustom creates custom loss using Rcpp::Function set R functions.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossCustom.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Create LossCustom by using R functions. — LossCustom","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossCustom.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create LossCustom by using R functions. — LossCustom","text":"","code":"LossCustom$new(lossFun, gradientFun, initFun)"},{"path":"https://schalkdaniel.github.io/compboost/reference/LossCustom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create LossCustom by using R functions. — LossCustom","text":"lossFun function R function calculate loss. details see Details. gradientFun function R function calculate gradient. details see Details. initFun function R function calculate constant initialization. details see Details.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossCustom.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create LossCustom by using R functions. — LossCustom","text":"functions must following structure: lossFun(truth, prediction) { ... return (loss) } vector argument truth containing real values vector predictions prediction. function must return vector containing loss component. gradientFun(truth, prediction) { ... return (grad) } vector argument truth containing real values vector predictions prediction. function must return vector containing gradient loss component. initFun(truth) { ... return (init) } vector argument truth containing real values. function must return numeric value containing offset constant initialization.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossCustom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create LossCustom by using R functions. — LossCustom","text":"","code":"# Loss function: myLoss = function (true_values, prediction) {   return (0.5 * (true_values - prediction)^2) } # Gradient of loss function: myGradient = function (true_values, prediction) {   return (prediction - true_values) } # Constant initialization: myConstInit = function (true_values) {   return (mean(true_values)) }  # Create new custom quadratic loss: my_loss = LossCustom$new(myLoss, myGradient, myConstInit)"},{"path":"https://schalkdaniel.github.io/compboost/reference/LossCustomCpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Create custom cpp losses by using cpp functions and external pointer. — LossCustomCpp","title":"Create custom cpp losses by using cpp functions and external pointer. — LossCustomCpp","text":"LossCustomCpp creates custom loss using Rcpp::XPtr set C++ functions.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossCustomCpp.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Create custom cpp losses by using cpp functions and external pointer. — LossCustomCpp","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossCustomCpp.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create custom cpp losses by using cpp functions and external pointer. — LossCustomCpp","text":"","code":"LossCustomCpp$new(loss_ptr, grad_ptr, const_init_ptr)"},{"path":"https://schalkdaniel.github.io/compboost/reference/LossCustomCpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create custom cpp losses by using cpp functions and external pointer. — LossCustomCpp","text":"loss_ptr externalptr External pointer C++ loss function. grad_ptr externalptr External pointer C++ gradient function. const_init_ptr externalptr External pointer C++ constant initialization function.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossCustomCpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create custom cpp losses by using cpp functions and external pointer. — LossCustomCpp","text":"","code":"if (FALSE) { # Load loss functions: Rcpp::sourceCpp(code = getCustomCppExample(example = \"loss\", silent = TRUE))  # Create new custom quadratic loss: my_cpp_loss = LossCustomCpp$new(lossFunSetter(), gradFunSetter(), constInitFunSetter()) }"},{"path":"https://schalkdaniel.github.io/compboost/reference/LossHuber.html","id":null,"dir":"Reference","previous_headings":"","what":"Huber loss for regression tasks. — LossHuber","title":"Huber loss for regression tasks. — LossHuber","text":"loss can used regression \\(y \\\\mathrm{R}\\).","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossHuber.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Huber loss for regression tasks. — LossHuber","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossHuber.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Huber loss for regression tasks. — LossHuber","text":"Loss Function: $$   L(y, f(x)) = 0.5(y - f(x))^2 \\ \\ \\mathrm{} \\ \\ |y - f(x)| < d $$ $$   L(y, f(x)) = d|y - f(x)| - 0.5d^2 \\ \\ \\mathrm{otherwise} $$ Gradient: $$   \\frac{\\delta}{\\delta f(x)}\\ L(y, f(x)) = f(x) - y \\ \\ \\mathrm{} \\ \\ |y - f(x)| < d $$ $$   \\frac{\\delta}{\\delta f(x)}\\ L(y, f(x)) = -d\\mathrm{sign}(y - f(x)) \\ \\ \\mathrm{otherwise} $$","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossHuber.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Huber loss for regression tasks. — LossHuber","text":"","code":"LossHuber$new() LossHuber$new(delta) LossHuber$new(offset, delta)"},{"path":"https://schalkdaniel.github.io/compboost/reference/LossHuber.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Huber loss for regression tasks. — LossHuber","text":"offset numeric(1) Numerical value can used set custom offset. , value returned instead loss optimal initialization. delta numeric(1) Numerical value greater 0 specify interval around 0 quadratic error measuring. Default 1.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossHuber.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Huber loss for regression tasks. — LossHuber","text":"","code":"# Create new loss object: huber_loss = LossHuber$new() huber_loss #> LossHuber: L(y,x) = if (y - f(x) < d) { 0.5(y - f(x))^2 } else { d|y - f(x)| - 0.5d^2 } #>  #>   with delta d = 1"},{"path":"https://schalkdaniel.github.io/compboost/reference/LossQuadratic.html","id":null,"dir":"Reference","previous_headings":"","what":"Quadratic loss for regression tasks. — LossQuadratic","title":"Quadratic loss for regression tasks. — LossQuadratic","text":"loss can used regression \\(y \\\\mathrm{R}\\).","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossQuadratic.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Quadratic loss for regression tasks. — LossQuadratic","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossQuadratic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quadratic loss for regression tasks. — LossQuadratic","text":"Loss Function: $$   L(y, f(x)) = \\frac{1}{2}( y - f(x))^2 $$ Gradient: $$   \\frac{\\delta}{\\delta f(x)}\\ L(y, f(x)) = f(x) - y $$ Initialization: $$   \\hat{f}^{[0]}(x) = \\mathrm{arg~min}{c\\\\mathrm{R}}{\\mathrm{arg~min}}\\ \\frac{1}{n}\\sum\\limits_{=1}^n   L\\left(y^{()}, c\\right) = \\bar{y} $$","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossQuadratic.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quadratic loss for regression tasks. — LossQuadratic","text":"","code":"LossQuadratic$new() LossQuadratic$new(offset)"},{"path":"https://schalkdaniel.github.io/compboost/reference/LossQuadratic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quadratic loss for regression tasks. — LossQuadratic","text":"offset numeric(1) Numerical value can used set custom offset. , value returned instead loss optimal initialization.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossQuadratic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quadratic loss for regression tasks. — LossQuadratic","text":"","code":"# Create new loss object: quadratic_loss = LossQuadratic$new() quadratic_loss #> LossQuadratic: L(y,x) = 0.5 * (y - f(x))^2 #>"},{"path":"https://schalkdaniel.github.io/compboost/reference/LossQuantile.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile loss for regression tasks. — LossQuantile","title":"Quantile loss for regression tasks. — LossQuantile","text":"loss can used regression \\(y \\\\mathrm{R}\\).","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossQuantile.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Quantile loss for regression tasks. — LossQuantile","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossQuantile.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantile loss for regression tasks. — LossQuantile","text":"Loss Function: $$   L(y, f(x)) = h| y - f(x)| $$ Gradient: $$   \\frac{\\delta}{\\delta f(x)}\\ L(y, f(x)) = -h\\mathrm{sign}( y - f(x)) $$ Initialization: $$   \\hat{f}^{[0]}(x) = \\mathrm{arg~min}_{c\\R}\\ \\frac{1}{n}\\sum\\limits_{=1}^n   L(y^{()}, c) = \\mathrm{quantile}(y, q) $$","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossQuantile.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile loss for regression tasks. — LossQuantile","text":"","code":"LossAbsolute$new() LossAbsolute$new(quantile) LossAbsolute$new(offset, quantile)"},{"path":"https://schalkdaniel.github.io/compboost/reference/LossQuantile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile loss for regression tasks. — LossQuantile","text":"offset numeric(1) Numerical value can used set custom offset. , value returned instead loss optimal initialization. quantile numeric(1) Numerical value 0 1 indicating quantile used boosting.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/LossQuantile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile loss for regression tasks. — LossQuantile","text":"","code":"# Create new loss object: quadratic_loss = LossQuadratic$new() quadratic_loss #> LossQuadratic: L(y,x) = 0.5 * (y - f(x))^2 #>"},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerAGBM.html","id":null,"dir":"Reference","previous_headings":"","what":"Nesterov momentum — OptimizerAGBM","title":"Nesterov momentum — OptimizerAGBM","text":"class defines new object used conduct Nesterovs momentum optimization technique.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerAGBM.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Nesterov momentum — OptimizerAGBM","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerAGBM.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nesterov momentum — OptimizerAGBM","text":"","code":"OptimizerAGBM$new(momentum) OptimizerAGBM$new(momentum, ncores)"},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerAGBM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nesterov momentum — OptimizerAGBM","text":"momentum numeric(1) Momentum term used accelerate fitting process. chosen large, algorithm trains faster also tends overfit faster. ncores integer(1) Number cores used fit algorithm. Note number used cores smaller equal number base learner.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerAGBM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nesterov momentum — OptimizerAGBM","text":"","code":"optimizer = OptimizerAGBM$new(0.1)"},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerCoordinateDescent.html","id":null,"dir":"Reference","previous_headings":"","what":"Coordinate Descent — OptimizerCoordinateDescent","title":"Coordinate Descent — OptimizerCoordinateDescent","text":"class defines new object greedy optimizer. optimizer just calculates base learner sum squared errors returns base learner smallest SSE.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerCoordinateDescent.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Coordinate Descent — OptimizerCoordinateDescent","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerCoordinateDescent.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coordinate Descent — OptimizerCoordinateDescent","text":"","code":"OptimizerCoordinateDescent$new() OptimizerCoordinateDescent$new(ncores)"},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerCoordinateDescent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coordinate Descent — OptimizerCoordinateDescent","text":"ncores integer(1) Number cores used fit algorithm. Note number used cores smaller equal number base learner.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerCoordinateDescent.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coordinate Descent — OptimizerCoordinateDescent","text":"","code":"# Define optimizer: optimizer = OptimizerCoordinateDescent$new()"},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerCoordinateDescentLineSearch.html","id":null,"dir":"Reference","previous_headings":"","what":"Coordinate Descent with line search — OptimizerCoordinateDescentLineSearch","title":"Coordinate Descent with line search — OptimizerCoordinateDescentLineSearch","text":"class defines new object used conduct Coordinate Descent line search. optimizer just calculates base learner sum squared error returns base learner smallest SSE. addition, optimizer computes line search find optimal step size iteration.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerCoordinateDescentLineSearch.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Coordinate Descent with line search — OptimizerCoordinateDescentLineSearch","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerCoordinateDescentLineSearch.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coordinate Descent with line search — OptimizerCoordinateDescentLineSearch","text":"","code":"OptimizerCoordinateDescentLineSearch$new() OptimizerCoordinateDescentLineSearch$new(ncores)"},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerCoordinateDescentLineSearch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coordinate Descent with line search — OptimizerCoordinateDescentLineSearch","text":"ncores integer(1) Number cores used fit algorithm. Note number used cores smaller equal number base learner.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerCoordinateDescentLineSearch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coordinate Descent with line search — OptimizerCoordinateDescentLineSearch","text":"","code":"# Define optimizer: optimizer = OptimizerCoordinateDescentLineSearch$new()"},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerCosineAnnealing.html","id":null,"dir":"Reference","previous_headings":"","what":"Coordinate Descent with Cosine Annealing — OptimizerCosineAnnealing","title":"Coordinate Descent with Cosine Annealing — OptimizerCosineAnnealing","text":"class defines new object used conduct Coordinate Descent cosine annealing learning rate strategy.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerCosineAnnealing.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Coordinate Descent with Cosine Annealing — OptimizerCosineAnnealing","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerCosineAnnealing.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coordinate Descent with Cosine Annealing — OptimizerCosineAnnealing","text":"","code":"OptimizerCosineAnnealing$new() OptimizerCosineAnnealing$new(ncores) OptimizerCosineAnnealing$new(nu_min, nu_max, cycles, anneal_iter_max, cycles) OptimizerCosineAnnealing$new(nu_min, nu_max, cycles, anneal_iter_max, cycles, ncores)"},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerCosineAnnealing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coordinate Descent with Cosine Annealing — OptimizerCosineAnnealing","text":"nu_min numeric(1) Minimal learning rate. nu_max numeric(1) Maximal learning rate. cycles integer(1) Number annealings form nu_max nu_min 1 anneal_iter_max. anneal_iter_max integer(1) Maximal number iters annealing applied. iteration bigger anneal_iter_max, nu_min used fixed learning rate. ncores integer(1) Number cores used fit algorithm. Note number used cores smaller equal number base learner.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/OptimizerCosineAnnealing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coordinate Descent with Cosine Annealing — OptimizerCosineAnnealing","text":"","code":"# Define optimizer: optimizer = OptimizerCosineAnnealing$new()"},{"path":"https://schalkdaniel.github.io/compboost/reference/ResponseBinaryClassif.html","id":null,"dir":"Reference","previous_headings":"","what":"Create response object for binary classification. — ResponseBinaryClassif","title":"Create response object for binary classification. — ResponseBinaryClassif","text":"ResponseBinaryClassif creates response object used target fitting process.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/ResponseBinaryClassif.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Create response object for binary classification. — ResponseBinaryClassif","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/ResponseBinaryClassif.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create response object for binary classification. — ResponseBinaryClassif","text":"","code":"ResponseBinaryClassif$new(target_name, pos_class, response) ResponseBinaryClassif$new(target_name, pos_class, response, weights)"},{"path":"https://schalkdaniel.github.io/compboost/reference/ResponseBinaryClassif.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create response object for binary classification. — ResponseBinaryClassif","text":"","code":"response_binary = ResponseBinaryClassif$new(\"target\", \"A\", sample(c(\"A\", \"B\"), 10, TRUE)) response_binary$getResponse() #>       [,1] #>  [1,]   -1 #>  [2,]   -1 #>  [3,]    1 #>  [4,]   -1 #>  [5,]    1 #>  [6,]    1 #>  [7,]    1 #>  [8,]    1 #>  [9,]   -1 #> [10,]   -1 response_binary$getPrediction() #>       [,1] #>  [1,]    0 #>  [2,]    0 #>  [3,]    0 #>  [4,]    0 #>  [5,]    0 #>  [6,]    0 #>  [7,]    0 #>  [8,]    0 #>  [9,]    0 #> [10,]    0 response_binary$getPredictionTransform() # Applies sigmoid to prediction scores #>       [,1] #>  [1,]  0.5 #>  [2,]  0.5 #>  [3,]  0.5 #>  [4,]  0.5 #>  [5,]  0.5 #>  [6,]  0.5 #>  [7,]  0.5 #>  [8,]  0.5 #>  [9,]  0.5 #> [10,]  0.5 response_binary$getPredictionResponse()  # Categorizes depending on the transformed predictions #>       [,1] #>  [1,]    1 #>  [2,]    1 #>  [3,]    1 #>  [4,]    1 #>  [5,]    1 #>  [6,]    1 #>  [7,]    1 #>  [8,]    1 #>  [9,]    1 #> [10,]    1 response_binary$getTargetName() #> [1] \"target\" response_binary$setThreshold(0.7) response_binary$getThreshold() #> [1] 0.7 response_binary$getPositiveClass() #> [1] \"A\""},{"path":"https://schalkdaniel.github.io/compboost/reference/ResponseRegr.html","id":null,"dir":"Reference","previous_headings":"","what":"Create response object for regression. — ResponseRegr","title":"Create response object for regression. — ResponseRegr","text":"ResponseRegr creates response object used target fitting process.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/ResponseRegr.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Create response object for regression. — ResponseRegr","text":"S4 object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/ResponseRegr.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create response object for regression. — ResponseRegr","text":"","code":"ResponseRegr$new(target_name, response) ResponseRegr$new(target_name, response, weights)"},{"path":"https://schalkdaniel.github.io/compboost/reference/ResponseRegr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create response object for regression. — ResponseRegr","text":"","code":"response_regr = ResponseRegr$new(\"target\", cbind(rnorm(10))) response_regr$getResponse() #>             [,1] #>  [1,]  0.9672268 #>  [2,] -0.8987517 #>  [3,]  0.7418967 #>  [4,] -0.7515093 #>  [5,] -0.3364271 #>  [6,]  0.4514301 #>  [7,] -0.1641708 #>  [8,] -0.4842900 #>  [9,]  0.5269698 #> [10,] -0.8655231 response_regr$getTargetName() #> [1] \"target\""},{"path":"https://schalkdaniel.github.io/compboost/reference/boostLinear.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper to boost linear models for each feature. — boostLinear","title":"Wrapper to boost linear models for each feature. — boostLinear","text":"wrapper function automatically initializes model adding numerical features linear base-learner. Categorical features dummy encoded inserted using another linear base-learners without intercept. function boostLinear also train model.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/boostLinear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper to boost linear models for each feature. — boostLinear","text":"","code":"boostLinear(   data,   target,   optimizer = NULL,   loss = NULL,   learning_rate = 0.05,   iterations = 100,   trace = -1,   intercept = TRUE,   data_source = InMemoryData,   oob_fraction = NULL )"},{"path":"https://schalkdaniel.github.io/compboost/reference/boostLinear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper to boost linear models for each feature. — boostLinear","text":"data data.frame data frame containing data. target character(1) Response class Character value containing target variable response object. Note loss must match data type target. optimizer S4 Optimizer initialized S4 Optimizer object exposed Rcpp (e.g. OptimizerCoordinateDescent$new()) select features iteration. loss S4 Loss Initialized S4 Loss object exposed Rcpp used calculate risk pseudo residuals (e.g. LossQuadratic$new()). learning_rate numeric(1) Learning rate shrink parameter step. iterations integer(1) Number iterations trained. iterations == 0, untrained object returned. can useful base learners (e.g. interaction via tensor base learner) added. trace integer(1) Integer indicating often trace printed. Specifying trace = 10, every 10th iteration printed. trace printed set trace = 0. Default -1 means total 40 iterations printed. intercept logical(1) Internally used BaselearnerPolynomial. logical value indicates feature get intercept (default TRUE). data_source S4 Data Uninitialized S4 Data object used store data. moment just memory training supported. oob_fraction numeric(1) Fraction much data used track bag risk.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/boostLinear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wrapper to boost linear models for each feature. — boostLinear","text":"model Compboost class. model R6 object can used retraining, predicting, plotting, anything described ?Compboost.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/boostLinear.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wrapper to boost linear models for each feature. — boostLinear","text":"returned object object Compboost class. object can used analyses (see ?Compboost details).","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/boostLinear.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wrapper to boost linear models for each feature. — boostLinear","text":"","code":"mod = boostLinear(data = iris, target = \"Sepal.Length\", loss = LossQuadratic$new(),   oob_fraction = 0.3) #>   1/100   risk = 0.3  oob_risk = 0.34    #>   2/100   risk = 0.28  oob_risk = 0.31    #>   4/100   risk = 0.24  oob_risk = 0.27    #>   6/100   risk = 0.21  oob_risk = 0.24    #>   8/100   risk = 0.19  oob_risk = 0.21    #>  10/100   risk = 0.17  oob_risk = 0.19    #>  12/100   risk = 0.15  oob_risk = 0.17    #>  14/100   risk = 0.14  oob_risk = 0.16    #>  16/100   risk = 0.12  oob_risk = 0.14    #>  18/100   risk = 0.12  oob_risk = 0.14    #>  20/100   risk = 0.11  oob_risk = 0.13    #>  22/100   risk = 0.1  oob_risk = 0.12    #>  24/100   risk = 0.097  oob_risk = 0.12    #>  26/100   risk = 0.093  oob_risk = 0.11    #>  28/100   risk = 0.09  oob_risk = 0.11    #>  30/100   risk = 0.087  oob_risk = 0.11    #>  32/100   risk = 0.085  oob_risk = 0.1    #>  34/100   risk = 0.083  oob_risk = 0.1    #>  36/100   risk = 0.081  oob_risk = 0.099    #>  38/100   risk = 0.08  oob_risk = 0.097    #>  40/100   risk = 0.078  oob_risk = 0.095    #>  42/100   risk = 0.077  oob_risk = 0.093    #>  44/100   risk = 0.075  oob_risk = 0.092    #>  46/100   risk = 0.074  oob_risk = 0.09    #>  48/100   risk = 0.072  oob_risk = 0.089    #>  50/100   risk = 0.071  oob_risk = 0.087    #>  52/100   risk = 0.07  oob_risk = 0.086    #>  54/100   risk = 0.069  oob_risk = 0.085    #>  56/100   risk = 0.068  oob_risk = 0.083    #>  58/100   risk = 0.067  oob_risk = 0.082    #>  60/100   risk = 0.066  oob_risk = 0.081    #>  62/100   risk = 0.065  oob_risk = 0.08    #>  64/100   risk = 0.064  oob_risk = 0.079    #>  66/100   risk = 0.063  oob_risk = 0.079    #>  68/100   risk = 0.062  oob_risk = 0.078    #>  70/100   risk = 0.062  oob_risk = 0.077    #>  72/100   risk = 0.061  oob_risk = 0.076    #>  74/100   risk = 0.06  oob_risk = 0.076    #>  76/100   risk = 0.06  oob_risk = 0.075    #>  78/100   risk = 0.059  oob_risk = 0.075    #>  80/100   risk = 0.058  oob_risk = 0.074    #>  82/100   risk = 0.058  oob_risk = 0.074    #>  84/100   risk = 0.057  oob_risk = 0.073    #>  86/100   risk = 0.057  oob_risk = 0.073    #>  88/100   risk = 0.056  oob_risk = 0.072    #>  90/100   risk = 0.056  oob_risk = 0.072    #>  92/100   risk = 0.056  oob_risk = 0.072    #>  94/100   risk = 0.055  oob_risk = 0.071    #>  96/100   risk = 0.055  oob_risk = 0.071    #>  98/100   risk = 0.054  oob_risk = 0.071    #> 100/100   risk = 0.054  oob_risk = 0.071    #>  #>  #> Train 100 iterations in 0 Seconds. #> Final risk based on the train set: 0.054 #>  mod$getBaselearnerNames() #> [1] \"Sepal.Width_linear\"  \"Petal.Length_linear\" \"Petal.Width_linear\"  #> [4] \"Species_ridge\"       mod$getEstimatedCoef() #> Depricated, use `$getCoef()` instead. #> $Petal.Length_linear #>            [,1] #> [1,] -1.5978252 #> [2,]  0.4248459 #> attr(,\"blclass\") #> [1] \"Rcpp_BaselearnerPolynomial\" #>  #> $Sepal.Width_linear #>            [,1] #> [1,] -1.1476025 #> [2,]  0.3766748 #> attr(,\"blclass\") #> [1] \"Rcpp_BaselearnerPolynomial\" #>  #> $offset #> [1] 5.833333 #>  table(mod$getSelectedBaselearner()) #>  #> Petal.Length_linear  Sepal.Width_linear  #>                  66                  34  mod$predict() #>            [,1] #>   [1,] 5.001052 #>   [2,] 4.845565 #>   [3,] 4.892866 #>   [4,] 5.038719 #>   [5,] 5.279175 #>   [6,] 4.963384 #>   [7,] 5.005869 #>   [8,] 4.775047 #>   [9,] 4.892866 #>  [10,] 5.048353 #>  [11,] 4.685260 #>  [12,] 5.104420 #>  [13,] 5.382544 #>  [14,] 5.109237 #>  [15,] 5.241508 #>  [16,] 5.156539 #>  [17,] 5.118871 #>  [18,] 4.868781 #>  [19,] 5.175807 #>  [20,] 4.897683 #>  [21,] 5.048353 #>  [22,] 5.043536 #>  [23,] 4.973018 #>  [24,] 4.935351 #>  [25,] 5.269541 #>  [26,] 4.958567 #>  [27,] 5.038719 #>  [28,] 4.770230 #>  [29,] 5.005869 #>  [30,] 4.958567 #>  [31,] 4.845565 #>  [32,] 5.086021 #>  [33,] 4.812714 #>  [34,] 4.925717 #>  [35,] 6.205071 #>  [36,] 6.096886 #>  [37,] 6.327708 #>  [38,] 5.393917 #>  [39,] 6.134554 #>  [40,] 6.002283 #>  [41,] 5.615974 #>  [42,] 6.177038 #>  [43,] 5.709708 #>  [44,] 6.124919 #>  [45,] 6.129737 #>  [46,] 5.846796 #>  [47,] 5.828397 #>  [48,] 5.686492 #>  [49,] 6.332525 #>  [50,] 6.111337 #>  [51,] 6.139371 #>  [52,] 6.007100 #>  [53,] 6.087252 #>  [54,] 6.342159 #>  [55,] 6.092069 #>  [56,] 5.554221 #>  [57,] 5.563855 #>  [58,] 5.761827 #>  [59,] 6.271642 #>  [60,] 6.252373 #>  [61,] 5.823580 #>  [62,] 5.959798 #>  [63,] 5.936582 #>  [64,] 6.172221 #>  [65,] 5.356249 #>  [66,] 5.889280 #>  [67,] 5.964615 #>  [68,] 6.007100 #>  [69,] 5.304130 #>  [70,] 5.884463 #>  [71,] 6.271642 #>  [72,] 6.724521 #>  [73,] 5.941399 #>  [74,] 6.856792 #>  [75,] 6.493699 #>  [76,] 7.035495 #>  [77,] 6.356611 #>  [78,] 6.554582 #>  [79,] 6.153822 #>  [80,] 6.554582 #>  [81,] 7.365737 #>  [82,] 6.998697 #>  [83,] 6.714887 #>  [84,] 6.224340 #>  [85,] 6.186672 #>  [86,] 6.752554 #>  [87,] 6.842340 #>  [88,] 6.181855 #>  [89,] 6.299675 #>  [90,] 6.521732 #>  [91,] 6.682036 #>  [92,] 6.521732 #>  [93,] 6.309309 #>  [94,] 6.446397 #>  [95,] 6.809490 #>  [96,] 6.592250 #>  [97,] 6.257190 #>  [98,] 6.549765 #>  [99,] 6.634734 #> [100,] 6.271642 #> [101,] 6.752554 #> [102,] 6.427129 #> [103,] 6.153822 #> [104,] 6.427129 #> [105,] 6.384644"},{"path":"https://schalkdaniel.github.io/compboost/reference/boostSplines.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper to boost general additive models for each feature. — boostSplines","title":"Wrapper to boost general additive models for each feature. — boostSplines","text":"wrapper function automatically initializes model adding numerical features spline base-learner. Categorical features dummy encoded inserted using another linear base-learners without intercept. function boostSplines also train model.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/boostSplines.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper to boost general additive models for each feature. — boostSplines","text":"","code":"boostSplines(   data,   target,   optimizer = NULL,   loss = NULL,   learning_rate = 0.05,   iterations = 100,   trace = -1,   degree = 3,   n_knots = 20,   penalty = 2,   df = 0,   differences = 2,   data_source = InMemoryData,   oob_fraction = NULL,   bin_root = 0,   cache_type = \"inverse\",   stop_args = list(),   df_cat = 1,   stop_time = \"microseconds\",   additional_risk_logs = list() )"},{"path":"https://schalkdaniel.github.io/compboost/reference/boostSplines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper to boost general additive models for each feature. — boostSplines","text":"data data.frame data frame containing data. target character(1) Response class Character value containing target variable Response object. Note loss must match data type target. optimizer S4 Optimizer initialized S4 Optimizer object exposed Rcpp (e.g. OptimizerCoordinateDescent$new()) select features iteration. loss S4 Loss Initialized S4 Loss object exposed Rcpp used calculate risk pseudo residuals (e.g. LossQuadratic$new()). learning_rate numeric(1) Learning rate shrink parameter step. iterations integer(1) Number iterations trained. iterations == 0, untrained object returned. can useful base learners (e.g. interaction via tensor base learner) added. trace integer(1) Integer indicating often trace printed. Specifying trace = 10, every 10th iteration printed. trace printed set trace = 0. Default -1 means total 40 iterations printed. degree integer(1) Polynomial degree splines. n_knots integer(1) Number equidistant \"inner knots\". actual number used knots also depend polynomial degree. penalty numeric(1) Penalty term p-splines. penalty equals 0, ordinary b-splines fitted. higher penalty, higher smoothness. df numeric(1) Degrees freedom whole spline. important set amount degrees freedom able compare different base-learner. differences integer(1) Number differences used penalization. higher difference, higher smoothness. data_source S4 Data Uninitialized S4 Data object used store data. moment just memory training supported. oob_fraction numeric(1) Fraction much data want use track bag risk. bin_root integer(1) set value greater zero, binning applied reduces number used x values n^(1/bin_root) equidistant points. want use binning suggest set bin_root = 2. cache_type character(1)+ String indicate method used estimate parameter iteration. Default cache_type = \"cholesky\" computes Cholesky decomposition, caches , reuses matrix . option use cache_type = \"inverse\" caches inverse. stop_args list(2) List containing two elements patience eps_for_break can set use early stopping left data setting oob_fraction. df_cat numeric(1) Degrees freedom categorical base-learner. stop_time character(1) Unit measured time. additional_risk_logs list(Logger) Additional logger passed Compboost object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/boostSplines.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wrapper to boost general additive models for each feature. — boostSplines","text":"model Compboost class. model R6 object can used retraining, predicting, plotting, anything described ?Compboost.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/boostSplines.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wrapper to boost general additive models for each feature. — boostSplines","text":"returned object object Compboost class. object can used analyses (see ?Compboost details).","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/boostSplines.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wrapper to boost general additive models for each feature. — boostSplines","text":"","code":"mod = boostSplines(data = iris, target = \"Sepal.Length\", loss = LossQuadratic$new(),   oob_fraction = 0.3) #>   1/100   risk = 0.3  oob_risk = 0.35   time = 0    #>   2/100   risk = 0.28  oob_risk = 0.32   time = 81    #>   4/100   risk = 0.24  oob_risk = 0.27   time = 179    #>   6/100   risk = 0.2  oob_risk = 0.23   time = 275    #>   8/100   risk = 0.18  oob_risk = 0.2   time = 369    #>  10/100   risk = 0.16  oob_risk = 0.18   time = 462    #>  12/100   risk = 0.14  oob_risk = 0.15   time = 553    #>  14/100   risk = 0.12  oob_risk = 0.14   time = 643    #>  16/100   risk = 0.11  oob_risk = 0.12   time = 734    #>  18/100   risk = 0.1  oob_risk = 0.11   time = 827    #>  20/100   risk = 0.096  oob_risk = 0.1   time = 919    #>  22/100   risk = 0.09  oob_risk = 0.093   time = 1010    #>  24/100   risk = 0.085  oob_risk = 0.087   time = 1129    #>  26/100   risk = 0.08  oob_risk = 0.082   time = 1225    #>  28/100   risk = 0.077  oob_risk = 0.078   time = 1319    #>  30/100   risk = 0.074  oob_risk = 0.074   time = 1414    #>  32/100   risk = 0.071  oob_risk = 0.073   time = 1530    #>  34/100   risk = 0.069  oob_risk = 0.072   time = 1625    #>  36/100   risk = 0.067  oob_risk = 0.072   time = 1718    #>  38/100   risk = 0.065  oob_risk = 0.071   time = 1811    #>  40/100   risk = 0.063  oob_risk = 0.07   time = 1904    #>  42/100   risk = 0.061  oob_risk = 0.07   time = 1997    #>  44/100   risk = 0.06  oob_risk = 0.069   time = 2092    #>  46/100   risk = 0.058  oob_risk = 0.069   time = 2186    #>  48/100   risk = 0.057  oob_risk = 0.069   time = 2280    #>  50/100   risk = 0.056  oob_risk = 0.068   time = 2375    #>  52/100   risk = 0.055  oob_risk = 0.068   time = 2468    #>  54/100   risk = 0.053  oob_risk = 0.068   time = 2561    #>  56/100   risk = 0.053  oob_risk = 0.068   time = 2657    #>  58/100   risk = 0.052  oob_risk = 0.068   time = 2753    #>  60/100   risk = 0.051  oob_risk = 0.068   time = 2850    #>  62/100   risk = 0.05  oob_risk = 0.067   time = 2945    #>  64/100   risk = 0.049  oob_risk = 0.067   time = 3041    #>  66/100   risk = 0.049  oob_risk = 0.067   time = 3138    #>  68/100   risk = 0.048  oob_risk = 0.067   time = 3247    #>  70/100   risk = 0.047  oob_risk = 0.067   time = 3343    #>  72/100   risk = 0.047  oob_risk = 0.067   time = 3439    #>  74/100   risk = 0.046  oob_risk = 0.067   time = 3535    #>  76/100   risk = 0.046  oob_risk = 0.067   time = 3630    #>  78/100   risk = 0.045  oob_risk = 0.067   time = 3728    #>  80/100   risk = 0.045  oob_risk = 0.067   time = 3824    #>  82/100   risk = 0.044  oob_risk = 0.067   time = 3920    #>  84/100   risk = 0.044  oob_risk = 0.067   time = 4014    #>  86/100   risk = 0.044  oob_risk = 0.067   time = 4109    #>  88/100   risk = 0.043  oob_risk = 0.067   time = 4206    #>  90/100   risk = 0.043  oob_risk = 0.067   time = 4302    #>  92/100   risk = 0.043  oob_risk = 0.067   time = 4401    #>  94/100   risk = 0.042  oob_risk = 0.067   time = 4498    #>  96/100   risk = 0.042  oob_risk = 0.067   time = 4595    #>  98/100   risk = 0.042  oob_risk = 0.068   time = 4693    #> 100/100   risk = 0.041  oob_risk = 0.067   time = 4793    #>  #>  #> Train 100 iterations in 0 Seconds. #> Final risk based on the train set: 0.041 #>  mod$getBaselearnerNames() #> [1] \"Sepal.Width_spline\"  \"Petal.Length_spline\" \"Petal.Width_spline\"  #> [4] \"Species_ridge\"       mod$getEstimatedCoef() #> Depricated, use `$getCoef()` instead. #> $Petal.Length_spline #>              [,1] #>  [1,] -1.05834736 #>  [2,] -0.90332534 #>  [3,] -0.77252565 #>  [4,] -0.62949367 #>  [5,] -0.60846779 #>  [6,] -0.69563654 #>  [7,] -0.77204494 #>  [8,] -0.80950548 #>  [9,] -0.78151531 #> [10,] -0.66157161 #> [11,] -0.43346606 #> [12,] -0.25387847 #> [13,] -0.12896417 #> [14,]  0.07727353 #> [15,]  0.31035786 #> [16,]  0.43562087 #> [17,]  0.32978932 #> [18,]  0.38060685 #> [19,]  0.51964373 #> [20,]  0.79770827 #> [21,]  1.16794500 #> [22,]  1.45643790 #> [23,]  1.58684317 #> [24,]  1.69032086 #> attr(,\"blclass\") #> [1] \"Rcpp_BaselearnerPSpline\" #>  #> $Petal.Width_spline #>                [,1] #>  [1,] -0.2936077843 #>  [2,] -0.2306673235 #>  [3,] -0.1692863643 #>  [4,] -0.0961276922 #>  [5,] -0.0317133747 #>  [6,] -0.0349620817 #>  [7,] -0.0279065833 #>  [8,]  0.0008609872 #>  [9,]  0.0259059379 #> [10,]  0.0210443422 #> [11,] -0.0152608329 #> [12,] -0.0015115470 #> [13,]  0.0923922299 #> [14,]  0.1230523331 #> [15,]  0.0210148367 #> [16,] -0.0601193785 #> [17,] -0.0142121543 #> [18,]  0.0850542217 #> [19,]  0.1850354873 #> [20,]  0.1995192802 #> [21,]  0.1587042242 #> [22,]  0.0677795969 #> [23,]  0.0006220810 #> [24,] -0.0500095739 #> attr(,\"blclass\") #> [1] \"Rcpp_BaselearnerPSpline\" #>  #> $Sepal.Width_spline #>              [,1] #>  [1,]  0.13190502 #>  [2,] -0.02035514 #>  [3,] -0.15822390 #>  [4,] -0.23978234 #>  [5,] -0.26619135 #>  [6,] -0.20441619 #>  [7,] -0.11714285 #>  [8,] -0.01080995 #>  [9,] -0.01873584 #> [10,]  0.07739103 #> [11,]  0.18721534 #> [12,]  0.06051406 #> [13,] -0.07708973 #> [14,] -0.09885890 #> [15,] -0.03405277 #> [16,]  0.06761781 #> [17,]  0.19453418 #> [18,]  0.29940807 #> [19,]  0.37560089 #> [20,]  0.36950815 #> [21,]  0.36624304 #> [22,]  0.39430664 #> [23,]  0.43620219 #> [24,]  0.48040270 #> attr(,\"blclass\") #> [1] \"Rcpp_BaselearnerPSpline\" #>  #> $offset #> [1] 5.845714 #>  table(mod$getSelectedBaselearner()) #>  #> Petal.Length_spline  Petal.Width_spline  Sepal.Width_spline  #>                  43                  23                  34  mod$predict() #>            [,1] #>   [1,] 5.007290 #>   [2,] 5.028145 #>   [3,] 4.968136 #>   [4,] 5.479036 #>   [5,] 4.941578 #>   [6,] 4.923360 #>   [7,] 4.952102 #>   [8,] 5.084884 #>   [9,] 4.952332 #>  [10,] 4.952007 #>  [11,] 5.230850 #>  [12,] 5.559389 #>  [13,] 5.345340 #>  [14,] 5.330001 #>  [15,] 5.232018 #>  [16,] 4.767411 #>  [17,] 5.182742 #>  [18,] 4.945859 #>  [19,] 5.078687 #>  [20,] 4.936908 #>  [21,] 4.880936 #>  [22,] 5.148937 #>  [23,] 5.040306 #>  [24,] 5.319954 #>  [25,] 5.336151 #>  [26,] 5.140167 #>  [27,] 4.957895 #>  [28,] 4.923360 #>  [29,] 4.830885 #>  [30,] 5.109818 #>  [31,] 5.366927 #>  [32,] 5.067933 #>  [33,] 5.115073 #>  [34,] 4.957330 #>  [35,] 6.438842 #>  [36,] 6.321046 #>  [37,] 6.456524 #>  [38,] 5.641128 #>  [39,] 6.222341 #>  [40,] 6.117392 #>  [41,] 5.086638 #>  [42,] 6.215607 #>  [43,] 5.646046 #>  [44,] 6.014023 #>  [45,] 5.739305 #>  [46,] 5.548310 #>  [47,] 6.277979 #>  [48,] 5.689221 #>  [49,] 6.188981 #>  [50,] 5.425512 #>  [51,] 5.737852 #>  [52,] 5.996854 #>  [53,] 6.187527 #>  [54,] 6.218009 #>  [55,] 6.195607 #>  [56,] 5.250892 #>  [57,] 5.400588 #>  [58,] 5.367311 #>  [59,] 6.077357 #>  [60,] 6.049422 #>  [61,] 6.447161 #>  [62,] 5.945518 #>  [63,] 5.896202 #>  [64,] 5.531823 #>  [65,] 5.827321 #>  [66,] 6.325153 #>  [67,] 5.522932 #>  [68,] 5.168299 #>  [69,] 5.792228 #>  [70,] 5.922789 #>  [71,] 5.916360 #>  [72,] 5.996854 #>  [73,] 5.805273 #>  [74,] 6.798550 #>  [75,] 6.124536 #>  [76,] 6.909171 #>  [77,] 6.786644 #>  [78,] 7.615267 #>  [79,] 5.826625 #>  [80,] 6.294212 #>  [81,] 6.937235 #>  [82,] 6.457749 #>  [83,] 6.152145 #>  [84,] 6.104067 #>  [85,] 6.214544 #>  [86,] 7.831219 #>  [87,] 6.283407 #>  [88,] 6.707694 #>  [89,] 7.525069 #>  [90,] 6.644316 #>  [91,] 6.263853 #>  [92,] 6.942510 #>  [93,] 7.618592 #>  [94,] 6.512197 #>  [95,] 6.240767 #>  [96,] 6.264662 #>  [97,] 6.357292 #>  [98,] 6.432768 #>  [99,] 6.586697 #> [100,] 6.466392 #> [101,] 6.124536 #> [102,] 6.922589 #> [103,] 6.458348 #> [104,] 6.381314 #> [105,] 6.313058"},{"path":"https://schalkdaniel.github.io/compboost/reference/getCustomCppExample.html","id":null,"dir":"Reference","previous_headings":"","what":"Get C++ example script to define a custom cpp logger — getCustomCppExample","title":"Get C++ example script to define a custom cpp logger — getCustomCppExample","text":"function can used print trace parameters trained compboost object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/getCustomCppExample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get C++ example script to define a custom cpp logger — getCustomCppExample","text":"","code":"getCustomCppExample(example = \"blearner\", silent = FALSE)"},{"path":"https://schalkdaniel.github.io/compboost/reference/getCustomCppExample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get C++ example script to define a custom cpp logger — getCustomCppExample","text":"example character(1)  Character value indicating example base-learner loss returned. values one blearner loss. silent logical(1)  Logical value indicating example code printed screen .","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/getCustomCppExample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get C++ example script to define a custom cpp logger — getCustomCppExample","text":"function returns character vector can compiled using Rcpp::sourceCpp(code = getCustomCppExample()) define new custom cpp logger.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotBaselearner.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize contribution of one base learner — plotBaselearner","title":"Visualize contribution of one base learner — plotBaselearner","text":"function visualizes contribution base learner overall prediction score. visualization partial effects see plotPEUni.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotBaselearner.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize contribution of one base learner — plotBaselearner","text":"","code":"plotBaselearner(cboost, blname, npoints = 100L)"},{"path":"https://schalkdaniel.github.io/compboost/reference/plotBaselearner.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize contribution of one base learner — plotBaselearner","text":"cboost Compboost class trained Compboost object. blname character(1L) Name base learner. Must one cboost$getBaselearnerNames(). npoints integer(1L) Number points predicted lines (applies numerical features).","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotBaselearner.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize contribution of one base learner — plotBaselearner","text":"ggplot object containing graphic.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotBaselearner.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize contribution of one base learner — plotBaselearner","text":"","code":"cboost = Compboost$new(data = iris, target = \"Petal.Length\",   loss = LossQuadratic$new()) cboost$addComponents(\"Sepal.Width\") cboost$train(500L) #>   1/500   risk = 1.5   #>  12/500   risk = 1.3   #>  24/500   risk = 1.2   #>  36/500   risk = 1.2   #>  48/500   risk = 1.1   #>  60/500   risk = 1.1   #>  72/500   risk = 1.1   #>  84/500   risk = 1.1   #>  96/500   risk = 1.1   #> 108/500   risk = 1.1   #> 120/500   risk = 1.1   #> 132/500   risk = 1.1   #> 144/500   risk = 1.1   #> 156/500   risk = 1.1   #> 168/500   risk = 1.1   #> 180/500   risk = 1.1   #> 192/500   risk = 1   #> 204/500   risk = 1   #> 216/500   risk = 1   #> 228/500   risk = 1   #> 240/500   risk = 1   #> 252/500   risk = 1   #> 264/500   risk = 1   #> 276/500   risk = 1   #> 288/500   risk = 1   #> 300/500   risk = 1   #> 312/500   risk = 1   #> 324/500   risk = 1   #> 336/500   risk = 1   #> 348/500   risk = 1   #> 360/500   risk = 1   #> 372/500   risk = 1   #> 384/500   risk = 1   #> 396/500   risk = 1   #> 408/500   risk = 1   #> 420/500   risk = 1   #> 432/500   risk = 1   #> 444/500   risk = 1   #> 456/500   risk = 1   #> 468/500   risk = 1   #> 480/500   risk = 1   #> 492/500   risk = 1   #>  #>  #> Train 500 iterations in 0 Seconds. #> Final risk based on the train set: 1 #>  plotBaselearner(cboost, \"Sepal.Width_linear\")  plotBaselearner(cboost, \"Sepal.Width_Sepal.Width_spline_centered\")"},{"path":"https://schalkdaniel.github.io/compboost/reference/plotBaselearnerTraces.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize base learner traces — plotBaselearnerTraces","title":"Visualize base learner traces — plotBaselearnerTraces","text":"function shows base learners evolves fitting process. default show frequency single base learner included model evolves. Additionally, value argument, vectors (e.g. risk) can used show base learner specific risk reduction evolves fitting process.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotBaselearnerTraces.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize base learner traces — plotBaselearnerTraces","text":"","code":"plotBaselearnerTraces(cboost, value = 1, n_legend = 5L)"},{"path":"https://schalkdaniel.github.io/compboost/reference/plotBaselearnerTraces.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize base learner traces — plotBaselearnerTraces","text":"cboost Compboost class trained Compboost object. value numeric(1L) | numeric(length(cboost$getSelectedBaselearner())) Value used show base learner development w.r.t. value. n_legend integer(1L) Number colored base learners added legend.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotBaselearnerTraces.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize base learner traces — plotBaselearnerTraces","text":"ggplot object containing graphic.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotBaselearnerTraces.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize base learner traces — plotBaselearnerTraces","text":"","code":"cboost = Compboost$new(data = iris, target = \"Petal.Length\",  loss = LossQuadratic$new()) cboost$addComponents(\"Sepal.Width\") cboost$addBaselearner(\"Species\", \"ridge\", BaselearnerCategoricalRidge) cboost$train(500L) #>   1/500   risk = 1.4   #>  12/500   risk = 0.52   #>  24/500   risk = 0.21   #>  36/500   risk = 0.13   #>  48/500   risk = 0.1   #>  60/500   risk = 0.093   #>  72/500   risk = 0.088   #>  84/500   risk = 0.085   #>  96/500   risk = 0.083   #> 108/500   risk = 0.081   #> 120/500   risk = 0.079   #> 132/500   risk = 0.078   #> 144/500   risk = 0.077   #> 156/500   risk = 0.076   #> 168/500   risk = 0.075   #> 180/500   risk = 0.074   #> 192/500   risk = 0.074   #> 204/500   risk = 0.073   #> 216/500   risk = 0.073   #> 228/500   risk = 0.072   #> 240/500   risk = 0.072   #> 252/500   risk = 0.072   #> 264/500   risk = 0.071   #> 276/500   risk = 0.071   #> 288/500   risk = 0.071   #> 300/500   risk = 0.071   #> 312/500   risk = 0.071   #> 324/500   risk = 0.07   #> 336/500   risk = 0.07   #> 348/500   risk = 0.07   #> 360/500   risk = 0.07   #> 372/500   risk = 0.07   #> 384/500   risk = 0.07   #> 396/500   risk = 0.069   #> 408/500   risk = 0.069   #> 420/500   risk = 0.069   #> 432/500   risk = 0.069   #> 444/500   risk = 0.069   #> 456/500   risk = 0.069   #> 468/500   risk = 0.069   #> 480/500   risk = 0.069   #> 492/500   risk = 0.069   #>  #>  #> Train 500 iterations in 0 Seconds. #> Final risk based on the train set: 0.069 #>  plotBaselearnerTraces(cboost)"},{"path":"https://schalkdaniel.github.io/compboost/reference/plotFeatureImportance.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize the feature importance — plotFeatureImportance","title":"Visualize the feature importance — plotFeatureImportance","text":"function visualizes feature importance horizontal bar plot.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotFeatureImportance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize the feature importance — plotFeatureImportance","text":"","code":"plotFeatureImportance(cboost, num_feats = NULL, aggregate = TRUE)"},{"path":"https://schalkdaniel.github.io/compboost/reference/plotFeatureImportance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize the feature importance — plotFeatureImportance","text":"cboost Compboost class trained Compboost object. num_feats integer(1L) Number features visualized. features added set NULL. aggregate logical(1L) Flag whether feature importance aggregated feature. Otherwise visualized per base learner.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotFeatureImportance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize the feature importance — plotFeatureImportance","text":"ggplot object containing graphic.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotFeatureImportance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize the feature importance — plotFeatureImportance","text":"","code":"cboost = boostSplines(data = iris, target = \"Sepal.Length\", loss = LossQuadratic$new()) #>   1/100   risk = 0.31  time = 0    #>   2/100   risk = 0.29  time = 89    #>   4/100   risk = 0.25  time = 212    #>   6/100   risk = 0.21  time = 329    #>   8/100   risk = 0.18  time = 444    #>  10/100   risk = 0.16  time = 562    #>  12/100   risk = 0.14  time = 677    #>  14/100   risk = 0.13  time = 791    #>  16/100   risk = 0.11  time = 906    #>  18/100   risk = 0.1  time = 1021    #>  20/100   risk = 0.095  time = 1134    #>  22/100   risk = 0.088  time = 1254    #>  24/100   risk = 0.083  time = 1367    #>  26/100   risk = 0.078  time = 1493    #>  28/100   risk = 0.074  time = 1611    #>  30/100   risk = 0.071  time = 1726    #>  32/100   risk = 0.069  time = 1840    #>  34/100   risk = 0.067  time = 1954    #>  36/100   risk = 0.065  time = 2068    #>  38/100   risk = 0.063  time = 2183    #>  40/100   risk = 0.062  time = 2297    #>  42/100   risk = 0.061  time = 2414    #>  44/100   risk = 0.06  time = 2531    #>  46/100   risk = 0.059  time = 2645    #>  48/100   risk = 0.058  time = 2760    #>  50/100   risk = 0.057  time = 2874    #>  52/100   risk = 0.056  time = 2990    #>  54/100   risk = 0.056  time = 3107    #>  56/100   risk = 0.055  time = 3221    #>  58/100   risk = 0.054  time = 3336    #>  60/100   risk = 0.054  time = 3453    #>  62/100   risk = 0.053  time = 3568    #>  64/100   risk = 0.052  time = 3682    #>  66/100   risk = 0.052  time = 3803    #>  68/100   risk = 0.051  time = 3919    #>  70/100   risk = 0.051  time = 4036    #>  72/100   risk = 0.051  time = 4151    #>  74/100   risk = 0.05  time = 4267    #>  76/100   risk = 0.05  time = 4398    #>  78/100   risk = 0.049  time = 4516    #>  80/100   risk = 0.049  time = 4633    #>  82/100   risk = 0.049  time = 4748    #>  84/100   risk = 0.048  time = 4865    #>  86/100   risk = 0.048  time = 4980    #>  88/100   risk = 0.048  time = 5096    #>  90/100   risk = 0.048  time = 5213    #>  92/100   risk = 0.047  time = 5330    #>  94/100   risk = 0.047  time = 5463    #>  96/100   risk = 0.047  time = 5586    #>  98/100   risk = 0.047  time = 5704    #> 100/100   risk = 0.046  time = 5823    #>  #>  #> Train 100 iterations in 0 Seconds. #> Final risk based on the train set: 0.046 #>  plotFeatureImportance(cboost)  plotFeatureImportance(cboost, num_feats = 2)  plotFeatureImportance(cboost, num_feats = 2, aggregate = FALSE)"},{"path":"https://schalkdaniel.github.io/compboost/reference/plotIndividualContribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Decompose the predicted value based on the given features — plotIndividualContribution","title":"Decompose the predicted value based on the given features — plotIndividualContribution","text":"function visualizes contribution feature regarding predicted value. default, multiple base learners defined one feature aggregated. want show contribution single base learner, set aggregate = FALSE.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotIndividualContribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Decompose the predicted value based on the given features — plotIndividualContribution","text":"","code":"plotIndividualContribution(   cboost,   newdata,   aggregate = TRUE,   colbreaks = c(-Inf, 0, Inf),   collabels = c(\"negative\", \"positive\"),   nround = 2L,   offset = TRUE )"},{"path":"https://schalkdaniel.github.io/compboost/reference/plotIndividualContribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Decompose the predicted value based on the given features — plotIndividualContribution","text":"cboost Compboost class trained Compboost object. newdata data.frame Data frame containing exactly one row holding new observations. aggregate logical(1L) Number colored base learners added legend. colbreaks numeric() Breaks visualize/highlight different predicted values. Default creates different colors positive negative score values. set NULL coloring applied. collabels character(length(colbreaks) - 1) Labels color breaks. set NULL intervals used labels. nround integer(1L) Digit passed round labels (default nround = 2L). offset logical(1L) Flag indicate whether offset added figure .","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotIndividualContribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Decompose the predicted value based on the given features — plotIndividualContribution","text":"ggplot object containing graphic.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotIndividualContribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Decompose the predicted value based on the given features — plotIndividualContribution","text":"","code":"dat = mtcars fnum = c(\"cyl\", \"disp\", \"hp\", \"drat\", \"wt\", \"qsec\") fcat = c(\"vs\", \"am\", \"gear\", \"carb\") for (fn in fcat) dat[[fn]] = as.factor(dat[[fn]])  cboost = Compboost$new(data = dat, target = \"mpg\",   loss = LossQuadratic$new())  for (fn in fnum) cboost$addComponents(fn, df = 3) for (fn in fcat) cboost$addBaselearner(fn, \"ridge\", BaselearnerCategoricalRidge) cboost$train(500L) #>   1/500   risk = 16   #>  12/500   risk = 7.9   #>  24/500   risk = 4.6   #>  36/500   risk = 3.4   #>  48/500   risk = 3   #>  60/500   risk = 2.7   #>  72/500   risk = 2.6   #>  84/500   risk = 2.6   #>  96/500   risk = 2.5   #> 108/500   risk = 2.5   #> 120/500   risk = 2.4   #> 132/500   risk = 2.4   #> 144/500   risk = 2.4   #> 156/500   risk = 2.3   #> 168/500   risk = 2.3   #> 180/500   risk = 2.3   #> 192/500   risk = 2.3   #> 204/500   risk = 2.3   #> 216/500   risk = 2.2   #> 228/500   risk = 2.2   #> 240/500   risk = 2.2   #> 252/500   risk = 2.2   #> 264/500   risk = 2.2   #> 276/500   risk = 2.2   #> 288/500   risk = 2.1   #> 300/500   risk = 2.1   #> 312/500   risk = 2.1   #> 324/500   risk = 2.1   #> 336/500   risk = 2.1   #> 348/500   risk = 2.1   #> 360/500   risk = 2.1   #> 372/500   risk = 2.1   #> 384/500   risk = 2.1   #> 396/500   risk = 2   #> 408/500   risk = 2   #> 420/500   risk = 2   #> 432/500   risk = 2   #> 444/500   risk = 2   #> 456/500   risk = 2   #> 468/500   risk = 2   #> 480/500   risk = 2   #> 492/500   risk = 2   #>  #>  #> Train 500 iterations in 0 Seconds. #> Final risk based on the train set: 2 #>  cbreaks = c(-Inf, -0.1, 0.1, Inf) clabs   = c(\"bad\", \"middle\", \"good\") plotIndividualContribution(cboost, dat[10, ], colbreaks = cbreaks,   collabels = clabs)  plotIndividualContribution(cboost, dat[10, ], offset = FALSE,   colbreaks = cbreaks, collabels = clabs)"},{"path":"https://schalkdaniel.github.io/compboost/reference/plotPEUni.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize partial effect of a feature — plotPEUni","title":"Visualize partial effect of a feature — plotPEUni","text":"function visualizes contribution specific feature overall prediction score. multiple base learner features included, added graphic well aggregated contribution. difference plotBaselearner potentially multiple base learners based feat aggregated visualized plotBaselearner visualizes contribution one specific base learner. function also automatically decides whether given feature numeric categorical chooses appropriate technique (lines numeric horizontal lines categorical).","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotPEUni.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize partial effect of a feature — plotPEUni","text":"","code":"plotPEUni(cboost, feat, npoints = 100L, individual = TRUE)"},{"path":"https://schalkdaniel.github.io/compboost/reference/plotPEUni.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize partial effect of a feature — plotPEUni","text":"cboost Compboost class trained Compboost object. feat character(1L) Name feature. npoints integer(1L) Number points predicted lines (applies numerical features). individual logical(1L) Flag whether individual base learners added graphic .","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotPEUni.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize partial effect of a feature — plotPEUni","text":"ggplot object containing graphic.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotPEUni.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize partial effect of a feature — plotPEUni","text":"","code":"cboost = Compboost$new(data = iris, target = \"Petal.Length\",   loss = LossQuadratic$new()) cboost$addComponents(\"Sepal.Width\") cboost$train(500L) #>   1/500   risk = 1.5   #>  12/500   risk = 1.3   #>  24/500   risk = 1.2   #>  36/500   risk = 1.2   #>  48/500   risk = 1.1   #>  60/500   risk = 1.1   #>  72/500   risk = 1.1   #>  84/500   risk = 1.1   #>  96/500   risk = 1.1   #> 108/500   risk = 1.1   #> 120/500   risk = 1.1   #> 132/500   risk = 1.1   #> 144/500   risk = 1.1   #> 156/500   risk = 1.1   #> 168/500   risk = 1.1   #> 180/500   risk = 1.1   #> 192/500   risk = 1   #> 204/500   risk = 1   #> 216/500   risk = 1   #> 228/500   risk = 1   #> 240/500   risk = 1   #> 252/500   risk = 1   #> 264/500   risk = 1   #> 276/500   risk = 1   #> 288/500   risk = 1   #> 300/500   risk = 1   #> 312/500   risk = 1   #> 324/500   risk = 1   #> 336/500   risk = 1   #> 348/500   risk = 1   #> 360/500   risk = 1   #> 372/500   risk = 1   #> 384/500   risk = 1   #> 396/500   risk = 1   #> 408/500   risk = 1   #> 420/500   risk = 1   #> 432/500   risk = 1   #> 444/500   risk = 1   #> 456/500   risk = 1   #> 468/500   risk = 1   #> 480/500   risk = 1   #> 492/500   risk = 1   #>  #>  #> Train 500 iterations in 0 Seconds. #> Final risk based on the train set: 1 #>  plotPEUni(cboost, \"Sepal.Width\")"},{"path":"https://schalkdaniel.github.io/compboost/reference/plotRisk.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize the risk — plotRisk","title":"Visualize the risk — plotRisk","text":"function visualizes risk training. validation data given, train risk plotted validation risk.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotRisk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize the risk — plotRisk","text":"","code":"plotRisk(cboost)"},{"path":"https://schalkdaniel.github.io/compboost/reference/plotRisk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize the risk — plotRisk","text":"cboost Compboost class trained Compboost object.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotRisk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize the risk — plotRisk","text":"ggplot object containing graphic.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotRisk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize the risk — plotRisk","text":"","code":"cboost_no_valdat = boostSplines(data = iris, target = \"Sepal.Length\",   loss = LossQuadratic$new()) #>   1/100   risk = 0.31  time = 0    #>   2/100   risk = 0.29  time = 46246    #>   4/100   risk = 0.25  time = 53217    #>   6/100   risk = 0.21  time = 53361    #>   8/100   risk = 0.18  time = 53478    #>  10/100   risk = 0.16  time = 53592    #>  12/100   risk = 0.14  time = 53704    #>  14/100   risk = 0.13  time = 53813    #>  16/100   risk = 0.11  time = 53923    #>  18/100   risk = 0.1  time = 54041    #>  20/100   risk = 0.095  time = 54153    #>  22/100   risk = 0.088  time = 54264    #>  24/100   risk = 0.083  time = 54373    #>  26/100   risk = 0.078  time = 54484    #>  28/100   risk = 0.074  time = 54594    #>  30/100   risk = 0.071  time = 54705    #>  32/100   risk = 0.069  time = 54817    #>  34/100   risk = 0.067  time = 54929    #>  36/100   risk = 0.065  time = 55041    #>  38/100   risk = 0.063  time = 55153    #>  40/100   risk = 0.062  time = 55264    #>  42/100   risk = 0.061  time = 55377    #>  44/100   risk = 0.06  time = 55488    #>  46/100   risk = 0.059  time = 55600    #>  48/100   risk = 0.058  time = 55735    #>  50/100   risk = 0.057  time = 55849    #>  52/100   risk = 0.056  time = 55962    #>  54/100   risk = 0.056  time = 56073    #>  56/100   risk = 0.055  time = 56186    #>  58/100   risk = 0.054  time = 56299    #>  60/100   risk = 0.054  time = 56413    #>  62/100   risk = 0.053  time = 56527    #>  64/100   risk = 0.052  time = 56639    #>  66/100   risk = 0.052  time = 56757    #>  68/100   risk = 0.051  time = 56873    #>  70/100   risk = 0.051  time = 56987    #>  72/100   risk = 0.051  time = 57099    #>  74/100   risk = 0.05  time = 57212    #>  76/100   risk = 0.05  time = 57325    #>  78/100   risk = 0.049  time = 57438    #>  80/100   risk = 0.049  time = 57551    #>  82/100   risk = 0.049  time = 57668    #>  84/100   risk = 0.048  time = 57782    #>  86/100   risk = 0.048  time = 57896    #>  88/100   risk = 0.048  time = 58011    #>  90/100   risk = 0.048  time = 58125    #>  92/100   risk = 0.047  time = 58239    #>  94/100   risk = 0.047  time = 58354    #>  96/100   risk = 0.047  time = 58467    #>  98/100   risk = 0.047  time = 58581    #> 100/100   risk = 0.046  time = 58695    #>  #>  #> Train 100 iterations in 0 Seconds. #> Final risk based on the train set: 0.046 #>  plotRisk(cboost_no_valdat)   cboost_valdat = boostSplines(data = iris, target = \"Sepal.Length\",   loss = LossQuadratic$new(), oob_fraction = 0.3) #>   1/100   risk = 0.35  oob_risk = 0.23   time = 0    #>   2/100   risk = 0.32  oob_risk = 0.22   time = 75    #>   4/100   risk = 0.27  oob_risk = 0.19   time = 166    #>   6/100   risk = 0.23  oob_risk = 0.16   time = 256    #>   8/100   risk = 0.2  oob_risk = 0.15   time = 344    #>  10/100   risk = 0.18  oob_risk = 0.13   time = 433    #>  12/100   risk = 0.16  oob_risk = 0.12   time = 520    #>  14/100   risk = 0.14  oob_risk = 0.11   time = 622    #>  16/100   risk = 0.12  oob_risk = 0.097   time = 712    #>  18/100   risk = 0.11  oob_risk = 0.09   time = 803    #>  20/100   risk = 0.1  oob_risk = 0.084   time = 891    #>  22/100   risk = 0.096  oob_risk = 0.079   time = 981    #>  24/100   risk = 0.09  oob_risk = 0.075   time = 1070    #>  26/100   risk = 0.085  oob_risk = 0.071   time = 1156    #>  28/100   risk = 0.08  oob_risk = 0.068   time = 1243    #>  30/100   risk = 0.077  oob_risk = 0.066   time = 1352    #>  32/100   risk = 0.074  oob_risk = 0.063   time = 1440    #>  34/100   risk = 0.072  oob_risk = 0.061   time = 1528    #>  36/100   risk = 0.07  oob_risk = 0.06   time = 1616    #>  38/100   risk = 0.068  oob_risk = 0.059   time = 1723    #>  40/100   risk = 0.066  oob_risk = 0.058   time = 1815    #>  42/100   risk = 0.065  oob_risk = 0.057   time = 1904    #>  44/100   risk = 0.064  oob_risk = 0.056   time = 1992    #>  46/100   risk = 0.062  oob_risk = 0.056   time = 2081    #>  48/100   risk = 0.061  oob_risk = 0.055   time = 2171    #>  50/100   risk = 0.06  oob_risk = 0.055   time = 2260    #>  52/100   risk = 0.059  oob_risk = 0.055   time = 2350    #>  54/100   risk = 0.058  oob_risk = 0.054   time = 2437    #>  56/100   risk = 0.057  oob_risk = 0.054   time = 2528    #>  58/100   risk = 0.056  oob_risk = 0.054   time = 2617    #>  60/100   risk = 0.056  oob_risk = 0.053   time = 2707    #>  62/100   risk = 0.055  oob_risk = 0.053   time = 2797    #>  64/100   risk = 0.054  oob_risk = 0.053   time = 2886    #>  66/100   risk = 0.054  oob_risk = 0.053   time = 2979    #>  68/100   risk = 0.053  oob_risk = 0.052   time = 3070    #>  70/100   risk = 0.052  oob_risk = 0.052   time = 3161    #>  72/100   risk = 0.052  oob_risk = 0.052   time = 3252    #>  74/100   risk = 0.051  oob_risk = 0.052   time = 3344    #>  76/100   risk = 0.051  oob_risk = 0.052   time = 3434    #>  78/100   risk = 0.05  oob_risk = 0.051   time = 3524    #>  80/100   risk = 0.05  oob_risk = 0.051   time = 3615    #>  82/100   risk = 0.05  oob_risk = 0.051   time = 3705    #>  84/100   risk = 0.049  oob_risk = 0.051   time = 3795    #>  86/100   risk = 0.049  oob_risk = 0.051   time = 3884    #>  88/100   risk = 0.048  oob_risk = 0.051   time = 3974    #>  90/100   risk = 0.048  oob_risk = 0.051   time = 4065    #>  92/100   risk = 0.048  oob_risk = 0.051   time = 4155    #>  94/100   risk = 0.047  oob_risk = 0.051   time = 4246    #>  96/100   risk = 0.047  oob_risk = 0.051   time = 4339    #>  98/100   risk = 0.047  oob_risk = 0.051   time = 4431    #> 100/100   risk = 0.046  oob_risk = 0.051   time = 4525    #>  #>  #> Train 100 iterations in 0 Seconds. #> Final risk based on the train set: 0.046 #>  plotRisk(cboost_valdat)"},{"path":"https://schalkdaniel.github.io/compboost/reference/plotTensor.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize bivariate tensor products — plotTensor","title":"Visualize bivariate tensor products — plotTensor","text":"function visualizes contribution bivariate tensor product.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotTensor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize bivariate tensor products — plotTensor","text":"","code":"plotTensor(cboost, tname, npoints = 100L, nbins = 15L)"},{"path":"https://schalkdaniel.github.io/compboost/reference/plotTensor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize bivariate tensor products — plotTensor","text":"cboost Compboost class trained Compboost object. tname character(2L) Name tensor base learner. npoints integer(1L) Number grid points per numerical feature. Note: two numerical features overall number grid points npoints^2. numerical categorical feature npoints * ncat ncat number categories. two categorical features ncat^2 grid points drawn. nbins logical(1L) Number bins surface. applies case two numerical features. smooth surface drawn nbins = NULL.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotTensor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize bivariate tensor products — plotTensor","text":"ggplot object containing graphic.","code":""},{"path":"https://schalkdaniel.github.io/compboost/reference/plotTensor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize bivariate tensor products — plotTensor","text":"","code":"cboost = Compboost$new(data = iris, target = \"Petal.Length\",       loss = LossQuadratic$new())  cboost$addBaselearner(\"Sepal.Width\", \"spline\", BaselearnerPSpline, df = 4) cboost$addBaselearner(\"Sepal.Length\", \"spline\", BaselearnerPSpline, df = 4) cboost$addBaselearner(\"Species\", \"ridge\", BaselearnerCategoricalRidge) cboost$addTensor(\"Sepal.Width\", \"Sepal.Length\", df1 = 4, df2 = 4) cboost$addTensor(\"Sepal.Width\", \"Species\", df1 = 4, df2 = 2)  cboost$train(1000L) #>    1/1000   risk = 1.4   #>   25/1000   risk = 0.18   #>   50/1000   risk = 0.054   #>   75/1000   risk = 0.041   #>  100/1000   risk = 0.039   #>  125/1000   risk = 0.038   #>  150/1000   risk = 0.037   #>  175/1000   risk = 0.036   #>  200/1000   risk = 0.036   #>  225/1000   risk = 0.035   #>  250/1000   risk = 0.035   #>  275/1000   risk = 0.035   #>  300/1000   risk = 0.034   #>  325/1000   risk = 0.034   #>  350/1000   risk = 0.034   #>  375/1000   risk = 0.033   #>  400/1000   risk = 0.033   #>  425/1000   risk = 0.033   #>  450/1000   risk = 0.033   #>  475/1000   risk = 0.032   #>  500/1000   risk = 0.032   #>  525/1000   risk = 0.032   #>  550/1000   risk = 0.032   #>  575/1000   risk = 0.032   #>  600/1000   risk = 0.031   #>  625/1000   risk = 0.031   #>  650/1000   risk = 0.031   #>  675/1000   risk = 0.031   #>  700/1000   risk = 0.031   #>  725/1000   risk = 0.031   #>  750/1000   risk = 0.031   #>  775/1000   risk = 0.031   #>  800/1000   risk = 0.03   #>  825/1000   risk = 0.03   #>  850/1000   risk = 0.03   #>  875/1000   risk = 0.03   #>  900/1000   risk = 0.03   #>  925/1000   risk = 0.03   #>  950/1000   risk = 0.03   #>  975/1000   risk = 0.03   #> 1000/1000   risk = 0.03   #>  #>  #> Train 1000 iterations in 0 Seconds. #> Final risk based on the train set: 0.03 #>   plotTensor(cboost, \"Sepal.Width_Species_tensor\")  plotTensor(cboost, \"Sepal.Width_Sepal.Length_tensor\")  plotTensor(cboost, \"Sepal.Width_Sepal.Length_tensor\", nbins = NULL)"}]

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compboost.R
\name{Compboost}
\alias{Compboost}
\title{Component-wise boosting}
\description{
Fit a component-wise boosting model Buehlmann (2003).
This class wraps the \code{S4} class system with \link{Compboost_internal}
as internal model representation exposed by \code{Rcpp}.
The two convenient wrapper \code{\link[=boostLinear]{boostLinear()}} and \code{\link[=boostSplines]{boostSplines()}} are
also creating objects of this class.

Visualizing the internals see \code{\link[=plotBaselearnerTraces]{plotBaselearnerTraces()}}, \code{\link[=plotBaselearner]{plotBaselearner()}}, \code{\link[=plotFeatureImportance]{plotFeatureImportance()}},
\code{\link[=plotPEUni]{plotPEUni()}}, \code{\link[=plotTensor]{plotTensor()}}, and \code{\link[=plotRisk]{plotRisk()}}. Visualizing the contribution for
one new observation see \code{\link[=plotIndividualContribution]{plotIndividualContribution()}}.
}
\examples{
cboost = Compboost$new(mtcars, "mpg", loss = LossQuadratic$new(), oob_fraction = 0.3)
cboost$addBaselearner("hp", "spline", BaselearnerPSpline, degree = 3,
  n_knots = 10, df = 3, differences = 2)
cboost$addBaselearner("wt", "spline", BaselearnerPSpline)
cboost$train(1000, 0)

table(cboost$getSelectedBaselearner())
head(cboost$logs)
names(cboost$baselearner_list)

# Access information about the a base learner in the list:
cboost$baselearner_list$hp_spline$factory$getDF()
cboost$baselearner_list$hp_spline$factory$getPenalty()
plotBaselearner(cboost, "hp_spline")
}
\references{
Buehlmann, Peter, Yu, Bin (2003).
\dQuote{Boosting with the L2 loss: regression and classification.}
\emph{Journal of the American Statistical Association}, \bold{98}(462), 324--339.
\doi{10.1198/016214503000125}.
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{data}}{(\code{data.frame})\cr
The data used for training the model. Note: If \code{oob_fraction} is set, the
input data is split into \code{data} and \code{data_oob}. Hence, \code{data} contains a
subset of the input data to train the model.}

\item{\code{data_oob}}{(\code{data.frame})\cr
An out-of-bag data set used for risk logging or early stopping. \code{data_oob}
is split from the input data (see the \code{data} field).}

\item{\code{oob_fraction}}{(\code{numeric(1)})\cr
The fraction of \verb{nrow(input data)} defining the number of observations in
\code{data_oob}.}

\item{\code{response}}{(\link{ResponseRegr} | \link{ResponseBinaryClassif})\cr
A \code{S4} response object. See \code{?ResponseRegr} or \code{?ResponseBinaryClassif} for help.
This object holds the current prediction, pseudo residuals and functions to
transform scores. Note: This response corresponds to the \code{data} field and holds
the predictions for that \code{data.frame}.}

\item{\code{response_oob}}{(\link{ResponseRegr} | \link{ResponseBinaryClassif})\cr
A \code{S4} response object. See \code{?ResponseRegr} or \code{?ResponseBinaryClassif} for help.
Same as \code{response} but for \code{data_oob}.}

\item{\code{target}}{(\code{character(1)})\cr
Name of the target variable in \code{data}.}

\item{\code{id}}{(\code{character(1)})\cr
Name of the data object defined in \verb{$new(data, ...)}.}

\item{\code{optimizer}}{(\link{OptimizerCoordinateDescent} | \link{OptimizerCoordinateDescentLineSearch} | \link{OptimizerAGBM} | \link{OptimizerCosineAnnealing})\cr
An initialized \code{S4} optimizer object (requires to call \verb{Optimizer*$new(..)}.
See the respective help page for further information.}

\item{\code{loss}}{(\link{LossQuadratic} | \link{LossBinomial} | \link{LossHuber} | \link{LossAbsolute} | \link{LossQuantile})\cr
An initialized \code{S4} loss object (requires to call \verb{Loss*$new(...)}).
See the respective help page for further information.}

\item{\code{learning_rate}}{(\code{numeric(1)})\cr
The learning rate of the model. Note: Some optimizer do dynamically vary the learning rate.}

\item{\code{model}}{(\link{Compboost_internal})\cr
The internal Compboost object exported from \code{Rcpp}. See \code{?Compboost_internal} for details.}

\item{\code{bl_factory_list}}{([BlearnerFactoryList)\cr
A container with all base learners. See \code{?BlearnerFactoryList} for details.}

\item{\code{positive}}{(\code{character(1)})\cr
The positive class in the case of binary classification.}

\item{\code{stop_all}}{(\code{logical(1)})\cr
Indicator whether all stopper must return \code{TRUE} to early stop the algorithm.
Comparable to \code{all()} if \code{stop_all = TRUE} and \code{any()} if \code{stop_all = FALSE}.}

\item{\code{early_stop}}{(\code{logical(1)})\cr
Indicator whether early stopping is used or not.}
}
\if{html}{\out{</div>}}
}
\section{Active bindings}{
\if{html}{\out{<div class="r6-active-bindings">}}
\describe{
\item{\code{offset}}{(\code{numeric()})\cr
Offset of the estimated model.}

\item{\code{baselearner_list}}{(\code{list()})\cr
Named \code{list} with names \verb{$getBaselearnerNames()}. Each elements contains
\itemize{
\item \code{"feature"} (\code{character(1)}): The name of the feature from \code{data}.
\item \code{"factory"} (\verb{Baselearner*}): The raw base learner as  \code{factory}object. See \verb{?Baselearner*} for details.
}}

\item{\code{boost_intercept}}{(\code{logical(1)})\cr
Logical value indicating whether an intercept base learner was added with \verb{$addIntercept()} or not.}

\item{\code{logs}}{(\code{data.frame})\cr
Basic information such as risk, selected base learner etc. about each iteration.
If \code{oob_data} is set, further information about the validation/oob risk is also logged.
The same applies for time logging etc. Note: Using the field \code{logs} internally is set and updated
after each call to \verb{$getLoggerData()}. Hence, it cashes the logged data set instead of
recalculating the data set as it is done for \verb{$getLoggerData()}.}

\item{\code{idx_oob}}{(\code{integer()})\cr
An index vector used to split \code{data} into \code{data = data[idx_train, ]} and \code{data_oob = data[idx_oob, ]}.
Note: \code{oob_fraction} is ignored if this argument is set.}

\item{\code{idx_train}}{(\code{integer()})\cr
An index vector used to split \code{data} into \code{data = data[idx_train, ]} and \code{data_oob = data[idx_oob, ]}.
Note: \code{oob_fraction} is ignored if this argument is set.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{Compboost$new()}}
\item \href{#method-addLogger}{\code{Compboost$addLogger()}}
\item \href{#method-getCurrentIteration}{\code{Compboost$getCurrentIteration()}}
\item \href{#method-addIntercept}{\code{Compboost$addIntercept()}}
\item \href{#method-addBaselearner}{\code{Compboost$addBaselearner()}}
\item \href{#method-rmBaselearner}{\code{Compboost$rmBaselearner()}}
\item \href{#method-addTensor}{\code{Compboost$addTensor()}}
\item \href{#method-addComponents}{\code{Compboost$addComponents()}}
\item \href{#method-train}{\code{Compboost$train()}}
\item \href{#method-prepareData}{\code{Compboost$prepareData()}}
\item \href{#method-prepareResponse}{\code{Compboost$prepareResponse()}}
\item \href{#method-predict}{\code{Compboost$predict()}}
\item \href{#method-predictIndividual}{\code{Compboost$predictIndividual()}}
\item \href{#method-transformData}{\code{Compboost$transformData()}}
\item \href{#method-getInbagRisk}{\code{Compboost$getInbagRisk()}}
\item \href{#method-getSelectedBaselearner}{\code{Compboost$getSelectedBaselearner()}}
\item \href{#method-print}{\code{Compboost$print()}}
\item \href{#method-getCoef}{\code{Compboost$getCoef()}}
\item \href{#method-getEstimatedCoef}{\code{Compboost$getEstimatedCoef()}}
\item \href{#method-getBaselearnerNames}{\code{Compboost$getBaselearnerNames()}}
\item \href{#method-getLoggerData}{\code{Compboost$getLoggerData()}}
\item \href{#method-calculateFeatureImportance}{\code{Compboost$calculateFeatureImportance()}}
\item \href{#method-saveToJson}{\code{Compboost$saveToJson()}}
\item \href{#method-clone}{\code{Compboost$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Creates a new instance of this \link[R6:R6Class]{R6} class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$new(
  data = NULL,
  target = NULL,
  optimizer = NULL,
  loss = NULL,
  learning_rate = 0.05,
  positive = NULL,
  oob_fraction = NULL,
  early_stop = FALSE,
  idx_oob = NULL,
  stop_args = list(eps_for_break = 0, patience = 10L),
  file = NULL
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{data}}{(\code{data.frame})\cr
The data set to build the object. Note: This data set is completely used for training if \code{is.null(idx_oob)}.
Otherwise, the data set is split into \code{data = data[idx_train, ]} and \code{data_oob = data[idx_oob, ]}.}

\item{\code{target}}{(\code{character(1)})\cr
Character indicating the name of the target variable.}

\item{\code{optimizer}}{(\link{OptimizerCoordinateDescent} | \link{OptimizerCoordinateDescentLineSearch} | \link{OptimizerAGBM} | \link{OptimizerCosineAnnealing})\cr
An initialized \code{S4} optimizer object (requires to call \code{Optimizer*.new(..)}.
See the respective help page for further information.}

\item{\code{loss}}{(\link{LossQuadratic} | \link{LossBinomial} | \link{LossHuber} | \link{LossAbsolute} | \link{LossQuantile})\cr
An initialized \code{S4} loss object (requires to call \verb{Loss*$new(...)}).
See the respective help page for further information.}

\item{\code{learning_rate}}{(\code{numeric(1)})\cr
Learning rate of the model (default is \code{0.05}).}

\item{\code{positive}}{(\code{character(1)})\cr
The name of the positive class (in the case of binary classification).}

\item{\code{oob_fraction}}{(\code{numeric(1)})\cr
The fraction of \verb{nrow(input data)} defining the number of observations in
\code{data_oob}. This argument is ignored if \code{idx_oob} is set.}

\item{\code{early_stop}}{(\code{logical(1)})\cr
Indicator whether early stopping should be used or not.}

\item{\code{idx_oob}}{(\code{integer()})\cr
An index vector used to split \code{data} into \code{data = data[idx_train, ]} and \code{data_oob = data[idx_oob, ]}.
Note: \code{oob_fraction} is ignored if this argument is set.}

\item{\code{stop_args}}{(\code{list(integer(1), integer(1))})\cr
\code{list} containing two elements \code{patience} and \code{eps_for_break} which are used for early stopping.}

\item{\code{file}}{(\verb{character(1})\cr
File from which a model should be loaded. If \code{NULL}, \code{data} and \code{target} must be defined.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-addLogger"></a>}}
\if{latex}{\out{\hypertarget{method-addLogger}{}}}
\subsection{Method \code{addLogger()}}{
Add a logger to the model.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$addLogger(logger, use_as_stopper = FALSE, logger_id, ...)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{logger}}{(\link{LoggerIteration} | \link{LoggerTime} | \link{LoggerInbagRisk} | \link{LoggerOobRisk})\cr
The uninitialized logger.}

\item{\code{use_as_stopper}}{(\code{logical(1)})\cr
Indicator defining the logger as stopper considering it for early stopping.}

\item{\code{logger_id}}{(\code{character(1)})\cr
The id of the logger. This allows to define two logger of the same type (\verb{e.g. risk logging}) but with different arguments.}

\item{\code{...}}{\cr
Additional arguments passed to \code{loger$new(logger_id, use_as_stopper, ...)}.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-getCurrentIteration"></a>}}
\if{latex}{\out{\hypertarget{method-getCurrentIteration}{}}}
\subsection{Method \code{getCurrentIteration()}}{
Get the number of the current iteration.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$getCurrentIteration()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{integer(1)} value.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-addIntercept"></a>}}
\if{latex}{\out{\hypertarget{method-addIntercept}{}}}
\subsection{Method \code{addIntercept()}}{
This functions adds a base learner that adjusts the intercept (if selected).
Adding an intercept base learner may be necessary, e.g., when adding linear effects
without intercept.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$addIntercept(id = "intercept", data_source = InMemoryData)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{id}}{(\code{character(1)})\cr
The id of the base learner (default is \code{"intercept"}).}

\item{\code{data_source}}{(\link{InMemoryData})\cr
Uninitialized data object used to store the meta data. Note: At the moment, just in memory
storing is supported, see \code{?InMemorydata} for details.}

\item{\code{data_source}}{(\link{InMemoryData})\cr
Uninitialized data object used to store the meta data. Note: At the moment, just in memory
storing is supported, see \code{?InMemorydata} for details.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-addBaselearner"></a>}}
\if{latex}{\out{\hypertarget{method-addBaselearner}{}}}
\subsection{Method \code{addBaselearner()}}{
Add a base learner of one feature to the model that is considered in each iteration.
Using \verb{$addBaselearner()} just allows including univariate features. See \verb{$addTensor()} for
bivariate effect modelling and \verb{$addComponents()} for an effect decomposition.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$addBaselearner(
  feature,
  id,
  bl_factory,
  data_source = InMemoryData,
  ...
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{feature}}{(\code{character(1)})\cr
Name of the feature, must be a column in \code{data}.}

\item{\code{feature}}{(\code{character(1)})\cr
Name of the feature, must be a column in \code{data}.}

\item{\code{id}}{(\code{character(1)})\cr
The name of the base learner.}

\item{\code{bl_factory}}{(\link{BaselearnerPolynomial} | \link{BaselearnerPSpline} | \link{BaselearnerCategoricalBinary} | \link{BaselearnerCategoricalRidge})\cr
Uninitialized base learner class. See the respective help page for details.}

\item{\code{data_source}}{(\link{InMemoryData})\cr
Uninitialized data object used to store the meta data. Note: At the moment, just in memory
storing is supported, see \code{?InMemorydata} for details.}

\item{\code{data_source}}{(\link{InMemoryData})\cr
Uninitialized data object used to store the meta data. Note: At the moment, just in memory
storing is supported, see \code{?InMemorydata} for details.}

\item{\code{...}}{\cr
Further argument spassed to the \verb{$new(...)} constructor of \code{bl_factory}.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-rmBaselearner"></a>}}
\if{latex}{\out{\hypertarget{method-rmBaselearner}{}}}
\subsection{Method \code{rmBaselearner()}}{
Remove a base learner from the model.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$rmBaselearner(blname)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{blname}}{(\code{character(1)})\cr
Name of the base learner that should be removed. Must be an element of \verb{$getBaselearnerNames()}.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-addTensor"></a>}}
\if{latex}{\out{\hypertarget{method-addTensor}{}}}
\subsection{Method \code{addTensor()}}{
Add a row-wise tensor product of features. Note: The base learner are pre-defined
by the type of the feature. Numerical features uses a \code{BaselearnerPSpline} while categorical
features are included using a \code{BaselearnerCategoricalRidge} base learner.
To include an arbitrary tensor product requires to use the \code{S4} API with using
\code{BaselearnerTensor} on two base learners of any type.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$addTensor(
  feature1,
  feature2,
  df = NULL,
  df1 = NULL,
  df2 = NULL,
  isotrop = FALSE,
  ...
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{feature1}}{(\code{character(1)})\cr
Name of the first feature. Must be an element of \code{names(data)}.}

\item{\code{feature2}}{(\code{character(1)})\cr
Name of the second feature. Must be an element of \code{names(data)}.}

\item{\code{df}}{(\code{numeric(1)})\cr
The degrees of freedom used for both base learner (this parameter overwrites \code{df1} and \code{df2}).}

\item{\code{df1}}{(\code{numeric(1)})\cr
The degrees of freedom used for the first base learner.}

\item{\code{df2}}{(\code{numeric(1)})\cr
The degrees of freedom used for the first base learner.}

\item{\code{isotrop}}{(\code{logical(1)})\cr
Indicator how the two penalties should be combined, if \code{isotrop == TRUE},
the total degrees of freedom are uniformly distributed over the dimensions while
\code{isotrop == FALSE} allows to define how strong each of the two dimensions is penalized.}

\item{\code{...}}{\cr
Additional arguments passed to the \verb{$new()} constructor of the \link{BaselearnerPSpline} class.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-addComponents"></a>}}
\if{latex}{\out{\hypertarget{method-addComponents}{}}}
\subsection{Method \code{addComponents()}}{
Add an effect with individual components. A linear term is added as well as
a non-linear term without the linear effect. This ensures that the linear
component is selected prior to the non-linear effect. The non-linear effect
is only included if a deviation from a linear effect is required.

Note: Internally, a \link{BaselearnerPolynomial} with degree one and a \link{BaselearnerCentered} is added.
Centering a base learner makes the design matrix dense and hence memory is filled very fast.
Considering binning may be an option to reduce the memory consumption.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$addComponents(feature, ...)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{feature}}{(\code{character(1)})\cr
Name of the feature, must be a column in \code{data}.}

\item{\code{feature}}{(\code{character(1)})\cr
Name of the feature, must be a column in \code{data}.}

\item{\code{...}}{\cr
Additional arguments passed to the \verb{$new()} constructor of the \link{BaselearnerPSpline} class.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-train"></a>}}
\if{latex}{\out{\hypertarget{method-train}{}}}
\subsection{Method \code{train()}}{
Start fitting a model.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$train(iteration = 100, trace = -1)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{iteration}}{(\code{integer(1)})\cr
The maximal number of iteration. The algorithm can be stopped earlier
if early stopping is active.}

\item{\code{trace}}{(\code{integer(1)})\cr
The number of integers after which the status of the fitting is printed to the screen.
The default \code{trace = -1} internally uses \code{trace = round(iteration / 40)}.
To silently fit the model use \code{trace = 0}.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-prepareData"></a>}}
\if{latex}{\out{\hypertarget{method-prepareData}{}}}
\subsection{Method \code{prepareData()}}{
Internally, each base learner is build on a \link{InMemoryData} object. Some
methods (e.g. adding a \link{LoggerOobRisk}) requires to pass the data as
\code{list(InMemoryData | CategoricalDataRaw)} with data objects as elements.
This function converts the given \code{data.frame} into that format.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$prepareData(newdata)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}

\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}

\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}

\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
\code{list(InMemoryData | CategoricalDataRaw)} with data container as elements.
Numeric features are wrapped by \link{InMemoryData} while categorical features
are included with \link{CategoricalDataRaw}.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-prepareResponse"></a>}}
\if{latex}{\out{\hypertarget{method-prepareResponse}{}}}
\subsection{Method \code{prepareResponse()}}{
Same as for \verb{$prepareData()} but for the response. Internally, \code{vectorToResponse()} is
used to generate a \link{ResponseRegr} or \link{ResponseBinaryClassif} object.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$prepareResponse(response)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{response}}{(\code{vector()})\cr
A vector of type \code{numberic} or \code{categorical} that is transformed to an
response object.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
\link{ResponseRegr} | \link{ResponseBinaryClassif} object.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-predict"></a>}}
\if{latex}{\out{\hypertarget{method-predict}{}}}
\subsection{Method \code{predict()}}{
Calculate predictions.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$predict(newdata = NULL, as_response = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}

\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}

\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}

\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}

\item{\code{as_response}}{(\code{logical(1)})\cr
In the case of binary classification, \code{as_response = TRUE} returns predictions as
response, i.e. classes.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Vector of predictions.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-predictIndividual"></a>}}
\if{latex}{\out{\hypertarget{method-predictIndividual}{}}}
\subsection{Method \code{predictIndividual()}}{
While \verb{$predict()} returns the sum of all base learner predictions, this function
returns a \code{list} with the predictions for each base learner.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$predictIndividual(newdata)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}

\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}

\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}

\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Named \code{list()} with the included base learner names as names and the base learner
predictions as elements.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-transformData"></a>}}
\if{latex}{\out{\hypertarget{method-transformData}{}}}
\subsection{Method \code{transformData()}}{
Get design matrices of all (or a subset) base learners for a new \code{data.frame}.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$transformData(newdata, blnames = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}

\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}

\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}

\item{\code{newdata}}{(\code{data.frame})\cr
New data set of the same structure as \code{data}.}

\item{\code{blnames}}{(\code{character()})\cr
Names of the base learners for which the design matrices are returned. If
\code{is.null(blnames)}, compboost tries to guess all base learners that were
constructed based on the feature names of \code{newdata}.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
\code{list(matrix | Matrix::Matrix)} matrices as elements.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-getInbagRisk"></a>}}
\if{latex}{\out{\hypertarget{method-getInbagRisk}{}}}
\subsection{Method \code{getInbagRisk()}}{
Return the training risk of each iteration.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$getInbagRisk()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{numeric()} vector of risk values or \code{NULL} if \verb{$train()} was not called previously.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-getSelectedBaselearner"></a>}}
\if{latex}{\out{\hypertarget{method-getSelectedBaselearner}{}}}
\subsection{Method \code{getSelectedBaselearner()}}{
Get a vector with the name of the selected base learner of each iteration.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$getSelectedBaselearner()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{character()} vector of base learner names.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-print"></a>}}
\if{latex}{\out{\hypertarget{method-print}{}}}
\subsection{Method \code{print()}}{
Printer of the object.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$print()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
Invisibly returns the object.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-getCoef"></a>}}
\if{latex}{\out{\hypertarget{method-getCoef}{}}}
\subsection{Method \code{getCoef()}}{
Get the estimated coefficients.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$getCoef()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{list(pars, offset)} with estimated coefficients/parameters and intercept/offset.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-getEstimatedCoef"></a>}}
\if{latex}{\out{\hypertarget{method-getEstimatedCoef}{}}}
\subsection{Method \code{getEstimatedCoef()}}{
DEPRICATED use \verb{$getCoef()} instead.
Get the estimated coefficients.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$getEstimatedCoef()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{list(pars, offset)} with estimated coefficients/parameters and intercept/offset.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-getBaselearnerNames"></a>}}
\if{latex}{\out{\hypertarget{method-getBaselearnerNames}{}}}
\subsection{Method \code{getBaselearnerNames()}}{
Get the names of the registered base learners.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$getBaselearnerNames()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{charcter()} of base learner names.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-getLoggerData"></a>}}
\if{latex}{\out{\hypertarget{method-getLoggerData}{}}}
\subsection{Method \code{getLoggerData()}}{
Get the logged information.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$getLoggerData()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{data.frame} of logging information.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-calculateFeatureImportance"></a>}}
\if{latex}{\out{\hypertarget{method-calculateFeatureImportance}{}}}
\subsection{Method \code{calculateFeatureImportance()}}{
Calculate feature important based on the training risk. Note that early
stopping should be used to get adequate importance measures.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$calculateFeatureImportance(
  num_feats = NULL,
  aggregate_bl_by_feat = FALSE
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{num_feats}}{(\code{integer(1)})\cr
The number considered features, the \code{num_feats} most important feature names and
the respective value is returned. If \code{num_feats = NULL}, all features are considered.}

\item{\code{aggregate_bl_by_feat}}{(\code{logical(1)})\cr
Indicator whether the importance is aggregated based on feature level. For example,
adding components included two different base learners for the same feature. If
\code{aggregate_bl_by_feat == TRUE}, the importance of these two base learners is aggregated
instead of considering them individually.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Named \code{numeric()} vector of length \code{num_feats} (if at least \code{num_feats} were selected)
with importance values as elements.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-saveToJson"></a>}}
\if{latex}{\out{\hypertarget{method-saveToJson}{}}}
\subsection{Method \code{saveToJson()}}{
Save a \link{Compboost} object to a JSON file. Because of the underlying \code{C++} objects,
it is not possible to use \code{R}'s native load and save methods.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$saveToJson(file, rm_data = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{file}}{(\code{character(1)})\cr
Name/path to the file.}

\item{\code{rm_data}}{(\code{logical(1)})\cr
Remove all data from the model. This applies to the training data, response, as well as
the test data and response used for the test risk logging. Note: If data is removed, no
continuation of the training is possible after reloading. Also, everything related to
predictions based on the training data throws an error.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}

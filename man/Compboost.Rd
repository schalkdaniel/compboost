% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compboost.R
\name{Compboost}
\alias{Compboost}
\title{Component-wise boosting}
\description{
Component-wise boosting

Component-wise boosting
}
\details{
This class wraps the `S4` class system exposed by `Rcpp` to fit a component-wise
boosting model. The two convenient wrapper [boostLinear()] and [boostSplines()] are
also creating objects of this class.

Visualizing the internals see [plotBaselearnerTraces()], [plotBaselearner()], [plotFeatureImportance()],
[plotPEUni()], [plotTensor()], and [plotRisk()]. Visualizing the contribution for
one new observation see [plotIndividualContribution()].
}
\examples{
cboost = Compboost$new(mtcars, "mpg", loss = LossQuadratic$new(), oob_fraction = 0.3)
cboost$addBaselearner("hp", "spline", BaselearnerPSpline, degree = 3,
  n_knots = 10, df = 3, differences = 2)
cboost$addBaselearner("wt", "spline", BaselearnerPSpline)
cboost$train(1000)

table(cboost$getSelectedBaselearner())
head(cboost$logs)
names(cboost$baselearner_list)

# Access information about the a base learner in the list:
cboost$baselearner_list$hp_spline$factory$getDF()
cboost$baselearner_list$hp_spline$factory$getPenalty()
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{data}}{(`data.frame`)\cr
The data used for training the model. Note: If `oob_fraction` is set, the
input data is split into `data` and `data_oob`. Hence, `data` contains a
subset of the input data to train the model.}

\item{\code{data_oob}}{(`data.frame`)\cr
An out-of-bag data set used for risk logging or early stopping. `data_oob`
is split from the input data (see the `data` field).}

\item{\code{oob_fraction}}{(`numeric(1)`)\cr
The fraction of `nrow(input data)` defining the number of observations in
`data_oob`.}

\item{\code{response}}{([ResponseRegr] | [ResponseBinaryClassif])\cr
A `S4` response object. See `?ResponseRegr` or `?ResponseBinaryClassif` for help.
This object holds the current prediction, pseudo residuals and functions to
transform scores. Note: This response corresponds to the `data` field and holds
the predictions for that `data.frame`.}

\item{\code{response_oob}}{([ResponseRegr] | [ResponseBinaryClassif])\cr
A `S4` response object. See `?ResponseRegr` or `?ResponseBinaryClassif` for help.
Same as `response` but for `data_oob`.}

\item{\code{target}}{(`character(1)`)\cr
Name of the target variable in `data`.}

\item{\code{id}}{(`character(1)`)\cr
Name of the data object defined in `$new(data, ...)`.}

\item{\code{optimizer}}{([OptimizerCoordinateDescent] | [OptimizerCoordinateDescentLineSearch] | [OptimizerAGBM] | [OptimizerCosineAnnealing])\cr
An initialized `S4` optimizer object (requires to call `Optimizer*.new(..)`.
See the respective help page for further information.}

\item{\code{loss}}{([LossQuadratic] | [LossBinomial] | [LossHuber] | [LossAbsolute] | [LossQuantile])\cr
An initialized `S4` loss object (requires to call `Loss*$new(...)`).
See the respective help page for further information.}

\item{\code{learning_rate}}{(`numeric(1)`)\cr
The learning rate of the model. Note: Some optimizer do dynamically vary the learning rate.}

\item{\code{model}}{([Compboost_internal])\cr
The internal Compboost object exported from `Rcpp`. See `?Compboost_internal` for details.}

\item{\code{bl_factory_list}}{([BlearnerFactoryList)\cr
A container with all base learners. See `?BlearnerFactoryList` for details.}

\item{\code{positive}}{(`character(1)`)\cr
The positive class in the case of binary classification.}

\item{\code{stop_all}}{(`logical(1)`)\cr
Indicator whether all stopper must return `TRUE` to early stop the algorithm.
Comparable to `all()` if `stop_all = TRUE` and `any()` if `stop_all = FALSE`.}

\item{\code{early_stop}}{(`logical(1)`)\cr
Indicator whether early stopping is used or not.}
}
\if{html}{\out{</div>}}
}
\section{Active bindings}{
\if{html}{\out{<div class="r6-active-bindings">}}
\describe{
\item{\code{baselearner_list}}{(`list()`)\cr
Named `list` with names `$getBaselearnerNames()`. Each elements contains

* `"feature"` (`character(1)`): The name of the feature from `data`.
* `"factory"` (`Baselearner*`): The raw base learner as  `factory`object. See `?Baselearner*` for details.}

\item{\code{boost_intercept}}{(`logical(1)`)\cr
Logical value indicating whether an intercept base learner was added with `$addIntercept()` or not.}

\item{\code{logs}}{(`data.frame`)\cr
Basic information such as risk, selected base learner etc. about each iteration.
If `oob_data` is set, further information about the validation/oob risk is also logged.
The same applies for time logging etc. Note: Using the field `logs` internally is set and updated
after each call to `$getLoggerData()`. Hence, it cashes the logged data set instead of
recalculating the data set as it is done for `$getLoggerData()`.}

\item{\code{idx_oob}}{(`integer()`)\cr
An index vector used to split `data` into `data = data[idx_train, ]` and `data_oob = data[idx_oob, ]`.
Note: `oob_fraction` is ignored if this argument is set.}

\item{\code{idx_train}}{(`integer()`)\cr
An index vector used to split `data` into `data = data[idx_train, ]` and `data_oob = data[idx_oob, ]`.
Note: `oob_fraction` is ignored if this argument is set.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{Compboost$new()}}
\item \href{#method-addLogger}{\code{Compboost$addLogger()}}
\item \href{#method-getCurrentIteration}{\code{Compboost$getCurrentIteration()}}
\item \href{#method-addIntercept}{\code{Compboost$addIntercept()}}
\item \href{#method-addBaselearner}{\code{Compboost$addBaselearner()}}
\item \href{#method-rmBaselearner}{\code{Compboost$rmBaselearner()}}
\item \href{#method-addTensor}{\code{Compboost$addTensor()}}
\item \href{#method-addComponents}{\code{Compboost$addComponents()}}
\item \href{#method-extractComponents}{\code{Compboost$extractComponents()}}
\item \href{#method-train}{\code{Compboost$train()}}
\item \href{#method-prepareData}{\code{Compboost$prepareData()}}
\item \href{#method-prepareResponse}{\code{Compboost$prepareResponse()}}
\item \href{#method-predict}{\code{Compboost$predict()}}
\item \href{#method-predictIndividual}{\code{Compboost$predictIndividual()}}
\item \href{#method-transformData}{\code{Compboost$transformData()}}
\item \href{#method-getInbagRisk}{\code{Compboost$getInbagRisk()}}
\item \href{#method-getSelectedBaselearner}{\code{Compboost$getSelectedBaselearner()}}
\item \href{#method-print}{\code{Compboost$print()}}
\item \href{#method-getCoef}{\code{Compboost$getCoef()}}
\item \href{#method-getEstimatedCoef}{\code{Compboost$getEstimatedCoef()}}
\item \href{#method-getBaselearnerNames}{\code{Compboost$getBaselearnerNames()}}
\item \href{#method-getLoggerData}{\code{Compboost$getLoggerData()}}
\item \href{#method-calculateFeatureImportance}{\code{Compboost$calculateFeatureImportance()}}
\item \href{#method-clone}{\code{Compboost$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Creates a new instance of this [R6][R6::R6Class] class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$new(
  data = NULL,
  target = NULL,
  optimizer = NULL,
  loss = NULL,
  learning_rate = 0.05,
  positive = NULL,
  oob_fraction = NULL,
  early_stop = FALSE,
  idx_oob = NULL,
  stop_args = list(eps_for_break = 0, patience = 10L),
  file = NULL
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{data}}{(`data.frame`)\cr
The data set to build the object. Note: This data set is completely used for training if `is.null(idx_oob)`.
Otherwise, the data set is split into `data = data[idx_train, ]` and `data_oob = data[idx_oob, ]`.}

\item{\code{target}}{(`character(1)`)\cr
Character indicating the name of the target variable.}

\item{\code{optimizer}}{([OptimizerCoordinateDescent] | [OptimizerCoordinateDescentLineSearch] | [OptimizerAGBM] | [OptimizerCosineAnnealing])\cr
An initialized `S4` optimizer object (requires to call `Optimizer*.new(..)`.
See the respective help page for further information.}

\item{\code{loss}}{([LossQuadratic] | [LossBinomial] | [LossHuber] | [LossAbsolute] | [LossQuantile])\cr
An initialized `S4` loss object (requires to call `Loss*$new(...)`).
See the respective help page for further information.}

\item{\code{learning_rate}}{(`numeric(1)`)\cr
Learning rate of the model (default is `0.05`).}

\item{\code{positive}}{(`character(1)`)\cr
The name of the positive class (in the case of binary classification).}

\item{\code{oob_fraction}}{(`numeric(1)`)\cr
The fraction of `nrow(input data)` defining the number of observations in
`data_oob`. This argument is ignored if `idx_oob` is set.}

\item{\code{early_stop}}{(`logical(1)`)\cr
Indicator whether early stopping should be used or not.}

\item{\code{idx_oob}}{(`integer()`)\cr
An index vector used to split `data` into `data = data[idx_train, ]` and `data_oob = data[idx_oob, ]`.
Note: `oob_fraction` is ignored if this argument is set.}

\item{\code{stop_args}}{(`list(integer(1), integer(1))`)\cr
`list` containing two elements `patience` and `eps_for_break` which are used for early stopping.}

\item{\code{file}}{(`character(1`)\cr
File from which a model should be loaded. If `NULL`, `data` and `target` must be defined.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-addLogger"></a>}}
\if{latex}{\out{\hypertarget{method-addLogger}{}}}
\subsection{Method \code{addLogger()}}{
Add a logger to the model.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$addLogger(logger, use_as_stopper = FALSE, logger_id, ...)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{logger}}{([LoggerIteration] | [LoggerTime] | [LoggerInbagRisk] | [LoggerOobRisk])\cr
The uninitialized logger.}

\item{\code{use_as_stopper}}{(`logical(1)`)\cr
Indicator defining the logger as stopper considering it for early stopping.}

\item{\code{logger_id}}{(`character(1)`)\cr
The id of the logger. This allows to define two logger of the same type (`e.g. risk logging`) but with different arguments.}

\item{\code{...}}{\cr
Additional arguments passed to `loger$new(logger_id, use_as_stopper, ...)`.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-getCurrentIteration"></a>}}
\if{latex}{\out{\hypertarget{method-getCurrentIteration}{}}}
\subsection{Method \code{getCurrentIteration()}}{
Get the number of the current iteration.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$getCurrentIteration()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
`integer(1)` value.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-addIntercept"></a>}}
\if{latex}{\out{\hypertarget{method-addIntercept}{}}}
\subsection{Method \code{addIntercept()}}{
This functions adds a base learner that adjusts the intercept (if selected).
Adding an intercept base learner may be necessary, e.g., when adding linear effects
without intercept.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$addIntercept(id = "intercept", data_source = InMemoryData)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{id}}{(`character(1)`)\cr
The id of the base learner (default is `"intercept"`).}

\item{\code{data_source}}{([InMemoryData])\cr
Uninitialized data object used to store the meta data. Note: At the moment, just in memory
storing is supported, see `?InMemorydata` for details.}

\item{\code{data_source}}{([InMemoryData])\cr
Uninitialized data object used to store the meta data. Note: At the moment, just in memory
storing is supported, see `?InMemorydata` for details.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-addBaselearner"></a>}}
\if{latex}{\out{\hypertarget{method-addBaselearner}{}}}
\subsection{Method \code{addBaselearner()}}{
Add a base learner of one feature to the model that is considered in each iteration.
Using `$addBaselearner()` just allows including univariate features. See `$addTensor()` for
bivariate effect modelling and `$addComponents()` for an effect decomposition.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$addBaselearner(
  feature,
  id,
  bl_factory,
  data_source = InMemoryData,
  ...
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{feature}}{(`character(1)`)\cr
Name of the feature, must be a column in `data`.}

\item{\code{feature}}{(`character(1)`)\cr
Name of the feature, must be a column in `data`.}

\item{\code{id}}{(`character(1)`)\cr
The name of the base learner.}

\item{\code{bl_factory}}{([BaselearnerPolynomial] | [BaselearnerPSpline] | [BaselearnerCategoricalBinary] | [BaselearnerCategoricalRidge])\cr
Uninitialized base learner class. See the respective help page for details.}

\item{\code{data_source}}{([InMemoryData])\cr
Uninitialized data object used to store the meta data. Note: At the moment, just in memory
storing is supported, see `?InMemorydata` for details.}

\item{\code{data_source}}{([InMemoryData])\cr
Uninitialized data object used to store the meta data. Note: At the moment, just in memory
storing is supported, see `?InMemorydata` for details.}

\item{\code{...}}{\cr
Further argument spassed to the `$new(...)` constructor of `bl_factory`.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-rmBaselearner"></a>}}
\if{latex}{\out{\hypertarget{method-rmBaselearner}{}}}
\subsection{Method \code{rmBaselearner()}}{
Remove a base learner from the model.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$rmBaselearner(blname)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{blname}}{(`character(1)`)\cr
Name of the base learner that should be removed. Must be an element of `$getBaselearnerNames()`.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-addTensor"></a>}}
\if{latex}{\out{\hypertarget{method-addTensor}{}}}
\subsection{Method \code{addTensor()}}{
Add a row-wise tensor product of features. Note: The base learner are pre-defined
by the type of the feature. Numerical features uses a `BaselearnerPSpline` while categorical
features are included using a `BaselearnerCategoricalRidge` base learner.
To include an arbitrary tensor product requires to use the `S4` API with using
`BaselearnerTensor` on two base learners of any type.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$addTensor(
  feature1,
  feature2,
  df1 = NULL,
  df2 = NULL,
  isotrop = FALSE,
  ...
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{feature1}}{(`character(1)`)\cr
Name of the first feature. Must be an element of `names(data)`.}

\item{\code{feature2}}{(`character(1)`)\cr
Name of the second feature. Must be an element of `names(data)`.}

\item{\code{df1}}{(`numeric(1)`)\cr
The degrees of freedom used for the first base learner.}

\item{\code{df2}}{(`numeric(1)`)\cr
The degrees of freedom used for the first base learner.}

\item{\code{isotrop}}{(`logical(1)`)\cr
Indicator how the two penalties should be combined, if `isotrop == TRUE`,
the total degrees of freedom are uniformly distributed over the dimensions while
`isotrop == FALSE` allows to define how strong each of the two dimensions is penalized.}

\item{\code{...}}{\cr
Additional arguments passed to the `$new()` constructor of the [BaselearnerPSpline] class.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-addComponents"></a>}}
\if{latex}{\out{\hypertarget{method-addComponents}{}}}
\subsection{Method \code{addComponents()}}{
Add an effect with individual components. A linear term is added as well as
a non-linear term without the linear effect. This ensures that the linear
component is selected prior to the non-linear effect. The non-linear effect
is only included if a deviation from a linear effect is required.

Note: Internally, a [BaselearnerPolynomial] with degree one and a [BaselearnerCentered] is added.
Centering a base learner makes the design matrix dense and hence memory is filled very fast.
Considering binning may be an option to reduce the memory consumption.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$addComponents(feature, ...)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{feature}}{(`character(1)`)\cr
Name of the feature, must be a column in `data`.}

\item{\code{feature}}{(`character(1)`)\cr
Name of the feature, must be a column in `data`.}

\item{\code{...}}{\cr
Additional arguments passed to the `$new()` constructor of the [BaselearnerPSpline] class.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-extractComponents"></a>}}
\if{latex}{\out{\hypertarget{method-extractComponents}{}}}
\subsection{Method \code{extractComponents()}}{
This function extracts all information from components added with `$addComponents()`
that defines a model. The result is an `S3` object of class
`compboostExtract` that can be used for very basic operations such as
predicting.

Note: At the moment it is not possible to save the whole [Compboost] object
and reuse it later. Using `$extractComponents()` gives the opportunity to
"save" the minimal amount of data that defines the model.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$extractComponents()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
`list` with all components.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-train"></a>}}
\if{latex}{\out{\hypertarget{method-train}{}}}
\subsection{Method \code{train()}}{
Start fitting a model.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$train(iteration = 100, trace = -1)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{iteration}}{(`integer(1)`)\cr
The maximal number of iteration. The algorithm can be stopped earlier
if early stopping is active.}

\item{\code{trace}}{(`integer(1)`)\cr
The number of integers after which the status of the fitting is printed to the screen.
The default `trace = -1` internally uses `trace = round(iteration / 40)`.
To silently fit the model use `trace = 0`.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-prepareData"></a>}}
\if{latex}{\out{\hypertarget{method-prepareData}{}}}
\subsection{Method \code{prepareData()}}{
Internally, each base learner is build on a [InMemoryData] object. Some
methods (e.g. adding a [LoggerOobRisk]) requires to pass the data as
`list(InMemoryData | CategoricalDataRaw)` with data objects as elements.
This function converts the given `data.frame` into that format.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$prepareData(newdata)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}

\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}

\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}

\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
`list(InMemoryData | CategoricalDataRaw)` with data container as elements.
Numeric features are wrapped by [InMemoryData] while categorical features
are included with [CategoricalDataRaw].
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-prepareResponse"></a>}}
\if{latex}{\out{\hypertarget{method-prepareResponse}{}}}
\subsection{Method \code{prepareResponse()}}{
Same as for `$prepareData()` but for the response. Internally, `vectorToResponse()` is
used to generate a [ResponseRegr] or [ResponseBinaryClassif] object.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$prepareResponse(response)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{response}}{(`vector()`)\cr
A vector of type `numberic` or `categorical` that is transformed to an
response object.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
[ResponseRegr] | [ResponseBinaryClassif] object.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-predict"></a>}}
\if{latex}{\out{\hypertarget{method-predict}{}}}
\subsection{Method \code{predict()}}{
Calculate predictions.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$predict(newdata = NULL, as_response = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}

\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}

\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}

\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}

\item{\code{as_response}}{(`logical(1)`)\cr
In the case of binary classification, `as_response = TRUE` returns predictions as
response, i.e. classes.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Vector of predictions.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-predictIndividual"></a>}}
\if{latex}{\out{\hypertarget{method-predictIndividual}{}}}
\subsection{Method \code{predictIndividual()}}{
While `$predict()` returns the sum of all base learner predictions, this function
returns a `list` with the predictions for each base learner.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$predictIndividual(newdata)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}

\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}

\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}

\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Named `list()` with the included base learner names as names and the base learner
predictions as elements.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-transformData"></a>}}
\if{latex}{\out{\hypertarget{method-transformData}{}}}
\subsection{Method \code{transformData()}}{
Get design matrices of all (or a subset) base learners for a new `data.frame`.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$transformData(newdata, blnames = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}

\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}

\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}

\item{\code{newdata}}{(`data.frame`)\cr
New data set of the same structure as `data`.}

\item{\code{blnames}}{(`character()`)\cr
Names of the base learners for which the design matrices are returned. If
`is.null(blnames)`, compboost tries to guess all base learners that were
constructed based on the feature names of `newdata`.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
`list(matrix | Matrix::Matrix)` matrices as elements.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-getInbagRisk"></a>}}
\if{latex}{\out{\hypertarget{method-getInbagRisk}{}}}
\subsection{Method \code{getInbagRisk()}}{
Return the training risk of each iteration.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$getInbagRisk()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
`numeric()` vector of risk values or `NULL` if `$train()` was not called previously.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-getSelectedBaselearner"></a>}}
\if{latex}{\out{\hypertarget{method-getSelectedBaselearner}{}}}
\subsection{Method \code{getSelectedBaselearner()}}{
Get a vector with the name of the selected base learner of each iteration.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$getSelectedBaselearner()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
`character()` vector of base learner names.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-print"></a>}}
\if{latex}{\out{\hypertarget{method-print}{}}}
\subsection{Method \code{print()}}{
Printer of the object.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$print()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
Invisibly returns the object.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-getCoef"></a>}}
\if{latex}{\out{\hypertarget{method-getCoef}{}}}
\subsection{Method \code{getCoef()}}{
Get the estimated coefficients.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$getCoef()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
`list(pars, offset)` with estimated coefficients/parameters and intercept/offset.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-getEstimatedCoef"></a>}}
\if{latex}{\out{\hypertarget{method-getEstimatedCoef}{}}}
\subsection{Method \code{getEstimatedCoef()}}{
DEPRICATED use `$getCoef()` instead.
Get the estimated coefficients.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$getEstimatedCoef()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
`list(pars, offset)` with estimated coefficients/parameters and intercept/offset.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-getBaselearnerNames"></a>}}
\if{latex}{\out{\hypertarget{method-getBaselearnerNames}{}}}
\subsection{Method \code{getBaselearnerNames()}}{
Get the names of the registered base learners.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$getBaselearnerNames()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
`charcter()` of base learner names.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-getLoggerData"></a>}}
\if{latex}{\out{\hypertarget{method-getLoggerData}{}}}
\subsection{Method \code{getLoggerData()}}{
Get the logged information.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$getLoggerData()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
`data.frame` of logging information.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-calculateFeatureImportance"></a>}}
\if{latex}{\out{\hypertarget{method-calculateFeatureImportance}{}}}
\subsection{Method \code{calculateFeatureImportance()}}{
Calculate feature important based on the training risk. Note that early
stopping should be used to get adequate importance measures.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$calculateFeatureImportance(
  num_feats = NULL,
  aggregate_bl_by_feat = FALSE
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{num_feats}}{(`integer(1)`)\cr
The number considered features, the `num_feats` most important feature names and
the respective value is returned.}

\item{\code{aggregate_bl_by_feat}}{(`logical(1)`)\cr
Indicator whether the importance is aggregated based on feature level. For example,
adding components included two different base learners for the same feature. If
`aggregate_bl_by_feat == TRUE`, the importance of these two base learners is aggregated
instead of considering them individually.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Named `numeric()` vector of length `num_feats` (if at least `num_feats` were selected)
with importance values as elements.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Compboost$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}

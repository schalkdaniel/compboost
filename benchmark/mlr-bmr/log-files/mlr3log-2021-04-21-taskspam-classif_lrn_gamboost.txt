INFO  [22:15:35.432] [mlr3]  Running benchmark with 5 resampling iterations 
INFO  [22:15:35.540] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost.tuned' on task 'spam' (iter 4/5) 
INFO  [22:15:35.645] [bbotk] Starting to optimize 3 parameter(s) with '<OptimizerInterMBO>' and '<TerminatorEvals> [n_evals=150]' 
DEBUG [22:15:36.588] [bbotk]  
INFO  [22:15:36.607] [bbotk] Evaluating 24 configuration(s) 
INFO  [22:15:37.518] [mlr3]  Running benchmark with 72 resampling iterations 
INFO  [22:15:37.526] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:15:38.835] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:15:40.760] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:15:58.240] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:16:14.603] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:16:38.191] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:16:39.577] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:17:11.305] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:17:39.763] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:17:40.897] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:18:43.076] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:19:44.719] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:20:30.154] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:21:25.319] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:22:08.178] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:22:52.496] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:22:53.214] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:23:19.966] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:23:24.689] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:23:25.428] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:24:10.618] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:24:33.558] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:24:40.361] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:24:41.333] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:25:24.238] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:25:31.424] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:25:53.509] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:26:48.418] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:26:49.162] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:27:01.918] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:27:14.453] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:27:15.166] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:27:15.976] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:27:16.700] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:28:11.260] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:29:09.286] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:29:10.019] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:29:10.730] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:29:53.912] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:30:30.714] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:31:07.416] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:31:41.146] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:32:18.012] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:32:19.108] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:33:00.026] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:33:00.983] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:33:01.689] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:33:16.818] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:34:18.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:34:55.046] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:35:24.787] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:35:29.384] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:36:07.501] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:36:21.282] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:36:58.018] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:37:39.174] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:37:40.048] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:38:38.245] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:38:39.468] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:38:43.921] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:38:44.707] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:38:58.062] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:38:59.290] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:39:26.116] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:39:49.921] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:40:03.458] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:40:33.467] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:40:46.289] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:40:47.259] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:41:11.221] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:41:45.345] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:42:19.730] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:42:43.231] [mlr3]  Finished benchmark 
INFO  [22:42:44.384] [bbotk] Result of batch 1: 
INFO  [22:42:44.388] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu classif.auc 
INFO  [22:42:44.388] [bbotk]                   4              2755     0.42810484   0.9762241 
INFO  [22:42:44.388] [bbotk]                   3              3682     0.20870807   0.9766624 
INFO  [22:42:44.388] [bbotk]                   6              2430     0.41460919   0.9751174 
INFO  [22:42:44.388] [bbotk]                   9              1470     0.25919580   0.5000000 
INFO  [22:42:44.388] [bbotk]                   5              1895     0.34114199   0.9764574 
INFO  [22:42:44.388] [bbotk]                   8              4715     0.16094838   0.8184373 
INFO  [22:42:44.388] [bbotk]                   8              3313     0.28944866   0.8179976 
INFO  [22:42:44.388] [bbotk]                   7              1793     0.02946754   0.9746078 
INFO  [22:42:44.388] [bbotk]                   7              1041     0.18244542   0.9765043 
INFO  [22:42:44.388] [bbotk]                   9              4345     0.48917294   0.5000000 
INFO  [22:42:44.388] [bbotk]                  10              3814     0.13680996   0.5000000 
INFO  [22:42:44.388] [bbotk]                   3              3033     0.37313743   0.9767238 
INFO  [22:42:44.388] [bbotk]                   4              4486     0.24130717   0.9763204 
INFO  [22:42:44.388] [bbotk]                  10              2192     0.37638721   0.5000000 
INFO  [22:42:44.388] [bbotk]                   8               470     0.32164923   0.8196277 
INFO  [22:42:44.388] [bbotk]                   3              1218     0.04604161   0.9701529 
INFO  [22:42:44.388] [bbotk]                   7              2984     0.08557116   0.9764866 
INFO  [22:42:44.388] [bbotk]                   5              3525     0.44614464   0.9754016 
INFO  [22:42:44.388] [bbotk]                  10               642     0.11325119   0.5000000 
INFO  [22:42:44.388] [bbotk]                   4              2208     0.20907193   0.9768031 
INFO  [22:42:44.388] [bbotk]                   9              4131     0.29936130   0.5000000 
INFO  [22:42:44.388] [bbotk]                   6               295     0.01337088   0.9581518 
INFO  [22:42:44.388] [bbotk]                   6               950     0.47843437   0.9762471 
INFO  [22:42:44.388] [bbotk]                   5              4986     0.07558126   0.9770807 
INFO  [22:42:44.388] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu classif.auc 
INFO  [22:42:44.388] [bbotk]                                 uhash 
INFO  [22:42:44.388] [bbotk]  8162dea3-7bd5-4321-8ba1-3172b6d2f80c 
INFO  [22:42:44.388] [bbotk]  ca00d750-9ea7-479f-8a4a-5d3ad486d2d5 
INFO  [22:42:44.388] [bbotk]  4afeadde-4b1e-4736-9d43-de4a2b4f44a7 
INFO  [22:42:44.388] [bbotk]  eb7757d8-cbfc-4261-babf-b4e771073b71 
INFO  [22:42:44.388] [bbotk]  f9eae173-aa44-4d5b-84fc-02c7ddb23ce1 
INFO  [22:42:44.388] [bbotk]  4d2945b0-67a4-4155-985a-61f375fe4449 
INFO  [22:42:44.388] [bbotk]  7aae14a9-0106-4281-866b-c3f5a5cc32a4 
INFO  [22:42:44.388] [bbotk]  220a097d-88eb-4764-a96b-4b7d078663ce 
INFO  [22:42:44.388] [bbotk]  8b819782-7d28-4293-8fcb-69d738be28a9 
INFO  [22:42:44.388] [bbotk]  8a707e76-2198-4e9b-8361-2b5201956e64 
INFO  [22:42:44.388] [bbotk]  b42a32fc-17e8-4452-bf56-b6e81488874c 
INFO  [22:42:44.388] [bbotk]  d7af48c3-ce3c-4f01-a335-7cdd32979c48 
INFO  [22:42:44.388] [bbotk]  80cbb721-2ac9-47e4-829e-185b953670c4 
INFO  [22:42:44.388] [bbotk]  bbd337d6-6070-4b54-a466-1097d0cf0fa7 
INFO  [22:42:44.388] [bbotk]  fc3cfd17-17d4-46e2-83b3-5e14ccf5ea52 
INFO  [22:42:44.388] [bbotk]  f62b5979-a2bb-42c2-8a5e-607832b199fd 
INFO  [22:42:44.388] [bbotk]  080da2c4-5981-4733-a2c9-26b0a8c8e5fa 
INFO  [22:42:44.388] [bbotk]  d1e8320c-e5ed-46a2-be13-e1924e431e37 
INFO  [22:42:44.388] [bbotk]  32b06a08-7c52-47c9-a908-32c9d5e5726a 
INFO  [22:42:44.388] [bbotk]  5d9a7a3c-355c-4ecb-81c1-19bb0355a5eb 
INFO  [22:42:44.388] [bbotk]  f940fd02-6326-4881-8cc0-8a143fe0e75f 
INFO  [22:42:44.388] [bbotk]  5c3da127-d1e3-44e1-b962-d851d3ffac49 
INFO  [22:42:44.388] [bbotk]  f1c9a372-09bb-4d6a-af34-b009d5a92c29 
INFO  [22:42:44.388] [bbotk]  8c58c73f-4487-4fef-ae91-8050e2bf2926 
INFO  [22:42:44.388] [bbotk]                                 uhash 
DEBUG [22:42:46.134] [bbotk]  
DEBUG [22:42:46.137] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.203194e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.003981476 0.4203194 
  - best initial criterion value(s) :  29.74066 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -29.741  |proj g|=       3.0176
At iterate     1  f =      -33.818  |proj g|=        1.8361
At iterate     2  f =      -34.591  |proj g|=        2.6453
At iterate     3  f =      -35.015  |proj g|=        2.3812
At iterate     4  f =      -35.354  |proj g|=       0.92873
At iterate     5  f =      -38.445  |proj g|=      0.022967
At iterate     6  f =      -38.445  |proj g|=       0.40798
At iterate     7  f =      -38.445  |proj g|=      0.008361
At iterate     8  f =      -38.445  |proj g|=     0.0014844
At iterate     9  f =      -38.445  |proj g|=     0.0067769

iterations 9
function evaluations 16
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0067769
final function value -38.4454

F = -38.4454
final  value -38.445443 
converged
 
INFO  [22:42:46.141] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:42:46.192] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:42:46.199] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:43:24.431] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:44:03.242] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:44:42.086] [mlr3]  Finished benchmark 
INFO  [22:44:42.150] [bbotk] Result of batch 2: 
INFO  [22:44:42.152] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [22:44:42.152] [bbotk]                   5              3141      0.2244009        0.548 -0.9235384 
INFO  [22:44:42.152] [bbotk]  errors.model classif.auc                                uhash 
INFO  [22:44:42.152] [bbotk]          <NA>   0.9763424 df96997f-9990-4c9b-86ca-4afa283d54ca 
DEBUG [22:44:43.047] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.106331e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.003906583 0.4106331 
  - best initial criterion value(s) :  31.97853 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -31.979  |proj g|=       2.1073
At iterate     1  f =      -34.511  |proj g|=         2.076
At iterate     2  f =      -35.157  |proj g|=        2.5092
At iterate     3  f =      -35.614  |proj g|=        2.1756
At iterate     4  f =       -35.75  |proj g|=       0.33802
At iterate     5  f =      -35.876  |proj g|=        1.0314
At iterate     6  f =      -35.896  |proj g|=        1.1123
At iterate     7  f =      -35.922  |proj g|=        1.0746
At iterate     8  f =      -36.079  |proj g|=       0.86356
At iterate     9  f =      -36.386  |proj g|=       0.53883
At iterate    10  f =      -37.429  |proj g|=       0.40088
At iterate    11  f =      -37.739  |proj g|=       0.99955
At iterate    12  f =      -37.799  |proj g|=       0.74418
At iterate    13  f =      -37.846  |proj g|=       0.14301
At iterate    14  f =      -37.848  |proj g|=       0.39813
At iterate    15  f =      -37.848  |proj g|=       0.39812
At iterate    16  f =      -37.848  |proj g|=      0.066216
At iterate    17  f =      -37.848  |proj g|=     0.0024743

iterations 17
function evaluations 21
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0024743
final function value -37.8478

F = -37.8478
final  value -37.847766 
converged
 
INFO  [22:44:43.051] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:44:43.104] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:44:43.110] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:44:44.078] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:44:44.781] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:44:45.844] [mlr3]  Finished benchmark 
INFO  [22:44:45.906] [bbotk] Result of batch 3: 
INFO  [22:44:45.907] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [22:44:45.907] [bbotk]                   9               636      0.2478146        0.539 -0.9260725 
INFO  [22:44:45.907] [bbotk]  errors.model classif.auc                                uhash 
INFO  [22:44:45.907] [bbotk]          <NA>         0.5 2ed1c7c0-146e-4f3d-ba62-6b657c291187 
DEBUG [22:44:46.686] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.392081e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.004309744 0.4392081 
  - best initial criterion value(s) :  43.6887 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -43.689  |proj g|=       3.0734
At iterate     1  f =      -43.722  |proj g|=        2.4716
At iterate     2  f =      -43.856  |proj g|=         3.036
At iterate     3  f =       -43.95  |proj g|=         3.027
At iterate     4  f =      -44.082  |proj g|=        2.9951
At iterate     5  f =      -44.682  |proj g|=        2.6441
At iterate     6  f =      -45.901  |proj g|=        2.5404
At iterate     7  f =      -46.461  |proj g|=        2.4104
At iterate     8  f =       -46.52  |proj g|=        2.3922
At iterate     9  f =      -46.739  |proj g|=        1.6372
At iterate    10  f =      -46.903  |proj g|=       0.87578
At iterate    11  f =        -47.2  |proj g|=       0.30038
At iterate    12  f =      -47.428  |proj g|=       0.83827
At iterate    13  f =       -47.47  |proj g|=      0.091642
At iterate    14  f =      -47.474  |proj g|=      0.041429
At iterate    15  f =      -47.474  |proj g|=        0.1624
At iterate    16  f =      -47.474  |proj g|=     0.0072714
At iterate    17  f =      -47.474  |proj g|=     0.0013112

iterations 17
function evaluations 21
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00131119
final function value -47.4737

F = -47.4737
final  value -47.473744 
converged
 
INFO  [22:44:46.690] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:44:46.752] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:44:46.758] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:45:12.368] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:45:38.109] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:46:03.980] [mlr3]  Finished benchmark 
INFO  [22:46:04.043] [bbotk] Result of batch 4: 
INFO  [22:46:04.045] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [22:46:04.045] [bbotk]                   6              2047     0.09709126        0.541 -0.9188867 
INFO  [22:46:04.045] [bbotk]  errors.model classif.auc                                uhash 
INFO  [22:46:04.045] [bbotk]          <NA>    0.976812 253b6689-71f1-4fa2-8e36-e2f4128a6ee7 
DEBUG [22:46:04.834] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.304187e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.004263782 0.4304187 
  - best initial criterion value(s) :  34.71578 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -34.716  |proj g|=       5.5694
At iterate     1  f =      -36.189  |proj g|=         0.843
At iterate     2  f =      -39.427  |proj g|=        1.9711
At iterate     3  f =      -41.222  |proj g|=        3.5432
At iterate     4  f =      -42.195  |proj g|=        4.2844
At iterate     5  f =      -44.426  |proj g|=        3.7958
At iterate     6  f =      -45.748  |proj g|=        3.5217
At iterate     7  f =        -47.4  |proj g|=        1.5568
At iterate     8  f =      -50.304  |proj g|=        2.9958
At iterate     9  f =      -50.666  |proj g|=        2.6134
At iterate    10  f =      -51.031  |proj g|=       0.41926
At iterate    11  f =      -51.031  |proj g|=     0.0095515
At iterate    12  f =      -51.031  |proj g|=      0.006934
At iterate    13  f =      -51.031  |proj g|=     0.0013116

iterations 13
function evaluations 21
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00131159
final function value -51.0312

F = -51.0312
final  value -51.031221 
converged
 
INFO  [22:46:04.838] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:46:04.890] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:46:04.897] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:46:05.616] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:46:06.580] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:46:07.310] [mlr3]  Finished benchmark 
INFO  [22:46:07.375] [bbotk] Result of batch 5: 
INFO  [22:46:07.377] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [22:46:07.377] [bbotk]                  10              1455     0.03649582         0.56 -0.9155387 
INFO  [22:46:07.377] [bbotk]  errors.model classif.auc                                uhash 
INFO  [22:46:07.377] [bbotk]          <NA>         0.5 c52f7027-e1fa-4b31-872e-7539c11ee2de 
DEBUG [22:46:08.210] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.544085e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.004421871 0.4544085 
  - best initial criterion value(s) :  34.74059 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -34.741  |proj g|=      0.97457
At iterate     1  f =      -42.059  |proj g|=        2.8783
At iterate     2  f =      -44.392  |proj g|=        3.1883
At iterate     3  f =       -46.91  |proj g|=        2.8661
At iterate     4  f =      -47.808  |proj g|=        2.8603
At iterate     5  f =      -47.828  |proj g|=        2.8569
At iterate     6  f =      -47.878  |proj g|=        2.8415
At iterate     7  f =      -47.916  |proj g|=        2.8241
At iterate     8  f =      -47.999  |proj g|=        2.7823
At iterate     9  f =      -48.175  |proj g|=        2.1058
At iterate    10  f =      -48.584  |proj g|=        1.0136
At iterate    11  f =      -49.577  |proj g|=       0.88261
At iterate    12  f =      -50.323  |proj g|=        1.8064
At iterate    13  f =      -50.593  |proj g|=        1.3456
At iterate    14  f =      -50.682  |proj g|=       0.44345
At iterate    15  f =      -50.686  |proj g|=     0.0085629
At iterate    16  f =      -50.686  |proj g|=       0.44338
At iterate    17  f =      -50.686  |proj g|=      0.014682
At iterate    18  f =      -50.686  |proj g|=     0.0020023

iterations 18
function evaluations 23
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00200234
final function value -50.6861

F = -50.6861
final  value -50.686136 
converged
 
INFO  [22:46:08.214] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:46:08.276] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:46:08.284] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:46:23.960] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:46:39.725] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:46:55.859] [mlr3]  Finished benchmark 
INFO  [22:46:55.923] [bbotk] Result of batch 6: 
INFO  [22:46:55.925] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [22:46:55.925] [bbotk]                   7              1225      0.2073948        0.594 -0.9150609 
INFO  [22:46:55.925] [bbotk]  errors.model classif.auc                                uhash 
INFO  [22:46:55.925] [bbotk]          <NA>    0.976482 061eba8d-6572-4947-addb-061baa1d961f 
DEBUG [22:46:56.900] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.463626e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.004297014 0.4463626 
  - best initial criterion value(s) :  39.78389 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -39.784  |proj g|=       2.3122
At iterate     1  f =      -45.296  |proj g|=        1.7907
At iterate     2  f =      -46.254  |proj g|=        3.1693
At iterate     3  f =      -46.546  |proj g|=        3.0102
At iterate     4  f =      -46.969  |proj g|=        2.5252
At iterate     5  f =      -47.212  |proj g|=        2.2768
At iterate     6  f =      -47.282  |proj g|=        2.3658
At iterate     7  f =      -47.302  |proj g|=        2.3434
At iterate     8  f =      -47.334  |proj g|=        2.3334
At iterate     9  f =      -47.485  |proj g|=        2.3015
At iterate    10  f =      -47.806  |proj g|=        2.2587
At iterate    11  f =      -48.939  |proj g|=        2.1891
At iterate    12  f =      -51.837  |proj g|=        2.1188
At iterate    13  f =      -53.322  |proj g|=        2.0755
At iterate    14  f =      -53.455  |proj g|=        2.0471
At iterate    15  f =      -53.554  |proj g|=        1.3494
At iterate    16  f =      -53.604  |proj g|=       0.79613
At iterate    17  f =      -53.655  |proj g|=       0.24925
At iterate    18  f =      -53.717  |proj g|=       0.26098
At iterate    19  f =      -53.761  |proj g|=       0.43564
At iterate    20  f =       -53.77  |proj g|=      0.054034
At iterate    21  f =       -53.77  |proj g|=     0.0065545
At iterate    22  f =       -53.77  |proj g|=      0.037879
At iterate    23  f =       -53.77  |proj g|=     0.0024075

iterations 23
function evaluations 28
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00240749
final function value -53.7701

F = -53.7701
final  value -53.770078 
converged
 
INFO  [22:46:56.903] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:46:56.953] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:46:56.959] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:47:21.419] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:47:46.091] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:48:10.319] [mlr3]  Finished benchmark 
INFO  [22:48:10.383] [bbotk] Result of batch 7: 
INFO  [22:48:10.385] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [22:48:10.385] [bbotk]                   4              1949      0.2439789        0.729 -0.9141029 
INFO  [22:48:10.385] [bbotk]  errors.model classif.auc                                uhash 
INFO  [22:48:10.385] [bbotk]          <NA>   0.9767855 23f87820-59da-4bd1-a6d5-ab2fed8a9fa8 
DEBUG [22:48:10.980] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.38375e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.004304695 0.438375 
  - best initial criterion value(s) :  41.22886 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -41.229  |proj g|=       5.2864
At iterate     1  f =      -42.687  |proj g|=        1.9722
At iterate     2  f =      -48.287  |proj g|=         3.554
At iterate     3  f =      -48.687  |proj g|=        4.8011
At iterate     4  f =      -50.207  |proj g|=        4.5037
ys=-2.187e-02  -gs= 1.510e+00, BFGS update SKIPPED
At iterate     5  f =      -51.765  |proj g|=        3.6757
At iterate     6  f =      -60.673  |proj g|=       0.84296
At iterate     7  f =      -60.787  |proj g|=       0.42855
At iterate     8  f =      -60.798  |proj g|=       0.42829
At iterate     9  f =      -60.799  |proj g|=      0.043254
At iterate    10  f =        -60.8  |proj g|=     0.0059054
At iterate    11  f =        -60.8  |proj g|=     0.0019549

iterations 11
function evaluations 20
segments explored during Cauchy searches 15
BFGS updates skipped 1
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00195485
final function value -60.7997

F = -60.7997
final  value -60.799659 
converged
 
INFO  [22:48:10.984] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:48:11.039] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:48:11.046] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:48:11.789] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:48:12.533] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:48:13.499] [mlr3]  Finished benchmark 
INFO  [22:48:13.566] [bbotk] Result of batch 8: 
INFO  [22:48:13.567] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [22:48:13.567] [bbotk]                  10               593     0.04092589        0.415 -0.909808 
INFO  [22:48:13.567] [bbotk]  errors.model classif.auc                                uhash 
INFO  [22:48:13.567] [bbotk]          <NA>         0.5 ac543b03-2ee7-43e3-879d-a1568a57decb 
DEBUG [22:48:14.155] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.594718e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.004509984 0.4594718 
  - best initial criterion value(s) :  55.30589 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -55.306  |proj g|=       3.4431
At iterate     1  f =        -61.1  |proj g|=        1.4976
At iterate     2  f =      -63.429  |proj g|=        0.4772
At iterate     3  f =      -64.019  |proj g|=       0.85857
At iterate     4  f =      -64.053  |proj g|=       0.70505
At iterate     5  f =      -64.053  |proj g|=        1.0767
At iterate     6  f =      -64.302  |proj g|=       0.44977
At iterate     7  f =      -65.173  |proj g|=        1.4078
At iterate     8  f =      -65.239  |proj g|=       0.69218
At iterate     9  f =      -65.264  |proj g|=      0.027001
At iterate    10  f =      -65.264  |proj g|=       0.44943
At iterate    11  f =      -65.264  |proj g|=     0.0055264
At iterate    12  f =      -65.264  |proj g|=     0.0019952

iterations 12
function evaluations 19
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00199523
final function value -65.2641

F = -65.2641
final  value -65.264093 
converged
 
INFO  [22:48:14.159] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:48:14.224] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:48:14.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:49:04.280] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:49:54.056] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:50:43.725] [mlr3]  Finished benchmark 
INFO  [22:50:43.796] [bbotk] Result of batch 9: 
INFO  [22:50:43.798] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [22:50:43.798] [bbotk]                   7              4083      0.1908105         0.41 -0.904922 
INFO  [22:50:43.798] [bbotk]  errors.model classif.auc                                uhash 
INFO  [22:50:43.798] [bbotk]          <NA>   0.9746824 81703eb8-bbc3-4925-8902-5c1cd3e17dd3 
DEBUG [22:50:44.394] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.519369e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.004486476 0.4519369 
  - best initial criterion value(s) :  42.71388 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -42.714  |proj g|=       5.3982
At iterate     1  f =      -42.998  |proj g|=        1.4723
At iterate     2  f =      -49.986  |proj g|=        1.9995
At iterate     3  f =      -54.711  |proj g|=        4.2107
At iterate     4  f =      -60.602  |proj g|=        3.6854
At iterate     5  f =      -60.778  |proj g|=         2.696
At iterate     6  f =      -61.242  |proj g|=         3.566
At iterate     7  f =      -61.682  |proj g|=        3.5079
At iterate     8  f =      -62.026  |proj g|=        3.4196
At iterate     9  f =      -63.266  |proj g|=        3.0611
At iterate    10  f =      -64.963  |proj g|=        2.5572
At iterate    11  f =        -67.7  |proj g|=        1.9033
At iterate    12  f =      -67.985  |proj g|=      0.017243
At iterate    13  f =      -68.065  |proj g|=       0.39627
At iterate    14  f =      -68.073  |proj g|=       0.44217
At iterate    15  f =      -68.073  |proj g|=     0.0053291
At iterate    16  f =      -68.073  |proj g|=     0.0053199
At iterate    17  f =      -68.073  |proj g|=     0.0048129

iterations 17
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00481295
final function value -68.0732

F = -68.0732
final  value -68.073247 
converged
 
INFO  [22:50:44.398] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:50:44.451] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:50:44.457] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:51:21.091] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:51:57.721] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:52:34.279] [mlr3]  Finished benchmark 
INFO  [22:52:34.346] [bbotk] Result of batch 10: 
INFO  [22:52:34.348] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [22:52:34.348] [bbotk]                   5              3046      0.2960758        0.412 -0.9044361 
INFO  [22:52:34.348] [bbotk]  errors.model classif.auc                                uhash 
INFO  [22:52:34.348] [bbotk]          <NA>   0.9760606 6239a26b-11c1-48be-a168-4a0714044053 
DEBUG [22:52:34.975] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.445692e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.004445692 0.4448006 
  - best initial criterion value(s) :  56.05203 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -56.052  |proj g|=       6.3252
At iterate     1  f =      -65.577  |proj g|=        2.2176
At iterate     2  f =      -69.373  |proj g|=        3.0305
At iterate     3  f =      -70.238  |proj g|=        2.7983
At iterate     4  f =      -72.293  |proj g|=        2.2268
At iterate     5  f =      -73.543  |proj g|=       0.10531
At iterate     6  f =      -73.548  |proj g|=       0.43564
At iterate     7  f =      -73.555  |proj g|=       0.43544
At iterate     8  f =      -73.565  |proj g|=       0.43534
At iterate     9  f =      -73.633  |proj g|=       0.50214
At iterate    10  f =      -73.783  |proj g|=       0.89409
At iterate    11  f =      -74.148  |proj g|=       0.70966
At iterate    12  f =      -74.273  |proj g|=       0.83197
At iterate    13  f =      -74.492  |proj g|=       0.58269
At iterate    14  f =      -74.526  |proj g|=       0.43579
At iterate    15  f =      -74.537  |proj g|=     0.0052672
At iterate    16  f =      -74.537  |proj g|=     0.0058833
At iterate    17  f =      -74.537  |proj g|=     0.0049369
At iterate    18  f =      -74.537  |proj g|=     0.0049367
At iterate    19  f =      -74.537  |proj g|=      0.004937

iterations 19
function evaluations 28
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00493698
final function value -74.5368

F = -74.5368
final  value -74.536821 
converged
 
INFO  [22:52:34.980] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:52:35.033] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:52:35.040] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:52:35.783] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:52:36.501] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:52:37.226] [mlr3]  Finished benchmark 
INFO  [22:52:37.292] [bbotk] Result of batch 11: 
INFO  [22:52:37.294] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [22:52:37.294] [bbotk]                  10              1822      0.2489502        0.435 -0.9022823 
INFO  [22:52:37.294] [bbotk]  errors.model classif.auc                                uhash 
INFO  [22:52:37.294] [bbotk]          <NA>         0.5 0738ccb8-0949-4755-abd7-a2db7025e278 
DEBUG [22:52:37.897] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.633753e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.004591314 0.4633753 
  - best initial criterion value(s) :  67.42452 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -67.425  |proj g|=        5.548
At iterate     1  f =      -71.148  |proj g|=        3.1246
At iterate     2  f =      -74.915  |proj g|=        1.8606
At iterate     3  f =      -75.687  |proj g|=       0.13267
At iterate     4  f =      -75.699  |proj g|=       0.63952
At iterate     5  f =      -75.715  |proj g|=        0.4955
At iterate     6  f =      -75.723  |proj g|=       0.45417
At iterate     7  f =      -75.797  |proj g|=       0.45459
At iterate     8  f =      -75.955  |proj g|=        0.5394
At iterate     9  f =      -76.423  |proj g|=        1.7432
At iterate    10  f =      -77.425  |proj g|=        2.5982
At iterate    11  f =      -77.542  |proj g|=        3.0941
At iterate    12  f =      -77.801  |proj g|=        1.8622
At iterate    13  f =      -77.969  |proj g|=       0.45454
At iterate    14  f =      -77.974  |proj g|=       0.45437
At iterate    15  f =      -77.975  |proj g|=       0.45429
At iterate    16  f =      -77.975  |proj g|=      0.070938
At iterate    17  f =      -77.975  |proj g|=     0.0020393

iterations 17
function evaluations 21
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00203931
final function value -77.975

F = -77.975
final  value -77.975008 
converged
 
INFO  [22:52:37.901] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:52:37.956] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:52:37.963] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:53:23.721] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:54:09.282] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:54:10.392] [mlr3]  Finished benchmark 
INFO  [22:54:10.453] [bbotk] Result of batch 12: 
INFO  [22:54:10.455] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [22:54:10.455] [bbotk]                   8              3772      0.1218767        0.426 -0.900912 
INFO  [22:54:10.455] [bbotk]  errors.model classif.auc                                uhash 
INFO  [22:54:10.455] [bbotk]          <NA>    0.819301 249fa7e3-ec64-4b72-8c5c-ff2d321a8524 
DEBUG [22:54:11.061] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.497481e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.004450946 0.4497481 
  - best initial criterion value(s) :  61.98285 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -61.983  |proj g|=       3.8016
At iterate     1  f =      -70.377  |proj g|=         1.542
At iterate     2  f =      -75.257  |proj g|=        1.4237
At iterate     3  f =      -75.308  |proj g|=       0.59419
At iterate     4  f =      -75.312  |proj g|=       0.44069
At iterate     5  f =      -75.328  |proj g|=       0.47829
At iterate     6  f =      -75.407  |proj g|=       0.83231
At iterate     7  f =      -75.615  |proj g|=        1.4423
At iterate     8  f =      -75.667  |proj g|=        1.7409
At iterate     9  f =      -75.779  |proj g|=         1.079
At iterate    10  f =       -75.84  |proj g|=       0.44063
At iterate    11  f =       -75.84  |proj g|=        0.0565
At iterate    12  f =      -75.841  |proj g|=     0.0087508
At iterate    13  f =      -75.841  |proj g|=      0.013283
At iterate    14  f =      -75.841  |proj g|=     0.0047573

iterations 14
function evaluations 22
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0047573
final function value -75.8408

F = -75.8408
final  value -75.840759 
converged
 
INFO  [22:54:11.065] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:54:11.117] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:54:11.123] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:55:05.064] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:55:58.375] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:56:51.207] [mlr3]  Finished benchmark 
INFO  [22:56:51.278] [bbotk] Result of batch 13: 
INFO  [22:56:51.283] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [22:56:51.283] [bbotk]                   4              4416      0.2308946        0.417 -0.9032125 
INFO  [22:56:51.283] [bbotk]  errors.model classif.auc                                uhash 
INFO  [22:56:51.283] [bbotk]          <NA>   0.9763668 67a9cb31-d3df-4939-945e-bea9b9bb1826 
DEBUG [22:56:52.194] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.435628e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.004416617 0.4435628 
  - best initial criterion value(s) :  63.22778 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -63.228  |proj g|=       3.4676
At iterate     1  f =      -71.464  |proj g|=        2.1606
At iterate     2  f =      -73.496  |proj g|=        3.6177
At iterate     3  f =      -74.207  |proj g|=        3.4885
At iterate     4  f =      -75.277  |proj g|=        3.1937
At iterate     5  f =      -77.565  |proj g|=        2.5295
At iterate     6  f =      -78.834  |proj g|=        1.9776
At iterate     7  f =      -78.858  |proj g|=         1.905
At iterate     8  f =      -78.938  |proj g|=        1.9221
At iterate     9  f =      -79.961  |proj g|=        1.8198
At iterate    10  f =      -82.122  |proj g|=        1.3764
At iterate    11  f =      -84.465  |proj g|=        1.0016
At iterate    12  f =      -84.531  |proj g|=       0.43762
At iterate    13  f =      -85.332  |proj g|=       0.25209
At iterate    14  f =      -86.352  |proj g|=        1.2205
At iterate    15  f =       -86.61  |proj g|=       0.63964
At iterate    16  f =      -86.615  |proj g|=        0.5253
At iterate    17  f =      -86.626  |proj g|=       0.43495
At iterate    18  f =      -86.626  |proj g|=     0.0042277
At iterate    19  f =      -86.626  |proj g|=     0.0042184
At iterate    20  f =      -86.626  |proj g|=     0.0023999

iterations 20
function evaluations 30
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00239991
final function value -86.6261

F = -86.6261
final  value -86.626105 
converged
 
INFO  [22:56:52.199] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:56:52.260] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:56:52.268] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:56:53.594] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:56:54.593] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:56:55.296] [mlr3]  Finished benchmark 
INFO  [22:56:55.358] [bbotk] Result of batch 14: 
INFO  [22:56:55.360] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [22:56:55.360] [bbotk]                   9              1826      0.2299716        0.652 -0.8996359 
INFO  [22:56:55.360] [bbotk]  errors.model classif.auc                                uhash 
INFO  [22:56:55.360] [bbotk]          <NA>         0.5 d5ec5bd2-fb0b-40fd-81fd-535b925386c4 
DEBUG [22:56:56.012] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.599249e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.004527343 0.4599249 
  - best initial criterion value(s) :  73.46662 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -73.467  |proj g|=       1.7458
At iterate     1  f =      -75.711  |proj g|=        2.9978
At iterate     2  f =      -77.823  |proj g|=        2.7197
At iterate     3  f =      -79.028  |proj g|=        2.4515
At iterate     4  f =      -80.665  |proj g|=        1.9662
At iterate     5  f =       -80.84  |proj g|=        3.0098
At iterate     6  f =      -81.342  |proj g|=       0.22668
At iterate     7  f =      -81.362  |proj g|=       0.45131
At iterate     8  f =      -81.372  |proj g|=        0.1048
At iterate     9  f =      -81.377  |proj g|=       0.45108
At iterate    10  f =      -81.396  |proj g|=       0.45128
At iterate    11  f =      -81.454  |proj g|=       0.45165
At iterate    12  f =      -81.558  |proj g|=       0.45188
At iterate    13  f =      -81.599  |proj g|=       0.45161
At iterate    14  f =       -81.63  |proj g|=       0.45116
At iterate    15  f =      -81.632  |proj g|=       0.20632
At iterate    16  f =      -81.633  |proj g|=       0.12022
At iterate    17  f =      -81.634  |proj g|=      0.032807
At iterate    18  f =      -81.634  |proj g|=     0.0045164
At iterate    19  f =      -81.634  |proj g|=     0.0045167
At iterate    20  f =      -81.634  |proj g|=     0.0045167

iterations 20
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00451669
final function value -81.6339

F = -81.6339
final  value -81.633880 
converged
 
INFO  [22:56:56.016] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:56:56.067] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:56:56.074] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:57:06.597] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:57:17.810] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [22:57:28.408] [mlr3]  Finished benchmark 
INFO  [22:57:28.472] [bbotk] Result of batch 15: 
INFO  [22:57:28.474] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [22:57:28.474] [bbotk]                   7               801      0.2885817        0.449 -0.9032872 
INFO  [22:57:28.474] [bbotk]  errors.model classif.auc                                uhash 
INFO  [22:57:28.474] [bbotk]          <NA>   0.9765014 a2736d06-360b-4ee4-9e36-ff1635623e39 
DEBUG [22:57:29.093] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.541921e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.00440305 0.4541921 
  - best initial criterion value(s) :  82.32789 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -82.328  |proj g|=        1.356
At iterate     1  f =      -86.932  |proj g|=        3.3283
At iterate     2  f =        -87.7  |proj g|=        3.3017
At iterate     3  f =      -88.086  |proj g|=        3.0968
At iterate     4  f =      -88.587  |proj g|=        2.4396
At iterate     5  f =      -88.717  |proj g|=        2.3953
At iterate     6  f =      -88.943  |proj g|=        2.5498
At iterate     7  f =          -89  |proj g|=        2.4808
At iterate     8  f =       -89.02  |proj g|=        2.4373
At iterate     9  f =      -89.114  |proj g|=        2.3703
At iterate    10  f =      -89.713  |proj g|=        2.0977
At iterate    11  f =      -90.853  |proj g|=        1.6437
At iterate    12  f =      -91.732  |proj g|=        1.8564
At iterate    13  f =      -97.337  |proj g|=       0.65486
At iterate    14  f =      -97.519  |proj g|=       0.44614
At iterate    15  f =      -97.529  |proj g|=       0.44603
At iterate    16  f =      -97.529  |proj g|=       0.44598
At iterate    17  f =      -97.529  |proj g|=     0.0038172
At iterate    18  f =      -97.529  |proj g|=     0.0038175

iterations 18
function evaluations 22
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00381754
final function value -97.5288

F = -97.5288
final  value -97.528823 
converged
 
INFO  [22:57:29.097] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:57:29.149] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:57:29.155] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [22:58:20.782] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [22:59:11.600] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:00:03.249] [mlr3]  Finished benchmark 
INFO  [23:00:03.325] [bbotk] Result of batch 16: 
INFO  [23:00:03.328] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:00:03.328] [bbotk]                   3              4210      0.3942434        0.435 -0.8977177 
INFO  [23:00:03.328] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:00:03.328] [bbotk]          <NA>   0.9767687 53afaff2-7c3e-466f-85a1-9629acf3784c 
DEBUG [23:00:04.039] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.484479e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9516041 
  - variance bounds :  0.004395394 0.4484478 
  - best initial criterion value(s) :  72.25849 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -72.258  |proj g|=      0.53472
At iterate     1  f =      -84.317  |proj g|=        2.3903
At iterate     2  f =      -86.282  |proj g|=        2.3025
At iterate     3  f =      -88.378  |proj g|=         2.173
At iterate     4  f =      -89.003  |proj g|=        2.1724
At iterate     5  f =      -89.027  |proj g|=        2.1722
At iterate     6  f =      -89.032  |proj g|=         2.172
At iterate     7  f =      -89.032  |proj g|=        2.1719
At iterate     8  f =      -89.032  |proj g|=        2.1717
At iterate     9  f =      -89.034  |proj g|=        2.1711
At iterate    10  f =      -89.037  |proj g|=        2.1694
At iterate    11  f =      -89.046  |proj g|=        2.1648
At iterate    12  f =      -89.069  |proj g|=        2.1528
At iterate    13  f =      -89.126  |proj g|=        2.1217
At iterate    14  f =      -89.262  |proj g|=         1.574
At iterate    15  f =      -89.541  |proj g|=       0.27185
At iterate    16  f =      -89.937  |proj g|=        1.0141
At iterate    17  f =      -89.985  |proj g|=       0.44016
At iterate    18  f =      -89.988  |proj g|=      0.084124
At iterate    19  f =      -89.988  |proj g|=     0.0043362
At iterate    20  f =      -89.988  |proj g|=      0.028861
At iterate    21  f =      -89.988  |proj g|=     0.0043363

iterations 21
function evaluations 25
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00433633
final function value -89.9884

F = -89.9884
final  value -89.988389 
converged
 
INFO  [23:00:04.044] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:00:04.489] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:00:04.497] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:00:20.205] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:00:36.277] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:00:52.218] [mlr3]  Finished benchmark 
INFO  [23:00:52.282] [bbotk] Result of batch 17: 
INFO  [23:00:52.283] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:00:52.283] [bbotk]                   3              1261      0.4920271        0.511 -0.9031741 
INFO  [23:00:52.283] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:00:52.283] [bbotk]          <NA>   0.9765148 32e52835-df9b-4cac-b0cb-fdc517b234c2 
DEBUG [23:00:52.908] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.426765e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9573124 
  - variance bounds :  0.004296026 0.4426765 
  - best initial criterion value(s) :  72.32368 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -72.324  |proj g|=       2.7609
At iterate     1  f =      -98.328  |proj g|=        2.5449
At iterate     2  f =       -100.5  |proj g|=       0.51757
At iterate     3  f =      -100.61  |proj g|=        1.0692
At iterate     4  f =      -100.64  |proj g|=       0.43482
At iterate     5  f =      -100.68  |proj g|=       0.13492
At iterate     6  f =      -101.01  |proj g|=        0.9731
At iterate     7  f =      -101.04  |proj g|=       0.55378
At iterate     8  f =      -101.05  |proj g|=       0.43478
At iterate     9  f =      -101.05  |proj g|=      0.032049
At iterate    10  f =      -101.05  |proj g|=       0.01643
At iterate    11  f =      -101.05  |proj g|=     0.0027741

iterations 11
function evaluations 17
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00277405
final function value -101.054

F = -101.054
final  value -101.054000 
converged
 
INFO  [23:00:52.912] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:00:52.966] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:00:52.973] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:01:34.018] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:02:15.998] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:02:57.563] [mlr3]  Finished benchmark 
INFO  [23:02:57.630] [bbotk] Result of batch 18: 
INFO  [23:02:57.632] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:02:57.632] [bbotk]                   3              3378     0.01470467        0.445 -0.9006266 
INFO  [23:02:57.632] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:02:57.632] [bbotk]          <NA>   0.9694879 f8ff7da3-091e-46de-ae79-b7c1f227700a 
DEBUG [23:02:58.254] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.364275e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9573124 
  - variance bounds :  0.004277433 0.4364275 
  - best initial criterion value(s) :  90.1227 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -90.123  |proj g|=       1.6373
At iterate     1  f =      -101.42  |proj g|=         3.155
At iterate     2  f =      -101.77  |proj g|=        3.0306
At iterate     3  f =      -106.07  |proj g|=        2.2633
At iterate     4  f =       -107.6  |proj g|=      0.088349
At iterate     5  f =      -107.68  |proj g|=       0.20559
At iterate     6  f =      -107.68  |proj g|=        0.4288
At iterate     7  f =      -107.68  |proj g|=     0.0033687
At iterate     8  f =      -107.68  |proj g|=     0.0033669
At iterate     9  f =      -107.68  |proj g|=     0.0022904

iterations 9
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00229043
final function value -107.679

F = -107.679
final  value -107.678939 
converged
 
INFO  [23:02:58.258] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:02:58.315] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:02:58.328] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:02:59.037] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:02:59.998] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:03:00.725] [mlr3]  Finished benchmark 
INFO  [23:03:00.790] [bbotk] Result of batch 19: 
INFO  [23:03:00.792] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:03:00.792] [bbotk]                  10              1522     0.00188503        0.443 -0.8985426 
INFO  [23:03:00.792] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:03:00.792] [bbotk]          <NA>         0.5 ce7a13cc-112b-47d1-b7af-f438a39d055c 
DEBUG [23:03:01.623] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.520851e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004455894 0.4520851 
  - best initial criterion value(s) :  87.80193 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -87.802  |proj g|=        7.307
At iterate     1  f =       -98.58  |proj g|=        3.9404
At iterate     2  f =      -99.009  |proj g|=        3.9338
At iterate     3  f =       -103.6  |proj g|=         3.053
At iterate     4  f =      -107.64  |proj g|=        2.4408
At iterate     5  f =      -109.25  |proj g|=         2.448
At iterate     6  f =      -109.39  |proj g|=        1.8932
At iterate     7  f =      -109.67  |proj g|=        0.5312
At iterate     8  f =      -109.68  |proj g|=       0.74127
At iterate     9  f =       -109.7  |proj g|=        1.0434
At iterate    10  f =      -109.76  |proj g|=        1.5153
At iterate    11  f =       -109.9  |proj g|=        1.8585
At iterate    12  f =      -110.29  |proj g|=        1.9079
At iterate    13  f =      -111.33  |proj g|=        2.0004
At iterate    14  f =      -112.84  |proj g|=        2.0706
At iterate    15  f =      -113.61  |proj g|=        2.0064
At iterate    16  f =      -113.83  |proj g|=        1.9485
At iterate    17  f =      -113.88  |proj g|=        1.2625
At iterate    18  f =      -113.92  |proj g|=       0.77384
At iterate    19  f =      -113.99  |proj g|=      0.097321
At iterate    20  f =      -114.06  |proj g|=       0.35912
At iterate    21  f =      -114.06  |proj g|=       0.44464
At iterate    22  f =      -114.06  |proj g|=     0.0041775
At iterate    23  f =      -114.06  |proj g|=       0.09956
At iterate    24  f =      -114.06  |proj g|=      0.002159

iterations 24
function evaluations 33
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00215898
final function value -114.064

F = -114.064
final  value -114.063697 
converged
 
INFO  [23:03:01.627] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:03:01.682] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:03:01.696] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:03:36.148] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:04:10.786] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:04:46.109] [mlr3]  Finished benchmark 
INFO  [23:04:46.173] [bbotk] Result of batch 20: 
INFO  [23:04:46.175] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:04:46.175] [bbotk]                   7              2849      0.4748029        0.585 -0.8949061 
INFO  [23:04:46.175] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:04:46.175] [bbotk]          <NA>   0.9733361 44b38a24-7a93-432a-af9e-39a02bc56ced 
DEBUG [23:04:47.018] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.464759e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.0044307 0.4464759 
  - best initial criterion value(s) :  91.7414 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -91.741  |proj g|=       1.2512
At iterate     1  f =      -105.97  |proj g|=        1.5164
At iterate     2  f =       -109.9  |proj g|=        2.0252
At iterate     3  f =      -111.38  |proj g|=        1.8522
At iterate     4  f =      -111.55  |proj g|=       0.78112
At iterate     5  f =      -111.59  |proj g|=        1.2494
At iterate     6  f =       -111.6  |proj g|=        1.4443
At iterate     7  f =       -111.6  |proj g|=        1.4088
At iterate     8  f =       -111.6  |proj g|=        1.2275
At iterate     9  f =      -111.62  |proj g|=       0.91109
At iterate    10  f =      -111.65  |proj g|=       0.41889
At iterate    11  f =      -111.68  |proj g|=      0.072214
At iterate    12  f =       -111.7  |proj g|=       0.43897
At iterate    13  f =       -111.7  |proj g|=       0.43902
At iterate    14  f =       -111.7  |proj g|=     0.0076376
At iterate    15  f =       -111.7  |proj g|=     0.0030487
At iterate    16  f =       -111.7  |proj g|=     0.0030487

iterations 16
function evaluations 24
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00304871
final function value -111.697

F = -111.697
final  value -111.696550 
converged
 
INFO  [23:04:47.022] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:04:47.078] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:04:47.084] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:05:26.777] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:06:06.803] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:06:46.616] [mlr3]  Finished benchmark 
INFO  [23:06:46.685] [bbotk] Result of batch 21: 
INFO  [23:06:46.687] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:06:46.687] [bbotk]                   4              3234      0.4889832        0.596 -0.8970053 
INFO  [23:06:46.687] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:06:46.687] [bbotk]          <NA>    0.975882 b61b70a5-bb40-4a94-98f9-6c3c744476e1 
DEBUG [23:06:47.346] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.410686e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004410686 0.4469403 
  - best initial criterion value(s) :  101.2282 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -101.23  |proj g|=       1.1151
At iterate     1  f =      -112.66  |proj g|=        3.1984
At iterate     2  f =       -114.7  |proj g|=         2.979
At iterate     3  f =      -114.84  |proj g|=        2.9575
At iterate     4  f =      -115.73  |proj g|=        2.8291
At iterate     5  f =       -116.9  |proj g|=        2.5768
At iterate     6  f =      -118.51  |proj g|=        1.9818
At iterate     7  f =      -119.99  |proj g|=        2.3511
At iterate     8  f =       -120.2  |proj g|=        0.1577
At iterate     9  f =      -120.23  |proj g|=      0.081113
At iterate    10  f =      -120.23  |proj g|=       0.43975
At iterate    11  f =      -120.23  |proj g|=     0.0027862
At iterate    12  f =      -120.23  |proj g|=     0.0023911

iterations 12
function evaluations 17
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00239108
final function value -120.233

F = -120.233
final  value -120.232855 
converged
 
INFO  [23:06:47.350] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:06:47.402] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:06:47.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:07:28.773] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:08:10.188] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:08:51.868] [mlr3]  Finished benchmark 
INFO  [23:08:51.935] [bbotk] Result of batch 22: 
INFO  [23:08:51.936] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:08:51.936] [bbotk]                   6              3426      0.3579656        0.476 -0.8949958 
INFO  [23:08:51.936] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:08:51.936] [bbotk]          <NA>   0.9746364 3cc07783-ee3f-46b4-8fd3-0b1db55ac0c8 
DEBUG [23:08:52.608] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.356112e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004356112 0.4465587 
  - best initial criterion value(s) :  100.0653 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -100.07  |proj g|=       5.8883
At iterate     1  f =       -106.5  |proj g|=        3.6721
At iterate     2  f =      -112.59  |proj g|=        2.4039
At iterate     3  f =      -113.68  |proj g|=        1.8814
At iterate     4  f =      -113.69  |proj g|=         1.917
At iterate     5  f =      -113.74  |proj g|=        1.9207
At iterate     6  f =      -114.39  |proj g|=        1.9442
At iterate     7  f =      -115.59  |proj g|=        2.0046
At iterate     8  f =      -119.94  |proj g|=        2.1432
At iterate     9  f =      -121.89  |proj g|=        2.1467
At iterate    10  f =      -122.35  |proj g|=         2.119
At iterate    11  f =      -122.49  |proj g|=        2.0924
At iterate    12  f =      -122.55  |proj g|=        2.0676
At iterate    13  f =      -122.62  |proj g|=        1.8254
At iterate    14  f =      -122.71  |proj g|=         1.026
At iterate    15  f =      -122.92  |proj g|=        0.1099
At iterate    16  f =      -123.12  |proj g|=       0.26485
At iterate    17  f =      -123.13  |proj g|=       0.43954
At iterate    18  f =      -123.13  |proj g|=     0.0096772
At iterate    19  f =      -123.13  |proj g|=       0.15464
At iterate    20  f =      -123.13  |proj g|=     0.0038247

iterations 20
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00382466
final function value -123.13

F = -123.13
final  value -123.129691 
converged
 
INFO  [23:08:52.612] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:08:52.667] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:08:52.674] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:09:39.521] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:10:26.027] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:11:12.195] [mlr3]  Finished benchmark 
INFO  [23:11:12.271] [bbotk] Result of batch 23: 
INFO  [23:11:12.272] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:11:12.272] [bbotk]                   4              3857     0.09089942        0.462 -0.8945451 
INFO  [23:11:12.272] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:11:12.272] [bbotk]          <NA>   0.9768164 4c837fec-070c-4d9e-92b8-8fbd7416470f 
DEBUG [23:11:12.928] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.303361e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004303361 0.4466 
  - best initial criterion value(s) :  90.27755 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -90.278  |proj g|=       4.8633
At iterate     1  f =      -101.58  |proj g|=        3.6832
At iterate     2  f =      -102.71  |proj g|=        3.3881
At iterate     3  f =      -103.58  |proj g|=        3.0154
At iterate     4  f =      -104.49  |proj g|=        2.5752
At iterate     5  f =      -104.98  |proj g|=        2.4034
At iterate     6  f =      -105.43  |proj g|=         2.117
At iterate     7  f =      -107.34  |proj g|=        1.2753
At iterate     8  f =      -116.76  |proj g|=        5.0069
At iterate     9  f =      -120.58  |proj g|=        1.5812
At iterate    10  f =      -122.69  |proj g|=        2.0545
At iterate    11  f =      -123.14  |proj g|=       0.35073
At iterate    12  f =      -123.23  |proj g|=       0.52943
At iterate    13  f =      -123.26  |proj g|=       0.38694
At iterate    14  f =      -123.26  |proj g|=       0.43959
At iterate    15  f =      -123.26  |proj g|=     0.0033617
At iterate    16  f =      -123.26  |proj g|=     0.0033617

iterations 16
function evaluations 21
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00336168
final function value -123.264

F = -123.264
final  value -123.264331 
converged
 
INFO  [23:11:12.932] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:11:12.986] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:11:12.993] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:11:14.017] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:11:14.729] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:11:15.563] [mlr3]  Finished benchmark 
INFO  [23:11:15.628] [bbotk] Result of batch 24: 
INFO  [23:11:15.630] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [23:11:15.630] [bbotk]                  10              4254     0.07570241        0.469 -0.894777 
INFO  [23:11:15.630] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:11:15.630] [bbotk]          <NA>         0.5 d0cc865e-2e4f-4bde-b0a1-627d2cb9b3ce 
DEBUG [23:11:16.298] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.45225e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.00445225 0.4555839 
  - best initial criterion value(s) :  98.66961 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -98.67  |proj g|=       4.7199
At iterate     1  f =      -101.78  |proj g|=        1.6707
At iterate     2  f =      -104.57  |proj g|=        4.4558
At iterate     3  f =      -105.78  |proj g|=        4.3149
At iterate     4  f =      -126.04  |proj g|=        2.6257
At iterate     5  f =       -131.4  |proj g|=         0.622
At iterate     6  f =       -131.9  |proj g|=        1.1569
At iterate     7  f =      -131.91  |proj g|=        1.6689
At iterate     8  f =      -131.92  |proj g|=        1.4736
At iterate     9  f =      -131.92  |proj g|=        1.4507
At iterate    10  f =      -131.93  |proj g|=        1.2168
At iterate    11  f =      -131.94  |proj g|=       0.93217
At iterate    12  f =      -131.97  |proj g|=       0.42779
At iterate    13  f =         -132  |proj g|=      0.074911
At iterate    14  f =      -132.02  |proj g|=       0.44863
At iterate    15  f =      -132.02  |proj g|=       0.44871
At iterate    16  f =      -132.02  |proj g|=     0.0026905
At iterate    17  f =      -132.02  |proj g|=      0.022968

iterations 17
function evaluations 27
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0229682
final function value -132.02

F = -132.02
final  value -132.020236 
converged
 
INFO  [23:11:16.302] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:11:16.359] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:11:16.366] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:11:37.172] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:11:57.944] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:12:18.552] [mlr3]  Finished benchmark 
INFO  [23:12:18.620] [bbotk] Result of batch 25: 
INFO  [23:12:18.622] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:12:18.622] [bbotk]                   3              1642     0.09520099        0.471 -0.8902245 
INFO  [23:12:18.622] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:12:18.622] [bbotk]          <NA>    0.974584 8bb6e9e2-555d-4338-837a-1fd7d0051596 
DEBUG [23:12:19.269] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.400845e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004400845 0.4497658 
  - best initial criterion value(s) :  93.72985 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -93.73  |proj g|=      0.18532
At iterate     1  f =      -112.43  |proj g|=      0.029913
At iterate     2  f =      -112.46  |proj g|=       0.44136
At iterate     3  f =      -113.18  |proj g|=     0.0042793
At iterate     4  f =      -113.18  |proj g|=     0.0042776
At iterate     5  f =      -113.18  |proj g|=     0.0039811

iterations 5
function evaluations 10
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00398114
final function value -113.179

F = -113.179
final  value -113.178768 
converged
 
INFO  [23:12:19.273] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:12:19.330] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:12:19.344] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:12:31.494] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:12:43.800] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:12:56.279] [mlr3]  Finished benchmark 
INFO  [23:12:56.343] [bbotk] Result of batch 26: 
INFO  [23:12:56.344] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:12:56.344] [bbotk]                   3               926      0.4314485        0.462 -0.9254964 
INFO  [23:12:56.344] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:12:56.344] [bbotk]          <NA>   0.9761211 daeac118-af2c-4516-8440-c9a91a302050 
DEBUG [23:12:57.002] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.350741e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004350741 0.4388836 
  - best initial criterion value(s) :  120.8368 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -120.84  |proj g|=      0.74872
At iterate     1  f =      -135.39  |proj g|=         2.808
At iterate     2  f =      -137.78  |proj g|=        2.6673
At iterate     3  f =      -137.89  |proj g|=        2.6667
At iterate     4  f =       -137.9  |proj g|=        2.6659
At iterate     5  f =      -138.19  |proj g|=        2.6201
At iterate     6  f =      -140.81  |proj g|=       0.94967
At iterate     7  f =      -141.52  |proj g|=       0.40487
At iterate     8  f =      -141.69  |proj g|=       0.47216
At iterate     9  f =       -141.7  |proj g|=       0.43234
At iterate    10  f =       -141.7  |proj g|=      0.006417
At iterate    11  f =       -141.7  |proj g|=     0.0027403
At iterate    12  f =       -141.7  |proj g|=     0.0027403

iterations 12
function evaluations 21
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0027403
final function value -141.698

F = -141.698
final  value -141.697594 
converged
 
INFO  [23:12:57.006] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:12:57.059] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:12:57.066] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:12:57.781] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:12:58.505] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:12:59.215] [mlr3]  Finished benchmark 
INFO  [23:12:59.285] [bbotk] Result of batch 27: 
INFO  [23:12:59.287] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:12:59.287] [bbotk]                  10              1975      0.4735061        0.471 -0.8879246 
INFO  [23:12:59.287] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:12:59.287] [bbotk]          <NA>         0.5 1738c013-b365-401d-94fa-eb6b26461de3 
DEBUG [23:13:00.106] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.48814e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004460215 0.4488139 
  - best initial criterion value(s) :  89.16043 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -89.16  |proj g|=       5.5828
At iterate     1  f =      -90.757  |proj g|=        4.2157
At iterate     2  f =      -96.067  |proj g|=        4.7259
At iterate     3  f =      -98.868  |proj g|=        4.2384
At iterate     4  f =      -104.11  |proj g|=        3.8328
At iterate     5  f =      -107.08  |proj g|=        3.4362
At iterate     6  f =      -116.38  |proj g|=         4.123
At iterate     7  f =      -117.74  |proj g|=        2.6627
At iterate     8  f =      -117.94  |proj g|=       0.15595
At iterate     9  f =      -117.97  |proj g|=      0.059713
At iterate    10  f =      -117.97  |proj g|=       0.44147
At iterate    11  f =      -117.97  |proj g|=     0.0091205
At iterate    12  f =      -117.97  |proj g|=     0.0091205

iterations 12
function evaluations 23
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00912052
final function value -117.969

F = -117.969
final  value -117.969004 
converged
 
INFO  [23:13:00.110] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:13:00.163] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:13:00.170] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:13:53.873] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:14:46.428] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:15:40.454] [mlr3]  Finished benchmark 
INFO  [23:15:40.518] [bbotk] Result of batch 28: 
INFO  [23:15:40.520] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:15:40.520] [bbotk]                   6              4353      0.2058422         0.62 -0.8943265 
INFO  [23:15:40.520] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:15:40.520] [bbotk]          <NA>   0.9753186 2de54a8c-b25c-40b0-8d45-05141fc49f2a 
DEBUG [23:15:41.173] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.440029e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004440029 0.4456394 
  - best initial criterion value(s) :  107.463 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -107.46  |proj g|=       9.2552
At iterate     1  f =      -117.04  |proj g|=        3.8831
At iterate     2  f =      -125.18  |proj g|=        1.3232
At iterate     3  f =      -126.82  |proj g|=        2.0271
At iterate     4  f =      -126.97  |proj g|=        1.9364
At iterate     5  f =      -126.99  |proj g|=        1.9118
At iterate     6  f =      -127.03  |proj g|=        1.8915
At iterate     7  f =      -127.29  |proj g|=        1.4729
At iterate     8  f =      -127.78  |proj g|=       0.78716
At iterate     9  f =      -129.92  |proj g|=        1.6197
At iterate    10  f =      -134.84  |proj g|=        4.7297
At iterate    11  f =      -140.04  |proj g|=        1.0481
At iterate    12  f =      -140.68  |proj g|=        2.0062
At iterate    13  f =      -140.79  |proj g|=        0.6906
At iterate    14  f =      -140.81  |proj g|=       0.43918
At iterate    15  f =      -140.81  |proj g|=       0.43914
At iterate    16  f =      -140.81  |proj g|=       0.43912
At iterate    17  f =      -140.81  |proj g|=      0.022719
At iterate    18  f =      -140.81  |proj g|=     0.0043287

iterations 18
function evaluations 24
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00432875
final function value -140.809

F = -140.809
final  value -140.809460 
converged
 
INFO  [23:15:41.177] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:15:41.231] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:15:41.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:16:09.539] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:16:37.914] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:17:06.298] [mlr3]  Finished benchmark 
INFO  [23:17:06.365] [bbotk] Result of batch 29: 
INFO  [23:17:06.366] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:17:06.366] [bbotk]                   3              2324      0.4216725        0.463 -0.8866871 
INFO  [23:17:06.366] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:17:06.366] [bbotk]          <NA>   0.9766665 7abe281b-3ba7-4335-8faf-892923a75958 
DEBUG [23:17:07.008] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.392979e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004392979 0.4414946 
  - best initial criterion value(s) :  105.8176 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -105.82  |proj g|=       8.0528
At iterate     1  f =      -117.49  |proj g|=        4.4965
At iterate     2  f =       -128.9  |proj g|=        3.1276
At iterate     3  f =       -135.3  |proj g|=        2.3399
At iterate     4  f =      -135.68  |proj g|=        2.3225
At iterate     5  f =      -137.75  |proj g|=        1.5361
At iterate     6  f =      -137.87  |proj g|=        0.4351
At iterate     7  f =      -137.94  |proj g|=       0.57657
At iterate     8  f =       -138.1  |proj g|=       0.70402
At iterate     9  f =      -138.12  |proj g|=       0.20106
At iterate    10  f =      -138.13  |proj g|=      0.073346
At iterate    11  f =      -138.13  |proj g|=       0.43493
At iterate    12  f =      -138.13  |proj g|=       0.22662
At iterate    13  f =      -138.13  |proj g|=     0.0060379

iterations 13
function evaluations 21
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00603792
final function value -138.135

F = -138.135
final  value -138.134779 
converged
 
INFO  [23:17:07.012] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:17:07.068] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:17:07.075] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:17:08.052] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:17:08.776] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:17:09.718] [mlr3]  Finished benchmark 
INFO  [23:17:09.780] [bbotk] Result of batch 30: 
INFO  [23:17:09.782] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:17:09.782] [bbotk]                  10              1300      0.0180688        0.449 -0.8879402 
INFO  [23:17:09.782] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:17:09.782] [bbotk]          <NA>         0.5 32cdb24c-6251-4682-95bf-0a6f046828fc 
DEBUG [23:17:10.425] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.520499e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004520499 0.4565896 
  - best initial criterion value(s) :  125.7744 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -125.77  |proj g|=       1.4919
At iterate     1  f =      -136.13  |proj g|=        3.9627
At iterate     2  f =      -137.65  |proj g|=         4.036
At iterate     3  f =      -138.05  |proj g|=        4.0985
At iterate     4  f =      -140.33  |proj g|=        4.5658
At iterate     5  f =      -159.74  |proj g|=        2.0519
At iterate     6  f =      -160.42  |proj g|=       0.87136
At iterate     7  f =      -160.43  |proj g|=       0.23653
At iterate     8  f =      -160.44  |proj g|=       0.45057
At iterate     9  f =      -160.44  |proj g|=     0.0030627
At iterate    10  f =      -160.44  |proj g|=     0.0030627
At iterate    11  f =      -160.44  |proj g|=     0.0030627

iterations 11
function evaluations 20
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00306274
final function value -160.44

F = -160.44
final  value -160.439844 
converged
 
INFO  [23:17:10.429] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:17:10.482] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:17:10.489] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:17:33.962] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:17:57.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:18:22.077] [mlr3]  Finished benchmark 
INFO  [23:18:22.146] [bbotk] Result of batch 31: 
INFO  [23:18:22.148] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:18:22.148] [bbotk]                   4              1932      0.2653838        0.453 -0.8830807 
INFO  [23:18:22.148] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:18:22.148] [bbotk]          <NA>   0.9768104 1a5a5d20-e419-473c-8a2c-6cf405a3eac7 
DEBUG [23:18:22.812] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.475733e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004475733 0.449673 
  - best initial criterion value(s) :  111.9141 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -111.91  |proj g|=        8.568
At iterate     1  f =      -130.29  |proj g|=        4.2639
At iterate     2  f =       -133.5  |proj g|=        3.7107
At iterate     3  f =      -135.86  |proj g|=        3.2288
At iterate     4  f =       -138.1  |proj g|=        2.8146
At iterate     5  f =      -144.62  |proj g|=       0.69683
At iterate     6  f =       -146.5  |proj g|=        8.0765
At iterate     7  f =         -153  |proj g|=       0.66956
At iterate     8  f =      -162.08  |proj g|=        2.0502
At iterate     9  f =       -162.7  |proj g|=        1.1257
At iterate    10  f =       -162.8  |proj g|=       0.44373
At iterate    11  f =       -162.8  |proj g|=     0.0037121
At iterate    12  f =       -162.8  |proj g|=      0.029165
At iterate    13  f =       -162.8  |proj g|=     0.0074061
At iterate    14  f =       -162.8  |proj g|=     0.0037127

iterations 14
function evaluations 21
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00371268
final function value -162.803

F = -162.803
final  value -162.803097 
converged
 
INFO  [23:18:22.826] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:18:22.874] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:18:22.881] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:18:23.722] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:19:09.999] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:19:56.636] [mlr3]  Finished benchmark 
INFO  [23:19:56.700] [bbotk] Result of batch 32: 
INFO  [23:19:56.702] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:19:56.702] [bbotk]                   8              3836      0.3576817        0.471 -0.8831462 
INFO  [23:19:56.702] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:19:56.702] [bbotk]          <NA>   0.8172922 c34ede26-56c9-49cf-8d1b-843fb1065edc 
DEBUG [23:19:57.356] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.393222e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004393222 0.4427811 
  - best initial criterion value(s) :  104.5454 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -104.55  |proj g|=       9.7994
At iterate     1  f =      -129.83  |proj g|=        4.1194
At iterate     2  f =      -132.63  |proj g|=        3.2424
At iterate     3  f =       -135.7  |proj g|=        2.5163
At iterate     4  f =      -135.88  |proj g|=        2.4259
At iterate     5  f =      -136.08  |proj g|=        2.3461
At iterate     6  f =      -137.96  |proj g|=        2.0616
At iterate     7  f =      -143.14  |proj g|=        3.7637
At iterate     8  f =      -151.65  |proj g|=        6.3987
At iterate     9  f =       -163.8  |proj g|=        9.4118
At iterate    10  f =      -168.75  |proj g|=        2.3213
At iterate    11  f =      -169.36  |proj g|=        1.9906
At iterate    12  f =      -169.78  |proj g|=       0.18972
At iterate    13  f =      -169.89  |proj g|=       0.53115
At iterate    14  f =       -169.9  |proj g|=      0.040156
At iterate    15  f =       -169.9  |proj g|=     0.0083799
At iterate    16  f =       -169.9  |proj g|=      0.028858
At iterate    17  f =       -169.9  |proj g|=     0.0033211

iterations 17
function evaluations 22
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00332106
final function value -169.902

F = -169.902
final  value -169.902272 
converged
 
INFO  [23:19:57.360] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:19:57.415] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:19:57.422] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:20:21.222] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:20:45.002] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:21:08.998] [mlr3]  Finished benchmark 
INFO  [23:21:09.075] [bbotk] Result of batch 33: 
INFO  [23:21:09.077] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:21:09.077] [bbotk]                   7              1934      0.3088992        0.458 -0.8817346 
INFO  [23:21:09.077] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:21:09.077] [bbotk]          <NA>   0.9752162 550cc71e-63d9-4ae1-b7a6-29fc4f9ce2c2 
DEBUG [23:21:09.786] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.350302e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004350302 0.4370842 
  - best initial criterion value(s) :  118.1664 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -118.17  |proj g|=       4.1841
At iterate     1  f =      -134.75  |proj g|=        3.9297
At iterate     2  f =      -135.31  |proj g|=        3.8511
At iterate     3  f =      -135.68  |proj g|=        3.5125
At iterate     4  f =      -136.24  |proj g|=        3.2389
At iterate     5  f =       -136.4  |proj g|=        3.0042
At iterate     6  f =      -141.42  |proj g|=        2.6063
At iterate     7  f =      -145.64  |proj g|=        2.3031
At iterate     8  f =      -165.77  |proj g|=        6.0062
At iterate     9  f =      -166.84  |proj g|=       0.25051
At iterate    10  f =      -166.86  |proj g|=       0.43117
At iterate    11  f =      -166.87  |proj g|=      0.024273
At iterate    12  f =      -166.87  |proj g|=     0.0046845
At iterate    13  f =      -166.87  |proj g|=     0.0093067

iterations 13
function evaluations 18
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00930674
final function value -166.866

F = -166.866
final  value -166.865588 
converged
 
INFO  [23:21:09.790] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:21:09.843] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:21:09.850] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:21:47.155] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:22:24.654] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:22:25.756] [mlr3]  Finished benchmark 
INFO  [23:22:25.821] [bbotk] Result of batch 34: 
INFO  [23:22:25.823] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:22:25.823] [bbotk]                   8              3101      0.3074749        0.508 -0.8836619 
INFO  [23:22:25.823] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:22:25.823] [bbotk]          <NA>   0.8180106 1592905a-4489-476c-a7ba-18ced00484c7 
DEBUG [23:22:26.495] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.273062e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004273062 0.433843 
  - best initial criterion value(s) :  152.4581 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -152.46  |proj g|=         4.73
At iterate     1  f =      -161.79  |proj g|=        3.3399
At iterate     2  f =      -177.23  |proj g|=        2.0106
At iterate     3  f =      -177.58  |proj g|=         1.881
At iterate     4  f =      -178.12  |proj g|=       0.86439
At iterate     5  f =      -178.16  |proj g|=       0.42818
At iterate     6  f =      -178.36  |proj g|=       0.81979
At iterate     7  f =       -178.9  |proj g|=        1.8269
At iterate     8  f =      -178.98  |proj g|=        1.5459
At iterate     9  f =      -179.04  |proj g|=       0.42822
At iterate    10  f =      -179.04  |proj g|=       0.17044
At iterate    11  f =      -179.04  |proj g|=       0.20564
At iterate    12  f =      -179.04  |proj g|=     0.0036167

iterations 12
function evaluations 21
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0036167
final function value -179.041

F = -179.041
final  value -179.040659 
converged
 
INFO  [23:22:26.498] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:22:26.566] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:22:26.573] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:23:18.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:23:19.453] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:24:11.617] [mlr3]  Finished benchmark 
INFO  [23:24:11.684] [bbotk] Result of batch 35: 
INFO  [23:24:11.686] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:24:11.686] [bbotk]                   8              4299      0.1235383        0.482 -0.8817567 
INFO  [23:24:11.686] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:24:11.686] [bbotk]          <NA>   0.8190797 b83918d2-2973-45b2-a4be-bc398abde92a 
DEBUG [23:24:12.366] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.198462e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004198462 0.4259523 
  - best initial criterion value(s) :  122.5885 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -122.59  |proj g|=       5.2271
At iterate     1  f =       -126.4  |proj g|=        3.0988
At iterate     2  f =      -130.86  |proj g|=         4.789
At iterate     3  f =      -134.22  |proj g|=           4.5
At iterate     4  f =      -145.48  |proj g|=        3.6116
At iterate     5  f =      -167.78  |proj g|=        1.7241
At iterate     6  f =      -168.62  |proj g|=       0.89806
At iterate     7  f =      -168.62  |proj g|=       0.93518
At iterate     8  f =      -168.62  |proj g|=       0.97153
At iterate     9  f =      -168.62  |proj g|=       0.98699
At iterate    10  f =      -168.62  |proj g|=        1.0112
At iterate    11  f =      -168.62  |proj g|=        1.0098
At iterate    12  f =      -168.63  |proj g|=       0.92441
At iterate    13  f =      -168.64  |proj g|=       0.65511
At iterate    14  f =      -168.65  |proj g|=       0.42016
At iterate    15  f =      -168.65  |proj g|=       0.42012
At iterate    16  f =      -168.65  |proj g|=       0.17615
At iterate    17  f =      -168.65  |proj g|=       0.00691

iterations 17
function evaluations 25
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00691005
final function value -168.65

F = -168.65
final  value -168.650197 
converged
 
INFO  [23:24:12.370] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:24:12.454] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:24:12.466] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:24:13.635] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:24:33.153] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:24:53.496] [mlr3]  Finished benchmark 
INFO  [23:24:53.575] [bbotk] Result of batch 36: 
INFO  [23:24:53.580] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:24:53.580] [bbotk]                   8              1599      0.1459691        0.474 -0.8839286 
INFO  [23:24:53.580] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:24:53.580] [bbotk]          <NA>   0.8196916 b350e4c0-f404-4bad-8964-1c932a479a41 
DEBUG [23:24:54.273] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.126393e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004126393 0.4176464 
  - best initial criterion value(s) :  134.9778 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -134.98  |proj g|=       2.9518
At iterate     1  f =      -137.77  |proj g|=        3.3745
At iterate     2  f =      -145.45  |proj g|=        2.4913
At iterate     3  f =      -148.22  |proj g|=        2.0816
At iterate     4  f =      -148.87  |proj g|=        1.9423
At iterate     5  f =      -149.44  |proj g|=       0.80507
At iterate     6  f =      -149.46  |proj g|=       0.50075
At iterate     7  f =      -149.49  |proj g|=       0.40213
At iterate     8  f =      -149.59  |proj g|=       0.28766
At iterate     9  f =      -150.15  |proj g|=      0.054729
At iterate    10  f =      -151.05  |proj g|=      0.090499
At iterate    11  f =      -151.33  |proj g|=       0.50909
At iterate    12  f =      -151.87  |proj g|=       0.01284
At iterate    13  f =      -151.88  |proj g|=       0.41141
At iterate    14  f =      -151.88  |proj g|=      0.012894
At iterate    15  f =      -151.88  |proj g|=      0.095693
At iterate    16  f =      -151.88  |proj g|=      0.024835
At iterate    17  f =      -151.88  |proj g|=      0.012896

iterations 17
function evaluations 26
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0128955
final function value -151.881

F = -151.881
final  value -151.881195 
converged
 
INFO  [23:24:54.277] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:24:54.333] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:24:54.340] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:25:01.672] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:25:09.104] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:25:16.401] [mlr3]  Finished benchmark 
INFO  [23:25:16.463] [bbotk] Result of batch 37: 
INFO  [23:25:16.465] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:25:16.465] [bbotk]                   5               519       0.203614        0.481 -0.8886304 
INFO  [23:25:16.465] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:25:16.465] [bbotk]          <NA>    0.976259 010c5012-3325-4709-8169-5600af51a4de 
DEBUG [23:25:17.147] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.090582e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004079163 0.4090582 
  - best initial criterion value(s) :  126.6645 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -126.66  |proj g|=       9.5263
At iterate     1  f =       -144.5  |proj g|=        4.6613
At iterate     2  f =      -156.13  |proj g|=        2.9243
At iterate     3  f =      -160.07  |proj g|=        2.0627
At iterate     4  f =      -160.12  |proj g|=        2.0358
At iterate     5  f =      -160.17  |proj g|=        1.9238
At iterate     6  f =      -160.82  |proj g|=        2.0406
At iterate     7  f =      -164.19  |proj g|=        2.3067
At iterate     8  f =      -181.61  |proj g|=        5.3435
At iterate     9  f =       -182.3  |proj g|=      0.082913
At iterate    10  f =      -182.32  |proj g|=       0.49794
At iterate    11  f =      -182.33  |proj g|=       0.40345
At iterate    12  f =      -182.33  |proj g|=      0.005723
At iterate    13  f =      -182.33  |proj g|=      0.017264

iterations 13
function evaluations 19
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0172642
final function value -182.33

F = -182.33
final  value -182.329520 
converged
 
INFO  [23:25:17.151] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:25:17.204] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:25:17.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:26:05.640] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:26:54.306] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:26:55.161] [mlr3]  Finished benchmark 
INFO  [23:26:55.225] [bbotk] Result of batch 38: 
INFO  [23:26:55.227] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:26:55.227] [bbotk]                   8              4014       0.491817        0.485 -0.8824369 
INFO  [23:26:55.227] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:26:55.227] [bbotk]          <NA>   0.8164156 ef9df219-c3d1-4c2c-83c7-a68ab73107e2 
DEBUG [23:26:55.915] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.023006e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.004023006 0.4031691 
  - best initial criterion value(s) :  160.5461 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -160.55  |proj g|=       4.9121
At iterate     1  f =      -167.05  |proj g|=        3.5874
At iterate     2  f =       -188.2  |proj g|=        2.0182
At iterate     3  f =       -189.1  |proj g|=       0.31546
At iterate     4  f =      -189.21  |proj g|=       0.19579
At iterate     5  f =      -189.22  |proj g|=       0.61422
At iterate     6  f =      -189.42  |proj g|=       0.39793
At iterate     7  f =      -189.99  |proj g|=       0.39807
At iterate     8  f =      -190.04  |proj g|=       0.39786
At iterate     9  f =      -190.06  |proj g|=        0.3977
At iterate    10  f =      -190.06  |proj g|=       0.39767
At iterate    11  f =      -190.06  |proj g|=      0.030282
At iterate    12  f =      -190.06  |proj g|=      0.005034

iterations 12
function evaluations 22
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00503403
final function value -190.059

F = -190.059
final  value -190.058948 
converged
 
INFO  [23:26:55.919] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:26:55.973] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:26:55.979] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:27:29.308] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:28:02.259] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:28:35.422] [mlr3]  Finished benchmark 
INFO  [23:28:35.490] [bbotk] Result of batch 39: 
INFO  [23:28:35.491] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:28:35.491] [bbotk]                   3              2705      0.3572843        0.495 -0.8817586 
INFO  [23:28:35.491] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:28:35.491] [bbotk]          <NA>    0.976686 9044b36b-fd29-40c0-b8e7-d61c67663f25 
DEBUG [23:28:36.212] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.989327e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.003989327 0.4004953 
  - best initial criterion value(s) :  165.0964 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -165.1  |proj g|=       10.512
At iterate     1  f =      -177.35  |proj g|=        1.5135
At iterate     2  f =      -187.12  |proj g|=        2.9664
At iterate     3  f =       -189.6  |proj g|=        2.7707
At iterate     4  f =      -191.92  |proj g|=         2.494
At iterate     5  f =      -195.33  |proj g|=        1.9668
At iterate     6  f =      -195.92  |proj g|=        1.5036
At iterate     7  f =      -196.01  |proj g|=        2.1188
At iterate     8  f =      -196.33  |proj g|=        0.3055
At iterate     9  f =      -196.57  |proj g|=       0.77432
At iterate    10  f =      -197.17  |proj g|=       0.95375
At iterate    11  f =      -197.72  |proj g|=       0.39564
At iterate    12  f =      -197.85  |proj g|=       0.39522
At iterate    13  f =      -197.85  |proj g|=       0.39514
At iterate    14  f =      -197.85  |proj g|=       0.39512
At iterate    15  f =      -197.85  |proj g|=      0.045284
At iterate    16  f =      -197.85  |proj g|=      0.004702
At iterate    17  f =      -197.85  |proj g|=       0.17303
At iterate    18  f =      -197.85  |proj g|=      0.004702
At iterate    19  f =      -197.85  |proj g|=      0.004702

iterations 19
function evaluations 33
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00470204
final function value -197.852

F = -197.852
final  value -197.852384 
converged
 
INFO  [23:28:36.216] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:28:36.275] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:28:36.282] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:29:35.205] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:30:33.546] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:31:31.448] [mlr3]  Finished benchmark 
INFO  [23:31:31.516] [bbotk] Result of batch 40: 
INFO  [23:31:31.518] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:31:31.518] [bbotk]                   6              4803      0.4595935        0.504 -0.8807518 
INFO  [23:31:31.518] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:31:31.518] [bbotk]          <NA>   0.9730963 8fd06f98-656f-4cb8-bda3-6a67b8f60da9 
DEBUG [23:31:32.219] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.954161e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.003953678 0.3954161 
  - best initial criterion value(s) :  138.5366 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -138.54  |proj g|=       6.6207
At iterate     1  f =      -161.08  |proj g|=        4.9291
At iterate     2  f =      -162.68  |proj g|=        4.7278
At iterate     3  f =      -164.18  |proj g|=        4.3273
At iterate     4  f =      -166.47  |proj g|=        3.7672
At iterate     5  f =       -170.8  |proj g|=        2.7581
At iterate     6  f =       -186.8  |proj g|=        1.8788
At iterate     7  f =       -191.9  |proj g|=        12.666
At iterate     8  f =      -200.72  |proj g|=         2.685
At iterate     9  f =      -204.22  |proj g|=        2.3454
At iterate    10  f =      -206.06  |proj g|=        2.1816
At iterate    11  f =      -206.88  |proj g|=        1.9926
At iterate    12  f =       -207.3  |proj g|=         2.946
At iterate    13  f =      -207.51  |proj g|=       0.05313
At iterate    14  f =      -207.51  |proj g|=       0.39019
At iterate    15  f =      -207.51  |proj g|=     0.0037828
At iterate    16  f =      -207.51  |proj g|=     0.0037828
At iterate    17  f =      -207.51  |proj g|=     0.0037828

iterations 17
function evaluations 25
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00378283
final function value -207.508

F = -207.508
final  value -207.507716 
converged
 
INFO  [23:31:32.223] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:31:32.286] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:31:32.292] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:31:41.091] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:31:42.185] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:31:50.718] [mlr3]  Finished benchmark 
INFO  [23:31:50.790] [bbotk] Result of batch 41: 
INFO  [23:31:50.791] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:31:50.791] [bbotk]                   8               637     0.06713399        0.501 -0.8795748 
INFO  [23:31:50.791] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:31:50.791] [bbotk]          <NA>   0.8177458 d561dd87-3c65-443b-b332-28b6b02aed19 
DEBUG [23:31:51.498] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.892148e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.00388288 0.3892148 
  - best initial criterion value(s) :  162.1403 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -162.14  |proj g|=      0.88927
At iterate     1  f =      -167.89  |proj g|=        3.2745
At iterate     2  f =      -169.03  |proj g|=        3.2664
At iterate     3  f =       -169.7  |proj g|=        3.1059
At iterate     4  f =      -170.98  |proj g|=        2.6347
At iterate     5  f =       -171.9  |proj g|=        2.1523
At iterate     6  f =      -172.09  |proj g|=        2.3179
At iterate     7  f =      -172.11  |proj g|=         2.286
At iterate     8  f =      -172.19  |proj g|=        2.2511
At iterate     9  f =      -172.82  |proj g|=        2.0782
At iterate    10  f =      -174.12  |proj g|=        1.9063
At iterate    11  f =      -179.27  |proj g|=       0.38479
At iterate    12  f =      -183.51  |proj g|=        3.1645
At iterate    13  f =      -183.67  |proj g|=        1.7709
At iterate    14  f =      -183.75  |proj g|=      0.062842
At iterate    15  f =      -183.75  |proj g|=     0.0096239
At iterate    16  f =      -183.75  |proj g|=     0.0096242
At iterate    17  f =      -183.75  |proj g|=     0.0096243

iterations 17
function evaluations 21
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00962429
final function value -183.746

F = -183.746
final  value -183.746062 
converged
 
INFO  [23:31:51.502] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:31:51.555] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:31:51.562] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:32:04.677] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:32:18.124] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:32:31.683] [mlr3]  Finished benchmark 
INFO  [23:32:31.753] [bbotk] Result of batch 42: 
INFO  [23:32:31.754] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:32:31.754] [bbotk]                   7              1015      0.4397951        0.506 -0.8841532 
INFO  [23:32:31.754] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:32:31.754] [bbotk]          <NA>   0.9757944 27310baf-76ed-4a31-af40-c329a6940dd2 
DEBUG [23:32:32.613] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.859985e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.003815316 0.3859985 
  - best initial criterion value(s) :  157.6104 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -157.61  |proj g|=       5.0843
At iterate     1  f =      -163.06  |proj g|=        4.2837
At iterate     2  f =      -175.57  |proj g|=         2.851
At iterate     3  f =      -178.06  |proj g|=        2.5127
At iterate     4  f =      -179.26  |proj g|=        2.2427
At iterate     5  f =      -180.74  |proj g|=        1.9649
At iterate     6  f =       -180.9  |proj g|=        1.8426
At iterate     7  f =      -180.94  |proj g|=        1.3052
At iterate     8  f =      -180.96  |proj g|=        1.3619
At iterate     9  f =      -181.08  |proj g|=        1.7555
At iterate    10  f =      -181.33  |proj g|=         1.752
At iterate    11  f =      -182.17  |proj g|=        1.7355
At iterate    12  f =      -184.43  |proj g|=        1.7166
At iterate    13  f =      -189.33  |proj g|=        1.7232
At iterate    14  f =      -189.93  |proj g|=        5.3568
At iterate    15  f =      -190.59  |proj g|=        1.1265
At iterate    16  f =      -190.76  |proj g|=       0.38088
At iterate    17  f =       -190.8  |proj g|=       0.38066
At iterate    18  f =       -190.8  |proj g|=       0.38058
At iterate    19  f =       -190.8  |proj g|=       0.31928
At iterate    20  f =       -190.8  |proj g|=     0.0089749

iterations 20
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00897494
final function value -190.799

F = -190.799
final  value -190.798797 
converged
 
INFO  [23:32:32.617] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:32:32.670] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:32:32.677] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:33:14.677] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:33:15.833] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:33:57.488] [mlr3]  Finished benchmark 
INFO  [23:33:57.552] [bbotk] Result of batch 43: 
INFO  [23:33:57.553] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:33:57.553] [bbotk]                   8              3408      0.2733816         0.48 -0.8828227 
INFO  [23:33:57.553] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:33:57.553] [bbotk]          <NA>   0.8180763 e1d957db-91d1-4afe-9699-14e08b88d987 
DEBUG [23:33:58.236] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.801427e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.003770383 0.3801427 
  - best initial criterion value(s) :  167.7409 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -167.74  |proj g|=       11.353
At iterate     1  f =      -182.97  |proj g|=        5.4922
At iterate     2  f =      -206.86  |proj g|=        2.9793
At iterate     3  f =      -212.57  |proj g|=        2.3403
At iterate     4  f =      -213.16  |proj g|=        2.2296
At iterate     5  f =      -214.76  |proj g|=        1.7905
At iterate     6  f =      -214.91  |proj g|=       0.42739
At iterate     7  f =      -215.12  |proj g|=       0.85706
At iterate     8  f =      -215.99  |proj g|=        3.5074
At iterate     9  f =       -218.2  |proj g|=         7.176
At iterate    10  f =      -220.82  |proj g|=        8.3376
At iterate    11  f =       -221.8  |proj g|=        6.2871
At iterate    12  f =      -222.63  |proj g|=       0.69583
At iterate    13  f =      -222.69  |proj g|=       0.23241
At iterate    14  f =       -222.7  |proj g|=      0.003961
At iterate    15  f =       -222.7  |proj g|=       0.37511
At iterate    16  f =       -222.7  |proj g|=     0.0065854

iterations 16
function evaluations 22
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00658545
final function value -222.699

F = -222.699
final  value -222.698525 
converged
 
INFO  [23:33:58.240] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:33:58.295] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:33:58.302] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:34:24.051] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:34:50.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:35:16.396] [mlr3]  Finished benchmark 
INFO  [23:35:16.459] [bbotk] Result of batch 44: 
INFO  [23:35:16.461] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:35:16.461] [bbotk]                   6              2103      0.1553019         0.48 -0.8782002 
INFO  [23:35:16.461] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:35:16.461] [bbotk]          <NA>   0.9766504 a925d708-e4c9-4326-b053-b25a0507a7c0 
DEBUG [23:35:17.163] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.771265e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.003759325 0.3771265 
  - best initial criterion value(s) :  190.0465 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -190.05  |proj g|=       11.317
At iterate     1  f =      -203.53  |proj g|=        1.7492
At iterate     2  f =      -215.72  |proj g|=        3.1851
At iterate     3  f =      -218.57  |proj g|=        2.8971
At iterate     4  f =      -224.06  |proj g|=         2.327
At iterate     5  f =      -225.57  |proj g|=        2.1146
At iterate     6  f =      -226.45  |proj g|=        1.9005
At iterate     7  f =      -226.74  |proj g|=         1.333
At iterate     8  f =      -226.79  |proj g|=       0.37217
At iterate     9  f =      -226.82  |proj g|=       0.37215
At iterate    10  f =      -226.96  |proj g|=        1.5364
At iterate    11  f =      -227.27  |proj g|=         1.893
At iterate    12  f =      -227.29  |proj g|=        1.8925
At iterate    13  f =      -227.31  |proj g|=        1.8941
At iterate    14  f =       -227.4  |proj g|=        1.8536
At iterate    15  f =      -227.53  |proj g|=        0.3722
At iterate    16  f =      -227.54  |proj g|=      0.006799
At iterate    17  f =      -227.54  |proj g|=     0.0040393
At iterate    18  f =      -227.54  |proj g|=     0.0040393

iterations 18
function evaluations 28
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0040393
final function value -227.537

F = -227.537
final  value -227.536612 
converged
 
INFO  [23:35:17.167] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:35:17.221] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:35:17.228] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:35:18.184] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:35:18.905] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:35:19.614] [mlr3]  Finished benchmark 
INFO  [23:35:19.679] [bbotk] Result of batch 45: 
INFO  [23:35:19.680] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:35:19.680] [bbotk]                  10              2054      0.3436367        0.492 -0.8776146 
INFO  [23:35:19.680] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:35:19.680] [bbotk]          <NA>         0.5 af251f35-44a3-4366-961f-2366733864ae 
DEBUG [23:35:20.410] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.888086e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.003830931 0.3888086 
  - best initial criterion value(s) :  154.1391 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -154.14  |proj g|=        12.92
At iterate     1  f =      -181.33  |proj g|=        5.1818
At iterate     2  f =      -197.73  |proj g|=        3.3031
At iterate     3  f =      -207.32  |proj g|=        2.3638
At iterate     4  f =      -208.23  |proj g|=        2.1375
At iterate     5  f =      -209.49  |proj g|=        1.5142
At iterate     6  f =      -209.51  |proj g|=        1.2926
At iterate     7  f =      -209.66  |proj g|=       0.28996
At iterate     8  f =      -209.95  |proj g|=        1.2741
At iterate     9  f =      -210.76  |proj g|=        3.3955
At iterate    10  f =      -212.57  |proj g|=        5.5299
At iterate    11  f =       -216.2  |proj g|=        7.8202
At iterate    12  f =      -219.97  |proj g|=        9.4536
At iterate    13  f =      -222.28  |proj g|=        9.1969
At iterate    14  f =      -223.15  |proj g|=        5.4713
At iterate    15  f =      -224.03  |proj g|=        5.1327
At iterate    16  f =      -224.43  |proj g|=          2.79
At iterate    17  f =       -224.6  |proj g|=       0.38392
At iterate    18  f =      -224.61  |proj g|=       0.38388
At iterate    19  f =      -224.61  |proj g|=       0.38386
At iterate    20  f =      -224.61  |proj g|=     0.0076472

iterations 20
function evaluations 29
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00764719
final function value -224.605

F = -224.605
final  value -224.605494 
converged
 
INFO  [23:35:20.414] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:35:20.475] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:35:20.481] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:35:44.428] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:36:08.508] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:36:32.364] [mlr3]  Finished benchmark 
INFO  [23:36:32.428] [bbotk] Result of batch 46: 
INFO  [23:36:32.430] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:36:32.430] [bbotk]                   5              1948      0.2033707        0.502 -0.8781775 
INFO  [23:36:32.430] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:36:32.430] [bbotk]          <NA>   0.9770398 00c31f1b-05ec-4369-bb3c-03dabc42ebd9 
DEBUG [23:36:33.160] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.858906e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9382 0.9802841 
  - variance bounds :  0.003796977 0.3858906 
  - best initial criterion value(s) :  178.7756 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -178.78  |proj g|=       3.3932
At iterate     1  f =      -229.82  |proj g|=        1.7498
At iterate     2  f =      -231.12  |proj g|=      0.013528
At iterate     3  f =      -231.15  |proj g|=        0.4221
At iterate     4  f =      -231.16  |proj g|=        0.7703
At iterate     5  f =      -231.16  |proj g|=       0.73306
At iterate     6  f =      -231.16  |proj g|=       0.72541
At iterate     7  f =      -231.16  |proj g|=       0.65026
At iterate     8  f =      -231.16  |proj g|=       0.55928
At iterate     9  f =      -231.17  |proj g|=       0.36422
At iterate    10  f =      -231.17  |proj g|=       0.11234
At iterate    11  f =      -231.18  |proj g|=      0.065972
At iterate    12  f =      -231.18  |proj g|=      0.034675
At iterate    13  f =      -231.18  |proj g|=      0.005391
At iterate    14  f =      -231.18  |proj g|=      0.005391

iterations 14
function evaluations 21
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00539104
final function value -231.178

F = -231.178
final  value -231.178186 
converged
 
INFO  [23:36:33.164] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:36:33.217] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:36:33.223] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:36:37.816] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:36:42.156] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:36:46.773] [mlr3]  Finished benchmark 
INFO  [23:36:46.841] [bbotk] Result of batch 47: 
INFO  [23:36:46.842] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:36:46.842] [bbotk]                   6               282       0.173701        0.508 -0.8775745 
INFO  [23:36:46.842] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:36:46.842] [bbotk]          <NA>   0.9747638 c0c34062-f5aa-4c73-bf80-3ddb85c3fefd 
DEBUG [23:36:47.559] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.8289e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003725335 0.38289 
  - best initial criterion value(s) :  193.5063 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -193.51  |proj g|=       5.4782
At iterate     1  f =      -199.32  |proj g|=        3.6736
At iterate     2  f =       -230.7  |proj g|=        2.2138
At iterate     3  f =      -232.86  |proj g|=       0.66461
At iterate     4  f =      -232.92  |proj g|=       0.12756
At iterate     5  f =      -232.96  |proj g|=         1.059
At iterate     6  f =      -234.16  |proj g|=       0.83911
At iterate     7  f =      -234.19  |proj g|=       0.37784
At iterate     8  f =      -234.19  |proj g|=       0.37784
At iterate     9  f =      -234.19  |proj g|=     0.0053763

iterations 9
function evaluations 18
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00537628
final function value -234.185

F = -234.185
final  value -234.185070 
converged
 
INFO  [23:36:47.563] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:36:47.619] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:36:47.626] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:37:18.309] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:37:49.244] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:38:20.108] [mlr3]  Finished benchmark 
INFO  [23:38:20.171] [bbotk] Result of batch 48: 
INFO  [23:38:20.173] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:38:20.173] [bbotk]                   6              2497      0.1490877        0.513 -0.8767264 
INFO  [23:38:20.173] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:38:20.173] [bbotk]          <NA>   0.9765336 ae5c71c9-7272-4990-8724-26c7cff3faf2 
DEBUG [23:38:20.899] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.799698e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.00370858 0.3799698 
  - best initial criterion value(s) :  168.4886 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -168.49  |proj g|=       5.0308
At iterate     1  f =      -175.31  |proj g|=        1.9826
At iterate     2  f =      -180.86  |proj g|=        4.6705
At iterate     3  f =      -183.66  |proj g|=        4.4483
At iterate     4  f =      -203.59  |proj g|=        3.3149
At iterate     5  f =       -220.3  |proj g|=        11.638
At iterate     6  f =      -224.99  |proj g|=        10.456
At iterate     7  f =      -226.48  |proj g|=        9.4651
At iterate     8  f =      -226.79  |proj g|=        8.7118
At iterate     9  f =       -226.8  |proj g|=        8.6188
At iterate    10  f =      -226.84  |proj g|=        8.3423
At iterate    11  f =      -226.95  |proj g|=        7.5242
At iterate    12  f =      -227.19  |proj g|=        5.9226
At iterate    13  f =      -227.66  |proj g|=        2.8789
At iterate    14  f =      -228.18  |proj g|=       0.37554
At iterate    15  f =       -228.4  |proj g|=       0.37516
At iterate    16  f =      -228.43  |proj g|=       0.37497
At iterate    17  f =      -228.43  |proj g|=       0.37492
At iterate    18  f =      -228.43  |proj g|=       0.16176
At iterate    19  f =      -228.43  |proj g|=     0.0077551

iterations 19
function evaluations 26
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00775511
final function value -228.434

F = -228.434
final  value -228.433525 
converged
 
INFO  [23:38:20.901] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:38:20.944] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:38:20.950] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:38:39.419] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:38:40.264] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:38:58.804] [mlr3]  Finished benchmark 
INFO  [23:38:58.878] [bbotk] Result of batch 49: 
INFO  [23:38:58.880] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:38:58.880] [bbotk]                   8              1487      0.4490921        0.509 -0.8780306 
INFO  [23:38:58.880] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:38:58.880] [bbotk]          <NA>   0.8186187 a16a26a9-627e-4ca6-b0c5-49a611ac9e80 
DEBUG [23:38:59.606] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.747068e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.00366355 0.3747068 
  - best initial criterion value(s) :  214.2652 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -214.27  |proj g|=       4.2828
At iterate     1  f =      -214.39  |proj g|=        4.2459
At iterate     2  f =      -214.68  |proj g|=        4.2379
At iterate     3  f =      -215.89  |proj g|=        4.1098
At iterate     4  f =      -217.58  |proj g|=        4.0107
At iterate     5  f =       -222.7  |proj g|=        3.6324
At iterate     6  f =      -235.57  |proj g|=        2.4182
At iterate     7  f =      -236.91  |proj g|=        2.2186
At iterate     8  f =      -238.77  |proj g|=       0.14779
At iterate     9  f =      -238.78  |proj g|=       0.36975
At iterate    10  f =      -238.78  |proj g|=     0.0069924
At iterate    11  f =      -238.78  |proj g|=     0.0065763
At iterate    12  f =      -238.78  |proj g|=     0.0065763

iterations 12
function evaluations 20
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00657629
final function value -238.781

F = -238.781
final  value -238.780988 
converged
 
INFO  [23:38:59.610] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:38:59.665] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:38:59.672] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:39:18.155] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:39:36.469] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:39:54.576] [mlr3]  Finished benchmark 
INFO  [23:39:54.640] [bbotk] Result of batch 50: 
INFO  [23:39:54.642] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:39:54.642] [bbotk]                   5              1443      0.2558645        0.515 -0.8768459 
INFO  [23:39:54.642] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:39:54.642] [bbotk]          <NA>   0.9770333 a5f72a05-a16b-4aa5-b82f-89bed6e2887c 
DEBUG [23:39:55.386] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.71944e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003624615 0.371944 
  - best initial criterion value(s) :  162.8399 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -162.84  |proj g|=       12.729
At iterate     1  f =      -185.26  |proj g|=        5.3251
At iterate     2  f =       -208.5  |proj g|=        3.0743
At iterate     3  f =       -215.9  |proj g|=        2.4008
At iterate     4  f =      -217.08  |proj g|=        2.1788
At iterate     5  f =      -218.89  |proj g|=        1.3876
At iterate     6  f =      -218.93  |proj g|=       0.56962
At iterate     7  f =      -218.95  |proj g|=       0.47366
At iterate     8  f =      -218.96  |proj g|=       0.52044
At iterate     9  f =         -219  |proj g|=       0.63376
At iterate    10  f =      -219.08  |proj g|=       0.82004
At iterate    11  f =      -219.32  |proj g|=        1.3404
At iterate    12  f =      -219.96  |proj g|=        1.6991
At iterate    13  f =      -221.71  |proj g|=        1.7532
At iterate    14  f =      -225.05  |proj g|=        1.8663
At iterate    15  f =      -226.09  |proj g|=       0.39851
At iterate    16  f =      -226.77  |proj g|=       0.55118
At iterate    17  f =      -226.96  |proj g|=       0.36712
At iterate    18  f =      -226.99  |proj g|=       0.36695
At iterate    19  f =      -226.99  |proj g|=        0.3669
At iterate    20  f =      -226.99  |proj g|=      0.034289
At iterate    21  f =      -226.99  |proj g|=      0.010533

iterations 21
function evaluations 30
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0105331
final function value -226.993

F = -226.993
final  value -226.992540 
converged
 
INFO  [23:39:55.390] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:39:55.444] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:39:55.450] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:40:31.481] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:41:08.463] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:41:44.616] [mlr3]  Finished benchmark 
INFO  [23:41:44.682] [bbotk] Result of batch 51: 
INFO  [23:41:44.684] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:41:44.684] [bbotk]                   7              2968      0.0872491        0.516 -0.8792955 
INFO  [23:41:44.684] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:41:44.684] [bbotk]          <NA>   0.9764857 e8d55e8f-67db-498e-8342-ca2f67450044 
DEBUG [23:41:45.448] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.691724e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003611016 0.3691724 
  - best initial criterion value(s) :  217.426 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -217.43  |proj g|=       13.028
At iterate     1  f =      -237.19  |proj g|=        4.0251
At iterate     2  f =      -245.47  |proj g|=        2.6485
At iterate     3  f =       -248.7  |proj g|=        2.5127
At iterate     4  f =      -250.01  |proj g|=        2.3216
At iterate     5  f =      -251.84  |proj g|=        1.7516
At iterate     6  f =      -251.96  |proj g|=        1.8443
At iterate     7  f =      -252.38  |proj g|=       0.70272
At iterate     8  f =      -252.44  |proj g|=        1.1996
At iterate     9  f =      -252.45  |proj g|=       0.92727
At iterate    10  f =      -252.46  |proj g|=        0.7431
At iterate    11  f =      -252.49  |proj g|=       0.17697
At iterate    12  f =      -252.55  |proj g|=        0.5052
At iterate    13  f =      -252.71  |proj g|=        1.9575
At iterate    14  f =      -252.99  |proj g|=        3.7621
At iterate    15  f =      -253.55  |proj g|=        6.2025
At iterate    16  f =      -253.93  |proj g|=          9.22
At iterate    17  f =       -255.9  |proj g|=        10.119
At iterate    18  f =      -259.16  |proj g|=        6.9634
At iterate    19  f =      -260.99  |proj g|=        2.8179
At iterate    20  f =      -261.16  |proj g|=       0.36441
At iterate    21  f =      -261.17  |proj g|=      0.018592
At iterate    22  f =      -261.17  |proj g|=       0.36439
At iterate    23  f =      -261.17  |proj g|=       0.36439
At iterate    24  f =      -261.17  |proj g|=      0.041061

iterations 24
function evaluations 30
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0410605
final function value -261.166

F = -261.166
final  value -261.166343 
converged
 
INFO  [23:41:45.452] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:41:45.507] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:41:45.514] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:42:33.492] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:43:19.778] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:44:05.815] [mlr3]  Finished benchmark 
INFO  [23:44:05.891] [bbotk] Result of batch 52: 
INFO  [23:44:05.893] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:44:05.893] [bbotk]                   7              3859     0.09350653        0.524 -0.8750344 
INFO  [23:44:05.893] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:44:05.893] [bbotk]          <NA>   0.9762096 ad109e87-a68e-46ca-bfd5-1e1f7964955f 
DEBUG [23:44:06.640] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.66405e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003606392 0.366405 
  - best initial criterion value(s) :  203.2023 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -203.2  |proj g|=       1.6341
At iterate     1  f =      -211.03  |proj g|=        4.6114
At iterate     2  f =      -214.33  |proj g|=         4.483
At iterate     3  f =      -216.08  |proj g|=        4.2682
At iterate     4  f =      -218.98  |proj g|=        3.8334
At iterate     5  f =      -225.46  |proj g|=        3.0145
At iterate     6  f =      -233.54  |proj g|=        1.9874
At iterate     7  f =      -233.59  |proj g|=        1.8878
At iterate     8  f =       -233.7  |proj g|=        1.9208
At iterate     9  f =      -234.14  |proj g|=        1.9706
At iterate    10  f =      -239.52  |proj g|=        2.3165
At iterate    11  f =      -242.16  |proj g|=        2.3804
At iterate    12  f =      -244.02  |proj g|=        1.9039
At iterate    13  f =       -245.3  |proj g|=        1.8439
At iterate    14  f =      -245.45  |proj g|=        0.3858
At iterate    15  f =      -245.46  |proj g|=       0.02953
At iterate    16  f =      -245.46  |proj g|=     0.0094122
At iterate    17  f =      -245.46  |proj g|=     0.0094123
At iterate    18  f =      -245.46  |proj g|=     0.0094123

iterations 18
function evaluations 26
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00941231
final function value -245.456

F = -245.456
final  value -245.456069 
converged
 
INFO  [23:44:06.644] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:44:06.707] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:44:06.720] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:44:56.955] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:45:48.274] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:46:39.028] [mlr3]  Finished benchmark 
INFO  [23:46:39.092] [bbotk] Result of batch 53: 
INFO  [23:46:39.094] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:46:39.094] [bbotk]                   3              4165       0.192431        0.525 -0.8773624 
INFO  [23:46:39.094] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:46:39.094] [bbotk]          <NA>   0.9766864 fadf75dc-a5ec-4daa-b748-84b799d30276 
DEBUG [23:46:39.843] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.636698e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003592631 0.3636698 
  - best initial criterion value(s) :  205.6849 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -205.68  |proj g|=       6.4839
At iterate     1  f =      -207.88  |proj g|=        5.7651
At iterate     2  f =      -228.49  |proj g|=         4.581
ys=-2.473e+00  -gs= 1.768e+01, BFGS update SKIPPED
At iterate     3  f =      -230.13  |proj g|=        3.9769
At iterate     4  f =      -242.26  |proj g|=        3.4379
At iterate     5  f =      -243.48  |proj g|=        3.2969
At iterate     6  f =      -248.63  |proj g|=        2.6699
At iterate     7  f =      -255.67  |proj g|=        5.2563
At iterate     8  f =      -256.89  |proj g|=        3.9907
At iterate     9  f =      -257.26  |proj g|=       0.81081
At iterate    10  f =      -257.28  |proj g|=      0.044467
At iterate    11  f =      -257.28  |proj g|=      0.016184
At iterate    12  f =      -257.28  |proj g|=     0.0080121
At iterate    13  f =      -257.28  |proj g|=     0.0080121

iterations 13
function evaluations 24
segments explored during Cauchy searches 16
BFGS updates skipped 1
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0080121
final function value -257.281

F = -257.281
final  value -257.281098 
converged
 
INFO  [23:46:39.847] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:46:39.900] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:46:39.907] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:47:27.890] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:48:16.282] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:49:03.570] [mlr3]  Finished benchmark 
INFO  [23:49:03.634] [bbotk] Result of batch 54: 
INFO  [23:49:03.635] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:49:03.635] [bbotk]                   7              3882      0.1743954        0.524 -0.8760062 
INFO  [23:49:03.635] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:49:03.635] [bbotk]          <NA>   0.9750031 eee1b750-64f5-47bf-994f-e08f0349829e 
DEBUG [23:49:04.515] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.608967e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003586838 0.3608967 
  - best initial criterion value(s) :  173.613 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -173.61  |proj g|=       5.4435
At iterate     1  f =      -238.71  |proj g|=       0.36809
At iterate     2  f =      -245.14  |proj g|=        3.6791
At iterate     3  f =       -249.1  |proj g|=        3.5155
At iterate     4  f =      -255.37  |proj g|=        3.1066
At iterate     5  f =      -260.42  |proj g|=        2.6982
At iterate     6  f =      -269.22  |proj g|=        6.7531
At iterate     7  f =      -270.36  |proj g|=        3.5554
At iterate     8  f =      -270.64  |proj g|=        1.3335
At iterate     9  f =      -270.67  |proj g|=      0.040558
At iterate    10  f =      -270.67  |proj g|=      0.010276
At iterate    11  f =      -270.67  |proj g|=        0.2912
At iterate    12  f =      -270.67  |proj g|=      0.046252

iterations 12
function evaluations 21
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.046252
final function value -270.673

F = -270.673
final  value -270.673307 
converged
 
INFO  [23:49:04.519] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:49:04.573] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:49:04.579] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:49:05.290] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:49:06.239] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:49:07.197] [mlr3]  Finished benchmark 
INFO  [23:49:07.263] [bbotk] Result of batch 55: 
INFO  [23:49:07.265] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:49:07.265] [bbotk]                  10              2249       0.278153        0.505 -0.8744761 
INFO  [23:49:07.265] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:49:07.265] [bbotk]          <NA>         0.5 89e013fa-07ea-4800-bfff-447e58455c6d 
DEBUG [23:49:07.984] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.721085e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003670628 0.3721085 
  - best initial criterion value(s) :  229.1435 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -229.14  |proj g|=       5.6675
At iterate     1  f =      -234.98  |proj g|=        1.2659
At iterate     2  f =      -249.87  |proj g|=        3.3799
At iterate     3  f =      -252.87  |proj g|=        3.1222
At iterate     4  f =      -263.75  |proj g|=       0.30842
At iterate     5  f =      -264.78  |proj g|=        0.6051
At iterate     6  f =      -265.12  |proj g|=       0.15136
At iterate     7  f =      -265.12  |proj g|=       0.36753
At iterate     8  f =      -265.12  |proj g|=        0.3675
At iterate     9  f =      -265.12  |proj g|=      0.009006
At iterate    10  f =      -265.12  |proj g|=      0.068122

iterations 10
function evaluations 19
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0681216
final function value -265.121

F = -265.121
final  value -265.120734 
converged
 
INFO  [23:49:07.988] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:49:08.043] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:49:08.050] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:49:45.327] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:50:23.041] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:51:02.003] [mlr3]  Finished benchmark 
INFO  [23:51:02.068] [bbotk] Result of batch 56: 
INFO  [23:51:02.069] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:51:02.069] [bbotk]                   4              3102      0.3298643        0.506 -0.8755798 
INFO  [23:51:02.069] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:51:02.069] [bbotk]          <NA>   0.9763594 9523a120-48ed-498d-a475-4cde5aa64ed1 
DEBUG [23:51:02.799] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.694353e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003666021 0.3694353 
  - best initial criterion value(s) :  224.0663 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -224.07  |proj g|=       11.956
At iterate     1  f =      -239.29  |proj g|=        1.7198
At iterate     2  f =      -254.67  |proj g|=        3.4688
At iterate     3  f =      -256.23  |proj g|=        3.2125
At iterate     4  f =      -266.45  |proj g|=        2.4476
At iterate     5  f =      -269.78  |proj g|=        1.7436
At iterate     6  f =      -270.51  |proj g|=        4.1059
At iterate     7  f =      -270.84  |proj g|=       0.29866
At iterate     8  f =      -270.87  |proj g|=      0.045003
At iterate     9  f =      -270.88  |proj g|=       0.36488
At iterate    10  f =      -270.88  |proj g|=     0.0089411
At iterate    11  f =      -270.88  |proj g|=     0.0089411

iterations 11
function evaluations 20
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00894115
final function value -270.876

F = -270.876
final  value -270.875759 
converged
 
INFO  [23:51:02.803] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:51:02.874] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:51:02.883] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:51:56.429] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:52:49.574] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:52:50.433] [mlr3]  Finished benchmark 
INFO  [23:52:50.531] [bbotk] Result of batch 57: 
INFO  [23:52:50.533] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:52:50.533] [bbotk]                   8              4376      0.1918391        0.518 -0.8750366 
INFO  [23:52:50.533] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:52:50.533] [bbotk]          <NA>   0.8182522 fceb0939-c12c-411e-a27e-ff51430b6e64 
DEBUG [23:52:51.318] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.648791e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003608749 0.3648791 
  - best initial criterion value(s) :  216.4737 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -216.47  |proj g|=       5.7717
At iterate     1  f =      -237.86  |proj g|=        2.3932
At iterate     2  f =      -270.63  |proj g|=        2.5416
At iterate     3  f =      -277.14  |proj g|=        12.843
At iterate     4  f =      -277.39  |proj g|=        12.822
At iterate     5  f =      -278.81  |proj g|=        1.7778
At iterate     6  f =      -279.72  |proj g|=        3.6031
At iterate     7  f =      -279.75  |proj g|=        3.2327
At iterate     8  f =      -279.81  |proj g|=        2.4226
At iterate     9  f =      -279.89  |proj g|=        1.9619
At iterate    10  f =      -280.21  |proj g|=        0.7118
At iterate    11  f =      -280.86  |proj g|=       0.43507
At iterate    12  f =      -283.95  |proj g|=        1.0207
At iterate    13  f =      -284.35  |proj g|=        1.8102
At iterate    14  f =      -284.61  |proj g|=         1.677
At iterate    15  f =       -284.7  |proj g|=       0.36049
At iterate    16  f =       -284.7  |proj g|=       0.36044
At iterate    17  f =       -284.7  |proj g|=       0.11415
At iterate    18  f =       -284.7  |proj g|=     0.0073368
At iterate    19  f =       -284.7  |proj g|=      0.060185

iterations 19
function evaluations 30
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.060185
final function value -284.704

F = -284.704
final  value -284.704261 
converged
 
INFO  [23:52:51.323] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:52:51.381] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:52:51.389] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:52:52.283] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:52:53.245] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:52:54.192] [mlr3]  Finished benchmark 
INFO  [23:52:54.264] [bbotk] Result of batch 58: 
INFO  [23:52:54.265] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:52:54.265] [bbotk]                   9              3405      0.3098447        0.553 -0.8733683 
INFO  [23:52:54.265] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:52:54.265] [bbotk]          <NA>         0.5 c19049bc-2a4e-44dd-ab9d-b3de3836a10a 
DEBUG [23:52:55.020] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.753448e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003693163 0.3753448 
  - best initial criterion value(s) :  251.2136 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -251.21  |proj g|=       9.4134
At iterate     1  f =      -259.21  |proj g|=        1.7296
At iterate     2  f =      -271.94  |proj g|=        2.7417
At iterate     3  f =      -275.41  |proj g|=        2.0563
At iterate     4  f =      -278.62  |proj g|=          1.45
At iterate     5  f =      -278.62  |proj g|=        1.8661
At iterate     6  f =      -278.73  |proj g|=       0.61872
At iterate     7  f =      -284.35  |proj g|=       0.96335
At iterate     8  f =      -284.41  |proj g|=       0.37089
At iterate     9  f =      -284.41  |proj g|=       0.37088
At iterate    10  f =      -284.41  |proj g|=       0.23621
At iterate    11  f =      -284.41  |proj g|=     0.0084318

iterations 11
function evaluations 19
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00843179
final function value -284.413

F = -284.413
final  value -284.413219 
converged
 
INFO  [23:52:55.024] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:52:55.077] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:52:55.083] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:53:47.454] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:54:38.732] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:55:31.591] [mlr3]  Finished benchmark 
INFO  [23:55:31.657] [bbotk] Result of batch 59: 
INFO  [23:55:31.658] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:55:31.658] [bbotk]                   4              4282      0.1193292        0.522 -0.8734169 
INFO  [23:55:31.658] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:55:31.658] [bbotk]          <NA>   0.9768391 957acca0-374c-49d4-859b-b81a5c0ee9ad 
DEBUG [23:55:32.408] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.728445e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003687907 0.3728445 
  - best initial criterion value(s) :  259.2408 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -259.24  |proj g|=       2.5884
At iterate     1  f =       -266.6  |proj g|=         4.791
At iterate     2  f =      -270.94  |proj g|=        4.4921
At iterate     3  f =       -273.3  |proj g|=        4.2389
At iterate     4  f =      -276.49  |proj g|=        3.8418
At iterate     5  f =      -280.46  |proj g|=        3.4698
At iterate     6  f =      -292.92  |proj g|=       0.40347
At iterate     7  f =      -299.06  |proj g|=        6.6246
At iterate     8  f =      -302.92  |proj g|=       0.46188
At iterate     9  f =      -303.83  |proj g|=         1.902
At iterate    10  f =      -304.25  |proj g|=        1.5908
At iterate    11  f =      -304.29  |proj g|=       0.36848
At iterate    12  f =      -304.29  |proj g|=     0.0058404
At iterate    13  f =      -304.29  |proj g|=       0.36847
At iterate    14  f =      -304.29  |proj g|=     0.0058404

iterations 14
function evaluations 22
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00584041
final function value -304.294

F = -304.294
final  value -304.294005 
converged
 
INFO  [23:55:32.412] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:55:32.466] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:55:32.473] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:55:54.512] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:56:16.788] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:56:39.131] [mlr3]  Finished benchmark 
INFO  [23:56:39.196] [bbotk] Result of batch 60: 
INFO  [23:56:39.198] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:56:39.198] [bbotk]                   4              1782      0.1569571         0.53 -0.8711797 
INFO  [23:56:39.198] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:56:39.198] [bbotk]          <NA>   0.9766183 9ea3df70-3926-45f7-ae67-bead341781b1 
DEBUG [23:56:39.974] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.703473e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003647905 0.3703473 
  - best initial criterion value(s) :  242.6396 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -242.64  |proj g|=       12.487
At iterate     1  f =      -268.48  |proj g|=        5.4902
At iterate     2  f =      -288.26  |proj g|=        3.6321
At iterate     3  f =      -306.63  |proj g|=        8.2465
At iterate     4  f =      -306.81  |proj g|=        8.4768
At iterate     5  f =      -308.28  |proj g|=       0.36611
At iterate     6  f =      -308.29  |proj g|=       0.36606
At iterate     7  f =      -308.33  |proj g|=       0.65828
At iterate     8  f =      -308.36  |proj g|=       0.85382
At iterate     9  f =      -308.49  |proj g|=        1.2258
At iterate    10  f =      -308.78  |proj g|=        1.9493
At iterate    11  f =      -309.18  |proj g|=       0.83031
At iterate    12  f =      -310.23  |proj g|=        2.1612
At iterate    13  f =      -311.29  |proj g|=        2.2604
At iterate    14  f =      -312.51  |proj g|=        2.0892
At iterate    15  f =      -313.34  |proj g|=        1.9673
At iterate    16  f =      -313.63  |proj g|=       0.82893
At iterate    17  f =      -313.72  |proj g|=      0.028103
At iterate    18  f =      -313.73  |proj g|=     0.0099862
At iterate    19  f =      -313.73  |proj g|=       0.36602
At iterate    20  f =      -313.73  |proj g|=     0.0052369

iterations 20
function evaluations 27
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00523689
final function value -313.726

F = -313.726
final  value -313.725615 
converged
 
INFO  [23:56:39.978] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:56:40.031] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:56:40.037] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:57:04.085] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:57:27.855] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [23:57:51.679] [mlr3]  Finished benchmark 
INFO  [23:57:51.743] [bbotk] Result of batch 61: 
INFO  [23:57:51.745] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [23:57:51.745] [bbotk]                   5              1919      0.2449426         0.54 -0.8704983 
INFO  [23:57:51.745] [bbotk]  errors.model classif.auc                                uhash 
INFO  [23:57:51.745] [bbotk]          <NA>   0.9768784 838bc51c-d285-491c-b705-aedfa57825dd 
DEBUG [23:57:52.496] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.678702e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003626654 0.3678702 
  - best initial criterion value(s) :  256.8618 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -256.86  |proj g|=       3.2406
At iterate     1  f =      -300.59  |proj g|=        1.9607
At iterate     2  f =      -301.84  |proj g|=        2.0286
At iterate     3  f =      -302.01  |proj g|=        2.0101
At iterate     4  f =      -302.13  |proj g|=        1.9706
At iterate     5  f =      -302.43  |proj g|=          1.89
At iterate     6  f =      -302.66  |proj g|=       0.36359
At iterate     7  f =      -302.66  |proj g|=     0.0083618
At iterate     8  f =      -302.66  |proj g|=       0.36356
At iterate     9  f =      -302.66  |proj g|=     0.0083623

iterations 9
function evaluations 17
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00836228
final function value -302.664

F = -302.664
final  value -302.664353 
converged
 
INFO  [23:57:52.500] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:57:52.553] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:57:52.559] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [23:58:36.179] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [23:59:19.877] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:00:03.383] [mlr3]  Finished benchmark 
INFO  [00:00:03.449] [bbotk] Result of batch 62: 
INFO  [00:00:03.451] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:00:03.451] [bbotk]                   7              3511      0.3429054         0.54 -0.8721139 
INFO  [00:00:03.451] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:00:03.451] [bbotk]          <NA>   0.9736381 07ae6519-9bdc-4cc2-b232-9d45cca0704e 
DEBUG [00:00:04.339] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.653098e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003620132 0.3653098 
  - best initial criterion value(s) :  253.0993 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -253.1  |proj g|=       5.7181
At iterate     1  f =      -271.26  |proj g|=        3.0564
At iterate     2  f =      -301.43  |proj g|=        2.2731
At iterate     3  f =      -301.77  |proj g|=        2.2346
At iterate     4  f =      -304.02  |proj g|=        5.0834
At iterate     5  f =      -304.25  |proj g|=        5.8429
At iterate     6  f =      -304.43  |proj g|=        1.8292
At iterate     7  f =      -304.65  |proj g|=        1.1612
At iterate     8  f =      -304.66  |proj g|=        1.2675
At iterate     9  f =      -304.77  |proj g|=        1.9349
At iterate    10  f =      -304.93  |proj g|=        2.4706
At iterate    11  f =      -305.58  |proj g|=        4.5168
At iterate    12  f =      -306.12  |proj g|=        5.7609
At iterate    13  f =      -306.61  |proj g|=        3.9112
At iterate    14  f =      -306.89  |proj g|=        1.0934
At iterate    15  f =      -306.91  |proj g|=      0.036872
At iterate    16  f =      -306.91  |proj g|=       0.36103
At iterate    17  f =      -306.91  |proj g|=       0.35639

iterations 17
function evaluations 25
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.356394
final function value -306.908

F = -306.908
final  value -306.908229 
converged
 
INFO  [00:00:04.343] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:00:04.406] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:00:04.413] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:00:42.158] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:01:19.841] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:01:56.595] [mlr3]  Finished benchmark 
INFO  [00:01:56.662] [bbotk] Result of batch 63: 
INFO  [00:01:56.663] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:01:56.663] [bbotk]                   7              3062    0.003806013        0.637 -0.8719073 
INFO  [00:01:56.663] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:01:56.663] [bbotk]          <NA>   0.9685799 1c15d505-4b81-4937-9bd0-c9158e69efe0 
DEBUG [00:01:57.615] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.626263e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.00360618 0.3626263 
  - best initial criterion value(s) :  249.7005 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -249.7  |proj g|=       7.1886
At iterate     1  f =      -251.75  |proj g|=       0.81108
At iterate     2  f =      -266.23  |proj g|=        5.9869
At iterate     3  f =      -272.92  |proj g|=        5.8195
At iterate     4  f =      -276.85  |proj g|=        5.5964
At iterate     5  f =      -286.08  |proj g|=        5.0986
At iterate     6  f =      -291.98  |proj g|=        4.4904
At iterate     7  f =      -323.17  |proj g|=        1.3811
At iterate     8  f =      -323.18  |proj g|=        1.3376
At iterate     9  f =      -323.22  |proj g|=     0.0063785
At iterate    10  f =      -323.22  |proj g|=         0.173
At iterate    11  f =      -323.22  |proj g|=     0.0063785

iterations 11
function evaluations 21
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00637847
final function value -323.216

F = -323.216
final  value -323.215883 
converged
 
INFO  [00:01:57.619] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:01:57.673] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:01:57.679] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:01:58.774] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:02:58.132] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:03:57.915] [mlr3]  Finished benchmark 
INFO  [00:03:57.980] [bbotk] Result of batch 64: 
INFO  [00:03:57.982] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:03:57.982] [bbotk]                   8              4893     0.01344838        0.684 -0.8690797 
INFO  [00:03:57.982] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:03:57.982] [bbotk]          <NA>   0.8186618 ccdf553c-a319-4256-9ea6-88a819e2fd76 
DEBUG [00:03:58.927] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.585384e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003545576 0.3585384 
  - best initial criterion value(s) :  266.4164 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -266.42  |proj g|=       5.9521
At iterate     1  f =      -281.57  |proj g|=        3.7205
At iterate     2  f =       -285.2  |proj g|=        5.4922
At iterate     3  f =      -287.83  |proj g|=        5.2693
At iterate     4  f =      -316.01  |proj g|=        3.1662
At iterate     5  f =      -322.25  |proj g|=        3.1107
At iterate     6  f =      -322.42  |proj g|=        3.1057
At iterate     7  f =      -323.14  |proj g|=        3.0338
At iterate     8  f =      -323.65  |proj g|=        3.0098
At iterate     9  f =       -327.3  |proj g|=        2.6842
At iterate    10  f =      -332.51  |proj g|=        2.4978
At iterate    11  f =      -333.02  |proj g|=        2.6891
At iterate    12  f =      -333.15  |proj g|=       0.41159
At iterate    13  f =      -333.16  |proj g|=      0.012923
At iterate    14  f =      -333.16  |proj g|=      0.022375
At iterate    15  f =      -333.16  |proj g|=       0.35424
At iterate    16  f =      -333.16  |proj g|=     0.0054889

iterations 16
function evaluations 23
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00548891
final function value -333.16

F = -333.16
final  value -333.160069 
converged
 
INFO  [00:03:58.931] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:03:58.986] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:03:58.993] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:04:38.029] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:05:17.489] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:05:56.509] [mlr3]  Finished benchmark 
INFO  [00:05:56.574] [bbotk] Result of batch 65: 
INFO  [00:05:56.576] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:05:56.576] [bbotk]                   6              3215     0.03064731        0.713 -0.8690305 
INFO  [00:05:56.576] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:05:56.576] [bbotk]          <NA>   0.9762605 9e3395a1-6c3a-47da-85b9-5ba00aa68071 
DEBUG [00:05:57.372] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.561792e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003544401 0.3561792 
  - best initial criterion value(s) :  269.9273 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -269.93  |proj g|=       6.8537
At iterate     1  f =      -275.93  |proj g|=        6.0782
At iterate     2  f =      -299.68  |proj g|=        4.6868
At iterate     3  f =      -302.37  |proj g|=        4.3825
At iterate     4  f =      -308.67  |proj g|=        4.1248
At iterate     5  f =      -310.63  |proj g|=        3.9217
At iterate     6  f =      -313.33  |proj g|=        3.6907
At iterate     7  f =       -322.5  |proj g|=        2.9867
At iterate     8  f =      -331.28  |proj g|=        6.7452
At iterate     9  f =         -332  |proj g|=        5.7918
At iterate    10  f =      -332.71  |proj g|=       0.20373
At iterate    11  f =      -332.73  |proj g|=        0.1345
At iterate    12  f =      -332.73  |proj g|=       0.35181
At iterate    13  f =      -332.73  |proj g|=       0.19186
At iterate    14  f =      -332.73  |proj g|=     0.0057825

iterations 14
function evaluations 26
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00578248
final function value -332.729

F = -332.729
final  value -332.729038 
converged
 
INFO  [00:05:57.376] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:05:57.434] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:05:57.441] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:06:30.347] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:07:03.687] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:07:36.682] [mlr3]  Finished benchmark 
INFO  [00:07:36.747] [bbotk] Result of batch 66: 
INFO  [00:07:36.749] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:07:36.749] [bbotk]                   4              2696      0.1282773        0.545 -0.8707602 
INFO  [00:07:36.749] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:07:36.749] [bbotk]          <NA>   0.9768025 b7d6d5a3-1574-4be3-ad91-6a96d5a57485 
DEBUG [00:07:37.530] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.538495e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003529057 0.3538495 
  - best initial criterion value(s) :  285.0228 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -285.02  |proj g|=      0.22549
At iterate     1  f =      -300.68  |proj g|=        4.5983
At iterate     2  f =      -307.05  |proj g|=        4.5729
At iterate     3  f =      -309.15  |proj g|=        4.5505
At iterate     4  f =      -312.05  |proj g|=         4.526
At iterate     5  f =      -313.04  |proj g|=        4.5255
At iterate     6  f =      -313.05  |proj g|=        4.5251
At iterate     7  f =      -313.06  |proj g|=        4.5242
At iterate     8  f =      -313.07  |proj g|=        4.5231
At iterate     9  f =       -313.1  |proj g|=        4.5185
At iterate    10  f =      -313.18  |proj g|=        4.5076
At iterate    11  f =      -313.38  |proj g|=        4.4773
At iterate    12  f =      -313.87  |proj g|=        4.3998
At iterate    13  f =      -315.09  |proj g|=        4.2043
At iterate    14  f =      -318.08  |proj g|=        2.5389
At iterate    15  f =      -326.96  |proj g|=         5.076
At iterate    16  f =      -340.62  |proj g|=        8.3904
At iterate    17  f =      -342.15  |proj g|=       0.52416
At iterate    18  f =      -342.17  |proj g|=       0.39343
At iterate    19  f =      -342.17  |proj g|=     0.0051574
At iterate    20  f =      -342.17  |proj g|=       0.34949
At iterate    21  f =      -342.17  |proj g|=     0.0051568

iterations 21
function evaluations 30
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00515676
final function value -342.171

F = -342.171
final  value -342.171445 
converged
 
INFO  [00:07:37.534] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:07:37.588] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:07:37.595] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:08:02.495] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:08:27.000] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:08:51.279] [mlr3]  Finished benchmark 
INFO  [00:08:51.347] [bbotk] Result of batch 67: 
INFO  [00:08:51.348] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:08:51.348] [bbotk]                   4              1988     0.07969679        0.538 -0.8700794 
INFO  [00:08:51.348] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:08:51.348] [bbotk]          <NA>   0.9760864 f9345e31-c912-4b0f-b55f-4547fb313df2 
DEBUG [00:08:52.186] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.51515e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.00351515 0.3520643 
  - best initial criterion value(s) :  309.37 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -309.37  |proj g|=       4.4804
At iterate     1  f =      -316.14  |proj g|=      0.082623
At iterate     2  f =      -342.06  |proj g|=        2.0186
At iterate     3  f =       -342.7  |proj g|=        1.5178
At iterate     4  f =      -342.74  |proj g|=      0.066545
At iterate     5  f =       -342.8  |proj g|=       0.87743
At iterate     6  f =      -342.83  |proj g|=       0.50791
At iterate     7  f =      -342.85  |proj g|=       0.41848
At iterate     8  f =      -342.89  |proj g|=       0.34797
At iterate     9  f =      -343.05  |proj g|=       0.34815
At iterate    10  f =      -343.17  |proj g|=       0.34812
At iterate    11  f =      -343.27  |proj g|=       0.34788
At iterate    12  f =      -343.28  |proj g|=       0.34781
At iterate    13  f =      -343.28  |proj g|=      0.098824
At iterate    14  f =      -343.28  |proj g|=      0.074079
At iterate    15  f =      -343.28  |proj g|=      0.020578
At iterate    16  f =      -343.28  |proj g|=       0.33105
At iterate    17  f =      -343.28  |proj g|=     0.0059471

iterations 17
function evaluations 25
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00594709
final function value -343.276

F = -343.276
final  value -343.276049 
converged
 
INFO  [00:08:52.190] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:08:52.246] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:08:52.259] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:09:24.245] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:09:56.374] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:10:28.575] [mlr3]  Finished benchmark 
INFO  [00:10:28.639] [bbotk] Result of batch 68: 
INFO  [00:10:28.640] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:10:28.640] [bbotk]                   3              2607      0.4123332        0.586 -0.8699742 
INFO  [00:10:28.640] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:10:28.640] [bbotk]          <NA>    0.976684 a7a9da2f-3260-4953-abb1-05353ec001b9 
DEBUG [00:10:29.420] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.492126e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003492126 0.3515306 
  - best initial criterion value(s) :  270.6438 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -270.64  |proj g|=       12.057
At iterate     1  f =      -294.45  |proj g|=        5.7991
At iterate     2  f =       -323.1  |proj g|=        3.2471
At iterate     3  f =      -334.77  |proj g|=        2.5085
At iterate     4  f =       -336.7  |proj g|=        1.9873
At iterate     5  f =      -337.37  |proj g|=        6.6196
At iterate     6  f =      -338.46  |proj g|=       0.65798
At iterate     7  f =      -338.63  |proj g|=        1.2805
At iterate     8  f =      -338.63  |proj g|=       0.88748
At iterate     9  f =      -338.65  |proj g|=       0.69173
At iterate    10  f =       -338.8  |proj g|=       0.95561
At iterate    11  f =      -339.08  |proj g|=        2.7472
At iterate    12  f =      -339.91  |proj g|=        5.9707
At iterate    13  f =      -341.79  |proj g|=        9.9457
At iterate    14  f =      -345.14  |proj g|=        12.768
At iterate    15  f =      -346.99  |proj g|=          9.85
At iterate    16  f =      -348.87  |proj g|=        1.5791
At iterate    17  f =      -348.91  |proj g|=       0.34736
At iterate    18  f =      -348.91  |proj g|=       0.34732
At iterate    19  f =      -348.91  |proj g|=        0.2507
At iterate    20  f =      -348.91  |proj g|=     0.0061698

iterations 20
function evaluations 23
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0061698
final function value -348.911

F = -348.911
final  value -348.911157 
converged
 
INFO  [00:10:29.424] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:10:29.476] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:10:29.483] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:10:37.508] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:10:45.120] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:10:53.131] [mlr3]  Finished benchmark 
INFO  [00:10:53.197] [bbotk] Result of batch 69: 
INFO  [00:10:53.199] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [00:10:53.199] [bbotk]                   3               554      0.4489618        0.543 -0.869766 
INFO  [00:10:53.199] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:10:53.199] [bbotk]          <NA>     0.97542 c84d620c-a2b9-40e9-ba69-730d9e0c534f 
DEBUG [00:10:54.172] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.468936e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003447554 0.3468936 
  - best initial criterion value(s) :  313.2374 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -313.24  |proj g|=       3.8703
At iterate     1  f =      -317.47  |proj g|=        4.5962
At iterate     2  f =      -341.94  |proj g|=        2.4238
At iterate     3  f =      -344.27  |proj g|=        1.3215
At iterate     4  f =       -344.5  |proj g|=        1.8568
At iterate     5  f =      -344.51  |proj g|=        1.8692
At iterate     6  f =      -344.54  |proj g|=        1.8719
At iterate     7  f =      -344.65  |proj g|=        1.8829
At iterate     8  f =       -345.2  |proj g|=        1.9114
At iterate     9  f =      -346.36  |proj g|=        1.9656
At iterate    10  f =      -349.77  |proj g|=         2.102
At iterate    11  f =      -352.17  |proj g|=        2.1408
At iterate    12  f =      -353.28  |proj g|=        2.1185
At iterate    13  f =      -353.53  |proj g|=        2.1026
At iterate    14  f =      -353.58  |proj g|=        2.0918
At iterate    15  f =       -353.6  |proj g|=        2.0833
At iterate    16  f =      -353.63  |proj g|=        2.0712
At iterate    17  f =      -353.74  |proj g|=        2.0335
At iterate    18  f =      -354.01  |proj g|=       0.85981
At iterate    19  f =      -354.42  |proj g|=        1.0233
At iterate    20  f =       -354.5  |proj g|=       0.34281
At iterate    21  f =       -354.5  |proj g|=      0.017038
At iterate    22  f =       -354.5  |proj g|=     0.0062144
At iterate    23  f =       -354.5  |proj g|=     0.0062143

iterations 23
function evaluations 31
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00621434
final function value -354.504

F = -354.504
final  value -354.503801 
converged
 
INFO  [00:10:54.176] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:10:54.230] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:10:54.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:10:54.953] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:10:55.665] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:10:56.518] [mlr3]  Finished benchmark 
INFO  [00:10:56.581] [bbotk] Result of batch 70: 
INFO  [00:10:56.583] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:10:56.583] [bbotk]                   9               388     0.01589402        0.716 -0.8698317 
INFO  [00:10:56.583] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:10:56.583] [bbotk]          <NA>         0.5 9a7ec6cd-2686-4f0e-8930-f57c6a998f85 
DEBUG [00:10:57.460] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.569432e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9802841 
  - variance bounds :  0.003569432 0.3597378 
  - best initial criterion value(s) :  243.6957 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -243.7  |proj g|=       13.133
At iterate     1  f =      -299.56  |proj g|=        5.0521
At iterate     2  f =      -302.11  |proj g|=        4.8279
At iterate     3  f =      -307.51  |proj g|=        4.2726
At iterate     4  f =      -316.83  |proj g|=        3.3944
At iterate     5  f =      -329.56  |proj g|=        5.7896
At iterate     6  f =      -329.96  |proj g|=        4.5601
At iterate     7  f =      -331.39  |proj g|=        1.9511
At iterate     8  f =      -331.47  |proj g|=        1.9208
At iterate     9  f =      -331.53  |proj g|=        1.8756
At iterate    10  f =      -331.58  |proj g|=        1.8565
At iterate    11  f =       -332.1  |proj g|=        1.3937
At iterate    12  f =      -333.08  |proj g|=       0.73033
At iterate    13  f =      -335.21  |proj g|=        4.3579
At iterate    14  f =      -346.42  |proj g|=        11.326
At iterate    15  f =      -359.81  |proj g|=        8.7563
At iterate    16  f =      -360.03  |proj g|=        9.0284
At iterate    17  f =      -361.07  |proj g|=        4.5164
At iterate    18  f =      -361.42  |proj g|=       0.35566
At iterate    19  f =      -361.43  |proj g|=       0.35557
At iterate    20  f =      -361.44  |proj g|=       0.35554
At iterate    21  f =      -361.44  |proj g|=      0.060428
At iterate    22  f =      -361.44  |proj g|=     0.0056263

iterations 22
function evaluations 32
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00562633
final function value -361.435

F = -361.435
final  value -361.435156 
converged
 
INFO  [00:10:57.464] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:10:57.518] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:10:57.524] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:11:37.682] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:12:17.582] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:12:58.047] [mlr3]  Finished benchmark 
INFO  [00:12:58.112] [bbotk] Result of batch 71: 
INFO  [00:12:58.114] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:12:58.114] [bbotk]                   7              3302       0.494608        0.618 -0.8689206 
INFO  [00:12:58.114] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:12:58.114] [bbotk]          <NA>   0.9729378 fd59259c-75ef-4297-8d6a-d79ecfde3757 
DEBUG [00:12:58.960] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.545936e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003545936 0.35922 
  - best initial criterion value(s) :  301.962 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -301.96  |proj g|=        3.363
At iterate     1  f =      -311.53  |proj g|=        1.0389
At iterate     2  f =      -344.42  |proj g|=        1.2112
At iterate     3  f =      -344.61  |proj g|=         2.066
At iterate     4  f =      -344.63  |proj g|=        3.1506
At iterate     5  f =      -347.29  |proj g|=         2.723
At iterate     6  f =      -347.53  |proj g|=       0.35523
At iterate     7  f =      -347.54  |proj g|=       0.35515
At iterate     8  f =      -347.54  |proj g|=       0.35512
At iterate     9  f =      -347.54  |proj g|=      0.078552
At iterate    10  f =      -347.54  |proj g|=     0.0095181

iterations 10
function evaluations 19
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00951808
final function value -347.544

F = -347.544
final  value -347.544213 
converged
 
INFO  [00:12:58.964] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:12:59.019] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:12:59.026] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:13:40.467] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:14:21.863] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:15:02.872] [mlr3]  Finished benchmark 
INFO  [00:15:02.939] [bbotk] Result of batch 72: 
INFO  [00:15:02.941] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:15:02.941] [bbotk]                   7              3371      0.4724501        0.602 -0.8705016 
INFO  [00:15:02.941] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:15:02.941] [bbotk]          <NA>   0.9729981 3f2024b8-eeec-42b8-9f1c-4392b6411d91 
DEBUG [00:15:03.927] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.522644e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003522644 0.3585556 
  - best initial criterion value(s) :  277.6056 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -277.61  |proj g|=       1.3593
At iterate     1  f =      -307.85  |proj g|=        4.9205
At iterate     2  f =      -313.79  |proj g|=        5.1013
At iterate     3  f =      -316.45  |proj g|=        5.2397
At iterate     4  f =      -323.89  |proj g|=        5.5571
At iterate     5  f =      -324.63  |proj g|=        5.5655
At iterate     6  f =      -325.18  |proj g|=         5.551
At iterate     7  f =      -325.67  |proj g|=        5.5235
At iterate     8  f =      -326.88  |proj g|=         5.416
At iterate     9  f =      -333.99  |proj g|=        4.5715
At iterate    10  f =      -345.54  |proj g|=        3.4742
At iterate    11  f =       -370.1  |proj g|=        2.6483
At iterate    12  f =      -370.53  |proj g|=        3.0029
At iterate    13  f =      -370.69  |proj g|=       0.35442
At iterate    14  f =      -370.69  |proj g|=       0.35441
At iterate    15  f =      -370.69  |proj g|=       0.01823
At iterate    16  f =      -370.69  |proj g|=      0.006053

iterations 16
function evaluations 25
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.006053
final function value -370.686

F = -370.686
final  value -370.685620 
converged
 
INFO  [00:15:03.931] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:15:03.988] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:15:04.002] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:15:21.588] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:15:38.891] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:15:56.070] [mlr3]  Finished benchmark 
INFO  [00:15:56.134] [bbotk] Result of batch 73: 
INFO  [00:15:56.135] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:15:56.135] [bbotk]                   4              1346      0.1716224        0.727 -0.8698591 
INFO  [00:15:56.135] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:15:56.135] [bbotk]          <NA>   0.9764917 d1e353f1-c2a1-4531-a415-796c5d9068ce 
DEBUG [00:15:56.923] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.500401e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003500401 0.3541024 
  - best initial criterion value(s) :  301.04 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -301.04  |proj g|=       4.2343
At iterate     1  f =      -336.26  |proj g|=        10.623
At iterate     2  f =      -365.09  |proj g|=        12.779
At iterate     3  f =      -365.64  |proj g|=         1.505
At iterate     4  f =      -365.73  |proj g|=        2.7696
At iterate     5  f =      -366.13  |proj g|=        9.4262
At iterate     6  f =      -366.49  |proj g|=        7.3725
At iterate     7  f =      -367.29  |proj g|=        4.0115
At iterate     8  f =      -373.04  |proj g|=       0.54422
At iterate     9  f =      -376.79  |proj g|=        1.2756
At iterate    10  f =       -376.8  |proj g|=       0.88703
At iterate    11  f =      -376.81  |proj g|=        0.4701
At iterate    12  f =      -376.82  |proj g|=       0.34998
At iterate    13  f =      -376.82  |proj g|=     0.0060582
At iterate    14  f =      -376.82  |proj g|=     0.0060582

iterations 14
function evaluations 18
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0060582
final function value -376.819

F = -376.819
final  value -376.818564 
converged
 
INFO  [00:15:56.927] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:15:56.983] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:15:56.989] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:16:13.011] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:16:28.925] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:16:44.625] [mlr3]  Finished benchmark 
INFO  [00:16:44.692] [bbotk] Result of batch 74: 
INFO  [00:16:44.693] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:16:44.693] [bbotk]                   5              1231      0.1008544        0.559 -0.8694763 
INFO  [00:16:44.693] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:16:44.693] [bbotk]          <NA>   0.9764923 2db2ca04-6ce9-44ad-bd96-6a401fadf453 
DEBUG [00:16:45.507] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.478318e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003478318 0.3497784 
  - best initial criterion value(s) :  307.4825 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -307.48  |proj g|=       1.4214
At iterate     1  f =      -315.14  |proj g|=        4.5569
At iterate     2  f =      -319.13  |proj g|=        4.4138
At iterate     3  f =      -321.91  |proj g|=        4.1706
At iterate     4  f =      -326.26  |proj g|=        3.7466
At iterate     5  f =      -333.37  |proj g|=        3.2103
At iterate     6  f =      -343.58  |proj g|=        12.699
At iterate     7  f =       -345.7  |proj g|=        5.6861
At iterate     8  f =      -347.31  |proj g|=        1.8755
At iterate     9  f =      -347.35  |proj g|=        1.8554
At iterate    10  f =      -347.36  |proj g|=        1.8347
At iterate    11  f =      -347.49  |proj g|=        1.2074
At iterate    12  f =      -348.43  |proj g|=        2.6417
At iterate    13  f =      -350.41  |proj g|=        7.4391
At iterate    14  f =      -352.78  |proj g|=        9.3255
At iterate    15  f =      -353.41  |proj g|=        4.8308
At iterate    16  f =      -354.08  |proj g|=        1.1996
At iterate    17  f =      -354.14  |proj g|=        0.3458
At iterate    18  f =      -354.14  |proj g|=       0.34576
At iterate    19  f =      -354.14  |proj g|=        0.2664
At iterate    20  f =      -354.14  |proj g|=      0.011742

iterations 20
function evaluations 29
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0117415
final function value -354.141

F = -354.141
final  value -354.140875 
converged
 
INFO  [00:16:45.511] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:16:45.568] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:16:45.575] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:16:53.617] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:17:01.583] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:17:09.840] [mlr3]  Finished benchmark 
INFO  [00:17:09.905] [bbotk] Result of batch 75: 
INFO  [00:17:09.907] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:17:09.907] [bbotk]                   5               582      0.3739936        0.558 -0.8718143 
INFO  [00:17:09.907] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:17:09.907] [bbotk]          <NA>    0.976881 fb9e8e42-b7ae-43c6-8340-cd071ed8867d 
DEBUG [00:17:10.914] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.456494e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.00345326 0.3456494 
  - best initial criterion value(s) :  283.0285 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -283.03  |proj g|=       12.162
At iterate     1  f =      -313.38  |proj g|=        5.7133
At iterate     2  f =      -354.21  |proj g|=        2.2387
At iterate     3  f =      -354.29  |proj g|=        2.2251
At iterate     4  f =       -356.1  |proj g|=        1.7542
At iterate     5  f =      -357.48  |proj g|=        2.3446
At iterate     6  f =      -360.01  |proj g|=         0.283
At iterate     7  f =      -379.55  |proj g|=        2.1395
At iterate     8  f =      -380.63  |proj g|=        1.6301
At iterate     9  f =      -380.82  |proj g|=         1.894
At iterate    10  f =      -380.96  |proj g|=       0.41858
At iterate    11  f =      -380.96  |proj g|=       0.02659
At iterate    12  f =      -380.96  |proj g|=       0.34164
At iterate    13  f =      -380.96  |proj g|=     0.0072089
At iterate    14  f =      -380.96  |proj g|=      0.007209

iterations 14
function evaluations 22
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00720895
final function value -380.965

F = -380.965
final  value -380.964593 
converged
 
INFO  [00:17:10.918] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:17:10.972] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:17:10.979] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:17:35.250] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:17:59.726] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:18:24.226] [mlr3]  Finished benchmark 
INFO  [00:18:24.291] [bbotk] Result of batch 76: 
INFO  [00:18:24.293] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:18:24.293] [bbotk]                   7              1958      0.3591564         0.76 -0.8692197 
INFO  [00:18:24.293] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:18:24.293] [bbotk]          <NA>   0.9748455 ff1758a1-10c6-4a9f-8c98-6c2cb661b9f1 
DEBUG [00:18:25.175] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.434361e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003434361 0.3436599 
  - best initial criterion value(s) :  340.6822 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -340.68  |proj g|=       12.525
At iterate     1  f =      -362.86  |proj g|=        3.1192
At iterate     2  f =      -374.49  |proj g|=        2.9426
At iterate     3  f =      -378.49  |proj g|=        2.7936
At iterate     4  f =      -380.14  |proj g|=         2.655
At iterate     5  f =      -384.51  |proj g|=        2.0036
At iterate     6  f =      -385.74  |proj g|=        4.9414
At iterate     7  f =      -386.39  |proj g|=        0.3185
At iterate     8  f =      -386.44  |proj g|=       0.50819
At iterate     9  f =      -386.46  |proj g|=        0.3453
At iterate    10  f =      -386.46  |proj g|=       0.33975
At iterate    11  f =      -386.48  |proj g|=       0.33983
At iterate    12  f =      -386.53  |proj g|=       0.33991
At iterate    13  f =      -386.66  |proj g|=       0.34006
At iterate    14  f =      -386.98  |proj g|=       0.66387
At iterate    15  f =      -389.02  |proj g|=        6.4259
At iterate    16  f =      -391.24  |proj g|=        7.1353
At iterate    17  f =      -391.81  |proj g|=        10.044
At iterate    18  f =      -393.55  |proj g|=        4.1469
At iterate    19  f =      -393.79  |proj g|=       0.33983
At iterate    20  f =      -393.84  |proj g|=       0.33968
At iterate    21  f =      -393.84  |proj g|=       0.33964
At iterate    22  f =      -393.84  |proj g|=       0.28439
At iterate    23  f =      -393.84  |proj g|=     0.0059539

iterations 23
function evaluations 30
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00595395
final function value -393.842

F = -393.842
final  value -393.841594 
converged
 
INFO  [00:18:25.177] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:18:25.220] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:18:25.227] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:19:14.981] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:20:02.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:20:50.700] [mlr3]  Finished benchmark 
INFO  [00:20:50.766] [bbotk] Result of batch 77: 
INFO  [00:20:50.767] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [00:20:50.767] [bbotk]                   4              3991      0.1272181        0.605 -0.868399 
INFO  [00:20:50.767] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:20:50.767] [bbotk]          <NA>   0.9768586 9c4a9306-074a-4417-a41d-c7ea960cdfac 
DEBUG [00:20:51.566] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.412873e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003412873 0.343301 
  - best initial criterion value(s) :  278.688 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -278.69  |proj g|=       5.7642
At iterate     1  f =       -289.7  |proj g|=         3.846
At iterate     2  f =      -298.13  |proj g|=        5.2153
At iterate     3  f =      -300.34  |proj g|=        5.1283
At iterate     4  f =      -329.26  |proj g|=        3.9209
At iterate     5  f =      -371.16  |proj g|=        4.9463
At iterate     6  f =      -371.24  |proj g|=        3.7645
At iterate     7  f =      -371.48  |proj g|=         1.553
At iterate     8  f =      -371.53  |proj g|=       0.33943
At iterate     9  f =      -371.53  |proj g|=       0.33941
At iterate    10  f =      -371.53  |proj g|=       0.04262
At iterate    11  f =      -371.53  |proj g|=        0.0119

iterations 11
function evaluations 18
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0119002
final function value -371.533

F = -371.533
final  value -371.532705 
converged
 
INFO  [00:20:51.570] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:20:51.622] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:20:51.630] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:21:02.968] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:21:13.540] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:21:24.341] [mlr3]  Finished benchmark 
INFO  [00:21:24.409] [bbotk] Result of batch 78: 
INFO  [00:21:24.411] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [00:21:24.411] [bbotk]                   4               805       0.348889        0.565 -0.870731 
INFO  [00:21:24.411] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:21:24.411] [bbotk]          <NA>   0.9765926 e5d214bd-df61-4ffa-9cd3-e396f3c4b1ff 
DEBUG [00:21:25.234] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.391497e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003391497 0.3392034 
  - best initial criterion value(s) :  325.4718 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -325.47  |proj g|=       5.8217
At iterate     1  f =      -330.86  |proj g|=        5.5707
At iterate     2  f =      -373.35  |proj g|=        2.2267
At iterate     3  f =      -374.77  |proj g|=       0.18442
At iterate     4  f =      -375.07  |proj g|=        1.8382
At iterate     5  f =      -375.08  |proj g|=        1.8678
At iterate     6  f =      -375.37  |proj g|=        1.8505
At iterate     7  f =      -376.37  |proj g|=         1.839
At iterate     8  f =      -379.79  |proj g|=        1.8328
At iterate     9  f =      -387.23  |proj g|=        1.8294
At iterate    10  f =      -387.46  |proj g|=       0.38056
At iterate    11  f =      -387.48  |proj g|=       0.33542
At iterate    12  f =      -387.48  |proj g|=       0.33538
At iterate    13  f =      -387.48  |proj g|=      0.088988
At iterate    14  f =      -387.48  |proj g|=       0.33535
At iterate    15  f =      -387.48  |proj g|=     0.0095346

iterations 15
function evaluations 23
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00953462
final function value -387.485

F = -387.485
final  value -387.484738 
converged
 
INFO  [00:21:25.238] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:21:25.298] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:21:25.304] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:21:26.003] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:21:27.086] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:21:27.792] [mlr3]  Finished benchmark 
INFO  [00:21:27.856] [bbotk] Result of batch 79: 
INFO  [00:21:27.858] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:21:27.858] [bbotk]                   9              1543      0.4316721        0.578 -0.8692355 
INFO  [00:21:27.858] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:21:27.858] [bbotk]          <NA>         0.5 e75b9035-b5fc-4066-9ffd-28206a512df4 
DEBUG [00:21:28.685] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.487977e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003482296 0.3487977 
  - best initial criterion value(s) :  279.7659 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -279.77  |proj g|=       11.852
At iterate     1  f =      -299.97  |proj g|=        5.8841
At iterate     2  f =      -317.64  |proj g|=        2.4518
At iterate     3  f =      -344.86  |proj g|=        1.9916
At iterate     4  f =      -345.11  |proj g|=        1.8804
At iterate     5  f =      -345.23  |proj g|=        1.8294
At iterate     6  f =      -347.52  |proj g|=        1.9461
At iterate     7  f =      -358.05  |proj g|=        11.746
At iterate     8  f =       -373.3  |proj g|=        12.782
At iterate     9  f =      -378.82  |proj g|=        8.3794
At iterate    10  f =      -379.77  |proj g|=       0.34532
At iterate    11  f =      -379.95  |proj g|=        0.4847
At iterate    12  f =      -379.95  |proj g|=      0.038995
At iterate    13  f =      -379.95  |proj g|=      0.012245
At iterate    14  f =      -379.95  |proj g|=      0.012245

iterations 14
function evaluations 23
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0122452
final function value -379.952

F = -379.952
final  value -379.951664 
converged
 
INFO  [00:21:28.689] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:21:28.744] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:21:28.750] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:21:41.261] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:21:53.690] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:22:06.554] [mlr3]  Finished benchmark 
INFO  [00:22:06.619] [bbotk] Result of batch 80: 
INFO  [00:22:06.620] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:22:06.620] [bbotk]                   3               978     0.04184303        0.577 -0.8703799 
INFO  [00:22:06.620] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:22:06.620] [bbotk]          <NA>   0.9683752 0b4b63a1-830a-4f2a-99d0-d5e812a5edcb 
DEBUG [00:22:07.462] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.465047e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003439885 0.3465047 
  - best initial criterion value(s) :  365.6286 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -365.63  |proj g|=       3.6244
At iterate     1  f =      -374.52  |proj g|=        10.339
At iterate     2  f =      -393.38  |proj g|=        1.7884
At iterate     3  f =      -393.58  |proj g|=        1.5958
At iterate     4  f =       -393.7  |proj g|=        1.0028
At iterate     5  f =      -393.77  |proj g|=       0.63844
At iterate     6  f =      -393.83  |proj g|=       0.34289
At iterate     7  f =      -393.92  |proj g|=       0.40734
At iterate     8  f =      -394.23  |proj g|=        1.1161
At iterate     9  f =      -394.57  |proj g|=       0.92807
At iterate    10  f =       -394.7  |proj g|=       0.34283
At iterate    11  f =      -394.71  |proj g|=       0.56994
At iterate    12  f =      -394.71  |proj g|=       0.62297
At iterate    13  f =      -394.71  |proj g|=       0.62822
At iterate    14  f =      -394.71  |proj g|=       0.63442
At iterate    15  f =      -394.71  |proj g|=       0.64438
At iterate    16  f =      -394.71  |proj g|=       0.65558
At iterate    17  f =      -394.71  |proj g|=       0.66054
At iterate    18  f =      -394.71  |proj g|=       0.63173
At iterate    19  f =      -394.72  |proj g|=       0.50665
At iterate    20  f =      -394.72  |proj g|=       0.20501
At iterate    21  f =      -394.72  |proj g|=      0.010359
At iterate    22  f =      -394.72  |proj g|=      0.010359
At iterate    23  f =      -394.72  |proj g|=      0.020872

iterations 23
function evaluations 27
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0208715
final function value -394.72

F = -394.72
final  value -394.719700 
converged
 
INFO  [00:22:07.466] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:22:07.520] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:22:07.527] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:22:28.586] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:22:49.686] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:23:10.716] [mlr3]  Finished benchmark 
INFO  [00:23:10.793] [bbotk] Result of batch 81: 
INFO  [00:23:10.795] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:23:10.795] [bbotk]                   3              1687     0.04528301        0.574 -0.8689558 
INFO  [00:23:10.795] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:23:10.795] [bbotk]          <NA>   0.9715293 c356e4c9-563f-4294-815f-6fb18f587309 
DEBUG [00:23:11.796] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.443004e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003403382 0.3443004 
  - best initial criterion value(s) :  328.4948 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -328.49  |proj g|=       12.666
At iterate     1  f =      -354.49  |proj g|=        2.4862
At iterate     2  f =      -366.12  |proj g|=        2.8907
At iterate     3  f =      -370.34  |proj g|=        2.7156
At iterate     4  f =      -372.67  |proj g|=        2.5012
At iterate     5  f =       -377.2  |proj g|=        1.8415
At iterate     6  f =      -377.69  |proj g|=        1.8194
At iterate     7  f =      -377.71  |proj g|=        1.2567
At iterate     8  f =      -386.15  |proj g|=        1.1706
At iterate     9  f =      -397.43  |proj g|=         1.176
At iterate    10  f =       -397.5  |proj g|=       0.34057
At iterate    11  f =       -397.5  |proj g|=       0.34055
At iterate    12  f =       -397.5  |proj g|=       0.01285
At iterate    13  f =       -397.5  |proj g|=      0.011153
At iterate    14  f =       -397.5  |proj g|=      0.011153

iterations 14
function evaluations 23
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0111527
final function value -397.501

F = -397.501
final  value -397.501049 
converged
 
INFO  [00:23:11.800] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:23:11.853] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:23:11.860] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:23:12.831] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:23:13.537] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:23:14.245] [mlr3]  Finished benchmark 
INFO  [00:23:14.311] [bbotk] Result of batch 82: 
INFO  [00:23:14.312] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:23:14.312] [bbotk]                  10              3443      0.4327506        0.745 -0.8689584 
INFO  [00:23:14.312] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:23:14.312] [bbotk]          <NA>         0.5 6c3ce614-72c2-41cb-bb01-c5a439e03695 
DEBUG [00:23:15.206] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.535225e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003488406 0.3535225 
  - best initial criterion value(s) :  333.8795 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -333.88  |proj g|=       6.2026
At iterate     1  f =      -339.82  |proj g|=        3.4201
At iterate     2  f =      -361.09  |proj g|=         3.442
At iterate     3  f =      -368.12  |proj g|=        2.9846
At iterate     4  f =      -378.06  |proj g|=        2.3698
At iterate     5  f =      -380.68  |proj g|=        1.9929
At iterate     6  f =      -382.27  |proj g|=        4.2045
At iterate     7  f =      -382.55  |proj g|=       0.38554
At iterate     8  f =      -382.56  |proj g|=       0.34985
At iterate     9  f =      -382.57  |proj g|=       0.34977
At iterate    10  f =      -382.67  |proj g|=        1.0625
At iterate    11  f =       -382.8  |proj g|=        1.3511
At iterate    12  f =      -382.82  |proj g|=       0.54459
At iterate    13  f =      -382.83  |proj g|=       0.34976
At iterate    14  f =      -382.83  |proj g|=       0.34976
At iterate    15  f =      -382.83  |proj g|=      0.015801

iterations 15
function evaluations 25
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0158009
final function value -382.827

F = -382.827
final  value -382.826754 
converged
 
INFO  [00:23:15.210] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:23:15.271] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:23:15.277] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:23:50.472] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:24:26.622] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:25:01.844] [mlr3]  Finished benchmark 
INFO  [00:25:01.912] [bbotk] Result of batch 83: 
INFO  [00:25:01.913] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [00:25:01.913] [bbotk]                   3              2893      0.4069204        0.614 -0.870714 
INFO  [00:25:01.913] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:25:01.913] [bbotk]          <NA>   0.9767311 104529b8-6933-40a2-8bb2-608a1203d262 
DEBUG [00:25:02.757] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.514565e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003483099 0.3514565 
  - best initial criterion value(s) :  374.2774 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -374.28  |proj g|=       9.4205
At iterate     1  f =      -382.14  |proj g|=        2.4034
At iterate     2  f =      -401.37  |proj g|=        3.1135
At iterate     3  f =      -406.34  |proj g|=        2.4368
At iterate     4  f =      -413.83  |proj g|=        2.0383
At iterate     5  f =      -415.42  |proj g|=         1.786
At iterate     6  f =      -415.47  |proj g|=        1.8145
At iterate     7  f =       -415.5  |proj g|=       0.41747
At iterate     8  f =      -415.53  |proj g|=       0.87657
At iterate     9  f =      -415.77  |proj g|=        1.8481
At iterate    10  f =      -416.37  |proj g|=        1.9509
At iterate    11  f =      -417.83  |proj g|=        2.1119
At iterate    12  f =      -419.77  |proj g|=        2.2031
At iterate    13  f =         -421  |proj g|=          2.04
At iterate    14  f =      -421.85  |proj g|=        1.9956
At iterate    15  f =      -421.89  |proj g|=       0.78007
At iterate    16  f =      -421.91  |proj g|=       0.22902
At iterate    17  f =      -421.91  |proj g|=     0.0086597
At iterate    18  f =      -421.91  |proj g|=      0.076834
At iterate    19  f =      -421.91  |proj g|=     0.0086595

iterations 19
function evaluations 29
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00865952
final function value -421.91

F = -421.91
final  value -421.910361 
converged
 
INFO  [00:25:02.761] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:25:02.817] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:25:02.833] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:25:15.319] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:25:27.954] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:25:40.322] [mlr3]  Finished benchmark 
INFO  [00:25:40.389] [bbotk] Result of batch 84: 
INFO  [00:25:40.390] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:25:40.390] [bbotk]                   5               947       0.263262         0.57 -0.8670796 
INFO  [00:25:40.390] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:25:40.390] [bbotk]          <NA>    0.977043 00d1644f-4b2f-445c-a5c8-0a2b73556f82 
DEBUG [00:25:41.226] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.494122e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003446522 0.3494122 
  - best initial criterion value(s) :  355.2526 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -355.25  |proj g|=        13.37
At iterate     1  f =      -396.32  |proj g|=        8.3721
At iterate     2  f =      -408.93  |proj g|=        3.2286
At iterate     3  f =      -417.63  |proj g|=        2.9425
At iterate     4  f =      -419.81  |proj g|=        2.7597
At iterate     5  f =       -425.8  |proj g|=        2.1356
At iterate     6  f =      -428.71  |proj g|=       0.81374
At iterate     7  f =      -428.76  |proj g|=       0.34585
At iterate     8  f =      -429.03  |proj g|=        1.8233
At iterate     9  f =       -433.3  |proj g|=         1.875
At iterate    10  f =      -433.45  |proj g|=       0.48521
At iterate    11  f =      -433.45  |proj g|=       0.34574
At iterate    12  f =      -433.45  |proj g|=      0.021536

iterations 12
function evaluations 22
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0215359
final function value -433.453

F = -433.453
final  value -433.452962 
converged
 
INFO  [00:25:41.230] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:25:41.285] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:25:41.292] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:26:13.934] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:26:46.741] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:27:19.214] [mlr3]  Finished benchmark 
INFO  [00:27:19.279] [bbotk] Result of batch 85: 
INFO  [00:27:19.281] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:27:19.281] [bbotk]                   3              2645      0.3763161        0.575 -0.8662412 
INFO  [00:27:19.281] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:27:19.281] [bbotk]          <NA>   0.9767017 afe1be64-462c-4460-aa59-0da814d978cf 
DEBUG [00:27:20.105] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.473755e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.00343708 0.3473755 
  - best initial criterion value(s) :  335.7515 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -335.75  |proj g|=       4.0089
At iterate     1  f =      -410.51  |proj g|=        3.3905
At iterate     2  f =      -422.15  |proj g|=        2.4502
At iterate     3  f =      -430.06  |proj g|=       0.34394
At iterate     4  f =       -430.1  |proj g|=       0.24293
At iterate     5  f =       -430.1  |proj g|=     0.0097924
At iterate     6  f =       -430.1  |proj g|=     0.0097923
At iterate     7  f =       -430.1  |proj g|=     0.0097923

iterations 7
function evaluations 13
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00979231
final function value -430.097

F = -430.097
final  value -430.096615 
converged
 
INFO  [00:27:20.109] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:27:20.177] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:27:20.188] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:27:57.576] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:28:34.784] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:29:12.556] [mlr3]  Finished benchmark 
INFO  [00:29:12.620] [bbotk] Result of batch 86: 
INFO  [00:29:12.621] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [00:29:12.621] [bbotk]                   5              3067      0.2378856        0.593 -0.866946 
INFO  [00:29:12.621] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:29:12.621] [bbotk]          <NA>   0.9763128 f1aa3cf0-7c37-4fb8-b658-db491fef294b 
DEBUG [00:29:13.672] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.45346e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003442763 0.345346 
  - best initial criterion value(s) :  374.6115 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -374.61  |proj g|=       7.2622
At iterate     1  f =      -383.19  |proj g|=         1.684
At iterate     2  f =      -403.76  |proj g|=        3.9338
At iterate     3  f =      -411.78  |proj g|=        3.3189
At iterate     4  f =      -430.92  |proj g|=        10.762
At iterate     5  f =      -432.42  |proj g|=        1.8677
At iterate     6  f =      -432.46  |proj g|=        1.8998
At iterate     7  f =       -432.7  |proj g|=       0.10417
At iterate     8  f =      -432.78  |proj g|=        0.6582
At iterate     9  f =      -433.24  |proj g|=        1.8201
At iterate    10  f =      -434.41  |proj g|=         1.948
At iterate    11  f =       -437.1  |proj g|=        2.1307
At iterate    12  f =      -437.93  |proj g|=        2.1385
At iterate    13  f =      -438.91  |proj g|=        2.0001
At iterate    14  f =      -439.65  |proj g|=        0.3419
At iterate    15  f =      -439.67  |proj g|=       0.12378
At iterate    16  f =      -439.67  |proj g|=     0.0094299
At iterate    17  f =      -439.67  |proj g|=     0.0094298
At iterate    18  f =      -439.67  |proj g|=      0.014273

iterations 18
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0142734
final function value -439.673

F = -439.673
final  value -439.672996 
converged
 
INFO  [00:29:13.676] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:29:13.727] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:29:13.734] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:29:40.657] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:30:08.056] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:30:09.137] [mlr3]  Finished benchmark 
INFO  [00:30:09.203] [bbotk] Result of batch 87: 
INFO  [00:30:09.205] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:30:09.205] [bbotk]                   8              2168      0.1934692        0.743 -0.8664479 
INFO  [00:30:09.205] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:30:09.205] [bbotk]          <NA>   0.8193861 6bb72db2-bc46-4831-87b9-b7e7fb4e39ba 
DEBUG [00:30:10.417] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.423555e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003416237 0.3423555 
  - best initial criterion value(s) :  371.0488 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -371.05  |proj g|=       11.433
At iterate     1  f =      -384.76  |proj g|=         2.836
At iterate     2  f =      -404.14  |proj g|=         3.332
At iterate     3  f =      -412.77  |proj g|=        2.4641
At iterate     4  f =      -421.88  |proj g|=        1.9953
At iterate     5  f =      -422.64  |proj g|=        1.8238
At iterate     6  f =      -422.71  |proj g|=        1.8274
At iterate     7  f =      -422.76  |proj g|=       0.85113
At iterate     8  f =      -429.46  |proj g|=        1.8272
At iterate     9  f =      -438.47  |proj g|=       0.80945
At iterate    10  f =       -438.5  |proj g|=       0.33883
At iterate    11  f =       -438.5  |proj g|=      0.010918
At iterate    12  f =       -438.5  |proj g|=      0.010918

iterations 12
function evaluations 20
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0109181
final function value -438.501

F = -438.501
final  value -438.500927 
converged
 
INFO  [00:30:10.421] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:30:10.486] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:30:10.492] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:31:05.249] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:31:59.081] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:32:53.397] [mlr3]  Finished benchmark 
INFO  [00:32:53.461] [bbotk] Result of batch 88: 
INFO  [00:32:53.463] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:32:53.463] [bbotk]                   4              4442       0.216841        0.915 -0.8668659 
INFO  [00:32:53.463] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:32:53.463] [bbotk]          <NA>   0.9764984 321e7292-b0b6-4368-813c-51ef97a7cc39 
DEBUG [00:32:54.300] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.403995e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.0033895 0.3403995 
  - best initial criterion value(s) :  377.3635 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -377.36  |proj g|=       0.2747
At iterate     1  f =      -400.49  |proj g|=        4.3688
At iterate     2  f =      -401.68  |proj g|=        4.3844
At iterate     3  f =      -404.85  |proj g|=        4.3085
At iterate     4  f =      -405.35  |proj g|=        4.3067
At iterate     5  f =      -405.52  |proj g|=        4.3066
At iterate     6  f =      -405.53  |proj g|=        4.3062
At iterate     7  f =      -405.55  |proj g|=        4.3054
At iterate     8  f =      -405.58  |proj g|=        4.3022
At iterate     9  f =      -405.67  |proj g|=        4.2937
At iterate    10  f =      -405.88  |proj g|=        4.2709
At iterate    11  f =      -406.37  |proj g|=        4.2133
At iterate    12  f =      -407.55  |proj g|=        4.0702
At iterate    13  f =      -410.36  |proj g|=        3.7246
At iterate    14  f =      -417.73  |proj g|=        2.1084
At iterate    15  f =      -439.89  |proj g|=        12.611
At iterate    16  f =      -441.66  |proj g|=        1.8525
At iterate    17  f =      -441.73  |proj g|=        1.8856
At iterate    18  f =      -442.01  |proj g|=       0.98995
At iterate    19  f =      -442.03  |proj g|=      0.030026
At iterate    20  f =      -442.03  |proj g|=      0.011702
At iterate    21  f =      -442.03  |proj g|=      0.011702

iterations 21
function evaluations 27
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0117022
final function value -442.027

F = -442.027
final  value -442.027118 
converged
 
INFO  [00:32:54.304] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:32:54.355] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:32:54.362] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:33:13.440] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:33:32.957] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:33:51.812] [mlr3]  Finished benchmark 
INFO  [00:33:51.878] [bbotk] Result of batch 89: 
INFO  [00:33:51.880] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:33:51.880] [bbotk]                   3              1505      0.3739171        0.581 -0.8673425 
INFO  [00:33:51.880] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:33:51.880] [bbotk]          <NA>   0.9765131 2d481dcc-1a69-4b31-86b2-5a3a7f59f375 
DEBUG [00:33:52.723] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.384585e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003365255 0.3384585 
  - best initial criterion value(s) :  405.4874 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -405.49  |proj g|=       5.3172
At iterate     1  f =      -411.39  |proj g|=        4.7218
At iterate     2  f =      -421.36  |proj g|=        3.5837
At iterate     3  f =      -437.03  |proj g|=        1.9206
At iterate     4  f =      -437.41  |proj g|=        2.0062
At iterate     5  f =      -437.54  |proj g|=        2.1601
At iterate     6  f =      -439.05  |proj g|=          1.98
At iterate     7  f =      -441.11  |proj g|=        1.8967
At iterate     8  f =      -466.94  |proj g|=        2.5098
At iterate     9  f =      -471.85  |proj g|=        1.9476
At iterate    10  f =      -472.39  |proj g|=       0.60812
At iterate    11  f =      -472.45  |proj g|=      0.022878
At iterate    12  f =      -472.45  |proj g|=     0.0070593
At iterate    13  f =      -472.45  |proj g|=        0.3349
At iterate    14  f =      -472.45  |proj g|=     0.0070577

iterations 14
function evaluations 19
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00705772
final function value -472.454

F = -472.454
final  value -472.454237 
converged
 
INFO  [00:33:52.727] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:33:52.783] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:33:52.790] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:34:35.196] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:35:18.194] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:36:00.618] [mlr3]  Finished benchmark 
INFO  [00:36:00.683] [bbotk] Result of batch 90: 
INFO  [00:36:00.685] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:36:00.685] [bbotk]                   5              3532      0.4087453        0.592 -0.8646208 
INFO  [00:36:00.685] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:36:00.685] [bbotk]          <NA>   0.9754952 27a48360-10d3-440c-b0b2-e92b4c1bf09a 
DEBUG [00:36:01.539] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.365125e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003358044 0.3365125 
  - best initial criterion value(s) :  377.2068 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -377.21  |proj g|=       12.239
At iterate     1  f =      -402.16  |proj g|=        2.5402
At iterate     2  f =      -422.53  |proj g|=        3.2992
At iterate     3  f =       -427.9  |proj g|=        2.9564
At iterate     4  f =      -440.15  |proj g|=        12.638
At iterate     5  f =      -442.34  |proj g|=        1.8376
At iterate     6  f =      -442.44  |proj g|=        1.8443
At iterate     7  f =       -442.6  |proj g|=        1.2708
At iterate     8  f =      -445.49  |proj g|=        1.8287
At iterate     9  f =       -445.6  |proj g|=       0.92259
At iterate    10  f =      -445.62  |proj g|=       0.33308
At iterate    11  f =      -445.62  |proj g|=       0.33307
At iterate    12  f =      -445.62  |proj g|=      0.013584

iterations 12
function evaluations 20
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0135839
final function value -445.619

F = -445.619
final  value -445.618716 
converged
 
INFO  [00:36:01.543] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:36:01.599] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:36:01.606] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:36:18.751] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:36:35.346] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:36:51.948] [mlr3]  Finished benchmark 
INFO  [00:36:52.012] [bbotk] Result of batch 91: 
INFO  [00:36:52.014] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:36:52.014] [bbotk]                   3              1340      0.0031147        0.599 -0.8674005 
INFO  [00:36:52.014] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:36:52.014] [bbotk]          <NA>   0.9441094 57689819-1c3f-4cd3-a872-715e12e70104 
DEBUG [00:36:52.956] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.340669e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003324572 0.3340669 
  - best initial criterion value(s) :  373.9552 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -373.96  |proj g|=       12.197
At iterate     1  f =       -392.2  |proj g|=        5.6001
At iterate     2  f =      -412.45  |proj g|=        1.8448
At iterate     3  f =      -423.37  |proj g|=        2.4505
At iterate     4  f =      -423.86  |proj g|=        0.3427
At iterate     5  f =      -423.87  |proj g|=        0.8431
At iterate     6  f =      -423.89  |proj g|=      0.099944
At iterate     7  f =       -424.4  |proj g|=       0.76544
At iterate     8  f =      -424.51  |proj g|=        0.3242
At iterate     9  f =      -424.51  |proj g|=       0.32411
At iterate    10  f =      -424.51  |proj g|=       0.19711
At iterate    11  f =      -424.51  |proj g|=     0.0099428

iterations 11
function evaluations 14
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00994281
final function value -424.514

F = -424.514
final  value -424.513969 
converged
 
INFO  [00:36:52.960] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:36:53.015] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:36:53.021] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:36:54.117] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:37:40.260] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:38:25.421] [mlr3]  Finished benchmark 
INFO  [00:38:25.486] [bbotk] Result of batch 92: 
INFO  [00:38:25.487] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [00:38:25.487] [bbotk]                   8              3740      0.3672356        0.688 -0.876239 
INFO  [00:38:25.487] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:38:25.487] [bbotk]          <NA>   0.8172672 58435586-b129-4e9d-9a98-67e28c623ef0 
DEBUG [00:38:26.401] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.313506e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003304123 0.3313506 
  - best initial criterion value(s) :  380.2902 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -380.29  |proj g|=       12.197
At iterate     1  f =      -401.26  |proj g|=        2.3834
At iterate     2  f =      -408.58  |proj g|=        3.1574
At iterate     3  f =      -410.17  |proj g|=         3.073
At iterate     4  f =      -413.76  |proj g|=        2.5628
At iterate     5  f =      -415.52  |proj g|=        1.0593
At iterate     6  f =      -415.53  |proj g|=       0.99586
At iterate     7  f =      -415.54  |proj g|=        0.8582
At iterate     8  f =      -415.73  |proj g|=        0.3258
At iterate     9  f =      -416.14  |proj g|=        1.6904
At iterate    10  f =      -417.08  |proj g|=        3.4719
At iterate    11  f =      -417.27  |proj g|=          1.57
At iterate    12  f =      -418.78  |proj g|=         2.562
At iterate    13  f =      -419.91  |proj g|=         1.088
At iterate    14  f =      -420.38  |proj g|=       0.95319
At iterate    15  f =      -420.53  |proj g|=       0.98003
At iterate    16  f =      -420.56  |proj g|=       0.32189
At iterate    17  f =      -420.56  |proj g|=       0.32178
At iterate    18  f =      -420.56  |proj g|=       0.12392
At iterate    19  f =      -420.57  |proj g|=      0.039798
At iterate    20  f =      -420.57  |proj g|=       0.01195
At iterate    21  f =      -420.57  |proj g|=       0.01195
At iterate    22  f =      -420.57  |proj g|=       0.01195

iterations 22
function evaluations 32
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0119496
final function value -420.565

F = -420.565
final  value -420.565447 
converged
 
INFO  [00:38:26.405] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:38:26.457] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:38:26.464] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:38:48.368] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:39:09.951] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:39:32.123] [mlr3]  Finished benchmark 
INFO  [00:39:32.191] [bbotk] Result of batch 93: 
INFO  [00:39:32.193] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:39:32.193] [bbotk]                   4              1763      0.1329723         0.61 -0.8761237 
INFO  [00:39:32.193] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:39:32.193] [bbotk]          <NA>   0.9765491 445a1ccc-2bae-4a42-a997-f8e78ed660e2 
DEBUG [00:39:33.374] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.295141e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003282927 0.3295141 
  - best initial criterion value(s) :  429.4284 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -429.43  |proj g|=       9.9592
At iterate     1  f =      -436.02  |proj g|=        1.0154
At iterate     2  f =      -440.31  |proj g|=        3.6453
At iterate     3  f =      -442.24  |proj g|=        3.3905
At iterate     4  f =      -444.62  |proj g|=        2.6967
At iterate     5  f =      -445.28  |proj g|=      0.026619
At iterate     6  f =      -445.28  |proj g|=      0.026607
At iterate     7  f =      -445.29  |proj g|=       0.31999
At iterate     8  f =      -445.36  |proj g|=       0.58526
At iterate     9  f =      -445.37  |proj g|=       0.31953
At iterate    10  f =      -445.37  |proj g|=       0.31952
At iterate    11  f =      -445.37  |proj g|=     0.0086648
At iterate    12  f =      -445.37  |proj g|=     0.0086645
At iterate    13  f =      -445.37  |proj g|=     0.0086645

iterations 13
function evaluations 22
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0086645
final function value -445.371

F = -445.371
final  value -445.371098 
converged
 
INFO  [00:39:33.378] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:39:33.430] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:39:33.437] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:40:14.947] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:40:57.186] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:41:39.102] [mlr3]  Finished benchmark 
INFO  [00:41:39.172] [bbotk] Result of batch 94: 
INFO  [00:41:39.174] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:41:39.174] [bbotk]                   7              3439      0.4025603         0.64 -0.8754495 
INFO  [00:41:39.174] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:41:39.174] [bbotk]          <NA>   0.9733297 7f770160-ea76-4f8f-9fed-831e632cc3c8 
DEBUG [00:41:40.039] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.276324e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003274858 0.3276323 
  - best initial criterion value(s) :  405.7376 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -405.74  |proj g|=       6.6229
At iterate     1  f =      -417.56  |proj g|=        6.1035
At iterate     2  f =      -423.62  |proj g|=        5.9159
At iterate     3  f =      -427.64  |proj g|=        5.6767
At iterate     4  f =      -433.49  |proj g|=        5.1427
At iterate     5  f =      -444.73  |proj g|=        4.3771
At iterate     6  f =      -456.59  |proj g|=        1.5888
At iterate     7  f =      -459.08  |proj g|=        2.7281
At iterate     8  f =      -459.32  |proj g|=        3.2047
At iterate     9  f =      -459.37  |proj g|=        3.1917
At iterate    10  f =      -459.53  |proj g|=        3.1406
At iterate    11  f =      -459.85  |proj g|=        3.0126
At iterate    12  f =      -460.24  |proj g|=         2.554
At iterate    13  f =      -460.43  |proj g|=       0.31748
At iterate    14  f =      -460.44  |proj g|=       0.31741
At iterate    15  f =      -460.44  |proj g|=      0.061679
At iterate    16  f =      -460.44  |proj g|=     0.0071395

iterations 16
function evaluations 23
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00713947
final function value -460.436

F = -460.436
final  value -460.435863 
converged
 
INFO  [00:41:40.044] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:41:40.116] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:41:40.124] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:41:40.936] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:41:41.675] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:41:42.399] [mlr3]  Finished benchmark 
INFO  [00:41:42.464] [bbotk] Result of batch 95: 
INFO  [00:41:42.465] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:41:42.465] [bbotk]                  10              4801      0.3933661        0.613 -0.8749174 
INFO  [00:41:42.465] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:41:42.465] [bbotk]          <NA>         0.5 ad243090-4d57-4d63-885c-e4a85ae9f93f 
DEBUG [00:41:43.436] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.363283e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003363282 0.3396525 
  - best initial criterion value(s) :  384.9777 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -384.98  |proj g|=       4.3529
At iterate     1  f =      -426.72  |proj g|=        9.2741
At iterate     2  f =      -433.49  |proj g|=        6.7791
At iterate     3  f =      -434.19  |proj g|=        4.0615
At iterate     4  f =      -434.22  |proj g|=        1.5937
At iterate     5  f =      -434.26  |proj g|=        2.5081
At iterate     6  f =      -434.85  |proj g|=        2.7729
At iterate     7  f =      -436.83  |proj g|=       0.66967
At iterate     8  f =      -437.11  |proj g|=       0.33095
At iterate     9  f =      -437.13  |proj g|=       0.46426
At iterate    10  f =      -437.18  |proj g|=       0.33032
At iterate    11  f =      -437.18  |proj g|=       0.16078
At iterate    12  f =      -437.18  |proj g|=        0.1686
At iterate    13  f =      -437.18  |proj g|=       0.16231
At iterate    14  f =      -437.18  |proj g|=       0.12776
At iterate    15  f =      -437.18  |proj g|=      0.050375
At iterate    16  f =      -437.18  |proj g|=      0.011948
At iterate    17  f =      -437.18  |proj g|=      0.011948
At iterate    18  f =      -437.18  |proj g|=      0.011948

iterations 18
function evaluations 23
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0119476
final function value -437.176

F = -437.176
final  value -437.176228 
converged
 
INFO  [00:41:43.440] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:41:43.494] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:41:43.501] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:41:44.477] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:41:45.185] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:41:46.028] [mlr3]  Finished benchmark 
INFO  [00:41:46.093] [bbotk] Result of batch 96: 
INFO  [00:41:46.095] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:41:46.095] [bbotk]                   9              4106      0.3944712        0.669 -0.8756502 
INFO  [00:41:46.095] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:41:46.095] [bbotk]          <NA>         0.5 e56afafd-58cb-47eb-a428-1364f72799e2 
DEBUG [00:41:47.081] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.446852e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003446852 0.3487307 
  - best initial criterion value(s) :  404.7572 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -404.76  |proj g|=       10.734
At iterate     1  f =      -422.71  |proj g|=        1.7293
At iterate     2  f =      -436.78  |proj g|=        4.4458
At iterate     3  f =      -437.91  |proj g|=         4.383
At iterate     4  f =      -447.14  |proj g|=         3.589
At iterate     5  f =      -456.94  |proj g|=        2.7607
At iterate     6  f =      -459.44  |proj g|=        2.2662
At iterate     7  f =      -459.97  |proj g|=        1.5048
At iterate     8  f =      -460.03  |proj g|=       0.77115
At iterate     9  f =      -460.04  |proj g|=        1.0871
At iterate    10  f =       -460.1  |proj g|=        2.0127
At iterate    11  f =      -460.24  |proj g|=        2.2179
At iterate    12  f =       -460.6  |proj g|=        2.3187
At iterate    13  f =      -461.46  |proj g|=        2.5098
At iterate    14  f =      -463.87  |proj g|=         4.629
At iterate    15  f =      -468.61  |proj g|=       0.44245
At iterate    16  f =      -469.15  |proj g|=       0.37641
At iterate    17  f =      -469.15  |proj g|=       0.33863
At iterate    18  f =      -469.15  |proj g|=       0.33862
At iterate    19  f =      -469.15  |proj g|=       0.33862
At iterate    20  f =      -469.15  |proj g|=     0.0073461
At iterate    21  f =      -469.15  |proj g|=     0.0073461

iterations 21
function evaluations 33
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00734611
final function value -469.152

F = -469.152
final  value -469.152128 
converged
 
INFO  [00:41:47.085] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:41:47.139] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:41:47.146] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:42:38.500] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:43:30.002] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:44:20.905] [mlr3]  Finished benchmark 
INFO  [00:44:20.969] [bbotk] Result of batch 97: 
INFO  [00:44:20.971] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:44:20.971] [bbotk]                   6              4252    0.007081178        0.643 -0.8745196 
INFO  [00:44:20.971] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:44:20.971] [bbotk]          <NA>   0.9737799 ce7159a7-0d92-4465-bd38-42c11f948398 
DEBUG [00:44:22.152] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.428276e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003428276 0.3461684 
  - best initial criterion value(s) :  401.4354 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -401.44  |proj g|=       5.2974
At iterate     1  f =      -453.83  |proj g|=        11.678
At iterate     2  f =      -467.02  |proj g|=        9.3932
At iterate     3  f =      -469.68  |proj g|=        3.1365
At iterate     4  f =      -469.74  |proj g|=        3.1143
At iterate     5  f =      -469.76  |proj g|=        2.0572
At iterate     6  f =      -469.79  |proj g|=        1.9871
At iterate     7  f =       -469.9  |proj g|=        1.8173
At iterate     8  f =      -470.31  |proj g|=        1.3089
At iterate     9  f =      -470.98  |proj g|=       0.62463
At iterate    10  f =      -471.83  |proj g|=        0.9398
At iterate    11  f =      -471.99  |proj g|=        1.9228
At iterate    12  f =      -472.36  |proj g|=        1.1015
At iterate    13  f =      -472.45  |proj g|=        2.0447
At iterate    14  f =      -472.45  |proj g|=        2.1459
At iterate    15  f =      -472.45  |proj g|=        2.1606
At iterate    16  f =      -472.45  |proj g|=        2.1448
At iterate    17  f =      -472.45  |proj g|=        2.1547
At iterate    18  f =      -472.45  |proj g|=        2.1887
At iterate    19  f =      -472.47  |proj g|=         2.268
At iterate    20  f =      -472.51  |proj g|=        2.1622
At iterate    21  f =      -472.57  |proj g|=        1.6414
At iterate    22  f =      -472.62  |proj g|=       0.80733
At iterate    23  f =      -472.64  |proj g|=      0.078697
At iterate    24  f =      -472.64  |proj g|=        0.3362
At iterate    25  f =      -472.64  |proj g|=        0.3362
At iterate    26  f =      -472.64  |proj g|=       0.33622
At iterate    27  f =      -472.64  |proj g|=       0.33622
At iterate    28  f =      -472.64  |proj g|=      0.014565
At iterate    29  f =      -472.64  |proj g|=     0.0075365
At iterate    30  f =      -472.64  |proj g|=      0.034185
At iterate    31  f =      -472.64  |proj g|=      0.010392

iterations 31
function evaluations 42
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0103925
final function value -472.644

F = -472.644
final  value -472.644271 
converged
 
INFO  [00:44:22.156] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:44:22.211] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:44:22.218] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:44:23.083] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:44:41.580] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:45:00.192] [mlr3]  Finished benchmark 
INFO  [00:45:00.267] [bbotk] Result of batch 98: 
INFO  [00:45:00.269] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:45:00.269] [bbotk]                   8              1462     0.09094522        0.836 -0.8748687 
INFO  [00:45:00.269] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:45:00.269] [bbotk]          <NA>   0.8195861 c6ec7e28-3e00-4905-b8d6-d2fcee77e073 
DEBUG [00:45:01.214] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.401269e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003401269 0.3437121 
  - best initial criterion value(s) :  410.2136 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -410.21  |proj g|=       2.5118
At iterate     1  f =      -431.18  |proj g|=        5.2039
At iterate     2  f =      -432.15  |proj g|=        5.2525
At iterate     3  f =      -432.41  |proj g|=        5.2242
At iterate     4  f =       -433.8  |proj g|=        5.0378
At iterate     5  f =      -436.02  |proj g|=        4.6385
At iterate     6  f =      -438.17  |proj g|=        4.2796
At iterate     7  f =      -444.03  |proj g|=         3.491
At iterate     8  f =      -451.09  |proj g|=        2.6981
At iterate     9  f =       -452.2  |proj g|=        2.3147
At iterate    10  f =      -452.31  |proj g|=        2.2617
At iterate    11  f =      -452.36  |proj g|=        2.3634
At iterate    12  f =       -452.4  |proj g|=        2.3378
At iterate    13  f =      -452.67  |proj g|=        2.2387
At iterate    14  f =       -453.2  |proj g|=        2.1257
At iterate    15  f =      -454.68  |proj g|=       0.79728
At iterate    16  f =      -457.69  |proj g|=        6.2728
At iterate    17  f =      -460.44  |proj g|=        12.505
At iterate    18  f =      -466.75  |proj g|=        9.9031
At iterate    19  f =      -469.43  |proj g|=        5.7697
At iterate    20  f =      -471.06  |proj g|=       0.34707
At iterate    21  f =      -471.11  |proj g|=        0.3345
At iterate    22  f =      -471.13  |proj g|=       0.53642
At iterate    23  f =      -471.15  |proj g|=       0.71935
At iterate    24  f =      -471.15  |proj g|=       0.70155
At iterate    25  f =      -471.16  |proj g|=       0.46918
At iterate    26  f =      -471.17  |proj g|=        0.1855
At iterate    27  f =      -471.17  |proj g|=      0.027802
At iterate    28  f =      -471.17  |proj g|=     0.0087937
At iterate    29  f =      -471.17  |proj g|=      0.039192
At iterate    30  f =      -471.17  |proj g|=     0.0087932

iterations 30
function evaluations 39
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00879325
final function value -471.168

F = -471.168
final  value -471.168276 
converged
 
INFO  [00:45:01.218] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:45:01.272] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:45:01.280] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:45:45.448] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:46:29.306] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:47:13.328] [mlr3]  Finished benchmark 
INFO  [00:47:13.395] [bbotk] Result of batch 99: 
INFO  [00:47:13.397] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:47:13.397] [bbotk]                   5              3636      0.2191011        0.614 -0.8743658 
INFO  [00:47:13.397] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:47:13.397] [bbotk]          <NA>   0.9762117 15fcbcc3-219e-44f3-91ed-be0d76019c42 
DEBUG [00:47:14.309] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.383721e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003383721 0.3429353 
  - best initial criterion value(s) :  457.6718 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -457.67  |proj g|=       4.4207
At iterate     1  f =      -467.95  |proj g|=        9.5056
At iterate     2  f =      -475.93  |proj g|=        7.2816
At iterate     3  f =      -478.34  |proj g|=         1.881
At iterate     4  f =       -478.4  |proj g|=       0.58666
At iterate     5  f =      -478.41  |proj g|=       0.25512
At iterate     6  f =      -478.41  |proj g|=       0.33454
At iterate     7  f =      -478.41  |proj g|=       0.33457
At iterate     8  f =      -478.42  |proj g|=       0.33461
At iterate     9  f =      -478.42  |proj g|=       0.33466
At iterate    10  f =      -478.44  |proj g|=       0.33471
At iterate    11  f =      -478.49  |proj g|=       0.33471
At iterate    12  f =      -478.58  |proj g|=       0.54517
At iterate    13  f =       -478.7  |proj g|=       0.98265
At iterate    14  f =       -478.8  |proj g|=        1.4041
At iterate    15  f =      -478.84  |proj g|=       0.98556
At iterate    16  f =      -478.89  |proj g|=       0.33323
At iterate    17  f =      -478.89  |proj g|=       0.33321
At iterate    18  f =      -478.89  |proj g|=      0.074137
At iterate    19  f =      -478.89  |proj g|=     0.0085281

iterations 19
function evaluations 25
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00852807
final function value -478.889

F = -478.889
final  value -478.888911 
converged
 
INFO  [00:47:14.313] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:47:14.376] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:47:14.383] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:47:28.950] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:47:42.995] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:47:57.113] [mlr3]  Finished benchmark 
INFO  [00:47:57.181] [bbotk] Result of batch 100: 
INFO  [00:47:57.183] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:47:57.183] [bbotk]                   5              1113     0.03090429         0.62 -0.8738878 
INFO  [00:47:57.183] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:47:57.183] [bbotk]          <NA>   0.9739326 868237a4-6e2b-43cd-9115-e95159d03010 
DEBUG [00:47:58.119] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.365878e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003365878 0.3401101 
  - best initial criterion value(s) :  421.1535 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -421.15  |proj g|=       12.689
At iterate     1  f =      -454.18  |proj g|=        5.1714
At iterate     2  f =      -471.92  |proj g|=        1.7084
At iterate     3  f =      -484.11  |proj g|=       0.40088
At iterate     4  f =       -484.2  |proj g|=        1.4216
At iterate     5  f =      -484.22  |proj g|=       0.36027
At iterate     6  f =      -484.22  |proj g|=       0.71081
At iterate     7  f =      -484.28  |proj g|=        1.0457
At iterate     8  f =      -484.67  |proj g|=        2.2816
At iterate     9  f =      -485.25  |proj g|=        2.3362
At iterate    10  f =      -486.37  |proj g|=        2.4502
At iterate    11  f =      -486.68  |proj g|=        2.6838
At iterate    12  f =      -487.22  |proj g|=        2.6909
At iterate    13  f =      -487.56  |proj g|=        1.0793
At iterate    14  f =      -487.86  |proj g|=       0.33063
At iterate    15  f =      -487.91  |proj g|=        0.3302
At iterate    16  f =      -487.91  |proj g|=       0.33007
At iterate    17  f =      -487.91  |proj g|=     0.0094165
At iterate    18  f =      -487.91  |proj g|=      0.007413
At iterate    19  f =      -487.91  |proj g|=      0.007413

iterations 19
function evaluations 27
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00741302
final function value -487.913

F = -487.913
final  value -487.912719 
converged
 
INFO  [00:47:58.123] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:47:58.187] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:47:58.193] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:48:40.078] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:49:22.082] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:50:04.040] [mlr3]  Finished benchmark 
INFO  [00:50:04.105] [bbotk] Result of batch 101: 
INFO  [00:50:04.106] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:50:04.106] [bbotk]                   4              3440      0.4119343        0.636 -0.8739729 
INFO  [00:50:04.106] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:50:04.106] [bbotk]          <NA>   0.9760256 01b189f3-db97-4c14-b5e3-bc9cffb5b706 
DEBUG [00:50:05.246] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.34854e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.00334854 0.3392343 
  - best initial criterion value(s) :  410.518 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -410.52  |proj g|=        12.65
At iterate     1  f =      -448.04  |proj g|=        2.1386
At iterate     2  f =      -457.29  |proj g|=        3.2082
At iterate     3  f =      -461.03  |proj g|=        3.0348
At iterate     4  f =      -462.81  |proj g|=        2.8111
At iterate     5  f =      -465.36  |proj g|=        2.2154
At iterate     6  f =      -465.79  |proj g|=         3.073
At iterate     7  f =      -466.36  |proj g|=         1.054
At iterate     8  f =      -466.41  |proj g|=         1.641
At iterate     9  f =      -466.41  |proj g|=        1.4406
At iterate    10  f =      -466.42  |proj g|=        1.3527
At iterate    11  f =      -466.44  |proj g|=       0.90969
At iterate    12  f =      -466.49  |proj g|=       0.39689
At iterate    13  f =      -466.61  |proj g|=       0.65388
At iterate    14  f =      -466.87  |proj g|=        2.2381
At iterate    15  f =      -467.39  |proj g|=        4.5621
At iterate    16  f =      -468.19  |proj g|=        7.1239
At iterate    17  f =       -469.9  |proj g|=        2.5296
At iterate    18  f =      -470.29  |proj g|=        3.5904
At iterate    19  f =      -471.79  |proj g|=        3.3802
At iterate    20  f =      -472.96  |proj g|=       0.92562
At iterate    21  f =      -473.04  |proj g|=       0.33147
At iterate    22  f =      -473.29  |proj g|=       0.66511
At iterate    23  f =      -473.33  |proj g|=       0.51052
At iterate    24  f =      -473.39  |proj g|=       0.32984
At iterate    25  f =      -473.39  |proj g|=       0.12505
At iterate    26  f =      -473.39  |proj g|=       0.32975
At iterate    27  f =      -473.39  |proj g|=       0.10569
At iterate    28  f =      -473.39  |proj g|=      0.010974

iterations 28
function evaluations 37
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0109744
final function value -473.394

F = -473.394
final  value -473.394431 
converged
 
INFO  [00:50:05.250] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:50:05.303] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:50:05.310] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:50:06.402] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:50:27.476] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:50:48.714] [mlr3]  Finished benchmark 
INFO  [00:50:48.781] [bbotk] Result of batch 102: 
INFO  [00:50:48.783] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [00:50:48.783] [bbotk]                   8              1676      0.1465847        0.798 -0.873607 
INFO  [00:50:48.783] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:50:48.783] [bbotk]          <NA>   0.8197064 c18f2d94-6c90-48d4-8af5-a6621aca88af 
DEBUG [00:50:49.696] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.323208e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003323208 0.336358 
  - best initial criterion value(s) :  450.2552 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -450.26  |proj g|=       5.9183
At iterate     1  f =       -463.9  |proj g|=        3.6293
At iterate     2  f =      -465.43  |proj g|=        5.1439
At iterate     3  f =      -470.62  |proj g|=        5.4114
At iterate     4  f =      -473.11  |proj g|=        5.2364
At iterate     5  f =      -480.55  |proj g|=        4.6682
At iterate     6  f =      -496.68  |proj g|=        2.7383
At iterate     7  f =      -500.71  |proj g|=       0.64964
At iterate     8  f =      -500.77  |proj g|=      0.094824
At iterate     9  f =       -500.8  |proj g|=       0.56147
At iterate    10  f =       -500.8  |proj g|=       0.48519
At iterate    11  f =       -500.8  |proj g|=       0.44442
At iterate    12  f =       -500.8  |proj g|=       0.30004
At iterate    13  f =       -500.8  |proj g|=       0.14597
At iterate    14  f =       -500.8  |proj g|=      0.040692
At iterate    15  f =      -500.81  |proj g|=       0.32639
At iterate    16  f =      -500.81  |proj g|=       0.16525
At iterate    17  f =      -500.81  |proj g|=     0.0075972

iterations 17
function evaluations 24
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00759723
final function value -500.806

F = -500.806
final  value -500.806470 
converged
 
INFO  [00:50:49.701] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:50:49.757] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:50:49.764] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:50:50.491] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:50:51.457] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:50:52.169] [mlr3]  Finished benchmark 
INFO  [00:50:52.244] [bbotk] Result of batch 103: 
INFO  [00:50:52.246] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:50:52.246] [bbotk]                  10              2373      0.2119471        0.622 -0.8731501 
INFO  [00:50:52.246] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:50:52.246] [bbotk]          <NA>         0.5 c441e617-09d1-4e37-8f7d-d92689683dd6 
DEBUG [00:50:53.143] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.402388e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003402388 0.3429631 
  - best initial criterion value(s) :  438.4795 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -438.48  |proj g|=       5.4514
At iterate     1  f =      -440.93  |proj g|=        5.2424
At iterate     2  f =      -442.11  |proj g|=        5.2567
At iterate     3  f =      -443.71  |proj g|=        5.1769
At iterate     4  f =      -445.67  |proj g|=        5.1005
At iterate     5  f =      -449.84  |proj g|=        4.8022
At iterate     6  f =      -463.46  |proj g|=        3.6773
At iterate     7  f =       -466.7  |proj g|=         3.453
At iterate     8  f =         -468  |proj g|=        3.2506
At iterate     9  f =      -469.25  |proj g|=        3.0025
At iterate    10  f =      -470.67  |proj g|=        1.1539
At iterate    11  f =       -470.7  |proj g|=      0.013976
At iterate    12  f =       -470.7  |proj g|=       0.33399
At iterate    13  f =       -470.7  |proj g|=       0.01397
At iterate    14  f =       -470.7  |proj g|=       0.01397

iterations 14
function evaluations 18
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0139703
final function value -470.701

F = -470.701
final  value -470.700816 
converged
 
INFO  [00:50:53.147] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:50:53.199] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:50:53.205] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:51:16.260] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:51:39.853] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:52:03.117] [mlr3]  Finished benchmark 
INFO  [00:52:03.182] [bbotk] Result of batch 104: 
INFO  [00:52:03.184] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:52:03.184] [bbotk]                   3              1885      0.3405426        0.628 -0.8732617 
INFO  [00:52:03.184] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:52:03.184] [bbotk]          <NA>   0.9765424 71d9a0ab-beb8-4d8b-90ea-e40ad5992da9 
DEBUG [00:52:04.133] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.385687e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003385687 0.3410907 
  - best initial criterion value(s) :  449.107 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -449.11  |proj g|=       4.5596
At iterate     1  f =      -466.84  |proj g|=        9.2609
At iterate     2  f =       -475.6  |proj g|=        6.8448
At iterate     3  f =      -477.58  |proj g|=        1.8271
At iterate     4  f =      -477.59  |proj g|=       0.79862
At iterate     5  f =      -477.61  |proj g|=       0.33399
At iterate     6  f =      -477.62  |proj g|=       0.91791
At iterate     7  f =      -477.63  |proj g|=       0.37589
At iterate     8  f =      -477.63  |proj g|=       0.39318
At iterate     9  f =      -477.63  |proj g|=       0.41284
At iterate    10  f =      -477.64  |proj g|=       0.47926
At iterate    11  f =      -477.64  |proj g|=       0.57154
At iterate    12  f =      -477.66  |proj g|=       0.72031
At iterate    13  f =       -477.7  |proj g|=       0.94169
At iterate    14  f =      -477.78  |proj g|=        1.3081
At iterate    15  f =      -477.78  |proj g|=       0.96029
At iterate    16  f =      -477.91  |proj g|=        1.1157
At iterate    17  f =      -478.11  |proj g|=       0.41695
At iterate    18  f =      -478.12  |proj g|=       0.33217
At iterate    19  f =      -478.12  |proj g|=       0.33214
At iterate    20  f =      -478.12  |proj g|=       0.14298
At iterate    21  f =      -478.12  |proj g|=      0.013805

iterations 21
function evaluations 26
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0138048
final function value -478.124

F = -478.124
final  value -478.123769 
converged
 
INFO  [00:52:04.137] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:52:04.190] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:52:04.196] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:52:11.521] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:52:18.702] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:52:26.008] [mlr3]  Finished benchmark 
INFO  [00:52:26.075] [bbotk] Result of batch 105: 
INFO  [00:52:26.077] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:52:26.077] [bbotk]                   3               516      0.4747585        0.645 -0.8727291 
INFO  [00:52:26.077] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:52:26.077] [bbotk]          <NA>   0.9754006 01fb29d8-bc3a-4e5c-a341-2037133e2a98 
DEBUG [00:52:27.006] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.368888e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003368888 0.3376867 
  - best initial criterion value(s) :  434.5031 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -434.5  |proj g|=      0.66728
At iterate     1  f =      -456.14  |proj g|=        5.0481
At iterate     2  f =      -460.87  |proj g|=        5.1624
At iterate     3  f =      -461.77  |proj g|=        5.1881
At iterate     4  f =         -466  |proj g|=        5.4212
At iterate     5  f =      -466.44  |proj g|=        5.4477
At iterate     6  f =      -466.49  |proj g|=        5.4439
At iterate     7  f =      -466.82  |proj g|=        5.4034
At iterate     8  f =      -467.24  |proj g|=         5.352
At iterate     9  f =      -469.31  |proj g|=        5.0587
At iterate    10  f =      -473.25  |proj g|=        4.6756
At iterate    11  f =       -484.9  |proj g|=        3.6185
At iterate    12  f =      -490.32  |proj g|=        10.343
At iterate    13  f =      -492.97  |proj g|=       0.20747
At iterate    14  f =      -493.08  |proj g|=       0.98545
At iterate    15  f =      -493.14  |proj g|=       0.12942
At iterate    16  f =      -493.14  |proj g|=      0.012235
At iterate    17  f =      -493.14  |proj g|=       0.10451
At iterate    18  f =      -493.14  |proj g|=      0.012233

iterations 18
function evaluations 22
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0122334
final function value -493.143

F = -493.143
final  value -493.143484 
converged
 
INFO  [00:52:27.010] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:52:27.065] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:52:27.071] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:52:57.479] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:53:28.018] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:53:59.091] [mlr3]  Finished benchmark 
INFO  [00:53:59.157] [bbotk] Result of batch 106: 
INFO  [00:53:59.159] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [00:53:59.159] [bbotk]                   3              2493      0.2175078         0.64 -0.872483 
INFO  [00:53:59.159] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:53:59.159] [bbotk]          <NA>   0.9765114 c08d6e59-300c-4ba1-bd13-afe5ac668dc5 
DEBUG [00:54:00.249] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.352393e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003352393 0.3376376 
  - best initial criterion value(s) :  480.5426 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -480.54  |proj g|=       4.4586
At iterate     1  f =      -496.22  |proj g|=         5.398
At iterate     2  f =      -500.34  |proj g|=       0.20857
At iterate     3  f =      -500.95  |proj g|=       0.32982
At iterate     4  f =      -500.96  |proj g|=       0.47745
At iterate     5  f =      -500.96  |proj g|=       0.21756
At iterate     6  f =      -500.96  |proj g|=        0.3298
At iterate     7  f =      -500.96  |proj g|=        0.3298
At iterate     8  f =      -500.97  |proj g|=       0.32978
At iterate     9  f =      -500.99  |proj g|=       0.69492
At iterate    10  f =      -501.03  |proj g|=         1.215
At iterate    11  f =       -501.1  |proj g|=        1.6204
At iterate    12  f =      -501.12  |proj g|=        1.5716
At iterate    13  f =      -501.22  |proj g|=        1.1602
At iterate    14  f =      -501.25  |proj g|=       0.43423
At iterate    15  f =      -501.26  |proj g|=      0.046687
At iterate    16  f =      -501.26  |proj g|=      0.011724
At iterate    17  f =      -501.26  |proj g|=        0.3206

iterations 17
function evaluations 24
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.320603
final function value -501.26

F = -501.26
final  value -501.259643 
converged
 
INFO  [00:54:00.253] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:54:00.308] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:54:00.315] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:54:52.658] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:55:45.763] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:56:38.668] [mlr3]  Finished benchmark 
INFO  [00:56:38.733] [bbotk] Result of batch 107: 
INFO  [00:56:38.735] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:56:38.735] [bbotk]                   6              4372      0.3025007        0.625 -0.8722532 
INFO  [00:56:38.735] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:56:38.735] [bbotk]          <NA>   0.9744511 653fc804-85a0-4caf-a410-f1f3c9212a08 
DEBUG [00:56:39.655] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.335653e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003335653 0.3348225 
  - best initial criterion value(s) :  446.8254 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -446.83  |proj g|=       7.1065
At iterate     1  f =      -449.87  |proj g|=        6.5256
At iterate     2  f =      -493.27  |proj g|=        5.0511
At iterate     3  f =      -500.75  |proj g|=        4.5986
At iterate     4  f =      -524.77  |proj g|=        1.9069
At iterate     5  f =      -524.78  |proj g|=        1.4275
At iterate     6  f =      -524.86  |proj g|=       0.32547
At iterate     7  f =      -524.87  |proj g|=       0.22078
At iterate     8  f =      -524.88  |proj g|=       0.24644
At iterate     9  f =      -524.88  |proj g|=      0.051391
At iterate    10  f =      -524.88  |proj g|=     0.0085101
At iterate    11  f =      -524.88  |proj g|=     0.0085093
At iterate    12  f =      -524.88  |proj g|=      0.008708

iterations 12
function evaluations 20
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00870801
final function value -524.882

F = -524.882
final  value -524.881834 
converged
 
INFO  [00:56:39.659] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:56:39.715] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:56:39.722] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:57:21.125] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:58:02.521] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:58:03.367] [mlr3]  Finished benchmark 
INFO  [00:58:03.432] [bbotk] Result of batch 108: 
INFO  [00:58:03.433] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:58:03.433] [bbotk]                   8              3406      0.2955347        0.634 -0.8721234 
INFO  [00:58:03.433] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:58:03.433] [bbotk]          <NA>   0.8179004 587b5eba-beee-419b-b02f-478d7e1671f4 
DEBUG [00:58:04.396] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.311734e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003311734 0.3330875 
  - best initial criterion value(s) :  470.7839 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -470.78  |proj g|=       6.6102
At iterate     1  f =      -474.01  |proj g|=        6.3243
At iterate     2  f =      -501.23  |proj g|=        5.2311
At iterate     3  f =      -509.24  |proj g|=        4.7344
At iterate     4  f =      -534.79  |proj g|=        1.2478
At iterate     5  f =      -536.14  |proj g|=        3.4888
At iterate     6  f =      -536.39  |proj g|=        0.4187
At iterate     7  f =      -536.43  |proj g|=       0.26205
At iterate     8  f =      -536.44  |proj g|=       0.26745
At iterate     9  f =      -536.44  |proj g|=       0.32379
At iterate    10  f =      -536.44  |proj g|=       0.32381
At iterate    11  f =      -536.44  |proj g|=       0.32383
At iterate    12  f =      -536.45  |proj g|=       0.32383
At iterate    13  f =      -536.46  |proj g|=       0.32377
At iterate    14  f =      -536.47  |proj g|=        0.3237
At iterate    15  f =      -536.48  |proj g|=       0.17934
At iterate    16  f =      -536.48  |proj g|=       0.15657
At iterate    17  f =      -536.48  |proj g|=      0.047328
At iterate    18  f =      -536.48  |proj g|=     0.0077839
At iterate    19  f =      -536.48  |proj g|=     0.0077837

iterations 19
function evaluations 27
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00778369
final function value -536.484

F = -536.484
final  value -536.484219 
converged
 
INFO  [00:58:04.400] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:58:04.456] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:58:04.463] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:58:10.833] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:58:17.304] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:58:24.503] [mlr3]  Finished benchmark 
INFO  [00:58:24.566] [bbotk] Result of batch 109: 
INFO  [00:58:24.568] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:58:24.568] [bbotk]                   7               437      0.1580121        0.634 -0.8718658 
INFO  [00:58:24.568] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:58:24.568] [bbotk]          <NA>    0.975006 12ef4ed3-57d8-4e73-b659-e4a8e4fc4859 
DEBUG [00:58:25.638] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.295574e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9408 0.9854458 
  - variance bounds :  0.003295574 0.3297595 
  - best initial criterion value(s) :  487.6928 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -487.69  |proj g|=       6.9168
At iterate     1  f =      -519.58  |proj g|=        8.0307
At iterate     2  f =      -538.86  |proj g|=        2.8157
At iterate     3  f =      -539.21  |proj g|=        1.7665
At iterate     4  f =      -539.43  |proj g|=       0.22283
At iterate     5  f =      -539.44  |proj g|=       0.32102
At iterate     6  f =      -539.47  |proj g|=       0.32107
At iterate     7  f =      -539.52  |proj g|=       0.33455
At iterate     8  f =      -539.59  |proj g|=       0.58705
At iterate     9  f =      -539.62  |proj g|=       0.32043
At iterate    10  f =      -539.62  |proj g|=       0.32033
At iterate    11  f =      -539.62  |proj g|=         0.249
At iterate    12  f =      -539.62  |proj g|=       0.22997
At iterate    13  f =      -539.62  |proj g|=       0.16137
At iterate    14  f =      -539.62  |proj g|=      0.059988
At iterate    15  f =      -539.62  |proj g|=     0.0082134
At iterate    16  f =      -539.62  |proj g|=     0.0082125
At iterate    17  f =      -539.62  |proj g|=     0.0082125

iterations 17
function evaluations 23
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00821245
final function value -539.623

F = -539.623
final  value -539.623362 
converged
 
INFO  [00:58:25.641] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:58:25.694] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:58:25.701] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [00:58:29.561] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:58:33.391] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [00:58:37.033] [mlr3]  Finished benchmark 
INFO  [00:58:37.122] [bbotk] Result of batch 110: 
INFO  [00:58:37.124] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [00:58:37.124] [bbotk]                   5               211      0.2504339        0.741 -0.8714007 
INFO  [00:58:37.124] [bbotk]  errors.model classif.auc                                uhash 
INFO  [00:58:37.124] [bbotk]          <NA>   0.9749496 0ac47603-b020-4741-a87c-7f83e79acc3c 
DEBUG [00:58:38.425] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.279513e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9854458 
  - variance bounds :  0.003271539 0.3279513 
  - best initial criterion value(s) :  510.4566 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -510.46  |proj g|=       3.9049
At iterate     1  f =      -516.47  |proj g|=        4.0619
At iterate     2  f =      -523.49  |proj g|=        3.6613
At iterate     3  f =      -525.58  |proj g|=        3.3377
At iterate     4  f =      -529.67  |proj g|=        2.8562
At iterate     5  f =      -531.83  |proj g|=        1.1941
At iterate     6  f =      -532.02  |proj g|=        2.2207
At iterate     7  f =      -532.04  |proj g|=        2.4082
At iterate     8  f =      -532.14  |proj g|=        2.2904
At iterate     9  f =      -533.62  |proj g|=        2.3275
At iterate    10  f =      -535.43  |proj g|=        2.4511
At iterate    11  f =      -537.26  |proj g|=        1.3007
At iterate    12  f =      -537.69  |proj g|=       0.95574
At iterate    13  f =      -537.87  |proj g|=       0.98537
At iterate    14  f =      -537.89  |proj g|=       0.31892
At iterate    15  f =      -537.89  |proj g|=       0.42481
At iterate    16  f =      -537.89  |proj g|=       0.34899
At iterate    17  f =       -537.9  |proj g|=       0.31603
At iterate    18  f =       -537.9  |proj g|=      0.017857
At iterate    19  f =       -537.9  |proj g|=      0.009465
At iterate    20  f =       -537.9  |proj g|=     0.0094651
At iterate    21  f =       -537.9  |proj g|=       0.31873
At iterate    22  f =       -537.9  |proj g|=      0.017684
At iterate    23  f =       -537.9  |proj g|=      0.010203
At iterate    24  f =       -537.9  |proj g|=      0.009469
At iterate    25  f =       -537.9  |proj g|=      0.026422
At iterate    26  f =       -537.9  |proj g|=      0.062258
At iterate    27  f =      -537.91  |proj g|=       0.11788
At iterate    28  f =      -537.93  |proj g|=        0.1538
At iterate    29  f =      -537.99  |proj g|=      0.036072
At iterate    30  f =       -538.1  |proj g|=       0.52597
At iterate    31  f =      -538.27  |proj g|=        1.4376
At iterate    32  f =      -538.51  |proj g|=        3.0585
At iterate    33  f =      -538.75  |proj g|=        3.1529
At iterate    34  f =      -539.46  |proj g|=        3.3252
At iterate    35  f =      -540.94  |proj g|=        3.5794
At iterate    36  f =      -543.01  |proj g|=        3.6272
At iterate    37  f =      -545.19  |proj g|=        3.2386
At iterate    38  f =      -547.54  |proj g|=        1.5119
At iterate    39  f =       -547.6  |proj g|=      0.019085
At iterate    40  f =       -547.6  |proj g|=       0.31841
At iterate    41  f =       -547.6  |proj g|=     0.0062792
At iterate    42  f =       -547.6  |proj g|=    0.00038817

iterations 42
function evaluations 51
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000388167
final function value -547.604

F = -547.604
final  value -547.604250 
converged
 
INFO  [00:58:38.429] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:58:38.490] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:58:38.498] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [00:59:36.372] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:00:34.410] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:01:32.028] [mlr3]  Finished benchmark 
INFO  [01:01:32.094] [bbotk] Result of batch 111: 
INFO  [01:01:32.095] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:01:32.095] [bbotk]                   6              4799      0.4755705        0.635 -0.8695395 
INFO  [01:01:32.095] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:01:32.095] [bbotk]          <NA>   0.9729758 12db691f-c3b2-4608-b634-efb282b2b6a6 
DEBUG [01:01:33.072] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.263246e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9854458 
  - variance bounds :  0.003238917 0.3263246 
  - best initial criterion value(s) :  474.1309 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -474.13  |proj g|=       7.1171
At iterate     1  f =      -481.95  |proj g|=        4.4624
At iterate     2  f =      -488.12  |proj g|=        4.5175
At iterate     3  f =      -490.92  |proj g|=        4.3327
At iterate     4  f =      -494.59  |proj g|=        4.0261
At iterate     5  f =      -505.03  |proj g|=        3.0846
At iterate     6  f =      -510.97  |proj g|=       0.58635
At iterate     7  f =      -510.99  |proj g|=       0.57972
At iterate     8  f =      -510.99  |proj g|=       0.54046
At iterate     9  f =      -511.56  |proj g|=        1.1141
At iterate    10  f =      -512.64  |proj g|=        1.4765
At iterate    11  f =      -513.02  |proj g|=       0.56671
At iterate    12  f =      -513.02  |proj g|=       0.96557
At iterate    13  f =      -513.08  |proj g|=       0.38146
At iterate    14  f =      -513.09  |proj g|=       0.31794
At iterate    15  f =      -513.09  |proj g|=        0.3179
At iterate    16  f =      -513.09  |proj g|=      0.087857

iterations 16
function evaluations 27
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0878568
final function value -513.086

F = -513.086
final  value -513.086373 
converged
 
INFO  [01:01:33.075] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:01:33.132] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:01:33.138] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:01:33.865] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:01:34.609] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:01:35.715] [mlr3]  Finished benchmark 
INFO  [01:01:35.786] [bbotk] Result of batch 112: 
INFO  [01:01:35.788] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:01:35.788] [bbotk]                   9              4982      0.4957677        0.649 -0.8701965 
INFO  [01:01:35.788] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:01:35.788] [bbotk]          <NA>         0.5 8967e78c-b9a3-4f85-8ff0-d58841784d00 
DEBUG [01:01:36.761] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.339059e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9877653 
  - variance bounds :  0.003339059 0.336308 
  - best initial criterion value(s) :  510.1673 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -510.17  |proj g|=       4.0969
At iterate     1  f =      -523.34  |proj g|=        9.2364
At iterate     2  f =      -530.29  |proj g|=        5.8396
At iterate     3  f =      -531.41  |proj g|=        2.4359
At iterate     4  f =       -531.5  |proj g|=       0.63469
At iterate     5  f =      -531.51  |proj g|=       0.40448
At iterate     6  f =      -531.51  |proj g|=       0.33135
At iterate     7  f =      -531.56  |proj g|=       0.32936
At iterate     8  f =      -531.65  |proj g|=       0.43587
At iterate     9  f =      -531.82  |proj g|=       0.83428
At iterate    10  f =         -532  |proj g|=       0.96762
At iterate    11  f =       -532.1  |proj g|=       0.98615
At iterate    12  f =       -532.1  |proj g|=       0.98777
At iterate    13  f =      -532.11  |proj g|=       0.98777
At iterate    14  f =      -532.11  |proj g|=       0.98777
At iterate    15  f =      -532.11  |proj g|=       0.98777
At iterate    16  f =      -532.11  |proj g|=       0.98698
At iterate    17  f =      -532.12  |proj g|=        0.4589
At iterate    18  f =      -532.13  |proj g|=       0.32759
At iterate    19  f =      -532.13  |proj g|=       0.32756
At iterate    20  f =      -532.14  |proj g|=       0.24849
At iterate    21  f =      -532.14  |proj g|=      0.012584

iterations 21
function evaluations 26
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0125844
final function value -532.135

F = -532.135
final  value -532.135204 
converged
 
INFO  [01:01:36.765] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:01:36.819] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:01:36.825] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:01:43.393] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:01:50.049] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:01:56.826] [mlr3]  Finished benchmark 
INFO  [01:01:56.891] [bbotk] Result of batch 113: 
INFO  [01:01:56.892] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:01:56.892] [bbotk]                   4               481     0.03879402         0.65 -0.8669044 
INFO  [01:01:56.892] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:01:56.892] [bbotk]          <NA>   0.9689345 bafa5fb4-4995-47ff-abb4-5d6e806a8175 
DEBUG [01:01:58.085] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.322268e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9877653 
  - variance bounds :  0.003322268 0.3335198 
  - best initial criterion value(s) :  455.374 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -455.37  |proj g|=       12.948
At iterate     1  f =      -522.21  |proj g|=        5.1899
At iterate     2  f =      -525.19  |proj g|=        4.9705
At iterate     3  f =      -533.73  |proj g|=        4.2645
At iterate     4  f =      -540.94  |proj g|=        3.7484
At iterate     5  f =      -550.03  |proj g|=        2.7107
At iterate     6  f =      -550.85  |proj g|=        1.9104
At iterate     7  f =      -551.09  |proj g|=        1.6759
At iterate     8  f =      -551.24  |proj g|=       0.13557
At iterate     9  f =      -551.25  |proj g|=       0.13541
At iterate    10  f =      -551.26  |proj g|=       0.32674
At iterate    11  f =      -551.27  |proj g|=        0.3268
At iterate    12  f =      -551.33  |proj g|=       0.32691
At iterate    13  f =      -551.45  |proj g|=       0.32695
At iterate    14  f =      -551.72  |proj g|=       0.32679
At iterate    15  f =      -552.09  |proj g|=       0.93697
At iterate    16  f =      -552.17  |proj g|=       0.99299
At iterate    17  f =      -552.51  |proj g|=       0.98701
At iterate    18  f =      -552.58  |proj g|=       0.98777
At iterate    19  f =      -552.59  |proj g|=       0.94335
At iterate    20  f =      -552.59  |proj g|=        0.9687
At iterate    21  f =      -552.59  |proj g|=       0.99283
At iterate    22  f =      -552.59  |proj g|=       0.97798
At iterate    23  f =      -552.59  |proj g|=       0.96618
At iterate    24  f =       -552.6  |proj g|=       0.81142
At iterate    25  f =       -552.6  |proj g|=       0.79822
At iterate    26  f =      -552.62  |proj g|=        0.3244
At iterate    27  f =      -552.62  |proj g|=       0.32439
At iterate    28  f =      -552.62  |proj g|=     0.0098089

iterations 28
function evaluations 38
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00980889
final function value -552.624

F = -552.624
final  value -552.623807 
converged
 
INFO  [01:01:58.089] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:01:58.143] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:01:58.150] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:02:55.499] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:03:51.716] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:04:47.600] [mlr3]  Finished benchmark 
INFO  [01:04:47.665] [bbotk] Result of batch 114: 
INFO  [01:04:47.667] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:04:47.667] [bbotk]                   5              4693      0.1152934        0.814 -0.8665901 
INFO  [01:04:47.667] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:04:47.667] [bbotk]          <NA>   0.9767977 12cc6446-17bc-4916-9573-f549270574b0 
DEBUG [01:04:48.737] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.306837e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9877653 
  - variance bounds :  0.003306837 0.3312569 
  - best initial criterion value(s) :  492.9426 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -492.94  |proj g|=       11.445
At iterate     1  f =      -511.92  |proj g|=        4.0563
At iterate     2  f =      -524.63  |proj g|=        3.5835
At iterate     3  f =      -526.18  |proj g|=        3.4541
At iterate     4  f =       -529.5  |proj g|=        3.1685
At iterate     5  f =      -536.02  |proj g|=        2.5073
At iterate     6  f =      -537.19  |proj g|=       0.34204
At iterate     7  f =      -546.16  |proj g|=        5.7362
At iterate     8  f =      -547.67  |proj g|=        1.2935
At iterate     9  f =      -547.73  |proj g|=       0.32252
At iterate    10  f =      -547.73  |proj g|=      0.031145
At iterate    11  f =      -547.73  |proj g|=      0.096059
At iterate    12  f =      -547.73  |proj g|=       0.32246
At iterate    13  f =      -547.73  |proj g|=       0.11199

iterations 13
function evaluations 22
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.111987
final function value -547.73

F = -547.73
final  value -547.730176 
converged
 
INFO  [01:04:48.741] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:04:48.795] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:04:48.802] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:05:28.143] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:06:07.575] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:06:08.436] [mlr3]  Finished benchmark 
INFO  [01:06:08.502] [bbotk] Result of batch 115: 
INFO  [01:06:08.504] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:06:08.504] [bbotk]                   8              3276      0.2344785        0.723 -0.8658887 
INFO  [01:06:08.504] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:06:08.504] [bbotk]          <NA>   0.8184049 bdefbdb9-4985-4ef5-9a63-1c23e62119ae 
DEBUG [01:06:09.608] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.284382e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9877653 
  - variance bounds :  0.003284382 0.3293394 
  - best initial criterion value(s) :  502.5123 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -502.51  |proj g|=       10.919
At iterate     1  f =      -523.75  |proj g|=       0.62051
At iterate     2  f =      -540.13  |proj g|=        4.3142
At iterate     3  f =      -541.26  |proj g|=        4.2591
At iterate     4  f =      -551.29  |proj g|=        3.4457
At iterate     5  f =      -561.71  |proj g|=        2.3103
At iterate     6  f =      -561.78  |proj g|=        1.3256
At iterate     7  f =      -561.83  |proj g|=       0.44274
At iterate     8  f =      -562.12  |proj g|=       0.33737
At iterate     9  f =      -564.71  |proj g|=       0.32349
At iterate    10  f =      -565.91  |proj g|=       0.36494
At iterate    11  f =      -566.46  |proj g|=       0.96329
At iterate    12  f =      -566.53  |proj g|=         1.222
At iterate    13  f =      -566.66  |proj g|=       0.98777
At iterate    14  f =      -566.68  |proj g|=        0.3808
At iterate    15  f =      -566.71  |proj g|=       0.68373
At iterate    16  f =      -566.73  |proj g|=       0.32027
At iterate    17  f =      -566.73  |proj g|=     0.0094575
At iterate    18  f =      -566.73  |proj g|=       0.01238

iterations 18
function evaluations 32
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0123795
final function value -566.729

F = -566.729
final  value -566.729357 
converged
 
INFO  [01:06:09.612] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:06:09.674] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:06:09.681] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:07:03.965] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:07:57.013] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:08:49.872] [mlr3]  Finished benchmark 
INFO  [01:08:49.939] [bbotk] Result of batch 116: 
INFO  [01:08:49.941] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:08:49.941] [bbotk]                   7              4437      0.4596691        0.718 -0.8649986 
INFO  [01:08:49.941] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:08:49.941] [bbotk]          <NA>   0.9725241 14de5610-6fc7-4aef-84dd-be363a6c7d2e 
DEBUG [01:08:51.128] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.26871e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9877653 
  - variance bounds :  0.00326871 0.327766 
  - best initial criterion value(s) :  520.9827 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -520.98  |proj g|=       5.9947
At iterate     1  f =      -533.78  |proj g|=        4.7791
At iterate     2  f =       -540.2  |proj g|=        4.5522
At iterate     3  f =      -542.37  |proj g|=        4.3899
At iterate     4  f =      -544.55  |proj g|=        4.1573
At iterate     5  f =      -551.89  |proj g|=        3.3466
At iterate     6  f =      -558.01  |proj g|=          2.64
At iterate     7  f =      -558.58  |proj g|=        1.0138
At iterate     8  f =       -559.2  |proj g|=        2.1071
At iterate     9  f =      -559.37  |proj g|=        2.3391
At iterate    10  f =      -559.48  |proj g|=        2.2506
At iterate    11  f =      -559.51  |proj g|=        2.2366
At iterate    12  f =      -559.79  |proj g|=         2.151
At iterate    13  f =      -560.34  |proj g|=        1.0198
At iterate    14  f =      -561.79  |proj g|=        3.5981
At iterate    15  f =      -564.66  |proj g|=        8.8984
At iterate    16  f =      -567.06  |proj g|=        11.389
At iterate    17  f =       -571.3  |proj g|=        9.0244
At iterate    18  f =      -577.48  |proj g|=        1.3078
At iterate    19  f =      -577.99  |proj g|=        1.1308
At iterate    20  f =      -578.04  |proj g|=        1.0067
At iterate    21  f =      -578.07  |proj g|=       0.31857
At iterate    22  f =      -578.07  |proj g|=      0.051312
At iterate    23  f =      -578.07  |proj g|=      0.008441
At iterate    24  f =      -578.07  |proj g|=      0.008441

iterations 24
function evaluations 35
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.008441
final function value -578.074

F = -578.074
final  value -578.073544 
converged
 
INFO  [01:08:51.132] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:08:51.188] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:08:51.195] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:08:51.940] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:08:52.660] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:08:53.389] [mlr3]  Finished benchmark 
INFO  [01:08:53.455] [bbotk] Result of batch 117: 
INFO  [01:08:53.457] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:08:53.457] [bbotk]                  10              2544      0.2984981        0.767 -0.8646472 
INFO  [01:08:53.457] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:08:53.457] [bbotk]          <NA>         0.5 187afd48-5321-4594-8207-efd2013a1853 
DEBUG [01:08:54.517] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.341398e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9877653 
  - variance bounds :  0.003329157 0.3341398 
  - best initial criterion value(s) :  529.0974 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -529.1  |proj g|=       11.429
At iterate     1  f =      -545.51  |proj g|=        2.6484
At iterate     2  f =      -557.66  |proj g|=        3.5113
At iterate     3  f =       -559.2  |proj g|=        3.3738
At iterate     4  f =      -562.94  |proj g|=        2.9805
At iterate     5  f =      -565.16  |proj g|=        8.3112
At iterate     6  f =      -566.63  |proj g|=        0.6443
At iterate     7  f =      -566.83  |proj g|=        2.3143
At iterate     8  f =      -566.95  |proj g|=       0.42931
At iterate     9  f =      -567.09  |proj g|=       0.32841
At iterate    10  f =      -568.58  |proj g|=        3.0078
At iterate    11  f =      -569.58  |proj g|=        2.5227
At iterate    12  f =         -570  |proj g|=       0.85915
At iterate    13  f =      -570.01  |proj g|=       0.68721
At iterate    14  f =      -570.02  |proj g|=       0.62755
At iterate    15  f =      -570.03  |proj g|=        0.3254
At iterate    16  f =      -570.03  |proj g|=      0.010985
At iterate    17  f =      -570.03  |proj g|=      0.010985

iterations 17
function evaluations 27
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0109854
final function value -570.026

F = -570.026
final  value -570.025597 
converged
 
INFO  [01:08:54.521] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:08:54.574] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:08:54.581] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:09:49.320] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:10:43.322] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:11:36.613] [mlr3]  Finished benchmark 
INFO  [01:11:36.677] [bbotk] Result of batch 118: 
INFO  [01:11:36.679] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:11:36.679] [bbotk]                   7              4449     0.05263517        0.675 -0.8646316 
INFO  [01:11:36.679] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:11:36.679] [bbotk]          <NA>   0.9765329 2d7949b0-37a3-45d0-88a7-e2bfcb628482 
DEBUG [01:11:38.004] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.326453e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9877653 
  - variance bounds :  0.003312647 0.3326453 
  - best initial criterion value(s) :  519.5991 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -519.6  |proj g|=       5.7713
At iterate     1  f =      -526.07  |proj g|=        4.5888
At iterate     2  f =      -528.86  |proj g|=        5.4208
At iterate     3  f =      -537.05  |proj g|=         5.308
At iterate     4  f =      -541.69  |proj g|=        5.1126
At iterate     5  f =      -555.02  |proj g|=        4.4251
At iterate     6  f =      -570.95  |proj g|=        3.7542
At iterate     7  f =      -584.51  |proj g|=        9.2595
At iterate     8  f =      -586.31  |proj g|=        1.2353
At iterate     9  f =      -586.34  |proj g|=       0.91718
At iterate    10  f =      -586.35  |proj g|=       0.53751
At iterate    11  f =      -586.35  |proj g|=       0.59082
At iterate    12  f =      -586.35  |proj g|=       0.63377
At iterate    13  f =      -586.35  |proj g|=       0.73511
At iterate    14  f =      -586.35  |proj g|=       0.87726
At iterate    15  f =      -586.36  |proj g|=        1.1074
At iterate    16  f =      -586.37  |proj g|=        1.4421
At iterate    17  f =       -586.4  |proj g|=        1.8963
At iterate    18  f =      -586.47  |proj g|=        2.2815
At iterate    19  f =      -586.58  |proj g|=        2.2373
At iterate    20  f =      -586.61  |proj g|=        1.4549
At iterate    21  f =      -586.61  |proj g|=        1.5765
At iterate    22  f =      -586.61  |proj g|=        1.5659
At iterate    23  f =      -586.61  |proj g|=        1.5764
At iterate    24  f =      -586.61  |proj g|=        1.5677
At iterate    25  f =      -586.61  |proj g|=        1.5916
At iterate    26  f =      -586.61  |proj g|=        1.6168
At iterate    27  f =      -586.61  |proj g|=        1.6923
At iterate    28  f =      -586.62  |proj g|=        1.7086
At iterate    29  f =      -586.64  |proj g|=         1.558
At iterate    30  f =      -586.67  |proj g|=        1.0935
At iterate    31  f =      -586.69  |proj g|=       0.32376
At iterate    32  f =       -586.7  |proj g|=     0.0090368
At iterate    33  f =       -586.7  |proj g|=       0.32366
At iterate    34  f =       -586.7  |proj g|=       0.32366
At iterate    35  f =       -586.7  |proj g|=      0.086805

iterations 35
function evaluations 45
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0868048
final function value -586.698

F = -586.698
final  value -586.697556 
converged
 
INFO  [01:11:38.006] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:11:38.048] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:11:38.055] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:11:45.105] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:11:52.031] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:11:59.455] [mlr3]  Finished benchmark 
INFO  [01:11:59.527] [bbotk] Result of batch 119: 
INFO  [01:11:59.528] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:11:59.528] [bbotk]                   5               500      0.1091899        0.862 -0.8639615 
INFO  [01:11:59.528] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:11:59.528] [bbotk]          <NA>   0.9750652 2b37b51a-69a7-42b4-ad71-1d699c68d0c7 
DEBUG [01:12:00.824] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.311366e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9877653 
  - variance bounds :  0.003290561 0.3311366 
  - best initial criterion value(s) :  526.5893 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -526.59  |proj g|=       6.8876
At iterate     1  f =      -534.21  |proj g|=        6.4736
At iterate     2  f =      -545.12  |proj g|=        6.0955
At iterate     3  f =      -551.33  |proj g|=        5.7848
At iterate     4  f =      -558.52  |proj g|=        5.2753
At iterate     5  f =      -573.64  |proj g|=        4.3245
At iterate     6  f =      -591.23  |proj g|=        1.7678
At iterate     7  f =      -592.87  |proj g|=        2.5697
At iterate     8  f =      -592.92  |proj g|=        3.0216
At iterate     9  f =      -592.95  |proj g|=        3.0198
At iterate    10  f =      -592.97  |proj g|=        3.0157
At iterate    11  f =      -593.13  |proj g|=        1.9305
At iterate    12  f =      -593.29  |proj g|=       0.54304
At iterate    13  f =      -593.47  |proj g|=       0.65349
At iterate    14  f =      -593.53  |proj g|=        0.4999
At iterate    15  f =      -593.54  |proj g|=      0.085323
At iterate    16  f =      -593.54  |proj g|=     0.0089677
At iterate    17  f =      -593.54  |proj g|=       0.20769

iterations 17
function evaluations 24
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.207692
final function value -593.537

F = -593.537
final  value -593.537069 
converged
 
INFO  [01:12:00.828] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:12:00.880] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:12:00.887] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:12:24.679] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:12:48.220] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:13:12.497] [mlr3]  Finished benchmark 
INFO  [01:13:12.566] [bbotk] Result of batch 120: 
INFO  [01:13:12.567] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:13:12.567] [bbotk]                   3              1910     0.06691013         0.75 -0.8637294 
INFO  [01:13:12.567] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:13:12.567] [bbotk]          <NA>   0.9738927 c2246ac0-feab-4689-9d20-9ca071a1e02e 
DEBUG [01:13:13.569] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.296195e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9877653 
  - variance bounds :  0.003270755 0.3296195 
  - best initial criterion value(s) :  569.2196 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -569.22  |proj g|=       3.7985
At iterate     1  f =      -581.25  |proj g|=        9.1224
At iterate     2  f =      -588.14  |proj g|=        6.9558
At iterate     3  f =      -590.02  |proj g|=        2.0626
At iterate     4  f =      -590.11  |proj g|=        0.5292
At iterate     5  f =      -590.14  |proj g|=        0.3209
At iterate     6  f =      -590.21  |proj g|=       0.32088
At iterate     7  f =      -590.36  |proj g|=       0.90115
At iterate     8  f =      -590.47  |proj g|=       0.71902
At iterate     9  f =      -590.51  |proj g|=       0.31985
At iterate    10  f =      -590.51  |proj g|=       0.31977
At iterate    11  f =      -590.51  |proj g|=      0.038291
At iterate    12  f =      -590.51  |proj g|=      0.039942
At iterate    13  f =      -590.51  |proj g|=      0.038236
At iterate    14  f =      -590.51  |proj g|=       0.02603
At iterate    15  f =      -590.51  |proj g|=     0.0092549
At iterate    16  f =      -590.51  |proj g|=     0.0092546
At iterate    17  f =      -590.51  |proj g|=     0.0092544

iterations 17
function evaluations 23
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00925441
final function value -590.514

F = -590.514
final  value -590.513953 
converged
 
INFO  [01:13:13.573] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:13:13.628] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:13:13.635] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:14:04.160] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:14:53.797] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:15:42.878] [mlr3]  Finished benchmark 
INFO  [01:15:42.943] [bbotk] Result of batch 121: 
INFO  [01:15:42.945] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:15:42.945] [bbotk]                   7              4087      0.1398981        0.678 -0.8664638 
INFO  [01:15:42.945] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:15:42.945] [bbotk]          <NA>   0.9753858 cb736c31-5a94-47ef-b9e5-544f9eb3aeb3 
DEBUG [01:15:43.969] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.281349e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9877653 
  - variance bounds :  0.003263521 0.3281349 
  - best initial criterion value(s) :  524.9879 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -524.99  |proj g|=       3.0548
At iterate     1  f =      -540.53  |proj g|=        5.6008
At iterate     2  f =      -546.32  |proj g|=        4.8819
At iterate     3  f =      -549.99  |proj g|=        4.3462
At iterate     4  f =      -557.09  |proj g|=        3.6429
At iterate     5  f =      -559.96  |proj g|=        3.2689
At iterate     6  f =      -565.93  |proj g|=        3.2374
At iterate     7  f =      -567.36  |proj g|=        2.0544
At iterate     8  f =      -569.52  |proj g|=        2.6268
At iterate     9  f =      -578.29  |proj g|=       0.98777
At iterate    10  f =      -583.01  |proj g|=        1.6882
At iterate    11  f =      -583.35  |proj g|=       0.83055
At iterate    12  f =      -583.68  |proj g|=       0.31924
At iterate    13  f =      -583.71  |proj g|=       0.31902
At iterate    14  f =      -583.72  |proj g|=      0.011716
At iterate    15  f =      -583.72  |proj g|=      0.011714
At iterate    16  f =      -583.72  |proj g|=      0.026595

iterations 16
function evaluations 25
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0265949
final function value -583.717

F = -583.717
final  value -583.716758 
converged
 
INFO  [01:15:43.973] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:15:44.026] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:15:44.033] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:16:02.257] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:16:19.903] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:16:37.664] [mlr3]  Finished benchmark 
INFO  [01:16:37.731] [bbotk] Result of batch 122: 
INFO  [01:16:37.733] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:16:37.733] [bbotk]                   3              1424      0.2596759        0.686 -0.8659799 
INFO  [01:16:37.733] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:16:37.733] [bbotk]          <NA>   0.9761195 7722e481-14a5-49a2-ad93-e8f300e966aa 
DEBUG [01:16:38.766] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.266705e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9877653 
  - variance bounds :  0.003243777 0.3266705 
  - best initial criterion value(s) :  452.8671 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -452.87  |proj g|=       12.419
At iterate     1  f =      -494.45  |proj g|=        5.5013
At iterate     2  f =      -523.83  |proj g|=        3.5512
At iterate     3  f =      -532.53  |proj g|=        2.8522
At iterate     4  f =      -533.52  |proj g|=        2.6394
At iterate     5  f =      -534.46  |proj g|=        3.4625
At iterate     6  f =      -534.71  |proj g|=        0.1521
At iterate     7  f =      -534.72  |proj g|=       0.32029
At iterate     8  f =      -534.72  |proj g|=       0.32029
At iterate     9  f =      -534.73  |proj g|=       0.35782
At iterate    10  f =      -534.77  |proj g|=       0.97634
At iterate    11  f =      -534.87  |proj g|=         2.002
At iterate    12  f =      -535.08  |proj g|=         3.202
At iterate    13  f =      -535.46  |proj g|=        4.0129
At iterate    14  f =      -535.51  |proj g|=        4.0204
At iterate    15  f =      -535.86  |proj g|=        3.1399
At iterate    16  f =      -536.05  |proj g|=       0.95336
At iterate    17  f =      -536.07  |proj g|=       0.31903
At iterate    18  f =      -536.07  |proj g|=       0.03461
At iterate    19  f =      -536.07  |proj g|=      0.022965
At iterate    20  f =      -536.07  |proj g|=      0.022965

iterations 20
function evaluations 27
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0229654
final function value -536.072

F = -536.072
final  value -536.072461 
converged
 
INFO  [01:16:38.770] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:16:38.825] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:16:38.832] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:17:11.808] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:17:44.359] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:18:16.646] [mlr3]  Finished benchmark 
INFO  [01:18:16.711] [bbotk] Result of batch 123: 
INFO  [01:18:16.713] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:18:16.713] [bbotk]                   7              2697     0.07838911        0.683 -0.8683448 
INFO  [01:18:16.713] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:18:16.713] [bbotk]          <NA>   0.9765274 f3dba767-9815-49a1-97a8-52cf61588df2 
DEBUG [01:18:17.755] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.252213e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9877653 
  - variance bounds :  0.003234147 0.3252213 
  - best initial criterion value(s) :  475.7301 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -475.73  |proj g|=       12.149
At iterate     1  f =      -519.44  |proj g|=        5.7414
At iterate     2  f =      -537.21  |proj g|=        4.5518
At iterate     3  f =      -552.11  |proj g|=        3.4501
At iterate     4  f =      -558.05  |proj g|=        2.9613
At iterate     5  f =      -560.41  |proj g|=        2.5276
At iterate     6  f =      -560.54  |proj g|=       0.31882
At iterate     7  f =      -560.57  |proj g|=       0.16191
At iterate     8  f =      -560.58  |proj g|=       0.18711
At iterate     9  f =      -560.58  |proj g|=       0.14372
At iterate    10  f =      -560.58  |proj g|=       0.31858
At iterate    11  f =      -560.67  |proj g|=       0.65016
At iterate    12  f =       -560.8  |proj g|=        1.3086
At iterate    13  f =      -561.11  |proj g|=         1.973
At iterate    14  f =      -561.43  |proj g|=       0.98251
At iterate    15  f =       -561.5  |proj g|=          2.83
At iterate    16  f =      -561.65  |proj g|=        1.0808
At iterate    17  f =      -561.68  |proj g|=       0.31718
At iterate    18  f =      -561.68  |proj g|=       0.31712
At iterate    19  f =      -561.68  |proj g|=        0.3171
At iterate    20  f =      -561.68  |proj g|=        0.1906
At iterate    21  f =      -561.68  |proj g|=      0.018631

iterations 21
function evaluations 29
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0186312
final function value -561.68

F = -561.68
final  value -561.679699 
converged
 
INFO  [01:18:17.759] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:18:17.812] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:18:17.818] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:18:47.019] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:19:16.298] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:19:45.987] [mlr3]  Finished benchmark 
INFO  [01:19:46.062] [bbotk] Result of batch 124: 
INFO  [01:19:46.064] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:19:46.064] [bbotk]                   6              2400       0.262519        0.677 -0.8667477 
INFO  [01:19:46.064] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:19:46.064] [bbotk]          <NA>   0.9758182 a91b22d3-42f6-4ff1-8bc6-22c463a4573b 
DEBUG [01:19:47.515] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.237708e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9877653 
  - variance bounds :  0.003224579 0.3237708 
  - best initial criterion value(s) :  554.8157 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -554.82  |proj g|=       9.6443
At iterate     1  f =      -560.95  |proj g|=        2.6117
At iterate     2  f =      -567.77  |proj g|=        3.5605
At iterate     3  f =      -569.95  |proj g|=        3.4157
At iterate     4  f =      -573.43  |proj g|=        2.6617
At iterate     5  f =      -575.41  |proj g|=        7.1226
At iterate     6  f =      -576.68  |proj g|=       0.15779
At iterate     7  f =      -576.84  |proj g|=       0.85588
At iterate     8  f =      -576.85  |proj g|=       0.41218
At iterate     9  f =      -576.85  |proj g|=       0.41665
At iterate    10  f =      -576.85  |proj g|=       0.42987
At iterate    11  f =      -576.86  |proj g|=       0.45499
At iterate    12  f =      -576.87  |proj g|=       0.44087
At iterate    13  f =       -576.9  |proj g|=       0.31775
At iterate    14  f =      -576.98  |proj g|=       0.31784
At iterate    15  f =      -577.16  |proj g|=       0.84838
At iterate    16  f =      -577.49  |proj g|=        1.7522
At iterate    17  f =      -577.94  |proj g|=        4.6068
At iterate    18  f =      -578.39  |proj g|=        3.5947
At iterate    19  f =      -578.89  |proj g|=        2.7373
At iterate    20  f =      -578.89  |proj g|=        2.9735
At iterate    21  f =      -578.89  |proj g|=        3.0034
At iterate    22  f =      -578.89  |proj g|=         2.957
At iterate    23  f =      -578.89  |proj g|=        2.9997
At iterate    24  f =      -578.89  |proj g|=        2.9627
At iterate    25  f =       -578.9  |proj g|=        2.8533
At iterate    26  f =      -578.94  |proj g|=        2.0724
At iterate    27  f =      -579.01  |proj g|=        1.1652
At iterate    28  f =       -579.1  |proj g|=       0.58059
At iterate    29  f =      -579.16  |proj g|=       0.86462
At iterate    30  f =      -579.18  |proj g|=       0.31536
At iterate    31  f =      -579.18  |proj g|=       0.31534
At iterate    32  f =      -579.18  |proj g|=       0.06276

iterations 32
function evaluations 37
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0627599
final function value -579.181

F = -579.181
final  value -579.181447 
converged
 
INFO  [01:19:47.519] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:19:47.571] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:19:47.577] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:20:11.376] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:20:34.884] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:20:58.301] [mlr3]  Finished benchmark 
INFO  [01:20:58.368] [bbotk] Result of batch 125: 
INFO  [01:20:58.370] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:20:58.370] [bbotk]                   6              1898      0.4744896        1.012 -0.8657868 
INFO  [01:20:58.370] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:20:58.370] [bbotk]          <NA>   0.9752964 fbd525ae-1d76-4085-a79e-cc4ad0cfdf90 
DEBUG [01:20:59.362] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.223221e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9877653 
  - variance bounds :  0.003211638 0.3223221 
  - best initial criterion value(s) :  531.2276 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -531.23  |proj g|=        11.22
At iterate     1  f =       -554.3  |proj g|=        6.3308
At iterate     2  f =      -576.86  |proj g|=        2.9485
At iterate     3  f =      -604.65  |proj g|=       0.78591
At iterate     4  f =      -604.85  |proj g|=        2.2603
At iterate     5  f =      -604.99  |proj g|=        2.3516
At iterate     6  f =      -606.09  |proj g|=        2.4473
At iterate     7  f =      -610.68  |proj g|=        2.7541
At iterate     8  f =      -613.08  |proj g|=        2.8392
At iterate     9  f =      -614.28  |proj g|=        1.6874
At iterate    10  f =      -614.45  |proj g|=        0.3983
At iterate    11  f =      -614.58  |proj g|=      0.010359
At iterate    12  f =      -614.58  |proj g|=        0.3129
At iterate    13  f =      -614.58  |proj g|=       0.31287
At iterate    14  f =      -614.58  |proj g|=       0.31287
At iterate    15  f =      -614.58  |proj g|=      0.010323
At iterate    16  f =      -614.58  |proj g|=      0.010322
At iterate    17  f =      -614.58  |proj g|=      0.018156

iterations 17
function evaluations 22
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0181561
final function value -614.582

F = -614.582
final  value -614.581867 
converged
 
INFO  [01:20:59.366] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:20:59.422] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:20:59.437] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:21:03.864] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:21:08.348] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:21:12.992] [mlr3]  Finished benchmark 
INFO  [01:21:13.058] [bbotk] Result of batch 126: 
INFO  [01:21:13.060] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:21:13.060] [bbotk]                   5               277      0.3999746        0.668 -0.8650314 
INFO  [01:21:13.060] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:21:13.060] [bbotk]          <NA>   0.9759531 23f50a79-37fd-41ab-846e-8f53ffdb1122 
DEBUG [01:21:14.106] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.208922e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9550 0.9877653 
  - variance bounds :  0.003190599 0.3208922 
  - best initial criterion value(s) :  537.0258 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -537.03  |proj g|=       5.0407
At iterate     1  f =      -591.37  |proj g|=        11.742
At iterate     2  f =      -608.59  |proj g|=        11.928
At iterate     3  f =      -612.18  |proj g|=        3.6007
At iterate     4  f =      -612.28  |proj g|=        3.9023
At iterate     5  f =       -612.3  |proj g|=        1.9942
At iterate     6  f =      -612.31  |proj g|=        2.7241
At iterate     7  f =      -612.31  |proj g|=        2.8475
At iterate     8  f =      -612.36  |proj g|=        3.5342
At iterate     9  f =      -612.51  |proj g|=         4.701
At iterate    10  f =      -612.78  |proj g|=         6.631
At iterate    11  f =      -613.21  |proj g|=        7.0719
At iterate    12  f =      -614.22  |proj g|=        2.6312
At iterate    13  f =      -615.81  |proj g|=        3.0476
At iterate    14  f =       -616.2  |proj g|=        2.3223
At iterate    15  f =      -616.28  |proj g|=        1.3258
At iterate    16  f =      -616.32  |proj g|=      0.011125
At iterate    17  f =      -616.32  |proj g|=       0.31169
At iterate    18  f =      -616.32  |proj g|=      0.011117
At iterate    19  f =      -616.32  |proj g|=      0.011117

iterations 19
function evaluations 27
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0111168
final function value -616.325

F = -616.325
final  value -616.324836 
converged
 
INFO  [01:21:14.108] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:21:14.151] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:21:14.157] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:21:36.842] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:22:00.027] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:22:22.867] [mlr3]  Finished benchmark 
INFO  [01:22:22.931] [bbotk] Result of batch 127: 
INFO  [01:22:22.933] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:22:22.933] [bbotk]                   4              1866     0.03822929         0.69 -0.8647508 
INFO  [01:22:22.933] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:22:22.933] [bbotk]          <NA>   0.9748733 9d50bc33-487c-46f6-ad86-48ce8db42d96 
DEBUG [01:22:23.005] [bbotk]  
INFO  [01:22:23.017] [bbotk] Finished optimizing after 150 evaluation(s) 
INFO  [01:22:23.019] [bbotk] Result: 
INFO  [01:22:23.021] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu learner_param_vals 
INFO  [01:22:23.021] [bbotk]                   5              4986     0.07558126         <list[15]> 
INFO  [01:22:23.021] [bbotk]   x_domain classif.auc 
INFO  [01:22:23.021] [bbotk]  <list[3]>   0.9770807 
INFO  [01:23:41.598] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost.tuned' on task 'spam' (iter 1/5) 
INFO  [01:23:41.683] [bbotk] Starting to optimize 3 parameter(s) with '<OptimizerInterMBO>' and '<TerminatorEvals> [n_evals=150]' 
DEBUG [01:23:41.752] [bbotk]  
INFO  [01:23:41.757] [bbotk] Evaluating 24 configuration(s) 
INFO  [01:23:42.606] [mlr3]  Running benchmark with 72 resampling iterations 
INFO  [01:23:42.622] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:23:43.524] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:24:07.396] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:25:06.012] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:25:36.665] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:26:23.975] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:27:07.309] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:27:42.581] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:28:17.371] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:29:06.869] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:29:31.980] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:30:16.677] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:30:24.315] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:30:25.231] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:30:44.285] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:30:58.925] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:31:36.818] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:31:47.918] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:32:17.656] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:33:16.014] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:33:16.925] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:33:25.714] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:33:26.471] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:33:34.108] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:34:23.585] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:35:01.729] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:35:18.668] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:35:19.581] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:35:36.287] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:35:37.196] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:36:15.553] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:36:42.613] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:37:37.174] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:38:27.652] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:38:32.065] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:38:54.735] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:39:41.790] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:40:13.641] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:40:45.662] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:41:09.876] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:41:10.829] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:42:04.347] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:42:05.248] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:42:43.724] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:42:54.520] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:43:44.521] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:43:45.443] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:43:46.350] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:44:12.642] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:44:16.874] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:44:27.857] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:45:12.009] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:45:58.083] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:46:34.956] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:46:35.868] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:47:02.245] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:47:10.729] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:47:26.220] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:47:48.863] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:48:47.264] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:49:07.563] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:49:08.458] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:49:51.065] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:50:41.107] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:51:25.602] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:51:26.490] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:51:27.287] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:52:02.445] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:52:26.929] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:52:31.512] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:52:32.384] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:53:27.036] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:54:17.378] [mlr3]  Finished benchmark 
INFO  [01:54:18.710] [bbotk] Result of batch 1: 
INFO  [01:54:18.712] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu classif.auc 
INFO  [01:54:18.712] [bbotk]                   4              2003     0.19080436   0.9759989 
INFO  [01:54:18.712] [bbotk]                   6              4160     0.13047522   0.9773255 
INFO  [01:54:18.712] [bbotk]                   3              4252     0.38671671   0.9746226 
INFO  [01:54:18.712] [bbotk]                   7              1171     0.12044141   0.8183198 
INFO  [01:54:18.712] [bbotk]                   7              3115     0.36877513   0.8191565 
INFO  [01:54:18.712] [bbotk]                   8               635     0.26122128   0.8184675 
INFO  [01:54:18.712] [bbotk]                   5              3218     0.43563344   0.9767915 
INFO  [01:54:18.712] [bbotk]                   4              2208     0.09823224   0.9755686 
INFO  [01:54:18.712] [bbotk]                  10              1623     0.33061583   0.6593334 
INFO  [01:54:18.712] [bbotk]                   9               563     0.04484595   0.8162497 
INFO  [01:54:18.712] [bbotk]                   7              3593     0.15442551   0.8192207 
INFO  [01:54:18.712] [bbotk]                   3              3947     0.17288658   0.9740108 
INFO  [01:54:18.712] [bbotk]                   9              2622     0.34384696   0.8170375 
INFO  [01:54:18.712] [bbotk]                   8              1339     0.40630347   0.8187905 
INFO  [01:54:18.712] [bbotk]                   9              2472     0.01926172   0.8172786 
INFO  [01:54:18.712] [bbotk]                   6              1886     0.27429567   0.9773255 
INFO  [01:54:18.712] [bbotk]                   8              4657     0.23674700   0.8182309 
INFO  [01:54:18.712] [bbotk]                   3              2892     0.30144769   0.9741185 
INFO  [01:54:18.712] [bbotk]                   5               845     0.07029913   0.9747003 
INFO  [01:54:18.712] [bbotk]                  10              1495     0.22717252   0.6594167 
INFO  [01:54:18.712] [bbotk]                   4              4879     0.48111514   0.9761026 
INFO  [01:54:18.712] [bbotk]                   6               266     0.43953027   0.9759916 
INFO  [01:54:18.712] [bbotk]                  10              4547     0.46025986   0.6583929 
INFO  [01:54:18.712] [bbotk]                   5              3737     0.02252636   0.9756332 
INFO  [01:54:18.712] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu classif.auc 
INFO  [01:54:18.712] [bbotk]                                 uhash 
INFO  [01:54:18.712] [bbotk]  1c2375e7-86b2-47e4-930f-fca72808490d 
INFO  [01:54:18.712] [bbotk]  6e0b48f6-e6d0-461e-807b-13387f7eda00 
INFO  [01:54:18.712] [bbotk]  6dce8931-9d89-42d5-9e9a-bff2f7b0170e 
INFO  [01:54:18.712] [bbotk]  8e9e4bc5-731d-49f2-84de-74b606b28f24 
INFO  [01:54:18.712] [bbotk]  c9d0292b-aed5-48c0-b723-84fb0aaa55d2 
INFO  [01:54:18.712] [bbotk]  34dc3ba3-bf74-4bff-9afa-60d4f2412402 
INFO  [01:54:18.712] [bbotk]  a09fff52-d79c-48df-af49-5ab935b52d95 
INFO  [01:54:18.712] [bbotk]  18f3dd7a-e4e5-450a-9db5-fef36ec032d0 
INFO  [01:54:18.712] [bbotk]  5add528d-8df1-4948-bfc1-33dd09011267 
INFO  [01:54:18.712] [bbotk]  3e61d0e9-321a-457f-abfb-e1ba8c435845 
INFO  [01:54:18.712] [bbotk]  1c3ea648-2c5d-488f-b373-7ce45e53d351 
INFO  [01:54:18.712] [bbotk]  15fe470e-c69a-473c-97a5-9e7b50c327c8 
INFO  [01:54:18.712] [bbotk]  19060702-cc2d-452e-83e6-889a96667559 
INFO  [01:54:18.712] [bbotk]  81efc758-b6eb-4a12-928e-137ec73d25c3 
INFO  [01:54:18.712] [bbotk]  674694f3-b446-404f-8ea4-fee085a5792c 
INFO  [01:54:18.712] [bbotk]  ff09e923-b358-4e49-9a93-9a4a25d5820a 
INFO  [01:54:18.712] [bbotk]  56db48e2-491e-4fee-863e-bc283972c0a5 
INFO  [01:54:18.712] [bbotk]  a9803e4f-7614-4df2-b4ee-e3fe0f70909f 
INFO  [01:54:18.712] [bbotk]  ee290121-decb-40dc-a774-85321b84d1c8 
INFO  [01:54:18.712] [bbotk]  3222ac15-066b-49ad-92e6-dcb5380fe6b8 
INFO  [01:54:18.712] [bbotk]  cb070a23-ee2b-4cbb-b7a4-45eba098173f 
INFO  [01:54:18.712] [bbotk]  141e6646-f52e-4a35-8df8-8f683bc7835d 
INFO  [01:54:18.712] [bbotk]  a0fc4be8-4b2c-4c47-9e1f-1f4b82295232 
INFO  [01:54:18.712] [bbotk]  65419c75-0cea-48a1-87fa-ae0233f56600 
INFO  [01:54:18.712] [bbotk]                                 uhash 
DEBUG [01:54:19.343] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.263617e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9226 0.9237068 
  - variance bounds :  0.001241676 0.1263617 
  - best initial criterion value(s) :  35.99333 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -35.993  |proj g|=       3.3064
At iterate     1  f =        -41.5  |proj g|=         1.452
At iterate     2  f =      -41.995  |proj g|=        2.8374
At iterate     3  f =      -42.506  |proj g|=        2.8793
At iterate     4  f =      -45.409  |proj g|=         2.176
At iterate     5  f =      -48.223  |proj g|=        1.4554
At iterate     6  f =      -48.459  |proj g|=        2.0726
At iterate     7  f =      -48.557  |proj g|=        2.0196
At iterate     8  f =      -48.665  |proj g|=       0.56203
At iterate     9  f =      -48.666  |proj g|=       0.53337
At iterate    10  f =       -48.67  |proj g|=       0.43589
At iterate    11  f =      -48.679  |proj g|=       0.31318
At iterate    12  f =      -48.706  |proj g|=      0.092276
At iterate    13  f =      -48.773  |proj g|=       0.38015
At iterate    14  f =      -48.818  |proj g|=       0.85658
At iterate    15  f =      -49.017  |proj g|=       0.13919
At iterate    16  f =      -49.109  |proj g|=       0.78138
At iterate    17  f =      -49.136  |proj g|=       0.29518
At iterate    18  f =       -49.14  |proj g|=       0.12197
At iterate    19  f =      -49.141  |proj g|=     0.0054742
At iterate    20  f =      -49.141  |proj g|=     0.0011362
At iterate    21  f =      -49.141  |proj g|=     0.0011362

iterations 21
function evaluations 30
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00113617
final function value -49.1406

F = -49.1406
final  value -49.140579 
converged
 
INFO  [01:54:19.347] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:54:19.407] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:54:19.415] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:54:39.057] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:54:58.806] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:54:59.703] [mlr3]  Finished benchmark 
INFO  [01:54:59.768] [bbotk] Result of batch 2: 
INFO  [01:54:59.777] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:54:59.777] [bbotk]                   8              1598      0.1421987         0.41 -0.9300258 
INFO  [01:54:59.777] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:54:59.777] [bbotk]          <NA>   0.8186286 de0b46dd-d588-4fd0-a915-30cbb77e6225 
DEBUG [01:55:00.357] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.224597e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9226 0.9237068 
  - variance bounds :  0.001208465 0.1224597 
  - best initial criterion value(s) :  44.88479 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -44.885  |proj g|=       4.5564
At iterate     1  f =      -49.395  |proj g|=        2.5061
At iterate     2  f =      -50.866  |proj g|=        2.1395
At iterate     3  f =      -51.946  |proj g|=        1.7903
At iterate     4  f =      -52.893  |proj g|=        1.3345
At iterate     5  f =      -53.046  |proj g|=       0.14911
At iterate     6  f =       -53.23  |proj g|=       0.55407
At iterate     7  f =      -53.546  |proj g|=        1.1265
At iterate     8  f =      -53.629  |proj g|=        1.2271
At iterate     9  f =      -53.702  |proj g|=       0.52792
At iterate    10  f =      -53.715  |proj g|=      0.065956
At iterate    11  f =      -53.715  |proj g|=       0.11826
At iterate    12  f =      -53.715  |proj g|=     0.0014488

iterations 12
function evaluations 18
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00144883
final function value -53.7147

F = -53.7147
final  value -53.714739 
converged
 
INFO  [01:55:00.361] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:55:00.416] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:55:00.422] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:55:11.969] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:55:22.912] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:55:34.040] [mlr3]  Finished benchmark 
INFO  [01:55:34.104] [bbotk] Result of batch 3: 
INFO  [01:55:34.106] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:55:34.106] [bbotk]                   4               861      0.2418484        0.407 -0.9280853 
INFO  [01:55:34.106] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:55:34.106] [bbotk]          <NA>   0.9754841 e086e1ac-4525-4ae6-bd5c-f73672812cd4 
DEBUG [01:55:34.684] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.214705e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9226 0.9237068 
  - variance bounds :  0.001188169 0.1214705 
  - best initial criterion value(s) :  47.12348 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -47.123  |proj g|=       2.9533
At iterate     1  f =      -48.997  |proj g|=        1.4603
At iterate     2  f =      -49.262  |proj g|=        2.0379
At iterate     3  f =      -49.879  |proj g|=        2.7273
At iterate     4  f =       -50.29  |proj g|=        2.6255
At iterate     5  f =       -51.21  |proj g|=        2.3878
At iterate     6  f =      -52.844  |proj g|=        1.9683
At iterate     7  f =      -54.862  |proj g|=        1.4051
At iterate     8  f =       -55.15  |proj g|=        2.0504
At iterate     9  f =      -55.472  |proj g|=         1.047
At iterate    10  f =      -55.493  |proj g|=       0.34577
At iterate    11  f =      -55.513  |proj g|=       0.47319
At iterate    12  f =      -55.514  |proj g|=       0.52543
At iterate    13  f =      -55.514  |proj g|=       0.54943
At iterate    14  f =      -55.523  |proj g|=       0.72652
At iterate    15  f =      -55.548  |proj g|=        1.1503
At iterate    16  f =      -55.593  |proj g|=        1.5437
At iterate    17  f =      -55.727  |proj g|=        2.0852
At iterate    18  f =       -55.81  |proj g|=        1.6214
At iterate    19  f =      -55.928  |proj g|=       0.15307
At iterate    20  f =      -55.932  |proj g|=       0.02479
At iterate    21  f =      -55.932  |proj g|=       0.11734
At iterate    22  f =      -55.932  |proj g|=     0.0048054
At iterate    23  f =      -55.932  |proj g|=     0.0013639

iterations 23
function evaluations 30
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00136388
final function value -55.9324

F = -55.9324
final  value -55.932354 
converged
 
INFO  [01:55:34.688] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:55:34.743] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:55:34.750] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:55:35.541] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:56:34.128] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:56:35.021] [mlr3]  Finished benchmark 
INFO  [01:56:35.087] [bbotk] Result of batch 4: 
INFO  [01:56:35.088] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:56:35.088] [bbotk]                  10              4856      0.1886435        0.391 -0.9298953 
INFO  [01:56:35.088] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:56:35.088] [bbotk]          <NA>   0.6590465 35e0561b-18d7-45ac-9bc6-4e3d7fbbb8b8 
DEBUG [01:56:35.671] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.34643e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9226 0.9237068 
  - variance bounds :  0.00134643 0.1365253 
  - best initial criterion value(s) :  42.09977 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=        -42.1  |proj g|=       3.5418
At iterate     1  f =      -48.143  |proj g|=        2.4232
At iterate     2  f =      -48.621  |proj g|=        2.3289
At iterate     3  f =       -49.03  |proj g|=        2.1087
At iterate     4  f =      -49.668  |proj g|=        1.6434
At iterate     5  f =      -49.901  |proj g|=          1.53
At iterate     6  f =      -50.194  |proj g|=       0.98626
At iterate     7  f =       -54.53  |proj g|=       0.13312
At iterate     8  f =      -55.591  |proj g|=        1.1508
At iterate     9  f =      -55.781  |proj g|=      0.046708
At iterate    10  f =       -55.81  |proj g|=       0.20815
At iterate    11  f =      -55.813  |proj g|=     0.0027865
At iterate    12  f =      -55.813  |proj g|=     0.0027753
At iterate    13  f =      -55.813  |proj g|=     0.0089077
At iterate    14  f =      -55.813  |proj g|=      0.002064

iterations 14
function evaluations 19
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00206403
final function value -55.8131

F = -55.8131
final  value -55.813137 
converged
 
INFO  [01:56:35.675] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:56:35.735] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:56:35.742] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [01:57:34.196] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [01:58:32.723] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:59:31.620] [mlr3]  Finished benchmark 
INFO  [01:59:31.685] [bbotk] Result of batch 5: 
INFO  [01:59:31.687] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [01:59:31.687] [bbotk]                   4              4912       0.125052          0.4 -0.9295838 
INFO  [01:59:31.687] [bbotk]  errors.model classif.auc                                uhash 
INFO  [01:59:31.687] [bbotk]          <NA>   0.9759788 25568ae2-7cb7-424e-8144-85658a6862e8 
DEBUG [01:59:32.283] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.33636e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9292 0.9237068 
  - variance bounds :  0.00133636 0.1350574 
  - best initial criterion value(s) :  56.69187 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -56.692  |proj g|=       3.0585
At iterate     1  f =      -58.913  |proj g|=        2.3706
At iterate     2  f =      -60.646  |proj g|=        1.7287
At iterate     3  f =       -61.21  |proj g|=        1.4816
At iterate     4  f =       -61.27  |proj g|=        1.3817
At iterate     5  f =      -61.276  |proj g|=        1.1963
At iterate     6  f =      -61.278  |proj g|=        1.3136
At iterate     7  f =      -61.279  |proj g|=         1.354
At iterate     8  f =      -61.284  |proj g|=        1.3657
At iterate     9  f =      -61.296  |proj g|=        1.3834
At iterate    10  f =      -61.329  |proj g|=        1.4114
At iterate    11  f =      -61.413  |proj g|=        1.4603
At iterate    12  f =      -61.626  |proj g|=        1.5524
At iterate    13  f =        -62.1  |proj g|=        1.6932
At iterate    14  f =      -63.068  |proj g|=        1.8261
At iterate    15  f =       -63.67  |proj g|=        1.7618
At iterate    16  f =       -64.33  |proj g|=        1.5638
At iterate    17  f =      -64.751  |proj g|=      0.088203
At iterate    18  f =       -64.83  |proj g|=       0.40842
At iterate    19  f =      -64.844  |proj g|=      0.030414
At iterate    20  f =      -64.845  |proj g|=     0.0045485
At iterate    21  f =      -64.845  |proj g|=       0.13133
At iterate    22  f =      -64.845  |proj g|=     0.0011443

iterations 22
function evaluations 26
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00114427
final function value -64.8447

F = -64.8447
final  value -64.844692 
converged
 
INFO  [01:59:32.287] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:59:32.343] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:59:32.350] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [01:59:56.818] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:00:21.993] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:00:22.872] [mlr3]  Finished benchmark 
INFO  [02:00:22.935] [bbotk] Result of batch 6: 
INFO  [02:00:22.936] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:00:22.936] [bbotk]                   9              2033      0.2219829        0.412 -0.9269859 
INFO  [02:00:22.936] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:00:22.936] [bbotk]          <NA>   0.8180026 741a1049-0703-4b30-9fed-883f5e1de83c 
DEBUG [02:00:23.536] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.299518e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9292 0.9237068 
  - variance bounds :  0.001299518 0.1330865 
  - best initial criterion value(s) :  58.57829 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -58.578  |proj g|=       1.2015
At iterate     1  f =        -61.1  |proj g|=        2.5697
At iterate     2  f =      -61.505  |proj g|=        2.5066
At iterate     3  f =      -62.035  |proj g|=        2.2944
At iterate     4  f =      -62.539  |proj g|=        2.0077
At iterate     5  f =        -63.2  |proj g|=        1.3787
At iterate     6  f =      -63.225  |proj g|=        1.6129
At iterate     7  f =      -63.328  |proj g|=        1.5901
At iterate     8  f =      -63.342  |proj g|=        1.5204
At iterate     9  f =      -63.347  |proj g|=        1.5379
At iterate    10  f =      -63.353  |proj g|=        1.5311
At iterate    11  f =      -63.412  |proj g|=        1.4819
At iterate    12  f =      -63.505  |proj g|=        1.1157
At iterate    13  f =      -63.749  |proj g|=       0.24573
At iterate    14  f =      -64.401  |proj g|=        1.4489
At iterate    15  f =      -65.644  |proj g|=         3.345
At iterate    16  f =       -66.93  |proj g|=        3.2275
At iterate    17  f =      -67.315  |proj g|=        2.6572
At iterate    18  f =      -67.607  |proj g|=        0.1755
At iterate    19  f =      -67.614  |proj g|=       0.08058
At iterate    20  f =      -67.614  |proj g|=       0.12943
At iterate    21  f =      -67.614  |proj g|=     0.0023562
At iterate    22  f =      -67.614  |proj g|=     0.0013665

iterations 22
function evaluations 29
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0013665
final function value -67.6141

F = -67.6141
final  value -67.614117 
converged
 
INFO  [02:00:23.540] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:00:23.593] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:00:23.600] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:00:24.474] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:00:55.147] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:00:55.903] [mlr3]  Finished benchmark 
INFO  [02:00:55.982] [bbotk] Result of batch 7: 
INFO  [02:00:55.983] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [02:00:55.983] [bbotk]                  10              2545      0.4899339        0.419 -0.925067 
INFO  [02:00:55.983] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:00:55.983] [bbotk]          <NA>   0.6587938 7905c9e0-828b-4ad5-9bac-abbc2d77e480 
DEBUG [02:00:56.585] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.406584e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9292 0.9413443 
  - variance bounds :  0.001406584 0.1430396 
  - best initial criterion value(s) :  59.20778 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -59.208  |proj g|=       1.2481
At iterate     1  f =      -66.926  |proj g|=        1.5875
At iterate     2  f =       -67.86  |proj g|=       0.38287
At iterate     3  f =      -68.023  |proj g|=        1.3487
At iterate     4  f =      -68.024  |proj g|=        1.3486
At iterate     5  f =      -68.024  |proj g|=        1.3485
At iterate     6  f =      -68.025  |proj g|=        1.3482
At iterate     7  f =      -68.026  |proj g|=         1.347
At iterate     8  f =      -68.029  |proj g|=        1.3437
At iterate     9  f =      -68.036  |proj g|=        1.3353
At iterate    10  f =      -68.053  |proj g|=         1.314
At iterate    11  f =      -68.086  |proj g|=        1.2704
At iterate    12  f =      -68.135  |proj g|=       0.62793
At iterate    13  f =      -68.158  |proj g|=       0.13943
At iterate    14  f =      -68.158  |proj g|=       0.13942
At iterate    15  f =      -68.158  |proj g|=     0.0068695

iterations 15
function evaluations 18
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00686948
final function value -68.1583

F = -68.1583
final  value -68.158280 
converged
 
INFO  [02:00:56.589] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:00:56.643] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:00:56.649] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:00:57.549] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:01:52.366] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:02:47.544] [mlr3]  Finished benchmark 
INFO  [02:02:47.609] [bbotk] Result of batch 8: 
INFO  [02:02:47.611] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [02:02:47.611] [bbotk]                   8              4642      0.2647887        0.419 -0.924811 
INFO  [02:02:47.611] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:02:47.611] [bbotk]          <NA>    0.818125 54da495a-89ad-47a6-af11-4a2f8236eff1 
DEBUG [02:02:48.215] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.366827e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9292 0.9413443 
  - variance bounds :  0.001366827 0.1380924 
  - best initial criterion value(s) :  61.27443 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -61.274  |proj g|=       3.6348
At iterate     1  f =      -65.079  |proj g|=        2.8742
At iterate     2  f =       -67.41  |proj g|=        2.3949
At iterate     3  f =       -68.45  |proj g|=        2.1122
At iterate     4  f =      -69.785  |proj g|=        1.6994
At iterate     5  f =      -70.888  |proj g|=        1.0582
At iterate     6  f =      -70.891  |proj g|=       0.83691
At iterate     7  f =      -70.892  |proj g|=       0.74643
At iterate     8  f =      -71.035  |proj g|=       0.49754
At iterate     9  f =      -71.885  |proj g|=       0.11559
At iterate    10  f =      -73.197  |proj g|=       0.35611
At iterate    11  f =      -73.466  |proj g|=       0.40504
At iterate    12  f =      -73.826  |proj g|=       0.12863
At iterate    13  f =      -73.839  |proj g|=      0.063887
At iterate    14  f =      -73.839  |proj g|=      0.042757
At iterate    15  f =      -73.839  |proj g|=      0.026415
At iterate    16  f =      -73.839  |proj g|=       0.02309
At iterate    17  f =      -73.839  |proj g|=     0.0021127

iterations 17
function evaluations 28
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00211265
final function value -73.8394

F = -73.8394
final  value -73.839390 
converged
 
INFO  [02:02:48.219] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:02:48.285] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:02:48.292] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:02:49.159] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:03:36.583] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:04:24.300] [mlr3]  Finished benchmark 
INFO  [02:04:24.365] [bbotk] Result of batch 9: 
INFO  [02:04:24.366] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:04:24.366] [bbotk]                   9              4041      0.1142713        0.423 -0.9237007 
INFO  [02:04:24.366] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:04:24.366] [bbotk]          <NA>   0.8179711 0d6f6181-344f-46ae-b0db-3518528759a1 
DEBUG [02:04:25.009] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.329247e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9292 0.9413443 
  - variance bounds :  0.001329247 0.1336991 
  - best initial criterion value(s) :  59.50797 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -59.508  |proj g|=       2.6846
At iterate     1  f =      -63.832  |proj g|=       0.12362
At iterate     2  f =      -65.712  |proj g|=        1.0476
At iterate     3  f =      -66.477  |proj g|=       0.93092
At iterate     4  f =      -66.551  |proj g|=       0.39463
At iterate     5  f =      -66.553  |proj g|=       0.12978
At iterate     6  f =      -66.558  |proj g|=       0.12981
At iterate     7  f =      -66.666  |proj g|=        0.2438
At iterate     8  f =      -66.675  |proj g|=       0.35351
At iterate     9  f =      -66.681  |proj g|=       0.12981
At iterate    10  f =      -66.682  |proj g|=       0.12979
At iterate    11  f =      -66.682  |proj g|=      0.024674
At iterate    12  f =      -66.682  |proj g|=     0.0049383

iterations 12
function evaluations 17
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00493833
final function value -66.6818

F = -66.6818
final  value -66.681779 
converged
 
INFO  [02:04:25.013] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:04:25.068] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:04:25.074] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:04:50.814] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:05:16.300] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:05:42.090] [mlr3]  Finished benchmark 
INFO  [02:05:42.162] [bbotk] Result of batch 10: 
INFO  [02:05:42.164] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:05:42.164] [bbotk]                   5              2122      0.2474841        0.454 -0.9264728 
INFO  [02:05:42.164] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:05:42.164] [bbotk]          <NA>    0.977133 dd66232b-5f5f-4bc2-8e27-a1a27cd82947 
DEBUG [02:05:42.799] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.327743e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9292 0.9413443 
  - variance bounds :  0.001318506 0.1327743 
  - best initial criterion value(s) :  69.2309 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -69.231  |proj g|=       5.6386
At iterate     1  f =      -77.302  |proj g|=        2.5702
At iterate     2  f =      -78.098  |proj g|=        2.4753
At iterate     3  f =      -79.774  |proj g|=        2.1222
At iterate     4  f =      -82.195  |proj g|=        1.5499
At iterate     5  f =       -82.89  |proj g|=       0.54603
At iterate     6  f =      -82.977  |proj g|=      0.053831
At iterate     7  f =       -82.98  |proj g|=       0.13805
At iterate     8  f =       -82.98  |proj g|=        0.1881
At iterate     9  f =      -82.982  |proj g|=       0.28221
At iterate    10  f =      -82.992  |proj g|=       0.56019
At iterate    11  f =      -83.014  |proj g|=       0.92485
At iterate    12  f =      -83.077  |proj g|=        1.3064
At iterate    13  f =      -83.227  |proj g|=        1.3888
At iterate    14  f =      -83.432  |proj g|=        1.3946
At iterate    15  f =      -83.613  |proj g|=        1.3511
At iterate    16  f =      -83.831  |proj g|=       0.12961
At iterate    17  f =      -83.834  |proj g|=       0.12955
At iterate    18  f =      -83.834  |proj g|=       0.12954
At iterate    19  f =      -83.834  |proj g|=     0.0067829

iterations 19
function evaluations 26
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00678294
final function value -83.8341

F = -83.8341
final  value -83.834111 
converged
 
INFO  [02:05:42.803] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:05:42.856] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:05:42.862] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:05:43.735] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:05:44.488] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:06:42.849] [mlr3]  Finished benchmark 
INFO  [02:06:42.913] [bbotk] Result of batch 11: 
INFO  [02:06:42.915] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:06:42.915] [bbotk]                  10              4937     0.02514213        0.418 -0.9213767 
INFO  [02:06:42.915] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:06:42.915] [bbotk]          <NA>   0.6589363 183dbcc6-10a1-417c-9045-7f50618fbdfa 
DEBUG [02:06:43.523] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.413216e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.001413216 0.1431771 
  - best initial criterion value(s) :  71.97124 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -71.971  |proj g|=       5.5742
At iterate     1  f =      -77.044  |proj g|=        1.4878
At iterate     2  f =      -79.048  |proj g|=        1.1473
At iterate     3  f =      -79.762  |proj g|=        1.4464
At iterate     4  f =      -79.958  |proj g|=        1.2918
At iterate     5  f =      -79.997  |proj g|=       0.22094
At iterate     6  f =      -80.006  |proj g|=       0.19978
At iterate     7  f =      -80.006  |proj g|=       0.22903
At iterate     8  f =      -80.009  |proj g|=       0.35979
At iterate     9  f =      -80.014  |proj g|=       0.51637
At iterate    10  f =       -80.03  |proj g|=       0.80654
At iterate    11  f =      -80.069  |proj g|=        1.2596
At iterate    12  f =      -80.176  |proj g|=        1.3123
At iterate    13  f =      -80.446  |proj g|=        1.3935
At iterate    14  f =      -80.723  |proj g|=        1.4273
At iterate    15  f =      -80.921  |proj g|=        1.3878
At iterate    16  f =      -80.969  |proj g|=        1.2642
At iterate    17  f =      -81.002  |proj g|=       0.73761
At iterate    18  f =      -81.038  |proj g|=       0.18078
At iterate    19  f =      -81.076  |proj g|=        0.2598
At iterate    20  f =      -81.094  |proj g|=       0.13974
At iterate    21  f =      -81.095  |proj g|=       0.00518
At iterate    22  f =      -81.095  |proj g|=       0.13972
At iterate    23  f =      -81.095  |proj g|=     0.0029317

iterations 23
function evaluations 29
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00293175
final function value -81.0948

F = -81.0948
final  value -81.094787 
converged
 
INFO  [02:06:43.527] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:06:43.580] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:06:43.587] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:06:44.514] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:07:06.176] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:07:27.575] [mlr3]  Finished benchmark 
INFO  [02:07:27.640] [bbotk] Result of batch 12: 
INFO  [02:07:27.641] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:07:27.641] [bbotk]                   7              1757      0.4433943        0.423 -0.9191567 
INFO  [02:07:27.641] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:07:27.641] [bbotk]          <NA>   0.8191899 7763f6b2-e59a-473c-b490-7093e71070b7 
DEBUG [02:07:28.257] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.376315e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.001376315 0.1400273 
  - best initial criterion value(s) :  80.24149 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -80.241  |proj g|=       2.5538
At iterate     1  f =      -81.284  |proj g|=        2.5631
At iterate     2  f =      -84.892  |proj g|=        1.8081
At iterate     3  f =      -86.076  |proj g|=        1.5735
At iterate     4  f =      -86.521  |proj g|=        1.3417
At iterate     5  f =      -86.547  |proj g|=        1.0372
At iterate     6  f =      -86.618  |proj g|=       0.22101
At iterate     7  f =      -86.619  |proj g|=        0.2927
At iterate     8  f =       -86.62  |proj g|=       0.36263
At iterate     9  f =      -86.623  |proj g|=       0.49013
At iterate    10  f =      -86.631  |proj g|=       0.71727
At iterate    11  f =      -86.652  |proj g|=        1.0796
At iterate    12  f =      -86.707  |proj g|=        1.3117
At iterate    13  f =      -86.847  |proj g|=        1.3765
At iterate    14  f =      -87.106  |proj g|=        1.4507
At iterate    15  f =      -87.223  |proj g|=        1.0302
At iterate    16  f =      -87.313  |proj g|=        1.3887
At iterate    17  f =      -87.407  |proj g|=        1.3232
At iterate    18  f =      -87.455  |proj g|=        1.0965
At iterate    19  f =      -87.495  |proj g|=       0.13674
At iterate    20  f =      -87.495  |proj g|=      0.002499
At iterate    21  f =      -87.495  |proj g|=      0.002499
At iterate    22  f =      -87.495  |proj g|=      0.002499

iterations 22
function evaluations 26
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00249904
final function value -87.4954

F = -87.4954
final  value -87.495377 
converged
 
INFO  [02:07:28.261] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:07:28.315] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:07:28.322] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:08:02.158] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:08:35.951] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:09:09.872] [mlr3]  Finished benchmark 
INFO  [02:09:09.937] [bbotk] Result of batch 13: 
INFO  [02:09:09.938] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:09:09.938] [bbotk]                   6              2832      0.4625099        0.432 -0.9176314 
INFO  [02:09:09.938] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:09:09.938] [bbotk]          <NA>   0.9767397 b736e3e0-9eea-494c-aa42-72c57f7da1bc 
DEBUG [02:09:10.556] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.375867e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.001375867 0.1396409 
  - best initial criterion value(s) :  78.82268 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -78.823  |proj g|=       1.6989
At iterate     1  f =      -92.153  |proj g|=        1.6806
At iterate     2  f =      -92.589  |proj g|=        1.5894
At iterate     3  f =      -93.313  |proj g|=        1.4584
At iterate     4  f =      -93.314  |proj g|=        1.4581
At iterate     5  f =      -93.315  |proj g|=         1.458
At iterate     6  f =      -93.316  |proj g|=        1.4578
At iterate     7  f =      -93.319  |proj g|=        1.4559
At iterate     8  f =      -93.325  |proj g|=        1.4511
At iterate     9  f =      -93.341  |proj g|=        1.4371
At iterate    10  f =      -93.376  |proj g|=         1.405
At iterate    11  f =      -93.443  |proj g|=        1.3411
At iterate    12  f =      -93.525  |proj g|=       0.63482
At iterate    13  f =      -93.548  |proj g|=       0.13648
At iterate    14  f =      -93.548  |proj g|=       0.13646
At iterate    15  f =      -93.548  |proj g|=      0.060581
At iterate    16  f =      -93.548  |proj g|=     0.0020676

iterations 16
function evaluations 23
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00206762
final function value -93.548

F = -93.548
final  value -93.548000 
converged
 
INFO  [02:09:10.560] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:09:10.614] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:09:10.621] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:09:31.711] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:09:52.971] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:10:13.944] [mlr3]  Finished benchmark 
INFO  [02:10:14.011] [bbotk] Result of batch 14: 
INFO  [02:10:14.013] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:10:14.013] [bbotk]                   5              1729     0.05698381        0.435 -0.9161084 
INFO  [02:10:14.013] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:10:14.013] [bbotk]          <NA>   0.9760045 7bcd1bb8-e270-476a-af14-233fbbc9f587 
DEBUG [02:10:14.677] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.372945e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.001372945 0.1396171 
  - best initial criterion value(s) :  80.39409 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -80.394  |proj g|=       3.2432
At iterate     1  f =      -88.838  |proj g|=        3.9973
At iterate     2  f =       -93.72  |proj g|=        2.0634
At iterate     3  f =      -93.804  |proj g|=        1.1355
At iterate     4  f =      -93.806  |proj g|=       0.93371
At iterate     5  f =      -93.808  |proj g|=         1.137
At iterate     6  f =      -93.815  |proj g|=        1.0156
At iterate     7  f =      -93.844  |proj g|=       0.77722
At iterate     8  f =      -93.942  |proj g|=       0.29506
At iterate     9  f =      -94.168  |proj g|=       0.33362
At iterate    10  f =      -94.677  |proj g|=        0.8624
At iterate    11  f =      -94.728  |proj g|=        1.4787
At iterate    12  f =      -94.875  |proj g|=        1.4188
At iterate    13  f =      -95.022  |proj g|=       0.29871
At iterate    14  f =      -95.061  |proj g|=      0.076367
At iterate    15  f =      -95.067  |proj g|=      0.041097
At iterate    16  f =      -95.067  |proj g|=       0.13646
At iterate    17  f =      -95.067  |proj g|=       0.13646
At iterate    18  f =      -95.067  |proj g|=      0.024367
At iterate    19  f =      -95.067  |proj g|=     0.0027454

iterations 19
function evaluations 28
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00274537
final function value -95.0668

F = -95.0668
final  value -95.066834 
converged
 
INFO  [02:10:14.681] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:10:14.747] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:10:14.754] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:11:10.301] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:12:06.391] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:13:02.454] [mlr3]  Finished benchmark 
INFO  [02:13:02.519] [bbotk] Result of batch 15: 
INFO  [02:13:02.520] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:13:02.520] [bbotk]                   6              4724      0.3626077        0.471 -0.9161832 
INFO  [02:13:02.520] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:13:02.520] [bbotk]          <NA>   0.9765113 e6ae0361-0f89-454a-a18b-db9baf546ea0 
DEBUG [02:13:03.143] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.36867e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.00136867 0.138557 
  - best initial criterion value(s) :  69.85619 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -69.856  |proj g|=       4.0379
At iterate     1  f =      -70.292  |proj g|=         3.548
At iterate     2  f =      -78.409  |proj g|=        3.2265
At iterate     3  f =      -83.098  |proj g|=        3.1793
At iterate     4  f =      -86.459  |proj g|=        2.7622
At iterate     5  f =      -97.434  |proj g|=        1.0349
At iterate     6  f =      -97.456  |proj g|=        2.1415
At iterate     7  f =      -97.753  |proj g|=         1.238
At iterate     8  f =      -97.786  |proj g|=       0.35514
At iterate     9  f =        -97.8  |proj g|=       0.71529
At iterate    10  f =        -97.8  |proj g|=       0.67352
At iterate    11  f =        -97.8  |proj g|=        0.6683
At iterate    12  f =        -97.8  |proj g|=       0.66646
At iterate    13  f =        -97.8  |proj g|=       0.65634
At iterate    14  f =        -97.8  |proj g|=       0.64298
At iterate    15  f =        -97.8  |proj g|=       0.61588
At iterate    16  f =      -97.801  |proj g|=       0.56625
At iterate    17  f =      -97.802  |proj g|=       0.47035
At iterate    18  f =      -97.806  |proj g|=       0.29672
At iterate    19  f =      -97.812  |proj g|=       0.13557
At iterate    20  f =      -97.817  |proj g|=       0.20192
At iterate    21  f =      -97.818  |proj g|=       0.13548
At iterate    22  f =      -97.818  |proj g|=       0.09926
At iterate    23  f =      -97.818  |proj g|=     0.0046791

iterations 23
function evaluations 32
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00467911
final function value -97.8183

F = -97.8183
final  value -97.818257 
converged
 
INFO  [02:13:03.147] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:13:03.203] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:13:03.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:13:35.607] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:13:36.474] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:14:07.762] [mlr3]  Finished benchmark 
INFO  [02:14:07.825] [bbotk] Result of batch 16: 
INFO  [02:14:07.827] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [02:14:07.827] [bbotk]                   9              2597      0.2271532        0.433 -0.915791 
INFO  [02:14:07.827] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:14:07.827] [bbotk]          <NA>   0.8177837 fdcf7e3e-f549-4d85-855d-687529e00ba5 
DEBUG [02:14:08.459] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.339055e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.001339055 0.1361821 
  - best initial criterion value(s) :  78.40578 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -78.406  |proj g|=       2.9261
At iterate     1  f =       -85.86  |proj g|=         1.071
At iterate     2  f =      -89.815  |proj g|=        2.2722
At iterate     3  f =      -90.576  |proj g|=        2.2478
At iterate     4  f =      -96.797  |proj g|=        1.7239
At iterate     5  f =      -100.11  |proj g|=       0.13403
At iterate     6  f =      -101.29  |proj g|=     0.0022591
At iterate     7  f =      -101.35  |proj g|=       0.00227
At iterate     8  f =      -101.37  |proj g|=        0.1332
At iterate     9  f =      -101.37  |proj g|=     0.0022821
At iterate    10  f =      -101.38  |proj g|=     0.0022813
At iterate    11  f =      -101.38  |proj g|=      0.002282
At iterate    12  f =      -101.38  |proj g|=       0.13317
At iterate    13  f =      -101.38  |proj g|=     0.0022827

iterations 13
function evaluations 23
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00228274
final function value -101.382

F = -101.382
final  value -101.382132 
converged
 
INFO  [02:14:08.463] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:14:08.519] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:14:08.526] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:14:09.394] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:15:06.127] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:16:03.281] [mlr3]  Finished benchmark 
INFO  [02:16:03.353] [bbotk] Result of batch 17: 
INFO  [02:16:03.355] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:16:03.355] [bbotk]                   8              4804      0.3307862        0.448 -0.9311184 
INFO  [02:16:03.355] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:16:03.355] [bbotk]          <NA>    0.817701 3c553e41-a414-4e3a-b531-81a9473a5ae3 
DEBUG [02:16:04.005] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.310667e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.001310667 0.1324111 
  - best initial criterion value(s) :  95.47161 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -95.472  |proj g|=       3.4358
At iterate     1  f =      -97.944  |proj g|=        3.0935
At iterate     2  f =      -109.06  |proj g|=        1.6399
At iterate     3  f =      -110.03  |proj g|=        1.3438
At iterate     4  f =      -110.47  |proj g|=        1.6012
At iterate     5  f =      -110.57  |proj g|=        1.4066
At iterate     6  f =      -110.57  |proj g|=       0.98344
At iterate     7  f =      -110.57  |proj g|=        1.0318
At iterate     8  f =      -110.58  |proj g|=        1.1651
At iterate     9  f =      -110.58  |proj g|=        1.3323
At iterate    10  f =      -110.59  |proj g|=        1.6251
At iterate    11  f =      -110.63  |proj g|=        2.0579
At iterate    12  f =      -110.71  |proj g|=        2.7731
At iterate    13  f =      -110.92  |proj g|=        3.8994
At iterate    14  f =      -111.17  |proj g|=        4.2716
At iterate    15  f =      -111.51  |proj g|=        2.6596
At iterate    16  f =      -111.65  |proj g|=       0.84799
At iterate    17  f =      -111.72  |proj g|=       0.27469
At iterate    18  f =      -111.75  |proj g|=       0.12959
At iterate    19  f =      -111.75  |proj g|=       0.12957
At iterate    20  f =      -111.75  |proj g|=       0.12956
At iterate    21  f =      -111.75  |proj g|=      0.002478

iterations 21
function evaluations 28
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00247797
final function value -111.75

F = -111.75
final  value -111.750166 
converged
 
INFO  [02:16:04.009] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:16:04.063] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:16:04.070] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:16:13.163] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:16:22.381] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:16:32.098] [mlr3]  Finished benchmark 
INFO  [02:16:32.163] [bbotk] Result of batch 18: 
INFO  [02:16:32.164] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:16:32.164] [bbotk]                   3               694      0.1770308        0.462 -0.9134865 
INFO  [02:16:32.164] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:16:32.164] [bbotk]          <NA>    0.972244 64c32981-7080-4846-87dd-3f929173b25a 
DEBUG [02:16:32.814] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.30582e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.00130582 0.1333558 
  - best initial criterion value(s) :  83.02977 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -83.03  |proj g|=       6.8281
At iterate     1  f =      -96.393  |proj g|=        3.0496
At iterate     2  f =      -98.994  |proj g|=        2.1224
At iterate     3  f =         -100  |proj g|=        1.7699
At iterate     4  f =      -100.27  |proj g|=        1.6524
At iterate     5  f =      -100.28  |proj g|=        1.6501
At iterate     6  f =      -100.31  |proj g|=        1.6105
At iterate     7  f =      -100.43  |proj g|=        1.5922
At iterate     8  f =      -100.99  |proj g|=        1.4374
At iterate     9  f =       -102.2  |proj g|=       0.76944
At iterate    10  f =       -104.6  |proj g|=        3.0029
At iterate    11  f =      -108.47  |proj g|=        5.2457
At iterate    12  f =      -112.27  |proj g|=        7.1971
At iterate    13  f =      -114.86  |proj g|=        11.186
At iterate    14  f =      -117.75  |proj g|=        3.7911
At iterate    15  f =      -118.27  |proj g|=       0.21657
At iterate    16  f =      -118.27  |proj g|=       0.13061
At iterate    17  f =      -118.27  |proj g|=        0.1306
At iterate    18  f =      -118.27  |proj g|=        0.1306
At iterate    19  f =      -118.27  |proj g|=     0.0021056
At iterate    20  f =      -118.27  |proj g|=        0.1306

iterations 20
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.130599
final function value -118.269

F = -118.269
final  value -118.269412 
converged
 
INFO  [02:16:32.818] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:16:32.873] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:16:32.880] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:16:56.073] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:16:56.973] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:17:20.613] [mlr3]  Finished benchmark 
INFO  [02:17:20.678] [bbotk] Result of batch 19: 
INFO  [02:17:20.680] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:17:20.680] [bbotk]                   8              1910      0.3235027        0.437 -0.9135002 
INFO  [02:17:20.680] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:17:20.680] [bbotk]          <NA>   0.8186959 0ed511ca-3ee4-406b-81cb-7aea37d4f480 
DEBUG [02:17:21.347] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.279726e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.001279726 0.1303406 
  - best initial criterion value(s) :  93.83123 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -93.831  |proj g|=       6.6177
At iterate     1  f =      -100.34  |proj g|=        3.7326
At iterate     2  f =      -106.32  |proj g|=        1.9378
At iterate     3  f =      -111.31  |proj g|=        1.4405
At iterate     4  f =      -111.34  |proj g|=        1.4487
At iterate     5  f =      -111.37  |proj g|=        1.3752
At iterate     6  f =      -113.68  |proj g|=        1.3266
At iterate     7  f =      -121.77  |proj g|=        1.3007
At iterate     8  f =      -121.84  |proj g|=       0.15126
At iterate     9  f =      -121.84  |proj g|=       0.12764
At iterate    10  f =      -121.84  |proj g|=     0.0023503
At iterate    11  f =      -121.84  |proj g|=       0.12764
At iterate    12  f =      -121.84  |proj g|=     0.0023503

iterations 12
function evaluations 20
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00235028
final function value -121.837

F = -121.837
final  value -121.836907 
converged
 
INFO  [02:17:21.351] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:17:21.405] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:17:21.411] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:17:37.402] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:17:54.098] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:18:10.197] [mlr3]  Finished benchmark 
INFO  [02:18:10.264] [bbotk] Result of batch 20: 
INFO  [02:18:10.265] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:18:10.265] [bbotk]                   3              1283       0.357752        0.469 -0.9130025 
INFO  [02:18:10.265] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:18:10.265] [bbotk]          <NA>   0.9738455 1725c6a7-ca1c-4fb4-9fb0-41194f669452 
DEBUG [02:18:10.948] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.275959e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.001275959 0.1297382 
  - best initial criterion value(s) :  99.50092 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -99.501  |proj g|=      0.45271
At iterate     1  f =      -111.47  |proj g|=        1.8798
At iterate     2  f =      -113.77  |proj g|=        1.8027
At iterate     3  f =      -116.21  |proj g|=        1.6772
At iterate     4  f =      -117.14  |proj g|=        1.6771
At iterate     5  f =      -117.19  |proj g|=        1.6771
At iterate     6  f =      -117.21  |proj g|=        1.6771
At iterate     7  f =      -117.21  |proj g|=        1.6771
At iterate     8  f =      -117.21  |proj g|=        1.6771
At iterate     9  f =      -117.21  |proj g|=         1.677
At iterate    10  f =      -117.21  |proj g|=        1.6769
At iterate    11  f =      -117.21  |proj g|=        1.6765
At iterate    12  f =      -117.21  |proj g|=        1.6753
At iterate    13  f =      -117.22  |proj g|=        1.6723
At iterate    14  f =      -117.24  |proj g|=        1.6642
At iterate    15  f =      -117.29  |proj g|=        1.6429
At iterate    16  f =      -117.41  |proj g|=        1.5895
At iterate    17  f =      -117.68  |proj g|=        0.8599
At iterate    18  f =      -118.17  |proj g|=        1.0236
At iterate    19  f =      -118.38  |proj g|=       0.96782
At iterate    20  f =       -118.4  |proj g|=       0.43858
At iterate    21  f =      -118.41  |proj g|=      0.039094
At iterate    22  f =      -118.41  |proj g|=         0.127
At iterate    23  f =      -118.41  |proj g|=     0.0037249
At iterate    24  f =      -118.41  |proj g|=     0.0037249

iterations 24
function evaluations 29
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00372489
final function value -118.409

F = -118.409
final  value -118.408507 
converged
 
INFO  [02:18:10.952] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:18:11.016] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:18:11.023] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:18:48.768] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:19:25.916] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:20:02.845] [mlr3]  Finished benchmark 
INFO  [02:20:02.910] [bbotk] Result of batch 21: 
INFO  [02:20:02.912] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:20:02.912] [bbotk]                   4              3078      0.3793001        0.483 -0.9142978 
INFO  [02:20:02.912] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:20:02.912] [bbotk]          <NA>   0.9760125 f4765301-beed-43fe-9768-4ebe88f1ca53 
DEBUG [02:20:03.742] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.272223e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.001272223 0.1295324 
  - best initial criterion value(s) :  99.21826 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -99.218  |proj g|=       3.7755
At iterate     1  f =      -102.01  |proj g|=         3.361
At iterate     2  f =      -102.43  |proj g|=        3.5286
At iterate     3  f =      -103.68  |proj g|=        3.4648
At iterate     4  f =      -104.39  |proj g|=        3.2488
At iterate     5  f =      -107.31  |proj g|=        2.9929
At iterate     6  f =      -115.69  |proj g|=        1.9072
At iterate     7  f =      -117.13  |proj g|=        1.6134
At iterate     8  f =      -118.39  |proj g|=       0.59416
At iterate     9  f =      -118.42  |proj g|=       0.44783
At iterate    10  f =      -118.42  |proj g|=       0.42221
At iterate    11  f =      -118.42  |proj g|=       0.36516
At iterate    12  f =      -118.45  |proj g|=       0.14466
At iterate    13  f =       -118.5  |proj g|=       0.74612
At iterate    14  f =      -118.53  |proj g|=       0.74513
At iterate    15  f =      -118.55  |proj g|=       0.10612
At iterate    16  f =      -118.55  |proj g|=       0.02759
At iterate    17  f =      -118.55  |proj g|=       0.12679
At iterate    18  f =      -118.55  |proj g|=      0.035091

iterations 18
function evaluations 26
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0350911
final function value -118.547

F = -118.547
final  value -118.547352 
converged
 
INFO  [02:20:03.745] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:20:03.797] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:20:03.804] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:20:04.579] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:20:05.438] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:20:53.744] [mlr3]  Finished benchmark 
INFO  [02:20:53.809] [bbotk] Result of batch 22: 
INFO  [02:20:53.811] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:20:53.811] [bbotk]                  10              4038      0.1886226        0.583 -0.9145991 
INFO  [02:20:53.811] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:20:53.811] [bbotk]          <NA>    0.659139 ecf54b8e-080b-497c-8d86-2ce1b79b577c 
DEBUG [02:20:54.545] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.34363e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.00134363 0.1361802 
  - best initial criterion value(s) :  112.3511 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -112.35  |proj g|=      0.34415
At iterate     1  f =      -115.59  |proj g|=        2.4366
At iterate     2  f =      -116.02  |proj g|=        2.4617
At iterate     3  f =      -116.05  |proj g|=        2.4593
At iterate     4  f =      -116.14  |proj g|=        2.4072
At iterate     5  f =      -116.42  |proj g|=        2.1439
At iterate     6  f =      -116.62  |proj g|=        2.0533
At iterate     7  f =      -116.65  |proj g|=        1.9539
At iterate     8  f =      -116.66  |proj g|=        1.9751
At iterate     9  f =      -116.66  |proj g|=        1.9908
At iterate    10  f =      -116.69  |proj g|=         2.035
At iterate    11  f =      -116.77  |proj g|=        2.1007
At iterate    12  f =      -116.97  |proj g|=        2.2177
At iterate    13  f =         -117  |proj g|=        2.1992
At iterate    14  f =      -117.43  |proj g|=        2.3723
At iterate    15  f =      -117.85  |proj g|=        2.3601
At iterate    16  f =      -118.72  |proj g|=        2.2306
At iterate    17  f =      -119.93  |proj g|=        1.9833
At iterate    18  f =      -121.66  |proj g|=          1.41
At iterate    19  f =       -122.8  |proj g|=        2.7094
At iterate    20  f =      -123.08  |proj g|=       0.39666
At iterate    21  f =      -123.14  |proj g|=       0.22591
At iterate    22  f =      -123.14  |proj g|=     0.0045741
At iterate    23  f =      -123.14  |proj g|=       0.13343
At iterate    24  f =      -123.14  |proj g|=     0.0045742

iterations 24
function evaluations 32
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00457421
final function value -123.137

F = -123.137
final  value -123.136597 
converged
 
INFO  [02:20:54.547] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:20:54.599] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:20:54.606] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:21:23.894] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:21:53.107] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:21:53.998] [mlr3]  Finished benchmark 
INFO  [02:21:54.063] [bbotk] Result of batch 23: 
INFO  [02:21:54.065] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:21:54.065] [bbotk]                   8              2388       0.373607        0.493 -0.9116416 
INFO  [02:21:54.065] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:21:54.065] [bbotk]          <NA>   0.8184424 1696a39f-8062-4d18-ac86-f0067faa0bba 
DEBUG [02:21:54.902] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.318874e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.001318874 0.134227 
  - best initial criterion value(s) :  111.1378 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -111.14  |proj g|=      0.33143
At iterate     1  f =      -117.04  |proj g|=        2.4975
At iterate     2  f =       -117.8  |proj g|=        2.4572
At iterate     3  f =      -119.53  |proj g|=        2.3316
At iterate     4  f =      -119.54  |proj g|=        2.3312
At iterate     5  f =      -119.54  |proj g|=         2.331
At iterate     6  f =      -119.55  |proj g|=        2.3299
At iterate     7  f =      -119.56  |proj g|=         2.327
At iterate     8  f =       -119.6  |proj g|=        2.3183
At iterate     9  f =      -119.68  |proj g|=         2.296
At iterate    10  f =      -119.89  |proj g|=        2.2404
At iterate    11  f =      -120.37  |proj g|=         2.106
At iterate    12  f =      -121.49  |proj g|=       0.41023
At iterate    13  f =      -123.93  |proj g|=        4.2323
At iterate    14  f =      -124.68  |proj g|=       0.68451
At iterate    15  f =      -124.69  |proj g|=       0.22564
At iterate    16  f =       -124.7  |proj g|=       0.13148
At iterate    17  f =       -124.7  |proj g|=     0.0054342
At iterate    18  f =       -124.7  |proj g|=     0.0054343

iterations 18
function evaluations 26
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00543425
final function value -124.696

F = -124.696
final  value -124.696393 
converged
 
INFO  [02:21:54.905] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:21:54.965] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:21:54.971] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:22:00.679] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:22:06.441] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:22:12.294] [mlr3]  Finished benchmark 
INFO  [02:22:12.359] [bbotk] Result of batch 24: 
INFO  [02:22:12.361] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:22:12.361] [bbotk]                   3               395      0.2923691        0.587 -0.9117781 
INFO  [02:22:12.361] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:22:12.361] [bbotk]          <NA>   0.9721392 284b5792-f908-409b-8999-73cc5fd975bd 
DEBUG [02:22:13.036] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.314246e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.001314246 0.1343057 
  - best initial criterion value(s) :  110.0211 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -110.02  |proj g|=       4.4583
At iterate     1  f =      -113.44  |proj g|=        1.5847
At iterate     2  f =      -114.96  |proj g|=        2.0004
At iterate     3  f =      -115.63  |proj g|=        1.8397
At iterate     4  f =      -116.16  |proj g|=         1.402
At iterate     5  f =      -116.28  |proj g|=       0.94678
At iterate     6  f =      -116.43  |proj g|=         1.465
At iterate     7  f =      -116.45  |proj g|=        1.4341
At iterate     8  f =      -116.45  |proj g|=        1.4345
At iterate     9  f =      -116.45  |proj g|=        1.4338
At iterate    10  f =      -116.46  |proj g|=        1.4302
At iterate    11  f =      -116.47  |proj g|=        1.4256
At iterate    12  f =      -116.51  |proj g|=        1.4135
At iterate    13  f =      -116.58  |proj g|=       0.99044
At iterate    14  f =      -116.77  |proj g|=       0.31334
At iterate    15  f =      -117.12  |proj g|=        1.9721
At iterate    16  f =      -117.57  |proj g|=        4.0843
At iterate    17  f =      -117.63  |proj g|=        3.4688
At iterate    18  f =      -117.64  |proj g|=        2.9136
At iterate    19  f =         -118  |proj g|=        2.9299
At iterate    20  f =      -121.73  |proj g|=        2.3449
At iterate    21  f =      -124.85  |proj g|=        1.4424
At iterate    22  f =      -125.43  |proj g|=       0.14084
At iterate    23  f =      -125.56  |proj g|=       0.53604
At iterate    24  f =      -125.57  |proj g|=       0.51733
At iterate    25  f =      -125.57  |proj g|=        0.3573
At iterate    26  f =      -125.58  |proj g|=       0.13156
At iterate    27  f =      -125.58  |proj g|=     0.0063861
At iterate    28  f =      -125.58  |proj g|=     0.0063861

iterations 28
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0063861
final function value -125.577

F = -125.577
final  value -125.576526 
converged
 
INFO  [02:22:13.040] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:22:13.092] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:22:13.099] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:22:26.189] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:22:39.641] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:22:52.698] [mlr3]  Finished benchmark 
INFO  [02:22:52.761] [bbotk] Result of batch 25: 
INFO  [02:22:52.763] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:22:52.763] [bbotk]                   4              1022     0.04723107        0.471 -0.9126196 
INFO  [02:22:52.763] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:22:52.763] [bbotk]          <NA>   0.9722112 598547cf-783e-4624-a039-0ca7a194e78d 
DEBUG [02:22:53.459] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.308865e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.001308865 0.1346275 
  - best initial criterion value(s) :  99.71437 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -99.714  |proj g|=       2.4052
At iterate     1  f =      -117.08  |proj g|=        3.0583
At iterate     2  f =      -130.77  |proj g|=        3.0031
At iterate     3  f =      -131.42  |proj g|=        9.3046
At iterate     4  f =      -131.69  |proj g|=        10.203
At iterate     5  f =      -131.75  |proj g|=        8.9094
At iterate     6  f =      -131.81  |proj g|=        8.6361
At iterate     7  f =         -132  |proj g|=         8.331
At iterate     8  f =      -132.47  |proj g|=        7.7353
At iterate     9  f =      -133.82  |proj g|=        6.3359
At iterate    10  f =      -137.13  |proj g|=        4.1559
At iterate    11  f =       -138.8  |proj g|=        2.0832
At iterate    12  f =      -139.33  |proj g|=       0.99614
At iterate    13  f =       -139.5  |proj g|=       0.27966
At iterate    14  f =      -139.53  |proj g|=       0.13212
At iterate    15  f =      -139.53  |proj g|=       0.13209
At iterate    16  f =      -139.53  |proj g|=       0.13208
At iterate    17  f =      -139.53  |proj g|=     0.0043911
At iterate    18  f =      -139.53  |proj g|=     0.0043911

iterations 18
function evaluations 25
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00439105
final function value -139.529

F = -139.529
final  value -139.528647 
converged
 
INFO  [02:22:53.463] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:22:53.517] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:22:53.524] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:23:16.758] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:23:40.029] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:23:40.930] [mlr3]  Finished benchmark 
INFO  [02:23:40.996] [bbotk] Result of batch 26: 
INFO  [02:23:40.998] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:23:40.998] [bbotk]                   7              1933      0.2890077        0.461 -0.9093225 
INFO  [02:23:40.998] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:23:40.998] [bbotk]          <NA>   0.8191929 08dc1cc2-711b-43bb-ada6-f64d5e94149d 
DEBUG [02:23:41.682] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.286921e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.001286921 0.1325122 
  - best initial criterion value(s) :  126.6406 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -126.64  |proj g|=       2.8253
At iterate     1  f =      -130.21  |proj g|=        3.1941
At iterate     2  f =      -133.26  |proj g|=        2.5716
At iterate     3  f =      -135.83  |proj g|=        2.1016
At iterate     4  f =      -136.54  |proj g|=        1.9161
At iterate     5  f =      -137.22  |proj g|=        1.5915
At iterate     6  f =      -137.25  |proj g|=        1.4795
At iterate     7  f =      -137.34  |proj g|=        1.4978
At iterate     8  f =      -137.35  |proj g|=        1.5008
At iterate     9  f =      -137.35  |proj g|=        1.5053
At iterate    10  f =      -137.37  |proj g|=        1.5182
At iterate    11  f =      -137.42  |proj g|=        1.5373
At iterate    12  f =      -137.55  |proj g|=        1.5818
At iterate    13  f =      -137.85  |proj g|=        1.6687
At iterate    14  f =      -138.48  |proj g|=        1.8206
At iterate    15  f =      -139.58  |proj g|=        2.0184
At iterate    16  f =      -140.07  |proj g|=        2.0335
At iterate    17  f =       -142.3  |proj g|=        2.1644
At iterate    18  f =      -144.58  |proj g|=        1.9474
At iterate    19  f =      -147.13  |proj g|=      0.092012
At iterate    20  f =      -147.28  |proj g|=       0.86899
At iterate    21  f =       -147.3  |proj g|=         0.129
At iterate    22  f =       -147.3  |proj g|=       0.13004
At iterate    23  f =       -147.3  |proj g|=     0.0038847
At iterate    24  f =       -147.3  |proj g|=     0.0038847
At iterate    25  f =       -147.3  |proj g|=     0.0050304

iterations 25
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00503036
final function value -147.299

F = -147.299
final  value -147.299051 
converged
 
INFO  [02:23:41.683] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:23:41.737] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:23:41.744] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:23:42.641] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:24:01.200] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:24:19.596] [mlr3]  Finished benchmark 
INFO  [02:24:19.663] [bbotk] Result of batch 27: 
INFO  [02:24:19.664] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:24:19.664] [bbotk]                   8              1488       0.307215        0.485 -0.9076939 
INFO  [02:24:19.664] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:24:19.664] [bbotk]          <NA>   0.8188519 8340722e-61d2-4ca2-ad8c-86f5670a5763 
DEBUG [02:24:20.320] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.265732e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9413443 
  - variance bounds :  0.001265732 0.1307778 
  - best initial criterion value(s) :  139.0475 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -139.05  |proj g|=       3.6689
At iterate     1  f =      -147.48  |proj g|=        4.7398
At iterate     2  f =      -156.45  |proj g|=        3.9992
At iterate     3  f =      -156.82  |proj g|=       0.59334
At iterate     4  f =      -156.85  |proj g|=        0.1746
At iterate     5  f =      -156.86  |proj g|=      0.039258
At iterate     6  f =      -156.86  |proj g|=        0.1284
At iterate     7  f =      -156.87  |proj g|=       0.12841
At iterate     8  f =      -156.87  |proj g|=       0.12843
At iterate     9  f =      -156.88  |proj g|=       0.17937
At iterate    10  f =       -156.9  |proj g|=       0.29827
At iterate    11  f =      -156.91  |proj g|=       0.27429
At iterate    12  f =      -156.93  |proj g|=        0.1284
At iterate    13  f =      -156.93  |proj g|=      0.033138
At iterate    14  f =      -156.93  |proj g|=       0.12839
At iterate    15  f =      -156.93  |proj g|=       0.12839
At iterate    16  f =      -156.93  |proj g|=      0.016281

iterations 16
function evaluations 24
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0162814
final function value -156.931

F = -156.931
final  value -156.931230 
converged
 
INFO  [02:24:20.324] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:24:20.386] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:24:20.396] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:24:50.139] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:25:19.886] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:25:50.045] [mlr3]  Finished benchmark 
INFO  [02:25:50.112] [bbotk] Result of batch 28: 
INFO  [02:25:50.114] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:25:50.114] [bbotk]                   3              2426      0.4981828        0.467 -0.9064316 
INFO  [02:25:50.114] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:25:50.114] [bbotk]          <NA>   0.9743106 9839311b-5f7a-4bc2-ba70-a20dc6c4e729 
DEBUG [02:25:50.788] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.262488e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9578422 
  - variance bounds :  0.001262488 0.1316972 
  - best initial criterion value(s) :  127.1378 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -127.14  |proj g|=       3.8928
At iterate     1  f =      -130.84  |proj g|=        2.2306
At iterate     2  f =      -134.91  |proj g|=        2.2191
At iterate     3  f =      -135.61  |proj g|=        2.0308
At iterate     4  f =      -137.47  |proj g|=        1.5187
At iterate     5  f =      -137.53  |proj g|=       0.27935
At iterate     6  f =      -137.84  |proj g|=        1.3972
At iterate     7  f =      -137.85  |proj g|=        1.3819
At iterate     8  f =      -137.86  |proj g|=        1.3955
At iterate     9  f =      -137.87  |proj g|=        1.3962
At iterate    10  f =      -137.91  |proj g|=        1.3842
At iterate    11  f =      -137.97  |proj g|=       0.90389
At iterate    12  f =      -138.09  |proj g|=       0.27301
At iterate    13  f =      -138.45  |proj g|=        1.3467
At iterate    14  f =      -139.72  |proj g|=        3.3297
At iterate    15  f =      -142.39  |proj g|=        5.1694
At iterate    16  f =      -145.21  |proj g|=        5.4849
At iterate    17  f =       -146.2  |proj g|=        3.5724
At iterate    18  f =      -146.46  |proj g|=       0.77182
At iterate    19  f =      -146.52  |proj g|=      0.049165
At iterate    20  f =      -146.52  |proj g|=     0.0080592
At iterate    21  f =      -146.52  |proj g|=        0.1292
At iterate    22  f =      -146.52  |proj g|=     0.0062389

iterations 22
function evaluations 32
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00623888
final function value -146.521

F = -146.521
final  value -146.521271 
converged
 
INFO  [02:25:50.792] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:25:50.846] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:25:50.853] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:26:41.886] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:27:33.020] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:28:23.793] [mlr3]  Finished benchmark 
INFO  [02:28:23.858] [bbotk] Result of batch 29: 
INFO  [02:28:23.860] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:28:23.860] [bbotk]                   4              4309     0.09580749         0.47 -0.9103669 
INFO  [02:28:23.860] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:28:23.860] [bbotk]          <NA>   0.9759768 0ed04fcb-2b0a-49a9-a8fa-d209078d57c0 
DEBUG [02:28:24.526] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.25921e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9578422 
  - variance bounds :  0.00125921 0.1297272 
  - best initial criterion value(s) :  150.0201 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -150.02  |proj g|=       3.3917
At iterate     1  f =      -151.03  |proj g|=        2.3961
At iterate     2  f =      -152.08  |proj g|=        3.2346
At iterate     3  f =      -153.22  |proj g|=        3.2372
At iterate     4  f =      -153.73  |proj g|=        3.1776
At iterate     5  f =       -155.1  |proj g|=        3.0128
At iterate     6  f =      -159.28  |proj g|=        2.5052
At iterate     7  f =       -165.8  |proj g|=         1.566
At iterate     8  f =      -167.21  |proj g|=        1.5407
At iterate     9  f =      -167.24  |proj g|=        1.5364
At iterate    10  f =      -167.36  |proj g|=        1.5011
At iterate    11  f =      -167.46  |proj g|=        1.4687
At iterate    12  f =      -167.87  |proj g|=         1.143
At iterate    13  f =      -167.93  |proj g|=       0.18766
At iterate    14  f =      -167.93  |proj g|=       0.12746
At iterate    15  f =      -167.93  |proj g|=       0.12746
At iterate    16  f =      -167.93  |proj g|=     0.0034319

iterations 16
function evaluations 22
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00343192
final function value -167.932

F = -167.932
final  value -167.931577 
converged
 
INFO  [02:28:24.530] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:28:24.597] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:28:24.604] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:29:07.038] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:29:07.915] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:29:50.373] [mlr3]  Finished benchmark 
INFO  [02:29:50.438] [bbotk] Result of batch 30: 
INFO  [02:29:50.439] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:29:50.439] [bbotk]                   9              3605     0.03901437        0.471 -0.9066485 
INFO  [02:29:50.439] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:29:50.439] [bbotk]          <NA>   0.8183655 9e79bf72-d536-412f-86fb-ea69afe9f3cd 
DEBUG [02:29:51.220] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.240489e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9578422 
  - variance bounds :  0.001240489 0.1278853 
  - best initial criterion value(s) :  105.7317 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -105.73  |proj g|=       1.8314
At iterate     1  f =      -137.05  |proj g|=        1.8208
At iterate     2  f =      -139.42  |proj g|=       0.87413
At iterate     3  f =      -139.53  |proj g|=        1.3265
At iterate     4  f =      -139.65  |proj g|=       0.36241
At iterate     5  f =      -139.67  |proj g|=      0.074396
At iterate     6  f =      -139.67  |proj g|=      0.070239
At iterate     7  f =      -139.67  |proj g|=      0.011115
At iterate     8  f =      -139.67  |proj g|=      0.024276
At iterate     9  f =      -139.67  |proj g|=       0.06683
At iterate    10  f =      -139.67  |proj g|=      0.011118

iterations 10
function evaluations 17
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0111183
final function value -139.671

F = -139.671
final  value -139.671247 
converged
 
INFO  [02:29:51.224] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:29:51.279] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:29:51.286] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:30:22.769] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:30:54.432] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:30:55.369] [mlr3]  Finished benchmark 
INFO  [02:30:55.446] [bbotk] Result of batch 31: 
INFO  [02:30:55.448] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:30:55.448] [bbotk]                   7              2630      0.2769615        0.582 -0.9145651 
INFO  [02:30:55.448] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:30:55.448] [bbotk]          <NA>   0.8192215 a26b29db-220d-406d-b34b-335f8a55d400 
DEBUG [02:30:56.382] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.222108e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9578422 
  - variance bounds :  0.001222108 0.1268529 
  - best initial criterion value(s) :  151.0954 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -151.1  |proj g|=      0.14106
At iterate     1  f =       -166.2  |proj g|=        6.5532
At iterate     2  f =      -166.73  |proj g|=        9.0586
At iterate     3  f =      -166.96  |proj g|=        8.2033
At iterate     4  f =      -166.97  |proj g|=        8.0367
At iterate     5  f =      -166.97  |proj g|=        7.9919
At iterate     6  f =      -166.97  |proj g|=        7.9883
At iterate     7  f =      -166.97  |proj g|=        7.9735
At iterate     8  f =      -166.97  |proj g|=        7.9583
At iterate     9  f =      -166.97  |proj g|=        7.9395
At iterate    10  f =      -166.97  |proj g|=        7.9291
At iterate    11  f =      -166.98  |proj g|=        7.9609
At iterate    12  f =      -167.01  |proj g|=        8.1367
At iterate    13  f =      -167.08  |proj g|=        8.7357
At iterate    14  f =       -167.3  |proj g|=        10.186
At iterate    15  f =      -167.83  |proj g|=        10.454
At iterate    16  f =      -168.38  |proj g|=         9.708
At iterate    17  f =      -171.01  |proj g|=        5.3155
At iterate    18  f =      -174.24  |proj g|=       0.64642
At iterate    19  f =      -174.57  |proj g|=       0.78221
At iterate    20  f =      -174.59  |proj g|=       0.24274
At iterate    21  f =      -174.59  |proj g|=      0.027996
At iterate    22  f =      -174.59  |proj g|=       0.12464
At iterate    23  f =      -174.59  |proj g|=     0.0042805
At iterate    24  f =      -174.59  |proj g|=     0.0042805

iterations 24
function evaluations 30
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00428048
final function value -174.591

F = -174.591
final  value -174.591401 
converged
 
INFO  [02:30:56.387] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:30:56.461] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:30:56.469] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:30:57.463] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:31:10.891] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:31:24.491] [mlr3]  Finished benchmark 
INFO  [02:31:24.556] [bbotk] Result of batch 32: 
INFO  [02:31:24.558] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:31:24.558] [bbotk]                   8              1047      0.1275911        0.683 -0.9068864 
INFO  [02:31:24.558] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:31:24.558] [bbotk]          <NA>   0.8184167 2293e5bb-094a-4fbb-9206-57476fc85762 
DEBUG [02:31:25.707] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.20438e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9578422 
  - variance bounds :  0.00120438 0.1250982 
  - best initial criterion value(s) :  160.5113 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -160.51  |proj g|=        2.611
At iterate     1  f =      -164.02  |proj g|=        3.5051
At iterate     2  f =      -173.16  |proj g|=        2.3759
At iterate     3  f =      -175.01  |proj g|=        2.0687
At iterate     4  f =      -178.29  |proj g|=        1.5102
At iterate     5  f =      -178.49  |proj g|=        1.3854
At iterate     6  f =      -178.52  |proj g|=       0.17576
At iterate     7  f =      -178.59  |proj g|=        1.3038
At iterate     8  f =      -178.59  |proj g|=        1.3038
At iterate     9  f =      -178.59  |proj g|=        1.3048
At iterate    10  f =       -178.6  |proj g|=        1.3075
At iterate    11  f =      -178.61  |proj g|=        1.3103
At iterate    12  f =      -178.63  |proj g|=        1.3147
At iterate    13  f =       -178.7  |proj g|=        1.3224
At iterate    14  f =      -178.89  |proj g|=        1.3375
At iterate    15  f =       -179.4  |proj g|=        1.3711
At iterate    16  f =      -180.83  |proj g|=        1.4523
At iterate    17  f =      -182.92  |proj g|=        1.5257
At iterate    18  f =      -183.85  |proj g|=        1.5172
At iterate    19  f =      -184.03  |proj g|=        1.5117
At iterate    20  f =      -184.06  |proj g|=         1.508
At iterate    21  f =      -184.07  |proj g|=        1.5064
At iterate    22  f =      -184.07  |proj g|=        1.5049
At iterate    23  f =      -184.09  |proj g|=        1.4986
At iterate    24  f =      -184.12  |proj g|=        1.4826
At iterate    25  f =      -184.21  |proj g|=         1.441
At iterate    26  f =      -184.39  |proj g|=        0.6888
At iterate    27  f =      -184.67  |proj g|=       0.82151
At iterate    28  f =      -184.74  |proj g|=       0.12305
At iterate    29  f =      -184.76  |proj g|=     0.0037206
At iterate    30  f =      -184.76  |proj g|=     0.0037221
At iterate    31  f =      -184.76  |proj g|=      0.028274
At iterate    32  f =      -184.76  |proj g|=     0.0099128

iterations 32
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00991283
final function value -184.757

F = -184.757
final  value -184.756703 
converged
 
INFO  [02:31:25.711] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:31:25.771] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:31:25.777] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:31:45.512] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:32:04.814] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:32:24.214] [mlr3]  Finished benchmark 
INFO  [02:32:24.279] [bbotk] Result of batch 33: 
INFO  [02:32:24.281] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:32:24.281] [bbotk]                   5              1580      0.4255012         0.87 -0.9056872 
INFO  [02:32:24.281] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:32:24.281] [bbotk]          <NA>   0.9771086 d6109c26-c836-4bff-b8df-d2f3b99dc9fa 
DEBUG [02:32:25.124] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.203197e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9578422 
  - variance bounds :  0.001203197 0.1249851 
  - best initial criterion value(s) :  144.9192 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -144.92  |proj g|=       3.0178
At iterate     1  f =      -145.03  |proj g|=        2.9844
At iterate     2  f =      -145.24  |proj g|=        2.9818
At iterate     3  f =      -145.79  |proj g|=        2.9349
At iterate     4  f =      -147.95  |proj g|=        2.5554
At iterate     5  f =      -155.94  |proj g|=        1.9222
At iterate     6  f =      -159.89  |proj g|=        1.3393
At iterate     7  f =      -160.52  |proj g|=       0.10639
At iterate     8  f =      -160.69  |proj g|=        2.3126
At iterate     9  f =      -160.72  |proj g|=        1.3405
At iterate    10  f =      -160.94  |proj g|=        1.0255
At iterate    11  f =      -161.64  |proj g|=       0.67765
At iterate    12  f =      -161.76  |proj g|=       0.26202
At iterate    13  f =      -161.81  |proj g|=       0.12267
At iterate    14  f =      -161.81  |proj g|=       0.12263
At iterate    15  f =      -161.81  |proj g|=       0.12263
At iterate    16  f =      -161.81  |proj g|=     0.0091945

iterations 16
function evaluations 23
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00919451
final function value -161.813

F = -161.813
final  value -161.812825 
converged
 
INFO  [02:32:25.128] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:32:25.182] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:32:25.188] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:33:01.431] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:33:02.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:33:38.404] [mlr3]  Finished benchmark 
INFO  [02:33:38.468] [bbotk] Result of batch 34: 
INFO  [02:33:38.469] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:33:38.469] [bbotk]                   7              3006      0.1473053        0.586 -0.9106466 
INFO  [02:33:38.469] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:33:38.469] [bbotk]          <NA>   0.8190929 20a679d0-94ba-4862-8bee-d53c4a250d92 
DEBUG [02:33:39.328] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.186498e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9578422 
  - variance bounds :  0.001186498 0.1230706 
  - best initial criterion value(s) :  170.9362 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -170.94  |proj g|=       8.4308
At iterate     1  f =      -177.98  |proj g|=        1.3273
At iterate     2  f =      -184.79  |proj g|=        2.0008
At iterate     3  f =      -187.37  |proj g|=        1.5238
At iterate     4  f =      -188.09  |proj g|=       0.79605
At iterate     5  f =      -188.49  |proj g|=       0.19098
At iterate     6  f =      -188.51  |proj g|=        1.2118
At iterate     7  f =      -188.52  |proj g|=       0.98593
At iterate     8  f =      -188.52  |proj g|=       0.92902
At iterate     9  f =      -188.53  |proj g|=       0.85192
At iterate    10  f =       -188.6  |proj g|=       0.68418
At iterate    11  f =      -188.77  |proj g|=       0.38269
At iterate    12  f =      -189.24  |proj g|=        0.1659
At iterate    13  f =       -190.7  |proj g|=        1.4079
At iterate    14  f =      -194.16  |proj g|=        3.6416
At iterate    15  f =      -195.19  |proj g|=        3.5545
At iterate    16  f =      -195.41  |proj g|=        2.9199
At iterate    17  f =      -195.59  |proj g|=        1.5323
At iterate    18  f =      -195.64  |proj g|=       0.12102
At iterate    19  f =      -195.64  |proj g|=       0.12101
At iterate    20  f =      -195.64  |proj g|=      0.009221
At iterate    21  f =      -195.64  |proj g|=     0.0037838
At iterate    22  f =      -195.64  |proj g|=     0.0037838

iterations 22
function evaluations 31
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00378384
final function value -195.637

F = -195.637
final  value -195.637376 
converged
 
INFO  [02:33:39.331] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:33:39.385] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:33:39.392] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:34:12.775] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:34:45.811] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:35:19.334] [mlr3]  Finished benchmark 
INFO  [02:35:19.400] [bbotk] Result of batch 35: 
INFO  [02:35:19.402] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:35:19.402] [bbotk]                   4              2741      0.1947319        0.598 -0.9045343 
INFO  [02:35:19.402] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:35:19.402] [bbotk]          <NA>   0.9759898 d2b546cd-1f14-44bb-ba05-33a4261adcfe 
DEBUG [02:35:20.278] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.184902e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9578422 
  - variance bounds :  0.001184902 0.1222368 
  - best initial criterion value(s) :  169.0273 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -169.03  |proj g|=       2.6526
At iterate     1  f =      -176.77  |proj g|=        3.4591
At iterate     2  f =      -179.44  |proj g|=       0.36476
At iterate     3  f =      -179.74  |proj g|=       0.28585
At iterate     4  f =      -179.76  |proj g|=       0.34019
At iterate     5  f =      -179.77  |proj g|=        0.2232
At iterate     6  f =       -179.8  |proj g|=       0.12012
At iterate     7  f =      -180.02  |proj g|=       0.60173
At iterate     8  f =      -180.09  |proj g|=       0.53108
At iterate     9  f =      -180.11  |proj g|=       0.14909
At iterate    10  f =      -180.11  |proj g|=       0.12006
At iterate    11  f =      -180.11  |proj g|=       0.12006
At iterate    12  f =      -180.11  |proj g|=       0.12006
At iterate    13  f =      -180.11  |proj g|=      0.015265
At iterate    14  f =      -180.11  |proj g|=     0.0083001
At iterate    15  f =      -180.11  |proj g|=       0.12006
At iterate    16  f =      -180.11  |proj g|=      0.029547

iterations 16
function evaluations 23
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0295474
final function value -180.107

F = -180.107
final  value -180.106923 
converged
 
INFO  [02:35:20.282] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:35:20.338] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:35:20.345] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:35:31.905] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:35:43.757] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:35:55.857] [mlr3]  Finished benchmark 
INFO  [02:35:55.920] [bbotk] Result of batch 36: 
INFO  [02:35:55.922] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:35:55.922] [bbotk]                   6               906      0.2998961        0.614 -0.9079121 
INFO  [02:35:55.922] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:35:55.922] [bbotk]          <NA>   0.9771233 09fce992-df89-4be2-9866-41c4ed2bc227 
DEBUG [02:35:56.787] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.183121e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.9578422 
  - variance bounds :  0.00118312 0.1226801 
  - best initial criterion value(s) :  166.7221 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -166.72  |proj g|=       3.4277
At iterate     1  f =      -175.35  |proj g|=        1.7579
At iterate     2  f =       -193.3  |proj g|=        1.8224
At iterate     3  f =      -195.21  |proj g|=        1.6465
At iterate     4  f =      -198.28  |proj g|=        2.3293
At iterate     5  f =       -199.4  |proj g|=        4.5094
At iterate     6  f =      -199.43  |proj g|=        4.4987
At iterate     7  f =      -199.43  |proj g|=        4.2482
At iterate     8  f =      -199.46  |proj g|=        3.6772
At iterate     9  f =       -199.6  |proj g|=         2.745
At iterate    10  f =      -199.78  |proj g|=        1.1275
At iterate    11  f =      -200.67  |proj g|=        1.2353
At iterate    12  f =      -203.12  |proj g|=        1.4457
At iterate    13  f =      -203.37  |proj g|=        1.4432
At iterate    14  f =      -203.59  |proj g|=        1.3722
At iterate    15  f =      -203.81  |proj g|=       0.24557
At iterate    16  f =      -203.81  |proj g|=      0.077763
At iterate    17  f =      -203.81  |proj g|=       0.12067
At iterate    18  f =      -203.81  |proj g|=      0.067666
At iterate    19  f =      -203.81  |proj g|=     0.0043645

iterations 19
function evaluations 32
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00436447
final function value -203.814

F = -203.814
final  value -203.813559 
converged
 
INFO  [02:35:56.791] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:35:56.845] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:35:56.852] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:36:04.377] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:36:11.584] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:36:18.927] [mlr3]  Finished benchmark 
INFO  [02:36:18.994] [bbotk] Result of batch 37: 
INFO  [02:36:18.996] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:36:18.996] [bbotk]                   6               532      0.4989022        0.614 -0.9039949 
INFO  [02:36:18.996] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:36:18.996] [bbotk]          <NA>   0.9768947 21c2a3c2-43e9-447a-8e04-10b8f6aaaf7f 
DEBUG [02:36:19.682] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.18071e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.959281 
  - variance bounds :  0.00118071 0.1232284 
  - best initial criterion value(s) :  170.4198 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -170.42  |proj g|=       3.1319
At iterate     1  f =      -177.29  |proj g|=        3.2338
At iterate     2  f =      -178.99  |proj g|=        2.7831
At iterate     3  f =      -180.93  |proj g|=        2.2706
At iterate     4  f =      -184.27  |proj g|=        0.3984
At iterate     5  f =       -185.3  |proj g|=        1.4187
At iterate     6  f =      -186.25  |proj g|=        2.6558
At iterate     7  f =      -199.66  |proj g|=        1.6269
At iterate     8  f =      -201.81  |proj g|=        1.3955
At iterate     9  f =      -203.84  |proj g|=       0.65263
At iterate    10  f =      -204.51  |proj g|=       0.13789
At iterate    11  f =      -204.54  |proj g|=      0.042045
At iterate    12  f =      -204.54  |proj g|=       0.12123
At iterate    13  f =      -204.54  |proj g|=      0.005006
At iterate    14  f =      -204.54  |proj g|=     0.0094573

iterations 14
function evaluations 22
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00945735
final function value -204.541

F = -204.541
final  value -204.541343 
converged
 
INFO  [02:36:19.686] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:36:19.734] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:36:19.740] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:36:34.073] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:36:48.662] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:37:03.023] [mlr3]  Finished benchmark 
INFO  [02:37:03.089] [bbotk] Result of batch 38: 
INFO  [02:37:03.091] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:37:03.091] [bbotk]                   4              1148      0.3159375        0.483 -0.9047654 
INFO  [02:37:03.091] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:37:03.091] [bbotk]          <NA>   0.9759998 88133de1-05b2-495c-88a2-554c8f68b49f 
DEBUG [02:37:03.772] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.177516e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.959281 
  - variance bounds :  0.001177516 0.1228803 
  - best initial criterion value(s) :  174.5475 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -174.55  |proj g|=       3.9453
At iterate     1  f =      -176.58  |proj g|=        3.7381
At iterate     2  f =      -177.42  |proj g|=        3.7337
At iterate     3  f =      -179.63  |proj g|=        3.6488
At iterate     4  f =      -181.17  |proj g|=        3.4264
At iterate     5  f =      -191.79  |proj g|=        2.6982
At iterate     6  f =       -202.1  |proj g|=        1.9446
At iterate     7  f =      -204.57  |proj g|=         1.682
At iterate     8  f =      -207.37  |proj g|=        1.2223
At iterate     9  f =      -207.82  |proj g|=        1.3845
At iterate    10  f =      -207.86  |proj g|=        2.7875
At iterate    11  f =      -207.86  |proj g|=        2.3363
At iterate    12  f =      -207.88  |proj g|=         2.048
At iterate    13  f =      -207.97  |proj g|=       0.87834
At iterate    14  f =      -208.18  |proj g|=       0.68339
At iterate    15  f =      -208.79  |proj g|=        1.3575
At iterate    16  f =      -209.33  |proj g|=        1.3817
At iterate    17  f =      -209.63  |proj g|=         1.328
At iterate    18  f =      -209.84  |proj g|=       0.12883
At iterate    19  f =      -209.84  |proj g|=       0.12091
At iterate    20  f =      -209.84  |proj g|=       0.12091
At iterate    21  f =      -209.84  |proj g|=     0.0051133

iterations 21
function evaluations 32
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00511329
final function value -209.845

F = -209.845
final  value -209.844665 
converged
 
INFO  [02:37:03.777] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:37:03.840] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:37:03.848] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:37:37.469] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:37:38.364] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:38:11.906] [mlr3]  Finished benchmark 
INFO  [02:38:11.971] [bbotk] Result of batch 39: 
INFO  [02:38:11.972] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:38:11.972] [bbotk]                   7              2786      0.1302447        0.472 -0.9043765 
INFO  [02:38:11.972] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:38:11.972] [bbotk]          <NA>   0.8188715 57573313-3d23-4efc-9b4b-7ee7a6c8db7f 
DEBUG [02:38:12.658] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.163731e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9342 0.959281 
  - variance bounds :  0.001163731 0.1214543 
  - best initial criterion value(s) :  159.0222 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -159.02  |proj g|=         2.41
At iterate     1  f =      -170.76  |proj g|=        2.1745
At iterate     2  f =      -176.64  |proj g|=        1.8039
At iterate     3  f =      -185.09  |proj g|=         1.356
At iterate     4  f =      -185.33  |proj g|=     0.0088873
At iterate     5  f =       -186.1  |proj g|=     0.0091138
At iterate     6  f =      -186.11  |proj g|=        0.1193
At iterate     7  f =      -186.12  |proj g|=     0.0091578
At iterate     8  f =      -186.12  |proj g|=     0.0091599
At iterate     9  f =      -186.12  |proj g|=       0.00916

iterations 9
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00915999
final function value -186.12

F = -186.12
final  value -186.120012 
converged
 
INFO  [02:38:12.662] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:38:12.718] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:38:12.725] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:38:16.460] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:38:20.183] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:38:24.075] [mlr3]  Finished benchmark 
INFO  [02:38:24.150] [bbotk] Result of batch 40: 
INFO  [02:38:24.152] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:38:24.152] [bbotk]                   3               223      0.3732632        0.479 -0.9226097 
INFO  [02:38:24.152] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:38:24.152] [bbotk]          <NA>   0.9714227 f379a6de-a809-4302-8906-6aeffdad9973 
DEBUG [02:38:24.831] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.159287e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.959281 
  - variance bounds :  0.001159287 0.121875 
  - best initial criterion value(s) :  179.3508 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -179.35  |proj g|=       2.9316
At iterate     1  f =      -213.62  |proj g|=        11.542
At iterate     2  f =      -214.98  |proj g|=        5.2155
At iterate     3  f =      -215.01  |proj g|=         4.782
At iterate     4  f =      -215.04  |proj g|=        3.4192
At iterate     5  f =      -215.04  |proj g|=        3.6588
At iterate     6  f =      -215.04  |proj g|=         3.704
At iterate     7  f =      -215.05  |proj g|=        3.9771
At iterate     8  f =      -215.06  |proj g|=        4.3001
At iterate     9  f =      -215.09  |proj g|=        4.8505
At iterate    10  f =      -215.16  |proj g|=        5.7159
At iterate    11  f =      -215.35  |proj g|=        7.0744
At iterate    12  f =      -215.69  |proj g|=        8.1694
At iterate    13  f =      -215.75  |proj g|=        7.5508
At iterate    14  f =       -216.2  |proj g|=        6.2318
At iterate    15  f =      -216.94  |proj g|=         1.066
At iterate    16  f =      -217.01  |proj g|=       0.27773
At iterate    17  f =      -217.01  |proj g|=      0.022543
At iterate    18  f =      -217.01  |proj g|=     0.0059398
At iterate    19  f =      -217.01  |proj g|=     0.0059398

iterations 19
function evaluations 28
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0059398
final function value -217.008

F = -217.008
final  value -217.007774 
converged
 
INFO  [02:38:24.835] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:38:24.889] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:38:24.896] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:38:25.796] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:38:38.993] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:38:51.694] [mlr3]  Finished benchmark 
INFO  [02:38:51.758] [bbotk] Result of batch 41: 
INFO  [02:38:51.759] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [02:38:51.759] [bbotk]                   7              1000      0.4438465        0.477 -0.904168 
INFO  [02:38:51.759] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:38:51.759] [bbotk]          <NA>   0.8190455 d12c7f23-7ef4-480a-81f6-e23e9cffd094 
DEBUG [02:38:52.466] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.146303e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.959281 
  - variance bounds :  0.001146303 0.1202277 
  - best initial criterion value(s) :  191.0354 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -191.04  |proj g|=       8.2515
At iterate     1  f =      -207.47  |proj g|=        3.9933
At iterate     2  f =      -212.53  |proj g|=        2.3114
At iterate     3  f =      -215.79  |proj g|=        2.0636
At iterate     4  f =      -217.11  |proj g|=        1.8828
At iterate     5  f =      -218.88  |proj g|=        1.5289
At iterate     6  f =      -219.52  |proj g|=        2.5875
At iterate     7  f =      -219.92  |proj g|=        1.2807
At iterate     8  f =      -219.93  |proj g|=        1.2643
At iterate     9  f =      -219.94  |proj g|=        1.2709
At iterate    10  f =      -219.95  |proj g|=        1.2646
At iterate    11  f =      -220.07  |proj g|=        1.2216
At iterate    12  f =       -220.3  |proj g|=        1.0223
At iterate    13  f =      -221.08  |proj g|=       0.75497
At iterate    14  f =      -222.98  |proj g|=        4.7148
At iterate    15  f =      -228.49  |proj g|=        5.7251
At iterate    16  f =      -230.66  |proj g|=        3.2944
At iterate    17  f =      -231.13  |proj g|=        1.4306
At iterate    18  f =      -231.28  |proj g|=       0.23535
At iterate    19  f =       -231.3  |proj g|=        0.1184
At iterate    20  f =       -231.3  |proj g|=       0.11838
At iterate    21  f =       -231.3  |proj g|=       0.11838
At iterate    22  f =       -231.3  |proj g|=       0.02792

iterations 22
function evaluations 31
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0279198
final function value -231.3

F = -231.3
final  value -231.300076 
converged
 
INFO  [02:38:52.470] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:38:52.525] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:38:52.531] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:39:23.359] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:39:54.103] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:40:24.778] [mlr3]  Finished benchmark 
INFO  [02:40:24.844] [bbotk] Result of batch 42: 
INFO  [02:40:24.846] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:40:24.846] [bbotk]                   5              2580      0.1766512        0.491 -0.9028938 
INFO  [02:40:24.846] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:40:24.846] [bbotk]          <NA>   0.9771832 7a4ae1e0-4122-47d2-95b6-e9b42ff09ff7 
DEBUG [02:40:25.591] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.14383e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.959281 
  - variance bounds :  0.00114383 0.1196877 
  - best initial criterion value(s) :  180.3239 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -180.32  |proj g|=       9.2203
At iterate     1  f =      -192.92  |proj g|=       0.61145
At iterate     2  f =      -199.82  |proj g|=        2.6661
At iterate     3  f =      -200.36  |proj g|=        2.5552
At iterate     4  f =      -203.88  |proj g|=        2.0366
At iterate     5  f =      -206.67  |proj g|=        1.4561
At iterate     6  f =      -206.69  |proj g|=        1.3851
At iterate     7  f =      -222.36  |proj g|=        1.3174
At iterate     8  f =      -232.99  |proj g|=        3.3174
At iterate     9  f =      -234.11  |proj g|=        1.9862
At iterate    10  f =      -234.46  |proj g|=       0.87202
At iterate    11  f =      -234.47  |proj g|=       0.19112
At iterate    12  f =      -234.47  |proj g|=      0.004936
At iterate    13  f =      -234.47  |proj g|=     0.0049361

iterations 13
function evaluations 24
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00493605
final function value -234.47

F = -234.47
final  value -234.469737 
converged
 
INFO  [02:40:25.595] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:40:25.649] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:40:25.656] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:40:59.269] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:41:00.159] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:41:00.927] [mlr3]  Finished benchmark 
INFO  [02:41:00.990] [bbotk] Result of batch 43: 
INFO  [02:41:00.992] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:41:00.992] [bbotk]                  10              2814      0.3263962        0.516 -0.9029948 
INFO  [02:41:00.992] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:41:00.992] [bbotk]          <NA>     0.65904 4e7b9f29-0451-485f-8904-fd193cf414b6 
DEBUG [02:41:01.716] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.199241e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.959281 
  - variance bounds :  0.001199241 0.1247373 
  - best initial criterion value(s) :  202.426 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -202.43  |proj g|=       6.6277
At iterate     1  f =      -207.63  |proj g|=        1.8614
At iterate     2  f =       -218.7  |proj g|=        2.4756
At iterate     3  f =      -220.97  |proj g|=        2.2594
At iterate     4  f =      -225.52  |proj g|=         1.723
At iterate     5  f =      -228.67  |proj g|=        1.3564
At iterate     6  f =      -228.87  |proj g|=        1.2477
At iterate     7  f =      -228.89  |proj g|=         1.078
At iterate     8  f =      -228.93  |proj g|=       0.19482
At iterate     9  f =      -228.93  |proj g|=       0.24742
At iterate    10  f =      -228.93  |proj g|=       0.33761
At iterate    11  f =      -228.93  |proj g|=       0.47787
At iterate    12  f =      -228.94  |proj g|=       0.70559
At iterate    13  f =      -228.96  |proj g|=        1.0641
At iterate    14  f =         -229  |proj g|=        1.2233
At iterate    15  f =      -229.11  |proj g|=        1.2483
At iterate    16  f =      -229.42  |proj g|=        1.3034
At iterate    17  f =      -230.04  |proj g|=         1.388
At iterate    18  f =      -230.31  |proj g|=        1.4026
At iterate    19  f =      -230.38  |proj g|=        1.4005
At iterate    20  f =      -230.44  |proj g|=        1.3882
At iterate    21  f =      -230.52  |proj g|=        1.3617
At iterate    22  f =      -230.64  |proj g|=        1.3047
At iterate    23  f =      -230.78  |proj g|=       0.12053
At iterate    24  f =      -230.84  |proj g|=       0.68609
At iterate    25  f =      -230.85  |proj g|=        0.1229
At iterate    26  f =      -230.85  |proj g|=      0.006412
At iterate    27  f =      -230.85  |proj g|=        0.1229
At iterate    28  f =      -230.85  |proj g|=     0.0064122

iterations 28
function evaluations 39
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00641215
final function value -230.852

F = -230.852
final  value -230.852074 
converged
 
INFO  [02:41:01.720] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:41:01.774] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:41:01.781] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:41:02.708] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:41:31.121] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:41:59.237] [mlr3]  Finished benchmark 
INFO  [02:41:59.302] [bbotk] Result of batch 44: 
INFO  [02:41:59.304] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:41:59.304] [bbotk]                   8              2320      0.3282894        0.491 -0.9032736 
INFO  [02:41:59.304] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:41:59.304] [bbotk]          <NA>   0.8185389 66dfa1e2-c2cf-4ae7-a0ec-1acff49b14a6 
DEBUG [02:42:00.021] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.185867e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.959281 
  - variance bounds :  0.001185867 0.1237012 
  - best initial criterion value(s) :  211.808 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -211.81  |proj g|=       2.7645
At iterate     1  f =      -230.29  |proj g|=        6.3032
At iterate     2  f =      -242.68  |proj g|=        11.607
At iterate     3  f =      -243.91  |proj g|=        5.2726
At iterate     4  f =      -243.91  |proj g|=         4.978
At iterate     5  f =      -243.93  |proj g|=         4.202
At iterate     6  f =      -243.93  |proj g|=        4.0568
At iterate     7  f =      -244.03  |proj g|=        2.7951
At iterate     8  f =      -244.22  |proj g|=        1.2045
At iterate     9  f =      -244.77  |proj g|=        1.1973
At iterate    10  f =      -246.09  |proj g|=        1.3322
At iterate    11  f =      -246.63  |proj g|=         1.348
At iterate    12  f =       -246.8  |proj g|=        1.2894
At iterate    13  f =      -246.93  |proj g|=       0.19427
At iterate    14  f =      -246.93  |proj g|=       0.12193
At iterate    15  f =      -246.93  |proj g|=       0.12193
At iterate    16  f =      -246.93  |proj g|=       0.12193

iterations 16
function evaluations 27
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.121933
final function value -246.935

F = -246.935
final  value -246.934734 
converged
 
INFO  [02:42:00.025] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:42:00.080] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:42:00.088] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:42:00.983] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:42:25.945] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:42:51.308] [mlr3]  Finished benchmark 
INFO  [02:42:51.371] [bbotk] Result of batch 45: 
INFO  [02:42:51.373] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [02:42:51.373] [bbotk]                   9              2086      0.0367426          0.5 -0.901978 
INFO  [02:42:51.373] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:42:51.373] [bbotk]          <NA>   0.8180593 d08c8520-1aad-4b52-9355-ee8977452d1a 
DEBUG [02:42:52.057] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.172832e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.959281 
  - variance bounds :  0.001172832 0.1239255 
  - best initial criterion value(s) :  205.8914 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -205.89  |proj g|=      0.34744
At iterate     1  f =      -243.89  |proj g|=       0.12207
At iterate     2  f =      -245.39  |proj g|=     0.0046408
At iterate     3  f =      -245.39  |proj g|=     0.0046413
At iterate     4  f =      -245.39  |proj g|=     0.0046413

iterations 4
function evaluations 9
segments explored during Cauchy searches 6
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00464133
final function value -245.389

F = -245.389
final  value -245.388810 
converged
 
INFO  [02:42:52.061] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:42:52.115] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:42:52.122] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:42:57.282] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:42:58.159] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:43:03.280] [mlr3]  Finished benchmark 
INFO  [02:43:03.344] [bbotk] Result of batch 46: 
INFO  [02:43:03.346] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:43:03.346] [bbotk]                   7               368    0.003066571        0.492 -0.9171331 
INFO  [02:43:03.346] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:43:03.346] [bbotk]          <NA>   0.7912801 6615bebc-a423-4e82-8833-9e46a4c222cc 
DEBUG [02:43:04.081] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.165395e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.9916713 
  - variance bounds :  0.001165395 0.1214959 
  - best initial criterion value(s) :  192.6702 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -192.67  |proj g|=       6.1115
At iterate     1  f =      -197.98  |proj g|=        2.1512
At iterate     2  f =      -209.06  |proj g|=        2.7012
At iterate     3  f =       -216.1  |proj g|=        1.9381
At iterate     4  f =      -219.68  |proj g|=        1.0075
At iterate     5  f =      -221.05  |proj g|=       0.88847
At iterate     6  f =       -221.2  |proj g|=       0.63832
At iterate     7  f =      -221.21  |proj g|=       0.14847
At iterate     8  f =      -221.21  |proj g|=        0.1193
At iterate     9  f =      -221.21  |proj g|=       0.02363
At iterate    10  f =      -221.21  |proj g|=       0.11668
At iterate    11  f =      -221.22  |proj g|=       0.32871
At iterate    12  f =      -221.24  |proj g|=       0.64353
At iterate    13  f =      -221.27  |proj g|=        1.1434
At iterate    14  f =      -221.38  |proj g|=        1.9789
At iterate    15  f =       -221.6  |proj g|=        3.0234
At iterate    16  f =      -221.71  |proj g|=        2.6544
At iterate    17  f =      -221.82  |proj g|=        1.3996
At iterate    18  f =      -221.83  |proj g|=        1.6752
At iterate    19  f =      -221.87  |proj g|=        1.1732
At iterate    20  f =       -221.9  |proj g|=       0.11931
At iterate    21  f =       -221.9  |proj g|=        0.1193
At iterate    22  f =       -221.9  |proj g|=        0.0629
At iterate    23  f =       -221.9  |proj g|=       0.01006

iterations 23
function evaluations 35
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0100602
final function value -221.899

F = -221.899
final  value -221.898910 
converged
 
INFO  [02:43:04.085] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:43:04.140] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:43:04.158] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:43:40.774] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:44:16.744] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:44:17.635] [mlr3]  Finished benchmark 
INFO  [02:44:17.699] [bbotk] Result of batch 47: 
INFO  [02:44:17.701] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [02:44:17.701] [bbotk]                   7              3003      0.4402993        0.507 -0.902306 
INFO  [02:44:17.701] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:44:17.701] [bbotk]          <NA>   0.8190674 fcdf005a-aac4-4e5b-b1f8-edcc65e68c90 
DEBUG [02:44:18.484] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.152562e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.9916713 
  - variance bounds :  0.001152562 0.120525 
  - best initial criterion value(s) :  195.5705 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -195.57  |proj g|=       3.7835
At iterate     1  f =      -196.74  |proj g|=        3.6372
At iterate     2  f =      -197.73  |proj g|=        3.6243
At iterate     3  f =      -200.33  |proj g|=         3.519
At iterate     4  f =      -202.41  |proj g|=        3.2598
At iterate     5  f =      -212.08  |proj g|=        2.7383
At iterate     6  f =      -221.08  |proj g|=        2.1833
At iterate     7  f =      -226.12  |proj g|=        1.8036
At iterate     8  f =      -230.72  |proj g|=       0.50121
At iterate     9  f =      -230.84  |proj g|=       0.87794
At iterate    10  f =      -231.13  |proj g|=        3.7437
At iterate    11  f =      -231.14  |proj g|=        3.0581
At iterate    12  f =      -231.14  |proj g|=        3.0333
At iterate    13  f =      -231.15  |proj g|=        2.9947
At iterate    14  f =      -231.16  |proj g|=        2.9503
At iterate    15  f =      -231.19  |proj g|=        2.8337
At iterate    16  f =      -231.28  |proj g|=        2.6262
At iterate    17  f =      -231.53  |proj g|=        2.2292
At iterate    18  f =      -232.21  |proj g|=        1.5045
At iterate    19  f =      -232.99  |proj g|=        1.8082
At iterate    20  f =      -233.54  |proj g|=        2.8846
At iterate    21  f =      -233.62  |proj g|=        3.2259
At iterate    22  f =      -233.64  |proj g|=        3.3409
At iterate    23  f =      -233.65  |proj g|=        3.3723
At iterate    24  f =      -233.66  |proj g|=        3.3551
At iterate    25  f =      -233.68  |proj g|=        3.1859
At iterate    26  f =      -233.74  |proj g|=        2.5936
At iterate    27  f =      -233.85  |proj g|=        1.0524
At iterate    28  f =      -233.89  |proj g|=      0.035969
At iterate    29  f =      -233.89  |proj g|=       0.01539
At iterate    30  f =      -233.89  |proj g|=     0.0083858
At iterate    31  f =      -233.89  |proj g|=     0.0091471

iterations 31
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00914714
final function value -233.888

F = -233.888
final  value -233.887574 
converged
 
INFO  [02:44:18.488] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:44:18.553] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:44:18.559] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:44:55.133] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:45:32.010] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:46:08.630] [mlr3]  Finished benchmark 
INFO  [02:46:08.694] [bbotk] Result of batch 48: 
INFO  [02:46:08.696] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:46:08.696] [bbotk]                   3              3053     0.03055185        0.532 -0.9001597 
INFO  [02:46:08.696] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:46:08.696] [bbotk]          <NA>   0.9716059 b8874e61-27b4-4e5b-9b9c-c0155777dad8 
DEBUG [02:46:09.428] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.150184e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.9916713 
  - variance bounds :  0.001150184 0.1207607 
  - best initial criterion value(s) :  224.7248 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -224.72  |proj g|=       1.1855
At iterate     1  f =      -232.81  |proj g|=        2.9424
At iterate     2  f =      -233.11  |proj g|=        2.9793
At iterate     3  f =      -233.11  |proj g|=        2.9799
At iterate     4  f =      -233.12  |proj g|=        2.9765
At iterate     5  f =      -233.16  |proj g|=        2.9553
At iterate     6  f =      -233.24  |proj g|=        2.9025
At iterate     7  f =       -233.4  |proj g|=        2.7737
At iterate     8  f =      -233.67  |proj g|=        2.5753
At iterate     9  f =       -234.1  |proj g|=        2.3298
At iterate    10  f =      -234.15  |proj g|=         2.296
At iterate    11  f =      -234.21  |proj g|=        2.2666
At iterate    12  f =      -234.42  |proj g|=        2.1948
At iterate    13  f =      -234.88  |proj g|=        2.0894
At iterate    14  f =      -236.06  |proj g|=        1.8802
At iterate    15  f =      -238.61  |proj g|=        1.4342
At iterate    16  f =      -241.65  |proj g|=        10.534
At iterate    17  f =      -245.79  |proj g|=        6.8354
At iterate    18  f =      -252.45  |proj g|=        4.3129
At iterate    19  f =      -253.58  |proj g|=        1.2633
At iterate    20  f =      -253.86  |proj g|=        1.3716
At iterate    21  f =      -253.94  |proj g|=        0.2144
At iterate    22  f =      -253.95  |proj g|=         0.044
At iterate    23  f =      -253.95  |proj g|=        0.1185
At iterate    24  f =      -253.95  |proj g|=     0.0051742
At iterate    25  f =      -253.95  |proj g|=     0.0051742

iterations 25
function evaluations 29
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00517423
final function value -253.953

F = -253.953
final  value -253.953179 
converged
 
INFO  [02:46:09.432] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:46:09.486] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:46:09.493] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:46:33.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:46:33.967] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:46:34.741] [mlr3]  Finished benchmark 
INFO  [02:46:34.807] [bbotk] Result of batch 49: 
INFO  [02:46:34.808] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:46:34.808] [bbotk]                  10              1937      0.1029282        0.509 -0.8966886 
INFO  [02:46:34.808] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:46:34.808] [bbotk]          <NA>   0.6592307 41401e0d-b0a0-406a-b946-c6b2afa78269 
DEBUG [02:46:35.573] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.197456e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.9916713 
  - variance bounds :  0.001197456 0.1243586 
  - best initial criterion value(s) :  207.6156 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -207.62  |proj g|=       5.8017
At iterate     1  f =      -218.35  |proj g|=        4.3384
At iterate     2  f =      -221.68  |proj g|=        3.4847
At iterate     3  f =      -227.04  |proj g|=        2.7971
At iterate     4  f =      -227.52  |proj g|=        2.6337
At iterate     5  f =      -228.84  |proj g|=        2.3805
At iterate     6  f =       -230.1  |proj g|=         2.064
At iterate     7  f =      -230.71  |proj g|=        1.6432
At iterate     8  f =      -230.79  |proj g|=        1.6268
At iterate     9  f =      -230.83  |proj g|=        1.7926
At iterate    10  f =      -230.94  |proj g|=        1.7295
At iterate    11  f =      -231.28  |proj g|=        1.5982
At iterate    12  f =      -243.98  |proj g|=        1.4714
At iterate    13  f =      -262.26  |proj g|=        1.8186
At iterate    14  f =      -263.54  |proj g|=       0.68667
At iterate    15  f =      -263.91  |proj g|=        1.3783
At iterate    16  f =      -264.23  |proj g|=        2.2964
At iterate    17  f =      -264.34  |proj g|=       0.98081
At iterate    18  f =      -264.36  |proj g|=        0.1523
At iterate    19  f =      -264.36  |proj g|=       0.12206
At iterate    20  f =      -264.36  |proj g|=     0.0053186
At iterate    21  f =      -264.36  |proj g|=     0.0043849
At iterate    22  f =      -264.36  |proj g|=     0.0043849

iterations 22
function evaluations 31
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00438489
final function value -264.362

F = -264.362
final  value -264.362021 
converged
 
INFO  [02:46:35.577] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:46:35.642] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:46:35.649] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:46:36.415] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:46:42.780] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:46:43.682] [mlr3]  Finished benchmark 
INFO  [02:46:43.745] [bbotk] Result of batch 50: 
INFO  [02:46:43.747] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:46:43.747] [bbotk]                  10               427      0.4910057        0.533 -0.8953742 
INFO  [02:46:43.747] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:46:43.747] [bbotk]          <NA>   0.6591585 ba59845a-ba7d-4835-b252-2564d248e936 
DEBUG [02:46:44.495] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.241743e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.9916713 
  - variance bounds :  0.001241743 0.1296645 
  - best initial criterion value(s) :  241.6704 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -241.67  |proj g|=       1.5332
At iterate     1  f =      -247.01  |proj g|=        3.4484
At iterate     2  f =      -249.35  |proj g|=        3.1824
At iterate     3  f =      -251.13  |proj g|=        2.8877
At iterate     4  f =      -253.43  |proj g|=        2.4981
At iterate     5  f =      -257.66  |proj g|=        1.8191
At iterate     6  f =      -259.05  |proj g|=        1.6037
At iterate     7  f =      -259.16  |proj g|=        1.5087
At iterate     8  f =      -259.16  |proj g|=        1.4971
At iterate     9  f =      -259.17  |proj g|=        1.4987
At iterate    10  f =      -259.18  |proj g|=        1.5041
At iterate    11  f =       -259.2  |proj g|=        1.5116
At iterate    12  f =      -259.26  |proj g|=        1.5267
At iterate    13  f =      -259.41  |proj g|=        1.5569
At iterate    14  f =       -259.8  |proj g|=        1.6248
At iterate    15  f =      -260.64  |proj g|=        1.7653
At iterate    16  f =       -261.8  |proj g|=        1.9666
At iterate    17  f =       -262.8  |proj g|=        2.1289
At iterate    18  f =      -263.99  |proj g|=        2.2595
At iterate    19  f =       -264.2  |proj g|=        2.2393
At iterate    20  f =      -265.51  |proj g|=        2.0485
At iterate    21  f =      -266.73  |proj g|=        1.8097
At iterate    22  f =      -268.84  |proj g|=        3.2515
At iterate    23  f =      -269.56  |proj g|=        4.1197
At iterate    24  f =      -269.91  |proj g|=       0.76669
At iterate    25  f =      -269.93  |proj g|=       0.40328
At iterate    26  f =      -269.95  |proj g|=      0.016089
At iterate    27  f =      -269.95  |proj g|=       0.12735
At iterate    28  f =      -269.95  |proj g|=       0.00432
At iterate    29  f =      -269.95  |proj g|=       0.00432

iterations 29
function evaluations 37
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00431998
final function value -269.946

F = -269.946
final  value -269.946416 
converged
 
INFO  [02:46:44.499] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:46:44.552] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:46:44.558] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:46:45.461] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:47:13.092] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:47:40.948] [mlr3]  Finished benchmark 
INFO  [02:47:41.012] [bbotk] Result of batch 51: 
INFO  [02:47:41.014] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:47:41.014] [bbotk]                   7              2308      0.1038435        0.511 -0.8934957 
INFO  [02:47:41.014] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:47:41.014] [bbotk]          <NA>   0.8186476 e7356451-8278-47a5-9403-d1b09395ed01 
DEBUG [02:47:41.826] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.227912e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.9916713 
  - variance bounds :  0.001227912 0.1286864 
  - best initial criterion value(s) :  199.1873 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -199.19  |proj g|=       2.9438
At iterate     1  f =       -208.7  |proj g|=        2.2451
At iterate     2  f =      -217.84  |proj g|=        1.7104
At iterate     3  f =      -218.92  |proj g|=        1.6194
At iterate     4  f =      -222.04  |proj g|=        1.1673
At iterate     5  f =      -222.24  |proj g|=        5.1516
At iterate     6  f =      -222.43  |proj g|=         4.041
At iterate     7  f =      -222.43  |proj g|=        3.1077
At iterate     8  f =      -222.44  |proj g|=        3.4063
At iterate     9  f =      -222.53  |proj g|=        4.1057
At iterate    10  f =      -222.85  |proj g|=        6.2586
At iterate    11  f =      -223.46  |proj g|=        8.4857
At iterate    12  f =      -223.63  |proj g|=        9.4136
At iterate    13  f =      -224.17  |proj g|=        9.9351
At iterate    14  f =      -224.87  |proj g|=        6.9049
At iterate    15  f =      -225.67  |proj g|=        1.5358
At iterate    16  f =      -225.89  |proj g|=       0.37576
At iterate    17  f =      -225.92  |proj g|=       0.12652
At iterate    18  f =      -225.93  |proj g|=        0.1265
At iterate    19  f =      -225.93  |proj g|=        0.1265
At iterate    20  f =      -225.93  |proj g|=      0.016743

iterations 20
function evaluations 27
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.016743
final function value -225.925

F = -225.925
final  value -225.925277 
converged
 
INFO  [02:47:41.831] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:47:41.885] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:47:41.891] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:47:58.580] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:48:15.408] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:48:31.887] [mlr3]  Finished benchmark 
INFO  [02:48:31.952] [bbotk] Result of batch 52: 
INFO  [02:48:31.954] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:48:31.954] [bbotk]                   3              1338      0.3320002        0.581 -0.9018846 
INFO  [02:48:31.954] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:48:31.954] [bbotk]          <NA>    0.973801 0b9ba246-59db-41fc-9209-8c5d6af3a5ce 
DEBUG [02:48:32.744] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.226672e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.9916713 
  - variance bounds :  0.001226672 0.1285322 
  - best initial criterion value(s) :  247.8708 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -247.87  |proj g|=       9.1925
At iterate     1  f =      -255.92  |proj g|=        2.0506
At iterate     2  f =      -265.35  |proj g|=        2.2554
At iterate     3  f =      -269.46  |proj g|=        1.6955
At iterate     4  f =      -271.09  |proj g|=       0.24412
At iterate     5  f =      -271.61  |proj g|=        0.5836
At iterate     6  f =      -271.68  |proj g|=        1.3397
At iterate     7  f =       -271.7  |proj g|=        1.3249
At iterate     8  f =      -271.76  |proj g|=       0.44903
At iterate     9  f =      -271.89  |proj g|=       0.32482
At iterate    10  f =      -272.41  |proj g|=        2.8091
At iterate    11  f =      -272.47  |proj g|=        2.0531
At iterate    12  f =      -273.62  |proj g|=        4.9086
At iterate    13  f =      -280.47  |proj g|=        5.2866
At iterate    14  f =      -281.08  |proj g|=        1.9636
At iterate    15  f =       -281.2  |proj g|=       0.12624
At iterate    16  f =      -281.21  |proj g|=       0.12621
At iterate    17  f =      -281.21  |proj g|=      0.024344
At iterate    18  f =      -281.21  |proj g|=     0.0041629
At iterate    19  f =      -281.21  |proj g|=     0.0099248

iterations 19
function evaluations 27
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00992479
final function value -281.205

F = -281.205
final  value -281.205254 
converged
 
INFO  [02:48:32.748] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:48:32.805] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:48:32.812] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:49:01.159] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:49:02.039] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:49:30.599] [mlr3]  Finished benchmark 
INFO  [02:49:30.675] [bbotk] Result of batch 53: 
INFO  [02:49:30.677] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:49:30.677] [bbotk]                   9              2348     0.02455402        0.569 -0.8928902 
INFO  [02:49:30.677] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:49:30.677] [bbotk]          <NA>   0.8175723 57f26153-52e4-4f4e-b963-5255b5a4f816 
DEBUG [02:49:31.463] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.213652e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.9916713 
  - variance bounds :  0.001213652 0.1275793 
  - best initial criterion value(s) :  236.6135 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -236.61  |proj g|=       9.9423
At iterate     1  f =      -251.67  |proj g|=        7.2574
At iterate     2  f =      -257.76  |proj g|=        2.5897
At iterate     3  f =      -259.64  |proj g|=        2.5009
At iterate     4  f =      -262.76  |proj g|=        2.1739
At iterate     5  f =      -265.58  |proj g|=        1.8896
At iterate     6  f =      -269.42  |proj g|=        1.3466
At iterate     7  f =      -269.54  |proj g|=        1.2598
At iterate     8  f =      -269.56  |proj g|=       0.67561
At iterate     9  f =      -269.58  |proj g|=      0.038441
At iterate    10  f =      -269.58  |proj g|=        0.1255
At iterate    11  f =      -269.58  |proj g|=       0.14805
At iterate    12  f =      -269.58  |proj g|=       0.25627
At iterate    13  f =      -269.58  |proj g|=       0.42863
At iterate    14  f =       -269.6  |proj g|=       0.66513
At iterate    15  f =      -269.64  |proj g|=       0.99674
At iterate    16  f =      -269.73  |proj g|=        1.2193
At iterate    17  f =      -269.97  |proj g|=        1.2044
At iterate    18  f =      -270.09  |proj g|=        1.0227
At iterate    19  f =      -270.22  |proj g|=       0.15864
At iterate    20  f =      -270.22  |proj g|=       0.37275
At iterate    21  f =      -270.22  |proj g|=       0.40832
At iterate    22  f =      -270.22  |proj g|=       0.41328
At iterate    23  f =      -270.22  |proj g|=       0.42577
At iterate    24  f =      -270.22  |proj g|=       0.43133
At iterate    25  f =      -270.22  |proj g|=        0.4085
At iterate    26  f =      -270.22  |proj g|=       0.31914
At iterate    27  f =      -270.22  |proj g|=       0.15481
At iterate    28  f =      -270.23  |proj g|=     0.0078593
At iterate    29  f =      -270.23  |proj g|=     0.0078592

iterations 29
function evaluations 38
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00785918
final function value -270.225

F = -270.225
final  value -270.225200 
converged
 
INFO  [02:49:31.467] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:49:31.535] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:49:31.542] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:49:58.922] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:50:26.174] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:50:53.784] [mlr3]  Finished benchmark 
INFO  [02:50:53.849] [bbotk] Result of batch 54: 
INFO  [02:50:53.850] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:50:53.850] [bbotk]                   6              2239      0.2043614        0.534 -0.8955111 
INFO  [02:50:53.850] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:50:53.850] [bbotk]          <NA>   0.9773415 c3cbb972-0d81-4f5d-bb25-161f5860e149 
DEBUG [02:50:54.647] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.21342e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.9916713 
  - variance bounds :  0.00121342 0.1274942 
  - best initial criterion value(s) :  246.3649 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -246.36  |proj g|=       3.6062
At iterate     1  f =      -246.68  |proj g|=        3.5466
At iterate     2  f =      -247.08  |proj g|=        3.5436
At iterate     3  f =      -248.01  |proj g|=        3.4744
At iterate     4  f =      -263.32  |proj g|=        2.2919
At iterate     5  f =      -271.77  |proj g|=        1.4375
At iterate     6  f =      -272.27  |proj g|=        1.3854
At iterate     7  f =      -272.71  |proj g|=       0.30866
At iterate     8  f =      -272.84  |proj g|=        1.0759
At iterate     9  f =      -273.19  |proj g|=        2.0749
At iterate    10  f =      -273.24  |proj g|=         1.178
At iterate    11  f =      -273.27  |proj g|=      0.091317
At iterate    12  f =      -273.27  |proj g|=      0.011668
At iterate    13  f =      -273.27  |proj g|=       0.12544
At iterate    14  f =      -273.27  |proj g|=     0.0084775

iterations 14
function evaluations 24
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00847748
final function value -273.273

F = -273.273
final  value -273.273277 
converged
 
INFO  [02:50:54.651] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:50:54.706] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:50:54.713] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:51:02.767] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:51:10.926] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:51:11.819] [mlr3]  Finished benchmark 
INFO  [02:51:11.883] [bbotk] Result of batch 55: 
INFO  [02:51:11.885] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:51:11.885] [bbotk]                   8               598      0.2882912        0.545 -0.8955308 
INFO  [02:51:11.885] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:51:11.885] [bbotk]          <NA>   0.8184925 19e11ccb-bcd8-449d-a0a2-240c18428ba3 
DEBUG [02:51:12.746] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.200892e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9428 0.9916713 
  - variance bounds :  0.001200892 0.1258383 
  - best initial criterion value(s) :  239.7354 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -239.74  |proj g|=       11.479
At iterate     1  f =      -256.91  |proj g|=        2.9475
At iterate     2  f =      -265.82  |proj g|=        3.2207
At iterate     3  f =      -266.91  |proj g|=        3.1149
At iterate     4  f =      -272.69  |proj g|=        2.5287
At iterate     5  f =      -277.83  |proj g|=        2.0741
At iterate     6  f =      -281.77  |proj g|=        1.4856
At iterate     7  f =      -282.15  |proj g|=        1.4347
At iterate     8  f =      -282.26  |proj g|=       0.90507
At iterate     9  f =      -282.31  |proj g|=        1.3331
At iterate    10  f =      -282.36  |proj g|=        1.3212
At iterate    11  f =      -282.49  |proj g|=        1.3061
At iterate    12  f =      -283.02  |proj g|=        1.2766
At iterate    13  f =      -284.26  |proj g|=        1.2643
At iterate    14  f =       -288.3  |proj g|=        1.2851
At iterate    15  f =      -296.87  |proj g|=        1.4032
At iterate    16  f =      -300.15  |proj g|=         2.323
At iterate    17  f =      -300.39  |proj g|=        1.3439
At iterate    18  f =      -300.71  |proj g|=       0.12369
At iterate    19  f =      -300.74  |proj g|=       0.14785
At iterate    20  f =      -300.74  |proj g|=       0.12359
At iterate    21  f =      -300.74  |proj g|=       0.12359
At iterate    22  f =      -300.74  |proj g|=       0.05863
At iterate    23  f =      -300.74  |proj g|=     0.0043031

iterations 23
function evaluations 35
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00430307
final function value -300.744

F = -300.744
final  value -300.744177 
converged
 
INFO  [02:51:12.750] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:51:12.803] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:51:12.810] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:52:12.665] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:53:12.040] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:54:11.467] [mlr3]  Finished benchmark 
INFO  [02:54:11.533] [bbotk] Result of batch 56: 
INFO  [02:54:11.535] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:54:11.535] [bbotk]                   6              4999      0.3898992        0.619 -0.8920028 
INFO  [02:54:11.535] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:54:11.535] [bbotk]          <NA>   0.9763711 1a3c3333-8f58-4752-9eb3-2cfc5c117ad6 
DEBUG [02:54:12.422] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.200349e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001200349 0.1255151 
  - best initial criterion value(s) :  266.6931 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -266.69  |proj g|=       9.9343
At iterate     1  f =         -276  |proj g|=        1.7816
At iterate     2  f =      -287.61  |proj g|=        2.4889
At iterate     3  f =      -290.11  |proj g|=        2.2608
At iterate     4  f =      -293.53  |proj g|=        1.8367
At iterate     5  f =       -296.9  |proj g|=        1.4301
At iterate     6  f =       -297.2  |proj g|=        1.3389
At iterate     7  f =      -297.21  |proj g|=       0.69021
At iterate     8  f =      -298.75  |proj g|=         1.469
At iterate     9  f =      -303.21  |proj g|=        1.6901
At iterate    10  f =      -303.22  |proj g|=        1.6903
At iterate    11  f =      -303.25  |proj g|=        1.6907
At iterate    12  f =      -304.11  |proj g|=        1.5221
At iterate    13  f =      -304.48  |proj g|=       0.50247
At iterate    14  f =      -304.54  |proj g|=        0.1609
At iterate    15  f =      -304.55  |proj g|=      0.015007
At iterate    16  f =      -304.55  |proj g|=       0.12331
At iterate    17  f =      -304.55  |proj g|=     0.0046558

iterations 17
function evaluations 29
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00465577
final function value -304.551

F = -304.551
final  value -304.550521 
converged
 
INFO  [02:54:12.426] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:54:12.481] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:54:12.488] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:54:27.649] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:54:42.545] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:54:57.310] [mlr3]  Finished benchmark 
INFO  [02:54:57.375] [bbotk] Result of batch 57: 
INFO  [02:54:57.376] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:54:57.376] [bbotk]                   4              1179      0.1122702        0.624 -0.8928563 
INFO  [02:54:57.376] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:54:57.376] [bbotk]          <NA>   0.9749882 481c9490-d751-475e-bc85-9c7acc1ef927 
DEBUG [02:54:58.224] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.199086e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001199086 0.1253178 
  - best initial criterion value(s) :  267.1531 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -267.15  |proj g|=       4.2414
At iterate     1  f =      -272.61  |proj g|=        3.7167
At iterate     2  f =      -300.45  |proj g|=        1.6332
At iterate     3  f =      -301.08  |proj g|=        1.5978
At iterate     4  f =      -302.51  |proj g|=       0.55063
At iterate     5  f =      -302.54  |proj g|=        1.1516
At iterate     6  f =      -302.55  |proj g|=       0.90938
At iterate     7  f =      -302.55  |proj g|=        0.9133
At iterate     8  f =      -302.56  |proj g|=       0.92471
At iterate     9  f =      -302.56  |proj g|=       0.93874
At iterate    10  f =      -302.59  |proj g|=       0.99488
At iterate    11  f =      -302.65  |proj g|=        1.0985
At iterate    12  f =      -302.81  |proj g|=        1.4952
At iterate    13  f =      -303.15  |proj g|=        2.4053
At iterate    14  f =      -303.34  |proj g|=        2.5247
At iterate    15  f =      -303.51  |proj g|=        2.3441
At iterate    16  f =      -303.56  |proj g|=        1.9487
At iterate    17  f =       -303.6  |proj g|=        1.0939
At iterate    18  f =      -303.63  |proj g|=       0.12942
At iterate    19  f =      -303.63  |proj g|=      0.013911
At iterate    20  f =      -303.63  |proj g|=     0.0058477
At iterate    21  f =      -303.63  |proj g|=     0.0058475
At iterate    22  f =      -303.63  |proj g|=     0.0058475

iterations 22
function evaluations 31
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00584752
final function value -303.63

F = -303.63
final  value -303.629627 
converged
 
INFO  [02:54:58.228] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:54:58.281] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:54:58.288] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:55:38.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:56:18.007] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:56:57.780] [mlr3]  Finished benchmark 
INFO  [02:56:57.845] [bbotk] Result of batch 58: 
INFO  [02:56:57.846] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:56:57.846] [bbotk]                   4              3330      0.4394671        0.576 -0.8935692 
INFO  [02:56:57.846] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:56:57.846] [bbotk]          <NA>   0.9760544 50eeb72d-1b29-4392-be5f-7cf6c694b645 
DEBUG [02:56:58.833] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.19779e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.00119779 0.125185 
  - best initial criterion value(s) :  271.0622 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -271.06  |proj g|=        3.289
At iterate     1  f =      -293.07  |proj g|=        1.8442
At iterate     2  f =      -302.05  |proj g|=         1.912
At iterate     3  f =      -303.79  |proj g|=        1.8024
At iterate     4  f =      -308.45  |proj g|=        1.4437
At iterate     5  f =      -310.47  |proj g|=        7.9328
At iterate     6  f =       -310.6  |proj g|=        5.7131
At iterate     7  f =      -310.61  |proj g|=        5.4581
At iterate     8  f =      -310.61  |proj g|=        5.3324
At iterate     9  f =      -310.61  |proj g|=        5.2651
At iterate    10  f =      -310.62  |proj g|=        5.0335
At iterate    11  f =      -310.63  |proj g|=        4.7383
At iterate    12  f =      -310.66  |proj g|=        4.1864
At iterate    13  f =      -310.74  |proj g|=        3.2609
At iterate    14  f =      -310.96  |proj g|=         1.504
At iterate    15  f =      -311.47  |proj g|=        1.2571
At iterate    16  f =      -312.51  |proj g|=        1.3938
At iterate    17  f =      -314.48  |proj g|=        1.5516
At iterate    18  f =      -315.56  |proj g|=        1.5541
At iterate    19  f =      -315.86  |proj g|=         1.494
At iterate    20  f =      -316.14  |proj g|=       0.40947
At iterate    21  f =      -316.18  |proj g|=       0.15793
At iterate    22  f =      -316.18  |proj g|=       0.13455
At iterate    23  f =      -316.18  |proj g|=      0.027417
At iterate    24  f =      -316.18  |proj g|=     0.0046665
At iterate    25  f =      -316.18  |proj g|=      0.017684

iterations 25
function evaluations 31
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0176837
final function value -316.182

F = -316.182
final  value -316.182468 
converged
 
INFO  [02:56:58.837] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:56:58.892] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:56:58.899] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:57:46.105] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:58:33.421] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:58:34.310] [mlr3]  Finished benchmark 
INFO  [02:58:34.375] [bbotk] Result of batch 59: 
INFO  [02:58:34.377] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [02:58:34.377] [bbotk]                   7              4009      0.3426318        0.752 -0.8920513 
INFO  [02:58:34.377] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:58:34.377] [bbotk]          <NA>   0.8190554 0cb88239-ec84-4e9f-b49c-2399d3d0b0f9 
DEBUG [02:58:35.226] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.186426e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001186426 0.123575 
  - best initial criterion value(s) :  266.8072 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -266.81  |proj g|=       8.1508
At iterate     1  f =      -273.64  |proj g|=        2.7554
At iterate     2  f =      -283.73  |proj g|=        2.1915
At iterate     3  f =      -286.32  |proj g|=        1.9204
At iterate     4  f =      -288.23  |proj g|=        1.6203
At iterate     5  f =      -289.41  |proj g|=         1.444
At iterate     6  f =      -289.98  |proj g|=        1.3259
At iterate     7  f =      -289.99  |proj g|=        1.3045
At iterate     8  f =         -290  |proj g|=        1.3166
At iterate     9  f =         -290  |proj g|=        1.3135
At iterate    10  f =      -290.02  |proj g|=        1.2974
At iterate    11  f =      -290.06  |proj g|=        1.2754
At iterate    12  f =      -290.19  |proj g|=        1.0546
At iterate    13  f =      -290.51  |proj g|=       0.28599
At iterate    14  f =      -291.42  |proj g|=        2.8177
At iterate    15  f =      -293.71  |proj g|=        6.9606
At iterate    16  f =      -299.82  |proj g|=         10.92
At iterate    17  f =      -300.89  |proj g|=        11.912
At iterate    18  f =       -302.8  |proj g|=        8.3137
At iterate    19  f =      -303.58  |proj g|=        0.8906
At iterate    20  f =      -303.95  |proj g|=          1.48
At iterate    21  f =      -304.02  |proj g|=       0.82999
At iterate    22  f =      -304.05  |proj g|=       0.12161
At iterate    23  f =      -304.05  |proj g|=        0.1216
At iterate    24  f =      -304.05  |proj g|=     0.0080914
At iterate    25  f =      -304.05  |proj g|=     0.0080914

iterations 25
function evaluations 35
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00809139
final function value -304.047

F = -304.047
final  value -304.047395 
converged
 
INFO  [02:58:35.230] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:58:35.284] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:58:35.291] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [02:58:48.634] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [02:59:01.482] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:59:14.711] [mlr3]  Finished benchmark 
INFO  [02:59:14.777] [bbotk] Result of batch 60: 
INFO  [02:59:14.779] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [02:59:14.779] [bbotk]                   4              1009      0.1577147         0.59 -0.894714 
INFO  [02:59:14.779] [bbotk]  errors.model classif.auc                                uhash 
INFO  [02:59:14.779] [bbotk]          <NA>    0.975251 ff50ee9f-d7f6-42cd-b181-58bbb8981154 
DEBUG [02:59:15.543] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.184953e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001184953 0.1235905 
  - best initial criterion value(s) :  250.2624 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -250.26  |proj g|=       10.731
At iterate     1  f =      -266.49  |proj g|=        2.8177
At iterate     2  f =      -269.17  |proj g|=        2.8008
At iterate     3  f =      -270.73  |proj g|=        2.6035
At iterate     4  f =      -272.63  |proj g|=        2.2836
At iterate     5  f =      -275.55  |proj g|=        1.7628
At iterate     6  f =       -275.6  |proj g|=       0.82741
At iterate     7  f =      -276.65  |proj g|=        1.5502
At iterate     8  f =      -276.68  |proj g|=        1.5122
At iterate     9  f =      -276.71  |proj g|=        1.5374
At iterate    10  f =      -276.71  |proj g|=        1.5344
At iterate    11  f =      -276.75  |proj g|=        1.5051
At iterate    12  f =      -276.81  |proj g|=        1.4795
At iterate    13  f =      -277.04  |proj g|=        1.4128
At iterate    14  f =      -277.58  |proj g|=        1.3247
At iterate    15  f =      -279.29  |proj g|=        1.1663
At iterate    16  f =      -283.79  |proj g|=        4.7392
At iterate    17  f =      -295.73  |proj g|=        5.5933
At iterate    18  f =      -316.69  |proj g|=          7.24
At iterate    19  f =       -318.1  |proj g|=        6.5428
At iterate    20  f =      -318.55  |proj g|=        2.1993
At iterate    21  f =      -318.74  |proj g|=        1.2612
At iterate    22  f =      -318.92  |proj g|=       0.16878
At iterate    23  f =      -318.93  |proj g|=       0.12159
At iterate    24  f =      -318.93  |proj g|=       0.12158
At iterate    25  f =      -318.93  |proj g|=       0.03464
At iterate    26  f =      -318.93  |proj g|=     0.0063477

iterations 26
function evaluations 34
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00634773
final function value -318.932

F = -318.932
final  value -318.931605 
converged
 
INFO  [02:59:15.547] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:59:15.602] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:59:15.609] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [02:59:45.595] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:00:15.783] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:00:46.445] [mlr3]  Finished benchmark 
INFO  [03:00:46.514] [bbotk] Result of batch 61: 
INFO  [03:00:46.516] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:00:46.516] [bbotk]                   3              2496      0.0487997         0.52 -0.8929403 
INFO  [03:00:46.516] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:00:46.516] [bbotk]          <NA>   0.9722393 b60ca85f-d772-4148-9abb-ff063abdba24 
DEBUG [03:00:47.304] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.182485e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001182485 0.1232211 
  - best initial criterion value(s) :  291.0626 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -291.06  |proj g|=       4.3439
At iterate     1  f =      -297.01  |proj g|=         3.324
At iterate     2  f =      -300.67  |proj g|=        3.3236
At iterate     3  f =       -302.4  |proj g|=        3.1668
At iterate     4  f =      -305.32  |proj g|=        2.7829
At iterate     5  f =       -307.7  |proj g|=        2.5587
At iterate     6  f =      -316.62  |proj g|=        1.5424
At iterate     7  f =      -316.75  |proj g|=        1.4646
At iterate     8  f =      -316.78  |proj g|=        1.3688
At iterate     9  f =       -316.8  |proj g|=        1.4057
At iterate    10  f =      -316.81  |proj g|=        1.4083
At iterate    11  f =      -316.83  |proj g|=        1.4143
At iterate    12  f =       -316.9  |proj g|=        1.4305
At iterate    13  f =      -317.05  |proj g|=        1.4499
At iterate    14  f =      -317.49  |proj g|=        1.4844
At iterate    15  f =      -318.64  |proj g|=        1.5461
At iterate    16  f =      -321.57  |proj g|=        1.6719
At iterate    17  f =      -326.65  |proj g|=        1.8692
At iterate    18  f =      -328.36  |proj g|=        1.8339
At iterate    19  f =      -329.74  |proj g|=        1.7655
At iterate    20  f =      -330.09  |proj g|=        1.7144
At iterate    21  f =      -330.31  |proj g|=        1.6598
At iterate    22  f =      -330.71  |proj g|=        1.5537
At iterate    23  f =      -331.43  |proj g|=        1.1493
At iterate    24  f =      -331.69  |proj g|=        1.2432
At iterate    25  f =      -331.72  |proj g|=       0.46514
At iterate    26  f =      -331.73  |proj g|=      0.028823
At iterate    27  f =      -331.73  |proj g|=       0.12115
At iterate    28  f =      -331.73  |proj g|=     0.0051597
At iterate    29  f =      -331.73  |proj g|=     0.0051597

iterations 29
function evaluations 40
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00515971
final function value -331.733

F = -331.733
final  value -331.733087 
converged
 
INFO  [03:00:47.308] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:00:47.367] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:00:47.373] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:01:20.607] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:01:21.435] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:01:22.317] [mlr3]  Finished benchmark 
INFO  [03:01:22.381] [bbotk] Result of batch 62: 
INFO  [03:01:22.383] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:01:22.383] [bbotk]                  10              2730      0.4685859         0.53 -0.8914229 
INFO  [03:01:22.383] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:01:22.383] [bbotk]          <NA>   0.6587854 b9b970f4-0d9d-4106-a275-7e9c3d9152ad 
DEBUG [03:01:23.175] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.222813e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001222813 0.127245 
  - best initial criterion value(s) :  272.1068 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -272.11  |proj g|=       3.2533
At iterate     1  f =      -314.34  |proj g|=        1.4443
At iterate     2  f =      -316.45  |proj g|=        2.3077
At iterate     3  f =      -319.41  |proj g|=        1.9515
At iterate     4  f =      -321.16  |proj g|=        1.5744
At iterate     5  f =      -321.47  |proj g|=        1.4808
At iterate     6  f =      -321.48  |proj g|=        1.4037
At iterate     7  f =       -321.5  |proj g|=        1.4356
At iterate     8  f =      -321.54  |proj g|=        1.4582
At iterate     9  f =      -321.76  |proj g|=        1.5136
At iterate    10  f =      -322.38  |proj g|=        1.6118
At iterate    11  f =      -323.98  |proj g|=        1.7781
At iterate    12  f =      -326.12  |proj g|=        1.8665
At iterate    13  f =      -327.94  |proj g|=        1.6539
At iterate    14  f =      -329.31  |proj g|=        1.3439
At iterate    15  f =      -329.46  |proj g|=       0.84686
At iterate    16  f =      -329.48  |proj g|=      0.096951
At iterate    17  f =      -329.48  |proj g|=      0.026804
At iterate    18  f =      -329.48  |proj g|=       0.12529
At iterate    19  f =      -329.48  |proj g|=     0.0066864
At iterate    20  f =      -329.48  |proj g|=     0.0066864

iterations 20
function evaluations 30
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00668644
final function value -329.479

F = -329.479
final  value -329.478835 
converged
 
INFO  [03:01:23.179] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:01:23.236] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:01:23.243] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:01:42.733] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:02:02.104] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:02:21.153] [mlr3]  Finished benchmark 
INFO  [03:02:21.219] [bbotk] Result of batch 63: 
INFO  [03:02:21.221] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:02:21.221] [bbotk]                   5              1547      0.3901996        0.525 -0.8921423 
INFO  [03:02:21.221] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:02:21.221] [bbotk]          <NA>   0.9771255 964fd191-f3e9-47c6-a29c-118906a8c63f 
DEBUG [03:02:22.004] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.221449e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001221449 0.1271587 
  - best initial criterion value(s) :  296.4587 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -296.46  |proj g|=       4.6129
At iterate     1  f =      -303.34  |proj g|=        3.9696
At iterate     2  f =      -335.89  |proj g|=        1.7219
At iterate     3  f =      -337.28  |proj g|=        1.5559
At iterate     4  f =      -338.54  |proj g|=       0.73664
At iterate     5  f =      -338.59  |proj g|=        1.2782
At iterate     6  f =      -338.61  |proj g|=        0.9283
At iterate     7  f =      -338.61  |proj g|=       0.67866
At iterate     8  f =      -338.61  |proj g|=       0.75478
At iterate     9  f =      -338.61  |proj g|=       0.86756
At iterate    10  f =      -338.62  |proj g|=        1.2057
At iterate    11  f =      -338.63  |proj g|=         1.641
At iterate    12  f =      -338.67  |proj g|=        2.4008
At iterate    13  f =      -338.78  |proj g|=         3.563
At iterate    14  f =      -339.02  |proj g|=        5.3057
At iterate    15  f =      -339.16  |proj g|=        4.8591
At iterate    16  f =      -339.41  |proj g|=        2.6386
At iterate    17  f =      -339.56  |proj g|=       0.22928
At iterate    18  f =      -339.57  |proj g|=       0.12519
At iterate    19  f =      -339.57  |proj g|=       0.12518
At iterate    20  f =      -339.57  |proj g|=       0.12518
At iterate    21  f =      -339.57  |proj g|=     0.0059512

iterations 21
function evaluations 29
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00595122
final function value -339.573

F = -339.573
final  value -339.573249 
converged
 
INFO  [03:02:22.006] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:02:22.059] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:02:22.066] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:02:36.264] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:02:37.193] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:02:50.722] [mlr3]  Finished benchmark 
INFO  [03:02:50.787] [bbotk] Result of batch 64: 
INFO  [03:02:50.789] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:02:50.789] [bbotk]                   7              1069      0.1687147         0.55 -0.8911418 
INFO  [03:02:50.789] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:02:50.789] [bbotk]          <NA>   0.8184941 18f5d003-c322-4ba2-87a9-89de954c76d9 
DEBUG [03:02:51.543] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.210602e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001210602 0.1259633 
  - best initial criterion value(s) :  247.5833 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -247.58  |proj g|=       3.0159
At iterate     1  f =      -272.08  |proj g|=        4.1518
At iterate     2  f =      -272.73  |proj g|=        4.2399
At iterate     3  f =      -272.89  |proj g|=         4.298
At iterate     4  f =      -274.02  |proj g|=        4.9071
At iterate     5  f =      -306.84  |proj g|=        1.7392
At iterate     6  f =      -307.44  |proj g|=         1.654
At iterate     7  f =      -308.36  |proj g|=        1.3664
At iterate     8  f =      -329.19  |proj g|=        1.3422
At iterate     9  f =      -330.26  |proj g|=      0.062011
At iterate    10  f =      -330.29  |proj g|=      0.010977
At iterate    11  f =      -330.29  |proj g|=       0.12412
At iterate    12  f =      -330.29  |proj g|=     0.0090893
At iterate    13  f =      -330.29  |proj g|=     0.0090893

iterations 13
function evaluations 24
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00908926
final function value -330.286

F = -330.286
final  value -330.286011 
converged
 
INFO  [03:02:51.547] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:02:51.602] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:02:51.609] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:03:09.186] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:03:27.065] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:03:44.896] [mlr3]  Finished benchmark 
INFO  [03:03:44.960] [bbotk] Result of batch 65: 
INFO  [03:03:44.962] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:03:44.962] [bbotk]                   4              1409      0.4623662         0.53 -0.8941089 
INFO  [03:03:44.962] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:03:44.962] [bbotk]          <NA>   0.9760744 6cb8d56d-e1c9-4edd-acfa-d5fb6743b3ee 
DEBUG [03:03:45.776] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.209017e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001209017 0.126074 
  - best initial criterion value(s) :  294.7669 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -294.77  |proj g|=       4.0563
At iterate     1  f =      -310.02  |proj g|=        3.0563
At iterate     2  f =      -337.27  |proj g|=        1.8843
At iterate     3  f =      -339.51  |proj g|=        1.6502
At iterate     4  f =      -343.37  |proj g|=       0.12423
At iterate     5  f =      -343.52  |proj g|=        3.9971
At iterate     6  f =       -343.6  |proj g|=        3.8915
At iterate     7  f =      -343.61  |proj g|=        3.6068
At iterate     8  f =      -343.61  |proj g|=        3.6341
At iterate     9  f =      -343.61  |proj g|=        3.6539
At iterate    10  f =      -343.61  |proj g|=        3.7175
At iterate    11  f =      -343.62  |proj g|=        3.8138
At iterate    12  f =      -343.64  |proj g|=        4.0218
At iterate    13  f =      -343.68  |proj g|=        4.3781
At iterate    14  f =      -343.79  |proj g|=        5.1904
At iterate    15  f =      -344.06  |proj g|=        6.7315
At iterate    16  f =      -344.75  |proj g|=         8.896
At iterate    17  f =      -345.54  |proj g|=        10.521
At iterate    18  f =      -346.18  |proj g|=        8.9338
At iterate    19  f =      -347.45  |proj g|=         3.251
At iterate    20  f =      -347.63  |proj g|=       0.12416
At iterate    21  f =      -347.63  |proj g|=       0.12415
At iterate    22  f =      -347.63  |proj g|=       0.12414
At iterate    23  f =      -347.63  |proj g|=       0.12414
At iterate    24  f =      -347.63  |proj g|=     0.0064824

iterations 24
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00648238
final function value -347.628

F = -347.628
final  value -347.627507 
converged
 
INFO  [03:03:45.780] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:03:45.834] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:03:45.841] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:04:29.577] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:04:30.482] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:05:14.724] [mlr3]  Finished benchmark 
INFO  [03:05:14.791] [bbotk] Result of batch 66: 
INFO  [03:05:14.793] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:05:14.793] [bbotk]                   8              3669      0.2841686        0.565 -0.8914871 
INFO  [03:05:14.793] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:05:14.793] [bbotk]          <NA>   0.8182958 46ba0573-e2e9-4743-bece-c853082709e0 
DEBUG [03:05:15.594] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.198652e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001198652 0.1246918 
  - best initial criterion value(s) :  287.9001 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -287.9  |proj g|=       4.0945
At iterate     1  f =      -304.54  |proj g|=        1.4868
At iterate     2  f =      -334.22  |proj g|=        2.1014
At iterate     3  f =      -336.64  |proj g|=        1.9116
At iterate     4  f =      -345.35  |proj g|=        1.5856
At iterate     5  f =      -345.45  |proj g|=        4.7691
At iterate     6  f =       -345.5  |proj g|=        5.6962
At iterate     7  f =      -345.52  |proj g|=        4.5741
At iterate     8  f =      -345.52  |proj g|=        4.6985
At iterate     9  f =      -345.74  |proj g|=        3.6189
At iterate    10  f =       -347.7  |proj g|=        4.9627
At iterate    11  f =      -349.66  |proj g|=        6.0584
At iterate    12  f =       -350.4  |proj g|=        1.7688
At iterate    13  f =       -350.5  |proj g|=       0.12284
At iterate    14  f =      -350.51  |proj g|=       0.12281
At iterate    15  f =      -350.51  |proj g|=        0.1228
At iterate    16  f =      -350.51  |proj g|=        0.1228
At iterate    17  f =      -350.51  |proj g|=       0.11864
At iterate    18  f =      -350.51  |proj g|=      0.007062

iterations 18
function evaluations 27
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00706197
final function value -350.509

F = -350.509
final  value -350.508705 
converged
 
INFO  [03:05:15.598] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:05:15.682] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:05:15.688] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:05:55.319] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:06:35.412] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:06:36.371] [mlr3]  Finished benchmark 
INFO  [03:06:36.435] [bbotk] Result of batch 67: 
INFO  [03:06:36.437] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:06:36.437] [bbotk]                   8              3328      0.1963742        0.556 -0.8916328 
INFO  [03:06:36.437] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:06:36.437] [bbotk]          <NA>   0.8187414 c40209bd-8ad4-495e-873c-1f4cf5ce4201 
DEBUG [03:06:37.206] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.188393e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001188393 0.1237419 
  - best initial criterion value(s) :  334.4329 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -334.43  |proj g|=       3.4565
At iterate     1  f =      -341.67  |proj g|=        2.8123
At iterate     2  f =       -362.2  |proj g|=        1.5176
At iterate     3  f =       -362.4  |proj g|=        1.4632
At iterate     4  f =      -362.58  |proj g|=        5.9007
At iterate     5  f =      -362.98  |proj g|=        1.3017
At iterate     6  f =      -363.01  |proj g|=        1.0663
At iterate     7  f =      -363.02  |proj g|=        1.1151
At iterate     8  f =      -363.06  |proj g|=        1.1869
At iterate     9  f =      -363.19  |proj g|=        1.3331
At iterate    10  f =       -363.5  |proj g|=        1.5607
At iterate    11  f =      -363.95  |proj g|=        2.1558
At iterate    12  f =      -364.38  |proj g|=       0.72885
At iterate    13  f =      -364.48  |proj g|=       0.12182
At iterate    14  f =      -364.49  |proj g|=       0.12179
At iterate    15  f =      -364.49  |proj g|=       0.12178
At iterate    16  f =      -364.49  |proj g|=       0.12178
At iterate    17  f =      -364.49  |proj g|=       0.07818

iterations 17
function evaluations 23
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.07818
final function value -364.49

F = -364.49
final  value -364.490174 
converged
 
INFO  [03:06:37.210] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:06:37.264] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:06:37.271] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:06:38.174] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:07:23.468] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:08:07.968] [mlr3]  Finished benchmark 
INFO  [03:08:08.032] [bbotk] Result of batch 68: 
INFO  [03:08:08.034] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:08:08.034] [bbotk]                   9              3798      0.1587563         0.54 -0.8898897 
INFO  [03:08:08.034] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:08:08.034] [bbotk]          <NA>   0.8177679 3d34a61a-c243-494d-ad62-a7d024164d1e 
DEBUG [03:08:08.968] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.178406e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001178406 0.1225401 
  - best initial criterion value(s) :  307.5313 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -307.53  |proj g|=      0.06835
At iterate     1  f =      -360.16  |proj g|=        3.7052
At iterate     2  f =      -360.17  |proj g|=        3.6678
At iterate     3  f =      -360.25  |proj g|=        3.9186
ys=-5.934e-04  -gs= 8.011e-02, BFGS update SKIPPED
At iterate     4  f =      -360.25  |proj g|=        3.9265
At iterate     5  f =      -360.25  |proj g|=        3.9297
At iterate     6  f =      -360.25  |proj g|=        3.9369
At iterate     7  f =      -360.25  |proj g|=        3.9609
At iterate     8  f =      -360.25  |proj g|=        4.0122
At iterate     9  f =      -360.25  |proj g|=        4.1495
At iterate    10  f =      -360.26  |proj g|=        4.5217
At iterate    11  f =      -360.29  |proj g|=        5.7587
At iterate    12  f =      -360.44  |proj g|=        12.409
At iterate    13  f =      -360.57  |proj g|=        13.631
At iterate    14  f =      -360.71  |proj g|=        13.572
At iterate    15  f =      -361.25  |proj g|=          13.5
At iterate    16  f =      -363.81  |proj g|=        13.281
At iterate    17  f =      -369.18  |proj g|=        3.9066
At iterate    18  f =      -371.55  |proj g|=        3.4441
At iterate    19  f =      -372.27  |proj g|=       0.63417
At iterate    20  f =      -372.45  |proj g|=       0.12064
At iterate    21  f =      -372.48  |proj g|=       0.12058
At iterate    22  f =      -372.48  |proj g|=       0.12057
At iterate    23  f =      -372.48  |proj g|=     0.0054323
At iterate    24  f =      -372.48  |proj g|=       0.12056

iterations 24
function evaluations 33
segments explored during Cauchy searches 26
BFGS updates skipped 1
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.120564
final function value -372.481

F = -372.481
final  value -372.480872 
converged
 
INFO  [03:08:08.970] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:08:09.013] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:08:09.019] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:08:42.027] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:09:15.022] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:09:48.206] [mlr3]  Finished benchmark 
INFO  [03:09:48.272] [bbotk] Result of batch 69: 
INFO  [03:09:48.274] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:09:48.274] [bbotk]                   3              2762      0.4093718        0.653 -0.8890921 
INFO  [03:09:48.274] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:09:48.274] [bbotk]          <NA>    0.974318 28867b09-5d94-411d-9448-a3136796b644 
DEBUG [03:09:49.433] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.176995e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001176995 0.1219968 
  - best initial criterion value(s) :  325.3009 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -325.3  |proj g|=       9.3806
At iterate     1  f =      -332.25  |proj g|=        1.6368
At iterate     2  f =         -348  |proj g|=        2.4302
At iterate     3  f =      -350.85  |proj g|=        2.2031
At iterate     4  f =      -355.99  |proj g|=        1.7042
At iterate     5  f =      -358.82  |proj g|=        1.3746
At iterate     6  f =      -358.98  |proj g|=        1.2887
At iterate     7  f =      -358.99  |proj g|=       0.11523
At iterate     8  f =         -359  |proj g|=       0.30765
At iterate     9  f =         -359  |proj g|=       0.33964
At iterate    10  f =         -359  |proj g|=       0.62499
At iterate    11  f =      -359.01  |proj g|=        0.9532
At iterate    12  f =      -359.04  |proj g|=        1.2888
At iterate    13  f =       -359.1  |proj g|=        1.3149
At iterate    14  f =      -359.26  |proj g|=        1.3653
At iterate    15  f =      -359.65  |proj g|=        1.4408
At iterate    16  f =      -360.58  |proj g|=        1.5772
At iterate    17  f =      -361.07  |proj g|=        1.5761
At iterate    18  f =      -361.46  |proj g|=        1.5145
At iterate    19  f =      -362.06  |proj g|=       0.94316
At iterate    20  f =      -362.25  |proj g|=       0.62509
At iterate    21  f =      -362.26  |proj g|=       0.23686
At iterate    22  f =      -362.26  |proj g|=        0.1202
At iterate    23  f =      -362.26  |proj g|=      0.070033
At iterate    24  f =      -362.26  |proj g|=     0.0084646

iterations 24
function evaluations 33
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00846459
final function value -362.262

F = -362.262
final  value -362.262435 
converged
 
INFO  [03:09:49.437] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:09:49.500] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:09:49.507] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:09:50.239] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:09:51.106] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:10:38.939] [mlr3]  Finished benchmark 
INFO  [03:10:39.005] [bbotk] Result of batch 70: 
INFO  [03:10:39.006] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:10:39.006] [bbotk]                  10              3973      0.4869256        0.839 -0.8919187 
INFO  [03:10:39.006] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:10:39.006] [bbotk]          <NA>   0.6584485 f498f786-4a44-42ec-a27d-20f737f1b7eb 
DEBUG [03:10:39.941] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.213425e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001213425 0.1263633 
  - best initial criterion value(s) :  326.1987 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -326.2  |proj g|=       4.3807
At iterate     1  f =      -338.51  |proj g|=        3.4651
At iterate     2  f =      -371.95  |proj g|=        1.6904
At iterate     3  f =      -372.13  |proj g|=        12.479
At iterate     4  f =      -373.95  |proj g|=        10.946
At iterate     5  f =      -375.25  |proj g|=        1.9849
At iterate     6  f =      -375.32  |proj g|=        2.8654
At iterate     7  f =      -375.58  |proj g|=        4.6264
At iterate     8  f =       -376.4  |proj g|=        7.5892
At iterate     9  f =      -376.71  |proj g|=        7.6794
At iterate    10  f =      -377.28  |proj g|=        4.5773
At iterate    11  f =      -377.76  |proj g|=       0.18036
At iterate    12  f =      -377.78  |proj g|=       0.12451
At iterate    13  f =      -377.78  |proj g|=        0.1245
At iterate    14  f =      -377.78  |proj g|=      0.049931
At iterate    15  f =      -377.78  |proj g|=     0.0066426

iterations 15
function evaluations 24
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00664256
final function value -377.778

F = -377.778
final  value -377.778402 
converged
 
INFO  [03:10:39.945] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:10:40.001] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:10:40.008] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:11:28.702] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:12:17.341] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:13:06.124] [mlr3]  Finished benchmark 
INFO  [03:13:06.200] [bbotk] Result of batch 71: 
INFO  [03:13:06.202] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:13:06.202] [bbotk]                   3              4116      0.2640543        0.664 -0.8897252 
INFO  [03:13:06.202] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:13:06.202] [bbotk]          <NA>   0.9743134 91379a63-b6cc-4bec-b1a7-875b6b23ff1c 
DEBUG [03:13:07.013] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.21193e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.00121193 0.1259631 
  - best initial criterion value(s) :  311.5419 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -311.54  |proj g|=       13.092
At iterate     1  f =      -344.32  |proj g|=        4.9976
At iterate     2  f =      -355.78  |proj g|=        2.3455
At iterate     3  f =      -362.41  |proj g|=        3.1269
At iterate     4  f =      -363.82  |proj g|=        3.1072
At iterate     5  f =      -367.88  |proj g|=        2.9129
At iterate     6  f =      -378.79  |proj g|=        2.0622
At iterate     7  f =      -383.64  |proj g|=         1.611
At iterate     8  f =       -384.6  |proj g|=        1.4899
At iterate     9  f =      -385.16  |proj g|=       0.12283
At iterate    10  f =      -385.16  |proj g|=       0.12412
At iterate    11  f =      -385.16  |proj g|=     0.0064338
At iterate    12  f =      -385.16  |proj g|=     0.0064335
At iterate    13  f =      -385.16  |proj g|=     0.0064335

iterations 13
function evaluations 24
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0064335
final function value -385.161

F = -385.161
final  value -385.161020 
converged
 
INFO  [03:13:07.016] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:13:07.069] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:13:07.076] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:13:17.932] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:13:28.959] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:13:29.858] [mlr3]  Finished benchmark 
INFO  [03:13:29.922] [bbotk] Result of batch 72: 
INFO  [03:13:29.923] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:13:29.923] [bbotk]                   7               833      0.1472719        0.568 -0.8892978 
INFO  [03:13:29.923] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:13:29.923] [bbotk]          <NA>   0.8181779 f6c82ad1-3d46-4a48-ae82-d9460b4ed08b 
DEBUG [03:13:31.030] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.201998e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001201998 0.1248737 
  - best initial criterion value(s) :  339.9708 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -339.97  |proj g|=       3.7907
At iterate     1  f =       -344.8  |proj g|=        3.1496
At iterate     2  f =      -349.14  |proj g|=         3.122
At iterate     3  f =      -350.89  |proj g|=        3.0063
At iterate     4  f =      -354.01  |proj g|=        2.7081
At iterate     5  f =      -357.41  |proj g|=        2.4262
At iterate     6  f =      -363.51  |proj g|=        1.8959
At iterate     7  f =      -365.32  |proj g|=         1.547
At iterate     8  f =      -365.84  |proj g|=        1.4419
At iterate     9  f =      -365.86  |proj g|=        1.3831
At iterate    10  f =      -365.86  |proj g|=        1.4014
At iterate    11  f =      -365.88  |proj g|=        1.4132
At iterate    12  f =      -365.98  |proj g|=         1.456
At iterate    13  f =      -366.31  |proj g|=        1.5423
At iterate    14  f =       -366.4  |proj g|=        1.5839
At iterate    15  f =      -367.18  |proj g|=        1.7008
At iterate    16  f =       -368.9  |proj g|=        1.8809
At iterate    17  f =      -371.77  |proj g|=        2.0568
At iterate    18  f =       -372.4  |proj g|=        2.0643
At iterate    19  f =       -374.4  |proj g|=        1.8715
At iterate    20  f =      -376.79  |proj g|=        2.1251
At iterate    21  f =      -376.88  |proj g|=       0.43595
At iterate    22  f =      -376.89  |proj g|=      0.020729
At iterate    23  f =      -376.89  |proj g|=       0.12288
At iterate    24  f =      -376.89  |proj g|=      0.021255

iterations 24
function evaluations 36
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0212555
final function value -376.888

F = -376.888
final  value -376.888055 
converged
 
INFO  [03:13:31.034] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:13:31.089] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:13:31.096] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:13:47.146] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:13:47.924] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:13:48.922] [mlr3]  Finished benchmark 
INFO  [03:13:48.987] [bbotk] Result of batch 73: 
INFO  [03:13:48.989] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:13:48.989] [bbotk]                  10              1300      0.2711147        0.805 -0.8890372 
INFO  [03:13:48.989] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:13:48.989] [bbotk]          <NA>   0.6594223 059840ab-e8cc-4ac7-949e-a36a7f18ae69 
DEBUG [03:13:49.789] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.235824e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001235824 0.1271281 
  - best initial criterion value(s) :  354.1805 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -354.18  |proj g|=       9.3817
At iterate     1  f =       -361.1  |proj g|=        2.1017
At iterate     2  f =      -376.27  |proj g|=        2.3445
At iterate     3  f =       -379.8  |proj g|=        2.0458
At iterate     4  f =      -382.86  |proj g|=        1.6878
At iterate     5  f =      -385.07  |proj g|=       0.14399
At iterate     6  f =      -385.14  |proj g|=        0.2357
At iterate     7  f =      -385.15  |proj g|=       0.76479
At iterate     8  f =      -385.15  |proj g|=       0.60016
At iterate     9  f =      -385.17  |proj g|=       0.14387
At iterate    10  f =      -385.22  |proj g|=       0.80956
At iterate    11  f =      -385.35  |proj g|=        2.1737
At iterate    12  f =      -385.67  |proj g|=        4.2099
At iterate    13  f =      -386.44  |proj g|=        7.2326
At iterate    14  f =      -386.88  |proj g|=        8.1922
At iterate    15  f =      -388.68  |proj g|=        10.248
At iterate    16  f =      -390.35  |proj g|=        6.8857
At iterate    17  f =      -391.06  |proj g|=       0.31935
At iterate    18  f =      -391.15  |proj g|=       0.10259
At iterate    19  f =      -391.15  |proj g|=     0.0075518
At iterate    20  f =      -391.15  |proj g|=       0.12512
At iterate    21  f =      -391.15  |proj g|=     0.0075506

iterations 21
function evaluations 32
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00755061
final function value -391.154

F = -391.154
final  value -391.153577 
converged
 
INFO  [03:13:49.793] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:13:49.848] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:13:49.855] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:14:07.745] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:14:25.324] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:14:43.404] [mlr3]  Finished benchmark 
INFO  [03:14:43.481] [bbotk] Result of batch 74: 
INFO  [03:14:43.483] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:14:43.483] [bbotk]                   3              1395      0.1929775        0.547 -0.8880338 
INFO  [03:14:43.483] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:14:43.483] [bbotk]          <NA>   0.9736302 6b12dda2-0464-42bc-8a07-40be1d6c7987 
DEBUG [03:14:44.297] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.234355e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001234355 0.1269916 
  - best initial criterion value(s) :  349.4145 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -349.41  |proj g|=       3.0361
At iterate     1  f =       -357.6  |proj g|=        1.6438
At iterate     2  f =      -381.58  |proj g|=        0.1621
At iterate     3  f =      -381.86  |proj g|=        1.1795
At iterate     4  f =       -381.9  |proj g|=         2.641
At iterate     5  f =       -381.9  |proj g|=        2.7729
At iterate     6  f =       -381.9  |proj g|=        2.7474
At iterate     7  f =       -381.9  |proj g|=        2.7148
At iterate     8  f =       -381.9  |proj g|=        2.6518
At iterate     9  f =      -381.91  |proj g|=         2.557
At iterate    10  f =      -381.92  |proj g|=        2.4176
At iterate    11  f =      -381.95  |proj g|=        2.1144
At iterate    12  f =      -382.04  |proj g|=        1.4743
At iterate    13  f =      -382.24  |proj g|=       0.62949
At iterate    14  f =      -382.67  |proj g|=        1.4705
At iterate    15  f =      -382.84  |proj g|=       0.38601
At iterate    16  f =      -383.76  |proj g|=        1.6184
At iterate    17  f =      -384.32  |proj g|=        1.6198
At iterate    18  f =      -384.81  |proj g|=        1.5101
At iterate    19  f =      -385.11  |proj g|=       0.17559
At iterate    20  f =      -385.11  |proj g|=      0.068945
At iterate    21  f =      -385.12  |proj g|=     0.0098213
At iterate    22  f =      -385.12  |proj g|=       0.12505
At iterate    23  f =      -385.12  |proj g|=      0.009821

iterations 23
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00982103
final function value -385.116

F = -385.116
final  value -385.116346 
converged
 
INFO  [03:14:44.301] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:14:44.361] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:14:44.369] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:14:53.993] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:15:03.572] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:15:04.425] [mlr3]  Finished benchmark 
INFO  [03:15:04.489] [bbotk] Result of batch 75: 
INFO  [03:15:04.491] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:15:04.491] [bbotk]                   7               713      0.1127376        0.556 -0.8891697 
INFO  [03:15:04.491] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:15:04.491] [bbotk]          <NA>    0.817723 6242b3a3-2d77-40b7-b935-efc763099aec 
DEBUG [03:15:05.317] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.224369e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001224369 0.1258978 
  - best initial criterion value(s) :  373.9602 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -373.96  |proj g|=        2.933
At iterate     1  f =      -382.15  |proj g|=       0.17921
At iterate     2  f =      -400.56  |proj g|=        1.5878
At iterate     3  f =      -401.54  |proj g|=       0.85535
At iterate     4  f =      -401.79  |proj g|=        2.5089
At iterate     5  f =      -401.81  |proj g|=        2.7389
At iterate     6  f =      -401.81  |proj g|=        2.6465
At iterate     7  f =      -401.81  |proj g|=        2.6101
At iterate     8  f =      -401.81  |proj g|=        2.5077
At iterate     9  f =      -401.81  |proj g|=        2.3598
At iterate    10  f =      -401.82  |proj g|=        2.1049
At iterate    11  f =      -401.83  |proj g|=        1.6698
At iterate    12  f =      -401.87  |proj g|=       0.90794
At iterate    13  f =      -401.95  |proj g|=       0.28863
At iterate    14  f =      -402.11  |proj g|=        1.4304
At iterate    15  f =       -402.5  |proj g|=        1.5387
At iterate    16  f =      -402.67  |proj g|=        1.5756
At iterate    17  f =      -403.43  |proj g|=        1.6686
At iterate    18  f =      -404.28  |proj g|=        1.7061
At iterate    19  f =      -404.67  |proj g|=        1.6159
At iterate    20  f =      -404.89  |proj g|=      0.098226
At iterate    21  f =      -404.92  |proj g|=       0.27235
At iterate    22  f =      -404.92  |proj g|=      0.085233
At iterate    23  f =      -404.92  |proj g|=     0.0071727
At iterate    24  f =      -404.92  |proj g|=     0.0071727
At iterate    25  f =      -404.92  |proj g|=      0.015267

iterations 25
function evaluations 34
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0152667
final function value -404.922

F = -404.922
final  value -404.922313 
converged
 
INFO  [03:15:05.321] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:15:05.373] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:15:05.379] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:15:39.916] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:16:13.730] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:16:47.893] [mlr3]  Finished benchmark 
INFO  [03:16:47.959] [bbotk] Result of batch 76: 
INFO  [03:16:47.961] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:16:47.961] [bbotk]                   3              2805      0.4580655        0.559 -0.8874387 
INFO  [03:16:47.961] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:16:47.961] [bbotk]          <NA>   0.9744099 63f30f7a-078e-4caf-89e7-d5e4ea7a2649 
DEBUG [03:16:48.871] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.223097e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001223097 0.1253099 
  - best initial criterion value(s) :  381.3282 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -381.33  |proj g|=       1.5065
At iterate     1  f =      -386.92  |proj g|=        3.9157
At iterate     2  f =      -393.57  |proj g|=        3.4776
At iterate     3  f =      -397.77  |proj g|=        3.1005
At iterate     4  f =      -408.17  |proj g|=        2.2592
At iterate     5  f =       -415.1  |proj g|=        1.6831
At iterate     6  f =      -415.51  |proj g|=        1.5234
At iterate     7  f =      -415.62  |proj g|=        1.6747
At iterate     8  f =      -415.73  |proj g|=       0.34342
At iterate     9  f =      -415.74  |proj g|=        0.4934
At iterate    10  f =      -415.74  |proj g|=       0.49151
At iterate    11  f =      -415.74  |proj g|=       0.47569
At iterate    12  f =      -415.74  |proj g|=       0.48023
At iterate    13  f =      -415.75  |proj g|=       0.51534
At iterate    14  f =      -415.76  |proj g|=       0.67708
At iterate    15  f =       -415.8  |proj g|=        1.0463
At iterate    16  f =      -415.86  |proj g|=        1.5466
At iterate    17  f =       -415.9  |proj g|=        1.0455
At iterate    18  f =      -416.08  |proj g|=        1.6194
At iterate    19  f =      -416.58  |proj g|=        1.7092
At iterate    20  f =      -416.92  |proj g|=         1.641
At iterate    21  f =      -417.22  |proj g|=       0.89801
At iterate    22  f =      -417.27  |proj g|=       0.22283
At iterate    23  f =      -417.27  |proj g|=      0.019091
At iterate    24  f =      -417.27  |proj g|=      0.006346
At iterate    25  f =      -417.27  |proj g|=     0.0097002

iterations 25
function evaluations 33
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00970017
final function value -417.274

F = -417.274
final  value -417.273585 
converged
 
INFO  [03:16:48.875] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:16:48.936] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:16:48.943] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:17:06.413] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:17:23.977] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:17:41.361] [mlr3]  Finished benchmark 
INFO  [03:17:41.426] [bbotk] Result of batch 77: 
INFO  [03:17:41.428] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:17:41.428] [bbotk]                   6              1403     0.07289964        0.611 -0.8870235 
INFO  [03:17:41.428] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:17:41.428] [bbotk]          <NA>   0.9760184 91aece58-93ac-4882-9fd2-e72083a56b0f 
DEBUG [03:17:42.460] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.221966e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001221966 0.1253555 
  - best initial criterion value(s) :  327.0997 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -327.1  |proj g|=       4.9884
At iterate     1  f =      -345.12  |proj g|=         4.028
At iterate     2  f =      -383.59  |proj g|=        2.3373
At iterate     3  f =      -387.67  |proj g|=        2.0275
At iterate     4  f =      -395.05  |proj g|=        1.4625
At iterate     5  f =      -395.39  |proj g|=       0.12347
At iterate     6  f =      -395.49  |proj g|=        2.8966
At iterate     7  f =      -395.49  |proj g|=        2.4565
At iterate     8  f =      -395.49  |proj g|=        2.4193
At iterate     9  f =      -395.49  |proj g|=        2.3449
At iterate    10  f =       -395.5  |proj g|=        2.2283
At iterate    11  f =       -395.5  |proj g|=         2.036
At iterate    12  f =      -395.51  |proj g|=        1.7196
At iterate    13  f =      -395.53  |proj g|=        1.1677
At iterate    14  f =      -395.59  |proj g|=        0.1984
At iterate    15  f =      -395.72  |proj g|=          1.33
At iterate    16  f =      -395.97  |proj g|=        1.4588
At iterate    17  f =       -396.5  |proj g|=        1.5774
At iterate    18  f =      -396.99  |proj g|=        1.6735
At iterate    19  f =      -397.72  |proj g|=        1.6444
At iterate    20  f =      -398.27  |proj g|=        1.5259
At iterate    21  f =      -398.36  |proj g|=       0.16567
At iterate    22  f =      -398.36  |proj g|=      0.075521
At iterate    23  f =      -398.37  |proj g|=      0.048848
At iterate    24  f =      -398.37  |proj g|=       0.01001
At iterate    25  f =      -398.37  |proj g|=      0.034587
At iterate    26  f =      -398.37  |proj g|=       0.01001

iterations 26
function evaluations 34
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0100096
final function value -398.366

F = -398.366
final  value -398.365738 
converged
 
INFO  [03:17:42.464] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:17:42.516] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:17:42.523] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:18:34.332] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:19:26.202] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:20:17.905] [mlr3]  Finished benchmark 
INFO  [03:20:17.970] [bbotk] Result of batch 78: 
INFO  [03:20:17.972] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:20:17.972] [bbotk]                   5              4356      0.2026233         0.74 -0.8887323 
INFO  [03:20:17.972] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:20:17.972] [bbotk]          <NA>   0.9771308 f9f2eda5-3a6a-41de-8a29-2f91812a3dd6 
DEBUG [03:20:18.856] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.220871e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001220871 0.1248989 
  - best initial criterion value(s) :  334.6897 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -334.69  |proj g|=       3.6687
At iterate     1  f =       -354.1  |proj g|=        2.6555
At iterate     2  f =      -375.32  |proj g|=        1.8242
At iterate     3  f =      -379.68  |proj g|=        1.3347
At iterate     4  f =      -380.13  |proj g|=         3.804
At iterate     5  f =      -380.37  |proj g|=         3.907
At iterate     6  f =      -380.38  |proj g|=        3.3461
At iterate     7  f =      -380.38  |proj g|=        3.3772
At iterate     8  f =      -380.39  |proj g|=        3.4123
At iterate     9  f =      -380.39  |proj g|=        3.7553
At iterate    10  f =      -380.41  |proj g|=        4.1161
At iterate    11  f =      -380.44  |proj g|=        4.8448
At iterate    12  f =      -380.51  |proj g|=        5.7663
At iterate    13  f =      -380.69  |proj g|=        7.2636
At iterate    14  f =      -381.03  |proj g|=        8.9589
At iterate    15  f =      -381.82  |proj g|=        10.727
At iterate    16  f =       -382.6  |proj g|=        9.6675
At iterate    17  f =      -383.88  |proj g|=         1.933
At iterate    18  f =      -384.24  |proj g|=       0.60979
At iterate    19  f =      -384.28  |proj g|=       0.12279
At iterate    20  f =      -384.28  |proj g|=       0.12277
At iterate    21  f =      -384.28  |proj g|=       0.12277
At iterate    22  f =      -384.28  |proj g|=       0.01366

iterations 22
function evaluations 30
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0136596
final function value -384.284

F = -384.284
final  value -384.283555 
converged
 
INFO  [03:20:18.860] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:20:18.915] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:20:18.922] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:20:27.508] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:20:36.346] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:20:37.237] [mlr3]  Finished benchmark 
INFO  [03:20:37.303] [bbotk] Result of batch 79: 
INFO  [03:20:37.305] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:20:37.305] [bbotk]                   9               634      0.1891135        0.595 -0.8904706 
INFO  [03:20:37.305] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:20:37.305] [bbotk]          <NA>   0.8183462 dc84603d-2730-4625-8061-bca8db6eaeff 
DEBUG [03:20:38.158] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.211625e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001211624 0.1240218 
  - best initial criterion value(s) :  335.8497 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -335.85  |proj g|=       4.8778
At iterate     1  f =      -346.87  |proj g|=        4.4769
At iterate     2  f =      -350.26  |proj g|=        4.5232
At iterate     3  f =      -372.14  |proj g|=        3.2436
At iterate     4  f =      -385.65  |proj g|=        2.3985
At iterate     5  f =      -392.81  |proj g|=        1.8582
At iterate     6  f =       -396.3  |proj g|=        1.5527
At iterate     7  f =      -396.66  |proj g|=       0.46558
At iterate     8  f =      -396.68  |proj g|=        2.0978
At iterate     9  f =       -396.7  |proj g|=        1.1207
At iterate    10  f =       -396.7  |proj g|=        1.0821
At iterate    11  f =      -396.73  |proj g|=       0.60944
At iterate    12  f =      -396.88  |proj g|=       0.90432
At iterate    13  f =      -397.25  |proj g|=        1.5365
At iterate    14  f =      -397.51  |proj g|=        1.5635
At iterate    15  f =      -397.63  |proj g|=        1.1697
At iterate    16  f =      -397.67  |proj g|=      0.044021
At iterate    17  f =      -397.67  |proj g|=       0.12186
At iterate    18  f =      -397.67  |proj g|=      0.012051

iterations 18
function evaluations 31
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0120514
final function value -397.673

F = -397.673
final  value -397.672973 
converged
 
INFO  [03:20:38.162] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:20:38.217] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:20:38.223] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:21:11.736] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:21:44.947] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:22:18.244] [mlr3]  Finished benchmark 
INFO  [03:22:18.309] [bbotk] Result of batch 80: 
INFO  [03:22:18.311] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:22:18.311] [bbotk]                   4              2794      0.3096713        0.585 -0.8884825 
INFO  [03:22:18.311] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:22:18.311] [bbotk]          <NA>   0.9759985 05597a9f-dfb3-4735-99c9-b2ca922ba920 
DEBUG [03:22:19.152] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.210316e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001210316 0.1233936 
  - best initial criterion value(s) :  341.2927 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -341.29  |proj g|=       6.3158
At iterate     1  f =      -355.83  |proj g|=        4.2205
At iterate     2  f =      -372.02  |proj g|=        5.2915
At iterate     3  f =      -375.59  |proj g|=        5.0498
At iterate     4  f =      -387.84  |proj g|=        4.3216
At iterate     5  f =      -409.77  |proj g|=        3.1661
At iterate     6  f =      -423.96  |proj g|=        13.372
At iterate     7  f =      -427.07  |proj g|=        13.369
At iterate     8  f =      -427.22  |proj g|=        13.367
At iterate     9  f =      -427.67  |proj g|=        13.337
At iterate    10  f =      -429.26  |proj g|=        13.221
At iterate    11  f =      -432.49  |proj g|=        3.8529
At iterate    12  f =      -435.19  |proj g|=        2.7174
At iterate    13  f =      -436.12  |proj g|=       0.12144
At iterate    14  f =      -436.37  |proj g|=       0.12128
At iterate    15  f =       -436.4  |proj g|=       0.12121
At iterate    16  f =      -436.41  |proj g|=       0.12119
At iterate    17  f =      -436.41  |proj g|=       0.12119
At iterate    18  f =      -436.41  |proj g|=      0.006736

iterations 18
function evaluations 29
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00673596
final function value -436.405

F = -436.405
final  value -436.405190 
converged
 
INFO  [03:22:19.156] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:22:19.210] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:22:19.216] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:22:20.149] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:22:24.125] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:22:28.269] [mlr3]  Finished benchmark 
INFO  [03:22:28.346] [bbotk] Result of batch 81: 
INFO  [03:22:28.348] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:22:28.348] [bbotk]                   8               242       0.279546        0.579 -0.8859321 
INFO  [03:22:28.348] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:22:28.348] [bbotk]          <NA>   0.8176133 7e02364b-1394-4519-bf82-9ce226d222dd 
DEBUG [03:22:29.187] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.20148e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.00120148 0.1225879 
  - best initial criterion value(s) :  320.5716 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -320.57  |proj g|=       6.0832
At iterate     1  f =      -326.21  |proj g|=        2.9079
At iterate     2  f =      -331.15  |proj g|=        2.8535
At iterate     3  f =      -332.96  |proj g|=        2.7535
At iterate     4  f =      -335.88  |proj g|=        2.5158
At iterate     5  f =      -339.93  |proj g|=        2.1994
At iterate     6  f =      -345.94  |proj g|=        1.4931
At iterate     7  f =       -346.2  |proj g|=       0.65332
At iterate     8  f =      -346.84  |proj g|=       0.44907
At iterate     9  f =      -347.21  |proj g|=        1.3335
At iterate    10  f =      -348.03  |proj g|=        1.4075
At iterate    11  f =      -351.91  |proj g|=        1.6053
At iterate    12  f =      -357.66  |proj g|=        1.7737
At iterate    13  f =      -359.72  |proj g|=        1.7273
At iterate    14  f =      -361.28  |proj g|=        1.5066
At iterate    15  f =      -361.84  |proj g|=       0.18647
At iterate    16  f =      -361.85  |proj g|=       0.12059
At iterate    17  f =      -361.85  |proj g|=       0.12059
At iterate    18  f =      -361.85  |proj g|=      0.024799

iterations 18
function evaluations 27
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0247988
final function value -361.854

F = -361.854
final  value -361.853861 
converged
 
INFO  [03:22:29.191] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:22:29.246] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:22:29.252] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:23:26.094] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:24:23.424] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:25:19.998] [mlr3]  Finished benchmark 
INFO  [03:25:20.063] [bbotk] Result of batch 82: 
INFO  [03:25:20.065] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:25:20.065] [bbotk]                   4              4810      0.3067775        0.574 -0.8961498 
INFO  [03:25:20.065] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:25:20.065] [bbotk]          <NA>   0.9760702 8cf5509d-defd-49e3-95d2-290c9914260d 
DEBUG [03:25:20.937] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.200214e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001200214 0.1222303 
  - best initial criterion value(s) :  384.3608 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -384.36  |proj g|=       5.1078
At iterate     1  f =      -388.83  |proj g|=        4.8193
At iterate     2  f =      -395.92  |proj g|=        4.5523
At iterate     3  f =      -399.46  |proj g|=         4.318
At iterate     4  f =      -404.43  |proj g|=        3.9727
At iterate     5  f =      -417.68  |proj g|=        3.2002
At iterate     6  f =       -435.3  |proj g|=        2.3715
At iterate     7  f =      -445.95  |proj g|=        1.5003
At iterate     8  f =      -446.16  |proj g|=         1.252
At iterate     9  f =       -446.3  |proj g|=        2.9106
At iterate    10  f =      -446.35  |proj g|=        1.3306
At iterate    11  f =      -446.41  |proj g|=       0.95992
At iterate    12  f =      -446.84  |proj g|=       0.76428
At iterate    13  f =      -447.33  |proj g|=        1.2655
At iterate    14  f =      -447.53  |proj g|=       0.76657
At iterate    15  f =      -447.55  |proj g|=       0.12009
At iterate    16  f =      -447.55  |proj g|=       0.12008
At iterate    17  f =      -447.55  |proj g|=       0.12008
At iterate    18  f =      -447.55  |proj g|=     0.0082132
At iterate    19  f =      -447.55  |proj g|=     0.0069824
At iterate    20  f =      -447.55  |proj g|=     0.0069824

iterations 20
function evaluations 31
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00698236
final function value -447.553

F = -447.553
final  value -447.552601 
converged
 
INFO  [03:25:20.941] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:25:20.997] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:25:21.003] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:25:32.346] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:25:44.096] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:25:55.223] [mlr3]  Finished benchmark 
INFO  [03:25:55.288] [bbotk] Result of batch 83: 
INFO  [03:25:55.289] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:25:55.289] [bbotk]                   5               879      0.2397451         0.59 -0.8860202 
INFO  [03:25:55.289] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:25:55.289] [bbotk]          <NA>   0.9769669 b1d86d8a-0ea0-4325-ae44-c0e210cf07c9 
DEBUG [03:25:56.312] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.198956e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001198956 0.1223062 
  - best initial criterion value(s) :  359.3997 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -359.4  |proj g|=       3.7052
At iterate     1  f =      -384.63  |proj g|=        1.4295
At iterate     2  f =      -406.21  |proj g|=        1.9665
At iterate     3  f =      -412.71  |proj g|=        1.5262
At iterate     4  f =      -413.46  |proj g|=         1.857
At iterate     5  f =      -414.66  |proj g|=         6.844
At iterate     6  f =      -414.78  |proj g|=        4.4785
At iterate     7  f =       -414.8  |proj g|=        4.4378
At iterate     8  f =       -414.8  |proj g|=        4.4787
At iterate     9  f =       -414.8  |proj g|=        4.4933
At iterate    10  f =      -414.81  |proj g|=        4.5998
At iterate    11  f =      -414.81  |proj g|=        4.7254
At iterate    12  f =      -414.83  |proj g|=         4.989
At iterate    13  f =      -414.88  |proj g|=        5.4063
At iterate    14  f =      -415.01  |proj g|=        6.3443
At iterate    15  f =      -415.32  |proj g|=        7.3115
At iterate    16  f =      -416.13  |proj g|=         9.837
At iterate    17  f =      -416.39  |proj g|=        7.7438
At iterate    18  f =      -417.59  |proj g|=        8.7568
At iterate    19  f =      -419.09  |proj g|=         5.086
At iterate    20  f =      -419.71  |proj g|=       0.80482
At iterate    21  f =      -419.75  |proj g|=         0.526
At iterate    22  f =      -419.75  |proj g|=       0.10374
At iterate    23  f =      -419.75  |proj g|=       0.12022
At iterate    24  f =      -419.75  |proj g|=      0.030523

iterations 24
function evaluations 32
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0305235
final function value -419.752

F = -419.752
final  value -419.751678 
converged
 
INFO  [03:25:56.316] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:25:56.370] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:25:56.377] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:26:49.585] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:27:43.138] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:28:37.238] [mlr3]  Finished benchmark 
INFO  [03:28:37.304] [bbotk] Result of batch 84: 
INFO  [03:28:37.305] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:28:37.305] [bbotk]                   4              4522      0.3932606        0.739 -0.8887951 
INFO  [03:28:37.305] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:28:37.305] [bbotk]          <NA>   0.9761332 13e77350-c4b3-4446-a9ac-4e740827482b 
DEBUG [03:28:38.201] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.197373e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001197373 0.1215819 
  - best initial criterion value(s) :  340.9638 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -340.96  |proj g|=       4.7534
At iterate     1  f =      -347.22  |proj g|=        4.2158
At iterate     2  f =      -391.98  |proj g|=        1.7398
At iterate     3  f =      -393.51  |proj g|=       0.53823
At iterate     4  f =      -394.07  |proj g|=       0.53285
At iterate     5  f =      -394.11  |proj g|=       0.89139
At iterate     6  f =      -394.11  |proj g|=       0.72754
At iterate     7  f =      -394.11  |proj g|=       0.76605
At iterate     8  f =      -394.11  |proj g|=       0.77339
At iterate     9  f =      -394.12  |proj g|=       0.82826
At iterate    10  f =      -394.12  |proj g|=       0.88889
At iterate    11  f =      -394.14  |proj g|=        1.0158
At iterate    12  f =      -394.19  |proj g|=        1.2283
At iterate    13  f =      -394.32  |proj g|=        1.5073
At iterate    14  f =      -394.64  |proj g|=         1.661
At iterate    15  f =      -394.82  |proj g|=        1.1222
At iterate    16  f =      -395.06  |proj g|=        1.4034
At iterate    17  f =      -395.09  |proj g|=       0.82747
At iterate    18  f =      -395.09  |proj g|=       0.96776
At iterate    19  f =      -395.09  |proj g|=       0.98668
At iterate    20  f =      -395.09  |proj g|=        1.0083
At iterate    21  f =      -395.09  |proj g|=        1.0323
At iterate    22  f =      -395.09  |proj g|=        1.0541
At iterate    23  f =       -395.1  |proj g|=        1.0373
At iterate    24  f =       -395.1  |proj g|=       0.89568
At iterate    25  f =      -395.11  |proj g|=       0.50968
At iterate    26  f =      -395.11  |proj g|=       0.17214
At iterate    27  f =      -395.11  |proj g|=      0.019518
At iterate    28  f =      -395.11  |proj g|=      0.019517

iterations 28
function evaluations 38
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0195174
final function value -395.113

F = -395.113
final  value -395.112974 
converged
 
INFO  [03:28:38.205] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:28:38.258] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:28:38.265] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:29:16.030] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:29:53.326] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:29:54.214] [mlr3]  Finished benchmark 
INFO  [03:29:54.278] [bbotk] Result of batch 85: 
INFO  [03:29:54.280] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:29:54.280] [bbotk]                   8              3138      0.4018944        0.569 -0.8928092 
INFO  [03:29:54.280] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:29:54.280] [bbotk]          <NA>   0.8180731 123aad0f-c1db-4f6f-9c34-6fe337332daa 
DEBUG [03:29:55.181] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.18919e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.00118919 0.1210778 
  - best initial criterion value(s) :  425.7249 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -425.72  |proj g|=       4.1221
At iterate     1  f =      -430.21  |proj g|=        3.6782
At iterate     2  f =      -461.64  |proj g|=        1.5731
At iterate     3  f =       -461.7  |proj g|=        1.6062
At iterate     4  f =      -461.93  |proj g|=       0.34512
At iterate     5  f =      -461.95  |proj g|=       0.18148
At iterate     6  f =      -461.95  |proj g|=       0.11899
At iterate     7  f =      -461.95  |proj g|=        0.1302
At iterate     8  f =      -461.97  |proj g|=       0.36068
At iterate     9  f =      -461.97  |proj g|=        0.2845
At iterate    10  f =      -461.98  |proj g|=       0.02799
At iterate    11  f =      -461.98  |proj g|=       0.11898
At iterate    12  f =      -461.98  |proj g|=      0.059571
At iterate    13  f =      -461.98  |proj g|=     0.0076066

iterations 13
function evaluations 24
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00760664
final function value -461.977

F = -461.977
final  value -461.976850 
converged
 
INFO  [03:29:55.185] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:29:55.240] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:29:55.246] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:30:17.543] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:30:38.793] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:31:00.465] [mlr3]  Finished benchmark 
INFO  [03:31:00.531] [bbotk] Result of batch 86: 
INFO  [03:31:00.533] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:31:00.533] [bbotk]                   3              1749      0.3327566        0.623 -0.8856862 
INFO  [03:31:00.533] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:31:00.533] [bbotk]          <NA>   0.9739078 9863c427-c804-4b8d-b3d6-af785164c0a4 
DEBUG [03:31:01.468] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.187238e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001187238 0.1210534 
  - best initial criterion value(s) :  333.1039 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -333.1  |proj g|=       13.183
At iterate     1  f =      -370.79  |proj g|=        1.8331
At iterate     2  f =      -380.52  |proj g|=        2.6427
At iterate     3  f =      -384.03  |proj g|=         2.524
At iterate     4  f =      -385.49  |proj g|=        2.3736
At iterate     5  f =      -387.31  |proj g|=        2.1283
At iterate     6  f =      -389.76  |proj g|=         1.792
At iterate     7  f =      -418.17  |proj g|=        1.4125
At iterate     8  f =      -443.67  |proj g|=        4.4647
At iterate     9  f =      -445.04  |proj g|=        1.8904
At iterate    10  f =       -447.3  |proj g|=        1.6296
At iterate    11  f =      -447.63  |proj g|=        1.5416
At iterate    12  f =      -447.74  |proj g|=       0.74019
At iterate    13  f =      -447.75  |proj g|=      0.011004
At iterate    14  f =      -447.75  |proj g|=       0.11901
At iterate    15  f =      -447.75  |proj g|=      0.011004
At iterate    16  f =      -447.75  |proj g|=      0.011004

iterations 16
function evaluations 26
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0110037
final function value -447.753

F = -447.753
final  value -447.752712 
converged
 
INFO  [03:31:01.472] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:31:01.533] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:31:01.540] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:31:10.852] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:31:20.277] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:31:21.183] [mlr3]  Finished benchmark 
INFO  [03:31:21.271] [bbotk] Result of batch 87: 
INFO  [03:31:21.273] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:31:21.273] [bbotk]                   8               706      0.3710774        0.634 -0.8871513 
INFO  [03:31:21.273] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:31:21.273] [bbotk]          <NA>   0.8185568 935f4734-f951-429a-b79c-25f51db17ddd 
DEBUG [03:31:22.174] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.179288e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001179288 0.120183 
  - best initial criterion value(s) :  382.5978 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -382.6  |proj g|=       3.9676
At iterate     1  f =       -398.5  |proj g|=        1.0337
At iterate     2  f =      -436.29  |proj g|=        2.0315
At iterate     3  f =      -437.16  |proj g|=        1.9643
At iterate     4  f =      -443.19  |proj g|=        1.5342
At iterate     5  f =      -445.09  |proj g|=        5.5348
At iterate     6  f =      -445.13  |proj g|=        4.8005
At iterate     7  f =      -445.19  |proj g|=        3.7463
At iterate     8  f =      -445.36  |proj g|=        2.3567
At iterate     9  f =      -446.13  |proj g|=        1.3961
At iterate    10  f =      -447.59  |proj g|=        1.5463
At iterate    11  f =      -448.69  |proj g|=        1.6015
At iterate    12  f =      -449.01  |proj g|=        1.5219
At iterate    13  f =      -449.09  |proj g|=      0.079805
At iterate    14  f =      -449.09  |proj g|=       0.11817
At iterate    15  f =      -449.09  |proj g|=       0.11816
At iterate    16  f =      -449.09  |proj g|=      0.063245

iterations 16
function evaluations 23
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0632454
final function value -449.088

F = -449.088
final  value -449.088236 
converged
 
INFO  [03:31:22.179] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:31:22.239] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:31:22.246] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:32:05.242] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:32:48.207] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:33:31.357] [mlr3]  Finished benchmark 
INFO  [03:33:31.422] [bbotk] Result of batch 88: 
INFO  [03:33:31.424] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:33:31.424] [bbotk]                   5              3595       0.252557        0.583 -0.8874035 
INFO  [03:33:31.424] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:33:31.424] [bbotk]          <NA>   0.9770992 2baf8fe6-4b24-4c2c-a649-d3f9ddefe224 
DEBUG [03:33:32.403] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.177972e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001177972 0.1198096 
  - best initial criterion value(s) :  378.8154 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -378.82  |proj g|=      0.64387
At iterate     1  f =      -431.41  |proj g|=        13.244
At iterate     2  f =      -432.81  |proj g|=        13.206
At iterate     3  f =      -433.44  |proj g|=        13.178
At iterate     4  f =      -434.21  |proj g|=        13.156
At iterate     5  f =      -434.27  |proj g|=        13.156
At iterate     6  f =      -434.27  |proj g|=        13.156
At iterate     7  f =      -434.28  |proj g|=        13.156
At iterate     8  f =      -434.28  |proj g|=        13.156
At iterate     9  f =      -434.28  |proj g|=        13.156
At iterate    10  f =      -434.28  |proj g|=        13.155
At iterate    11  f =      -434.28  |proj g|=        13.155
At iterate    12  f =       -434.3  |proj g|=        13.153
At iterate    13  f =      -434.34  |proj g|=        13.148
At iterate    14  f =      -434.44  |proj g|=        13.134
At iterate    15  f =      -434.72  |proj g|=        13.099
At iterate    16  f =      -435.39  |proj g|=         13.01
At iterate    17  f =       -436.8  |proj g|=        9.0119
At iterate    18  f =      -438.53  |proj g|=        2.6795
At iterate    19  f =      -438.65  |proj g|=       0.24986
At iterate    20  f =      -438.65  |proj g|=      0.027741
At iterate    21  f =      -438.65  |proj g|=       0.11783
At iterate    22  f =      -438.65  |proj g|=      0.041926
At iterate    23  f =      -438.65  |proj g|=      0.015153

iterations 23
function evaluations 28
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0151534
final function value -438.654

F = -438.654
final  value -438.654165 
converged
 
INFO  [03:33:32.407] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:33:32.465] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:33:32.471] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:33:55.278] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:33:56.172] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:34:19.969] [mlr3]  Finished benchmark 
INFO  [03:34:20.037] [bbotk] Result of batch 89: 
INFO  [03:34:20.038] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:34:20.038] [bbotk]                   9              1893      0.3093027        0.689 -0.8888986 
INFO  [03:34:20.038] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:34:20.038] [bbotk]          <NA>   0.8177669 2f62b8d7-c54e-4556-b0f4-c6e573abbf36 
DEBUG [03:34:20.996] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.170371e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001170371 0.1191889 
  - best initial criterion value(s) :  395.3988 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -395.4  |proj g|=       7.5193
At iterate     1  f =      -400.95  |proj g|=        2.8262
At iterate     2  f =      -420.31  |proj g|=        2.7024
At iterate     3  f =      -423.64  |proj g|=        2.4796
At iterate     4  f =      -430.14  |proj g|=        1.9422
At iterate     5  f =      -434.43  |proj g|=        1.5471
At iterate     6  f =      -434.72  |proj g|=        1.4444
At iterate     7  f =      -434.76  |proj g|=       0.41916
At iterate     8  f =      -434.77  |proj g|=       0.24691
At iterate     9  f =      -434.77  |proj g|=       0.37678
At iterate    10  f =      -434.78  |proj g|=       0.58728
At iterate    11  f =      -434.82  |proj g|=         1.427
At iterate    12  f =       -434.9  |proj g|=        1.4612
At iterate    13  f =      -435.13  |proj g|=        1.5258
At iterate    14  f =      -435.68  |proj g|=        1.6349
At iterate    15  f =       -436.2  |proj g|=         1.617
At iterate    16  f =       -436.8  |proj g|=        1.4468
At iterate    17  f =      -436.91  |proj g|=       0.13946
At iterate    18  f =      -436.92  |proj g|=      0.019922
At iterate    19  f =      -436.92  |proj g|=       0.11724
At iterate    20  f =      -436.92  |proj g|=       0.01694

iterations 20
function evaluations 30
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0169395
final function value -436.917

F = -436.917
final  value -436.916570 
converged
 
INFO  [03:34:21.000] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:34:21.062] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:34:21.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:34:52.296] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:35:23.111] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:35:54.421] [mlr3]  Finished benchmark 
INFO  [03:35:54.497] [bbotk] Result of batch 90: 
INFO  [03:35:54.499] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:35:54.499] [bbotk]                   4              2615      0.4268839        0.655 -0.8896193 
INFO  [03:35:54.499] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:35:54.499] [bbotk]          <NA>   0.9760023 154e7f3b-9b56-418f-85c0-8bdf62b55842 
DEBUG [03:35:55.408] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.16889e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.00116889 0.1189474 
  - best initial criterion value(s) :  386.2074 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -386.21  |proj g|=       5.2165
At iterate     1  f =      -386.72  |proj g|=        9.4882
At iterate     2  f =      -411.32  |proj g|=        1.9264
At iterate     3  f =      -419.77  |proj g|=         4.486
At iterate     4  f =      -435.98  |proj g|=        3.9676
At iterate     5  f =      -445.77  |proj g|=        3.5481
At iterate     6  f =      -468.73  |proj g|=        2.5617
At iterate     7  f =      -477.44  |proj g|=        5.7855
At iterate     8  f =      -484.09  |proj g|=        1.7671
At iterate     9  f =      -484.54  |proj g|=         1.767
At iterate    10  f =      -484.54  |proj g|=        1.7669
At iterate    11  f =      -484.54  |proj g|=        1.7668
At iterate    12  f =      -484.55  |proj g|=        1.7666
At iterate    13  f =      -484.55  |proj g|=        1.7657
At iterate    14  f =      -484.56  |proj g|=        1.7637
At iterate    15  f =      -484.58  |proj g|=        1.7576
At iterate    16  f =      -484.63  |proj g|=        1.7423
At iterate    17  f =      -484.75  |proj g|=        1.7055
At iterate    18  f =         -485  |proj g|=        1.2097
At iterate    19  f =      -485.41  |proj g|=        1.0739
At iterate    20  f =      -485.58  |proj g|=      0.084912
At iterate    21  f =      -485.58  |proj g|=       0.11695
At iterate    22  f =      -485.58  |proj g|=     0.0090835
At iterate    23  f =      -485.58  |proj g|=     0.0090835

iterations 23
function evaluations 35
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00908349
final function value -485.583

F = -485.583
final  value -485.583347 
converged
 
INFO  [03:35:55.412] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:35:55.465] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:35:55.471] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:36:00.630] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:36:05.830] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:36:11.272] [mlr3]  Finished benchmark 
INFO  [03:36:11.337] [bbotk] Result of batch 91: 
INFO  [03:36:11.339] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:36:11.339] [bbotk]                   3               340      0.3587867        0.603 -0.8851747 
INFO  [03:36:11.339] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:36:11.339] [bbotk]          <NA>   0.9722958 013d6ac1-b677-4ad5-82b2-b68c8dead082 
DEBUG [03:36:12.443] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.166643e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001166643 0.1187438 
  - best initial criterion value(s) :  435.6248 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -435.62  |proj g|=       3.8867
At iterate     1  f =      -436.17  |proj g|=        3.8009
At iterate     2  f =      -436.95  |proj g|=        3.8112
At iterate     3  f =      -437.78  |proj g|=        3.7849
At iterate     4  f =      -442.26  |proj g|=        3.4926
At iterate     5  f =      -448.89  |proj g|=        3.0714
At iterate     6  f =      -459.32  |proj g|=        2.5077
At iterate     7  f =      -462.09  |proj g|=         2.319
At iterate     8  f =      -467.22  |proj g|=         1.825
At iterate     9  f =      -468.05  |proj g|=        8.7931
At iterate    10  f =      -469.15  |proj g|=       0.50783
At iterate    11  f =      -469.28  |proj g|=       0.84395
At iterate    12  f =      -469.29  |proj g|=       0.11679
At iterate    13  f =      -469.29  |proj g|=      0.012992
At iterate    14  f =      -469.29  |proj g|=      0.012992
At iterate    15  f =      -469.29  |proj g|=      0.012992

iterations 15
function evaluations 22
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0129915
final function value -469.291

F = -469.291
final  value -469.291397 
converged
 
INFO  [03:36:12.447] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:36:12.501] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:36:12.508] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:37:06.536] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:37:07.441] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:37:08.267] [mlr3]  Finished benchmark 
INFO  [03:37:08.331] [bbotk] Result of batch 92: 
INFO  [03:37:08.333] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [03:37:08.333] [bbotk]                  10              4609      0.2198169         0.83 -0.886508 
INFO  [03:37:08.333] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:37:08.333] [bbotk]          <NA>   0.6589687 4dc5305a-d813-47d2-a77d-cb42197ed19b 
DEBUG [03:37:09.399] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.197771e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001197771 0.1235019 
  - best initial criterion value(s) :  408.2498 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -408.25  |proj g|=       12.382
At iterate     1  f =      -433.85  |proj g|=        3.2615
At iterate     2  f =      -443.71  |proj g|=        2.8752
At iterate     3  f =      -445.03  |proj g|=        2.7361
At iterate     4  f =       -449.4  |proj g|=        2.0992
At iterate     5  f =      -456.05  |proj g|=        1.0267
At iterate     6  f =      -456.28  |proj g|=        1.6273
At iterate     7  f =      -457.03  |proj g|=        1.5066
At iterate     8  f =      -457.17  |proj g|=        1.4213
At iterate     9  f =      -457.93  |proj g|=        1.3423
At iterate    10  f =      -460.98  |proj g|=        1.8957
At iterate    11  f =      -471.82  |proj g|=        12.414
At iterate    12  f =      -486.46  |proj g|=        13.102
At iterate    13  f =      -496.25  |proj g|=        13.167
At iterate    14  f =      -503.22  |proj g|=        13.036
At iterate    15  f =      -505.37  |proj g|=        10.435
At iterate    16  f =      -506.99  |proj g|=        1.4898
At iterate    17  f =      -507.06  |proj g|=       0.12155
At iterate    18  f =      -507.08  |proj g|=       0.24842
At iterate    19  f =      -507.09  |proj g|=       0.12148
At iterate    20  f =      -507.09  |proj g|=       0.12148
At iterate    21  f =      -507.09  |proj g|=     0.0076344
At iterate    22  f =      -507.09  |proj g|=     0.0076344

iterations 22
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0076344
final function value -507.088

F = -507.088
final  value -507.087953 
converged
 
INFO  [03:37:09.403] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:37:09.458] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:37:09.465] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:37:50.433] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:38:30.541] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:39:10.838] [mlr3]  Finished benchmark 
INFO  [03:39:10.914] [bbotk] Result of batch 93: 
INFO  [03:39:10.916] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:39:10.916] [bbotk]                   5              3391      0.3584745        0.768 -0.8833666 
INFO  [03:39:10.916] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:39:10.916] [bbotk]          <NA>   0.9769523 96569f2f-646a-415a-bf0f-e19c8053a3ae 
DEBUG [03:39:11.846] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.196286e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001196286 0.1232964 
  - best initial criterion value(s) :  440.4539 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -440.45  |proj g|=        3.932
At iterate     1  f =      -458.11  |proj g|=        11.401
At iterate     2  f =      -479.01  |proj g|=        13.152
At iterate     3  f =      -485.23  |proj g|=        4.1259
At iterate     4  f =      -485.31  |proj g|=        3.5845
At iterate     5  f =      -485.44  |proj g|=         1.447
At iterate     6  f =      -485.49  |proj g|=       0.28191
At iterate     7  f =      -485.49  |proj g|=       0.22653
At iterate     8  f =      -485.49  |proj g|=       0.18714
At iterate     9  f =      -485.49  |proj g|=       0.13219
At iterate    10  f =      -485.49  |proj g|=        0.1214
At iterate    11  f =      -485.49  |proj g|=       0.12141
At iterate    12  f =       -485.5  |proj g|=       0.28307
At iterate    13  f =      -485.53  |proj g|=       0.55688
At iterate    14  f =       -485.6  |proj g|=       0.89409
At iterate    15  f =      -485.69  |proj g|=       0.72006
At iterate    16  f =      -485.78  |proj g|=       0.49019
At iterate    17  f =      -485.78  |proj g|=       0.58264
At iterate    18  f =      -485.78  |proj g|=       0.59551
At iterate    19  f =      -485.78  |proj g|=       0.60224
At iterate    20  f =      -485.78  |proj g|=       0.61263
At iterate    21  f =      -485.78  |proj g|=       0.62389
At iterate    22  f =      -485.78  |proj g|=       0.63452
At iterate    23  f =      -485.78  |proj g|=       0.62873
At iterate    24  f =      -485.79  |proj g|=       0.56495
At iterate    25  f =      -485.79  |proj g|=       0.37068
At iterate    26  f =      -485.79  |proj g|=        0.1564
At iterate    27  f =      -485.79  |proj g|=      0.012345
At iterate    28  f =      -485.79  |proj g|=      0.012345

iterations 28
function evaluations 38
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0123451
final function value -485.791

F = -485.791
final  value -485.790612 
converged
 
INFO  [03:39:11.850] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:39:11.903] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:39:11.909] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:39:12.783] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:39:52.777] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:40:32.289] [mlr3]  Finished benchmark 
INFO  [03:40:32.355] [bbotk] Result of batch 94: 
INFO  [03:40:32.357] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:40:32.357] [bbotk]                   8              3288      0.2762154        0.612 -0.8856271 
INFO  [03:40:32.357] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:40:32.357] [bbotk]          <NA>   0.8184369 0a3d0494-d1b0-4ac5-8808-10a92bb2b814 
DEBUG [03:40:33.421] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.18881e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.00118881 0.1225375 
  - best initial criterion value(s) :  454.5511 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -454.55  |proj g|=       11.232
At iterate     1  f =      -466.25  |proj g|=         2.189
At iterate     2  f =      -487.69  |proj g|=        3.3451
At iterate     3  f =      -496.45  |proj g|=        2.7434
At iterate     4  f =       -512.3  |proj g|=         1.718
At iterate     5  f =      -513.02  |proj g|=        1.6276
At iterate     6  f =      -513.56  |proj g|=        1.0098
At iterate     7  f =      -513.58  |proj g|=       0.20981
At iterate     8  f =      -513.58  |proj g|=      0.093842
At iterate     9  f =      -513.59  |proj g|=        0.2211
At iterate    10  f =      -513.64  |proj g|=       0.95299
At iterate    11  f =      -513.76  |proj g|=        1.9325
At iterate    12  f =      -514.07  |proj g|=        3.6098
At iterate    13  f =      -514.82  |proj g|=        5.9234
At iterate    14  f =      -516.01  |proj g|=        8.6785
At iterate    15  f =      -516.71  |proj g|=        5.0736
At iterate    16  f =      -517.21  |proj g|=       0.16194
At iterate    17  f =      -517.21  |proj g|=       0.12056
At iterate    18  f =      -517.21  |proj g|=       0.12056
At iterate    19  f =      -517.21  |proj g|=      0.068826

iterations 19
function evaluations 28
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0688258
final function value -517.213

F = -517.213
final  value -517.213153 
converged
 
INFO  [03:40:33.425] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:40:33.480] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:40:33.495] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:40:57.225] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:41:20.701] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:41:44.280] [mlr3]  Finished benchmark 
INFO  [03:41:44.346] [bbotk] Result of batch 95: 
INFO  [03:41:44.348] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:41:44.348] [bbotk]                   6              1946      0.2131325        0.734 -0.8831479 
INFO  [03:41:44.348] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:41:44.348] [bbotk]          <NA>   0.9773074 67c38b79-03bb-4e0f-a93d-3ebdf72d4464 
DEBUG [03:41:45.476] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.187424e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001187424 0.1224785 
  - best initial criterion value(s) :  439.2092 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -439.21  |proj g|=       3.2527
At iterate     1  f =      -480.64  |proj g|=        6.9739
At iterate     2  f =       -499.3  |proj g|=        12.252
At iterate     3  f =       -499.8  |proj g|=          9.68
At iterate     4  f =      -499.88  |proj g|=        7.5237
At iterate     5  f =      -499.89  |proj g|=        7.3168
At iterate     6  f =       -499.9  |proj g|=        7.1456
At iterate     7  f =      -499.93  |proj g|=        6.8161
At iterate     8  f =      -500.01  |proj g|=        6.2639
At iterate     9  f =      -500.21  |proj g|=         5.259
At iterate    10  f =      -500.75  |proj g|=        3.4179
At iterate    11  f =      -502.15  |proj g|=       0.12113
At iterate    12  f =      -505.14  |proj g|=        1.3965
At iterate    13  f =      -506.71  |proj g|=        1.4066
At iterate    14  f =      -507.47  |proj g|=       0.12071
At iterate    15  f =      -507.58  |proj g|=        1.0645
At iterate    16  f =      -507.59  |proj g|=        1.4092
At iterate    17  f =      -507.59  |proj g|=        1.4538
At iterate    18  f =      -507.59  |proj g|=         1.457
At iterate    19  f =      -507.59  |proj g|=        1.4666
At iterate    20  f =      -507.59  |proj g|=         1.483
At iterate    21  f =      -507.59  |proj g|=        1.5053
At iterate    22  f =      -507.59  |proj g|=        1.5323
At iterate    23  f =      -507.59  |proj g|=        1.5497
At iterate    24  f =       -507.6  |proj g|=        1.5092
At iterate    25  f =      -507.61  |proj g|=        1.2881
At iterate    26  f =      -507.62  |proj g|=        0.7018
At iterate    27  f =      -507.62  |proj g|=       0.25941
At iterate    28  f =      -507.63  |proj g|=      0.014075
At iterate    29  f =      -507.63  |proj g|=      0.010946
At iterate    30  f =      -507.63  |proj g|=      0.010946

iterations 30
function evaluations 36
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0109461
final function value -507.63

F = -507.63
final  value -507.630046 
converged
 
INFO  [03:41:45.480] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:41:45.544] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:41:45.551] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:42:40.301] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:43:34.989] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:43:35.862] [mlr3]  Finished benchmark 
INFO  [03:43:35.926] [bbotk] Result of batch 96: 
INFO  [03:43:35.928] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:43:35.928] [bbotk]                   8              4664       0.181906        0.736 -0.8843259 
INFO  [03:43:35.928] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:43:35.928] [bbotk]          <NA>    0.818552 379ed744-2cbf-46fb-a65c-9e0c42857004 
DEBUG [03:43:36.999] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.180175e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001180175 0.1214886 
  - best initial criterion value(s) :  460.2634 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -460.26  |proj g|=       3.6969
At iterate     1  f =      -476.18  |proj g|=        2.5814
At iterate     2  f =      -491.91  |proj g|=        1.6547
At iterate     3  f =      -492.75  |proj g|=       0.57106
At iterate     4  f =      -492.77  |proj g|=       0.11964
At iterate     5  f =      -492.77  |proj g|=       0.25897
At iterate     6  f =      -493.11  |proj g|=       0.15694
At iterate     7  f =      -493.12  |proj g|=       0.11963
At iterate     8  f =      -493.12  |proj g|=       0.11963
At iterate     9  f =      -493.12  |proj g|=       0.01486

iterations 9
function evaluations 19
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0148603
final function value -493.116

F = -493.116
final  value -493.116107 
converged
 
INFO  [03:43:37.003] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:43:37.057] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:43:37.063] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:44:02.924] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:44:28.752] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:44:55.119] [mlr3]  Finished benchmark 
INFO  [03:44:55.184] [bbotk] Result of batch 97: 
INFO  [03:44:55.186] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:44:55.186] [bbotk]                   5              2152     0.05998744        0.749 -0.8862731 
INFO  [03:44:55.186] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:44:55.186] [bbotk]          <NA>   0.9764576 fc75d9cd-3e80-46f1-ad92-d263e55636ef 
DEBUG [03:44:56.090] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.178679e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001178679 0.1214652 
  - best initial criterion value(s) :  484.2913 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -484.29  |proj g|=       6.4508
At iterate     1  f =      -489.98  |proj g|=        3.2562
At iterate     2  f =      -496.73  |proj g|=        3.1343
At iterate     3  f =       -498.7  |proj g|=        3.0601
At iterate     4  f =      -504.92  |proj g|=        2.6068
At iterate     5  f =      -514.03  |proj g|=         1.521
At iterate     6  f =      -518.16  |proj g|=        2.2575
At iterate     7  f =      -518.23  |proj g|=        1.5438
At iterate     8  f =      -518.67  |proj g|=        1.4236
At iterate     9  f =         -519  |proj g|=       0.44308
At iterate    10  f =      -519.59  |proj g|=        1.9336
At iterate    11  f =      -521.02  |proj g|=        5.1553
At iterate    12  f =      -523.03  |proj g|=        13.056
At iterate    13  f =      -527.71  |proj g|=        12.997
At iterate    14  f =      -530.18  |proj g|=        4.2684
At iterate    15  f =      -531.02  |proj g|=       0.46778
At iterate    16  f =      -531.11  |proj g|=       0.11958
At iterate    17  f =      -531.12  |proj g|=       0.11955
At iterate    18  f =      -531.12  |proj g|=       0.11954
At iterate    19  f =      -531.12  |proj g|=      0.066009

iterations 19
function evaluations 26
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0660094
final function value -531.123

F = -531.123
final  value -531.123290 
converged
 
INFO  [03:44:56.094] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:44:56.148] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:44:56.155] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:45:08.408] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:45:20.872] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:45:33.391] [mlr3]  Finished benchmark 
INFO  [03:45:33.456] [bbotk] Result of batch 98: 
INFO  [03:45:33.457] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:45:33.457] [bbotk]                   4               956      0.1722242        0.615 -0.8830598 
INFO  [03:45:33.457] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:45:33.457] [bbotk]          <NA>   0.9752761 4deffaa1-a5fb-4dbf-8edf-e538de33b02b 
DEBUG [03:45:34.469] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.176876e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001176876 0.1214446 
  - best initial criterion value(s) :  433.8911 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -433.89  |proj g|=       6.2201
At iterate     1  f =      -438.64  |proj g|=        2.8818
At iterate     2  f =      -475.57  |proj g|=        4.5951
At iterate     3  f =      -478.78  |proj g|=        4.3801
At iterate     4  f =      -508.38  |proj g|=        3.2188
At iterate     5  f =      -533.29  |proj g|=        13.465
At iterate     6  f =      -533.38  |proj g|=        13.459
At iterate     7  f =      -540.37  |proj g|=         13.12
At iterate     8  f =      -544.79  |proj g|=       0.31695
At iterate     9  f =      -546.16  |proj g|=        1.7827
At iterate    10  f =      -546.24  |proj g|=       0.18289
At iterate    11  f =      -546.25  |proj g|=       0.11953
At iterate    12  f =      -546.25  |proj g|=       0.11952
At iterate    13  f =      -546.25  |proj g|=       0.11952
At iterate    14  f =      -546.25  |proj g|=     0.0081182

iterations 14
function evaluations 27
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00811821
final function value -546.25

F = -546.25
final  value -546.250087 
converged
 
INFO  [03:45:34.473] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:45:34.530] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:45:34.537] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:45:51.983] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:46:10.035] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:46:27.147] [mlr3]  Finished benchmark 
INFO  [03:46:27.213] [bbotk] Result of batch 99: 
INFO  [03:46:27.215] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:46:27.215] [bbotk]                   6              1405      0.1290007        0.705 -0.8824309 
INFO  [03:46:27.215] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:46:27.215] [bbotk]          <NA>    0.976795 42d2fac2-fe02-49be-81f1-dbfd099356d3 
DEBUG [03:46:28.377] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.175218e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001175218 0.121357 
  - best initial criterion value(s) :  498.6336 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -498.63  |proj g|=        5.773
At iterate     1  f =      -504.14  |proj g|=        3.2005
At iterate     2  f =      -514.52  |proj g|=        2.8215
At iterate     3  f =      -517.37  |proj g|=        2.5621
At iterate     4  f =      -527.05  |proj g|=        1.4305
At iterate     5  f =      -530.12  |proj g|=        1.0042
At iterate     6  f =       -530.2  |proj g|=        1.4784
At iterate     7  f =      -530.31  |proj g|=        1.3956
At iterate     8  f =      -530.59  |proj g|=        1.3468
At iterate     9  f =      -531.19  |proj g|=        1.3232
At iterate    10  f =      -532.65  |proj g|=        1.3348
At iterate    11  f =      -536.61  |proj g|=        1.3666
At iterate    12  f =      -542.71  |proj g|=        1.3273
At iterate    13  f =      -543.74  |proj g|=         1.365
At iterate    14  f =      -544.14  |proj g|=       0.65001
At iterate    15  f =       -544.2  |proj g|=       0.20331
At iterate    16  f =       -544.2  |proj g|=       0.11946
At iterate    17  f =       -544.2  |proj g|=       0.11945
At iterate    18  f =       -544.2  |proj g|=       0.11945
At iterate    19  f =       -544.2  |proj g|=      0.009069
At iterate    20  f =       -544.2  |proj g|=     0.0090689
At iterate    21  f =       -544.2  |proj g|=     0.0090688

iterations 21
function evaluations 30
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00906881
final function value -544.2

F = -544.2
final  value -544.200221 
converged
 
INFO  [03:46:28.381] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:46:28.436] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:46:28.443] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:46:29.326] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:46:57.269] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:47:25.258] [mlr3]  Finished benchmark 
INFO  [03:47:25.324] [bbotk] Result of batch 100: 
INFO  [03:47:25.325] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:47:25.325] [bbotk]                   7              2287     0.04939645         0.78 -0.8840746 
INFO  [03:47:25.325] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:47:25.325] [bbotk]          <NA>   0.8180906 182e0cf4-f0c1-41be-9d87-b82466c484d7 
DEBUG [03:47:26.445] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.168542e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001168542 0.1206431 
  - best initial criterion value(s) :  488.4972 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -488.5  |proj g|=       5.2216
At iterate     1  f =      -489.84  |proj g|=        5.0751
At iterate     2  f =      -503.85  |proj g|=        4.3014
At iterate     3  f =       -509.4  |proj g|=        3.8569
At iterate     4  f =      -524.79  |proj g|=         2.787
At iterate     5  f =      -532.29  |proj g|=      0.048993
At iterate     6  f =      -532.88  |proj g|=        0.8453
At iterate     7  f =      -532.89  |proj g|=       0.49303
At iterate     8  f =      -532.89  |proj g|=       0.51147
At iterate     9  f =      -532.89  |proj g|=       0.50261
At iterate    10  f =      -532.89  |proj g|=       0.48369
At iterate    11  f =       -532.9  |proj g|=       0.44329
At iterate    12  f =      -532.91  |proj g|=       0.36633
At iterate    13  f =      -532.93  |proj g|=       0.21575
At iterate    14  f =      -532.99  |proj g|=       0.11755
At iterate    15  f =      -533.14  |proj g|=       0.15451
At iterate    16  f =       -533.3  |proj g|=       0.32173
At iterate    17  f =      -533.42  |proj g|=        1.1797
At iterate    18  f =      -533.44  |proj g|=        1.3284
At iterate    19  f =      -533.45  |proj g|=        1.3342
At iterate    20  f =      -533.46  |proj g|=        1.1992
At iterate    21  f =      -533.47  |proj g|=       0.81312
At iterate    22  f =      -533.48  |proj g|=       0.35916
At iterate    23  f =      -533.49  |proj g|=     0.0050502
At iterate    24  f =      -533.49  |proj g|=      0.018884

iterations 24
function evaluations 37
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0188839
final function value -533.487

F = -533.487
final  value -533.486848 
converged
 
INFO  [03:47:26.449] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:47:26.503] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:47:26.510] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:47:59.485] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:48:32.794] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:49:06.589] [mlr3]  Finished benchmark 
INFO  [03:49:06.654] [bbotk] Result of batch 101: 
INFO  [03:49:06.656] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [03:49:06.656] [bbotk]                   6              2772      0.2951319        0.779 -0.883765 
INFO  [03:49:06.656] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:49:06.656] [bbotk]          <NA>   0.9770928 8ed47082-5f7d-49cc-8dea-d504517d6e2a 
DEBUG [03:49:07.716] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.166976e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001166976 0.1203144 
  - best initial criterion value(s) :  500.5693 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -500.57  |proj g|=       0.7113
At iterate     1  f =      -512.99  |proj g|=        2.8525
At iterate     2  f =      -514.66  |proj g|=        2.7481
At iterate     3  f =      -517.82  |proj g|=        2.5003
At iterate     4  f =       -518.5  |proj g|=         2.442
At iterate     5  f =      -519.84  |proj g|=        2.3016
At iterate     6  f =      -521.81  |proj g|=        1.9529
At iterate     7  f =      -522.42  |proj g|=       0.11771
At iterate     8  f =      -522.43  |proj g|=       0.13187
At iterate     9  f =      -522.43  |proj g|=     0.0083485
At iterate    10  f =      -522.43  |proj g|=       0.11764
At iterate    11  f =      -522.43  |proj g|=     0.0083436

iterations 11
function evaluations 19
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0083436
final function value -522.433

F = -522.433
final  value -522.432558 
converged
 
INFO  [03:49:07.720] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:49:07.774] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:49:07.781] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:49:37.898] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:50:07.743] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:50:37.519] [mlr3]  Finished benchmark 
INFO  [03:50:37.585] [bbotk] Result of batch 102: 
INFO  [03:50:37.586] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:50:37.586] [bbotk]                   4              2459      0.2323688        0.783 -0.8856324 
INFO  [03:50:37.586] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:50:37.586] [bbotk]          <NA>   0.9759481 4d32ad2f-2910-49e0-bea2-cb97148b8d56 
DEBUG [03:50:38.543] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.16513e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.00116513 0.1201201 
  - best initial criterion value(s) :  477.6847 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -477.68  |proj g|=       11.917
At iterate     1  f =      -502.76  |proj g|=        1.6243
At iterate     2  f =      -516.59  |proj g|=        3.5595
At iterate     3  f =      -520.78  |proj g|=        3.4045
At iterate     4  f =      -524.09  |proj g|=         3.116
At iterate     5  f =      -529.09  |proj g|=        2.6288
At iterate     6  f =      -536.39  |proj g|=        1.8181
At iterate     7  f =      -537.27  |proj g|=        1.7789
At iterate     8  f =      -537.36  |proj g|=       0.25784
At iterate     9  f =       -537.4  |proj g|=       0.40277
At iterate    10  f =      -537.49  |proj g|=         1.552
At iterate    11  f =      -537.64  |proj g|=        1.7928
At iterate    12  f =      -538.05  |proj g|=         1.903
At iterate    13  f =      -538.65  |proj g|=        2.1475
At iterate    14  f =       -539.7  |proj g|=        2.3493
At iterate    15  f =      -540.77  |proj g|=        2.3012
At iterate    16  f =      -541.04  |proj g|=        2.2982
At iterate    17  f =      -542.19  |proj g|=        0.8277
At iterate    18  f =      -542.21  |proj g|=       0.11688
At iterate    19  f =      -542.21  |proj g|=      0.010992
At iterate    20  f =      -542.21  |proj g|=       0.11687
At iterate    21  f =      -542.21  |proj g|=      0.010874

iterations 21
function evaluations 32
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0108737
final function value -542.209

F = -542.209
final  value -542.208763 
converged
 
INFO  [03:50:38.547] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:50:38.602] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:50:38.609] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:51:07.517] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:51:36.726] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:52:06.285] [mlr3]  Finished benchmark 
INFO  [03:52:06.361] [bbotk] Result of batch 103: 
INFO  [03:52:06.363] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:52:06.363] [bbotk]                   5              2423      0.4887754        0.638 -0.8834372 
INFO  [03:52:06.363] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:52:06.363] [bbotk]          <NA>    0.976943 a3a560bf-9388-4cd6-a727-a1c39a74a609 
DEBUG [03:52:07.338] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.163347e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001163347 0.1200347 
  - best initial criterion value(s) :  455.6819 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -455.68  |proj g|=         2.89
At iterate     1  f =      -466.29  |proj g|=        4.5892
At iterate     2  f =      -484.78  |proj g|=        2.7355
At iterate     3  f =      -493.37  |proj g|=        1.7615
At iterate     4  f =      -493.42  |proj g|=        1.7356
At iterate     5  f =      -493.47  |proj g|=        1.6715
At iterate     6  f =      -493.47  |proj g|=        1.6737
At iterate     7  f =      -493.53  |proj g|=        1.6829
At iterate     8  f =      -493.66  |proj g|=        1.6977
At iterate     9  f =      -494.01  |proj g|=        1.7293
At iterate    10  f =      -494.81  |proj g|=        1.7936
At iterate    11  f =      -496.67  |proj g|=        1.9627
At iterate    12  f =      -500.05  |proj g|=         2.531
At iterate    13  f =      -500.86  |proj g|=        2.8035
At iterate    14  f =      -501.83  |proj g|=        2.9582
At iterate    15  f =      -505.94  |proj g|=        2.8297
At iterate    16  f =         -507  |proj g|=        2.7821
At iterate    17  f =      -515.23  |proj g|=        2.0416
At iterate    18  f =      -516.98  |proj g|=        7.8794
At iterate    19  f =      -518.05  |proj g|=       0.46712
At iterate    20  f =      -518.11  |proj g|=       0.27443
At iterate    21  f =      -518.11  |proj g|=       0.11784
At iterate    22  f =      -518.11  |proj g|=      0.012528
At iterate    23  f =      -518.11  |proj g|=      0.012528

iterations 23
function evaluations 33
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0125281
final function value -518.114

F = -518.114
final  value -518.113883 
converged
 
INFO  [03:52:07.342] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:52:07.399] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:52:07.405] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:52:43.839] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:53:20.398] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:53:57.381] [mlr3]  Finished benchmark 
INFO  [03:53:57.454] [bbotk] Result of batch 104: 
INFO  [03:53:57.456] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:53:57.456] [bbotk]                   3              3056     0.01702882        0.645 -0.8880981 
INFO  [03:53:57.456] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:53:57.456] [bbotk]          <NA>   0.9696177 298e98e0-d7fd-4b39-966b-a8a302c8fc4e 
DEBUG [03:53:58.417] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.160402e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001160402 0.1197562 
  - best initial criterion value(s) :  497.3466 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -497.35  |proj g|=       5.6474
At iterate     1  f =      -512.02  |proj g|=        5.1797
At iterate     2  f =      -515.23  |proj g|=        5.1333
At iterate     3  f =      -517.38  |proj g|=        4.9884
At iterate     4  f =      -519.92  |proj g|=        4.7852
At iterate     5  f =      -526.37  |proj g|=        4.2383
At iterate     6  f =      -533.91  |proj g|=        3.5956
At iterate     7  f =      -546.74  |proj g|=        1.3932
At iterate     8  f =      -550.18  |proj g|=        7.1879
At iterate     9  f =      -551.06  |proj g|=        2.1418
At iterate    10  f =      -551.24  |proj g|=       0.27367
At iterate    11  f =      -551.25  |proj g|=       0.26257
At iterate    12  f =      -551.25  |proj g|=       0.13634
At iterate    13  f =      -551.25  |proj g|=       0.13653
At iterate    14  f =      -551.26  |proj g|=       0.13996
At iterate    15  f =      -551.26  |proj g|=       0.14551
At iterate    16  f =      -551.26  |proj g|=       0.16086
At iterate    17  f =      -551.26  |proj g|=       0.19198
At iterate    18  f =      -551.28  |proj g|=       0.22097
At iterate    19  f =      -551.29  |proj g|=       0.11451
At iterate    20  f =       -551.3  |proj g|=       0.22282
At iterate    21  f =       -551.3  |proj g|=       0.22541
At iterate    22  f =       -551.3  |proj g|=       0.15333
At iterate    23  f =       -551.3  |proj g|=       0.11634
At iterate    24  f =       -551.3  |proj g|=       0.11633
At iterate    25  f =       -551.3  |proj g|=       0.11633
At iterate    26  f =       -551.3  |proj g|=      0.006218

iterations 26
function evaluations 35
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00621799
final function value -551.304

F = -551.304
final  value -551.304328 
converged
 
INFO  [03:53:58.421] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:53:58.477] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:53:58.484] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:54:14.130] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:54:30.428] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:54:45.838] [mlr3]  Finished benchmark 
INFO  [03:54:45.905] [bbotk] Result of batch 105: 
INFO  [03:54:45.907] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:54:45.907] [bbotk]                   6              1247      0.2974672        0.626 -0.8791718 
INFO  [03:54:45.907] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:54:45.907] [bbotk]          <NA>   0.9772759 1646e970-77b1-4fce-92e9-ab0d94625988 
DEBUG [03:54:46.889] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.158513e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001158513 0.1196732 
  - best initial criterion value(s) :  478.7452 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -478.75  |proj g|=       5.9802
At iterate     1  f =       -482.6  |proj g|=        5.6479
At iterate     2  f =      -522.07  |proj g|=        3.8985
At iterate     3  f =       -534.3  |proj g|=        3.1911
At iterate     4  f =      -547.26  |proj g|=         2.381
At iterate     5  f =      -551.33  |proj g|=        1.3843
At iterate     6  f =      -551.76  |proj g|=       0.79216
At iterate     7  f =      -551.82  |proj g|=        1.3982
At iterate     8  f =      -551.82  |proj g|=        1.0086
At iterate     9  f =      -551.82  |proj g|=       0.99177
At iterate    10  f =      -551.86  |proj g|=       0.35846
At iterate    11  f =      -551.98  |proj g|=       0.33406
At iterate    12  f =      -552.61  |proj g|=        1.9405
At iterate    13  f =      -552.91  |proj g|=        1.9624
At iterate    14  f =      -553.05  |proj g|=         0.161
At iterate    15  f =      -553.05  |proj g|=       0.11651
At iterate    16  f =      -553.05  |proj g|=         0.135
At iterate    17  f =      -553.05  |proj g|=        0.1432
At iterate    18  f =      -553.06  |proj g|=       0.10575
At iterate    19  f =      -553.06  |proj g|=       0.02151
At iterate    20  f =      -553.06  |proj g|=     0.0071632
At iterate    21  f =      -553.06  |proj g|=     0.0071629

iterations 21
function evaluations 33
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0071629
final function value -553.055

F = -553.055
final  value -553.055239 
converged
 
INFO  [03:54:46.893] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:54:46.950] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:54:46.965] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:55:41.733] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:55:42.864] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:56:37.116] [mlr3]  Finished benchmark 
INFO  [03:56:37.182] [bbotk] Result of batch 106: 
INFO  [03:56:37.184] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:56:37.184] [bbotk]                   7              4624       0.118755        0.642 -0.8795039 
INFO  [03:56:37.184] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:56:37.184] [bbotk]          <NA>   0.8192022 04d2cfeb-0732-4554-92c5-7e0afd701879 
DEBUG [03:56:38.139] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.152491e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001152491 0.1189247 
  - best initial criterion value(s) :  522.0871 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -522.09  |proj g|=       13.135
At iterate     1  f =      -552.58  |proj g|=       0.10379
At iterate     2  f =      -557.87  |proj g|=         2.425
At iterate     3  f =      -559.35  |proj g|=        2.2668
At iterate     4  f =      -560.04  |proj g|=       0.96534
At iterate     5  f =      -560.36  |proj g|=        1.9232
At iterate     6  f =      -560.59  |proj g|=       0.90471
At iterate     7  f =      -560.62  |proj g|=       0.29098
At iterate     8  f =      -560.62  |proj g|=       0.19283
At iterate     9  f =      -560.62  |proj g|=       0.17155
At iterate    10  f =      -560.62  |proj g|=       0.10362
At iterate    11  f =      -560.63  |proj g|=       0.10334
At iterate    12  f =      -560.64  |proj g|=       0.15662
At iterate    13  f =      -560.66  |proj g|=       0.38547
At iterate    14  f =      -560.73  |proj g|=       0.65964
At iterate    15  f =       -560.9  |proj g|=       0.78491
At iterate    16  f =      -561.28  |proj g|=      0.059346
At iterate    17  f =      -561.55  |proj g|=        2.3889
At iterate    18  f =       -561.7  |proj g|=        2.3498
At iterate    19  f =      -561.75  |proj g|=        2.3304
At iterate    20  f =      -562.13  |proj g|=       0.45713
At iterate    21  f =      -562.47  |proj g|=       0.78555
At iterate    22  f =       -562.5  |proj g|=       0.23558
At iterate    23  f =      -562.51  |proj g|=      0.018887
At iterate    24  f =      -562.51  |proj g|=       0.11548
At iterate    25  f =      -562.51  |proj g|=     0.0063768

iterations 25
function evaluations 30
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00637681
final function value -562.506

F = -562.506
final  value -562.505653 
converged
 
INFO  [03:56:38.143] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:56:38.207] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:56:38.214] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:57:27.669] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:57:28.559] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:58:17.364] [mlr3]  Finished benchmark 
INFO  [03:58:17.430] [bbotk] Result of batch 107: 
INFO  [03:58:17.431] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:58:17.431] [bbotk]                   9              4147      0.3099493        0.631 -0.8783322 
INFO  [03:58:17.431] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:58:17.431] [bbotk]          <NA>   0.8160249 6bec52ea-258d-4f19-a5da-764aae2aa2db 
DEBUG [03:58:18.637] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.146827e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001146827 0.1182652 
  - best initial criterion value(s) :  450.6927 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -450.69  |proj g|=         12.4
At iterate     1  f =       -485.5  |proj g|=        1.5557
At iterate     2  f =      -500.65  |proj g|=        3.3302
At iterate     3  f =       -505.2  |proj g|=        3.1851
At iterate     4  f =      -508.63  |proj g|=        2.9404
At iterate     5  f =         -514  |proj g|=        2.4952
At iterate     6  f =      -522.21  |proj g|=        1.8885
At iterate     7  f =      -523.73  |proj g|=        5.7336
At iterate     8  f =      -525.38  |proj g|=         0.836
At iterate     9  f =      -525.45  |proj g|=         1.522
At iterate    10  f =      -525.52  |proj g|=        1.4747
At iterate    11  f =       -525.7  |proj g|=        1.1238
At iterate    12  f =      -526.68  |proj g|=        2.5375
At iterate    13  f =       -528.4  |proj g|=        5.7642
At iterate    14  f =         -533  |proj g|=        6.5936
At iterate    15  f =      -537.57  |proj g|=        12.898
At iterate    16  f =      -539.99  |proj g|=        8.1729
At iterate    17  f =      -541.12  |proj g|=       0.86359
At iterate    18  f =      -541.34  |proj g|=       0.25035
At iterate    19  f =      -541.47  |proj g|=       0.16843
At iterate    20  f =      -541.48  |proj g|=       0.11581
At iterate    21  f =      -541.48  |proj g|=        0.1158
At iterate    22  f =      -541.48  |proj g|=      0.011873

iterations 22
function evaluations 32
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.011873
final function value -541.478

F = -541.478
final  value -541.478234 
converged
 
INFO  [03:58:18.641] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:58:18.694] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:58:18.708] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:58:19.579] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:58:37.407] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:58:55.443] [mlr3]  Finished benchmark 
INFO  [03:58:55.509] [bbotk] Result of batch 108: 
INFO  [03:58:55.510] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [03:58:55.510] [bbotk]                   8              1408      0.1600421        0.819 -0.882616 
INFO  [03:58:55.510] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:58:55.510] [bbotk]          <NA>   0.8186388 f95a434f-97ea-4969-92c2-0bbe172d3352 
DEBUG [03:58:56.619] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.140948e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001140948 0.1176534 
  - best initial criterion value(s) :  464.3626 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -464.36  |proj g|=       12.953
At iterate     1  f =      -490.47  |proj g|=        1.6239
At iterate     2  f =      -502.02  |proj g|=        2.3105
At iterate     3  f =      -503.58  |proj g|=        2.2796
At iterate     4  f =      -506.51  |proj g|=        2.0597
At iterate     5  f =      -510.02  |proj g|=        1.7132
At iterate     6  f =      -511.83  |proj g|=       0.77877
At iterate     7  f =      -512.05  |proj g|=        1.7411
At iterate     8  f =       -512.7  |proj g|=       0.35584
At iterate     9  f =      -516.69  |proj g|=        1.5984
At iterate    10  f =      -521.67  |proj g|=         1.728
At iterate    11  f =      -524.93  |proj g|=        1.7476
At iterate    12  f =      -525.72  |proj g|=        1.6174
At iterate    13  f =      -525.93  |proj g|=       0.13845
At iterate    14  f =      -525.93  |proj g|=       0.11563
At iterate    15  f =      -525.93  |proj g|=       0.11563
At iterate    16  f =      -525.93  |proj g|=       0.11563

iterations 16
function evaluations 23
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.115629
final function value -525.935

F = -525.935
final  value -525.934811 
converged
 
INFO  [03:58:56.623] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:58:56.687] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:58:56.696] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:59:16.234] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:59:36.275] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:59:37.147] [mlr3]  Finished benchmark 
INFO  [03:59:37.220] [bbotk] Result of batch 109: 
INFO  [03:59:37.221] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:59:37.221] [bbotk]                   9              1597       0.254981        0.643 -0.8866803 
INFO  [03:59:37.221] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:59:37.221] [bbotk]          <NA>   0.8180556 77a4b4a8-f505-4ac9-8fef-43bf41ee65fd 
DEBUG [03:59:38.180] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.135169e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001135169 0.1170477 
  - best initial criterion value(s) :  512.7924 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -512.79  |proj g|=       11.486
At iterate     1  f =      -524.02  |proj g|=        2.3172
At iterate     2  f =       -541.9  |proj g|=        2.9632
At iterate     3  f =      -547.81  |proj g|=        2.5486
At iterate     4  f =      -550.82  |proj g|=        1.4597
At iterate     5  f =      -553.02  |proj g|=       0.32306
At iterate     6  f =      -555.24  |proj g|=        1.8266
At iterate     7  f =      -555.61  |proj g|=        1.6834
At iterate     8  f =      -555.64  |proj g|=       0.15775
At iterate     9  f =      -555.65  |proj g|=       0.52858
At iterate    10  f =      -555.65  |proj g|=       0.55432
At iterate    11  f =      -555.69  |proj g|=        1.3155
At iterate    12  f =      -556.46  |proj g|=        1.7307
At iterate    13  f =       -560.2  |proj g|=        1.4902
At iterate    14  f =       -560.4  |proj g|=        1.5221
At iterate    15  f =      -560.45  |proj g|=        0.1786
At iterate    16  f =      -560.45  |proj g|=      0.010504
At iterate    17  f =      -560.45  |proj g|=       0.11442
At iterate    18  f =      -560.45  |proj g|=      0.011954

iterations 18
function evaluations 29
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0119544
final function value -560.447

F = -560.447
final  value -560.446636 
converged
 
INFO  [03:59:38.184] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:59:38.238] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:59:38.244] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [03:59:39.126] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [03:59:54.507] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [03:59:55.276] [mlr3]  Finished benchmark 
INFO  [03:59:55.343] [bbotk] Result of batch 110: 
INFO  [03:59:55.344] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [03:59:55.344] [bbotk]                  10              1226       0.152274        0.635 -0.8806686 
INFO  [03:59:55.344] [bbotk]  errors.model classif.auc                                uhash 
INFO  [03:59:55.344] [bbotk]          <NA>    0.659202 99eb375d-703f-4a36-84d8-c87cf0a77aed 
DEBUG [03:59:56.344] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.163152e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001163152 0.119316 
  - best initial criterion value(s) :  476.4287 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -476.43  |proj g|=       5.9412
At iterate     1  f =      -477.07  |proj g|=        3.9905
At iterate     2  f =      -515.54  |proj g|=        4.5847
At iterate     3  f =      -518.96  |proj g|=        4.3742
At iterate     4  f =      -549.96  |proj g|=        3.1571
At iterate     5  f =      -552.86  |proj g|=        12.831
At iterate     6  f =      -556.01  |proj g|=        13.596
At iterate     7  f =      -556.18  |proj g|=        13.595
At iterate     8  f =      -556.21  |proj g|=        13.594
At iterate     9  f =      -556.32  |proj g|=        13.585
At iterate    10  f =      -556.77  |proj g|=        13.542
At iterate    11  f =      -557.74  |proj g|=        13.436
At iterate    12  f =      -562.86  |proj g|=         13.26
At iterate    13  f =      -573.02  |proj g|=        4.1677
At iterate    14  f =      -573.87  |proj g|=        6.2575
At iterate    15  f =      -575.34  |proj g|=       0.66859
At iterate    16  f =      -575.45  |proj g|=       0.17538
At iterate    17  f =      -575.47  |proj g|=       0.11639
At iterate    18  f =      -575.47  |proj g|=       0.11638
At iterate    19  f =      -575.47  |proj g|=      0.024522
At iterate    20  f =      -575.47  |proj g|=     0.0084345

iterations 20
function evaluations 35
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00843448
final function value -575.472

F = -575.472
final  value -575.471666 
converged
 
INFO  [03:59:56.348] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:59:56.416] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:59:56.423] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:00:54.557] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:01:51.680] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:02:48.826] [mlr3]  Finished benchmark 
INFO  [04:02:48.891] [bbotk] Result of batch 111: 
INFO  [04:02:48.893] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [04:02:48.893] [bbotk]                   3              4826      0.1187618        0.648 -0.878804 
INFO  [04:02:48.893] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:02:48.893] [bbotk]          <NA>   0.9739681 a08e15c3-f293-4d49-8ce6-8375f32d5871 
DEBUG [04:02:49.951] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.161262e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001161262 0.118963 
  - best initial criterion value(s) :  578.4615 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -578.46  |proj g|=       5.8673
At iterate     1  f =      -581.07  |proj g|=        2.3923
At iterate     2  f =      -588.72  |proj g|=        2.7241
At iterate     3  f =       -590.2  |proj g|=        2.4571
At iterate     4  f =       -591.7  |proj g|=        2.0209
At iterate     5  f =      -591.83  |proj g|=       0.20573
At iterate     6  f =      -591.86  |proj g|=       0.31886
At iterate     7  f =      -591.86  |proj g|=      0.018632
At iterate     8  f =      -591.86  |proj g|=       0.11563
At iterate     9  f =      -591.87  |proj g|=       0.13994
At iterate    10  f =      -591.87  |proj g|=       0.33752
At iterate    11  f =      -591.88  |proj g|=       0.61395
At iterate    12  f =       -591.9  |proj g|=        1.0849
At iterate    13  f =      -591.94  |proj g|=        1.6324
At iterate    14  f =      -591.98  |proj g|=        2.1722
At iterate    15  f =      -592.05  |proj g|=        2.0902
At iterate    16  f =      -592.13  |proj g|=       0.30264
At iterate    17  f =      -592.14  |proj g|=      0.010924
At iterate    18  f =      -592.14  |proj g|=     0.0077313
At iterate    19  f =      -592.14  |proj g|=     0.0064159
At iterate    20  f =      -592.14  |proj g|=     0.0064159

iterations 20
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00641589
final function value -592.138

F = -592.138
final  value -592.137895 
converged
 
INFO  [04:02:49.955] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:02:50.008] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:02:50.015] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:03:35.664] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:04:22.038] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:05:07.436] [mlr3]  Finished benchmark 
INFO  [04:05:07.501] [bbotk] Result of batch 112: 
INFO  [04:05:07.503] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:05:07.503] [bbotk]                   5              3831       0.134067        0.736 -0.8766871 
INFO  [04:05:07.503] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:05:07.503] [bbotk]          <NA>   0.9771693 a0000b57-4f53-4135-8f8c-e9c4c89231b1 
DEBUG [04:05:08.688] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.159758e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001159758 0.1185272 
  - best initial criterion value(s) :  533.5897 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -533.59  |proj g|=       12.495
At iterate     1  f =      -563.73  |proj g|=        1.9663
At iterate     2  f =      -576.47  |proj g|=        2.9245
At iterate     3  f =      -578.61  |proj g|=        2.6818
At iterate     4  f =      -584.87  |proj g|=         1.969
At iterate     5  f =         -586  |proj g|=        1.8445
At iterate     6  f =      -586.09  |proj g|=       0.19749
At iterate     7  f =      -586.11  |proj g|=       0.58171
At iterate     8  f =      -586.12  |proj g|=       0.78341
At iterate     9  f =      -586.18  |proj g|=        1.1922
At iterate    10  f =      -586.33  |proj g|=        1.7412
At iterate    11  f =      -586.72  |proj g|=        1.7555
At iterate    12  f =      -587.67  |proj g|=        1.8042
At iterate    13  f =      -589.35  |proj g|=        1.9094
At iterate    14  f =      -590.71  |proj g|=        0.2064
At iterate    15  f =      -590.84  |proj g|=        1.3717
At iterate    16  f =      -590.91  |proj g|=        1.9136
At iterate    17  f =      -591.01  |proj g|=          1.95
At iterate    18  f =      -591.11  |proj g|=       0.87575
At iterate    19  f =      -591.13  |proj g|=       0.18678
At iterate    20  f =      -591.13  |proj g|=       0.11542
At iterate    21  f =      -591.13  |proj g|=     0.0076277
At iterate    22  f =      -591.13  |proj g|=     0.0076279

iterations 22
function evaluations 32
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00762785
final function value -591.128

F = -591.128
final  value -591.127736 
converged
 
INFO  [04:05:08.692] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:05:08.745] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:05:08.752] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:05:15.574] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:05:22.245] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:05:29.126] [mlr3]  Finished benchmark 
INFO  [04:05:29.191] [bbotk] Result of batch 113: 
INFO  [04:05:29.192] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:05:29.192] [bbotk]                   4               481      0.4538712        0.766 -0.8773594 
INFO  [04:05:29.192] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:05:29.192] [bbotk]          <NA>   0.9755955 696c0e5f-3397-476d-8086-56d89a933152 
DEBUG [04:05:30.318] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.157948e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001157948 0.1185376 
  - best initial criterion value(s) :  550.909 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -550.91  |proj g|=       3.8317
At iterate     1  f =      -590.72  |proj g|=        12.278
At iterate     2  f =      -597.64  |proj g|=        8.7882
At iterate     3  f =      -598.66  |proj g|=        4.9659
At iterate     4  f =      -598.73  |proj g|=         3.201
At iterate     5  f =      -598.74  |proj g|=        3.0167
At iterate     6  f =      -598.75  |proj g|=        2.8547
At iterate     7  f =       -598.8  |proj g|=        2.4228
At iterate     8  f =      -598.92  |proj g|=        1.7991
At iterate     9  f =      -599.24  |proj g|=       0.66651
At iterate    10  f =      -599.98  |proj g|=       0.91342
At iterate    11  f =      -601.27  |proj g|=        1.8807
At iterate    12  f =      -602.29  |proj g|=        1.4071
At iterate    13  f =      -602.39  |proj g|=        2.6243
At iterate    14  f =      -602.45  |proj g|=         3.106
At iterate    15  f =      -602.57  |proj g|=        3.2658
At iterate    16  f =      -602.77  |proj g|=        2.3204
At iterate    17  f =      -602.87  |proj g|=       0.91026
At iterate    18  f =      -602.88  |proj g|=       0.40807
At iterate    19  f =      -602.88  |proj g|=     0.0074073
At iterate    20  f =      -602.88  |proj g|=      0.040396

iterations 20
function evaluations 26
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0403962
final function value -602.885

F = -602.885
final  value -602.884968 
converged
 
INFO  [04:05:30.322] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:05:30.378] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:05:30.385] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:06:17.092] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:07:03.769] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:07:50.600] [mlr3]  Finished benchmark 
INFO  [04:07:50.664] [bbotk] Result of batch 114: 
INFO  [04:07:50.665] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:07:50.665] [bbotk]                   5              3926      0.3604155          0.8 -0.8762264 
INFO  [04:07:50.665] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:07:50.665] [bbotk]          <NA>   0.9767869 9d28039a-d428-4d81-8783-af4b9e9bbd1f 
DEBUG [04:07:51.656] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.156233e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001156233 0.1182226 
  - best initial criterion value(s) :  540.7514 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -540.75  |proj g|=        5.721
At iterate     1  f =      -580.79  |proj g|=        8.8766
At iterate     2  f =      -602.35  |proj g|=        2.1439
At iterate     3  f =       -603.3  |proj g|=       0.83552
At iterate     4  f =      -603.31  |proj g|=       0.81147
At iterate     5  f =      -603.31  |proj g|=       0.79929
At iterate     6  f =      -603.31  |proj g|=       0.77491
At iterate     7  f =      -603.31  |proj g|=       0.73983
At iterate     8  f =      -603.31  |proj g|=       0.67951
At iterate     9  f =      -603.32  |proj g|=       0.56986
At iterate    10  f =      -603.33  |proj g|=       0.38926
At iterate    11  f =      -603.36  |proj g|=       0.11552
At iterate    12  f =      -603.46  |proj g|=       0.23547
At iterate    13  f =       -603.7  |proj g|=       0.43461
At iterate    14  f =      -604.13  |proj g|=       0.25636
At iterate    15  f =      -604.21  |proj g|=        2.1641
At iterate    16  f =      -604.29  |proj g|=        1.8767
At iterate    17  f =      -604.63  |proj g|=       0.11509
At iterate    18  f =      -604.64  |proj g|=       0.11504
At iterate    19  f =      -604.64  |proj g|=       0.11502
At iterate    20  f =      -604.64  |proj g|=       0.11502
At iterate    21  f =      -604.64  |proj g|=      0.007404

iterations 21
function evaluations 29
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00740395
final function value -604.637

F = -604.637
final  value -604.636609 
converged
 
INFO  [04:07:51.660] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:07:51.713] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:07:51.720] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:08:11.722] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:08:12.624] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:08:13.396] [mlr3]  Finished benchmark 
INFO  [04:08:13.462] [bbotk] Result of batch 115: 
INFO  [04:08:13.463] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:08:13.463] [bbotk]                  10              1625      0.3999709        0.651 -0.8764765 
INFO  [04:08:13.463] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:08:13.463] [bbotk]          <NA>   0.6592187 95dfc75f-2e8f-49d5-8b2a-67cee0ff1fcc 
DEBUG [04:08:14.500] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.183428e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001183428 0.1199116 
  - best initial criterion value(s) :  461.7868 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -461.79  |proj g|=       12.341
At iterate     1  f =      -489.62  |proj g|=        3.3392
At iterate     2  f =      -506.41  |proj g|=        2.8149
At iterate     3  f =      -514.15  |proj g|=        2.3525
At iterate     4  f =      -520.02  |proj g|=        1.9288
At iterate     5  f =      -523.13  |proj g|=        1.7034
At iterate     6  f =      -524.35  |proj g|=        1.5935
At iterate     7  f =      -524.65  |proj g|=        1.3178
At iterate     8  f =      -524.85  |proj g|=        1.4206
At iterate     9  f =      -524.87  |proj g|=        1.4303
At iterate    10  f =      -524.88  |proj g|=        1.4197
At iterate    11  f =      -524.92  |proj g|=        1.4072
At iterate    12  f =      -525.39  |proj g|=       0.40863
At iterate    13  f =       -526.2  |proj g|=        3.3486
At iterate    14  f =      -528.66  |proj g|=        9.8074
At iterate    15  f =      -532.48  |proj g|=         13.14
At iterate    16  f =      -541.54  |proj g|=        13.211
At iterate    17  f =      -550.43  |proj g|=        13.127
At iterate    18  f =      -553.95  |proj g|=        4.8992
At iterate    19  f =       -554.7  |proj g|=        1.5409
At iterate    20  f =      -555.01  |proj g|=       0.37895
At iterate    21  f =      -555.03  |proj g|=       0.11805
At iterate    22  f =      -555.03  |proj g|=      0.026544
At iterate    23  f =      -555.03  |proj g|=       0.11804
At iterate    24  f =      -555.03  |proj g|=      0.021736

iterations 24
function evaluations 34
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0217365
final function value -555.033

F = -555.033
final  value -555.032884 
converged
 
INFO  [04:08:14.504] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:08:14.558] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:08:14.564] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:08:51.588] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:09:28.521] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:10:04.974] [mlr3]  Finished benchmark 
INFO  [04:10:05.039] [bbotk] Result of batch 116: 
INFO  [04:10:05.040] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:10:05.040] [bbotk]                   6              3073      0.3559087        0.676 -0.8866729 
INFO  [04:10:05.040] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:10:05.040] [bbotk]          <NA>   0.9768966 b6d2c9e6-5c2c-4899-a59d-85c2d1046912 
DEBUG [04:10:06.133] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.181696e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001181696 0.1198782 
  - best initial criterion value(s) :  506.508 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -506.51  |proj g|=       12.109
At iterate     1  f =      -516.88  |proj g|=        2.0133
At iterate     2  f =      -535.46  |proj g|=        2.2498
At iterate     3  f =      -540.03  |proj g|=        1.8872
At iterate     4  f =      -542.65  |proj g|=        1.6081
At iterate     5  f =      -543.72  |proj g|=       0.99514
At iterate     6  f =      -543.91  |proj g|=        1.1744
At iterate     7  f =      -543.97  |proj g|=        1.2098
At iterate     8  f =      -543.97  |proj g|=        1.1467
At iterate     9  f =      -543.98  |proj g|=        1.1335
At iterate    10  f =      -543.98  |proj g|=        1.0619
At iterate    11  f =      -544.01  |proj g|=       0.92646
At iterate    12  f =      -544.06  |proj g|=       0.62179
At iterate    13  f =       -544.2  |proj g|=       0.19964
At iterate    14  f =      -544.56  |proj g|=       0.53234
At iterate    15  f =      -545.43  |proj g|=       0.72197
At iterate    16  f =      -547.31  |proj g|=        1.7532
At iterate    17  f =      -547.42  |proj g|=        1.8135
At iterate    18  f =      -548.96  |proj g|=        2.1025
At iterate    19  f =      -550.61  |proj g|=        2.0665
At iterate    20  f =      -553.01  |proj g|=        1.7784
At iterate    21  f =      -554.81  |proj g|=        2.2384
At iterate    22  f =       -554.9  |proj g|=       0.16824
At iterate    23  f =      -554.92  |proj g|=       0.20594
At iterate    24  f =      -554.92  |proj g|=      0.024078
At iterate    25  f =      -554.92  |proj g|=      0.024079
At iterate    26  f =      -554.92  |proj g|=      0.027351

iterations 26
function evaluations 36
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.027351
final function value -554.916

F = -554.916
final  value -554.915885 
converged
 
INFO  [04:10:06.137] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:10:06.193] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:10:06.200] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:10:07.075] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:10:21.684] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:10:35.949] [mlr3]  Finished benchmark 
INFO  [04:10:36.013] [bbotk] Result of batch 117: 
INFO  [04:10:36.015] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:10:36.015] [bbotk]                   8              1155     0.06759006        0.682 -0.8872375 
INFO  [04:10:36.015] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:10:36.015] [bbotk]          <NA>   0.8178294 76aa2079-555e-458d-a5fc-721d62e25a12 
DEBUG [04:10:37.116] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.175962e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001175962 0.1194098 
  - best initial criterion value(s) :  569.7558 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -569.76  |proj g|=       6.0132
At iterate     1  f =      -580.39  |proj g|=        4.3344
At iterate     2  f =      -589.57  |proj g|=        3.7589
At iterate     3  f =      -592.16  |proj g|=        3.4368
At iterate     4  f =      -601.76  |proj g|=        2.5428
At iterate     5  f =      -608.02  |proj g|=        1.8812
At iterate     6  f =      -608.18  |proj g|=        1.7883
At iterate     7  f =      -608.21  |proj g|=        1.7427
At iterate     8  f =      -608.21  |proj g|=        1.7469
At iterate     9  f =      -608.23  |proj g|=        1.7666
At iterate    10  f =      -608.26  |proj g|=        1.7907
At iterate    11  f =      -608.37  |proj g|=         1.835
At iterate    12  f =      -608.65  |proj g|=        1.9042
At iterate    13  f =      -609.32  |proj g|=        2.0375
At iterate    14  f =       -609.7  |proj g|=        2.0923
At iterate    15  f =      -611.86  |proj g|=        2.2424
At iterate    16  f =      -615.26  |proj g|=        2.3329
At iterate    17  f =      -623.34  |proj g|=        2.4636
At iterate    18  f =      -627.36  |proj g|=        2.4868
At iterate    19  f =      -627.66  |proj g|=        2.3564
At iterate    20  f =      -628.16  |proj g|=         3.603
At iterate    21  f =       -628.4  |proj g|=      0.044512
At iterate    22  f =      -628.41  |proj g|=       0.11598
At iterate    23  f =      -628.41  |proj g|=     0.0064222
At iterate    24  f =      -628.41  |proj g|=     0.0064221

iterations 24
function evaluations 35
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00642215
final function value -628.406

F = -628.406
final  value -628.406049 
converged
 
INFO  [04:10:37.120] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:10:37.175] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:10:37.182] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:11:30.911] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:12:24.663] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:13:17.918] [mlr3]  Finished benchmark 
INFO  [04:13:17.983] [bbotk] Result of batch 118: 
INFO  [04:13:17.985] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:13:17.985] [bbotk]                   5              4552      0.2014191        0.716 -0.8747892 
INFO  [04:13:17.985] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:13:17.985] [bbotk]          <NA>   0.9770992 62e24d4c-4d5f-43c5-93b2-0d8cf955638e 
DEBUG [04:13:19.022] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.1743e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.0011743 0.1191924 
  - best initial criterion value(s) :  575.778 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -575.78  |proj g|=       11.298
At iterate     1  f =      -584.78  |proj g|=        3.1083
At iterate     2  f =      -592.13  |proj g|=        3.6011
At iterate     3  f =      -594.38  |proj g|=        3.5093
At iterate     4  f =      -600.39  |proj g|=        3.0726
At iterate     5  f =      -606.19  |proj g|=        2.6839
At iterate     6  f =      -613.88  |proj g|=        2.0645
At iterate     7  f =       -615.2  |proj g|=        1.7981
At iterate     8  f =      -615.53  |proj g|=        0.3103
At iterate     9  f =      -615.69  |proj g|=       0.88423
At iterate    10  f =      -615.88  |proj g|=        1.2731
At iterate    11  f =      -617.09  |proj g|=        2.9195
At iterate    12  f =      -618.93  |proj g|=        3.9615
At iterate    13  f =      -621.35  |proj g|=        3.6059
At iterate    14  f =      -621.39  |proj g|=         2.233
At iterate    15  f =      -622.01  |proj g|=        1.0419
At iterate    16  f =      -622.31  |proj g|=       0.11639
At iterate    17  f =      -622.33  |proj g|=       0.11631
At iterate    18  f =      -622.34  |proj g|=       0.11629
At iterate    19  f =      -622.34  |proj g|=       0.11629
At iterate    20  f =      -622.34  |proj g|=     0.0086808

iterations 20
function evaluations 31
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00868084
final function value -622.336

F = -622.336
final  value -622.336110 
converged
 
INFO  [04:13:19.026] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:13:19.081] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:13:19.087] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:13:55.264] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:14:32.158] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:14:33.048] [mlr3]  Finished benchmark 
INFO  [04:14:33.112] [bbotk] Result of batch 119: 
INFO  [04:14:33.114] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:14:33.114] [bbotk]                   8              3026      0.3911895        0.674 -0.8763237 
INFO  [04:14:33.114] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:14:33.114] [bbotk]          <NA>   0.8181529 46f01b08-fc18-4ead-8891-74cf45fcfb7c 
DEBUG [04:14:34.246] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.168693e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001168693 0.1186433 
  - best initial criterion value(s) :  590.2938 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -590.29  |proj g|=       5.4212
At iterate     1  f =      -620.42  |proj g|=        10.912
At iterate     2  f =      -635.78  |proj g|=        3.4163
At iterate     3  f =      -637.25  |proj g|=      0.094422
At iterate     4  f =      -637.26  |proj g|=       0.37119
At iterate     5  f =      -637.26  |proj g|=        0.2925
At iterate     6  f =      -637.26  |proj g|=       0.18095
At iterate     7  f =      -637.27  |proj g|=       0.11566
At iterate     8  f =      -637.28  |proj g|=       0.40343
At iterate     9  f =      -637.32  |proj g|=       0.98007
At iterate    10  f =      -637.41  |proj g|=        1.9361
At iterate    11  f =      -637.62  |proj g|=        2.1187
At iterate    12  f =      -637.73  |proj g|=        2.1195
At iterate    13  f =      -637.84  |proj g|=        1.1047
At iterate    14  f =      -637.85  |proj g|=       0.81517
At iterate    15  f =      -637.85  |proj g|=       0.58365
At iterate    16  f =      -637.85  |proj g|=       0.33175
At iterate    17  f =      -637.86  |proj g|=      0.021623
At iterate    18  f =      -637.87  |proj g|=       0.16226
At iterate    19  f =      -637.87  |proj g|=      0.061632
At iterate    20  f =      -637.87  |proj g|=     0.0074545
At iterate    21  f =      -637.87  |proj g|=        0.0246

iterations 21
function evaluations 29
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0245998
final function value -637.868

F = -637.868
final  value -637.867875 
converged
 
INFO  [04:14:34.249] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:14:34.296] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:14:34.302] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:15:31.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:16:28.213] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:17:24.203] [mlr3]  Finished benchmark 
INFO  [04:17:24.269] [bbotk] Result of batch 120: 
INFO  [04:17:24.271] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:17:24.271] [bbotk]                   5              4767      0.2559126         0.73 -0.8749633 
INFO  [04:17:24.271] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:17:24.271] [bbotk]          <NA>   0.9769375 c086eeed-42cf-4b73-9cca-966914b40901 
DEBUG [04:17:25.497] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.16705e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.00116705 0.1183772 
  - best initial criterion value(s) :  603.9006 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -603.9  |proj g|=       4.0381
At iterate     1  f =      -630.38  |proj g|=        12.082
At iterate     2  f =      -638.53  |proj g|=        9.0446
At iterate     3  f =      -640.29  |proj g|=        3.5606
At iterate     4  f =      -640.36  |proj g|=        1.7738
At iterate     5  f =      -640.37  |proj g|=        1.0152
At iterate     6  f =      -640.38  |proj g|=        1.3203
At iterate     7  f =      -640.39  |proj g|=        1.5645
At iterate     8  f =      -640.41  |proj g|=         1.816
At iterate     9  f =      -640.53  |proj g|=        2.5273
At iterate    10  f =      -640.79  |proj g|=         3.348
At iterate    11  f =      -641.41  |proj g|=        4.2656
At iterate    12  f =      -641.98  |proj g|=        4.1004
At iterate    13  f =      -642.58  |proj g|=       0.30647
At iterate    14  f =      -642.59  |proj g|=       0.31405
At iterate    15  f =      -642.59  |proj g|=       0.18838
At iterate    16  f =      -642.59  |proj g|=       0.18227
At iterate    17  f =      -642.59  |proj g|=       0.12766
At iterate    18  f =      -642.59  |proj g|=       0.11527
At iterate    19  f =      -642.59  |proj g|=       0.11526
At iterate    20  f =      -642.59  |proj g|=      0.066097
At iterate    21  f =      -642.59  |proj g|=     0.0075862
At iterate    22  f =      -642.59  |proj g|=     0.0075862

iterations 22
function evaluations 28
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00758618
final function value -642.59

F = -642.59
final  value -642.590119 
converged
 
INFO  [04:17:25.501] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:17:25.565] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:17:25.571] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:17:42.513] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:17:59.277] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:18:15.926] [mlr3]  Finished benchmark 
INFO  [04:18:15.992] [bbotk] Result of batch 121: 
INFO  [04:18:15.994] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [04:18:15.994] [bbotk]                   3              1333        0.33704        0.682 -0.874951 
INFO  [04:18:15.994] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:18:15.994] [bbotk]          <NA>   0.9738056 42d34236-6cf8-4d0a-94b0-c2089dea8bd0 
DEBUG [04:18:17.054] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.164927e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001164927 0.118181 
  - best initial criterion value(s) :  616.5398 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -616.54  |proj g|=       3.5303
At iterate     1  f =       -633.3  |proj g|=        12.231
At iterate     2  f =      -643.15  |proj g|=        11.429
At iterate     3  f =       -645.6  |proj g|=        3.6663
At iterate     4  f =      -645.68  |proj g|=        2.1863
At iterate     5  f =      -645.69  |proj g|=       0.74553
At iterate     6  f =       -645.7  |proj g|=        1.3364
At iterate     7  f =       -645.7  |proj g|=        1.3259
At iterate     8  f =       -645.7  |proj g|=        1.2876
At iterate     9  f =       -645.7  |proj g|=          1.24
At iterate    10  f =      -645.71  |proj g|=        1.1853
At iterate    11  f =      -645.72  |proj g|=        1.1655
At iterate    12  f =      -645.74  |proj g|=         1.298
At iterate    13  f =      -645.77  |proj g|=        1.8525
At iterate    14  f =      -645.81  |proj g|=        3.1775
At iterate    15  f =      -645.82  |proj g|=        3.3856
At iterate    16  f =      -645.85  |proj g|=        3.8924
At iterate    17  f =      -645.88  |proj g|=        4.2986
At iterate    18  f =         -646  |proj g|=        5.0023
At iterate    19  f =      -646.25  |proj g|=         5.703
At iterate    20  f =      -646.86  |proj g|=        6.2658
At iterate    21  f =      -647.16  |proj g|=        5.6674
At iterate    22  f =      -647.57  |proj g|=         1.772
At iterate    23  f =      -647.63  |proj g|=        2.9078
At iterate    24  f =      -647.63  |proj g|=        2.7746
At iterate    25  f =      -647.63  |proj g|=        2.6432
At iterate    26  f =      -647.64  |proj g|=        2.3811
At iterate    27  f =      -647.66  |proj g|=        1.9195
At iterate    28  f =       -647.7  |proj g|=        1.1068
At iterate    29  f =      -647.75  |proj g|=       0.11537
At iterate    30  f =      -647.81  |proj g|=       0.29743
At iterate    31  f =      -647.82  |proj g|=       0.12341
At iterate    32  f =      -647.82  |proj g|=       0.11521
At iterate    33  f =      -647.82  |proj g|=      0.008119
At iterate    34  f =      -647.82  |proj g|=      0.029416

iterations 34
function evaluations 39
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0294157
final function value -647.825

F = -647.825
final  value -647.824500 
converged
 
INFO  [04:18:17.058] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:18:17.112] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:18:17.119] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:18:17.891] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:18:18.793] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:18:38.982] [mlr3]  Finished benchmark 
INFO  [04:18:39.047] [bbotk] Result of batch 122: 
INFO  [04:18:39.049] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:18:39.049] [bbotk]                  10              1634      0.1353812        0.658 -0.8752435 
INFO  [04:18:39.049] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:18:39.049] [bbotk]          <NA>   0.6592825 1f8aab6a-c1ad-4250-8e89-11ed28967543 
DEBUG [04:18:40.185] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.190803e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001190803 0.119967 
  - best initial criterion value(s) :  579.6259 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -579.63  |proj g|=       11.842
At iterate     1  f =      -602.48  |proj g|=        3.7016
At iterate     2  f =      -618.13  |proj g|=        3.0998
At iterate     3  f =      -633.39  |proj g|=        1.9144
At iterate     4  f =      -635.43  |proj g|=        1.8199
At iterate     5  f =      -635.94  |proj g|=        1.6366
At iterate     6  f =      -635.99  |proj g|=        1.6037
At iterate     7  f =      -636.02  |proj g|=        1.5974
At iterate     8  f =      -636.11  |proj g|=        1.5902
At iterate     9  f =      -636.35  |proj g|=        1.5846
At iterate    10  f =      -636.99  |proj g|=        1.5901
At iterate    11  f =      -638.68  |proj g|=        1.6309
At iterate    12  f =      -642.38  |proj g|=        1.7465
At iterate    13  f =      -647.63  |proj g|=         1.791
At iterate    14  f =      -649.81  |proj g|=        1.7616
At iterate    15  f =      -650.47  |proj g|=        1.3406
At iterate    16  f =      -650.65  |proj g|=         2.897
At iterate    17  f =      -650.75  |proj g|=        3.1543
At iterate    18  f =      -650.92  |proj g|=        2.8525
At iterate    19  f =      -651.02  |proj g|=        1.8404
At iterate    20  f =      -651.08  |proj g|=       0.13749
At iterate    21  f =      -651.08  |proj g|=       0.11714
At iterate    22  f =      -651.08  |proj g|=       0.11713
At iterate    23  f =      -651.08  |proj g|=     0.0087645

iterations 23
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0087645
final function value -651.077

F = -651.077
final  value -651.076901 
converged
 
INFO  [04:18:40.189] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:18:40.244] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:18:40.251] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:18:59.139] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:19:18.262] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:19:19.152] [mlr3]  Finished benchmark 
INFO  [04:19:19.217] [bbotk] Result of batch 123: 
INFO  [04:19:19.219] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:19:19.219] [bbotk]                   8              1536      0.3871882        0.738 -0.8756659 
INFO  [04:19:19.219] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:19:19.219] [bbotk]          <NA>    0.818719 1016b1f9-fb08-401e-85aa-f168cc767385 
DEBUG [04:19:20.274] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.185136e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001185136 0.1194396 
  - best initial criterion value(s) :  554.9319 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -554.93  |proj g|=       12.748
At iterate     1  f =      -594.18  |proj g|=        5.2925
At iterate     2  f =      -626.95  |proj g|=       0.61818
At iterate     3  f =      -645.15  |proj g|=        2.0122
At iterate     4  f =       -645.4  |proj g|=        5.9261
At iterate     5  f =      -645.64  |proj g|=        5.0557
At iterate     6  f =      -646.11  |proj g|=       0.16995
At iterate     7  f =      -646.11  |proj g|=       0.32689
At iterate     8  f =      -646.11  |proj g|=       0.35145
At iterate     9  f =      -646.11  |proj g|=        0.3715
At iterate    10  f =      -646.12  |proj g|=         0.432
At iterate    11  f =      -646.14  |proj g|=       0.47791
At iterate    12  f =      -646.18  |proj g|=       0.42214
At iterate    13  f =      -646.28  |proj g|=       0.11739
At iterate    14  f =      -646.51  |proj g|=        1.2523
At iterate    15  f =      -646.95  |proj g|=        2.4296
At iterate    16  f =      -647.87  |proj g|=         6.316
At iterate    17  f =      -647.99  |proj g|=        7.0075
At iterate    18  f =      -648.38  |proj g|=        6.1246
At iterate    19  f =      -649.15  |proj g|=        1.1497
At iterate    20  f =      -649.17  |proj g|=       0.08408
At iterate    21  f =      -649.17  |proj g|=      0.011425
At iterate    22  f =      -649.17  |proj g|=      0.010597
At iterate    23  f =      -649.17  |proj g|=       0.10087
At iterate    24  f =      -649.17  |proj g|=      0.010596

iterations 24
function evaluations 32
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0105958
final function value -649.171

F = -649.171
final  value -649.171158 
converged
 
INFO  [04:19:20.279] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:19:20.341] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:19:20.361] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:19:21.133] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:20:14.989] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:20:15.944] [mlr3]  Finished benchmark 
INFO  [04:20:16.008] [bbotk] Result of batch 124: 
INFO  [04:20:16.010] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:20:16.010] [bbotk]                  10              4564      0.1682285        0.677 -0.8773011 
INFO  [04:20:16.010] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:20:16.010] [bbotk]          <NA>   0.6591363 2b1eac68-3fe8-4930-8270-a42171f1aafb 
DEBUG [04:20:17.032] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.20998e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.00120998 0.1231523 
  - best initial criterion value(s) :  570.7736 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -570.77  |proj g|=       1.0215
At iterate     1  f =      -615.51  |proj g|=        3.8666
At iterate     2  f =      -630.56  |proj g|=        4.3031
At iterate     3  f =      -635.97  |proj g|=        4.4859
At iterate     4  f =      -635.97  |proj g|=        4.4858
At iterate     5  f =      -635.98  |proj g|=        4.4856
At iterate     6  f =      -635.98  |proj g|=        4.4853
At iterate     7  f =         -636  |proj g|=        4.4838
At iterate     8  f =      -636.03  |proj g|=        4.4803
At iterate     9  f =      -636.11  |proj g|=        4.4702
At iterate    10  f =      -636.33  |proj g|=        4.4444
At iterate    11  f =      -636.87  |proj g|=        4.3767
At iterate    12  f =      -638.21  |proj g|=        4.2054
At iterate    13  f =      -641.49  |proj g|=        3.3217
At iterate    14  f =      -650.24  |proj g|=        5.3882
At iterate    15  f =      -664.57  |proj g|=        6.6467
At iterate    16  f =      -665.08  |proj g|=        4.7712
At iterate    17  f =      -665.55  |proj g|=      0.088969
At iterate    18  f =      -665.55  |proj g|=       0.12031
At iterate    19  f =      -665.55  |proj g|=       0.12031
At iterate    20  f =      -665.55  |proj g|=     0.0085996

iterations 20
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00859958
final function value -665.547

F = -665.547
final  value -665.547224 
converged
 
INFO  [04:20:17.036] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:20:17.093] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:20:17.100] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:20:57.206] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:21:37.306] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:21:38.243] [mlr3]  Finished benchmark 
INFO  [04:21:38.310] [bbotk] Result of batch 125: 
INFO  [04:21:38.311] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:21:38.311] [bbotk]                   7              3376      0.4987024        0.672 -0.8749633 
INFO  [04:21:38.311] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:21:38.311] [bbotk]          <NA>   0.8188188 ff73a4d9-9e1a-438d-ae54-f06e29b37b5e 
DEBUG [04:21:39.533] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.204096e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001204096 0.1225679 
  - best initial criterion value(s) :  591.2131 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -591.21  |proj g|=       5.5136
At iterate     1  f =      -600.56  |proj g|=        4.8644
At iterate     2  f =      -648.76  |proj g|=        2.4227
At iterate     3  f =      -651.83  |proj g|=        2.0099
At iterate     4  f =      -653.11  |proj g|=        2.1251
At iterate     5  f =      -653.54  |proj g|=        1.4059
At iterate     6  f =      -653.55  |proj g|=       0.33156
At iterate     7  f =      -653.55  |proj g|=       0.44773
At iterate     8  f =      -653.55  |proj g|=       0.50321
At iterate     9  f =      -653.55  |proj g|=        0.6251
At iterate    10  f =      -653.56  |proj g|=       0.83209
At iterate    11  f =      -653.56  |proj g|=        1.1507
At iterate    12  f =      -653.58  |proj g|=        1.6725
At iterate    13  f =      -653.63  |proj g|=        2.4673
At iterate    14  f =      -653.74  |proj g|=        3.6524
At iterate    15  f =      -653.78  |proj g|=        5.1586
At iterate    16  f =         -654  |proj g|=        4.2339
At iterate    17  f =       -654.2  |proj g|=        1.8768
At iterate    18  f =      -654.28  |proj g|=       0.46422
At iterate    19  f =      -654.29  |proj g|=       0.12021
At iterate    20  f =      -654.29  |proj g|=       0.12021
At iterate    21  f =      -654.29  |proj g|=      0.012704

iterations 21
function evaluations 30
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0127042
final function value -654.293

F = -654.293
final  value -654.293050 
converged
 
INFO  [04:21:39.537] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:21:39.592] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:21:39.599] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:22:28.624] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:23:17.879] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:24:06.773] [mlr3]  Finished benchmark 
INFO  [04:24:06.839] [bbotk] Result of batch 126: 
INFO  [04:24:06.841] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:24:06.841] [bbotk]                   5              4132      0.4089595        0.844 -0.8775957 
INFO  [04:24:06.841] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:24:06.841] [bbotk]          <NA>   0.9765585 5ac186f5-fede-45b2-95df-5975f314352a 
DEBUG [04:24:08.049] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.202565e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9552 0.9916713 
  - variance bounds :  0.001202565 0.1223362 
  - best initial criterion value(s) :  606.7562 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -606.76  |proj g|=       11.108
At iterate     1  f =      -618.91  |proj g|=        2.2791
At iterate     2  f =      -640.59  |proj g|=        3.3267
At iterate     3  f =      -645.56  |proj g|=         3.031
At iterate     4  f =      -651.24  |proj g|=        2.5517
At iterate     5  f =      -658.99  |proj g|=        1.5626
At iterate     6  f =      -659.72  |proj g|=        1.8369
At iterate     7  f =      -659.87  |proj g|=       0.36601
At iterate     8  f =       -659.9  |proj g|=      0.096454
At iterate     9  f =      -659.91  |proj g|=       0.51928
At iterate    10  f =      -659.93  |proj g|=       0.94717
At iterate    11  f =      -660.02  |proj g|=        1.7975
At iterate    12  f =      -660.23  |proj g|=        1.8801
At iterate    13  f =      -660.26  |proj g|=        1.8934
At iterate    14  f =      -660.73  |proj g|=        2.0088
At iterate    15  f =      -661.23  |proj g|=        2.0797
At iterate    16  f =      -661.58  |proj g|=        2.0014
At iterate    17  f =      -661.98  |proj g|=       0.25784
At iterate    18  f =      -662.03  |proj g|=       0.41764
At iterate    19  f =      -662.03  |proj g|=       0.11996
At iterate    20  f =      -662.03  |proj g|=      0.011749
At iterate    21  f =      -662.03  |proj g|=      0.011749

iterations 21
function evaluations 31
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0117492
final function value -662.035

F = -662.035
final  value -662.034877 
converged
 
INFO  [04:24:08.053] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:24:08.110] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:24:08.126] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:24:43.430] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:25:19.076] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:25:54.616] [mlr3]  Finished benchmark 
INFO  [04:25:54.681] [bbotk] Result of batch 127: 
INFO  [04:25:54.683] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [04:25:54.683] [bbotk]                   4              2984      0.1933572        0.832 -0.877213 
INFO  [04:25:54.683] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:25:54.683] [bbotk]          <NA>   0.9759964 ae1145d3-5ed7-4f65-84ee-a92ca95369d2 
DEBUG [04:25:54.752] [bbotk]  
INFO  [04:25:54.764] [bbotk] Finished optimizing after 150 evaluation(s) 
INFO  [04:25:54.766] [bbotk] Result: 
INFO  [04:25:54.768] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu learner_param_vals 
INFO  [04:25:54.768] [bbotk]                   6              2239      0.2043614         <list[15]> 
INFO  [04:25:54.768] [bbotk]   x_domain classif.auc 
INFO  [04:25:54.768] [bbotk]  <list[3]>   0.9773415 
INFO  [04:26:29.759] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost.tuned' on task 'spam' (iter 3/5) 
INFO  [04:26:29.849] [bbotk] Starting to optimize 3 parameter(s) with '<OptimizerInterMBO>' and '<TerminatorEvals> [n_evals=150]' 
DEBUG [04:26:29.915] [bbotk]  
INFO  [04:26:29.920] [bbotk] Evaluating 24 configuration(s) 
INFO  [04:26:30.804] [mlr3]  Running benchmark with 72 resampling iterations 
INFO  [04:26:30.810] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:27:24.139] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:27:55.757] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:28:44.627] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:28:45.408] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:29:37.367] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:29:38.145] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:30:26.721] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:30:27.502] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:31:03.450] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:31:29.922] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:31:30.678] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:31:37.784] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:31:38.575] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:31:48.917] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:32:40.837] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:33:18.347] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:33:44.950] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:33:45.692] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:33:46.443] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:34:40.213] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:35:39.136] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:35:58.040] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:36:34.191] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:37:00.665] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:37:38.402] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:37:39.417] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:38:24.597] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:38:56.238] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:39:49.107] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:39:50.014] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:40:09.039] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:40:09.925] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:40:10.676] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:40:16.476] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:40:48.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:40:59.599] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:41:00.367] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:41:12.142] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:41:22.487] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:41:28.699] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:42:17.269] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:43:15.145] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:43:33.040] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:43:51.638] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:44:29.262] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:44:35.384] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:45:19.991] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:45:33.921] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:45:34.668] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:45:35.417] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:45:42.314] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:45:43.065] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:45:43.821] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:45:44.721] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:46:02.471] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:46:54.058] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:46:54.847] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:46:55.834] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:47:06.266] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:47:51.183] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:47:51.926] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:48:23.439] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:48:30.301] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:49:01.631] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:49:15.214] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:49:32.704] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:50:08.238] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:50:08.957] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:50:22.813] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:51:04.894] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:51:47.161] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:52:29.221] [mlr3]  Finished benchmark 
INFO  [04:52:30.351] [bbotk] Result of batch 1: 
INFO  [04:52:30.353] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu classif.auc 
INFO  [04:52:30.353] [bbotk]                   9              1978    0.476528047   0.5000000 
INFO  [04:52:30.353] [bbotk]                   9              3335    0.276070945   0.5000000 
INFO  [04:52:30.353] [bbotk]                   4              1075    0.170377662   0.9776993 
INFO  [04:52:30.353] [bbotk]                   6              3507    0.393461741   0.9763168 
INFO  [04:52:30.353] [bbotk]                   6              1514    0.008503051   0.9710233 
INFO  [04:52:30.353] [bbotk]                   7              3139    0.165589133   0.9767331 
INFO  [04:52:30.353] [bbotk]                   7              4455    0.244579595   0.9761230 
INFO  [04:52:30.353] [bbotk]                   6              4097    0.093741471   0.9772680 
INFO  [04:52:30.353] [bbotk]                   7              1392    0.355958216   0.9767424 
INFO  [04:52:30.353] [bbotk]                   9              3895    0.215683476   0.5000000 
INFO  [04:52:30.353] [bbotk]                   5              2161    0.427792037   0.9778711 
INFO  [04:52:30.353] [bbotk]                   3              3751    0.196748765   0.9772942 
INFO  [04:52:30.353] [bbotk]                   8              2551    0.442054649   0.8149794 
INFO  [04:52:30.353] [bbotk]                   4               504    0.080318392   0.9745057 
INFO  [04:52:30.353] [bbotk]                   5              2983    0.263550614   0.9780030 
INFO  [04:52:30.353] [bbotk]                   3               766    0.305847004   0.9765780 
INFO  [04:52:30.353] [bbotk]                   8               887    0.137284832   0.8161107 
INFO  [04:52:30.353] [bbotk]                  10              1664    0.343517542   0.5000000 
INFO  [04:52:30.353] [bbotk]                   8              4876    0.115797738   0.8158330 
INFO  [04:52:30.353] [bbotk]                   4              2609    0.059549221   0.9775965 
INFO  [04:52:30.353] [bbotk]                  10              4765    0.413806921   0.5000000 
INFO  [04:52:30.353] [bbotk]                   5               397    0.497181800   0.9780303 
INFO  [04:52:30.353] [bbotk]                   3              4346    0.314552036   0.9774434 
INFO  [04:52:30.353] [bbotk]                  10              2204    0.025682092   0.5000000 
INFO  [04:52:30.353] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu classif.auc 
INFO  [04:52:30.353] [bbotk]                                 uhash 
INFO  [04:52:30.353] [bbotk]  ecb104db-7b0b-421c-b3cf-114477681e9c 
INFO  [04:52:30.353] [bbotk]  2c8d7bf7-c940-4822-8da9-52a8cbb94777 
INFO  [04:52:30.353] [bbotk]  b106265c-73bb-4e02-9da3-670ac9d40b6c 
INFO  [04:52:30.353] [bbotk]  70864514-4f61-450c-bcd5-d18423d0beed 
INFO  [04:52:30.353] [bbotk]  063d70bc-617d-4a74-9aad-e0ebb8f94628 
INFO  [04:52:30.353] [bbotk]  888c9fc2-8afa-47ab-ace0-ca74fe42f34b 
INFO  [04:52:30.353] [bbotk]  8bb775a1-ea7a-4850-b347-7fc52aa69e52 
INFO  [04:52:30.353] [bbotk]  6810c6df-57c3-48c6-8bce-a7beca7adfc6 
INFO  [04:52:30.353] [bbotk]  42586cc6-b1cf-452a-b300-2e58eabc8b66 
INFO  [04:52:30.353] [bbotk]  b40dc909-10f5-4303-a5fc-b545e058eb59 
INFO  [04:52:30.353] [bbotk]  9276f79f-d5f4-4743-b3d6-6bb2b3b42d87 
INFO  [04:52:30.353] [bbotk]  2eda567d-d9c4-4572-9d8a-2e9a5561e1db 
INFO  [04:52:30.353] [bbotk]  2ef7e76b-0169-4314-a109-62bb8d67e00e 
INFO  [04:52:30.353] [bbotk]  cefe9e29-c7ab-4fb6-b999-86f281805801 
INFO  [04:52:30.353] [bbotk]  efa0120a-7411-4542-8873-f1ff8d9193ed 
INFO  [04:52:30.353] [bbotk]  1ae80d7f-0d1c-4f06-860e-746881f2e841 
INFO  [04:52:30.353] [bbotk]  5363970e-fc2f-4788-a8fb-eb04fb7a0a60 
INFO  [04:52:30.353] [bbotk]  bf73d21e-80b6-4066-9197-19435d301c9a 
INFO  [04:52:30.353] [bbotk]  99a570cd-df5b-4f9e-9996-c318529439ee 
INFO  [04:52:30.353] [bbotk]  dcc62fbe-d055-4802-800b-64cec75f6522 
INFO  [04:52:30.353] [bbotk]  c6f05c10-5c5f-4cd5-97e8-07f0ca0a5f2a 
INFO  [04:52:30.353] [bbotk]  8ed609ad-1e51-44bf-b2b6-00b7dcce75ee 
INFO  [04:52:30.353] [bbotk]  fc699586-6c8f-4b9c-95bb-cbf95e8774b2 
INFO  [04:52:30.353] [bbotk]  2a75a21c-997f-43f1-bcf6-5fc939c02939 
INFO  [04:52:30.353] [bbotk]                                 uhash 
DEBUG [04:52:30.951] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.240052e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.003897101 0.4240052 
  - best initial criterion value(s) :  33.07348 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -33.073  |proj g|=         3.93
At iterate     1  f =       -33.22  |proj g|=        2.6722
At iterate     2  f =      -34.082  |proj g|=        3.5923
At iterate     3  f =      -34.659  |proj g|=        3.5816
At iterate     4  f =      -35.956  |proj g|=        3.1981
At iterate     5  f =      -36.615  |proj g|=        3.0975
At iterate     6  f =      -37.434  |proj g|=        2.4469
At iterate     7  f =      -38.336  |proj g|=       0.67324
At iterate     8  f =      -39.382  |proj g|=        1.3377
At iterate     9  f =      -39.717  |proj g|=        1.5434
At iterate    10  f =      -39.847  |proj g|=       0.41278
At iterate    11  f =      -39.874  |proj g|=       0.15105
At iterate    12  f =      -39.887  |proj g|=      0.042413
At iterate    13  f =      -39.888  |proj g|=       0.41174
At iterate    14  f =      -39.888  |proj g|=     0.0083808
At iterate    15  f =      -39.888  |proj g|=     0.0013855

iterations 15
function evaluations 21
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00138549
final function value -39.8876

F = -39.8876
final  value -39.887618 
converged
 
INFO  [04:52:30.955] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:52:31.016] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:52:31.025] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:52:31.808] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:52:32.568] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:52:33.464] [mlr3]  Finished benchmark 
INFO  [04:52:33.537] [bbotk] Result of batch 2: 
INFO  [04:52:33.539] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:52:33.539] [bbotk]                   9              2746     0.01440761        0.392 -0.9281557 
INFO  [04:52:33.539] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:52:33.539] [bbotk]          <NA>         0.5 239e3aef-b0d8-49c5-9b40-22d2b389c43e 
DEBUG [04:52:34.100] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.518575e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.004181507 0.4518575 
  - best initial criterion value(s) :  34.99286 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -34.993  |proj g|=       3.1926
At iterate     1  f =      -39.788  |proj g|=       0.40723
At iterate     2  f =      -41.276  |proj g|=       0.38447
At iterate     3  f =      -41.753  |proj g|=       0.21486
At iterate     4  f =      -41.778  |proj g|=      0.020411
At iterate     5  f =      -41.781  |proj g|=       0.43976
At iterate     6  f =      -41.781  |proj g|=       0.43972
At iterate     7  f =      -41.781  |proj g|=       0.01188
At iterate     8  f =      -41.781  |proj g|=     0.0015488

iterations 8
function evaluations 13
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00154879
final function value -41.7807

F = -41.7807
final  value -41.780720 
converged
 
INFO  [04:52:34.104] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:52:34.158] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:52:34.164] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:53:17.772] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:53:18.526] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:54:01.409] [mlr3]  Finished benchmark 
INFO  [04:54:01.484] [bbotk] Result of batch 3: 
INFO  [04:54:01.485] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:54:01.485] [bbotk]                   8              3579      0.2087024        0.388 -0.9262826 
INFO  [04:54:01.485] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:54:01.485] [bbotk]          <NA>    0.815506 ba93e55f-e3f1-4623-a75d-a7ce540961d1 
DEBUG [04:54:02.123] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.3381e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.004059021 0.43381 
  - best initial criterion value(s) :  39.92162 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -39.922  |proj g|=       1.2369
At iterate     1  f =      -40.793  |proj g|=        2.3805
At iterate     2  f =      -41.147  |proj g|=        1.3635
At iterate     3  f =      -41.396  |proj g|=        1.0681
At iterate     4  f =      -41.422  |proj g|=       0.42137
At iterate     5  f =      -41.478  |proj g|=       0.39468
At iterate     6  f =      -41.962  |proj g|=       0.76379
At iterate     7  f =      -42.031  |proj g|=       0.34161
At iterate     8  f =      -42.048  |proj g|=       0.57017
At iterate     9  f =      -42.074  |proj g|=       0.42177
At iterate    10  f =      -42.075  |proj g|=     0.0081301
At iterate    11  f =      -42.075  |proj g|=      0.078033
At iterate    12  f =      -42.075  |proj g|=     0.0037678

iterations 12
function evaluations 17
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00376783
final function value -42.0748

F = -42.0748
final  value -42.074761 
converged
 
INFO  [04:54:02.127] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:54:02.182] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:54:02.189] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:54:23.533] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:54:44.972] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:54:45.692] [mlr3]  Finished benchmark 
INFO  [04:54:45.758] [bbotk] Result of batch 4: 
INFO  [04:54:45.759] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:54:45.759] [bbotk]                   8              1730      0.2226705        0.454 -0.9298472 
INFO  [04:54:45.759] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:54:45.759] [bbotk]          <NA>   0.8159714 e0cfd769-6c63-4490-8912-884967f95f5c 
DEBUG [04:54:46.384] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.171461e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.003915887 0.4171461 
  - best initial criterion value(s) :  40.48137 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -40.481  |proj g|=       2.4109
At iterate     1  f =      -46.591  |proj g|=      0.099095
At iterate     2  f =      -47.866  |proj g|=       0.57094
At iterate     3  f =      -48.305  |proj g|=       0.40626
At iterate     4  f =      -48.389  |proj g|=       0.94492
At iterate     5  f =      -48.393  |proj g|=       0.97017
At iterate     6  f =      -48.397  |proj g|=       0.94916
At iterate     7  f =      -48.436  |proj g|=       0.79297
At iterate     8  f =      -48.521  |proj g|=       0.59993
At iterate     9  f =      -48.737  |proj g|=       0.31329
At iterate    10  f =      -48.865  |proj g|=       0.13867
At iterate    11  f =      -48.937  |proj g|=       0.41884
At iterate    12  f =      -48.944  |proj g|=        0.1889
At iterate    13  f =      -48.946  |proj g|=      0.063374
At iterate    14  f =      -48.947  |proj g|=     0.0073137
At iterate    15  f =      -48.947  |proj g|=     0.0073117
At iterate    16  f =      -48.947  |proj g|=     0.0017639

iterations 16
function evaluations 21
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00176387
final function value -48.947

F = -48.947
final  value -48.946951 
converged
 
INFO  [04:54:46.388] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:54:46.448] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:54:46.454] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:55:06.150] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:55:25.756] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:55:46.086] [mlr3]  Finished benchmark 
INFO  [04:55:46.150] [bbotk] Result of batch 5: 
INFO  [04:55:46.152] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:55:46.152] [bbotk]                   4              1579     0.07159718        0.434 -0.9228159 
INFO  [04:55:46.152] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:55:46.152] [bbotk]          <NA>   0.9772263 719baa55-5def-4c08-a0bd-81fc30439e42 
DEBUG [04:55:46.898] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.101641e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.003827196 0.4101641 
  - best initial criterion value(s) :  32.19098 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -32.191  |proj g|=        4.274
At iterate     1  f =      -37.902  |proj g|=        2.5388
At iterate     2  f =      -38.116  |proj g|=        2.2188
At iterate     3  f =      -38.168  |proj g|=        2.1572
At iterate     4  f =      -38.457  |proj g|=        2.2901
At iterate     5  f =      -39.778  |proj g|=        2.3862
At iterate     6  f =      -42.825  |proj g|=        1.5654
At iterate     7  f =       -42.98  |proj g|=        2.0789
At iterate     8  f =      -43.463  |proj g|=        1.0018
At iterate     9  f =      -43.517  |proj g|=       0.39523
At iterate    10  f =      -43.534  |proj g|=      0.036483
At iterate    11  f =      -43.534  |proj g|=       0.39825
At iterate    12  f =      -43.534  |proj g|=     0.0081009
At iterate    13  f =      -43.534  |proj g|=     0.0080995
At iterate    14  f =      -43.534  |proj g|=      0.028115

iterations 14
function evaluations 19
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0281149
final function value -43.5338

F = -43.5338
final  value -43.533828 
converged
 
INFO  [04:55:46.902] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:55:46.957] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:55:46.964] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:55:47.692] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:55:48.422] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:55:49.298] [mlr3]  Finished benchmark 
INFO  [04:55:49.361] [bbotk] Result of batch 6: 
INFO  [04:55:49.363] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:55:49.363] [bbotk]                   9              3649      0.3946787        0.551 -0.9298297 
INFO  [04:55:49.363] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:55:49.363] [bbotk]          <NA>         0.5 76cb84ea-5235-4feb-b081-5eafc56a719d 
DEBUG [04:55:49.937] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.32782e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.004059312 0.432782 
  - best initial criterion value(s) :  42.38164 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -42.382  |proj g|=      0.72118
At iterate     1  f =      -47.342  |proj g|=        2.0435
At iterate     2  f =      -48.426  |proj g|=        3.1032
At iterate     3  f =      -48.968  |proj g|=        3.2885
At iterate     4  f =      -49.251  |proj g|=       0.90683
At iterate     5  f =      -50.038  |proj g|=        2.1842
At iterate     6  f =      -50.687  |proj g|=        3.1084
At iterate     7  f =      -51.296  |proj g|=        2.9163
At iterate     8  f =      -52.975  |proj g|=        2.4502
At iterate     9  f =      -54.578  |proj g|=       0.02093
At iterate    10  f =      -54.591  |proj g|=      0.041077
At iterate    11  f =      -54.591  |proj g|=       0.36557
At iterate    12  f =      -54.591  |proj g|=     0.0065521
At iterate    13  f =      -54.591  |proj g|=      0.002393

iterations 13
function evaluations 20
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00239297
final function value -54.5912

F = -54.5912
final  value -54.591184 
converged
 
INFO  [04:55:49.940] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:55:50.002] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:55:50.008] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:56:39.868] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:57:30.044] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:58:19.815] [mlr3]  Finished benchmark 
INFO  [04:58:19.880] [bbotk] Result of batch 7: 
INFO  [04:58:19.882] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:58:19.882] [bbotk]                   3              4161      0.4728849          0.4 -0.9206168 
INFO  [04:58:19.882] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:58:19.882] [bbotk]          <NA>   0.9774359 fb1de84b-b4ca-4345-9b49-f323bbf6e0b6 
DEBUG [04:58:20.503] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.263947e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.004025605 0.4263947 
  - best initial criterion value(s) :  46.80155 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -46.802  |proj g|=       4.7473
At iterate     1  f =      -49.643  |proj g|=        2.2343
At iterate     2  f =      -50.881  |proj g|=        4.3374
At iterate     3  f =      -51.512  |proj g|=        4.2193
At iterate     4  f =      -53.073  |proj g|=        3.8667
At iterate     5  f =      -56.367  |proj g|=        2.9344
At iterate     6  f =      -59.119  |proj g|=        2.8508
At iterate     7  f =      -59.524  |proj g|=         2.783
At iterate     8  f =      -59.857  |proj g|=        2.6888
At iterate     9  f =      -60.384  |proj g|=         2.423
At iterate    10  f =      -61.405  |proj g|=        2.2005
At iterate    11  f =      -62.165  |proj g|=       0.45199
At iterate    12  f =      -62.208  |proj g|=       0.22537
At iterate    13  f =      -62.291  |proj g|=      0.015416
At iterate    14  f =      -62.297  |proj g|=       0.41664
At iterate    15  f =      -62.298  |proj g|=     0.0058485
At iterate    16  f =      -62.298  |proj g|=     0.0058396
At iterate    17  f =      -62.298  |proj g|=     0.0015561

iterations 17
function evaluations 25
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00155612
final function value -62.2982

F = -62.2982
final  value -62.298194 
converged
 
INFO  [04:58:20.507] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:58:20.561] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:58:20.568] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:58:21.332] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:58:48.336] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:59:15.793] [mlr3]  Finished benchmark 
INFO  [04:59:15.859] [bbotk] Result of batch 8: 
INFO  [04:59:15.861] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [04:59:15.861] [bbotk]                   8              2249     0.07186335        0.413 -0.9156202 
INFO  [04:59:15.861] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:59:15.861] [bbotk]          <NA>   0.8161033 36e29f17-11bb-4ba2-8e94-6ccb4e319ef6 
DEBUG [04:59:16.445] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.121958e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.003874478 0.4121958 
  - best initial criterion value(s) :  46.40627 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -46.406  |proj g|=       6.9791
At iterate     1  f =       -52.92  |proj g|=        2.9072
At iterate     2  f =      -54.184  |proj g|=        2.5828
At iterate     3  f =      -54.308  |proj g|=        2.5389
At iterate     4  f =      -55.703  |proj g|=         2.053
At iterate     5  f =      -55.953  |proj g|=        1.1807
At iterate     6  f =      -55.987  |proj g|=       0.34865
At iterate     7  f =      -56.014  |proj g|=       0.17021
At iterate     8  f =      -56.022  |proj g|=       0.26162
At iterate     9  f =      -56.061  |proj g|=       0.65689
At iterate    10  f =      -56.148  |proj g|=         1.205
At iterate    11  f =      -56.385  |proj g|=        1.8703
At iterate    12  f =      -56.967  |proj g|=        1.9511
At iterate    13  f =      -57.693  |proj g|=        1.9923
At iterate    14  f =      -58.127  |proj g|=        1.4362
At iterate    15  f =      -58.205  |proj g|=         0.534
At iterate    16  f =      -58.219  |proj g|=       0.18378
At iterate    17  f =      -58.227  |proj g|=      0.015009
At iterate    18  f =      -58.232  |proj g|=      0.066681
At iterate    19  f =      -58.233  |proj g|=      0.014411
At iterate    20  f =      -58.233  |proj g|=      0.016286
At iterate    21  f =      -58.233  |proj g|=     0.0049107

iterations 21
function evaluations 28
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00491066
final function value -58.2327

F = -58.2327
final  value -58.232725 
converged
 
INFO  [04:59:16.449] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:59:16.507] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:59:16.514] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [04:59:17.246] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [04:59:18.057] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [04:59:19.077] [mlr3]  Finished benchmark 
INFO  [04:59:19.164] [bbotk] Result of batch 9: 
INFO  [04:59:19.166] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [04:59:19.166] [bbotk]                   9              3962      0.2774032        0.402 -0.919812 
INFO  [04:59:19.166] [bbotk]  errors.model classif.auc                                uhash 
INFO  [04:59:19.166] [bbotk]          <NA>         0.5 c7d6f7a5-4e40-4903-97de-539766f69a69 
DEBUG [04:59:19.756] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.314069e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.004116533 0.4314069 
  - best initial criterion value(s) :  53.10803 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -53.108  |proj g|=       6.3859
At iterate     1  f =      -62.057  |proj g|=        3.0039
At iterate     2  f =      -62.625  |proj g|=        2.8793
At iterate     3  f =      -63.951  |proj g|=        2.4404
At iterate     4  f =      -65.227  |proj g|=        1.8558
At iterate     5  f =      -65.265  |proj g|=       0.88568
At iterate     6  f =      -65.315  |proj g|=       0.74201
At iterate     7  f =      -65.359  |proj g|=       0.90682
At iterate     8  f =      -65.499  |proj g|=        1.2364
At iterate     9  f =      -65.891  |proj g|=        1.7688
At iterate    10  f =      -66.972  |proj g|=        1.8194
At iterate    11  f =      -69.519  |proj g|=        1.9551
At iterate    12  f =      -70.345  |proj g|=       0.52657
At iterate    13  f =      -70.509  |proj g|=       0.42288
At iterate    14  f =      -70.562  |proj g|=       0.42231
At iterate    15  f =      -70.569  |proj g|=       0.42206
At iterate    16  f =      -70.569  |proj g|=       0.42201
At iterate    17  f =      -70.569  |proj g|=     0.0090839
At iterate    18  f =      -70.569  |proj g|=     0.0016196

iterations 18
function evaluations 23
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00161957
final function value -70.5688

F = -70.5688
final  value -70.568829 
converged
 
INFO  [04:59:19.760] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:59:19.821] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:59:19.829] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:00:03.964] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:00:47.639] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:01:31.103] [mlr3]  Finished benchmark 
INFO  [05:01:31.167] [bbotk] Result of batch 10: 
INFO  [05:01:31.169] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:01:31.169] [bbotk]                   5              3640      0.1232877        0.409 -0.9107432 
INFO  [05:01:31.169] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:01:31.169] [bbotk]          <NA>   0.9783264 14a52f05-b562-45b2-8fc6-8ba5875574fb 
DEBUG [05:01:31.766] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.262634e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.004098359 0.4262633 
  - best initial criterion value(s) :  51.20884 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -51.209  |proj g|=       4.0885
At iterate     1  f =      -62.766  |proj g|=       0.57754
At iterate     2  f =       -68.58  |proj g|=         1.056
At iterate     3  f =       -68.81  |proj g|=        1.2035
At iterate     4  f =      -68.815  |proj g|=        1.3057
At iterate     5  f =      -68.826  |proj g|=        1.1358
At iterate     6  f =      -68.862  |proj g|=       0.87373
At iterate     7  f =      -69.005  |proj g|=       0.41805
At iterate     8  f =      -69.323  |proj g|=       0.90219
At iterate     9  f =      -69.852  |proj g|=        1.3482
At iterate    10  f =      -70.054  |proj g|=       0.98828
At iterate    11  f =       -70.07  |proj g|=       0.80126
At iterate    12  f =      -70.099  |proj g|=       0.15321
At iterate    13  f =      -70.099  |proj g|=       0.11691
At iterate    14  f =      -70.099  |proj g|=      0.022792

iterations 14
function evaluations 22
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0227916
final function value -70.0989

F = -70.0989
final  value -70.098892 
converged
 
INFO  [05:01:31.770] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:01:31.823] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:01:31.830] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:01:32.574] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:01:33.371] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:01:34.096] [mlr3]  Finished benchmark 
INFO  [05:01:34.161] [bbotk] Result of batch 11: 
INFO  [05:01:34.163] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:01:34.163] [bbotk]                  10              3468     0.04905086        0.418 -0.9134856 
INFO  [05:01:34.163] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:01:34.163] [bbotk]          <NA>         0.5 6ae48ef3-19ac-4a55-900f-e56471c63de0 
DEBUG [05:01:34.783] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.429908e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.004223252 0.4429908 
  - best initial criterion value(s) :  46.17687 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -46.177  |proj g|=       5.9087
At iterate     1  f =      -56.883  |proj g|=        2.9066
At iterate     2  f =      -57.435  |proj g|=        2.3743
At iterate     3  f =      -57.781  |proj g|=        2.1861
At iterate     4  f =      -57.801  |proj g|=        2.2406
At iterate     5  f =      -58.536  |proj g|=        2.3529
At iterate     6  f =      -61.713  |proj g|=        2.4973
At iterate     7  f =      -66.291  |proj g|=        1.3213
At iterate     8  f =      -67.676  |proj g|=        1.6681
At iterate     9  f =      -69.817  |proj g|=        0.2183
At iterate    10  f =      -70.112  |proj g|=        1.0375
At iterate    11  f =      -70.173  |proj g|=       0.43389
At iterate    12  f =      -70.173  |proj g|=      0.040012
At iterate    13  f =      -70.173  |proj g|=     0.0049574
At iterate    14  f =      -70.173  |proj g|=     0.0031213

iterations 14
function evaluations 21
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00312131
final function value -70.1734

F = -70.1734
final  value -70.173398 
converged
 
INFO  [05:01:34.787] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:01:34.841] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:01:34.848] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:02:17.716] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:02:59.944] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:03:42.103] [mlr3]  Finished benchmark 
INFO  [05:03:42.178] [bbotk] Result of batch 12: 
INFO  [05:03:42.180] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:03:42.180] [bbotk]                   6              3548      0.1100993        0.444 -0.9145313 
INFO  [05:03:42.180] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:03:42.180] [bbotk]          <NA>   0.9772448 0a688125-939c-4c44-adcb-4ec5270784f8 
DEBUG [05:03:42.760] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.381321e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.004164981 0.4381321 
  - best initial criterion value(s) :  70.20348 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -70.203  |proj g|=       1.7432
At iterate     1  f =      -78.294  |proj g|=       0.53894
At iterate     2  f =      -78.314  |proj g|=       0.78066
At iterate     3  f =      -78.348  |proj g|=       0.42945
At iterate     4  f =       -78.37  |proj g|=       0.42945
At iterate     5  f =      -78.384  |proj g|=       0.44706
At iterate     6  f =      -78.457  |proj g|=       0.75185
At iterate     7  f =      -78.475  |proj g|=       0.46172
At iterate     8  f =      -78.484  |proj g|=      0.012283
At iterate     9  f =      -78.484  |proj g|=     0.0046175
At iterate    10  f =      -78.484  |proj g|=      0.014217

iterations 10
function evaluations 16
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0142174
final function value -78.4838

F = -78.4838
final  value -78.483754 
converged
 
INFO  [05:03:42.764] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:03:42.823] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:03:42.831] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:04:25.966] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:05:09.584] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:05:52.372] [mlr3]  Finished benchmark 
INFO  [05:05:52.437] [bbotk] Result of batch 13: 
INFO  [05:05:52.438] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:05:52.438] [bbotk]                   5              3639      0.1624078        0.421 -0.9101202 
INFO  [05:05:52.438] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:05:52.438] [bbotk]          <NA>   0.9782779 ec2d1da3-7d55-49c9-ac1c-6bf87e2a5dc1 
DEBUG [05:05:53.035] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.332048e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.004124835 0.4332048 
  - best initial criterion value(s) :  54.29872 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -54.299  |proj g|=        6.554
At iterate     1  f =      -59.742  |proj g|=       0.65443
At iterate     2  f =      -63.923  |proj g|=        1.8831
At iterate     3  f =      -67.968  |proj g|=        4.9437
At iterate     4  f =       -68.78  |proj g|=        4.8137
At iterate     5  f =      -71.344  |proj g|=        4.4052
At iterate     6  f =       -74.97  |proj g|=          3.74
At iterate     7  f =      -78.284  |proj g|=        3.1106
At iterate     8  f =      -81.002  |proj g|=        2.6814
At iterate     9  f =      -83.719  |proj g|=        1.9819
At iterate    10  f =      -84.146  |proj g|=       0.67631
At iterate    11  f =      -84.219  |proj g|=       0.85039
At iterate    12  f =      -84.265  |proj g|=      0.026848
At iterate    13  f =      -84.267  |proj g|=     0.0044093
At iterate    14  f =      -84.268  |proj g|=       0.12518
At iterate    15  f =      -84.268  |proj g|=     0.0023328

iterations 15
function evaluations 28
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00233284
final function value -84.2675

F = -84.2675
final  value -84.267506 
converged
 
INFO  [05:05:53.039] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:05:53.099] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:05:53.107] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:06:18.747] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:06:44.152] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:07:09.536] [mlr3]  Finished benchmark 
INFO  [05:07:09.602] [bbotk] Result of batch 14: 
INFO  [05:07:09.604] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:07:09.604] [bbotk]                   3              2100      0.1887685        0.427 -0.9082914 
INFO  [05:07:09.604] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:07:09.604] [bbotk]          <NA>   0.9771616 c0d0600d-53d2-4e33-beea-b65b7643ad36 
DEBUG [05:07:10.229] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.280556e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.004080638 0.4280556 
  - best initial criterion value(s) :  64.70321 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -64.703  |proj g|=       4.8146
At iterate     1  f =      -68.809  |proj g|=        2.1058
At iterate     2  f =      -71.341  |proj g|=        4.3429
At iterate     3  f =      -72.374  |proj g|=        4.2284
At iterate     4  f =      -77.533  |proj g|=        3.5524
At iterate     5  f =      -88.789  |proj g|=        1.8385
At iterate     6  f =      -90.773  |proj g|=       0.56281
At iterate     7  f =      -90.965  |proj g|=      0.051087
At iterate     8  f =      -91.061  |proj g|=         1.633
At iterate     9  f =      -91.107  |proj g|=       0.82096
At iterate    10  f =      -91.111  |proj g|=       0.95708
At iterate    11  f =      -91.111  |proj g|=       0.98864
At iterate    12  f =      -91.111  |proj g|=       0.99629
At iterate    13  f =      -91.112  |proj g|=        1.0306
At iterate    14  f =      -91.113  |proj g|=        1.0572
At iterate    15  f =      -91.118  |proj g|=        1.0696
At iterate    16  f =      -91.127  |proj g|=       0.99897
At iterate    17  f =      -91.144  |proj g|=       0.72035
At iterate    18  f =      -91.164  |proj g|=       0.41999
At iterate    19  f =      -91.166  |proj g|=        0.4199
At iterate    20  f =      -91.166  |proj g|=       0.21998
At iterate    21  f =      -91.166  |proj g|=     0.0019922
At iterate    22  f =      -91.166  |proj g|=     0.0019922

iterations 22
function evaluations 30
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00199224
final function value -91.1663

F = -91.1663
final  value -91.166319 
converged
 
INFO  [05:07:10.233] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:07:10.295] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:07:10.302] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:07:26.102] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:07:42.177] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:07:57.892] [mlr3]  Finished benchmark 
INFO  [05:07:57.958] [bbotk] Result of batch 15: 
INFO  [05:07:57.960] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [05:07:57.960] [bbotk]                   4              1260      0.2277959        0.436 -0.905005 
INFO  [05:07:57.960] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:07:57.960] [bbotk]          <NA>   0.9779219 0d554eda-fba0-457b-af15-c649c7662b65 
DEBUG [05:07:58.567] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.228946e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.004038087 0.4228946 
  - best initial criterion value(s) :  68.67215 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -68.672  |proj g|=       5.9047
At iterate     1  f =      -69.731  |proj g|=        1.1398
At iterate     2  f =      -75.301  |proj g|=        2.6909
At iterate     3  f =      -77.978  |proj g|=        4.7383
At iterate     4  f =      -79.072  |proj g|=        4.6498
At iterate     5  f =      -83.391  |proj g|=         3.759
At iterate     6  f =      -93.775  |proj g|=         1.887
At iterate     7  f =      -94.504  |proj g|=       0.78658
At iterate     8  f =      -94.558  |proj g|=       0.12371
At iterate     9  f =       -94.56  |proj g|=      0.050104
At iterate    10  f =       -94.56  |proj g|=       0.28338
At iterate    11  f =       -94.56  |proj g|=     0.0022179

iterations 11
function evaluations 20
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00221793
final function value -94.5601

F = -94.5601
final  value -94.560061 
converged
 
INFO  [05:07:58.571] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:07:58.627] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:07:58.634] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:08:39.605] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:09:20.605] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:10:00.963] [mlr3]  Finished benchmark 
INFO  [05:10:01.030] [bbotk] Result of batch 16: 
INFO  [05:10:01.032] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:10:01.032] [bbotk]                   5              3381      0.2469896        0.429 -0.9043643 
INFO  [05:10:01.032] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:10:01.032] [bbotk]          <NA>   0.9779826 393a424e-934d-4988-a751-641df48496cb 
DEBUG [05:10:01.650] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.176899e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8958 0.9773575 
  - variance bounds :  0.003999025 0.4176899 
  - best initial criterion value(s) :  75.01143 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -75.011  |proj g|=       4.3116
At iterate     1  f =      -81.224  |proj g|=        3.5634
At iterate     2  f =      -84.509  |proj g|=        3.0663
At iterate     3  f =       -85.59  |proj g|=        2.8031
At iterate     4  f =      -87.401  |proj g|=        2.2992
At iterate     5  f =      -88.758  |proj g|=        1.3142
At iterate     6  f =      -88.767  |proj g|=        1.1802
At iterate     7  f =       -88.87  |proj g|=       0.58927
At iterate     8  f =      -89.349  |proj g|=        1.2021
At iterate     9  f =      -90.359  |proj g|=        3.3026
At iterate    10  f =      -92.589  |proj g|=        5.6599
At iterate    11  f =      -93.221  |proj g|=        3.5098
At iterate    12  f =      -93.748  |proj g|=       0.45831
At iterate    13  f =      -93.756  |proj g|=       0.40982
At iterate    14  f =      -93.756  |proj g|=       0.40978
At iterate    15  f =      -93.756  |proj g|=      0.029767
At iterate    16  f =      -93.756  |proj g|=     0.0033625

iterations 16
function evaluations 24
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00336249
final function value -93.7564

F = -93.7564
final  value -93.756450 
converged
 
INFO  [05:10:01.654] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:10:01.713] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:10:01.721] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:10:02.604] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:10:03.455] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:10:04.288] [mlr3]  Finished benchmark 
INFO  [05:10:04.379] [bbotk] Result of batch 17: 
INFO  [05:10:04.381] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:10:04.381] [bbotk]                  10              4963      0.4818509        0.432 -0.9068586 
INFO  [05:10:04.381] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:10:04.381] [bbotk]          <NA>         0.5 11703de5-3b17-4025-9b95-c2c2458461f5 
DEBUG [05:10:05.053] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.34185e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.0042497 0.434185 
  - best initial criterion value(s) :  78.68054 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -78.681  |proj g|=       1.5176
At iterate     1  f =      -82.446  |proj g|=        2.9717
At iterate     2  f =      -83.362  |proj g|=        2.8764
At iterate     3  f =      -83.998  |proj g|=        2.6423
At iterate     4  f =      -84.597  |proj g|=        1.9878
At iterate     5  f =      -84.731  |proj g|=        1.4728
At iterate     6  f =      -84.953  |proj g|=        2.1564
At iterate     7  f =      -85.001  |proj g|=        2.0973
At iterate     8  f =      -85.008  |proj g|=        2.0782
At iterate     9  f =       -85.03  |proj g|=        2.0502
At iterate    10  f =      -85.107  |proj g|=         1.987
At iterate    11  f =      -85.282  |proj g|=        1.2582
At iterate    12  f =      -85.735  |proj g|=       0.32307
At iterate    13  f =      -86.737  |proj g|=        2.4419
At iterate    14  f =      -88.784  |proj g|=        4.9003
At iterate    15  f =      -90.141  |proj g|=        3.3814
At iterate    16  f =      -90.555  |proj g|=       0.42625
At iterate    17  f =      -90.562  |proj g|=      0.075857
At iterate    18  f =      -90.572  |proj g|=     0.0098394
At iterate    19  f =      -90.572  |proj g|=       0.42597
At iterate    20  f =      -90.572  |proj g|=      0.033063
At iterate    21  f =      -90.572  |proj g|=     0.0051431

iterations 21
function evaluations 25
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00514307
final function value -90.5717

F = -90.5717
final  value -90.571666 
converged
 
INFO  [05:10:05.057] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:10:05.116] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:10:05.124] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:10:05.946] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:10:06.824] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:10:07.580] [mlr3]  Finished benchmark 
INFO  [05:10:07.645] [bbotk] Result of batch 18: 
INFO  [05:10:07.646] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:10:07.646] [bbotk]                   9              4455      0.4277709        0.479 -0.9047652 
INFO  [05:10:07.646] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:10:07.646] [bbotk]          <NA>         0.5 e4261415-31ea-45eb-b40a-35a10568f703 
DEBUG [05:10:08.271] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.485615e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004423595 0.4485615 
  - best initial criterion value(s) :  72.24648 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -72.246  |proj g|=       5.1691
At iterate     1  f =      -79.224  |proj g|=        3.3738
At iterate     2  f =      -95.926  |proj g|=        2.8733
At iterate     3  f =      -98.504  |proj g|=        2.5765
At iterate     4  f =      -101.64  |proj g|=       0.26677
At iterate     5  f =      -104.25  |proj g|=       0.94315
At iterate     6  f =      -104.34  |proj g|=        1.6751
At iterate     7  f =      -104.36  |proj g|=        2.9415
At iterate     8  f =      -104.37  |proj g|=        2.5042
At iterate     9  f =      -104.38  |proj g|=        2.3941
At iterate    10  f =       -104.4  |proj g|=         1.977
At iterate    11  f =      -104.46  |proj g|=         1.445
At iterate    12  f =      -104.63  |proj g|=        0.4491
At iterate    13  f =      -105.06  |proj g|=        1.1666
At iterate    14  f =      -106.18  |proj g|=        1.8425
At iterate    15  f =      -107.23  |proj g|=        1.9022
At iterate    16  f =      -107.59  |proj g|=        1.7092
At iterate    17  f =      -107.66  |proj g|=       0.80159
At iterate    18  f =      -107.67  |proj g|=       0.40492
At iterate    19  f =      -107.68  |proj g|=       0.12305
At iterate    20  f =      -107.69  |proj g|=       0.11475
At iterate    21  f =       -107.7  |proj g|=       0.44107
At iterate    22  f =       -107.7  |proj g|=     0.0030922
At iterate    23  f =       -107.7  |proj g|=     0.0027311
At iterate    24  f =       -107.7  |proj g|=     0.0025281

iterations 24
function evaluations 34
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00252808
final function value -107.697

F = -107.697
final  value -107.696807 
converged
 
INFO  [05:10:08.275] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:10:08.329] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:10:08.336] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:10:27.092] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:10:44.672] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:11:02.438] [mlr3]  Finished benchmark 
INFO  [05:11:02.504] [bbotk] Result of batch 19: 
INFO  [05:11:02.506] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:11:02.506] [bbotk]                   3              1422      0.4545284        0.432 -0.8983045 
INFO  [05:11:02.506] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:11:02.506] [bbotk]          <NA>   0.9772738 5aba8ed0-9cb5-43dd-ac56-27ba1529bb7d 
DEBUG [05:11:03.126] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.439847e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.00440619 0.4439847 
  - best initial criterion value(s) :  93.21527 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -93.215  |proj g|=       2.2212
At iterate     1  f =      -108.87  |proj g|=          2.47
At iterate     2  f =      -109.03  |proj g|=        2.5162
At iterate     3  f =      -109.43  |proj g|=        2.4501
At iterate     4  f =      -111.05  |proj g|=        2.0488
At iterate     5  f =      -111.64  |proj g|=       0.72382
At iterate     6  f =      -111.74  |proj g|=       0.78034
At iterate     7  f =      -111.76  |proj g|=       0.43668
At iterate     8  f =      -111.76  |proj g|=      0.037238
At iterate     9  f =      -111.76  |proj g|=      0.011797

iterations 9
function evaluations 17
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0117971
final function value -111.761

F = -111.761
final  value -111.760531 
converged
 
INFO  [05:11:03.130] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:11:03.187] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:11:03.194] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:11:25.856] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:11:48.544] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:12:11.313] [mlr3]  Finished benchmark 
INFO  [05:12:11.377] [bbotk] Result of batch 20: 
INFO  [05:12:11.379] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:12:11.379] [bbotk]                   6              1859      0.1870085        0.433 -0.8972373 
INFO  [05:12:11.379] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:12:11.379] [bbotk]          <NA>    0.977333 92137501-95e4-4d9f-bbd7-da9b1de954fb 
DEBUG [05:12:12.004] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.393413e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004393413 0.4408902 
  - best initial criterion value(s) :  77.6575 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -77.657  |proj g|=      0.46509
At iterate     1  f =      -92.237  |proj g|=        3.3308
At iterate     2  f =      -97.077  |proj g|=        3.4055
At iterate     3  f =      -99.005  |proj g|=        3.3118
At iterate     4  f =      -101.82  |proj g|=        3.1563
At iterate     5  f =      -102.47  |proj g|=        3.1137
At iterate     6  f =      -102.85  |proj g|=        3.0512
At iterate     7  f =      -103.81  |proj g|=        2.8171
At iterate     8  f =      -104.72  |proj g|=        1.5636
At iterate     9  f =      -106.58  |proj g|=        1.6226
At iterate    10  f =      -108.09  |proj g|=        3.5019
At iterate    11  f =      -108.92  |proj g|=        1.5565
At iterate    12  f =         -109  |proj g|=       0.10863
At iterate    13  f =      -109.01  |proj g|=     0.0087339
At iterate    14  f =      -109.01  |proj g|=       0.21374
At iterate    15  f =      -109.01  |proj g|=     0.0037651

iterations 15
function evaluations 23
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00376513
final function value -109.007

F = -109.007
final  value -109.006908 
converged
 
INFO  [05:12:12.008] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:12:12.061] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:12:12.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:13:00.287] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:13:48.302] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:14:36.316] [mlr3]  Finished benchmark 
INFO  [05:14:36.380] [bbotk] Result of batch 21: 
INFO  [05:14:36.382] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:14:36.382] [bbotk]                   6              4052     0.03830958        0.433 -0.8985506 
INFO  [05:14:36.382] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:14:36.382] [bbotk]          <NA>   0.9779745 30e33b57-6b82-49f1-9c4f-6ede32a98f91 
DEBUG [05:14:37.023] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.346963e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.00429017 0.4346963 
  - best initial criterion value(s) :  90.38148 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -90.381  |proj g|=       8.5502
At iterate     1  f =      -103.52  |proj g|=        3.7536
At iterate     2  f =      -104.13  |proj g|=         3.696
At iterate     3  f =      -107.79  |proj g|=        3.1079
At iterate     4  f =      -111.26  |proj g|=        2.6019
At iterate     5  f =      -114.99  |proj g|=        1.4715
At iterate     6  f =         -115  |proj g|=        1.1044
At iterate     7  f =      -115.17  |proj g|=         1.929
At iterate     8  f =      -115.37  |proj g|=       0.50331
At iterate     9  f =      -115.62  |proj g|=       0.45343
At iterate    10  f =      -117.03  |proj g|=        1.8916
At iterate    11  f =      -117.78  |proj g|=        1.9327
At iterate    12  f =      -118.08  |proj g|=       0.90392
At iterate    13  f =      -118.12  |proj g|=      0.025089
At iterate    14  f =      -118.12  |proj g|=       0.42762
At iterate    15  f =      -118.12  |proj g|=     0.0029474
At iterate    16  f =      -118.12  |proj g|=     0.0029474

iterations 16
function evaluations 23
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00294741
final function value -118.124

F = -118.124
final  value -118.123526 
converged
 
INFO  [05:14:37.027] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:14:37.082] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:14:37.089] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:15:26.711] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:16:17.249] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:17:06.110] [mlr3]  Finished benchmark 
INFO  [05:17:06.201] [bbotk] Result of batch 22: 
INFO  [05:17:06.204] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:17:06.204] [bbotk]                   3              4156      0.4438469        0.438 -0.8974329 
INFO  [05:17:06.204] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:17:06.204] [bbotk]          <NA>   0.9774731 8a9a915f-441b-4d70-809c-02b37e56d965 
DEBUG [05:17:06.835] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.299863e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004225185 0.4299863 
  - best initial criterion value(s) :  97.10896 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -97.109  |proj g|=      0.54857
At iterate     1  f =      -113.48  |proj g|=        3.1799
At iterate     2  f =       -114.6  |proj g|=        3.1916
At iterate     3  f =      -116.99  |proj g|=         3.089
At iterate     4  f =      -123.16  |proj g|=        2.0142
At iterate     5  f =      -123.74  |proj g|=        2.5069
At iterate     6  f =      -123.75  |proj g|=      0.036008
At iterate     7  f =      -123.92  |proj g|=        1.0056
At iterate     8  f =      -123.95  |proj g|=       0.16472
At iterate     9  f =      -123.95  |proj g|=      0.012444
At iterate    10  f =      -123.95  |proj g|=     0.0028912
At iterate    11  f =      -123.95  |proj g|=       0.10727

iterations 11
function evaluations 16
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.107273
final function value -123.954

F = -123.954
final  value -123.954085 
converged
 
INFO  [05:17:06.840] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:17:06.909] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:17:06.917] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:17:25.928] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:17:44.565] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:17:45.328] [mlr3]  Finished benchmark 
INFO  [05:17:45.392] [bbotk] Result of batch 23: 
INFO  [05:17:45.394] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:17:45.394] [bbotk]                   8              1505      0.2158594        0.439 -0.8979575 
INFO  [05:17:45.394] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:17:45.394] [bbotk]          <NA>   0.8159937 5dc6c5f8-b232-4db4-abac-59ed9f8c997e 
DEBUG [05:17:46.072] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.204642e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004133379 0.4204642 
  - best initial criterion value(s) :  106.8221 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -106.82  |proj g|=       4.5509
At iterate     1  f =      -116.67  |proj g|=        3.3282
At iterate     2  f =       -125.8  |proj g|=        2.2053
At iterate     3  f =      -125.96  |proj g|=       0.41384
At iterate     4  f =      -125.97  |proj g|=      0.033095
At iterate     5  f =      -125.97  |proj g|=     0.0053914
At iterate     6  f =      -125.97  |proj g|=     0.0036934
At iterate     7  f =      -125.97  |proj g|=       0.41366
At iterate     8  f =      -125.97  |proj g|=       0.41366
At iterate     9  f =      -125.97  |proj g|=       0.41366
At iterate    10  f =      -125.97  |proj g|=       0.41367
At iterate    11  f =      -125.97  |proj g|=       0.41367
At iterate    12  f =      -125.97  |proj g|=       0.41368
At iterate    13  f =      -125.97  |proj g|=        0.4137
At iterate    14  f =      -125.97  |proj g|=       0.41371
At iterate    15  f =      -125.97  |proj g|=       0.41372
At iterate    16  f =      -125.98  |proj g|=       0.47163
At iterate    17  f =      -125.98  |proj g|=        0.4836
At iterate    18  f =      -125.98  |proj g|=       0.54245
At iterate    19  f =      -125.98  |proj g|=       0.54835
At iterate    20  f =      -125.98  |proj g|=        0.5705
At iterate    21  f =      -125.98  |proj g|=        0.5986
At iterate    22  f =      -125.98  |proj g|=       0.63789
At iterate    23  f =      -125.99  |proj g|=       0.67652
At iterate    24  f =         -126  |proj g|=        0.6769
At iterate    25  f =      -126.03  |proj g|=        0.5129
At iterate    26  f =      -126.09  |proj g|=        0.4142
At iterate    27  f =      -126.17  |proj g|=        1.3097
At iterate    28  f =      -126.18  |proj g|=        1.7049
At iterate    29  f =      -126.18  |proj g|=        1.7267
At iterate    30  f =      -126.18  |proj g|=        1.7293
At iterate    31  f =      -126.18  |proj g|=        1.7456
At iterate    32  f =      -126.19  |proj g|=         1.772
At iterate    33  f =      -126.19  |proj g|=        1.8285
At iterate    34  f =       -126.2  |proj g|=         1.936
At iterate    35  f =      -126.21  |proj g|=        2.1397
At iterate    36  f =      -126.26  |proj g|=        2.5264
At iterate    37  f =      -126.38  |proj g|=        3.2442
At iterate    38  f =      -126.64  |proj g|=        4.5117
At iterate    39  f =      -127.14  |proj g|=         6.549
At iterate    40  f =      -127.78  |proj g|=        6.5783
At iterate    41  f =      -127.87  |proj g|=        7.4791
At iterate    42  f =      -128.09  |proj g|=         8.225
At iterate    43  f =      -130.51  |proj g|=        8.8225
At iterate    44  f =      -131.94  |proj g|=        5.8157
At iterate    45  f =      -132.96  |proj g|=       0.62246
At iterate    46  f =      -133.01  |proj g|=       0.41389
At iterate    47  f =      -133.02  |proj g|=       0.41384
At iterate    48  f =      -133.02  |proj g|=       0.41381
At iterate    49  f =      -133.02  |proj g|=      0.076983
At iterate    50  f =      -133.02  |proj g|=     0.0010951

iterations 50
function evaluations 60
segments explored during Cauchy searches 59
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00109515
final function value -133.019

F = -133.019
final  value -133.018560 
converged
 
INFO  [05:17:46.076] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:17:46.131] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:17:46.138] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:17:57.284] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:18:08.703] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:18:19.936] [mlr3]  Finished benchmark 
INFO  [05:18:20.000] [bbotk] Result of batch 24: 
INFO  [05:18:20.002] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:18:20.002] [bbotk]                   5               847       0.132212        0.452 -0.8957092 
INFO  [05:18:20.002] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:18:20.002] [bbotk]          <NA>   0.9780396 2848030e-f99a-466b-8101-8ef2ff8b0653 
DEBUG [05:18:20.640] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.161088e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004145988 0.4161088 
  - best initial criterion value(s) :  102.7473 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -102.75  |proj g|=       2.4117
At iterate     1  f =      -106.65  |proj g|=        3.6446
At iterate     2  f =      -111.89  |proj g|=         3.147
At iterate     3  f =      -112.92  |proj g|=        2.9976
At iterate     4  f =      -115.64  |proj g|=        2.6178
At iterate     5  f =      -119.28  |proj g|=        1.8468
At iterate     6  f =      -119.45  |proj g|=       0.70182
At iterate     7  f =       -119.5  |proj g|=      0.030616
At iterate     8  f =       -119.5  |proj g|=       0.23607
At iterate     9  f =       -119.5  |proj g|=     0.0059221
At iterate    10  f =       -119.5  |proj g|=     0.0059221

iterations 10
function evaluations 19
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00592206
final function value -119.498

F = -119.498
final  value -119.497552 
converged
 
INFO  [05:18:20.644] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:18:20.698] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:18:20.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:18:55.092] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:19:29.807] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:20:04.616] [mlr3]  Finished benchmark 
INFO  [05:20:04.680] [bbotk] Result of batch 25: 
INFO  [05:20:04.682] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:20:04.682] [bbotk]                   7              2862     0.04476059        0.457 -0.9015752 
INFO  [05:20:04.682] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:20:04.682] [bbotk]          <NA>   0.9770064 547974a2-47d4-4a2a-83cb-8c0599c84a2c 
DEBUG [05:20:05.344] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.116806e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004070603 0.4116806 
  - best initial criterion value(s) :  110.3696 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -110.37  |proj g|=        1.207
At iterate     1  f =      -115.76  |proj g|=        3.3189
At iterate     2  f =      -117.87  |proj g|=        3.8573
At iterate     3  f =      -118.85  |proj g|=        3.6851
At iterate     4  f =      -120.39  |proj g|=        3.3463
At iterate     5  f =      -123.71  |proj g|=        2.6398
At iterate     6  f =      -126.29  |proj g|=         1.963
At iterate     7  f =       -126.3  |proj g|=        1.9723
At iterate     8  f =      -126.32  |proj g|=         1.924
At iterate     9  f =      -127.32  |proj g|=        1.8753
At iterate    10  f =      -133.21  |proj g|=        1.7469
At iterate    11  f =      -133.44  |proj g|=       0.14208
At iterate    12  f =      -133.44  |proj g|=     0.0038079
At iterate    13  f =      -133.44  |proj g|=     0.0038082
At iterate    14  f =      -133.44  |proj g|=     0.0038082

iterations 14
function evaluations 22
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00380821
final function value -133.441

F = -133.441
final  value -133.441112 
converged
 
INFO  [05:20:05.348] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:20:05.402] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:20:05.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:20:06.155] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:20:06.909] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:20:07.798] [mlr3]  Finished benchmark 
INFO  [05:20:07.861] [bbotk] Result of batch 26: 
INFO  [05:20:07.863] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:20:07.863] [bbotk]                   9              3444      0.0587733        0.472 -0.8972336 
INFO  [05:20:07.863] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:20:07.863] [bbotk]          <NA>         0.5 46050f78-403d-478a-b112-7a8760675143 
DEBUG [05:20:08.520] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.259114e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004247936 0.4259113 
  - best initial criterion value(s) :  81.49216 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -81.492  |proj g|=        5.218
At iterate     1  f =        -89.6  |proj g|=        2.3303
At iterate     2  f =      -95.958  |proj g|=        4.5268
At iterate     3  f =      -97.463  |proj g|=        4.3585
At iterate     4  f =      -107.15  |proj g|=        3.4667
At iterate     5  f =      -126.63  |proj g|=        1.5918
At iterate     6  f =      -126.73  |proj g|=         2.366
At iterate     7  f =      -126.74  |proj g|=         2.257
At iterate     8  f =      -126.74  |proj g|=        2.1451
At iterate     9  f =      -126.75  |proj g|=          1.95
At iterate    10  f =      -126.78  |proj g|=        1.5058
At iterate    11  f =      -126.82  |proj g|=       0.82457
At iterate    12  f =      -126.87  |proj g|=       0.41948
At iterate    13  f =      -126.91  |proj g|=        0.4191
At iterate    14  f =      -126.91  |proj g|=      0.016317
At iterate    15  f =      -126.91  |proj g|=       0.41909
At iterate    16  f =      -126.91  |proj g|=       0.05222
At iterate    17  f =      -126.91  |proj g|=     0.0063246

iterations 17
function evaluations 26
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00632463
final function value -126.91

F = -126.91
final  value -126.909954 
converged
 
INFO  [05:20:08.524] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:20:08.580] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:20:08.594] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:20:09.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:20:10.072] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:20:10.825] [mlr3]  Finished benchmark 
INFO  [05:20:10.888] [bbotk] Result of batch 27: 
INFO  [05:20:10.890] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:20:10.890] [bbotk]                  10              1651      0.1833138        0.468 -0.9005323 
INFO  [05:20:10.890] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:20:10.890] [bbotk]          <NA>         0.5 bbf4d814-ba20-4b1c-a14b-1918988f36c0 
DEBUG [05:20:11.548] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.386676e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004339671 0.4386676 
  - best initial criterion value(s) :  99.95586 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -99.956  |proj g|=       6.6577
At iterate     1  f =       -103.4  |proj g|=        1.2938
At iterate     2  f =      -112.64  |proj g|=        4.0574
At iterate     3  f =      -117.21  |proj g|=        5.2491
At iterate     4  f =      -119.78  |proj g|=        4.9954
At iterate     5  f =      -125.41  |proj g|=         4.476
At iterate     6  f =      -128.19  |proj g|=        4.0232
At iterate     7  f =      -144.41  |proj g|=       0.43234
At iterate     8  f =      -144.41  |proj g|=       0.17851
At iterate     9  f =      -144.41  |proj g|=     0.0078472
At iterate    10  f =      -144.41  |proj g|=      0.031822
At iterate    11  f =      -144.41  |proj g|=     0.0035755

iterations 11
function evaluations 23
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00357549
final function value -144.414

F = -144.414
final  value -144.414481 
converged
 
INFO  [05:20:11.552] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:20:11.643] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:20:11.653] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:20:52.512] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:21:32.297] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:22:11.817] [mlr3]  Finished benchmark 
INFO  [05:22:11.882] [bbotk] Result of batch 28: 
INFO  [05:22:11.884] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:22:11.884] [bbotk]                   6              3298      0.4850244        0.472 -0.8949507 
INFO  [05:22:11.884] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:22:11.884] [bbotk]          <NA>   0.9761221 01b139c4-1e39-49d3-89e0-af992581c6d3 
DEBUG [05:22:12.640] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.346168e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004309997 0.4346168 
  - best initial criterion value(s) :  112.1832 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -112.18  |proj g|=      0.75488
At iterate     1  f =      -117.74  |proj g|=        3.6188
At iterate     2  f =      -119.53  |proj g|=        3.6443
At iterate     3  f =      -119.98  |proj g|=        3.5668
At iterate     4  f =      -121.08  |proj g|=        3.1786
At iterate     5  f =      -123.52  |proj g|=        2.6349
At iterate     6  f =      -124.46  |proj g|=         1.094
At iterate     7  f =      -125.02  |proj g|=        1.9447
At iterate     8  f =      -125.12  |proj g|=        2.2676
At iterate     9  f =      -125.38  |proj g|=        2.1395
At iterate    10  f =      -125.95  |proj g|=        1.9082
At iterate    11  f =      -126.97  |proj g|=       0.47831
At iterate    12  f =      -130.73  |proj g|=        4.0919
At iterate    13  f =      -131.78  |proj g|=       0.58164
At iterate    14  f =      -133.92  |proj g|=       0.42809
At iterate    15  f =      -133.92  |proj g|=       0.42807
At iterate    16  f =      -133.92  |proj g|=       0.42805
At iterate    17  f =      -133.92  |proj g|=     0.0068634
At iterate    18  f =      -133.92  |proj g|=     0.0066697
At iterate    19  f =      -133.92  |proj g|=       0.02237

iterations 19
function evaluations 24
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0223699
final function value -133.922

F = -133.922
final  value -133.921635 
converged
 
INFO  [05:22:12.644] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:22:12.697] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:22:12.704] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:22:13.476] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:22:14.232] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:22:14.982] [mlr3]  Finished benchmark 
INFO  [05:22:15.045] [bbotk] Result of batch 29: 
INFO  [05:22:15.047] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:22:15.047] [bbotk]                  10              2626      0.3749207        0.555 -0.8999252 
INFO  [05:22:15.047] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:22:15.047] [bbotk]          <NA>         0.5 57182600-82bf-428b-b830-73b24bed9f88 
DEBUG [05:22:15.712] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.46279e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004415644 0.446279 
  - best initial criterion value(s) :  123.5372 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -123.54  |proj g|=       3.7319
At iterate     1  f =      -137.99  |proj g|=        1.8715
At iterate     2  f =         -145  |proj g|=         1.887
At iterate     3  f =      -147.82  |proj g|=        1.9962
At iterate     4  f =      -149.77  |proj g|=        2.3616
At iterate     5  f =      -150.43  |proj g|=        7.3983
At iterate     6  f =      -150.68  |proj g|=        4.7306
At iterate     7  f =      -150.74  |proj g|=        4.4746
At iterate     8  f =      -150.89  |proj g|=        3.8537
At iterate     9  f =      -151.15  |proj g|=        3.1432
At iterate    10  f =      -152.19  |proj g|=       0.98366
At iterate    11  f =      -154.11  |proj g|=       0.58499
At iterate    12  f =      -156.63  |proj g|=        0.4412
At iterate    13  f =      -156.87  |proj g|=       0.79393
At iterate    14  f =      -156.91  |proj g|=        1.2195
At iterate    15  f =      -156.92  |proj g|=        1.3296
At iterate    16  f =      -156.92  |proj g|=        1.3695
At iterate    17  f =      -156.92  |proj g|=        1.3856
At iterate    18  f =      -156.92  |proj g|=        1.3925
At iterate    19  f =      -156.93  |proj g|=         1.339
At iterate    20  f =      -156.94  |proj g|=        1.1269
At iterate    21  f =      -156.96  |proj g|=       0.65182
At iterate    22  f =      -156.97  |proj g|=       0.33973
At iterate    23  f =      -156.98  |proj g|=     0.0029952
At iterate    24  f =      -156.98  |proj g|=     0.0029952

iterations 24
function evaluations 33
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00299516
final function value -156.978

F = -156.978
final  value -156.978176 
converged
 
INFO  [05:22:15.716] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:22:15.771] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:22:15.778] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:22:53.009] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:23:29.527] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:24:06.763] [mlr3]  Finished benchmark 
INFO  [05:24:06.836] [bbotk] Result of batch 30: 
INFO  [05:24:06.838] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:24:06.838] [bbotk]                   6              3056      0.3892774        0.468 -0.8908677 
INFO  [05:24:06.838] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:24:06.838] [bbotk]          <NA>   0.9764735 f6e43106-55a6-4f0c-9a01-d90c86a8144b 
DEBUG [05:24:07.503] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.424507e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004373923 0.4424507 
  - best initial criterion value(s) :  126.3819 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -126.38  |proj g|=       1.1393
At iterate     1  f =      -132.35  |proj g|=        3.2675
At iterate     2  f =      -135.03  |proj g|=        4.3386
At iterate     3  f =      -136.26  |proj g|=        4.1742
At iterate     4  f =      -138.67  |proj g|=        3.4999
At iterate     5  f =      -148.59  |proj g|=         2.148
At iterate     6  f =      -150.34  |proj g|=        1.1546
At iterate     7  f =      -152.91  |proj g|=        1.6742
At iterate     8  f =      -155.21  |proj g|=       0.45873
At iterate     9  f =      -155.56  |proj g|=       0.23819
At iterate    10  f =       -155.6  |proj g|=     0.0041218
At iterate    11  f =      -155.61  |proj g|=       0.43638
At iterate    12  f =      -155.61  |proj g|=     0.0041271
At iterate    13  f =      -155.61  |proj g|=     0.0041272
At iterate    14  f =      -155.61  |proj g|=     0.0041272

iterations 14
function evaluations 19
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00412718
final function value -155.61

F = -155.61
final  value -155.610331 
converged
 
INFO  [05:24:07.507] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:24:07.559] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:24:07.566] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:24:52.227] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:24:53.085] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:25:38.023] [mlr3]  Finished benchmark 
INFO  [05:25:38.088] [bbotk] Result of batch 31: 
INFO  [05:25:38.090] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:25:38.090] [bbotk]                   8              3740      0.0373602        0.476 -0.8925033 
INFO  [05:25:38.090] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:25:38.090] [bbotk]          <NA>   0.8160958 37b61f07-f073-456a-b4d1-42839a6fbecd 
DEBUG [05:25:38.760] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.341066e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004284089 0.4341066 
  - best initial criterion value(s) :  118.2674 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -118.27  |proj g|=       4.9822
At iterate     1  f =      -126.44  |proj g|=        4.0134
At iterate     2  f =      -145.77  |proj g|=        2.1759
At iterate     3  f =      -145.98  |proj g|=        2.1287
At iterate     4  f =      -147.65  |proj g|=       0.42832
At iterate     5  f =      -149.05  |proj g|=         1.326
At iterate     6  f =      -149.81  |proj g|=        1.4692
At iterate     7  f =      -149.87  |proj g|=       0.20066
At iterate     8  f =      -149.87  |proj g|=     0.0062357
At iterate     9  f =      -149.87  |proj g|=     0.0062359
At iterate    10  f =      -149.87  |proj g|=     0.0062359

iterations 10
function evaluations 17
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00623588
final function value -149.874

F = -149.874
final  value -149.874417 
converged
 
INFO  [05:25:38.764] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:25:38.819] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:25:38.826] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:26:20.582] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:27:02.562] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:27:44.540] [mlr3]  Finished benchmark 
INFO  [05:27:44.604] [bbotk] Result of batch 32: 
INFO  [05:27:44.606] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [05:27:44.606] [bbotk]                   6              3494      0.1166059         0.48 -0.895002 
INFO  [05:27:44.606] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:27:44.606] [bbotk]          <NA>   0.9772513 84ba3b6d-0210-4633-a01a-2ec865557c5f 
DEBUG [05:27:45.288] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.305265e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004259719 0.4305265 
  - best initial criterion value(s) :  135.9039 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -135.9  |proj g|=       5.5658
At iterate     1  f =      -141.49  |proj g|=        3.4264
At iterate     2  f =      -143.52  |proj g|=        5.1739
At iterate     3  f =      -145.69  |proj g|=        4.9458
ys=-2.740e-02  -gs= 2.163e+00, BFGS update SKIPPED
At iterate     4  f =      -147.06  |proj g|=        4.7751
At iterate     5  f =      -169.83  |proj g|=        1.9017
At iterate     6  f =      -169.92  |proj g|=       0.79995
At iterate     7  f =      -170.19  |proj g|=        1.1223
At iterate     8  f =      -170.28  |proj g|=       0.42485
At iterate     9  f =      -170.28  |proj g|=       0.05077
At iterate    10  f =      -170.28  |proj g|=      0.003755
At iterate    11  f =      -170.28  |proj g|=       0.14525
At iterate    12  f =      -170.28  |proj g|=     0.0037551

iterations 12
function evaluations 19
segments explored during Cauchy searches 15
BFGS updates skipped 1
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00375511
final function value -170.282

F = -170.282
final  value -170.282162 
converged
 
INFO  [05:27:45.292] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:27:45.347] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:27:45.353] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:27:46.115] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:27:46.866] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:27:47.597] [mlr3]  Finished benchmark 
INFO  [05:27:47.697] [bbotk] Result of batch 33: 
INFO  [05:27:47.699] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:27:47.699] [bbotk]                  10              1298      0.2266342        0.489 -0.8903955 
INFO  [05:27:47.699] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:27:47.699] [bbotk]          <NA>         0.5 6d28bcd9-b92d-4ee7-9661-7ed803db3462 
DEBUG [05:27:48.449] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.413863e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004359223 0.4413863 
  - best initial criterion value(s) :  136.6164 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -136.62  |proj g|=       5.2331
At iterate     1  f =      -142.37  |proj g|=        3.0076
At iterate     2  f =      -167.71  |proj g|=        2.1128
At iterate     3  f =      -169.42  |proj g|=        0.4359
At iterate     4  f =      -169.45  |proj g|=       0.52737
At iterate     5  f =      -169.47  |proj g|=        1.2529
At iterate     6  f =      -171.11  |proj g|=        1.2788
At iterate     7  f =      -171.16  |proj g|=       0.43558
At iterate     8  f =      -171.16  |proj g|=       0.43557
At iterate     9  f =      -171.16  |proj g|=      0.015842
At iterate    10  f =      -171.16  |proj g|=     0.0045414

iterations 10
function evaluations 21
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00454137
final function value -171.157

F = -171.157
final  value -171.156936 
converged
 
INFO  [05:27:48.453] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:27:48.506] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:27:48.513] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:28:46.320] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:29:43.762] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:30:41.417] [mlr3]  Finished benchmark 
INFO  [05:30:41.483] [bbotk] Result of batch 34: 
INFO  [05:30:41.485] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:30:41.485] [bbotk]                   4              4836      0.1885178        0.559 -0.8888711 
INFO  [05:30:41.485] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:30:41.485] [bbotk]          <NA>   0.9782925 21d85bf3-272d-4a4a-b6ca-b9ef1d979eba 
DEBUG [05:30:42.190] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.380278e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004313367 0.4380278 
  - best initial criterion value(s) :  140.0577 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -140.06  |proj g|=        9.198
At iterate     1  f =      -153.21  |proj g|=        4.9901
At iterate     2  f =      -155.42  |proj g|=        4.7657
At iterate     3  f =      -159.19  |proj g|=        4.2818
At iterate     4  f =      -165.55  |proj g|=        3.5154
At iterate     5  f =       -178.2  |proj g|=        1.7714
At iterate     6  f =       -178.3  |proj g|=        5.1004
At iterate     7  f =      -179.21  |proj g|=       0.43463
At iterate     8  f =      -179.62  |proj g|=       0.53505
At iterate     9  f =      -179.64  |proj g|=       0.43243
At iterate    10  f =      -180.23  |proj g|=       0.41373
At iterate    11  f =      -180.24  |proj g|=     0.0042346
At iterate    12  f =      -180.24  |proj g|=     0.0036933
At iterate    13  f =      -180.24  |proj g|=     0.0036933

iterations 13
function evaluations 19
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00369332
final function value -180.235

F = -180.235
final  value -180.235263 
converged
 
INFO  [05:30:42.194] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:30:42.256] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:30:42.262] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:31:00.481] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:31:18.579] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:31:36.178] [mlr3]  Finished benchmark 
INFO  [05:31:36.244] [bbotk] Result of batch 35: 
INFO  [05:31:36.246] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:31:36.246] [bbotk]                   7              1433      0.2127831        0.513 -0.8880186 
INFO  [05:31:36.246] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:31:36.246] [bbotk]          <NA>   0.9768156 71afa108-a467-44e3-9aba-1eedc546b271 
DEBUG [05:31:37.161] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.345539e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004294088 0.4345539 
  - best initial criterion value(s) :  153.681 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -153.68  |proj g|=       3.9879
At iterate     1  f =       -166.2  |proj g|=         4.887
At iterate     2  f =      -172.84  |proj g|=       0.70092
At iterate     3  f =      -173.62  |proj g|=       0.62273
At iterate     4  f =      -173.94  |proj g|=        1.2989
At iterate     5  f =      -173.95  |proj g|=        1.2621
At iterate     6  f =      -173.96  |proj g|=         1.447
At iterate     7  f =      -174.02  |proj g|=        1.9348
At iterate     8  f =      -174.44  |proj g|=        4.0633
At iterate     9  f =      -175.14  |proj g|=        5.7434
At iterate    10  f =      -175.52  |proj g|=        4.2415
At iterate    11  f =      -175.76  |proj g|=        1.7762
At iterate    12  f =      -175.98  |proj g|=       0.42887
At iterate    13  f =      -175.98  |proj g|=       0.42883
At iterate    14  f =      -175.98  |proj g|=       0.35186
At iterate    15  f =      -175.98  |proj g|=     0.0064286

iterations 15
function evaluations 22
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00642858
final function value -175.979

F = -175.979
final  value -175.979355 
converged
 
INFO  [05:31:37.165] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:31:37.230] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:31:37.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:32:13.445] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:32:50.498] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:33:26.641] [mlr3]  Finished benchmark 
INFO  [05:33:26.704] [bbotk] Result of batch 36: 
INFO  [05:33:26.705] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:33:26.705] [bbotk]                   3              3024      0.2270412        0.696 -0.8892908 
INFO  [05:33:26.705] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:33:26.705] [bbotk]          <NA>   0.9773017 3dc66b6b-2ff7-4bda-8d73-b314ce85fad9 
DEBUG [05:33:27.374] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.310849e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004249339 0.4310849 
  - best initial criterion value(s) :  145.4243 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -145.42  |proj g|=       11.306
At iterate     1  f =       -157.7  |proj g|=        4.8762
At iterate     2  f =      -173.68  |proj g|=       0.80222
At iterate     3  f =      -180.36  |proj g|=        2.0736
At iterate     4  f =      -180.89  |proj g|=         1.818
At iterate     5  f =         -181  |proj g|=       0.82718
At iterate     6  f =      -181.05  |proj g|=       0.57813
At iterate     7  f =       -181.3  |proj g|=       0.42572
At iterate     8  f =      -181.79  |proj g|=       0.76278
At iterate     9  f =      -183.66  |proj g|=         2.875
At iterate    10  f =      -187.23  |proj g|=        5.6709
At iterate    11  f =       -189.5  |proj g|=        5.3503
At iterate    12  f =      -190.06  |proj g|=          3.19
At iterate    13  f =      -190.31  |proj g|=       0.42568
At iterate    14  f =      -190.32  |proj g|=       0.42561
At iterate    15  f =      -190.32  |proj g|=       0.42559
At iterate    16  f =      -190.32  |proj g|=       0.31784
At iterate    17  f =      -190.32  |proj g|=     0.0037242

iterations 17
function evaluations 24
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00372422
final function value -190.318

F = -190.318
final  value -190.318427 
converged
 
INFO  [05:33:27.378] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:33:27.430] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:33:27.437] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:33:56.021] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:34:24.635] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:34:53.064] [mlr3]  Finished benchmark 
INFO  [05:34:53.129] [bbotk] Result of batch 37: 
INFO  [05:34:53.130] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:34:53.130] [bbotk]                   3              2353     0.03618143        0.465 -0.8871971 
INFO  [05:34:53.130] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:34:53.130] [bbotk]          <NA>   0.9744038 df398ebe-f1ed-4c93-b3c6-ce341e3dc3ef 
DEBUG [05:34:53.790] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.274568e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004211634 0.4274568 
  - best initial criterion value(s) :  157.073 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -157.07  |proj g|=       9.7007
At iterate     1  f =      -169.22  |proj g|=       0.73248
At iterate     2  f =      -180.01  |proj g|=        3.2664
At iterate     3  f =      -182.58  |proj g|=        2.9835
At iterate     4  f =      -189.83  |proj g|=        1.0773
At iterate     5  f =       -190.8  |proj g|=        1.1563
At iterate     6  f =      -190.91  |proj g|=       0.42204
At iterate     7  f =      -190.94  |proj g|=       0.34643
At iterate     8  f =      -191.07  |proj g|=       0.62462
At iterate     9  f =      -191.08  |proj g|=       0.42207
At iterate    10  f =      -191.09  |proj g|=         0.422
At iterate    11  f =      -191.09  |proj g|=     0.0059862
At iterate    12  f =      -191.09  |proj g|=     0.0041986
At iterate    13  f =      -191.09  |proj g|=     0.0041987

iterations 13
function evaluations 22
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00419865
final function value -191.09

F = -191.09
final  value -191.090340 
converged
 
INFO  [05:34:53.794] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:34:53.848] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:34:53.855] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:34:54.635] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:34:55.445] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:34:56.207] [mlr3]  Finished benchmark 
INFO  [05:34:56.272] [bbotk] Result of batch 38: 
INFO  [05:34:56.273] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:34:56.273] [bbotk]                  10              3620      0.1568412        0.466 -0.8880129 
INFO  [05:34:56.273] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:34:56.273] [bbotk]          <NA>         0.5 188098d7-7d81-4a18-9817-acbee4baa101 
DEBUG [05:34:56.946] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.380036e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004307914 0.4380036 
  - best initial criterion value(s) :  153.5537 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -153.55  |proj g|=       11.906
At iterate     1  f =      -168.91  |proj g|=        2.1205
At iterate     2  f =      -176.43  |proj g|=        2.8314
At iterate     3  f =      -179.37  |proj g|=        2.7166
At iterate     4  f =      -180.82  |proj g|=        2.5375
At iterate     5  f =      -183.49  |proj g|=         1.884
At iterate     6  f =      -184.18  |proj g|=        6.5339
At iterate     7  f =      -185.24  |proj g|=       0.88924
At iterate     8  f =      -185.48  |proj g|=       0.43253
At iterate     9  f =      -185.49  |proj g|=       0.44571
At iterate    10  f =      -185.56  |proj g|=        1.1684
At iterate    11  f =      -185.81  |proj g|=        2.3819
At iterate    12  f =      -186.87  |proj g|=        5.2901
At iterate    13  f =      -188.18  |proj g|=        6.6767
At iterate    14  f =      -188.79  |proj g|=         4.619
At iterate    15  f =      -189.16  |proj g|=        2.2582
At iterate    16  f =      -189.34  |proj g|=       0.43485
At iterate    17  f =      -189.35  |proj g|=       0.43257
At iterate    18  f =      -189.35  |proj g|=     0.0054291
At iterate    19  f =      -189.35  |proj g|=      0.038924
At iterate    20  f =      -189.35  |proj g|=     0.0054292

iterations 20
function evaluations 28
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00542916
final function value -189.349

F = -189.349
final  value -189.348848 
converged
 
INFO  [05:34:56.950] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:34:57.005] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:34:57.012] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:35:38.710] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:36:20.256] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:37:02.074] [mlr3]  Finished benchmark 
INFO  [05:37:02.139] [bbotk] Result of batch 39: 
INFO  [05:37:02.141] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:37:02.141] [bbotk]                   6              3487      0.4948455        0.463 -0.8885209 
INFO  [05:37:02.141] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:37:02.141] [bbotk]          <NA>    0.975996 16a548a0-609f-446b-bd0b-5c964152bdca 
DEBUG [05:37:02.824] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.346017e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004280535 0.4346017 
  - best initial criterion value(s) :  166.8201 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -166.82  |proj g|=       1.9766
At iterate     1  f =      -199.69  |proj g|=        2.3434
At iterate     2  f =      -199.87  |proj g|=        2.3308
At iterate     3  f =      -201.84  |proj g|=        2.1573
At iterate     4  f =      -202.26  |proj g|=        2.0678
At iterate     5  f =      -202.84  |proj g|=        1.9233
At iterate     6  f =      -203.13  |proj g|=        0.6761
At iterate     7  f =      -203.16  |proj g|=      0.081917
At iterate     8  f =      -203.17  |proj g|=       0.42935
At iterate     9  f =      -203.17  |proj g|=     0.0077673
At iterate    10  f =      -203.17  |proj g|=     0.0042282
At iterate    11  f =      -203.17  |proj g|=      0.031215

iterations 11
function evaluations 21
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0312151
final function value -203.167

F = -203.167
final  value -203.167383 
converged
 
INFO  [05:37:02.828] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:37:02.882] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:37:02.889] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:37:32.994] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:38:03.514] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:38:33.363] [mlr3]  Finished benchmark 
INFO  [05:38:33.428] [bbotk] Result of batch 40: 
INFO  [05:38:33.430] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:38:33.430] [bbotk]                   4              2483     0.07144768        0.484 -0.8869219 
INFO  [05:38:33.430] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:38:33.430] [bbotk]          <NA>   0.9776623 72e0be0f-ec25-4e81-93f4-e25ae49adbab 
DEBUG [05:38:34.194] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.312717e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004235629 0.4312717 
  - best initial criterion value(s) :  174.6432 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -174.64  |proj g|=       2.4608
At iterate     1  f =      -180.23  |proj g|=        4.5856
At iterate     2  f =      -186.16  |proj g|=        4.1535
At iterate     3  f =       -187.9  |proj g|=        3.9415
At iterate     4  f =       -191.5  |proj g|=        3.4803
At iterate     5  f =      -199.92  |proj g|=         2.242
At iterate     6  f =      -205.24  |proj g|=        1.8008
At iterate     7  f =      -205.54  |proj g|=        1.8122
At iterate     8  f =      -205.59  |proj g|=       0.47512
At iterate     9  f =      -205.62  |proj g|=       0.42604
At iterate    10  f =      -205.78  |proj g|=      0.035735
At iterate    11  f =         -206  |proj g|=        0.3629
At iterate    12  f =      -206.57  |proj g|=       0.77355
At iterate    13  f =      -206.81  |proj g|=        0.7032
At iterate    14  f =      -207.26  |proj g|=       0.30081
At iterate    15  f =      -207.26  |proj g|=       0.42614
At iterate    16  f =      -207.26  |proj g|=       0.21592
At iterate    17  f =      -207.26  |proj g|=       0.18647
At iterate    18  f =      -207.26  |proj g|=       0.42611
At iterate    19  f =      -207.26  |proj g|=       0.42609
At iterate    20  f =      -207.26  |proj g|=     0.0063227
At iterate    21  f =      -207.26  |proj g|=      0.004638

iterations 21
function evaluations 32
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00463803
final function value -207.265

F = -207.265
final  value -207.264740 
converged
 
INFO  [05:38:34.198] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:38:34.252] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:38:34.258] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:38:35.022] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:38:35.820] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:38:36.545] [mlr3]  Finished benchmark 
INFO  [05:38:36.611] [bbotk] Result of batch 41: 
INFO  [05:38:36.613] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:38:36.613] [bbotk]                  10              2923      0.3465527        0.534 -0.8866364 
INFO  [05:38:36.613] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:38:36.613] [bbotk]          <NA>         0.5 df4a8e0d-a619-4ffc-b1ff-bf0608ffb654 
DEBUG [05:38:37.336] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.41218e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004337463 0.4412179 
  - best initial criterion value(s) :  172.8613 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -172.86  |proj g|=       4.2226
At iterate     1  f =      -182.84  |proj g|=        4.4813
At iterate     2  f =      -185.92  |proj g|=        4.0979
At iterate     3  f =      -187.55  |proj g|=        3.8042
At iterate     4  f =      -189.56  |proj g|=        3.4018
At iterate     5  f =      -192.65  |proj g|=        2.9338
At iterate     6  f =      -196.92  |proj g|=         2.087
At iterate     7  f =      -196.95  |proj g|=         2.031
At iterate     8  f =      -196.99  |proj g|=        1.9948
At iterate     9  f =      -197.07  |proj g|=        1.9709
At iterate    10  f =      -197.65  |proj g|=        1.0871
At iterate    11  f =      -198.75  |proj g|=        1.7396
At iterate    12  f =      -201.54  |proj g|=        5.6168
At iterate    13  f =       -206.7  |proj g|=        9.1162
At iterate    14  f =      -212.57  |proj g|=        12.925
At iterate    15  f =      -215.53  |proj g|=        8.4937
At iterate    16  f =      -216.95  |proj g|=        1.5802
At iterate    17  f =       -217.2  |proj g|=       0.72946
At iterate    18  f =      -217.22  |proj g|=       0.43623
At iterate    19  f =      -217.22  |proj g|=      0.016603
At iterate    20  f =      -217.22  |proj g|=       0.43618
At iterate    21  f =      -217.22  |proj g|=     0.0040001
At iterate    22  f =      -217.22  |proj g|=     0.0040001

iterations 22
function evaluations 30
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00400015
final function value -217.225

F = -217.225
final  value -217.224839 
converged
 
INFO  [05:38:37.340] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:38:37.393] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:38:37.399] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:39:03.732] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:39:30.255] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:39:57.041] [mlr3]  Finished benchmark 
INFO  [05:39:57.116] [bbotk] Result of batch 42: 
INFO  [05:39:57.118] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:39:57.118] [bbotk]                   3              2177      0.2216622        0.501 -0.8853958 
INFO  [05:39:57.118] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:39:57.118] [bbotk]          <NA>    0.977272 71269b48-c13b-4682-b652-c3578e2c45c7 
DEBUG [05:39:57.827] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.379997e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004312378 0.4379997 
  - best initial criterion value(s) :  159.0627 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -159.06  |proj g|=       11.917
At iterate     1  f =      -184.92  |proj g|=        4.5967
At iterate     2  f =      -188.44  |proj g|=        4.2282
At iterate     3  f =      -192.79  |proj g|=        3.7165
At iterate     4  f =      -198.33  |proj g|=        3.1695
At iterate     5  f =      -206.68  |proj g|=        2.3128
At iterate     6  f =      -207.68  |proj g|=        2.1571
At iterate     7  f =      -208.78  |proj g|=         1.849
At iterate     8  f =      -209.13  |proj g|=       0.17892
At iterate     9  f =      -209.32  |proj g|=         1.146
At iterate    10  f =      -210.13  |proj g|=        3.5921
At iterate    11  f =      -212.91  |proj g|=        8.2725
At iterate    12  f =      -216.11  |proj g|=        7.2641
At iterate    13  f =      -217.38  |proj g|=        1.0643
At iterate    14  f =      -217.42  |proj g|=       0.51781
At iterate    15  f =      -217.43  |proj g|=         0.433
At iterate    16  f =      -217.43  |proj g|=     0.0049858
At iterate    17  f =      -217.43  |proj g|=     0.0049858

iterations 17
function evaluations 25
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0049858
final function value -217.431

F = -217.431
final  value -217.431329 
converged
 
INFO  [05:39:57.831] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:39:57.893] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:39:57.901] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:40:43.490] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:41:28.229] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:42:13.383] [mlr3]  Finished benchmark 
INFO  [05:42:13.448] [bbotk] Result of batch 43: 
INFO  [05:42:13.449] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:42:13.449] [bbotk]                   4              3779      0.1339023         0.49 -0.8856947 
INFO  [05:42:13.449] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:42:13.449] [bbotk]          <NA>   0.9780683 8f21955e-46fa-4ed0-8e4e-f0509d511308 
DEBUG [05:42:14.209] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.348076e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004258377 0.4348076 
  - best initial criterion value(s) :  151.0403 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -151.04  |proj g|=        3.493
At iterate     1  f =      -164.54  |proj g|=        3.6019
At iterate     2  f =      -164.89  |proj g|=        3.5246
At iterate     3  f =      -165.21  |proj g|=        3.1439
At iterate     4  f =      -165.53  |proj g|=        3.0773
At iterate     5  f =      -165.59  |proj g|=        2.9587
At iterate     6  f =      -171.24  |proj g|=        2.6344
At iterate     7  f =       -186.4  |proj g|=        1.9036
At iterate     8  f =      -192.88  |proj g|=        1.7157
At iterate     9  f =      -194.46  |proj g|=        1.3033
At iterate    10  f =      -195.26  |proj g|=       0.60771
At iterate    11  f =      -195.51  |proj g|=       0.02817
At iterate    12  f =      -195.51  |proj g|=       0.42942
At iterate    13  f =      -195.51  |proj g|=        0.4294
At iterate    14  f =      -195.51  |proj g|=        0.4294
At iterate    15  f =      -195.51  |proj g|=      0.010914
At iterate    16  f =      -195.51  |proj g|=      0.010914

iterations 16
function evaluations 22
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0109139
final function value -195.511

F = -195.511
final  value -195.511012 
converged
 
INFO  [05:42:14.213] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:42:14.268] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:42:14.275] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:42:32.160] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:42:50.121] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:43:08.586] [mlr3]  Finished benchmark 
INFO  [05:43:08.650] [bbotk] Result of batch 44: 
INFO  [05:43:08.652] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:43:08.652] [bbotk]                   3              1450      0.1804564        0.532 -0.8901821 
INFO  [05:43:08.652] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:43:08.652] [bbotk]          <NA>   0.9767543 fad70600-b47e-423a-86f6-146f78223f05 
DEBUG [05:43:09.354] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.315491e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004243311 0.4315491 
  - best initial criterion value(s) :  163.0687 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -163.07  |proj g|=       4.7477
At iterate     1  f =      -180.04  |proj g|=        4.4969
At iterate     2  f =      -181.39  |proj g|=        4.2956
At iterate     3  f =      -182.49  |proj g|=        3.9531
At iterate     4  f =      -183.83  |proj g|=        3.5038
At iterate     5  f =      -186.07  |proj g|=        2.7678
At iterate     6  f =      -197.75  |proj g|=        2.0242
At iterate     7  f =      -205.91  |proj g|=        12.975
At iterate     8  f =      -217.07  |proj g|=        4.8402
At iterate     9  f =       -220.7  |proj g|=        1.8451
At iterate    10  f =      -222.47  |proj g|=       0.42023
At iterate    11  f =       -223.1  |proj g|=        1.2479
At iterate    12  f =      -223.19  |proj g|=       0.77792
At iterate    13  f =      -223.27  |proj g|=       0.17273
At iterate    14  f =      -223.27  |proj g|=      0.092372
At iterate    15  f =      -223.27  |proj g|=       0.42662
At iterate    16  f =      -223.27  |proj g|=       0.42662
At iterate    17  f =      -223.27  |proj g|=     0.0058949

iterations 17
function evaluations 26
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00589494
final function value -223.275

F = -223.275
final  value -223.274804 
converged
 
INFO  [05:43:09.358] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:43:09.412] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:43:09.419] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:43:10.162] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:43:10.904] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:43:11.646] [mlr3]  Finished benchmark 
INFO  [05:43:11.711] [bbotk] Result of batch 45: 
INFO  [05:43:11.713] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [05:43:11.713] [bbotk]                  10              3317     0.04723665         0.49 -0.886033 
INFO  [05:43:11.713] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:43:11.713] [bbotk]          <NA>         0.5 38779415-9325-4e62-9902-87ce3d77912f 
DEBUG [05:43:12.420] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.410865e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004329386 0.4410865 
  - best initial criterion value(s) :  164.0194 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -164.02  |proj g|=       10.185
At iterate     1  f =       -180.9  |proj g|=        4.6466
At iterate     2  f =      -186.96  |proj g|=        3.3609
At iterate     3  f =      -192.01  |proj g|=        3.0504
At iterate     4  f =      -192.54  |proj g|=          2.97
At iterate     5  f =      -193.96  |proj g|=        2.3048
At iterate     6  f =       -194.4  |proj g|=        2.0579
At iterate     7  f =      -194.97  |proj g|=        2.2589
At iterate     8  f =      -195.13  |proj g|=         2.181
At iterate     9  f =      -195.41  |proj g|=        2.0811
At iterate    10  f =      -208.97  |proj g|=        1.9032
At iterate    11  f =      -235.49  |proj g|=       0.16682
At iterate    12  f =      -236.63  |proj g|=        1.3752
At iterate    13  f =      -236.95  |proj g|=       0.43676
At iterate    14  f =      -237.06  |proj g|=      0.070304
At iterate    15  f =      -237.08  |proj g|=        0.0329
At iterate    16  f =      -237.08  |proj g|=       0.43633
At iterate    17  f =      -237.08  |proj g|=      0.004831
At iterate    18  f =      -237.08  |proj g|=      0.004831

iterations 18
function evaluations 24
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.004831
final function value -237.077

F = -237.077
final  value -237.077214 
converged
 
INFO  [05:43:12.424] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:43:12.479] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:43:12.485] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:43:13.357] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:43:14.083] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:43:14.820] [mlr3]  Finished benchmark 
INFO  [05:43:14.884] [bbotk] Result of batch 46: 
INFO  [05:43:14.885] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:43:14.885] [bbotk]                   9              2615     0.04551025        0.498 -0.8844698 
INFO  [05:43:14.885] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:43:14.885] [bbotk]          <NA>         0.5 db29e151-63a0-4781-a0a6-7f570eaac1e8 
DEBUG [05:43:15.592] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.49887e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004382822 0.449887 
  - best initial criterion value(s) :  205.125 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -205.12  |proj g|=       2.4405
At iterate     1  f =      -237.82  |proj g|=         2.113
At iterate     2  f =      -237.87  |proj g|=        1.8055
At iterate     3  f =      -238.81  |proj g|=        2.1302
At iterate     4  f =      -239.19  |proj g|=        2.1104
At iterate     5  f =      -239.24  |proj g|=        2.1009
At iterate     6  f =      -239.68  |proj g|=        1.9787
At iterate     7  f =      -240.12  |proj g|=        1.8408
At iterate     8  f =      -240.45  |proj g|=        0.4452
At iterate     9  f =      -240.45  |proj g|=       0.44515
At iterate    10  f =      -240.45  |proj g|=      0.093276
At iterate    11  f =      -240.45  |proj g|=     0.0052076

iterations 11
function evaluations 18
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0052076
final function value -240.454

F = -240.454
final  value -240.453942 
converged
 
INFO  [05:43:15.596] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:43:15.651] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:43:15.658] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:43:42.812] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:44:09.677] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:44:35.949] [mlr3]  Finished benchmark 
INFO  [05:44:36.015] [bbotk] Result of batch 47: 
INFO  [05:44:36.017] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:44:36.017] [bbotk]                   5              2169      0.1972197        0.502 -0.8831846 
INFO  [05:44:36.017] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:44:36.017] [bbotk]          <NA>   0.9782809 4cfb6b94-490b-4b7e-b93e-a8efda176d83 
DEBUG [05:44:36.737] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.469426e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004358455 0.4469426 
  - best initial criterion value(s) :  209.4118 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -209.41  |proj g|=       2.6406
At iterate     1  f =      -223.88  |proj g|=        3.4749
At iterate     2  f =      -239.89  |proj g|=       0.44258
At iterate     3  f =       -240.5  |proj g|=        5.2136
At iterate     4  f =       -240.5  |proj g|=        5.1711
At iterate     5  f =      -243.13  |proj g|=        3.1658
At iterate     6  f =       -244.2  |proj g|=        2.2328
At iterate     7  f =      -244.33  |proj g|=       0.44232
At iterate     8  f =      -244.33  |proj g|=       0.44225
At iterate     9  f =      -244.33  |proj g|=       0.44224
At iterate    10  f =      -244.33  |proj g|=     0.0054388

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00543877
final function value -244.334

F = -244.334
final  value -244.334482 
converged
 
INFO  [05:44:36.741] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:44:36.798] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:44:36.804] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:45:18.310] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:45:59.737] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:46:40.958] [mlr3]  Finished benchmark 
INFO  [05:46:41.024] [bbotk] Result of batch 48: 
INFO  [05:46:41.026] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:46:41.026] [bbotk]                   3              3476      0.2844543        0.523 -0.8826649 
INFO  [05:46:41.026] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:46:41.026] [bbotk]          <NA>   0.9773952 a291af99-c1f3-458d-b208-cefe20c56d5c 
DEBUG [05:46:41.836] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.439443e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004327483 0.4439443 
  - best initial criterion value(s) :  191.2753 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -191.28  |proj g|=       5.6349
At iterate     1  f =      -198.22  |proj g|=        4.4914
At iterate     2  f =      -211.88  |proj g|=        2.9488
At iterate     3  f =      -217.22  |proj g|=         5.229
At iterate     4  f =      -217.48  |proj g|=        5.6082
At iterate     5  f =      -218.24  |proj g|=        2.0814
At iterate     6  f =      -218.99  |proj g|=        1.8612
At iterate     7  f =      -219.03  |proj g|=         1.842
At iterate     8  f =      -219.17  |proj g|=        1.7885
At iterate     9  f =      -219.39  |proj g|=        1.7545
At iterate    10  f =      -220.33  |proj g|=        1.4086
At iterate    11  f =      -226.45  |proj g|=        4.5213
At iterate    12  f =      -230.94  |proj g|=        3.2668
At iterate    13  f =      -231.18  |proj g|=        5.3098
At iterate    14  f =       -232.2  |proj g|=        4.5944
At iterate    15  f =      -232.65  |proj g|=       0.96182
At iterate    16  f =      -232.68  |proj g|=       0.43914
At iterate    17  f =      -232.68  |proj g|=       0.43912
At iterate    18  f =      -232.68  |proj g|=       0.10578
At iterate    19  f =      -232.68  |proj g|=     0.0087157

iterations 19
function evaluations 26
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00871568
final function value -232.678

F = -232.678
final  value -232.677545 
converged
 
INFO  [05:46:41.840] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:46:41.902] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:46:41.908] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:46:55.774] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:47:09.788] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:47:23.408] [mlr3]  Finished benchmark 
INFO  [05:47:23.473] [bbotk] Result of batch 49: 
INFO  [05:47:23.475] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:47:23.475] [bbotk]                   4              1102     0.01634596        0.592 -0.8840861 
INFO  [05:47:23.475] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:47:23.475] [bbotk]          <NA>   0.9706743 48337b68-a30e-47be-988c-1f084eb70f10 
DEBUG [05:47:24.209] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.406586e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004304826 0.4406586 
  - best initial criterion value(s) :  173.8671 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -173.87  |proj g|=      0.33566
At iterate     1  f =         -210  |proj g|=      0.041121
At iterate     2  f =      -210.66  |proj g|=       0.43495
At iterate     3  f =      -211.48  |proj g|=       0.43516
At iterate     4  f =      -211.71  |proj g|=       0.43477
At iterate     5  f =      -211.76  |proj g|=       0.43451
At iterate     6  f =      -211.76  |proj g|=       0.43445
At iterate     7  f =      -211.76  |proj g|=        0.1442
At iterate     8  f =      -211.76  |proj g|=     0.0088741

iterations 8
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00887414
final function value -211.765

F = -211.765
final  value -211.764845 
converged
 
INFO  [05:47:24.213] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:47:24.263] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:47:24.270] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:47:34.856] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:47:45.719] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:47:55.937] [mlr3]  Finished benchmark 
INFO  [05:47:56.010] [bbotk] Result of batch 50: 
INFO  [05:47:56.012] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:47:56.012] [bbotk]                   7               804     0.07910222        0.522 -0.9124464 
INFO  [05:47:56.012] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:47:56.012] [bbotk]          <NA>    0.976494 2507a66b-72be-4886-a732-38eb9b13d86a 
DEBUG [05:47:56.741] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.376184e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004276048 0.4376184 
  - best initial criterion value(s) :  209.601 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -209.6  |proj g|=       10.467
At iterate     1  f =      -222.01  |proj g|=       0.89188
At iterate     2  f =      -235.76  |proj g|=        3.2883
At iterate     3  f =      -238.72  |proj g|=        3.0007
At iterate     4  f =      -247.58  |proj g|=        2.0581
At iterate     5  f =         -248  |proj g|=        1.9984
At iterate     6  f =      -248.28  |proj g|=         3.165
At iterate     7  f =      -249.69  |proj g|=        0.1202
At iterate     8  f =      -250.88  |proj g|=        1.8935
At iterate     9  f =      -251.01  |proj g|=        1.5443
At iterate    10  f =       -251.1  |proj g|=       0.43292
At iterate    11  f =       -251.1  |proj g|=       0.08973
At iterate    12  f =       -251.1  |proj g|=     0.0067434
At iterate    13  f =       -251.1  |proj g|=      0.011185

iterations 13
function evaluations 21
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0111852
final function value -251.097

F = -251.097
final  value -251.096733 
converged
 
INFO  [05:47:56.745] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:47:56.798] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:47:56.805] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:47:57.578] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:47:58.330] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:47:59.098] [mlr3]  Finished benchmark 
INFO  [05:47:59.173] [bbotk] Result of batch 51: 
INFO  [05:47:59.175] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:47:59.175] [bbotk]                  10              2101      0.3595545         0.52 -0.8827746 
INFO  [05:47:59.175] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:47:59.175] [bbotk]          <NA>         0.5 04646e98-526a-49e6-b4c6-546fb812a967 
DEBUG [05:48:00.038] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.462152e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004367175 0.4462152 
  - best initial criterion value(s) :  217.6204 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -217.62  |proj g|=       5.4162
At iterate     1  f =      -219.79  |proj g|=        4.2897
At iterate     2  f =      -221.14  |proj g|=        5.1537
At iterate     3  f =      -223.98  |proj g|=        5.0915
At iterate     4  f =      -225.74  |proj g|=        4.9517
At iterate     5  f =       -229.4  |proj g|=        4.6526
At iterate     6  f =      -238.83  |proj g|=        3.9079
At iterate     7  f =      -254.17  |proj g|=        3.0945
At iterate     8  f =      -254.45  |proj g|=        3.0814
At iterate     9  f =       -254.6  |proj g|=        3.0655
At iterate    10  f =      -255.67  |proj g|=        2.9256
At iterate    11  f =      -257.23  |proj g|=        2.6724
At iterate    12  f =      -260.27  |proj g|=        1.1702
At iterate    13  f =      -263.43  |proj g|=        7.9732
At iterate    14  f =      -264.68  |proj g|=       0.47898
At iterate    15  f =      -264.73  |proj g|=       0.52834
At iterate    16  f =      -264.73  |proj g|=     0.0091912
At iterate    17  f =      -264.73  |proj g|=      0.083898
At iterate    18  f =      -264.73  |proj g|=       0.00906

iterations 18
function evaluations 26
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00906
final function value -264.731

F = -264.731
final  value -264.730891 
converged
 
INFO  [05:48:00.042] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:48:00.096] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:48:00.103] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:48:32.527] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:49:04.171] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:49:04.902] [mlr3]  Finished benchmark 
INFO  [05:49:05.003] [bbotk] Result of batch 52: 
INFO  [05:49:05.005] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:49:05.005] [bbotk]                   8              2634      0.3377826        0.634 -0.8812987 
INFO  [05:49:05.005] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:49:05.005] [bbotk]          <NA>   0.8152692 09316ad2-ddef-4108-9e21-1e0b843f1d5d 
DEBUG [05:49:05.747] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.401958e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004326462 0.4401958 
  - best initial criterion value(s) :  188.8283 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -188.83  |proj g|=       3.0469
At iterate     1  f =      -209.18  |proj g|=         6.409
At iterate     2  f =      -219.36  |proj g|=        12.812
At iterate     3  f =      -221.79  |proj g|=         3.144
At iterate     4  f =      -221.87  |proj g|=        2.9234
At iterate     5  f =      -221.87  |proj g|=        2.8218
At iterate     6  f =      -221.89  |proj g|=        2.5112
At iterate     7  f =      -221.93  |proj g|=        2.0236
At iterate     8  f =      -222.05  |proj g|=        1.1943
At iterate     9  f =      -222.35  |proj g|=       0.43577
At iterate    10  f =      -223.07  |proj g|=        1.7302
At iterate    11  f =       -223.8  |proj g|=        1.7674
At iterate    12  f =      -224.13  |proj g|=        1.2537
At iterate    13  f =      -224.15  |proj g|=       0.74566
At iterate    14  f =      -224.15  |proj g|=       0.59578
At iterate    15  f =      -224.15  |proj g|=       0.54356
At iterate    16  f =      -224.15  |proj g|=       0.47054
At iterate    17  f =      -224.16  |proj g|=       0.32949
At iterate    18  f =      -224.16  |proj g|=       0.10449
At iterate    19  f =      -224.16  |proj g|=      0.018806
At iterate    20  f =      -224.16  |proj g|=      0.016376
At iterate    21  f =      -224.16  |proj g|=      0.016376

iterations 21
function evaluations 28
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0163763
final function value -224.164

F = -224.164
final  value -224.163873 
converged
 
INFO  [05:49:05.751] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:49:05.803] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:49:05.810] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:49:06.569] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:49:07.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:49:08.294] [mlr3]  Finished benchmark 
INFO  [05:49:08.366] [bbotk] Result of batch 53: 
INFO  [05:49:08.367] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:49:08.367] [bbotk]                  10              4004        0.40751        0.519 -0.8877506 
INFO  [05:49:08.367] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:49:08.367] [bbotk]          <NA>         0.5 475b8bb6-302c-4e68-a263-fe146de4b625 
DEBUG [05:49:09.150] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.481426e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004408285 0.4481426 
  - best initial criterion value(s) :  223.608 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -223.61  |proj g|=       5.8749
At iterate     1  f =      -237.91  |proj g|=         1.103
At iterate     2  f =      -265.36  |proj g|=        2.0506
At iterate     3  f =      -265.89  |proj g|=         2.075
At iterate     4  f =      -266.93  |proj g|=        1.7224
At iterate     5  f =      -267.03  |proj g|=       0.44373
At iterate     6  f =      -267.05  |proj g|=      0.059752
At iterate     7  f =      -267.05  |proj g|=       0.44359
At iterate     8  f =      -267.05  |proj g|=       0.44359
At iterate     9  f =      -267.05  |proj g|=     0.0069535
At iterate    10  f =      -267.05  |proj g|=     0.0069535
At iterate    11  f =      -267.05  |proj g|=        0.4436
At iterate    12  f =      -267.07  |proj g|=       0.55627
At iterate    13  f =      -267.12  |proj g|=        1.1936
At iterate    14  f =      -267.17  |proj g|=        1.5747
At iterate    15  f =      -267.36  |proj g|=         2.635
At iterate    16  f =      -268.16  |proj g|=        6.3694
At iterate    17  f =      -269.23  |proj g|=        9.2592
At iterate    18  f =      -272.38  |proj g|=        12.845
At iterate    19  f =      -275.41  |proj g|=        12.662
At iterate    20  f =      -278.55  |proj g|=        1.1138
At iterate    21  f =      -278.56  |proj g|=        1.0351
At iterate    22  f =      -278.58  |proj g|=       0.44364
At iterate    23  f =      -278.58  |proj g|=    0.00080335
At iterate    24  f =      -278.58  |proj g|=    9.7851e-05

iterations 24
function evaluations 41
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 9.78513e-05
final function value -278.579

F = -278.579
final  value -278.578928 
converged
 
INFO  [05:49:09.154] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:49:09.206] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:49:09.213] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:49:39.962] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:49:40.721] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:50:11.877] [mlr3]  Finished benchmark 
INFO  [05:50:11.943] [bbotk] Result of batch 54: 
INFO  [05:50:11.945] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:50:11.945] [bbotk]                   8              2595       0.466144        0.527 -0.8795669 
INFO  [05:50:11.945] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:50:11.945] [bbotk]          <NA>   0.8148744 7965a6e4-5c77-435e-b52c-2002c56e9d6c 
DEBUG [05:50:12.683] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.422491e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004369748 0.4422491 
  - best initial criterion value(s) :  225.3387 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -225.34  |proj g|=       8.3662
At iterate     1  f =      -236.06  |proj g|=       0.75729
At iterate     2  f =      -250.05  |proj g|=        3.5131
At iterate     3  f =      -253.49  |proj g|=         3.198
At iterate     4  f =      -264.54  |proj g|=        8.9597
At iterate     5  f =      -265.87  |proj g|=         1.892
At iterate     6  f =         -266  |proj g|=        1.9305
At iterate     7  f =      -266.33  |proj g|=       0.13826
At iterate     8  f =      -266.78  |proj g|=       0.53122
At iterate     9  f =      -269.82  |proj g|=        1.7544
At iterate    10  f =      -273.36  |proj g|=        1.3872
At iterate    11  f =       -273.4  |proj g|=       0.43779
At iterate    12  f =       -273.4  |proj g|=     0.0068573
At iterate    13  f =       -273.4  |proj g|=     0.0068574
At iterate    14  f =       -273.4  |proj g|=     0.0068574

iterations 14
function evaluations 22
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00685741
final function value -273.4

F = -273.4
final  value -273.400248 
converged
 
INFO  [05:50:12.687] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:50:12.747] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:50:12.755] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:51:00.444] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:51:48.163] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:52:35.692] [mlr3]  Finished benchmark 
INFO  [05:52:35.758] [bbotk] Result of batch 55: 
INFO  [05:52:35.760] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [05:52:35.760] [bbotk]                   5              4023      0.2731512        0.523   -0.8808 
INFO  [05:52:35.760] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:52:35.760] [bbotk]          <NA>   0.9777467 5f8011e2-b44a-4bcd-9a20-9f52b33e8816 
DEBUG [05:52:36.527] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.397075e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004333683 0.4397075 
  - best initial criterion value(s) :  218.8548 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -218.85  |proj g|=       12.185
At iterate     1  f =      -242.14  |proj g|=        5.7244
At iterate     2  f =      -250.64  |proj g|=        4.8325
At iterate     3  f =      -261.61  |proj g|=        3.8518
At iterate     4  f =      -282.66  |proj g|=        9.9837
At iterate     5  f =       -283.8  |proj g|=        1.9707
At iterate     6  f =      -283.88  |proj g|=        2.0038
At iterate     7  f =      -284.63  |proj g|=       0.49291
At iterate     8  f =      -284.66  |proj g|=       0.26081
At iterate     9  f =      -284.94  |proj g|=        1.8219
At iterate    10  f =      -288.33  |proj g|=        1.8913
At iterate    11  f =      -288.57  |proj g|=       0.75645
At iterate    12  f =      -288.58  |proj g|=       0.43537
At iterate    13  f =      -288.58  |proj g|=       0.43533
At iterate    14  f =      -288.58  |proj g|=       0.26697
At iterate    15  f =      -288.58  |proj g|=      0.010501

iterations 15
function evaluations 26
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0105005
final function value -288.585

F = -288.585
final  value -288.584888 
converged
 
INFO  [05:52:36.531] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:52:36.596] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:52:36.605] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:52:37.336] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:53:33.305] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:54:29.561] [mlr3]  Finished benchmark 
INFO  [05:54:29.629] [bbotk] Result of batch 56: 
INFO  [05:54:29.631] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:54:29.631] [bbotk]                   8              4745     0.09002265        0.538 -0.8791331 
INFO  [05:54:29.631] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:54:29.631] [bbotk]          <NA>   0.8159417 e4f907f0-6a95-4e23-b912-909bab491bf5 
DEBUG [05:54:30.423] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.340745e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9132 0.9773575 
  - variance bounds :  0.004259272 0.4340745 
  - best initial criterion value(s) :  234.1045 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -234.1  |proj g|=        5.318
At iterate     1  f =      -243.76  |proj g|=         5.374
At iterate     2  f =      -247.52  |proj g|=        5.1093
At iterate     3  f =       -250.8  |proj g|=        4.7507
At iterate     4  f =      -255.45  |proj g|=         4.234
At iterate     5  f =      -266.67  |proj g|=        3.0965
At iterate     6  f =      -274.58  |proj g|=        12.941
At iterate     7  f =       -280.5  |proj g|=        1.8568
At iterate     8  f =      -280.64  |proj g|=        1.8756
At iterate     9  f =      -280.76  |proj g|=         1.323
At iterate    10  f =       -283.4  |proj g|=       0.46332
At iterate    11  f =      -289.43  |proj g|=        2.0567
At iterate    12  f =      -289.51  |proj g|=       0.51693
At iterate    13  f =      -289.52  |proj g|=       0.42973
At iterate    14  f =      -289.52  |proj g|=      0.013382
At iterate    15  f =      -289.52  |proj g|=       0.26427
At iterate    16  f =      -289.52  |proj g|=       0.00618

iterations 16
function evaluations 27
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00618002
final function value -289.519

F = -289.519
final  value -289.519444 
converged
 
INFO  [05:54:30.427] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:54:30.481] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:54:30.488] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:54:31.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:54:35.992] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:54:40.306] [mlr3]  Finished benchmark 
INFO  [05:54:40.371] [bbotk] Result of batch 57: 
INFO  [05:54:40.372] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [05:54:40.372] [bbotk]                   8               279      0.2029128        0.568 -0.8795654 
INFO  [05:54:40.372] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:54:40.372] [bbotk]          <NA>   0.8153788 0efa0d48-94cc-4498-86e1-e038084050c2 
DEBUG [05:54:41.127] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.285848e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9773575 
  - variance bounds :  0.004174472 0.4285848 
  - best initial criterion value(s) :  217.3946 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -217.39  |proj g|=      0.33797
At iterate     1  f =      -271.28  |proj g|=      0.023869
At iterate     2  f =      -271.98  |proj g|=       0.42358
At iterate     3  f =      -272.49  |proj g|=       0.42368
At iterate     4  f =      -272.63  |proj g|=        0.4234
At iterate     5  f =      -272.66  |proj g|=       0.42324
At iterate     6  f =      -272.66  |proj g|=       0.42321
At iterate     7  f =      -272.66  |proj g|=      0.038774
At iterate     8  f =      -272.66  |proj g|=      0.005572

iterations 8
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00557196
final function value -272.662

F = -272.662
final  value -272.662413 
converged
 
INFO  [05:54:41.131] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:54:41.185] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:54:41.191] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:55:25.752] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:56:10.640] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:56:55.365] [mlr3]  Finished benchmark 
INFO  [05:56:55.430] [bbotk] Result of batch 58: 
INFO  [05:56:55.432] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [05:56:55.432] [bbotk]                   3              3736      0.3654635        0.549  -0.90597 
INFO  [05:56:55.432] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:56:55.432] [bbotk]          <NA>   0.9774407 0ccd0002-4994-46ae-bf6d-24db5f0ba75f 
DEBUG [05:56:56.347] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.262263e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9773575 
  - variance bounds :  0.004136331 0.4262263 
  - best initial criterion value(s) :  211.5216 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -211.52  |proj g|=       6.2207
At iterate     1  f =      -223.25  |proj g|=        3.7725
At iterate     2  f =      -229.56  |proj g|=        5.5644
At iterate     3  f =       -231.5  |proj g|=        5.5121
At iterate     4  f =      -254.28  |proj g|=        3.9098
At iterate     5  f =      -274.54  |proj g|=        1.2735
At iterate     6  f =      -283.49  |proj g|=        2.7085
At iterate     7  f =       -283.8  |proj g|=        2.7022
At iterate     8  f =       -284.2  |proj g|=        2.6634
At iterate     9  f =      -286.11  |proj g|=        2.3084
At iterate    10  f =      -289.15  |proj g|=        2.1277
At iterate    11  f =      -291.02  |proj g|=        1.7552
At iterate    12  f =      -291.11  |proj g|=       0.42199
At iterate    13  f =      -291.11  |proj g|=     0.0082147
At iterate    14  f =      -291.11  |proj g|=      0.007746
At iterate    15  f =      -291.11  |proj g|=      0.007746

iterations 15
function evaluations 25
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00774602
final function value -291.113

F = -291.113
final  value -291.113054 
converged
 
INFO  [05:56:56.351] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:56:56.407] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:56:56.414] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [05:57:55.319] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [05:58:54.333] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [05:59:52.676] [mlr3]  Finished benchmark 
INFO  [05:59:52.742] [bbotk] Result of batch 59: 
INFO  [05:59:52.743] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [05:59:52.743] [bbotk]                   4              4950       0.458732         0.52 -0.879401 
INFO  [05:59:52.743] [bbotk]  errors.model classif.auc                                uhash 
INFO  [05:59:52.743] [bbotk]          <NA>    0.977996 a330bcd4-c615-45ff-8213-7b30a78694f7 
DEBUG [05:59:53.474] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.238747e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9773575 
  - variance bounds :  0.004100751 0.4238747 
  - best initial criterion value(s) :  217.6104 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -217.61  |proj g|=       7.4665
At iterate     1  f =      -226.11  |proj g|=        3.0223
At iterate     2  f =      -246.45  |proj g|=        6.2957
At iterate     3  f =       -264.1  |proj g|=        5.1907
At iterate     4  f =      -286.78  |proj g|=        3.8512
At iterate     5  f =         -288  |proj g|=        3.8121
At iterate     6  f =      -297.41  |proj g|=        3.0969
At iterate     7  f =      -302.05  |proj g|=        2.4266
At iterate     8  f =      -305.77  |proj g|=        12.806
At iterate     9  f =      -309.37  |proj g|=       0.43343
At iterate    10  f =      -309.38  |proj g|=       0.37382
At iterate    11  f =      -309.38  |proj g|=        0.4197
At iterate    12  f =      -309.38  |proj g|=     0.0053597
At iterate    13  f =      -309.38  |proj g|=     0.0053597

iterations 13
function evaluations 21
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00535968
final function value -309.379

F = -309.379
final  value -309.378510 
converged
 
INFO  [05:59:53.478] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:59:53.533] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:59:53.540] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:00:10.755] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:00:27.763] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:00:44.657] [mlr3]  Finished benchmark 
INFO  [06:00:44.723] [bbotk] Result of batch 60: 
INFO  [06:00:44.724] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:00:44.724] [bbotk]                   3              1361      0.4872262        0.516 -0.8774076 
INFO  [06:00:44.724] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:00:44.724] [bbotk]          <NA>   0.9772339 ed87315b-0f29-431c-a8ca-78b61dd8559a 
DEBUG [06:00:45.490] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.214832e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9773575 
  - variance bounds :  0.004100941 0.4214832 
  - best initial criterion value(s) :  240.7947 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -240.79  |proj g|=         1.41
At iterate     1  f =      -249.52  |proj g|=        3.9254
At iterate     2  f =      -252.01  |proj g|=        3.8563
At iterate     3  f =      -253.47  |proj g|=        3.6464
At iterate     4  f =       -255.5  |proj g|=        3.2704
At iterate     5  f =      -258.99  |proj g|=        2.7278
At iterate     6  f =      -261.43  |proj g|=        2.2376
At iterate     7  f =      -261.52  |proj g|=        2.1517
At iterate     8  f =      -261.53  |proj g|=        2.1569
At iterate     9  f =      -261.63  |proj g|=        2.1822
At iterate    10  f =      -261.81  |proj g|=        2.2126
At iterate    11  f =      -262.36  |proj g|=        2.2734
At iterate    12  f =       -263.7  |proj g|=         2.378
At iterate    13  f =      -266.97  |proj g|=        2.5792
At iterate    14  f =       -271.5  |proj g|=        2.7401
At iterate    15  f =      -274.51  |proj g|=         2.574
At iterate    16  f =      -279.99  |proj g|=        1.3362
At iterate    17  f =      -280.79  |proj g|=        1.4727
At iterate    18  f =      -280.92  |proj g|=       0.41738
At iterate    19  f =      -280.96  |proj g|=       0.01323
At iterate    20  f =      -280.96  |proj g|=       0.01701
At iterate    21  f =      -280.96  |proj g|=       0.41718
At iterate    22  f =      -280.96  |proj g|=      0.011978

iterations 22
function evaluations 30
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0119782
final function value -280.961

F = -280.961
final  value -280.960809 
converged
 
INFO  [06:00:45.494] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:00:45.549] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:00:45.556] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:00:46.305] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:01:21.333] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:01:56.222] [mlr3]  Finished benchmark 
INFO  [06:01:56.287] [bbotk] Result of batch 61: 
INFO  [06:01:56.289] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [06:01:56.289] [bbotk]                   8              2899      0.4197216        0.528 -0.881634 
INFO  [06:01:56.289] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:01:56.289] [bbotk]          <NA>   0.8148614 37427d92-b32f-4800-a131-8f3fe60ff6e5 
DEBUG [06:01:57.036] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.164233e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9773575 
  - variance bounds :  0.004052509 0.4164233 
  - best initial criterion value(s) :  242.7914 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -242.79  |proj g|=       12.987
At iterate     1  f =      -273.67  |proj g|=        5.0731
At iterate     2  f =      -278.61  |proj g|=        4.6809
At iterate     3  f =      -284.84  |proj g|=        4.1355
At iterate     4  f =      -292.65  |proj g|=        3.5667
At iterate     5  f =      -312.49  |proj g|=        5.6392
At iterate     6  f =      -312.82  |proj g|=        1.8316
At iterate     7  f =      -312.88  |proj g|=        1.8389
At iterate     8  f =      -313.07  |proj g|=       0.67138
At iterate     9  f =      -313.71  |proj g|=        1.7936
At iterate    10  f =      -313.84  |proj g|=        1.7994
At iterate    11  f =      -313.93  |proj g|=        0.5839
At iterate    12  f =      -313.94  |proj g|=      0.033774
At iterate    13  f =      -313.94  |proj g|=       0.20891
At iterate    14  f =      -313.94  |proj g|=     0.0065894

iterations 14
function evaluations 21
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00658944
final function value -313.941

F = -313.941
final  value -313.940509 
converged
 
INFO  [06:01:57.040] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:01:57.092] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:01:57.098] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:02:07.088] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:02:17.284] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:02:18.053] [mlr3]  Finished benchmark 
INFO  [06:02:18.117] [bbotk] Result of batch 62: 
INFO  [06:02:18.119] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:02:18.119] [bbotk]                   8               762      0.1248241        0.525 -0.8778152 
INFO  [06:02:18.119] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:02:18.119] [bbotk]          <NA>   0.8160308 2adbe6be-bff5-4240-96ba-0bda3b9ee7e3 
DEBUG [06:02:18.885] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.114802e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9773575 
  - variance bounds :  0.004004604 0.4114802 
  - best initial criterion value(s) :  274.4499 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -274.45  |proj g|=       10.652
At iterate     1  f =       -285.3  |proj g|=         1.709
At iterate     2  f =      -300.89  |proj g|=          2.91
At iterate     3  f =      -304.43  |proj g|=        2.3679
At iterate     4  f =      -311.05  |proj g|=       0.52687
At iterate     5  f =      -311.05  |proj g|=       0.64678
At iterate     6  f =      -311.06  |proj g|=       0.42831
At iterate     7  f =      -311.09  |proj g|=       0.25735
At iterate     8  f =      -311.14  |proj g|=        1.0267
At iterate     9  f =       -311.3  |proj g|=        2.4106
At iterate    10  f =      -311.69  |proj g|=        4.4108
At iterate    11  f =      -312.68  |proj g|=        7.7858
At iterate    12  f =      -314.48  |proj g|=        12.585
At iterate    13  f =      -315.64  |proj g|=        9.5716
At iterate    14  f =      -317.26  |proj g|=       0.40748
At iterate    15  f =      -317.26  |proj g|=       0.14446
At iterate    16  f =      -317.26  |proj g|=       0.40745
At iterate    17  f =      -317.26  |proj g|=     0.0072097
At iterate    18  f =      -317.26  |proj g|=     0.0072097

iterations 18
function evaluations 27
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00720969
final function value -317.258

F = -317.258
final  value -317.257718 
converged
 
INFO  [06:02:18.889] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:02:18.943] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:02:18.949] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:02:19.720] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:02:20.560] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:02:21.406] [mlr3]  Finished benchmark 
INFO  [06:02:21.473] [bbotk] Result of batch 63: 
INFO  [06:02:21.475] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:02:21.475] [bbotk]                  10              4246      0.1333183        0.533 -0.8777608 
INFO  [06:02:21.475] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:02:21.475] [bbotk]          <NA>         0.5 e9363565-4554-4b1f-89ee-8b7ffa424c85 
DEBUG [06:02:22.270] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.190689e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9773575 
  - variance bounds :  0.004076484 0.4190689 
  - best initial criterion value(s) :  256.4352 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -256.44  |proj g|=       5.4018
At iterate     1  f =      -257.08  |proj g|=        5.2847
At iterate     2  f =      -262.35  |proj g|=        5.0788
At iterate     3  f =      -270.11  |proj g|=        4.5659
At iterate     4  f =      -296.78  |proj g|=        2.8412
At iterate     5  f =      -306.45  |proj g|=       0.99204
At iterate     6  f =      -311.58  |proj g|=        2.4191
At iterate     7  f =      -313.51  |proj g|=        2.4111
At iterate     8  f =      -313.55  |proj g|=        2.4048
At iterate     9  f =      -313.61  |proj g|=         2.404
At iterate    10  f =      -313.68  |proj g|=         2.398
At iterate    11  f =      -314.08  |proj g|=        2.3478
At iterate    12  f =      -314.69  |proj g|=        2.2464
At iterate    13  f =      -315.81  |proj g|=        1.7945
At iterate    14  f =      -317.17  |proj g|=         2.499
At iterate    15  f =      -317.82  |proj g|=        1.8124
At iterate    16  f =      -317.98  |proj g|=       0.91961
At iterate    17  f =         -318  |proj g|=     0.0080996
At iterate    18  f =         -318  |proj g|=     0.0080995

iterations 18
function evaluations 25
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00809954
final function value -317.997

F = -317.997
final  value -317.996908 
converged
 
INFO  [06:02:22.275] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:02:22.328] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:02:22.335] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:02:57.851] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:03:33.459] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:04:09.382] [mlr3]  Finished benchmark 
INFO  [06:04:09.447] [bbotk] Result of batch 64: 
INFO  [06:04:09.449] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:04:09.449] [bbotk]                   3              2987      0.2995368        0.555 -0.8783279 
INFO  [06:04:09.449] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:04:09.449] [bbotk]          <NA>   0.9773238 782dc1d9-fd53-4e5a-82ba-645828afd987 
DEBUG [06:04:10.231] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.169283e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9773575 
  - variance bounds :  0.004055281 0.4169283 
  - best initial criterion value(s) :  273.4231 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -273.42  |proj g|=        7.802
At iterate     1  f =       -280.1  |proj g|=        5.6824
At iterate     2  f =      -303.46  |proj g|=        3.8195
At iterate     3  f =      -304.56  |proj g|=        3.6435
At iterate     4  f =       -324.1  |proj g|=        2.4231
At iterate     5  f =      -328.13  |proj g|=        1.9293
At iterate     6  f =      -328.35  |proj g|=        1.9029
At iterate     7  f =      -328.76  |proj g|=        1.7762
At iterate     8  f =      -328.78  |proj g|=        1.7681
At iterate     9  f =      -328.81  |proj g|=        1.2657
At iterate    10  f =      -328.83  |proj g|=     0.0073574
At iterate    11  f =      -328.83  |proj g|=     0.0073574

iterations 11
function evaluations 22
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00735736
final function value -328.834

F = -328.834
final  value -328.833828 
converged
 
INFO  [06:04:10.235] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:04:10.288] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:04:10.295] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:04:28.073] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:04:45.729] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:05:03.428] [mlr3]  Finished benchmark 
INFO  [06:05:03.494] [bbotk] Result of batch 65: 
INFO  [06:05:03.496] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:05:03.496] [bbotk]                   6              1435     0.03168272        0.556 -0.8777463 
INFO  [06:05:03.496] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:05:03.496] [bbotk]          <NA>   0.9763238 2f9661e1-8f46-467f-9507-10a0bc4e5618 
DEBUG [06:05:04.256] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.14741e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9773575 
  - variance bounds :  0.004051064 0.414741 
  - best initial criterion value(s) :  291.4154 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -291.42  |proj g|=        1.174
At iterate     1  f =      -315.66  |proj g|=        2.8362
At iterate     2  f =      -316.28  |proj g|=        2.7718
At iterate     3  f =       -317.7  |proj g|=        2.6831
At iterate     4  f =      -318.25  |proj g|=        2.6307
At iterate     5  f =      -319.53  |proj g|=        2.4673
At iterate     6  f =      -322.04  |proj g|=       0.32438
At iterate     7  f =      -323.59  |proj g|=        4.6449
At iterate     8  f =      -323.97  |proj g|=       0.77068
At iterate     9  f =         -324  |proj g|=       0.19663
At iterate    10  f =         -324  |proj g|=     0.0081424
At iterate    11  f =         -324  |proj g|=      0.064255

iterations 11
function evaluations 18
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0642551
final function value -323.998

F = -323.998
final  value -323.998326 
converged
 
INFO  [06:05:04.260] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:05:04.314] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:05:04.321] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:06:02.485] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:07:00.707] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:07:58.231] [mlr3]  Finished benchmark 
INFO  [06:07:58.305] [bbotk] Result of batch 66: 
INFO  [06:07:58.307] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:07:58.307] [bbotk]                   6              4879        0.26519        0.537 -0.8768232 
INFO  [06:07:58.307] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:07:58.307] [bbotk]          <NA>   0.9764077 bb7fa26a-2b55-4bef-869c-692ba114ad28 
DEBUG [06:07:59.100] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.125483e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9773575 
  - variance bounds :  0.004009598 0.4125483 
  - best initial criterion value(s) :  245.9286 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -245.93  |proj g|=       13.175
At iterate     1  f =      -277.01  |proj g|=        4.5605
At iterate     2  f =      -290.61  |proj g|=        0.4612
At iterate     3  f =      -300.49  |proj g|=        1.8909
At iterate     4  f =      -300.87  |proj g|=        1.9506
At iterate     5  f =      -300.88  |proj g|=        1.9865
At iterate     6  f =      -301.71  |proj g|=        2.0158
At iterate     7  f =      -305.38  |proj g|=        2.0648
At iterate     8  f =      -313.25  |proj g|=        2.1433
At iterate     9  f =      -331.38  |proj g|=        2.0537
At iterate    10  f =      -340.66  |proj g|=        1.6567
At iterate    11  f =       -340.7  |proj g|=        1.3825
At iterate    12  f =      -340.77  |proj g|=       0.40812
At iterate    13  f =      -340.77  |proj g|=      0.048455
At iterate    14  f =      -340.77  |proj g|=     0.0062313
At iterate    15  f =      -340.77  |proj g|=     0.0070179

iterations 15
function evaluations 20
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00701786
final function value -340.771

F = -340.771
final  value -340.770919 
converged
 
INFO  [06:07:59.104] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:07:59.158] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:07:59.164] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:08:46.116] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:09:32.771] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:10:19.227] [mlr3]  Finished benchmark 
INFO  [06:10:19.293] [bbotk] Result of batch 67: 
INFO  [06:10:19.295] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:10:19.295] [bbotk]                   7              3902     0.09255146        0.566 -0.8757758 
INFO  [06:10:19.295] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:10:19.295] [bbotk]          <NA>   0.9767971 2f5bf273-6b9d-4fc9-8ce7-569c76a9236c 
DEBUG [06:10:20.071] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.103624e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9773575 
  - variance bounds :  0.003984096 0.4103624 
  - best initial criterion value(s) :  288.2449 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -288.24  |proj g|=       4.8831
At iterate     1  f =      -312.82  |proj g|=         4.637
At iterate     2  f =      -333.05  |proj g|=        2.0931
At iterate     3  f =       -334.7  |proj g|=         2.153
At iterate     4  f =      -334.84  |proj g|=        1.0516
At iterate     5  f =      -335.16  |proj g|=        2.9947
At iterate     6  f =      -336.09  |proj g|=        5.1368
At iterate     7  f =      -337.58  |proj g|=        6.3465
At iterate     8  f =      -338.06  |proj g|=        3.5209
At iterate     9  f =      -338.35  |proj g|=        1.2163
At iterate    10  f =      -338.38  |proj g|=       0.40598
At iterate    11  f =      -338.38  |proj g|=     0.0094653
At iterate    12  f =      -338.38  |proj g|=       0.40596
At iterate    13  f =      -338.38  |proj g|=     0.0074495

iterations 13
function evaluations 19
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00744946
final function value -338.379

F = -338.379
final  value -338.378968 
converged
 
INFO  [06:10:20.075] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:10:20.140] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:10:20.147] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:10:21.037] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:10:21.798] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:10:22.543] [mlr3]  Finished benchmark 
INFO  [06:10:22.622] [bbotk] Result of batch 68: 
INFO  [06:10:22.624] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:10:22.624] [bbotk]                   9              2900     0.09432878        0.554 -0.8761416 
INFO  [06:10:22.624] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:10:22.624] [bbotk]          <NA>         0.5 f0d12c50-414d-4f3f-b044-acfb4fbc667c 
DEBUG [06:10:23.406] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.177677e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9773575 
  - variance bounds :  0.004061661 0.4177677 
  - best initial criterion value(s) :  305.246 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -305.25  |proj g|=       12.846
At iterate     1  f =      -329.75  |proj g|=        3.8062
At iterate     2  f =      -341.74  |proj g|=        3.0137
At iterate     3  f =      -346.35  |proj g|=        2.8421
At iterate     4  f =      -348.44  |proj g|=        2.4383
At iterate     5  f =      -354.07  |proj g|=       0.66387
At iterate     6  f =       -354.1  |proj g|=       0.37294
At iterate     7  f =       -354.1  |proj g|=       0.41337
At iterate     8  f =       -354.1  |proj g|=     0.0059997
At iterate     9  f =       -354.1  |proj g|=       0.05439

iterations 9
function evaluations 14
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0543897
final function value -354.104

F = -354.104
final  value -354.103623 
converged
 
INFO  [06:10:23.410] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:10:23.465] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:10:23.472] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:11:18.344] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:12:12.986] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:13:07.505] [mlr3]  Finished benchmark 
INFO  [06:13:07.580] [bbotk] Result of batch 69: 
INFO  [06:13:07.582] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:13:07.582] [bbotk]                   3              4586    0.008439244        0.563 -0.8746555 
INFO  [06:13:07.582] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:13:07.582] [bbotk]          <NA>   0.9708817 0cc82e52-f855-4f4f-ab50-a6682d385775 
DEBUG [06:13:08.404] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.154476e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9774851 
  - variance bounds :  0.00402113 0.4154476 
  - best initial criterion value(s) :  292.0349 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -292.03  |proj g|=       1.5796
At iterate     1  f =       -305.2  |proj g|=        5.0028
At iterate     2  f =      -308.32  |proj g|=        5.0171
At iterate     3  f =      -309.31  |proj g|=        4.7992
At iterate     4  f =       -312.5  |proj g|=        4.2426
At iterate     5  f =      -316.05  |proj g|=        3.7517
At iterate     6  f =      -323.93  |proj g|=        2.0573
At iterate     7  f =      -324.58  |proj g|=        2.0398
At iterate     8  f =      -325.42  |proj g|=        2.4499
At iterate     9  f =      -333.12  |proj g|=        2.0871
At iterate    10  f =      -346.59  |proj g|=        4.8733
At iterate    11  f =       -353.4  |proj g|=        4.5348
At iterate    12  f =      -354.68  |proj g|=        2.7197
At iterate    13  f =      -354.83  |proj g|=        1.0913
At iterate    14  f =      -354.94  |proj g|=       0.29679
At iterate    15  f =      -354.94  |proj g|=      0.069715
At iterate    16  f =      -354.94  |proj g|=       0.41113
At iterate    17  f =      -354.94  |proj g|=       0.41113
At iterate    18  f =      -354.94  |proj g|=     0.0065402
At iterate    19  f =      -354.94  |proj g|=     0.0065402

iterations 19
function evaluations 26
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00654016
final function value -354.94

F = -354.94
final  value -354.940379 
converged
 
INFO  [06:13:08.409] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:13:08.469] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:13:08.477] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:13:20.256] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:13:32.313] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:13:44.164] [mlr3]  Finished benchmark 
INFO  [06:13:44.231] [bbotk] Result of batch 70: 
INFO  [06:13:44.233] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:13:44.233] [bbotk]                   7               899      0.1727029        0.576 -0.8739143 
INFO  [06:13:44.233] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:13:44.233] [bbotk]          <NA>   0.9769013 a7ff7f34-da3d-41ce-80b1-18498dd4ce98 
DEBUG [06:13:45.029] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.133186e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9774851 
  - variance bounds :  0.003988544 0.4133186 
  - best initial criterion value(s) :  314.2035 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -314.2  |proj g|=       2.9068
At iterate     1  f =      -318.18  |proj g|=        4.2055
At iterate     2  f =      -332.99  |proj g|=        3.1005
At iterate     3  f =      -345.58  |proj g|=        1.8465
At iterate     4  f =       -345.7  |proj g|=        1.8607
At iterate     5  f =      -345.73  |proj g|=       0.23229
At iterate     6  f =      -345.81  |proj g|=       0.59718
At iterate     7  f =      -346.15  |proj g|=        1.8729
At iterate     8  f =         -347  |proj g|=        2.0191
At iterate     9  f =      -347.56  |proj g|=        2.0714
At iterate    10  f =      -347.97  |proj g|=        1.9882
At iterate    11  f =      -348.32  |proj g|=        1.7359
At iterate    12  f =      -348.43  |proj g|=       0.40912
At iterate    13  f =      -348.43  |proj g|=       0.40909
At iterate    14  f =      -348.43  |proj g|=       0.35209
At iterate    15  f =      -348.43  |proj g|=      0.029935

iterations 15
function evaluations 20
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0299348
final function value -348.434

F = -348.434
final  value -348.434341 
converged
 
INFO  [06:13:45.033] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:13:45.096] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:13:45.102] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:13:45.830] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:13:46.574] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:13:47.391] [mlr3]  Finished benchmark 
INFO  [06:13:47.466] [bbotk] Result of batch 71: 
INFO  [06:13:47.468] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:13:47.468] [bbotk]                  10               741      0.4277775        0.568 -0.8751582 
INFO  [06:13:47.468] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:13:47.468] [bbotk]          <NA>         0.5 3ddb4f4b-b370-4fad-9af6-3b25e0dabb08 
DEBUG [06:13:48.441] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.204256e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9774851 
  - variance bounds :  0.004076778 0.4204256 
  - best initial criterion value(s) :  315.7186 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -315.72  |proj g|=       2.6641
At iterate     1  f =      -321.51  |proj g|=        4.2407
At iterate     2  f =      -331.64  |proj g|=        3.4634
At iterate     3  f =      -340.85  |proj g|=        2.4595
At iterate     4  f =      -346.59  |proj g|=         2.027
At iterate     5  f =      -346.83  |proj g|=        1.8622
At iterate     6  f =      -346.88  |proj g|=        1.8654
At iterate     7  f =      -346.88  |proj g|=        1.8556
At iterate     8  f =      -346.89  |proj g|=        1.8446
At iterate     9  f =      -346.92  |proj g|=        1.2179
At iterate    10  f =      -346.99  |proj g|=       0.43494
At iterate    11  f =      -347.18  |proj g|=       0.89047
At iterate    12  f =      -347.66  |proj g|=        2.9357
At iterate    13  f =      -348.76  |proj g|=        6.1579
At iterate    14  f =      -350.75  |proj g|=        10.209
At iterate    15  f =      -352.68  |proj g|=        10.818
At iterate    16  f =      -353.84  |proj g|=        7.9721
At iterate    17  f =      -354.65  |proj g|=        4.1821
At iterate    18  f =      -354.96  |proj g|=       0.41635
At iterate    19  f =      -354.98  |proj g|=       0.41623
At iterate    20  f =      -354.98  |proj g|=        0.4162
At iterate    21  f =      -354.98  |proj g|=       0.10045
At iterate    22  f =      -354.98  |proj g|=      0.008284

iterations 22
function evaluations 27
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00828398
final function value -354.984

F = -354.984
final  value -354.984139 
converged
 
INFO  [06:13:48.446] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:13:48.505] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:13:48.513] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:14:35.413] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:15:21.777] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:16:08.252] [mlr3]  Finished benchmark 
INFO  [06:16:08.318] [bbotk] Result of batch 72: 
INFO  [06:16:08.319] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:16:08.319] [bbotk]                   5              3898      0.1476134        0.719 -0.8729408 
INFO  [06:16:08.319] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:16:08.319] [bbotk]          <NA>    0.978315 1c6f99fc-ef56-4827-bd2f-1c98ac35aeea 
DEBUG [06:16:09.072] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.183947e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9774851 
  - variance bounds :  0.004046865 0.4183947 
  - best initial criterion value(s) :  318.0592 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -318.06  |proj g|=       5.2363
At iterate     1  f =      -340.78  |proj g|=       0.41435
At iterate     2  f =      -342.32  |proj g|=     0.0063607
At iterate     3  f =      -342.34  |proj g|=     0.0063577
At iterate     4  f =      -342.34  |proj g|=       0.41322
At iterate     5  f =      -342.34  |proj g|=     0.0063557
At iterate     6  f =      -342.34  |proj g|=     0.0063557

iterations 6
function evaluations 9
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00635565
final function value -342.343

F = -342.343
final  value -342.343083 
converged
 
INFO  [06:16:09.076] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:16:09.141] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:16:09.147] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:16:09.895] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:16:10.653] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:16:11.413] [mlr3]  Finished benchmark 
INFO  [06:16:11.478] [bbotk] Result of batch 73: 
INFO  [06:16:11.480] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:16:11.480] [bbotk]                  10               687      0.3598469        0.551 -0.9056328 
INFO  [06:16:11.480] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:16:11.480] [bbotk]          <NA>         0.5 42ec7010-52b1-48ce-968b-bf20d6a1e07d 
DEBUG [06:16:12.276] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.25171e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9774851 
  - variance bounds :  0.004130483 0.425171 
  - best initial criterion value(s) :  296.9632 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -296.96  |proj g|=       7.2574
At iterate     1  f =       -310.3  |proj g|=        5.6973
At iterate     2  f =      -320.84  |proj g|=        6.1826
At iterate     3  f =      -323.85  |proj g|=        5.9129
At iterate     4  f =      -333.62  |proj g|=        5.3531
At iterate     5  f =      -344.41  |proj g|=        4.5156
At iterate     6  f =      -378.57  |proj g|=       0.46551
At iterate     7  f =      -378.57  |proj g|=       0.52654
At iterate     8  f =      -378.58  |proj g|=     0.0065871
At iterate     9  f =      -378.58  |proj g|=     0.0065868
At iterate    10  f =      -378.58  |proj g|=     0.0065868

iterations 10
function evaluations 20
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00658678
final function value -378.577

F = -378.577
final  value -378.576791 
converged
 
INFO  [06:16:12.280] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:16:12.333] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:16:12.340] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:16:46.161] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:17:20.164] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:17:54.405] [mlr3]  Finished benchmark 
INFO  [06:17:54.476] [bbotk] Result of batch 74: 
INFO  [06:17:54.478] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [06:17:54.478] [bbotk]                   6              2831      0.2371465        0.564 -0.870691 
INFO  [06:17:54.478] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:17:54.478] [bbotk]          <NA>   0.9769235 61d7acdd-caf6-449c-aede-8b6b42702a3b 
DEBUG [06:17:55.257] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.231466e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9774851 
  - variance bounds :  0.004107327 0.4231466 
  - best initial criterion value(s) :  296.3087 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -296.31  |proj g|=       5.4806
At iterate     1  f =      -317.73  |proj g|=        2.7826
At iterate     2  f =      -346.08  |proj g|=        1.9361
At iterate     3  f =      -346.45  |proj g|=        1.5091
At iterate     4  f =      -346.64  |proj g|=        1.6354
At iterate     5  f =      -346.71  |proj g|=        0.3561
At iterate     6  f =      -347.29  |proj g|=       0.27969
At iterate     7  f =       -347.3  |proj g|=      0.013436
At iterate     8  f =       -347.3  |proj g|=      0.013436

iterations 8
function evaluations 16
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0134361
final function value -347.296

F = -347.296
final  value -347.295727 
converged
 
INFO  [06:17:55.261] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:17:55.316] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:17:55.322] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:18:52.799] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:19:50.076] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:20:48.028] [mlr3]  Finished benchmark 
INFO  [06:20:48.095] [bbotk] Result of batch 75: 
INFO  [06:20:48.096] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:20:48.096] [bbotk]                   7              4842      0.4506704        0.557 -0.8745096 
INFO  [06:20:48.096] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:20:48.096] [bbotk]          <NA>   0.9748809 49e90c4d-30a4-4233-8c6f-cc3934ecd511 
DEBUG [06:20:48.914] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.210528e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9774851 
  - variance bounds :  0.004070912 0.4210528 
  - best initial criterion value(s) :  299.0844 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -299.08  |proj g|=      0.41635
At iterate     1  f =      -319.57  |proj g|=        4.8245
At iterate     2  f =      -320.34  |proj g|=        4.8466
At iterate     3  f =      -322.47  |proj g|=        4.7465
At iterate     4  f =      -322.96  |proj g|=        4.7449
At iterate     5  f =      -323.14  |proj g|=        4.7435
At iterate     6  f =      -323.21  |proj g|=        4.7401
At iterate     7  f =      -323.34  |proj g|=        4.7288
At iterate     8  f =      -323.64  |proj g|=        4.6957
At iterate     9  f =      -324.32  |proj g|=        4.6089
At iterate    10  f =      -325.69  |proj g|=        4.4161
At iterate    11  f =      -328.68  |proj g|=        3.9356
At iterate    12  f =      -336.35  |proj g|=        2.6679
At iterate    13  f =      -359.37  |proj g|=        9.6461
At iterate    14  f =      -360.53  |proj g|=        1.9397
At iterate    15  f =       -360.6  |proj g|=        1.9509
At iterate    16  f =      -360.98  |proj g|=       0.15988
At iterate    17  f =      -360.98  |proj g|=      0.011337
At iterate    18  f =      -360.98  |proj g|=      0.011337

iterations 18
function evaluations 24
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.011337
final function value -360.983

F = -360.983
final  value -360.982573 
converged
 
INFO  [06:20:48.918] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:20:48.973] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:20:48.980] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:20:57.690] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:21:06.106] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:21:14.516] [mlr3]  Finished benchmark 
INFO  [06:21:14.581] [bbotk] Result of batch 76: 
INFO  [06:21:14.583] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:21:14.583] [bbotk]                   6               622      0.4045572        0.571 -0.8731642 
INFO  [06:21:14.583] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:21:14.583] [bbotk]          <NA>     0.97757 a88043d8-357b-41dc-8eb6-ff10e4810082 
DEBUG [06:21:15.400] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.190373e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9774851 
  - variance bounds :  0.004060555 0.4190373 
  - best initial criterion value(s) :  313.1255 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -313.13  |proj g|=       6.4332
At iterate     1  f =      -315.94  |proj g|=        6.1589
At iterate     2  f =      -322.18  |proj g|=        5.9222
At iterate     3  f =      -325.56  |proj g|=        5.6298
At iterate     4  f =       -336.8  |proj g|=        4.5145
At iterate     5  f =      -348.02  |proj g|=        4.4098
At iterate     6  f =      -378.98  |proj g|=        2.0304
At iterate     7  f =      -379.32  |proj g|=        2.0042
At iterate     8  f =      -379.71  |proj g|=       0.41498
At iterate     9  f =      -379.71  |proj g|=     0.0087271
At iterate    10  f =      -379.71  |proj g|=        0.1314
At iterate    11  f =      -379.71  |proj g|=      0.044688

iterations 11
function evaluations 21
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0446875
final function value -379.711

F = -379.711
final  value -379.710994 
converged
 
INFO  [06:21:15.404] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:21:15.459] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:21:15.466] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:21:43.032] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:22:09.871] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:22:37.057] [mlr3]  Finished benchmark 
INFO  [06:22:37.123] [bbotk] Result of batch 77: 
INFO  [06:22:37.125] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:22:37.125] [bbotk]                   7              2222      0.3334932        0.566 -0.8705788 
INFO  [06:22:37.125] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:22:37.125] [bbotk]          <NA>   0.9764845 8d7597ca-2a28-4c24-81ea-80c43adcede9 
DEBUG [06:22:38.052] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.169852e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9774851 
  - variance bounds :  0.004042315 0.4169852 
  - best initial criterion value(s) :  308.9917 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -308.99  |proj g|=       2.0524
At iterate     1  f =      -346.72  |proj g|=        2.5748
ys=-1.386e+01  -gs= 2.415e+01, BFGS update SKIPPED
At iterate     2  f =      -349.09  |proj g|=        2.2752
At iterate     3  f =      -351.16  |proj g|=        2.0784
At iterate     4  f =      -352.59  |proj g|=        3.0792
At iterate     5  f =      -352.75  |proj g|=       0.41294
At iterate     6  f =      -352.75  |proj g|=      0.015505
At iterate     7  f =      -352.75  |proj g|=       0.41293
At iterate     8  f =      -352.75  |proj g|=       0.41293
At iterate     9  f =      -352.75  |proj g|=      0.015507
At iterate    10  f =      -352.75  |proj g|=      0.015507

iterations 10
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 1
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0155069
final function value -352.752

F = -352.752
final  value -352.752221 
converged
 
INFO  [06:22:38.057] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:22:38.121] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:22:38.127] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:23:12.136] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:23:46.515] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:24:20.792] [mlr3]  Finished benchmark 
INFO  [06:24:20.857] [bbotk] Result of batch 78: 
INFO  [06:24:20.859] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:24:20.859] [bbotk]                   5              2825     0.02747916        0.674 -0.8738616 
INFO  [06:24:20.859] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:24:20.859] [bbotk]          <NA>    0.977327 24128a22-e9df-4ebd-b3db-35e582d31c3b 
DEBUG [06:24:21.704] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.149558e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9368 0.9774851 
  - variance bounds :  0.004017411 0.4149558 
  - best initial criterion value(s) :  310.594 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -310.59  |proj g|=        5.824
At iterate     1  f =      -315.97  |proj g|=        3.9421
At iterate     2  f =      -321.71  |proj g|=        5.4667
At iterate     3  f =      -324.94  |proj g|=        5.3744
At iterate     4  f =       -332.6  |proj g|=        4.9884
At iterate     5  f =       -351.9  |proj g|=        4.0629
At iterate     6  f =      -391.66  |proj g|=        2.2384
At iterate     7  f =      -391.69  |proj g|=        2.2359
At iterate     8  f =      -392.14  |proj g|=        2.1691
At iterate     9  f =      -393.16  |proj g|=        1.7346
At iterate    10  f =      -393.22  |proj g|=       0.19817
At iterate    11  f =      -393.22  |proj g|=       0.41089
At iterate    12  f =      -393.22  |proj g|=     0.0083156
At iterate    13  f =      -393.22  |proj g|=     0.0083155
At iterate    14  f =      -393.22  |proj g|=     0.0083155

iterations 14
function evaluations 25
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00831547
final function value -393.217

F = -393.217
final  value -393.216668 
converged
 
INFO  [06:24:21.708] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:24:21.765] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:24:21.778] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:24:25.773] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:24:29.916] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:24:33.965] [mlr3]  Finished benchmark 
INFO  [06:24:34.029] [bbotk] Result of batch 79: 
INFO  [06:24:34.031] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:24:34.031] [bbotk]                   5               253      0.1334429        0.589 -0.8696627 
INFO  [06:24:34.031] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:24:34.031] [bbotk]          <NA>    0.975047 dbac6a66-3d84-4bbe-a725-2a304dc61d2a 
DEBUG [06:24:34.905] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.128605e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003997037 0.4128605 
  - best initial criterion value(s) :  328.1515 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -328.15  |proj g|=       3.6092
At iterate     1  f =      -397.36  |proj g|=        2.1608
At iterate     2  f =      -397.94  |proj g|=        2.1632
At iterate     3  f =      -397.95  |proj g|=        2.1622
At iterate     4  f =      -397.96  |proj g|=        2.1591
At iterate     5  f =      -397.99  |proj g|=        2.1523
At iterate     6  f =      -398.07  |proj g|=        2.1291
At iterate     7  f =      -398.23  |proj g|=        2.0782
At iterate     8  f =       -398.5  |proj g|=        2.0114
At iterate     9  f =      -398.68  |proj g|=        2.3454
At iterate    10  f =      -398.95  |proj g|=       0.15067
At iterate    11  f =      -398.96  |proj g|=       0.40884
At iterate    12  f =      -398.96  |proj g|=      0.008276
At iterate    13  f =      -398.96  |proj g|=     0.0082759

iterations 13
function evaluations 19
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00827593
final function value -398.959

F = -398.959
final  value -398.958748 
converged
 
INFO  [06:24:34.909] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:24:34.963] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:24:34.969] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:24:35.751] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:24:36.522] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:24:37.308] [mlr3]  Finished benchmark 
INFO  [06:24:37.373] [bbotk] Result of batch 80: 
INFO  [06:24:37.375] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:24:37.375] [bbotk]                  10              2228     0.03714018         0.63 -0.8687998 
INFO  [06:24:37.375] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:24:37.375] [bbotk]          <NA>         0.5 50b13160-5179-4871-82e4-49ce553d95e3 
DEBUG [06:24:38.191] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.195887e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.004058338 0.4195887 
  - best initial criterion value(s) :  316.9399 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -316.94  |proj g|=       4.4454
At iterate     1  f =      -354.54  |proj g|=       0.41553
At iterate     2  f =      -355.36  |proj g|=      0.010938
At iterate     3  f =      -355.37  |proj g|=      0.010941
At iterate     4  f =      -355.37  |proj g|=       0.41476
At iterate     5  f =      -355.37  |proj g|=      0.010942
At iterate     6  f =      -355.37  |proj g|=      0.010942

iterations 6
function evaluations 9
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0109418
final function value -355.369

F = -355.369
final  value -355.368995 
converged
 
INFO  [06:24:38.196] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:24:38.250] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:24:38.257] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:25:36.273] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:26:33.395] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:27:30.426] [mlr3]  Finished benchmark 
INFO  [06:27:30.495] [bbotk] Result of batch 81: 
INFO  [06:27:30.497] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:27:30.497] [bbotk]                   6              4802       0.143475        0.601 -0.9033223 
INFO  [06:27:30.497] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:27:30.497] [bbotk]          <NA>   0.9769291 4e2bbf07-8644-4c83-9c3c-8fdf33b9292e 
DEBUG [06:27:31.352] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.175931e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.004039595 0.4175931 
  - best initial criterion value(s) :  322.4868 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -322.49  |proj g|=       5.8909
At iterate     1  f =      -325.31  |proj g|=        5.6111
At iterate     2  f =      -331.71  |proj g|=        5.5452
At iterate     3  f =      -335.09  |proj g|=        5.4117
At iterate     4  f =      -344.26  |proj g|=         4.975
At iterate     5  f =      -369.84  |proj g|=        3.8599
At iterate     6  f =      -401.59  |proj g|=       0.22742
At iterate     7  f =      -404.82  |proj g|=        2.3685
At iterate     8  f =      -404.85  |proj g|=        2.3665
At iterate     9  f =      -405.03  |proj g|=        2.3666
At iterate    10  f =      -405.04  |proj g|=        2.3659
At iterate    11  f =      -405.08  |proj g|=        2.3607
At iterate    12  f =       -405.2  |proj g|=        2.3409
At iterate    13  f =      -405.59  |proj g|=        2.2659
At iterate    14  f =      -406.21  |proj g|=        2.1613
At iterate    15  f =      -407.19  |proj g|=        2.0281
At iterate    16  f =       -407.6  |proj g|=        1.6379
At iterate    17  f =      -407.62  |proj g|=        1.1037
At iterate    18  f =      -407.63  |proj g|=       0.86893
At iterate    19  f =      -407.64  |proj g|=     0.0089649
At iterate    20  f =      -407.64  |proj g|=     0.0089649

iterations 20
function evaluations 30
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00896488
final function value -407.64

F = -407.64
final  value -407.640077 
converged
 
INFO  [06:27:31.356] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:27:31.419] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:27:31.425] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:27:55.459] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:28:19.945] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:28:43.808] [mlr3]  Finished benchmark 
INFO  [06:28:43.873] [bbotk] Result of batch 82: 
INFO  [06:28:43.875] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:28:43.875] [bbotk]                   7              1985      0.3220313        0.583 -0.8686355 
INFO  [06:28:43.875] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:28:43.875] [bbotk]          <NA>   0.9766366 922abafd-295c-44ba-ba3a-74168055576f 
DEBUG [06:28:44.748] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.155886e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.004023276 0.4155886 
  - best initial criterion value(s) :  328.4394 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -328.44  |proj g|=       5.9418
At iterate     1  f =      -335.97  |proj g|=        5.7965
At iterate     2  f =      -364.76  |proj g|=        3.6887
At iterate     3  f =      -383.49  |proj g|=        2.3046
At iterate     4  f =      -384.78  |proj g|=        2.2311
At iterate     5  f =      -386.53  |proj g|=        1.9322
At iterate     6  f =      -386.61  |proj g|=       0.61831
At iterate     7  f =      -386.62  |proj g|=        1.2247
At iterate     8  f =      -386.64  |proj g|=         1.638
At iterate     9  f =      -386.69  |proj g|=        1.9009
At iterate    10  f =      -386.81  |proj g|=        1.9427
At iterate    11  f =      -390.75  |proj g|=        1.9345
At iterate    12  f =      -390.77  |proj g|=        2.0208
At iterate    13  f =       -396.3  |proj g|=        1.9952
At iterate    14  f =      -396.59  |proj g|=         1.898
At iterate    15  f =      -396.62  |proj g|=        1.6359
At iterate    16  f =      -396.67  |proj g|=      0.012203
At iterate    17  f =      -396.67  |proj g|=      0.012203
At iterate    18  f =      -396.67  |proj g|=      0.012203

iterations 18
function evaluations 28
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.012203
final function value -396.667

F = -396.667
final  value -396.666812 
converged
 
INFO  [06:28:44.754] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:28:44.808] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:28:44.815] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:29:36.338] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:30:27.487] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:31:18.779] [mlr3]  Finished benchmark 
INFO  [06:31:18.846] [bbotk] Result of batch 83: 
INFO  [06:31:18.870] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:31:18.870] [bbotk]                   6              4350      0.1872579        0.605 -0.8703625 
INFO  [06:31:18.870] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:31:18.870] [bbotk]          <NA>   0.9768121 a3263c99-9c15-4182-8dbc-a76100bbd8a3 
DEBUG [06:31:19.863] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.135894e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.004004073 0.4135894 
  - best initial criterion value(s) :  344.0489 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -344.05  |proj g|=        6.971
At iterate     1  f =      -345.42  |proj g|=        6.7664
At iterate     2  f =      -348.86  |proj g|=         6.554
ys=-1.263e-01  -gs= 3.378e+00, BFGS update SKIPPED
At iterate     3  f =      -364.72  |proj g|=        5.4421
At iterate     4  f =      -368.53  |proj g|=        5.0777
At iterate     5  f =      -383.45  |proj g|=        4.0449
At iterate     6  f =      -412.72  |proj g|=        2.0822
At iterate     7  f =      -412.92  |proj g|=        2.0633
At iterate     8  f =      -413.51  |proj g|=        1.7128
At iterate     9  f =      -413.52  |proj g|=        1.4923
At iterate    10  f =      -413.56  |proj g|=      0.010127
At iterate    11  f =      -413.56  |proj g|=      0.010127

iterations 11
function evaluations 22
segments explored during Cauchy searches 14
BFGS updates skipped 1
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0101265
final function value -413.561

F = -413.561
final  value -413.560957 
converged
 
INFO  [06:31:19.867] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:31:19.921] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:31:19.928] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:31:29.702] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:31:39.555] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:31:49.681] [mlr3]  Finished benchmark 
INFO  [06:31:49.749] [bbotk] Result of batch 84: 
INFO  [06:31:49.750] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [06:31:49.750] [bbotk]                   3               755      0.4054353        0.572 -0.868494 
INFO  [06:31:49.750] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:31:49.750] [bbotk]          <NA>   0.9769129 c8f7bf6c-5466-4667-83f5-25f15886ad91 
DEBUG [06:31:50.693] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.115944e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003984046 0.4115944 
  - best initial criterion value(s) :  348.0219 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -348.02  |proj g|=       2.5639
At iterate     1  f =      -367.96  |proj g|=        4.6441
At iterate     2  f =         -369  |proj g|=        4.6638
At iterate     3  f =      -369.24  |proj g|=        4.6058
At iterate     4  f =      -369.89  |proj g|=        4.3399
At iterate     5  f =      -370.96  |proj g|=        3.9272
At iterate     6  f =       -373.1  |proj g|=        3.0323
At iterate     7  f =      -374.04  |proj g|=        3.1821
At iterate     8  f =      -380.72  |proj g|=        3.5613
At iterate     9  f =      -403.16  |proj g|=        3.3815
At iterate    10  f =      -419.66  |proj g|=        2.4827
At iterate    11  f =      -422.51  |proj g|=        2.4428
At iterate    12  f =      -426.82  |proj g|=        1.8971
At iterate    13  f =      -426.88  |proj g|=       0.04235
At iterate    14  f =      -426.88  |proj g|=     0.0089286
At iterate    15  f =      -426.88  |proj g|=     0.0089286

iterations 15
function evaluations 19
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00892863
final function value -426.883

F = -426.883
final  value -426.883494 
converged
 
INFO  [06:31:50.697] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:31:50.762] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:31:50.769] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:32:22.455] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:32:54.079] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:33:25.637] [mlr3]  Finished benchmark 
INFO  [06:33:25.703] [bbotk] Result of batch 85: 
INFO  [06:33:25.704] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:33:25.704] [bbotk]                   7              2649       0.068279         0.69 -0.8675543 
INFO  [06:33:25.704] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:33:25.704] [bbotk]          <NA>    0.976944 278e2a3f-51c6-47fb-bc17-f964d80ffd6b 
DEBUG [06:33:26.544] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.096025e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003963515 0.4096025 
  - best initial criterion value(s) :  362.8694 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -362.87  |proj g|=       7.4055
At iterate     1  f =      -366.17  |proj g|=        7.0574
At iterate     2  f =      -373.16  |proj g|=         6.634
ys=-5.163e-01  -gs= 6.741e+00, BFGS update SKIPPED
At iterate     3  f =      -388.91  |proj g|=        5.5239
At iterate     4  f =      -394.08  |proj g|=        5.0589
At iterate     5  f =      -419.46  |proj g|=        3.3575
At iterate     6  f =      -435.02  |proj g|=        2.5505
At iterate     7  f =      -437.85  |proj g|=        2.1974
At iterate     8  f =      -439.52  |proj g|=       0.31794
At iterate     9  f =      -439.52  |proj g|=      0.008575
At iterate    10  f =      -439.52  |proj g|=     0.0080261
At iterate    11  f =      -439.52  |proj g|=     0.0080261

iterations 11
function evaluations 23
segments explored during Cauchy searches 14
BFGS updates skipped 1
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00802614
final function value -439.518

F = -439.518
final  value -439.517537 
converged
 
INFO  [06:33:26.548] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:33:26.603] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:33:26.610] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:33:45.455] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:34:04.444] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:34:05.175] [mlr3]  Finished benchmark 
INFO  [06:34:05.237] [bbotk] Result of batch 86: 
INFO  [06:34:05.239] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:34:05.239] [bbotk]                   8              1528      0.1703373        0.587 -0.8667053 
INFO  [06:34:05.239] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:34:05.239] [bbotk]          <NA>   0.8161432 053b72e7-ce98-4339-816b-a1408078908c 
DEBUG [06:34:06.101] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.058487e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003931215 0.4058487 
  - best initial criterion value(s) :  336.2451 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -336.25  |proj g|=       11.259
At iterate     1  f =      -350.26  |proj g|=        6.2874
At iterate     2  f =      -376.97  |proj g|=        3.7695
At iterate     3  f =       -403.8  |proj g|=        2.5055
At iterate     4  f =      -404.06  |proj g|=        2.4712
At iterate     5  f =      -407.46  |proj g|=        2.0246
At iterate     6  f =      -407.64  |proj g|=        1.9753
At iterate     7  f =      -407.81  |proj g|=        1.8864
At iterate     8  f =      -407.85  |proj g|=        1.6364
At iterate     9  f =      -408.33  |proj g|=        1.4402
At iterate    10  f =      -409.19  |proj g|=        4.7378
At iterate    11  f =      -411.54  |proj g|=        10.099
At iterate    12  f =      -416.37  |proj g|=        12.674
At iterate    13  f =      -425.56  |proj g|=        12.669
At iterate    14  f =       -428.7  |proj g|=        7.5749
At iterate    15  f =      -429.64  |proj g|=       0.17515
At iterate    16  f =      -429.64  |proj g|=      0.010667
At iterate    17  f =      -429.64  |proj g|=      0.010668

iterations 17
function evaluations 22
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0106675
final function value -429.642

F = -429.642
final  value -429.641643 
converged
 
INFO  [06:34:06.105] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:34:06.160] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:34:06.167] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:34:56.757] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:35:47.621] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:36:38.304] [mlr3]  Finished benchmark 
INFO  [06:36:38.369] [bbotk] Result of batch 87: 
INFO  [06:36:38.371] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [06:36:38.371] [bbotk]                   6              4258     0.03271241        0.602 -0.868262 
INFO  [06:36:38.371] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:36:38.371] [bbotk]          <NA>   0.9779746 cdae5bd5-55b4-4186-90df-563a58e5c92f 
DEBUG [06:36:39.282] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.03944e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003914784 0.403944 
  - best initial criterion value(s) :  362.5433 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -362.54  |proj g|=       11.934
At iterate     1  f =      -383.45  |proj g|=         1.496
At iterate     2  f =      -402.65  |proj g|=        3.4923
At iterate     3  f =      -408.19  |proj g|=        3.1617
At iterate     4  f =      -420.16  |proj g|=         2.288
At iterate     5  f =      -422.21  |proj g|=         1.528
At iterate     6  f =      -423.12  |proj g|=        1.9615
At iterate     7  f =      -423.27  |proj g|=        1.8894
At iterate     8  f =      -423.35  |proj g|=       0.21429
At iterate     9  f =      -423.38  |proj g|=       0.82085
At iterate    10  f =      -423.49  |proj g|=        1.8992
At iterate    11  f =      -423.87  |proj g|=        1.9761
At iterate    12  f =      -429.87  |proj g|=        1.9751
At iterate    13  f =      -430.03  |proj g|=        1.9314
At iterate    14  f =      -430.07  |proj g|=        1.9169
At iterate    15  f =      -430.15  |proj g|=      0.017686
At iterate    16  f =      -430.15  |proj g|=      0.011862
At iterate    17  f =      -430.15  |proj g|=      0.011862

iterations 17
function evaluations 31
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.011862
final function value -430.154

F = -430.154
final  value -430.154231 
converged
 
INFO  [06:36:39.286] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:36:39.339] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:36:39.345] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:36:52.019] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:37:04.761] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:37:17.585] [mlr3]  Finished benchmark 
INFO  [06:37:17.653] [bbotk] Result of batch 88: 
INFO  [06:37:17.655] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:37:17.655] [bbotk]                   3               995       0.325604        0.606 -0.8687486 
INFO  [06:37:17.655] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:37:17.655] [bbotk]          <NA>    0.976938 1c390b50-42cd-4c85-9368-3273248edfc7 
DEBUG [06:37:18.558] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.020154e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003898928 0.4020154 
  - best initial criterion value(s) :  349.099 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -349.1  |proj g|=       1.4158
At iterate     1  f =      -392.91  |proj g|=        4.2272
At iterate     2  f =      -399.14  |proj g|=        3.9935
At iterate     3  f =      -399.24  |proj g|=        3.9878
At iterate     4  f =      -399.37  |proj g|=        3.9831
At iterate     5  f =      -399.94  |proj g|=         3.942
At iterate     6  f =      -400.78  |proj g|=        3.8739
At iterate     7  f =      -403.66  |proj g|=        3.4159
At iterate     8  f =      -411.14  |proj g|=        3.2393
At iterate     9  f =      -427.84  |proj g|=        1.9287
At iterate    10  f =      -427.99  |proj g|=       0.26541
At iterate    11  f =         -428  |proj g|=      0.013591
At iterate    12  f =         -428  |proj g|=      0.013591

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0135912
final function value -427.996

F = -427.996
final  value -427.995639 
converged
 
INFO  [06:37:18.562] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:37:18.630] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:37:18.636] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:37:23.633] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:37:28.708] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:37:33.372] [mlr3]  Finished benchmark 
INFO  [06:37:33.444] [bbotk] Result of batch 89: 
INFO  [06:37:33.446] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:37:33.446] [bbotk]                   3               306       0.192539        0.663 -0.8694053 
INFO  [06:37:33.446] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:37:33.446] [bbotk]          <NA>   0.9729194 a58a3e46-9954-4d19-b748-85666528a9ed 
DEBUG [06:37:34.320] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.999932e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003889676 0.3999932 
  - best initial criterion value(s) :  412.6148 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -412.61  |proj g|=       1.4625
At iterate     1  f =      -424.52  |proj g|=        3.9999
At iterate     2  f =      -426.02  |proj g|=         3.979
At iterate     3  f =      -426.99  |proj g|=        3.7689
At iterate     4  f =      -428.69  |proj g|=        3.2387
At iterate     5  f =      -431.01  |proj g|=        2.5417
At iterate     6  f =      -431.13  |proj g|=        2.7411
At iterate     7  f =      -432.04  |proj g|=        2.6704
At iterate     8  f =      -436.85  |proj g|=        2.3399
At iterate     9  f =      -443.03  |proj g|=         2.198
At iterate    10  f =      -451.92  |proj g|=        2.0802
At iterate    11  f =      -461.84  |proj g|=        2.0319
At iterate    12  f =      -463.09  |proj g|=        2.0656
At iterate    13  f =       -463.4  |proj g|=        1.9903
At iterate    14  f =      -463.46  |proj g|=        1.9734
At iterate    15  f =       -463.5  |proj g|=         1.958
At iterate    16  f =      -463.55  |proj g|=        1.9388
At iterate    17  f =      -463.61  |proj g|=      0.013451
At iterate    18  f =      -463.61  |proj g|=     0.0082498
At iterate    19  f =      -463.61  |proj g|=     0.0082498

iterations 19
function evaluations 24
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00824978
final function value -463.611

F = -463.611
final  value -463.611036 
converged
 
INFO  [06:37:34.324] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:37:34.378] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:37:34.384] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:38:12.788] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:38:51.832] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:39:31.686] [mlr3]  Finished benchmark 
INFO  [06:39:31.753] [bbotk] Result of batch 90: 
INFO  [06:39:31.755] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [06:39:31.755] [bbotk]                   4              3250      0.4057874        0.609 -0.865377 
INFO  [06:39:31.755] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:39:31.755] [bbotk]          <NA>   0.9781576 eb305d52-52ba-4baf-a63f-c410b40a9ebf 
DEBUG [06:39:32.603] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.981045e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.00386551 0.3981045 
  - best initial criterion value(s) :  360.0789 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -360.08  |proj g|=       5.8879
At iterate     1  f =      -375.98  |proj g|=        3.8714
At iterate     2  f =      -424.41  |proj g|=        1.9275
At iterate     3  f =      -424.62  |proj g|=       0.14904
At iterate     4  f =      -424.66  |proj g|=       0.12445
At iterate     5  f =      -424.66  |proj g|=      0.024404
At iterate     6  f =      -424.66  |proj g|=      0.016618
At iterate     7  f =      -424.66  |proj g|=      0.016618

iterations 7
function evaluations 14
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0166183
final function value -424.661

F = -424.661
final  value -424.661281 
converged
 
INFO  [06:39:32.607] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:39:32.668] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:39:32.675] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:40:26.511] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:41:21.001] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:42:14.711] [mlr3]  Finished benchmark 
INFO  [06:42:14.776] [bbotk] Result of batch 91: 
INFO  [06:42:14.778] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:42:14.778] [bbotk]                   4              4418       0.360163        0.606 -0.8699136 
INFO  [06:42:14.778] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:42:14.778] [bbotk]          <NA>   0.9781009 52dd1f20-9ec5-48ac-84c5-2ad1bda77511 
DEBUG [06:42:15.677] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.962186e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003843787 0.3962186 
  - best initial criterion value(s) :  382.4463 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -382.45  |proj g|=       6.2863
At iterate     1  f =      -396.82  |proj g|=         5.496
At iterate     2  f =      -405.12  |proj g|=        4.3972
At iterate     3  f =      -424.49  |proj g|=        2.4842
At iterate     4  f =      -425.25  |proj g|=         2.006
At iterate     5  f =      -425.57  |proj g|=        2.1322
At iterate     6  f =       -425.7  |proj g|=         2.211
At iterate     7  f =      -426.23  |proj g|=        2.2504
At iterate     8  f =      -431.29  |proj g|=        2.4547
At iterate     9  f =      -439.28  |proj g|=        2.6406
At iterate    10  f =      -457.42  |proj g|=        2.7924
At iterate    11  f =      -469.51  |proj g|=        2.1452
At iterate    12  f =      -474.91  |proj g|=        2.0673
At iterate    13  f =      -475.19  |proj g|=        1.9978
At iterate    14  f =      -475.34  |proj g|=        1.6193
At iterate    15  f =      -475.38  |proj g|=      0.014231
At iterate    16  f =      -475.38  |proj g|=     0.0081311
At iterate    17  f =      -475.38  |proj g|=     0.0081311

iterations 17
function evaluations 25
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0081311
final function value -475.381

F = -475.381
final  value -475.380973 
converged
 
INFO  [06:42:15.681] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:42:15.742] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:42:15.749] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:42:32.710] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:42:49.835] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:42:50.613] [mlr3]  Finished benchmark 
INFO  [06:42:50.700] [bbotk] Result of batch 92: 
INFO  [06:42:50.702] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:42:50.702] [bbotk]                   8              1360      0.3118565        0.614 -0.8646682 
INFO  [06:42:50.702] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:42:50.702] [bbotk]          <NA>   0.8159203 d723132b-749d-4693-94b8-6d8bceeb5681 
DEBUG [06:42:51.608] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.928053e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003809806 0.3928053 
  - best initial criterion value(s) :  378.9875 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -378.99  |proj g|=       4.3333
At iterate     1  f =      -451.72  |proj g|=        12.664
ys=-1.761e-01  -gs= 5.589e+01, BFGS update SKIPPED
At iterate     2  f =      -455.84  |proj g|=        3.2402
At iterate     3  f =         -456  |proj g|=      0.094752
At iterate     4  f =         -456  |proj g|=      0.012411
At iterate     5  f =         -456  |proj g|=      0.012411

iterations 5
function evaluations 7
segments explored during Cauchy searches 8
BFGS updates skipped 1
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0124114
final function value -456.005

F = -456.005
final  value -456.004639 
converged
 
INFO  [06:42:51.610] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:42:51.653] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:42:51.660] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:43:20.485] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:43:49.020] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:44:17.780] [mlr3]  Finished benchmark 
INFO  [06:44:17.844] [bbotk] Result of batch 93: 
INFO  [06:44:17.846] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:44:17.846] [bbotk]                   6              2384      0.2507346        0.681 -0.8674085 
INFO  [06:44:17.846] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:44:17.846] [bbotk]          <NA>   0.9769996 4ef56309-2c0a-47b9-9a9e-e3f3da55b905 
DEBUG [06:44:18.925] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.909502e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003788392 0.3909501 
  - best initial criterion value(s) :  388.9201 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -388.92  |proj g|=        5.429
At iterate     1  f =      -389.33  |proj g|=        5.3571
At iterate     2  f =      -390.12  |proj g|=        5.3424
At iterate     3  f =      -392.26  |proj g|=        5.2574
At iterate     4  f =      -395.35  |proj g|=         5.045
At iterate     5  f =      -401.06  |proj g|=        4.5671
At iterate     6  f =      -417.24  |proj g|=        3.9514
At iterate     7  f =      -419.32  |proj g|=        3.9121
At iterate     8  f =      -419.86  |proj g|=        3.8784
At iterate     9  f =      -422.01  |proj g|=        3.6944
At iterate    10  f =      -425.01  |proj g|=        3.3755
At iterate    11  f =      -431.47  |proj g|=         1.401
At iterate    12  f =      -444.66  |proj g|=        12.569
At iterate    13  f =      -447.36  |proj g|=      0.082486
At iterate    14  f =      -447.36  |proj g|=      0.015426
At iterate    15  f =      -447.36  |proj g|=      0.015426

iterations 15
function evaluations 21
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0154262
final function value -447.363

F = -447.363
final  value -447.363295 
converged
 
INFO  [06:44:18.929] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:44:18.985] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:44:18.992] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:44:38.207] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:44:57.408] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:45:16.608] [mlr3]  Finished benchmark 
INFO  [06:45:16.674] [bbotk] Result of batch 94: 
INFO  [06:45:16.675] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:45:16.675] [bbotk]                   3              1559      0.2537824        0.814 -0.8687326 
INFO  [06:45:16.675] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:45:16.675] [bbotk]          <NA>   0.9771346 bb958a74-4eb1-433d-9c96-3c88abf2b73e 
DEBUG [06:45:17.567] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.891037e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003782593 0.3891037 
  - best initial criterion value(s) :  415.0583 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -415.06  |proj g|=        9.534
At iterate     1  f =      -423.99  |proj g|=        2.7824
At iterate     2  f =       -446.8  |proj g|=        3.3473
At iterate     3  f =      -451.62  |proj g|=        2.7507
At iterate     4  f =      -456.12  |proj g|=        12.851
At iterate     5  f =       -464.7  |proj g|=       0.98226
At iterate     6  f =      -464.75  |proj g|=       0.58949
At iterate     7  f =      -464.77  |proj g|=         1.011
At iterate     8  f =      -464.82  |proj g|=        1.9262
At iterate     9  f =      -464.95  |proj g|=        1.9674
At iterate    10  f =      -465.29  |proj g|=        2.0357
At iterate    11  f =      -469.83  |proj g|=        2.0146
At iterate    12  f =      -469.95  |proj g|=        2.0814
At iterate    13  f =      -470.78  |proj g|=         2.078
At iterate    14  f =      -471.19  |proj g|=        1.9924
At iterate    15  f =      -471.24  |proj g|=        1.9799
At iterate    16  f =      -471.43  |proj g|=       0.03771
At iterate    17  f =      -471.43  |proj g|=      0.011969
At iterate    18  f =      -471.43  |proj g|=      0.011969

iterations 18
function evaluations 28
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0119689
final function value -471.434

F = -471.434
final  value -471.433974 
converged
 
INFO  [06:45:17.570] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:45:17.613] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:45:17.620] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:45:18.390] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:45:19.134] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:45:20.047] [mlr3]  Finished benchmark 
INFO  [06:45:20.111] [bbotk] Result of batch 95: 
INFO  [06:45:20.113] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [06:45:20.113] [bbotk]                   9              1411       0.398522        0.605 -0.866391 
INFO  [06:45:20.113] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:45:20.113] [bbotk]          <NA>         0.5 cb1e95d4-bd68-4e17-b070-6658bece23c2 
DEBUG [06:45:21.067] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.958505e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003848269 0.3958505 
  - best initial criterion value(s) :  366.7189 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -366.72  |proj g|=       12.338
At iterate     1  f =      -423.97  |proj g|=        5.6947
At iterate     2  f =      -444.35  |proj g|=        4.5332
At iterate     3  f =      -464.77  |proj g|=         3.008
At iterate     4  f =       -483.6  |proj g|=        2.2444
At iterate     5  f =      -484.36  |proj g|=        2.1534
At iterate     6  f =      -484.93  |proj g|=        2.0571
At iterate     7  f =      -485.23  |proj g|=       0.68403
At iterate     8  f =      -485.24  |proj g|=       0.38316
At iterate     9  f =      -485.29  |proj g|=       0.56233
At iterate    10  f =       -485.4  |proj g|=        1.8034
At iterate    11  f =       -485.7  |proj g|=        3.9358
At iterate    12  f =      -486.44  |proj g|=        7.0995
At iterate    13  f =      -488.23  |proj g|=        11.562
At iterate    14  f =      -492.05  |proj g|=        12.601
At iterate    15  f =      -496.27  |proj g|=        10.525
At iterate    16  f =      -498.03  |proj g|=       0.16245
At iterate    17  f =      -498.03  |proj g|=      0.008495
At iterate    18  f =      -498.03  |proj g|=      0.008495

iterations 18
function evaluations 23
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00849499
final function value -498.027

F = -498.027
final  value -498.027329 
converged
 
INFO  [06:45:21.071] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:45:21.127] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:45:21.134] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:46:14.383] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:47:07.584] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:48:01.034] [mlr3]  Finished benchmark 
INFO  [06:48:01.101] [bbotk] Result of batch 96: 
INFO  [06:48:01.102] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [06:48:01.102] [bbotk]                   6              4491      0.2825076        0.678 -0.864015 
INFO  [06:48:01.102] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:48:01.102] [bbotk]          <NA>   0.9764197 6951cc1b-51ee-4030-9117-e45c60be31b3 
DEBUG [06:48:01.993] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.94018e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003825285 0.394018 
  - best initial criterion value(s) :  421.3399 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -421.34  |proj g|=       6.1475
At iterate     1  f =      -423.03  |proj g|=        5.9661
At iterate     2  f =      -424.36  |proj g|=        5.9474
At iterate     3  f =      -428.51  |proj g|=        5.7871
At iterate     4  f =      -430.94  |proj g|=        5.6243
At iterate     5  f =      -439.55  |proj g|=        4.8405
At iterate     6  f =      -448.55  |proj g|=        4.7605
At iterate     7  f =      -449.43  |proj g|=        4.7155
At iterate     8  f =      -452.27  |proj g|=        4.4855
At iterate     9  f =      -455.32  |proj g|=        4.1569
At iterate    10  f =      -461.92  |proj g|=       0.14801
At iterate    11  f =      -483.04  |proj g|=        12.793
At iterate    12  f =      -490.75  |proj g|=        1.1201
At iterate    13  f =      -490.77  |proj g|=      0.052401
At iterate    14  f =      -490.77  |proj g|=      0.010661
At iterate    15  f =      -490.77  |proj g|=      0.010661

iterations 15
function evaluations 21
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0106613
final function value -490.769

F = -490.769
final  value -490.769113 
converged
 
INFO  [06:48:01.997] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:48:02.059] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:48:02.066] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:48:11.979] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:48:21.814] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:48:31.884] [mlr3]  Finished benchmark 
INFO  [06:48:31.952] [bbotk] Result of batch 97: 
INFO  [06:48:31.954] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:48:31.954] [bbotk]                   5               741      0.1294813        0.617 -0.8657083 
INFO  [06:48:31.954] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:48:31.954] [bbotk]          <NA>   0.9778354 fd608b18-3db0-440f-8031-faa643e01eaa 
DEBUG [06:48:32.854] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.922228e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003809212 0.3922228 
  - best initial criterion value(s) :  447.471 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -447.47  |proj g|=       4.3241
At iterate     1  f =      -451.93  |proj g|=        5.6915
At iterate     2  f =      -465.51  |proj g|=        4.9019
At iterate     3  f =      -470.95  |proj g|=        4.5102
At iterate     4  f =       -478.5  |proj g|=        3.9341
At iterate     5  f =      -500.24  |proj g|=        2.6669
At iterate     6  f =      -508.71  |proj g|=        2.1748
At iterate     7  f =      -509.32  |proj g|=        2.0717
At iterate     8  f =      -509.43  |proj g|=        2.0474
At iterate     9  f =      -509.55  |proj g|=        2.0102
At iterate    10  f =      -509.67  |proj g|=      0.029359
At iterate    11  f =      -509.67  |proj g|=      0.008891
At iterate    12  f =      -509.67  |proj g|=      0.008891

iterations 12
function evaluations 19
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00889102
final function value -509.675

F = -509.675
final  value -509.674618 
converged
 
INFO  [06:48:32.858] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:48:32.922] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:48:32.929] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:48:33.698] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:48:34.580] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:48:35.464] [mlr3]  Finished benchmark 
INFO  [06:48:35.561] [bbotk] Result of batch 98: 
INFO  [06:48:35.563] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:48:35.563] [bbotk]                  10              1685      0.4260065        0.637 -0.8638181 
INFO  [06:48:35.563] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:48:35.563] [bbotk]          <NA>         0.5 55bc7a82-6e5f-48c1-967d-7a9440e4a58a 
DEBUG [06:48:36.610] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.987391e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.00387667 0.398739 
  - best initial criterion value(s) :  428.6869 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -428.69  |proj g|=       8.9271
At iterate     1  f =      -440.64  |proj g|=        4.5736
At iterate     2  f =      -460.58  |proj g|=        3.7714
At iterate     3  f =      -472.67  |proj g|=        2.8089
At iterate     4  f =      -483.17  |proj g|=        2.2849
At iterate     5  f =      -483.87  |proj g|=        2.2098
At iterate     6  f =      -484.06  |proj g|=        2.1841
At iterate     7  f =      -484.83  |proj g|=        1.9764
At iterate     8  f =      -484.84  |proj g|=        1.9708
At iterate     9  f =      -484.98  |proj g|=       0.66046
At iterate    10  f =      -485.23  |proj g|=        1.1934
At iterate    11  f =      -485.97  |proj g|=        4.5782
At iterate    12  f =       -487.7  |proj g|=        9.2421
At iterate    13  f =      -491.65  |proj g|=        12.565
At iterate    14  f =      -499.27  |proj g|=        12.721
At iterate    15  f =      -503.73  |proj g|=        12.533
At iterate    16  f =      -507.08  |proj g|=       0.42158
At iterate    17  f =      -507.08  |proj g|=      0.015705
At iterate    18  f =      -507.08  |proj g|=      0.010389
At iterate    19  f =      -507.08  |proj g|=      0.010389

iterations 19
function evaluations 26
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0103887
final function value -507.078

F = -507.078
final  value -507.077776 
converged
 
INFO  [06:48:36.615] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:48:36.674] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:48:36.682] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:49:33.482] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:50:30.440] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:51:27.477] [mlr3]  Finished benchmark 
INFO  [06:51:27.552] [bbotk] Result of batch 99: 
INFO  [06:51:27.554] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:51:27.554] [bbotk]                   3              4854      0.4474994        0.745 -0.8652626 
INFO  [06:51:27.554] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:51:27.554] [bbotk]          <NA>    0.977512 1aa03fc9-1b58-401e-b4f9-ae4e9a11a4f1 
DEBUG [06:51:28.469] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.969657e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003853052 0.3969657 
  - best initial criterion value(s) :  382.7584 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -382.76  |proj g|=        11.27
At iterate     1  f =      -457.83  |proj g|=        3.1943
At iterate     2  f =      -472.09  |proj g|=        3.6735
At iterate     3  f =      -473.93  |proj g|=        3.6298
At iterate     4  f =      -485.25  |proj g|=        2.7974
At iterate     5  f =      -498.52  |proj g|=        4.5329
At iterate     6  f =      -498.97  |proj g|=        0.2585
At iterate     7  f =      -499.14  |proj g|=        1.0349
At iterate     8  f =      -499.85  |proj g|=        2.0592
At iterate     9  f =      -501.06  |proj g|=        2.1752
At iterate    10  f =       -504.4  |proj g|=        2.3615
At iterate    11  f =      -514.12  |proj g|=        2.4233
At iterate    12  f =      -516.52  |proj g|=        2.2438
At iterate    13  f =       -517.5  |proj g|=        2.1232
At iterate    14  f =      -517.92  |proj g|=        2.0339
At iterate    15  f =      -518.07  |proj g|=       0.05216
At iterate    16  f =      -518.07  |proj g|=     0.0095419
At iterate    17  f =      -518.07  |proj g|=     0.0095419

iterations 17
function evaluations 23
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00954191
final function value -518.073

F = -518.073
final  value -518.073107 
converged
 
INFO  [06:51:28.473] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:51:28.527] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:51:28.534] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:51:53.283] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:52:17.355] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:52:18.114] [mlr3]  Finished benchmark 
INFO  [06:52:18.179] [bbotk] Result of batch 100: 
INFO  [06:52:18.180] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [06:52:18.180] [bbotk]                   8              1996      0.4232957        0.621 -0.865085 
INFO  [06:52:18.180] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:52:18.180] [bbotk]          <NA>   0.8153268 c5174d8c-b6d1-41b9-8a90-87abae85bbfd 
DEBUG [06:52:19.194] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.937713e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003825587 0.3937713 
  - best initial criterion value(s) :  367.7299 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -367.73  |proj g|=       7.5141
At iterate     1  f =      -391.98  |proj g|=        6.4789
At iterate     2  f =      -418.61  |proj g|=        3.8994
At iterate     3  f =      -437.84  |proj g|=        1.8834
At iterate     4  f =      -438.35  |proj g|=        2.2125
At iterate     5  f =      -438.36  |proj g|=        2.2338
At iterate     6  f =      -438.75  |proj g|=        2.0722
At iterate     7  f =      -440.65  |proj g|=        2.1765
At iterate     8  f =      -448.13  |proj g|=        2.3475
At iterate     9  f =      -463.97  |proj g|=        2.6237
At iterate    10  f =      -479.82  |proj g|=        2.8745
At iterate    11  f =      -484.47  |proj g|=         2.779
At iterate    12  f =      -492.23  |proj g|=        2.3504
At iterate    13  f =      -495.55  |proj g|=        1.9698
At iterate    14  f =      -495.63  |proj g|=        0.1005
At iterate    15  f =      -495.63  |proj g|=      0.014536
At iterate    16  f =      -495.63  |proj g|=      0.014536

iterations 16
function evaluations 26
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0145363
final function value -495.63

F = -495.63
final  value -495.629628 
converged
 
INFO  [06:52:19.198] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:52:19.252] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:52:19.259] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:52:20.035] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:52:20.801] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:52:21.559] [mlr3]  Finished benchmark 
INFO  [06:52:21.624] [bbotk] Result of batch 101: 
INFO  [06:52:21.626] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:52:21.626] [bbotk]                  10              1647      0.1881092        0.705 -0.8680155 
INFO  [06:52:21.626] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:52:21.626] [bbotk]          <NA>         0.5 85809896-8641-4e97-8cad-e748bf54ecb9 
DEBUG [06:52:22.729] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.000103e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.00388496 0.4000103 
  - best initial criterion value(s) :  429.8545 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -429.85  |proj g|=       1.2455
At iterate     1  f =      -506.64  |proj g|=        2.4783
At iterate     2  f =      -507.37  |proj g|=        2.4783
At iterate     3  f =      -507.56  |proj g|=        2.4783
At iterate     4  f =      -507.59  |proj g|=        2.4782
At iterate     5  f =      -507.59  |proj g|=        2.4781
At iterate     6  f =      -507.59  |proj g|=         2.478
At iterate     7  f =      -507.59  |proj g|=        2.4773
At iterate     8  f =      -507.61  |proj g|=        2.4759
At iterate     9  f =      -507.64  |proj g|=        2.4711
At iterate    10  f =      -507.72  |proj g|=        2.4591
At iterate    11  f =      -507.91  |proj g|=        2.4278
At iterate    12  f =      -508.38  |proj g|=        2.3521
At iterate    13  f =      -509.41  |proj g|=        2.1828
At iterate    14  f =      -511.28  |proj g|=        2.9588
At iterate    15  f =      -511.52  |proj g|=        2.0415
At iterate    16  f =      -511.73  |proj g|=       0.13735
At iterate    17  f =      -511.74  |proj g|=      0.013014
At iterate    18  f =      -511.74  |proj g|=      0.013014

iterations 18
function evaluations 20
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.013014
final function value -511.735

F = -511.735
final  value -511.735055 
converged
 
INFO  [06:52:22.733] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:52:22.787] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:52:22.793] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:52:23.555] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:52:59.990] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:53:35.809] [mlr3]  Finished benchmark 
INFO  [06:53:35.877] [bbotk] Result of batch 102: 
INFO  [06:53:35.879] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:53:35.879] [bbotk]                   8              3027     0.07858197         0.83 -0.8674564 
INFO  [06:53:35.879] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:53:35.879] [bbotk]          <NA>   0.8161423 1c0333dc-7125-401c-b713-a7ae5d80f0b8 
DEBUG [06:53:36.805] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.968276e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003861223 0.3968276 
  - best initial criterion value(s) :  417.5971 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -417.6  |proj g|=       6.2311
At iterate     1  f =      -481.46  |proj g|=       0.39297
At iterate     2  f =       -481.5  |proj g|=      0.012117
At iterate     3  f =      -481.51  |proj g|=      0.012116
At iterate     4  f =      -481.51  |proj g|=        0.3928
At iterate     5  f =      -481.51  |proj g|=      0.012116

iterations 5
function evaluations 8
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0121164
final function value -481.515

F = -481.515
final  value -481.514903 
converged
 
INFO  [06:53:36.809] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:53:36.869] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:53:36.875] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:54:10.417] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:54:44.374] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:55:17.895] [mlr3]  Finished benchmark 
INFO  [06:55:17.961] [bbotk] Result of batch 103: 
INFO  [06:55:17.963] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:55:17.963] [bbotk]                   4              2834       0.149811         0.66 -0.8963704 
INFO  [06:55:17.963] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:55:17.963] [bbotk]          <NA>    0.978021 f95eb201-7805-4978-b5b2-b1b065aa71be 
DEBUG [06:55:18.836] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.951826e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003847417 0.3951826 
  - best initial criterion value(s) :  382.7218 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -382.72  |proj g|=        13.41
At iterate     1  f =      -465.96  |proj g|=         2.495
At iterate     2  f =      -496.48  |proj g|=        4.0921
At iterate     3  f =      -503.92  |proj g|=         3.694
At iterate     4  f =      -525.05  |proj g|=        2.4884
At iterate     5  f =      -531.74  |proj g|=        2.1008
At iterate     6  f =      -532.13  |proj g|=       0.49866
At iterate     7  f =      -532.13  |proj g|=       0.01168
At iterate     8  f =      -532.13  |proj g|=       0.01168

iterations 8
function evaluations 13
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0116798
final function value -532.133

F = -532.133
final  value -532.132915 
converged
 
INFO  [06:55:18.840] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:55:18.897] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:55:18.913] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:55:54.581] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:56:30.433] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:57:05.843] [mlr3]  Finished benchmark 
INFO  [06:57:05.908] [bbotk] Result of batch 104: 
INFO  [06:57:05.910] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:57:05.910] [bbotk]                   6              2998      0.3825055        0.626 -0.8660411 
INFO  [06:57:05.910] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:57:05.910] [bbotk]          <NA>    0.976519 967790ad-4c9c-4318-8f1d-ec383d9a7925 
DEBUG [06:57:06.771] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.935073e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003825381 0.3935073 
  - best initial criterion value(s) :  502.0801 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -502.08  |proj g|=       4.7866
At iterate     1  f =      -508.29  |proj g|=       0.38968
At iterate     2  f =      -508.36  |proj g|=     0.0098454
At iterate     3  f =      -508.36  |proj g|=     0.0098452
At iterate     4  f =      -508.36  |proj g|=     0.0098452

iterations 4
function evaluations 7
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00984519
final function value -508.356

F = -508.356
final  value -508.355688 
converged
 
INFO  [06:57:06.775] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:57:06.828] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:57:06.834] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [06:57:40.501] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:58:14.628] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [06:58:48.751] [mlr3]  Finished benchmark 
INFO  [06:58:48.817] [bbotk] Result of batch 105: 
INFO  [06:58:48.819] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [06:58:48.819] [bbotk]                   5              2781      0.1678937        0.632 -0.8954809 
INFO  [06:58:48.819] [bbotk]  errors.model classif.auc                                uhash 
INFO  [06:58:48.819] [bbotk]          <NA>   0.9783069 5dade058-2858-4b8f-ae9a-844f0d99405e 
DEBUG [06:58:49.793] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.918738e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003801459 0.3918738 
  - best initial criterion value(s) :  465.8 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -465.8  |proj g|=       1.4272
At iterate     1  f =      -479.58  |proj g|=        5.8395
At iterate     2  f =      -484.78  |proj g|=        5.7839
At iterate     3  f =      -487.82  |proj g|=         5.533
At iterate     4  f =      -492.46  |proj g|=        5.0794
At iterate     5  f =      -501.62  |proj g|=        4.3133
At iterate     6  f =      -525.99  |proj g|=         2.748
At iterate     7  f =      -532.84  |proj g|=         2.302
At iterate     8  f =      -533.83  |proj g|=        2.2187
At iterate     9  f =      -534.04  |proj g|=        1.3511
At iterate    10  f =      -534.21  |proj g|=        2.0723
At iterate    11  f =      -534.25  |proj g|=        2.0903
At iterate    12  f =      -534.47  |proj g|=        2.1434
At iterate    13  f =      -535.07  |proj g|=          2.23
At iterate    14  f =      -536.52  |proj g|=        2.3548
At iterate    15  f =      -541.09  |proj g|=        2.3857
At iterate    16  f =      -547.06  |proj g|=        2.2836
At iterate    17  f =      -551.61  |proj g|=        2.1886
At iterate    18  f =      -552.27  |proj g|=        2.1784
At iterate    19  f =      -552.32  |proj g|=        2.1713
At iterate    20  f =      -552.58  |proj g|=        2.1327
At iterate    21  f =      -553.09  |proj g|=       0.11233
At iterate    22  f =      -553.09  |proj g|=       0.01069
At iterate    23  f =      -553.09  |proj g|=       0.01069

iterations 23
function evaluations 34
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0106899
final function value -553.088

F = -553.088
final  value -553.088450 
converged
 
INFO  [06:58:49.797] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:58:49.854] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:58:49.861] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [06:59:34.927] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:00:19.786] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:01:04.221] [mlr3]  Finished benchmark 
INFO  [07:01:04.286] [bbotk] Result of batch 106: 
INFO  [07:01:04.288] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:01:04.288] [bbotk]                   5              3773     0.08441954         0.63 -0.8647502 
INFO  [07:01:04.288] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:01:04.288] [bbotk]          <NA>   0.9783135 4a5800a2-7d38-404f-af69-c2cc33c564a1 
DEBUG [07:01:05.249] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.902434e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003783558 0.3902434 
  - best initial criterion value(s) :  452.7279 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -452.73  |proj g|=      0.22968
At iterate     1  f =       -481.2  |proj g|=        3.8001
At iterate     2  f =      -485.28  |proj g|=        3.7968
At iterate     3  f =      -487.53  |proj g|=        3.7944
At iterate     4  f =      -490.42  |proj g|=        3.7929
At iterate     5  f =      -490.88  |proj g|=        3.7927
At iterate     6  f =      -490.94  |proj g|=        3.7924
At iterate     7  f =      -490.94  |proj g|=        3.7922
At iterate     8  f =      -490.94  |proj g|=        3.7921
At iterate     9  f =      -490.95  |proj g|=        3.7915
At iterate    10  f =      -490.96  |proj g|=        3.7902
At iterate    11  f =         -491  |proj g|=        3.7865
At iterate    12  f =       -491.1  |proj g|=        3.7766
At iterate    13  f =      -491.36  |proj g|=        3.7504
At iterate    14  f =      -492.04  |proj g|=        3.6814
At iterate    15  f =      -493.71  |proj g|=        3.5063
At iterate    16  f =       -497.8  |proj g|=        3.0802
At iterate    17  f =      -509.17  |proj g|=         8.399
At iterate    18  f =      -518.65  |proj g|=        4.6321
At iterate    19  f =      -518.97  |proj g|=       0.04585
At iterate    20  f =      -518.97  |proj g|=      0.018048
At iterate    21  f =      -518.97  |proj g|=      0.018048

iterations 21
function evaluations 25
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.018048
final function value -518.971

F = -518.971
final  value -518.970536 
converged
 
INFO  [07:01:05.253] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:01:05.308] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:01:05.315] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:01:41.722] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:02:17.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:02:52.725] [mlr3]  Finished benchmark 
INFO  [07:02:52.791] [bbotk] Result of batch 107: 
INFO  [07:02:52.793] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:02:52.793] [bbotk]                   5              3001      0.2109245        0.657 -0.8684598 
INFO  [07:02:52.793] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:02:52.793] [bbotk]          <NA>   0.9782648 f6d665ce-d92f-40a9-88ab-520d2cf5d8d0 
DEBUG [07:02:53.751] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.886155e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003766796 0.3886155 
  - best initial criterion value(s) :  465.4258 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -465.43  |proj g|=       11.229
At iterate     1  f =      -486.99  |proj g|=       0.13445
At iterate     2  f =      -511.45  |proj g|=         4.023
At iterate     3  f =       -516.9  |proj g|=        3.7102
At iterate     4  f =      -542.71  |proj g|=        2.2184
At iterate     5  f =      -543.02  |proj g|=        7.2902
At iterate     6  f =      -543.94  |proj g|=       0.25617
At iterate     7  f =      -543.96  |proj g|=        0.5365
At iterate     8  f =      -544.16  |proj g|=        2.0169
At iterate     9  f =      -544.53  |proj g|=        2.0821
At iterate    10  f =      -545.59  |proj g|=        2.1986
At iterate    11  f =      -547.95  |proj g|=        2.3457
At iterate    12  f =      -551.63  |proj g|=         2.368
At iterate    13  f =      -553.05  |proj g|=        2.2561
At iterate    14  f =      -553.85  |proj g|=        2.1667
At iterate    15  f =      -554.14  |proj g|=         2.124
At iterate    16  f =      -554.66  |proj g|=       0.13153
At iterate    17  f =      -554.66  |proj g|=      0.012401
At iterate    18  f =      -554.66  |proj g|=      0.012401

iterations 18
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0124014
final function value -554.664

F = -554.664
final  value -554.663888 
converged
 
INFO  [07:02:53.755] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:02:53.810] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:02:53.817] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:02:54.550] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:02:55.285] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:02:56.073] [mlr3]  Finished benchmark 
INFO  [07:02:56.138] [bbotk] Result of batch 108: 
INFO  [07:02:56.139] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:02:56.139] [bbotk]                  10              4042      0.2240509        0.645 -0.8650687 
INFO  [07:02:56.139] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:02:56.139] [bbotk]          <NA>         0.5 e8c63053-ab3a-4579-9260-665d4309b35d 
DEBUG [07:02:57.077] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.946872e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.00381965 0.3946872 
  - best initial criterion value(s) :  484.5262 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -484.53  |proj g|=       2.5125
At iterate     1  f =      -551.12  |proj g|=         2.554
At iterate     2  f =      -551.46  |proj g|=        2.5597
At iterate     3  f =      -552.22  |proj g|=        2.5552
At iterate     4  f =      -552.38  |proj g|=        2.5469
At iterate     5  f =      -552.44  |proj g|=        2.5447
At iterate     6  f =      -552.65  |proj g|=        2.5282
At iterate     7  f =      -553.24  |proj g|=        2.4646
At iterate     8  f =      -554.22  |proj g|=          2.33
At iterate     9  f =       -555.8  |proj g|=      0.039592
At iterate    10  f =       -557.2  |proj g|=       0.83783
At iterate    11  f =      -557.21  |proj g|=      0.094573
At iterate    12  f =      -557.21  |proj g|=      0.013003
At iterate    13  f =      -557.21  |proj g|=      0.013003

iterations 13
function evaluations 18
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0130027
final function value -557.215

F = -557.215
final  value -557.214617 
converged
 
INFO  [07:02:57.081] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:02:57.135] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:02:57.141] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:03:17.870] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:03:38.950] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:03:59.800] [mlr3]  Finished benchmark 
INFO  [07:03:59.865] [bbotk] Result of batch 109: 
INFO  [07:03:59.867] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:03:59.867] [bbotk]                   3              1692      0.4002955        0.658 -0.8656616 
INFO  [07:03:59.867] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:03:59.867] [bbotk]          <NA>   0.9772673 1e47e31e-97c0-4744-bfc9-e62e73049388 
DEBUG [07:04:00.985] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.930626e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003804117 0.3930626 
  - best initial criterion value(s) :  495.1512 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -495.15  |proj g|=       5.7383
At iterate     1  f =      -496.16  |proj g|=        5.5478
At iterate     2  f =       -498.2  |proj g|=        5.5728
At iterate     3  f =      -500.21  |proj g|=        5.5495
At iterate     4  f =       -502.5  |proj g|=        5.3936
At iterate     5  f =      -525.09  |proj g|=        4.4227
At iterate     6  f =      -530.41  |proj g|=        4.2135
At iterate     7  f =      -531.22  |proj g|=        4.1781
At iterate     8  f =      -534.22  |proj g|=        3.9707
At iterate     9  f =      -538.23  |proj g|=        3.6646
At iterate    10  f =      -553.08  |proj g|=        2.8136
At iterate    11  f =      -561.87  |proj g|=        12.538
At iterate    12  f =      -565.83  |proj g|=        1.4101
At iterate    13  f =      -565.86  |proj g|=      0.068925
At iterate    14  f =      -565.86  |proj g|=      0.012636
At iterate    15  f =      -565.86  |proj g|=      0.012636

iterations 15
function evaluations 21
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0126365
final function value -565.858

F = -565.858
final  value -565.857952 
converged
 
INFO  [07:04:00.989] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:04:01.041] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:04:01.047] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:04:17.738] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:04:18.512] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:04:35.113] [mlr3]  Finished benchmark 
INFO  [07:04:35.185] [bbotk] Result of batch 110: 
INFO  [07:04:35.187] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:04:35.187] [bbotk]                   8              1328     0.03481959        0.653 -0.8652514 
INFO  [07:04:35.187] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:04:35.187] [bbotk]          <NA>   0.8151624 fbf9246d-e1ee-40d8-a891-9a4afddf932f 
DEBUG [07:04:36.142] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.901428e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003778476 0.3901428 
  - best initial criterion value(s) :  468.2775 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -468.28  |proj g|=        12.69
At iterate     1  f =      -518.23  |proj g|=        5.2643
At iterate     2  f =      -520.56  |proj g|=        5.1635
At iterate     3  f =       -533.8  |proj g|=        4.3793
At iterate     4  f =      -558.25  |proj g|=        2.9284
At iterate     5  f =      -573.37  |proj g|=        2.2632
At iterate     6  f =      -573.74  |proj g|=        2.2247
At iterate     7  f =      -574.43  |proj g|=         2.132
At iterate     8  f =      -574.93  |proj g|=      0.027779
At iterate     9  f =      -574.93  |proj g|=       0.13985
At iterate    10  f =      -574.95  |proj g|=       0.80377
At iterate    11  f =         -575  |proj g|=        1.6433
At iterate    12  f =      -575.14  |proj g|=        2.5462
At iterate    13  f =      -575.18  |proj g|=         1.846
At iterate    14  f =      -575.24  |proj g|=      0.014466
At iterate    15  f =      -575.24  |proj g|=      0.012072
At iterate    16  f =      -575.24  |proj g|=      0.012072

iterations 16
function evaluations 22
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0120722
final function value -575.236

F = -575.236
final  value -575.236226 
converged
 
INFO  [07:04:36.147] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:04:36.202] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:04:36.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:04:36.932] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:05:14.669] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:05:52.443] [mlr3]  Finished benchmark 
INFO  [07:05:52.508] [bbotk] Result of batch 111: 
INFO  [07:05:52.510] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:05:52.510] [bbotk]                   8              3191      0.2471468         0.65 -0.8647109 
INFO  [07:05:52.510] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:05:52.510] [bbotk]          <NA>   0.8154364 adc66a9c-069b-45bf-8f48-7ef9bc04f2b7 
DEBUG [07:05:53.526] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.872649e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003754329 0.3872649 
  - best initial criterion value(s) :  487.4751 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -487.48  |proj g|=       10.749
At iterate     1  f =      -506.68  |proj g|=        6.6904
At iterate     2  f =       -548.8  |proj g|=        4.1832
At iterate     3  f =      -580.79  |proj g|=        2.5051
At iterate     4  f =      -581.54  |proj g|=        2.4907
At iterate     5  f =      -584.22  |proj g|=        2.2583
At iterate     6  f =      -585.52  |proj g|=       0.89481
At iterate     7  f =      -585.54  |proj g|=       0.35428
At iterate     8  f =      -585.55  |proj g|=        0.1323
At iterate     9  f =      -585.61  |proj g|=        1.1188
At iterate    10  f =      -585.75  |proj g|=        2.5663
At iterate    11  f =      -586.13  |proj g|=        4.9623
At iterate    12  f =      -587.03  |proj g|=        8.4343
At iterate    13  f =      -589.17  |proj g|=        12.424
At iterate    14  f =       -591.5  |proj g|=        12.212
At iterate    15  f =      -593.81  |proj g|=         0.664
At iterate    16  f =      -593.82  |proj g|=      0.025199
At iterate    17  f =      -593.82  |proj g|=      0.010213
At iterate    18  f =      -593.82  |proj g|=      0.010213

iterations 18
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0102128
final function value -593.819

F = -593.819
final  value -593.819437 
converged
 
INFO  [07:05:53.530] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:05:53.585] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:05:53.591] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:05:54.354] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:05:55.125] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:05:55.847] [mlr3]  Finished benchmark 
INFO  [07:05:55.924] [bbotk] Result of batch 112: 
INFO  [07:05:55.926] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:05:55.926] [bbotk]                  10               596    0.009947476        0.696 -0.8630396 
INFO  [07:05:55.926] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:05:55.926] [bbotk]          <NA>         0.5 1ef68413-b640-40dd-a671-867cf2613646 
DEBUG [07:05:56.859] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.930649e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003831601 0.3930649 
  - best initial criterion value(s) :  406.1747 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -406.17  |proj g|=       11.247
At iterate     1  f =      -431.17  |proj g|=        6.2673
At iterate     2  f =      -450.54  |proj g|=        4.3288
At iterate     3  f =      -487.52  |proj g|=        2.1234
At iterate     4  f =      -488.14  |proj g|=        1.9612
At iterate     5  f =      -496.23  |proj g|=        0.4424
At iterate     6  f =      -538.37  |proj g|=        4.2394
At iterate     7  f =       -547.9  |proj g|=        1.1097
At iterate     8  f =      -547.92  |proj g|=       0.32868
At iterate     9  f =      -547.92  |proj g|=      0.019576
At iterate    10  f =      -547.92  |proj g|=      0.019576

iterations 10
function evaluations 14
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0195764
final function value -547.918

F = -547.918
final  value -547.917539 
converged
 
INFO  [07:05:56.863] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:05:56.917] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:05:56.924] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:06:37.657] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:07:18.338] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:07:59.287] [mlr3]  Finished benchmark 
INFO  [07:07:59.354] [bbotk] Result of batch 113: 
INFO  [07:07:59.356] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:07:59.356] [bbotk]                   7              3404     0.08101305        0.657 -0.8674125 
INFO  [07:07:59.356] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:07:59.356] [bbotk]          <NA>    0.976875 ef7556ec-0b8c-4ae0-9c59-a224de036b91 
DEBUG [07:08:00.561] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.915313e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003820383 0.3915313 
  - best initial criterion value(s) :  470.1678 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -470.17  |proj g|=       12.114
At iterate     1  f =      -522.69  |proj g|=        5.7542
At iterate     2  f =      -526.62  |proj g|=         5.536
At iterate     3  f =      -535.22  |proj g|=        4.9445
At iterate     4  f =      -549.89  |proj g|=        4.0256
At iterate     5  f =      -582.05  |proj g|=        2.3776
At iterate     6  f =      -582.66  |proj g|=        2.3218
At iterate     7  f =      -584.09  |proj g|=        2.0479
At iterate     8  f =      -584.12  |proj g|=        1.7207
At iterate     9  f =       -584.3  |proj g|=       0.24482
At iterate    10  f =      -584.66  |proj g|=        2.4651
At iterate    11  f =      -585.65  |proj g|=        6.3721
At iterate    12  f =      -587.95  |proj g|=         11.63
At iterate    13  f =      -593.08  |proj g|=        12.559
At iterate    14  f =      -602.65  |proj g|=        12.592
At iterate    15  f =      -606.75  |proj g|=        10.462
At iterate    16  f =      -608.46  |proj g|=       0.71956
At iterate    17  f =      -608.47  |proj g|=      0.025508
At iterate    18  f =      -608.47  |proj g|=     0.0098502
Bad direction in the line search;
   refresh the lbfgs memory and restart the iteration.
At iterate    19  f =       -608.5  |proj g|=       0.58998
At iterate    20  f =      -608.52  |proj g|=        1.8762
At iterate    21  f =      -608.52  |proj g|=        1.8682
At iterate    22  f =      -608.52  |proj g|=         1.859
At iterate    23  f =      -608.52  |proj g|=        1.8404
At iterate    24  f =      -608.52  |proj g|=        1.8136
At iterate    25  f =      -608.52  |proj g|=        1.7681
At iterate    26  f =      -608.52  |proj g|=        1.6956
At iterate    27  f =      -608.52  |proj g|=        1.5791
At iterate    28  f =      -608.52  |proj g|=        1.3927
At iterate    29  f =      -608.53  |proj g|=        1.0938
At iterate    30  f =      -608.54  |proj g|=       0.61717
At iterate    31  f =      -608.58  |proj g|=       0.14446
At iterate    32  f =      -608.67  |proj g|=         1.355
At iterate    33  f =      -608.91  |proj g|=         3.266
At iterate    34  f =      -609.27  |proj g|=        4.0159
At iterate    35  f =       -609.4  |proj g|=        2.6622
At iterate    36  f =      -609.51  |proj g|=      0.035623
At iterate    37  f =      -609.51  |proj g|=    0.00030981
At iterate    38  f =      -609.51  |proj g|=    3.5857e-08

iterations 38
function evaluations 68
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 3
norm of the final projected gradient 3.58566e-08
final function value -609.512

F = -609.512
final  value -609.511567 
converged
 
INFO  [07:08:00.565] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:08:00.620] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:08:00.627] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:08:29.501] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:08:57.948] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:09:26.636] [mlr3]  Finished benchmark 
INFO  [07:09:26.701] [bbotk] Result of batch 114: 
INFO  [07:09:26.702] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:09:26.702] [bbotk]                   3              2385       0.382382        0.674 -0.8619353 
INFO  [07:09:26.702] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:09:26.702] [bbotk]          <NA>   0.9773275 c0bba49e-be13-4e55-b46a-f97e30859ef2 
DEBUG [07:09:27.839] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.900094e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003803788 0.3900094 
  - best initial criterion value(s) :  405.5515 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -405.55  |proj g|=       7.7706
At iterate     1  f =      -419.32  |proj g|=        5.2671
At iterate     2  f =      -515.13  |proj g|=         5.092
At iterate     3  f =      -533.45  |proj g|=        4.5968
At iterate     4  f =      -580.84  |proj g|=        3.2267
At iterate     5  f =      -583.92  |proj g|=        3.2096
At iterate     6  f =      -584.53  |proj g|=        3.1648
At iterate     7  f =      -588.27  |proj g|=        2.9774
At iterate     8  f =      -599.55  |proj g|=        2.1094
At iterate     9  f =      -599.77  |proj g|=      0.021976
At iterate    10  f =      -599.77  |proj g|=      0.012195
At iterate    11  f =      -599.77  |proj g|=      0.012195

iterations 11
function evaluations 19
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0121954
final function value -599.768

F = -599.768
final  value -599.767759 
converged
 
INFO  [07:09:27.843] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:09:27.904] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:09:27.910] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:09:28.641] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:09:29.361] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:09:30.097] [mlr3]  Finished benchmark 
INFO  [07:09:30.172] [bbotk] Result of batch 115: 
INFO  [07:09:30.174] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:09:30.174] [bbotk]                  10              1749      0.3898639        0.836 -0.8633307 
INFO  [07:09:30.174] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:09:30.174] [bbotk]          <NA>         0.5 dcd3ecf8-41f5-4a83-b115-9c1b03e4f335 
DEBUG [07:09:31.117] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.956371e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003856488 0.3956371 
  - best initial criterion value(s) :  505.8425 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -505.84  |proj g|=       6.8787
At iterate     1  f =      -519.06  |proj g|=        5.8523
At iterate     2  f =      -521.05  |proj g|=        6.3828
At iterate     3  f =      -528.72  |proj g|=        6.2686
At iterate     4  f =      -532.56  |proj g|=        6.0701
At iterate     5  f =      -543.56  |proj g|=        5.4289
At iterate     6  f =      -558.02  |proj g|=        4.9634
At iterate     7  f =      -559.42  |proj g|=        4.9078
At iterate     8  f =      -564.34  |proj g|=         4.594
At iterate     9  f =       -571.1  |proj g|=        3.9984
At iterate    10  f =      -584.27  |proj g|=        5.6624
At iterate    11  f =      -608.25  |proj g|=        8.4223
ys=-2.141e-01  -gs= 1.937e+01, BFGS update SKIPPED
At iterate    12  f =      -609.31  |proj g|=        1.9011
At iterate    13  f =      -609.37  |proj g|=      0.056702
At iterate    14  f =      -609.37  |proj g|=      0.011759
At iterate    15  f =      -609.37  |proj g|=      0.011759

iterations 15
function evaluations 20
segments explored during Cauchy searches 19
BFGS updates skipped 1
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0117589
final function value -609.367

F = -609.367
final  value -609.367396 
converged
 
INFO  [07:09:31.122] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:09:31.180] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:09:31.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:09:40.004] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:09:48.795] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:09:57.659] [mlr3]  Finished benchmark 
INFO  [07:09:57.726] [bbotk] Result of batch 116: 
INFO  [07:09:57.728] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:09:57.728] [bbotk]                   7               656      0.4023422         0.65 -0.8632642 
INFO  [07:09:57.728] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:09:57.728] [bbotk]          <NA>   0.9768304 bfdb9801-506c-4540-a5c1-7776b1abf4b6 
DEBUG [07:09:58.699] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.94127e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.00383899 0.394127 
  - best initial criterion value(s) :  445.2101 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -445.21  |proj g|=       6.2002
At iterate     1  f =      -448.77  |proj g|=        5.9095
At iterate     2  f =      -468.67  |proj g|=        5.5412
At iterate     3  f =      -489.64  |proj g|=        5.0491
At iterate     4  f =      -563.18  |proj g|=        2.8626
At iterate     5  f =      -573.93  |proj g|=        2.4746
At iterate     6  f =      -582.57  |proj g|=         2.181
At iterate     7  f =      -585.27  |proj g|=        2.2457
At iterate     8  f =      -585.31  |proj g|=        1.6329
At iterate     9  f =      -585.35  |proj g|=      0.017002
At iterate    10  f =      -585.35  |proj g|=      0.017002
At iterate    11  f =      -585.35  |proj g|=      0.017002

iterations 11
function evaluations 19
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0170016
final function value -585.349

F = -585.349
final  value -585.349146 
converged
 
INFO  [07:09:58.703] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:09:58.759] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:09:58.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:10:44.114] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:11:29.089] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:12:16.010] [mlr3]  Finished benchmark 
INFO  [07:12:16.084] [bbotk] Result of batch 117: 
INFO  [07:12:16.085] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:12:16.085] [bbotk]                   7              3824     0.08965693        0.666 -0.8660014 
INFO  [07:12:16.085] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:12:16.085] [bbotk]          <NA>   0.9768064 f7580ead-1b95-4f72-be09-42918ef1efe2 
DEBUG [07:12:17.226] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.926189e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003827971 0.3926189 
  - best initial criterion value(s) :  523.1102 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -523.11  |proj g|=       11.015
At iterate     1  f =      -543.05  |proj g|=       0.55768
At iterate     2  f =      -568.79  |proj g|=        4.0453
At iterate     3  f =      -575.89  |proj g|=        3.6492
At iterate     4  f =      -601.66  |proj g|=        2.2538
At iterate     5  f =      -602.38  |proj g|=        1.6914
At iterate     6  f =      -602.52  |proj g|=        1.1512
At iterate     7  f =      -602.54  |proj g|=        1.4448
At iterate     8  f =      -602.76  |proj g|=        2.1028
At iterate     9  f =      -603.14  |proj g|=        2.1692
At iterate    10  f =      -604.27  |proj g|=        2.2895
At iterate    11  f =      -606.83  |proj g|=        2.4464
At iterate    12  f =      -617.81  |proj g|=        2.3803
At iterate    13  f =      -618.47  |proj g|=        2.3244
At iterate    14  f =      -618.83  |proj g|=        2.2879
At iterate    15  f =       -620.1  |proj g|=       0.30399
At iterate    16  f =       -620.1  |proj g|=      0.012343
At iterate    17  f =       -620.1  |proj g|=      0.012343

iterations 17
function evaluations 26
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.012343
final function value -620.099

F = -620.099
final  value -620.098588 
converged
 
INFO  [07:12:17.230] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:12:17.282] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:12:17.289] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:12:34.297] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:12:35.049] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:12:52.428] [mlr3]  Finished benchmark 
INFO  [07:12:52.495] [bbotk] Result of batch 118: 
INFO  [07:12:52.496] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:12:52.496] [bbotk]                   8              1378      0.4301606        0.649 -0.8633129 
INFO  [07:12:52.496] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:12:52.496] [bbotk]          <NA>   0.8156927 6050d258-8975-4130-b447-78ceb54b7ef1 
DEBUG [07:12:53.475] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.898616e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003801225 0.3898616 
  - best initial criterion value(s) :  543.3929 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -543.39  |proj g|=       6.2425
At iterate     1  f =      -580.89  |proj g|=      0.012406
At iterate     2  f =      -590.65  |proj g|=      0.010858
At iterate     3  f =      -596.79  |proj g|=             0

iterations 3
function evaluations 18
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 4
norm of the final projected gradient 0
final function value -596.786

F = -596.786
final  value -596.785991 
converged
 
INFO  [07:12:53.479] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:12:53.534] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:12:53.541] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:12:54.453] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:12:55.205] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:12:55.978] [mlr3]  Finished benchmark 
INFO  [07:12:56.063] [bbotk] Result of batch 119: 
INFO  [07:12:56.065] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:12:56.065] [bbotk]                   9              2511      0.2579047         0.69 -0.8931414 
INFO  [07:12:56.065] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:12:56.065] [bbotk]          <NA>         0.5 8dffa723-fb08-41bc-a695-fe34767a6eb2 
DEBUG [07:12:57.088] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.952988e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003847378 0.3952988 
  - best initial criterion value(s) :  487.6901 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -487.69  |proj g|=       1.3482
At iterate     1  f =      -552.85  |proj g|=        4.7683
At iterate     2  f =      -559.07  |proj g|=        4.9206
At iterate     3  f =      -564.93  |proj g|=        5.0682
At iterate     4  f =      -576.89  |proj g|=         5.471
At iterate     5  f =      -577.37  |proj g|=        5.4662
At iterate     6  f =      -577.51  |proj g|=        5.4613
At iterate     7  f =      -577.56  |proj g|=        5.4575
At iterate     8  f =      -577.67  |proj g|=        5.4476
At iterate     9  f =      -577.96  |proj g|=        5.4193
At iterate    10  f =      -578.67  |proj g|=        5.3461
At iterate    11  f =      -580.32  |proj g|=        5.1668
At iterate    12  f =      -584.26  |proj g|=        4.7317
At iterate    13  f =      -594.76  |proj g|=        2.4298
At iterate    14  f =      -637.44  |proj g|=        9.4232
ys=-1.799e+01  -gs= 2.768e+01, BFGS update SKIPPED
At iterate    15  f =      -638.75  |proj g|=        2.0185
At iterate    16  f =      -638.81  |proj g|=      0.064427
At iterate    17  f =      -638.81  |proj g|=      0.011522
At iterate    18  f =      -638.81  |proj g|=      0.011522

iterations 18
function evaluations 21
segments explored during Cauchy searches 21
BFGS updates skipped 1
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0115224
final function value -638.813

F = -638.813
final  value -638.813100 
converged
 
INFO  [07:12:57.092] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:12:57.146] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:12:57.153] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:13:34.864] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:14:11.957] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:14:48.481] [mlr3]  Finished benchmark 
INFO  [07:14:48.548] [bbotk] Result of batch 120: 
INFO  [07:14:48.550] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:14:48.550] [bbotk]                   7              3099      0.4968379        0.703 -0.8628539 
INFO  [07:14:48.550] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:14:48.550] [bbotk]          <NA>   0.9756044 73c3d723-12d8-4f13-9d3a-8d658942367a 
DEBUG [07:14:49.586] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.938223e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003834258 0.3938223 
  - best initial criterion value(s) :  498.0898 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -498.09  |proj g|=       13.245
At iterate     1  f =      -579.11  |proj g|=        4.8481
At iterate     2  f =       -613.1  |proj g|=         3.366
At iterate     3  f =      -624.67  |proj g|=        2.7248
At iterate     4  f =      -629.19  |proj g|=        2.3393
At iterate     5  f =      -632.38  |proj g|=        1.3803
At iterate     6  f =      -632.72  |proj g|=       0.67964
At iterate     7  f =      -633.46  |proj g|=        2.1869
At iterate     8  f =      -634.36  |proj g|=        2.2797
At iterate     9  f =      -637.27  |proj g|=        2.4586
At iterate    10  f =      -642.97  |proj g|=        2.1993
At iterate    11  f =      -648.34  |proj g|=       0.21824
At iterate    12  f =      -648.35  |proj g|=      0.044425
At iterate    13  f =      -648.35  |proj g|=      0.010896
At iterate    14  f =      -648.35  |proj g|=      0.010896

iterations 14
function evaluations 29
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0108962
final function value -648.346

F = -648.346
final  value -648.345610 
converged
 
INFO  [07:14:49.591] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:14:49.661] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:14:49.667] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:15:15.620] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:15:41.913] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:16:08.163] [mlr3]  Finished benchmark 
INFO  [07:16:08.228] [bbotk] Result of batch 121: 
INFO  [07:16:08.230] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:16:08.230] [bbotk]                   7              2147     0.04552171        0.685 -0.8621852 
INFO  [07:16:08.230] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:16:08.230] [bbotk]          <NA>   0.9769688 7a452f21-42a3-4b96-8dbc-73884632c356 
DEBUG [07:16:09.314] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.923744e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003821197 0.3923743 
  - best initial criterion value(s) :  411.9846 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -411.98  |proj g|=       5.2819
At iterate     1  f =      -444.96  |proj g|=       0.38855
At iterate     2  f =      -445.43  |proj g|=      0.058923
At iterate     3  f =      -445.45  |proj g|=      0.059081
At iterate     4  f =      -445.45  |proj g|=       0.38809
At iterate     5  f =      -445.45  |proj g|=      0.059122

iterations 5
function evaluations 8
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.059122
final function value -445.446

F = -445.446
final  value -445.446265 
converged
 
INFO  [07:16:09.318] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:16:09.372] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:16:09.379] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:16:59.576] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:17:00.334] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:17:51.916] [mlr3]  Finished benchmark 
INFO  [07:17:51.988] [bbotk] Result of batch 122: 
INFO  [07:17:51.990] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:17:51.990] [bbotk]                   8              4275      0.4843778        0.834 -0.9043633 
INFO  [07:17:51.990] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:17:51.990] [bbotk]          <NA>   0.8139391 bf359a03-7319-4c6e-8bdf-d6ac72bc63d9 
DEBUG [07:17:52.969] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.896992e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003791739 0.3896992 
  - best initial criterion value(s) :  521.8247 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -521.82  |proj g|=       5.8649
At iterate     1  f =      -585.99  |proj g|=      0.015282
At iterate     2  f =      -609.34  |proj g|=        0.0114
At iterate     3  f =      -616.36  |proj g|=             0

iterations 3
function evaluations 19
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 4
norm of the final projected gradient 0
final function value -616.359

F = -616.359
final  value -616.358667 
converged
 
INFO  [07:17:52.973] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:17:53.026] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:17:53.033] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:18:39.624] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:19:26.404] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:20:11.632] [mlr3]  Finished benchmark 
INFO  [07:20:11.708] [bbotk] Result of batch 123: 
INFO  [07:20:11.710] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:20:11.710] [bbotk]                   7              3878      0.4015444        0.678 -0.8929333 
INFO  [07:20:11.710] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:20:11.710] [bbotk]          <NA>   0.9755561 7d71af51-d33d-4c7d-9672-42cd53e7ffb8 
DEBUG [07:20:12.701] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.882592e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003779897 0.3882591 
  - best initial criterion value(s) :  570.5284 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -570.53  |proj g|=       7.9618
At iterate     1  f =      -580.75  |proj g|=        4.0164
At iterate     2  f =      -612.09  |proj g|=        4.6892
At iterate     3  f =      -623.13  |proj g|=        4.0223
At iterate     4  f =      -640.56  |proj g|=        3.3335
At iterate     5  f =       -654.5  |proj g|=        2.6053
At iterate     6  f =      -658.91  |proj g|=        2.3026
At iterate     7  f =      -659.98  |proj g|=       0.50222
At iterate     8  f =      -659.98  |proj g|=      0.013793
At iterate     9  f =      -659.98  |proj g|=        0.0119
At iterate    10  f =      -659.98  |proj g|=        0.0119

iterations 10
function evaluations 17
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0118996
final function value -659.985

F = -659.985
final  value -659.984623 
converged
 
INFO  [07:20:12.705] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:20:12.761] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:20:12.768] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:20:36.638] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:21:00.231] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:21:24.016] [mlr3]  Finished benchmark 
INFO  [07:21:24.081] [bbotk] Result of batch 124: 
INFO  [07:21:24.083] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:21:24.083] [bbotk]                   5              1974      0.4058905        0.683 -0.8619677 
INFO  [07:21:24.083] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:21:24.083] [bbotk]          <NA>   0.9780271 e6a2bede-a980-4cad-9828-610cf852f461 
DEBUG [07:21:25.137] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.868674e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003770621 0.3868674 
  - best initial criterion value(s) :  591.7869 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -591.79  |proj g|=       7.7468
At iterate     1  f =      -600.95  |proj g|=        4.3239
At iterate     2  f =      -607.62  |proj g|=        4.3185
At iterate     3  f =      -610.02  |proj g|=        4.2284
At iterate     4  f =      -617.35  |proj g|=        3.7081
At iterate     5  f =      -633.58  |proj g|=        2.8133
At iterate     6  f =      -640.59  |proj g|=        2.4157
At iterate     7  f =      -641.85  |proj g|=        2.1722
At iterate     8  f =      -641.86  |proj g|=        2.1576
At iterate     9  f =      -641.89  |proj g|=        2.1392
At iterate    10  f =      -641.98  |proj g|=        2.1051
At iterate    11  f =      -642.19  |proj g|=       0.51671
At iterate    12  f =      -642.77  |proj g|=        2.5785
At iterate    13  f =      -644.18  |proj g|=        7.2526
At iterate    14  f =       -647.5  |proj g|=        12.347
At iterate    15  f =      -654.48  |proj g|=        12.558
At iterate    16  f =      -664.63  |proj g|=        12.581
At iterate    17  f =      -669.45  |proj g|=        12.161
At iterate    18  f =      -671.66  |proj g|=        1.0429
At iterate    19  f =      -671.67  |proj g|=      0.043585
At iterate    20  f =      -671.67  |proj g|=      0.011173
At iterate    21  f =      -671.67  |proj g|=      0.011173

iterations 21
function evaluations 29
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0111726
final function value -671.671

F = -671.671
final  value -671.670849 
converged
 
INFO  [07:21:25.141] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:21:25.195] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:21:25.203] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:21:25.956] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:21:26.963] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:21:27.805] [mlr3]  Finished benchmark 
INFO  [07:21:27.869] [bbotk] Result of batch 125: 
INFO  [07:21:27.871] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:21:27.871] [bbotk]                   9              2024      0.0115343        0.686 -0.8612959 
INFO  [07:21:27.871] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:21:27.871] [bbotk]          <NA>         0.5 f9802816-5205-40a6-ac74-d06172098ed6 
DEBUG [07:21:28.886] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.921595e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003819849 0.3921595 
  - best initial criterion value(s) :  541.1715 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -541.17  |proj g|=       6.2265
At iterate     1  f =       -543.1  |proj g|=        6.0368
At iterate     2  f =       -544.8  |proj g|=        6.0381
At iterate     3  f =      -548.44  |proj g|=        5.9411
At iterate     4  f =       -552.6  |proj g|=        5.7195
At iterate     5  f =      -568.19  |proj g|=        4.7256
At iterate     6  f =      -579.45  |proj g|=        4.6514
At iterate     7  f =      -581.78  |proj g|=        4.5187
At iterate     8  f =      -587.95  |proj g|=        4.0204
At iterate     9  f =      -595.37  |proj g|=       0.25747
At iterate    10  f =      -622.48  |proj g|=        12.532
At iterate    11  f =       -625.6  |proj g|=        12.178
At iterate    12  f =       -627.8  |proj g|=        0.8258
At iterate    13  f =      -627.81  |proj g|=      0.034355
At iterate    14  f =      -627.81  |proj g|=       0.01972
At iterate    15  f =      -627.81  |proj g|=       0.01972

iterations 15
function evaluations 20
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0197204
final function value -627.812

F = -627.812
final  value -627.812063 
converged
 
INFO  [07:21:28.890] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:21:28.944] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:21:28.951] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:21:29.665] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:21:30.372] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:21:31.080] [mlr3]  Finished benchmark 
INFO  [07:21:31.144] [bbotk] Result of batch 126: 
INFO  [07:21:31.145] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:21:31.145] [bbotk]                  10              2598      0.1864425        0.686 -0.8658272 
INFO  [07:21:31.145] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:21:31.145] [bbotk]          <NA>         0.5 49b98514-c0df-4459-ad2e-904e6db25f6a 
DEBUG [07:21:32.195] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.972745e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9420 0.9774851 
  - variance bounds :  0.003862806 0.3972745 
  - best initial criterion value(s) :  519.0242 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -519.02  |proj g|=       5.4661
At iterate     1  f =      -519.72  |proj g|=        5.2883
At iterate     2  f =      -538.51  |proj g|=        5.1557
At iterate     3  f =      -544.42  |proj g|=         5.047
At iterate     4  f =      -574.46  |proj g|=         4.422
At iterate     5  f =      -665.34  |proj g|=        2.5923
At iterate     6  f =       -672.3  |proj g|=        2.3567
At iterate     7  f =      -679.47  |proj g|=        9.6616
At iterate     8  f =      -679.57  |proj g|=        11.732
At iterate     9  f =      -679.59  |proj g|=        12.052
At iterate    10  f =      -679.75  |proj g|=        12.302
At iterate    11  f =      -680.72  |proj g|=        10.764
At iterate    12  f =      -682.46  |proj g|=       0.54497
At iterate    13  f =      -682.47  |proj g|=      0.020027
At iterate    14  f =      -682.47  |proj g|=      0.011535
At iterate    15  f =      -682.47  |proj g|=      0.011535

iterations 15
function evaluations 22
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0115347
final function value -682.469

F = -682.469
final  value -682.468886 
converged
 
INFO  [07:21:32.199] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:21:32.253] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:21:32.259] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:22:26.615] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:23:20.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:24:14.066] [mlr3]  Finished benchmark 
INFO  [07:24:14.131] [bbotk] Result of batch 127: 
INFO  [07:24:14.133] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:24:14.133] [bbotk]                   4              4572      0.2403438        0.711 -0.8617988 
INFO  [07:24:14.133] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:24:14.133] [bbotk]          <NA>   0.9781977 478e1cc0-7b6f-44a1-93cc-28f3e5404479 
DEBUG [07:24:14.203] [bbotk]  
INFO  [07:24:14.214] [bbotk] Finished optimizing after 150 evaluation(s) 
INFO  [07:24:14.215] [bbotk] Result: 
INFO  [07:24:14.218] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu learner_param_vals 
INFO  [07:24:14.218] [bbotk]                   5              3640      0.1232877         <list[15]> 
INFO  [07:24:14.218] [bbotk]   x_domain classif.auc 
INFO  [07:24:14.218] [bbotk]  <list[3]>   0.9783264 
INFO  [07:25:09.833] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost.tuned' on task 'spam' (iter 2/5) 
INFO  [07:25:09.924] [bbotk] Starting to optimize 3 parameter(s) with '<OptimizerInterMBO>' and '<TerminatorEvals> [n_evals=150]' 
DEBUG [07:25:09.993] [bbotk]  
INFO  [07:25:09.999] [bbotk] Evaluating 24 configuration(s) 
INFO  [07:25:10.872] [mlr3]  Running benchmark with 72 resampling iterations 
INFO  [07:25:10.879] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:26:02.277] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:26:39.910] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:26:40.726] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:27:20.770] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:27:39.322] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:28:07.081] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:28:58.662] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:28:59.466] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:29:00.227] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:29:55.148] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:30:42.648] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:30:43.539] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:31:13.331] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:31:32.260] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:31:33.057] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:31:34.204] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:32:18.314] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:33:05.538] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:33:35.135] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:33:50.500] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:34:20.874] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:34:21.802] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:34:22.566] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:34:56.634] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:35:12.695] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:35:39.327] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:36:09.773] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:36:23.684] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:36:39.123] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:36:46.191] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:36:46.936] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:37:39.112] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:38:21.652] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:39:01.686] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:39:54.048] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:40:45.322] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:40:46.218] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:41:04.608] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:41:38.406] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:41:39.193] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:42:13.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:43:01.128] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:43:14.339] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:43:52.844] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:44:35.163] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:45:02.212] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:45:02.936] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:45:03.794] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:45:10.961] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:45:51.865] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:45:52.752] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:45:53.488] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:46:23.413] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:46:24.227] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:47:15.024] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:47:15.784] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:47:22.924] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:47:31.476] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:47:45.046] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:47:45.921] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:47:54.647] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:48:40.256] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:48:48.734] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:49:17.876] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:49:56.089] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:49:56.829] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:50:51.954] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:51:42.405] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:52:37.639] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:52:38.593] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:53:34.252] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:53:34.995] [mlr3]  Finished benchmark 
INFO  [07:53:36.127] [bbotk] Result of batch 1: 
INFO  [07:53:36.129] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu classif.auc 
INFO  [07:53:36.129] [bbotk]                   4              4278     0.13053425   0.9796461 
INFO  [07:53:36.129] [bbotk]                   4              3906     0.05552071   0.9789783 
INFO  [07:53:36.129] [bbotk]                   7              1224     0.35435927   0.9796970 
INFO  [07:53:36.129] [bbotk]                   5              1022     0.39446951   0.9795756 
INFO  [07:53:36.129] [bbotk]                   6              2804     0.15947897   0.9798152 
INFO  [07:53:36.129] [bbotk]                   9              1648     0.40470054   0.5000000 
INFO  [07:53:36.129] [bbotk]                   7              2163     0.23496925   0.9796135 
INFO  [07:53:36.129] [bbotk]                   5              3294     0.03388663   0.9785135 
INFO  [07:53:36.129] [bbotk]                   3              2394     0.20089379   0.9776751 
INFO  [07:53:36.129] [bbotk]                   9              2705     0.33354999   0.5000000 
INFO  [07:53:36.129] [bbotk]                   9               226     0.18528515   0.5000000 
INFO  [07:53:36.129] [bbotk]                   8              4445     0.26320652   0.8183030 
INFO  [07:53:36.129] [bbotk]                   5              2439     0.47465155   0.9792865 
INFO  [07:53:36.129] [bbotk]                   8              3545     0.08551111   0.8194846 
INFO  [07:53:36.129] [bbotk]                   8              3763     0.44698943   0.8178126 
INFO  [07:53:36.129] [bbotk]                   6              3106     0.28587476   0.9794223 
INFO  [07:53:36.129] [bbotk]                   7               609     0.30987733   0.9795595 
INFO  [07:53:36.129] [bbotk]                   6              1461     0.01960482   0.9745588 
INFO  [07:53:36.129] [bbotk]                   3              4178     0.41696934   0.9788602 
INFO  [07:53:36.129] [bbotk]                  10              1962     0.06744557   0.5000000 
INFO  [07:53:36.129] [bbotk]                   3               512     0.22155551   0.9743608 
INFO  [07:53:36.129] [bbotk]                  10              4887     0.36864378   0.5000000 
INFO  [07:53:36.129] [bbotk]                   4              4606     0.10801858   0.9797174 
INFO  [07:53:36.129] [bbotk]                  10               945     0.49721687   0.5000000 
INFO  [07:53:36.129] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu classif.auc 
INFO  [07:53:36.129] [bbotk]                                 uhash 
INFO  [07:53:36.129] [bbotk]  102fcaab-4a8f-4af9-abe8-9db65fb53827 
INFO  [07:53:36.129] [bbotk]  5ec9bbdd-0dc4-4e53-b8f8-cd5127bdc6ab 
INFO  [07:53:36.129] [bbotk]  a2c72319-bcb8-4ea4-919a-920af058bb6b 
INFO  [07:53:36.129] [bbotk]  23aeedae-e301-4a2c-92b2-1e90e4ea4bbd 
INFO  [07:53:36.129] [bbotk]  e0d8ee13-f5b5-4a6f-a0f5-b76004d54fa2 
INFO  [07:53:36.129] [bbotk]  b3b5da3e-7e67-4fe5-ba05-c7e6eea969a1 
INFO  [07:53:36.129] [bbotk]  2f0a0391-a3ec-4a33-b020-55596f9cc33c 
INFO  [07:53:36.129] [bbotk]  e40cb704-93d4-40b3-a0c5-174c29c690f9 
INFO  [07:53:36.129] [bbotk]  c387f0b9-4855-42d8-9650-9c39c7cc05f2 
INFO  [07:53:36.129] [bbotk]  86fbbb79-c278-4efa-a74e-266a2d324ff2 
INFO  [07:53:36.129] [bbotk]  51a05a10-8de2-4658-9804-74ec60bee658 
INFO  [07:53:36.129] [bbotk]  b225b499-3c86-4cd5-aca4-08cb4344599a 
INFO  [07:53:36.129] [bbotk]  947717cd-a436-4637-8c6e-2c0e20b31859 
INFO  [07:53:36.129] [bbotk]  01d9f5b6-028b-45c9-9f8d-0345a58cf9bf 
INFO  [07:53:36.129] [bbotk]  2959ca35-e8f2-4086-99fe-003214f23b1c 
INFO  [07:53:36.129] [bbotk]  17febe82-9a1f-409f-b754-fcf7fc573dbe 
INFO  [07:53:36.129] [bbotk]  a4196529-d6d4-4d6a-b5ec-d117e5285096 
INFO  [07:53:36.129] [bbotk]  3b6b187a-9120-4d40-9774-0e4a8d265923 
INFO  [07:53:36.129] [bbotk]  6e940090-9212-4a28-b01a-f28bf8f6a6e4 
INFO  [07:53:36.129] [bbotk]  74ac1edb-ddd7-474b-8115-265ca4e97b39 
INFO  [07:53:36.129] [bbotk]  4ac0bd3f-6c91-4d38-9cc6-fdd7467576b4 
INFO  [07:53:36.129] [bbotk]  860dc389-a7d1-4658-922e-be1cf5e1e057 
INFO  [07:53:36.129] [bbotk]  41b94c6b-5c2a-4490-bf30-fcbe19421e15 
INFO  [07:53:36.129] [bbotk]  d6bcb374-99ca-4904-b14c-8364b812bee7 
INFO  [07:53:36.129] [bbotk]                                 uhash 
DEBUG [07:53:36.766] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.274909e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.004274909 0.431927 
  - best initial criterion value(s) :  37.21902 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -37.219  |proj g|=       1.2699
At iterate     1  f =      -40.652  |proj g|=        2.0321
At iterate     2  f =      -41.587  |proj g|=         2.452
At iterate     3  f =      -42.619  |proj g|=        1.9977
At iterate     4  f =      -43.231  |proj g|=        1.0885
At iterate     5  f =      -43.232  |proj g|=        1.0661
At iterate     6  f =      -43.241  |proj g|=       0.89072
At iterate     7  f =      -43.251  |proj g|=       0.74615
At iterate     8  f =      -43.279  |proj g|=       0.41827
At iterate     9  f =      -43.317  |proj g|=      0.043049
At iterate    10  f =      -43.364  |proj g|=       0.42033
At iterate    11  f =      -43.366  |proj g|=      0.007591
At iterate    12  f =      -43.366  |proj g|=     0.0075391
At iterate    13  f =      -43.366  |proj g|=     0.0013529
At iterate    14  f =      -43.366  |proj g|=     0.0013529

iterations 14
function evaluations 18
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00135289
final function value -43.3661

F = -43.3661
final  value -43.366091 
converged
 
INFO  [07:53:36.770] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:53:36.831] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:53:36.838] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:53:37.746] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:53:38.490] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:53:39.239] [mlr3]  Finished benchmark 
INFO  [07:53:39.304] [bbotk] Result of batch 2: 
INFO  [07:53:39.305] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:53:39.305] [bbotk]                   9              1852      0.2256254         0.41 -0.9317005 
INFO  [07:53:39.305] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:53:39.305] [bbotk]          <NA>         0.5 9ab7638c-01f6-42f4-b99f-fa2d89f274e0 
DEBUG [07:53:39.883] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.556345e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.004457934 0.4556345 
  - best initial criterion value(s) :  40.86967 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -40.87  |proj g|=       4.1367
At iterate     1  f =      -44.346  |proj g|=        1.7961
At iterate     2  f =      -44.841  |proj g|=        2.4239
At iterate     3  f =      -45.464  |proj g|=        1.8811
At iterate     4  f =      -45.522  |proj g|=        1.3495
At iterate     5  f =      -45.692  |proj g|=      0.060465
At iterate     6  f =      -45.697  |proj g|=       0.44414
At iterate     7  f =        -45.7  |proj g|=         0.444
At iterate     8  f =      -45.705  |proj g|=        0.1129
At iterate     9  f =      -45.722  |proj g|=      0.088626
At iterate    10  f =       -45.76  |proj g|=      0.059176
At iterate    11  f =      -45.857  |proj g|=      0.014355
At iterate    12  f =      -45.954  |proj g|=      0.062007
At iterate    13  f =      -46.041  |proj g|=       0.46565
At iterate    14  f =       -46.06  |proj g|=        0.6317
At iterate    15  f =      -46.069  |proj g|=       0.55314
At iterate    16  f =      -46.088  |proj g|=       0.15629
At iterate    17  f =      -46.093  |proj g|=       0.44406
At iterate    18  f =      -46.093  |proj g|=     0.0071448
At iterate    19  f =      -46.093  |proj g|=     0.0024291
At iterate    20  f =      -46.093  |proj g|=     0.0015747

iterations 20
function evaluations 24
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0015747
final function value -46.0927

F = -46.0927
final  value -46.092667 
converged
 
INFO  [07:53:39.887] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:53:39.941] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:53:39.948] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:53:59.915] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:54:19.874] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:54:39.012] [mlr3]  Finished benchmark 
INFO  [07:54:39.079] [bbotk] Result of batch 3: 
INFO  [07:54:39.081] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:54:39.081] [bbotk]                   5              1533      0.2807431        0.398 -0.9273961 
INFO  [07:54:39.081] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:54:39.081] [bbotk]          <NA>   0.9796628 f0f0ea10-13df-44de-a362-576e0eb64ead 
DEBUG [07:54:39.848] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.465624e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.004363159 0.4465624 
  - best initial criterion value(s) :  35.84635 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -35.846  |proj g|=       4.9396
At iterate     1  f =      -44.889  |proj g|=       0.34135
At iterate     2  f =      -46.703  |proj g|=          1.44
At iterate     3  f =      -47.268  |proj g|=        2.4794
At iterate     4  f =      -47.887  |proj g|=        2.1904
At iterate     5  f =      -48.474  |proj g|=       0.58004
At iterate     6  f =      -48.757  |proj g|=        0.3284
At iterate     7  f =      -48.992  |proj g|=       0.71899
At iterate     8  f =      -49.017  |proj g|=       0.37328
At iterate     9  f =      -49.027  |proj g|=       0.43547
At iterate    10  f =      -49.028  |proj g|=     0.0068582
At iterate    11  f =      -49.028  |proj g|=     0.0021041
At iterate    12  f =      -49.028  |proj g|=     0.0017586

iterations 12
function evaluations 18
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00175857
final function value -49.0277

F = -49.0277
final  value -49.027737 
converged
 
INFO  [07:54:39.852] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:54:39.907] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:54:39.914] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:55:12.090] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:55:43.423] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:56:16.726] [mlr3]  Finished benchmark 
INFO  [07:56:16.791] [bbotk] Result of batch 4: 
INFO  [07:56:16.793] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:56:16.793] [bbotk]                   5              2597      0.2927482        0.399 -0.9263585 
INFO  [07:56:16.793] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:56:16.793] [bbotk]          <NA>    0.979561 b9714f66-7495-46dd-b4d5-9d479044ea8a 
DEBUG [07:56:17.364] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.37525e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.004374215 0.437525 
  - best initial criterion value(s) :  43.15308 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -43.153  |proj g|=       3.5503
At iterate     1  f =      -43.222  |proj g|=        2.3567
At iterate     2  f =       -43.37  |proj g|=        2.6766
At iterate     3  f =      -43.873  |proj g|=         3.701
At iterate     4  f =      -44.576  |proj g|=        3.6013
At iterate     5  f =      -51.958  |proj g|=        1.8837
At iterate     6  f =      -52.429  |proj g|=        1.7111
At iterate     7  f =      -52.527  |proj g|=        1.4818
At iterate     8  f =      -52.528  |proj g|=        1.4022
At iterate     9  f =      -52.531  |proj g|=        1.4348
At iterate    10  f =      -52.543  |proj g|=        1.3367
At iterate    11  f =      -52.588  |proj g|=        1.1726
At iterate    12  f =      -52.605  |proj g|=         1.249
At iterate    13  f =      -52.727  |proj g|=       0.64774
At iterate    14  f =      -52.764  |proj g|=       0.42679
At iterate    15  f =      -52.765  |proj g|=       0.42669
At iterate    16  f =      -52.765  |proj g|=       0.42667
At iterate    17  f =      -52.765  |proj g|=       0.10725
At iterate    18  f =      -52.765  |proj g|=       0.00189

iterations 18
function evaluations 23
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00188999
final function value -52.7651

F = -52.7651
final  value -52.765091 
converged
 
INFO  [07:56:17.368] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:56:17.424] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:56:17.431] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:56:18.191] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:56:41.821] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:57:06.168] [mlr3]  Finished benchmark 
INFO  [07:57:06.234] [bbotk] Result of batch 5: 
INFO  [07:57:06.236] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:57:06.236] [bbotk]                   8              1935     0.07220003        0.394 -0.9251514 
INFO  [07:57:06.236] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:57:06.236] [bbotk]          <NA>   0.8193136 9b9a7be2-5b0d-4dad-85e6-56b31dc9a734 
DEBUG [07:57:06.812] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.214298e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.004144376 0.4214298 
  - best initial criterion value(s) :  46.8262 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -46.826  |proj g|=       3.0005
At iterate     1  f =      -52.194  |proj g|=        2.4353
At iterate     2  f =      -52.277  |proj g|=        2.6852
At iterate     3  f =      -52.308  |proj g|=         2.593
At iterate     4  f =      -52.378  |proj g|=        2.5201
At iterate     5  f =      -52.798  |proj g|=        1.7295
At iterate     6  f =      -53.629  |proj g|=         0.334
At iterate     7  f =      -55.526  |proj g|=        2.3538
At iterate     8  f =      -55.886  |proj g|=        2.0022
At iterate     9  f =      -58.366  |proj g|=        1.4493
At iterate    10  f =      -58.433  |proj g|=        1.1653
At iterate    11  f =      -58.509  |proj g|=      0.020889
At iterate    12  f =       -58.51  |proj g|=     0.0060667
At iterate    13  f =       -58.51  |proj g|=      0.019235
At iterate    14  f =       -58.51  |proj g|=     0.0014783

iterations 14
function evaluations 18
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0014783
final function value -58.5101

F = -58.5101
final  value -58.510097 
converged
 
INFO  [07:57:06.816] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:57:06.870] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:57:06.877] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [07:57:07.998] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:57:33.379] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:57:59.750] [mlr3]  Finished benchmark 
INFO  [07:57:59.816] [bbotk] Result of batch 6: 
INFO  [07:57:59.817] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [07:57:59.817] [bbotk]                   8              2115      0.1159355        0.403 -0.9223379 
INFO  [07:57:59.817] [bbotk]  errors.model classif.auc                                uhash 
INFO  [07:57:59.817] [bbotk]          <NA>   0.8194645 2607851b-4a84-4882-89c4-7fe9780e8fdc 
DEBUG [07:58:00.403] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.064753e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.003958763 0.4064753 
  - best initial criterion value(s) :  59.14989 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -59.15  |proj g|=      0.14315
At iterate     1  f =      -60.781  |proj g|=          2.12
At iterate     2  f =      -60.977  |proj g|=        2.4379
At iterate     3  f =      -60.993  |proj g|=        2.4438
At iterate     4  f =      -61.032  |proj g|=        2.4585
At iterate     5  f =      -61.158  |proj g|=        2.5036
At iterate     6  f =      -61.198  |proj g|=        2.5029
At iterate     7  f =       -61.23  |proj g|=        2.5017
At iterate     8  f =      -61.232  |proj g|=        2.5012
At iterate     9  f =      -61.233  |proj g|=        2.5006
At iterate    10  f =      -61.238  |proj g|=        2.4985
At iterate    11  f =      -61.248  |proj g|=         2.493
At iterate    12  f =      -61.273  |proj g|=        2.4785
At iterate    13  f =      -61.337  |proj g|=        2.3713
At iterate    14  f =      -61.488  |proj g|=        1.6787
At iterate    15  f =      -61.826  |proj g|=       0.59541
At iterate    16  f =      -62.451  |proj g|=       0.99427
At iterate    17  f =      -62.775  |proj g|=      0.040959
At iterate    18  f =      -62.776  |proj g|=       0.39671
At iterate    19  f =      -62.776  |proj g|=       0.11456
At iterate    20  f =      -62.776  |proj g|=     0.0061111
At iterate    21  f =      -62.776  |proj g|=     0.0099674
At iterate    22  f =      -62.776  |proj g|=     0.0015427

iterations 22
function evaluations 26
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00154266
final function value -62.7757

F = -62.7757
final  value -62.775719 
converged
 
INFO  [07:58:00.407] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:58:00.477] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:58:00.484] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [07:58:44.219] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [07:59:27.373] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:00:12.322] [mlr3]  Finished benchmark 
INFO  [08:00:12.395] [bbotk] Result of batch 7: 
INFO  [08:00:12.397] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:00:12.397] [bbotk]                   3              3639      0.1342632        0.397 -0.9195006 
INFO  [08:00:12.397] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:00:12.397] [bbotk]          <NA>   0.9777187 82ca6834-9f00-43f7-8569-a0023424bd8a 
DEBUG [08:00:12.971] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.991899e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.003977841 0.3991899 
  - best initial criterion value(s) :  45.51613 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -45.516  |proj g|=       2.2766
At iterate     1  f =      -54.035  |proj g|=        4.2506
At iterate     2  f =      -59.538  |proj g|=       0.26706
At iterate     3  f =      -62.757  |proj g|=        3.0294
At iterate     4  f =      -62.776  |proj g|=        3.0257
At iterate     5  f =      -63.415  |proj g|=        2.8549
At iterate     6  f =      -64.617  |proj g|=        2.4679
At iterate     7  f =      -65.727  |proj g|=        2.0903
At iterate     8  f =      -66.316  |proj g|=        1.4669
At iterate     9  f =      -66.465  |proj g|=       0.15256
At iterate    10  f =      -66.469  |proj g|=       0.38989
At iterate    11  f =       -66.47  |proj g|=     0.0054779
At iterate    12  f =       -66.47  |proj g|=     0.0054678
At iterate    13  f =       -66.47  |proj g|=     0.0044516

iterations 13
function evaluations 20
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00445163
final function value -66.4703

F = -66.4703
final  value -66.470266 
converged
 
INFO  [08:00:12.975] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:00:13.027] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:00:13.034] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:00:13.785] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:00:14.527] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:00:15.415] [mlr3]  Finished benchmark 
INFO  [08:00:15.479] [bbotk] Result of batch 8: 
INFO  [08:00:15.481] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:00:15.481] [bbotk]                   9              2166      0.4340805        0.398 -0.9179004 
INFO  [08:00:15.481] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:00:15.481] [bbotk]          <NA>         0.5 974d17bf-6e9a-4841-8a7b-ab95067693b4 
DEBUG [08:00:16.065] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.232514e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.004203109 0.4232514 
  - best initial criterion value(s) :  50.13106 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -50.131  |proj g|=        3.952
At iterate     1  f =      -50.256  |proj g|=        2.5682
At iterate     2  f =      -50.431  |proj g|=        2.9869
At iterate     3  f =      -50.901  |proj g|=        3.7821
At iterate     4  f =      -53.805  |proj g|=        3.2574
At iterate     5  f =      -58.756  |proj g|=        1.5149
At iterate     6  f =      -60.148  |proj g|=        1.3118
At iterate     7  f =      -60.582  |proj g|=       0.43749
At iterate     8  f =      -60.584  |proj g|=        1.7693
At iterate     9  f =       -60.63  |proj g|=         1.288
At iterate    10  f =      -60.632  |proj g|=        1.2157
At iterate    11  f =      -60.636  |proj g|=        1.1393
At iterate    12  f =      -60.648  |proj g|=       0.96211
At iterate    13  f =      -60.676  |proj g|=       0.69639
At iterate    14  f =      -60.756  |proj g|=        0.4143
At iterate    15  f =      -60.907  |proj g|=       0.41439
At iterate    16  f =      -60.987  |proj g|=       0.41381
At iterate    17  f =      -61.014  |proj g|=       0.41333
At iterate    18  f =      -61.016  |proj g|=       0.41319
At iterate    19  f =      -61.017  |proj g|=       0.41315
At iterate    20  f =      -61.018  |proj g|=      0.061923
At iterate    21  f =      -61.018  |proj g|=     0.0058832
At iterate    22  f =      -61.018  |proj g|=       0.16782
At iterate    23  f =      -61.018  |proj g|=     0.0036444
At iterate    24  f =      -61.018  |proj g|=     0.0036444

iterations 24
function evaluations 32
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00364443
final function value -61.018

F = -61.018
final  value -61.017969 
converged
 
INFO  [08:00:16.069] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:00:16.122] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:00:16.128] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:00:54.290] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:01:32.396] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:02:11.627] [mlr3]  Finished benchmark 
INFO  [08:02:11.702] [bbotk] Result of batch 9: 
INFO  [08:02:11.704] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:02:11.704] [bbotk]                   3              3157      0.2120716        0.394 -0.9158874 
INFO  [08:02:11.704] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:02:11.704] [bbotk]          <NA>   0.9781984 3f9ff6b6-3a48-411a-a85f-2b9a72010a36 
DEBUG [08:02:12.314] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.165196e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.004165196 0.4223561 
  - best initial criterion value(s) :  52.53852 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -52.539  |proj g|=       2.3624
At iterate     1  f =       -64.44  |proj g|=        2.8399
At iterate     2  f =      -67.358  |proj g|=        2.2782
At iterate     3  f =      -67.619  |proj g|=        2.4295
At iterate     4  f =      -67.655  |proj g|=        2.4242
At iterate     5  f =      -67.671  |proj g|=        2.4231
At iterate     6  f =       -67.69  |proj g|=         2.418
At iterate     7  f =      -67.809  |proj g|=        2.3754
At iterate     8  f =      -68.008  |proj g|=        2.2176
At iterate     9  f =      -68.382  |proj g|=       0.94518
At iterate    10  f =      -68.891  |proj g|=       0.60638
At iterate    11  f =      -69.214  |proj g|=       0.81958
At iterate    12  f =      -69.327  |proj g|=       0.46599
At iterate    13  f =       -69.34  |proj g|=       0.41315
At iterate    14  f =      -69.341  |proj g|=     0.0051191
At iterate    15  f =      -69.341  |proj g|=      0.002979
At iterate    16  f =      -69.341  |proj g|=     0.0027428
At iterate    17  f =      -69.341  |proj g|=       0.41309
At iterate    18  f =      -69.341  |proj g|=       0.41311
At iterate    19  f =      -69.341  |proj g|=       0.41314
At iterate    20  f =      -69.342  |proj g|=       0.41319
At iterate    21  f =      -69.345  |proj g|=       0.41326
At iterate    22  f =      -69.353  |proj g|=       0.41338
At iterate    23  f =      -69.373  |proj g|=       0.48128
At iterate    24  f =      -69.428  |proj g|=       0.89356
At iterate    25  f =      -69.571  |proj g|=        1.6956
At iterate    26  f =      -69.885  |proj g|=        1.9065
At iterate    27  f =      -70.326  |proj g|=        2.1067
At iterate    28  f =      -70.545  |proj g|=        2.2223
At iterate    29  f =      -70.602  |proj g|=         2.284
At iterate    30  f =      -70.614  |proj g|=        2.3083
At iterate    31  f =      -70.618  |proj g|=          2.31
At iterate    32  f =      -70.623  |proj g|=        2.3196
At iterate    33  f =      -70.634  |proj g|=        2.3182
At iterate    34  f =      -70.655  |proj g|=         2.309
At iterate    35  f =      -70.704  |proj g|=        2.2863
At iterate    36  f =      -70.819  |proj g|=         2.072
At iterate    37  f =      -71.115  |proj g|=        1.1872
At iterate    38  f =      -71.889  |proj g|=       0.26978
At iterate    39  f =      -73.447  |proj g|=         2.267
At iterate    40  f =      -75.366  |proj g|=        3.0696
At iterate    41  f =      -75.598  |proj g|=        2.5159
At iterate    42  f =      -75.696  |proj g|=         1.945
At iterate    43  f =      -75.891  |proj g|=       0.41379
At iterate    44  f =        -75.9  |proj g|=      0.070791
At iterate    45  f =        -75.9  |proj g|=     0.0047169
At iterate    46  f =        -75.9  |proj g|=     0.0014875
At iterate    47  f =        -75.9  |proj g|=    0.00016652

iterations 47
function evaluations 57
segments explored during Cauchy searches 49
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000166525
final function value -75.9004

F = -75.9004
final  value -75.900436 
converged
 
INFO  [08:02:12.330] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:02:12.378] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:02:12.385] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:02:13.122] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:02:13.977] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:02:14.719] [mlr3]  Finished benchmark 
INFO  [08:02:14.784] [bbotk] Result of batch 10: 
INFO  [08:02:14.786] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:02:14.786] [bbotk]                  10              1776     0.07973287        0.411 -0.9117431 
INFO  [08:02:14.786] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:02:14.786] [bbotk]          <NA>         0.5 e2b21605-8065-42ef-96a7-77cb2b30a414 
DEBUG [08:02:15.374] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.373133e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.004373133 0.441628 
  - best initial criterion value(s) :  56.86039 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -56.86  |proj g|=       5.0434
At iterate     1  f =      -57.837  |proj g|=        2.3278
At iterate     2  f =      -61.533  |proj g|=        4.6221
At iterate     3  f =      -63.099  |proj g|=        4.2244
At iterate     4  f =      -67.272  |proj g|=        3.4989
At iterate     5  f =      -72.854  |proj g|=        2.7472
At iterate     6  f =      -74.297  |proj g|=        2.4178
At iterate     7  f =      -75.719  |proj g|=        1.9309
At iterate     8  f =       -75.79  |proj g|=        2.2417
At iterate     9  f =       -76.07  |proj g|=      0.099724
At iterate    10  f =       -76.07  |proj g|=       0.43287
At iterate    11  f =      -76.071  |proj g|=     0.0087342
At iterate    12  f =      -76.071  |proj g|=      0.004477
At iterate    13  f =      -76.071  |proj g|=      0.038183

iterations 13
function evaluations 25
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0381827
final function value -76.0711

F = -76.0711
final  value -76.071058 
converged
 
INFO  [08:02:15.378] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:02:15.433] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:02:15.439] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:03:00.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:03:44.570] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:04:28.748] [mlr3]  Finished benchmark 
INFO  [08:04:28.814] [bbotk] Result of batch 11: 
INFO  [08:04:28.815] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:04:28.815] [bbotk]                   4              3715      0.3092833        0.409 -0.9108991 
INFO  [08:04:28.815] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:04:28.815] [bbotk]          <NA>   0.9792155 20af0c78-3256-4308-adf5-08d0f7a49820 
DEBUG [08:04:29.409] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.31156e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.00431156 0.4419027 
  - best initial criterion value(s) :  63.73343 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -63.733  |proj g|=       3.1693
At iterate     1  f =      -76.921  |proj g|=       0.40998
At iterate     2  f =      -80.257  |proj g|=        1.2231
At iterate     3  f =      -80.995  |proj g|=       0.92845
At iterate     4  f =      -81.488  |proj g|=        2.3908
At iterate     5  f =        -81.5  |proj g|=        2.5895
At iterate     6  f =      -81.507  |proj g|=        2.4344
At iterate     7  f =      -81.523  |proj g|=        2.2754
At iterate     8  f =      -81.592  |proj g|=        1.9381
At iterate     9  f =       -81.81  |proj g|=        1.3192
At iterate    10  f =       -82.31  |proj g|=        0.6411
At iterate    11  f =      -82.693  |proj g|=       0.12777
At iterate    12  f =      -82.795  |proj g|=       0.94072
At iterate    13  f =      -82.823  |proj g|=       0.36817
At iterate    14  f =      -82.832  |proj g|=       0.14568
At iterate    15  f =      -82.835  |proj g|=      0.011142
At iterate    16  f =      -82.835  |proj g|=     0.0042004
At iterate    17  f =      -82.835  |proj g|=     0.0041999

iterations 17
function evaluations 24
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00419992
final function value -82.8346

F = -82.8346
final  value -82.834628 
converged
 
INFO  [08:04:29.413] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:04:29.466] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:04:29.472] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:05:18.194] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:06:07.337] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:06:57.038] [mlr3]  Finished benchmark 
INFO  [08:06:57.104] [bbotk] Result of batch 12: 
INFO  [08:06:57.106] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [08:06:57.106] [bbotk]                   5              4050      0.4037605        0.407 -0.908649 
INFO  [08:06:57.106] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:06:57.106] [bbotk]          <NA>   0.9790381 bfba7a18-0011-47f1-ad17-0a6f79cc1445 
DEBUG [08:06:57.705] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.249522e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.004249522 0.4483736 
  - best initial criterion value(s) :  64.36008 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -64.36  |proj g|=      0.76977
At iterate     1  f =      -69.099  |proj g|=        2.7302
At iterate     2  f =      -69.315  |proj g|=         2.768
At iterate     3  f =      -69.582  |proj g|=        2.7066
At iterate     4  f =      -71.515  |proj g|=         2.136
At iterate     5  f =      -71.924  |proj g|=        1.1657
At iterate     6  f =      -72.061  |proj g|=       0.68852
At iterate     7  f =      -72.247  |proj g|=       0.13062
At iterate     8  f =       -72.27  |proj g|=       0.43927
At iterate     9  f =      -72.274  |proj g|=     0.0053124
At iterate    10  f =      -72.274  |proj g|=     0.0053148
At iterate    11  f =      -72.274  |proj g|=     0.0053149

iterations 11
function evaluations 17
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00531488
final function value -72.2738

F = -72.2738
final  value -72.273822 
converged
 
INFO  [08:06:57.709] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:06:57.762] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:06:57.768] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:07:34.632] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:08:11.137] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:08:48.693] [mlr3]  Finished benchmark 
INFO  [08:08:48.768] [bbotk] Result of batch 13: 
INFO  [08:08:48.771] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:08:48.771] [bbotk]                   7              3048      0.2934032        0.421 -0.9110283 
INFO  [08:08:48.771] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:08:48.771] [bbotk]          <NA>    0.979088 bb4f29b0-bb47-4755-8686-0af6ea36131f 
DEBUG [08:08:49.379] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.187575e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.004187575 0.445424 
  - best initial criterion value(s) :  76.92408 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -76.924  |proj g|=       5.5068
At iterate     1  f =      -82.576  |proj g|=        3.3878
At iterate     2  f =      -83.703  |proj g|=        3.2257
At iterate     3  f =      -85.461  |proj g|=        2.8282
At iterate     4  f =      -88.131  |proj g|=        2.1372
At iterate     5  f =      -89.205  |proj g|=       0.16274
At iterate     6  f =      -89.237  |proj g|=       0.12237
At iterate     7  f =      -89.243  |proj g|=       0.43724
At iterate     8  f =       -89.25  |proj g|=       0.43735
At iterate     9  f =      -89.266  |proj g|=       0.43748
At iterate    10  f =      -89.304  |proj g|=       0.53045
At iterate    11  f =      -89.317  |proj g|=       0.43747
At iterate    12  f =      -89.329  |proj g|=       0.43721
At iterate    13  f =      -89.329  |proj g|=       0.11742
At iterate    14  f =       -89.33  |proj g|=       0.10599
At iterate    15  f =       -89.33  |proj g|=      0.077925
At iterate    16  f =       -89.33  |proj g|=      0.045697
At iterate    17  f =       -89.33  |proj g|=     0.0040568
At iterate    18  f =       -89.33  |proj g|=      0.029761
At iterate    19  f =       -89.33  |proj g|=      0.021275
At iterate    20  f =       -89.33  |proj g|=     0.0021113

iterations 20
function evaluations 29
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00211129
final function value -89.3303

F = -89.3303
final  value -89.330294 
converged
 
INFO  [08:08:49.383] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:08:49.438] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:08:49.445] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:09:24.682] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:10:02.822] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:10:39.174] [mlr3]  Finished benchmark 
INFO  [08:10:39.240] [bbotk] Result of batch 14: 
INFO  [08:10:39.241] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:10:39.241] [bbotk]                   4              2959      0.3409228        0.425 -0.9073658 
INFO  [08:10:39.241] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:10:39.241] [bbotk]          <NA>   0.9792878 2d697fcd-688f-465a-8e58-5db59c4d92a0 
DEBUG [08:10:39.849] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.126097e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.004126097 0.4458098 
  - best initial criterion value(s) :  66.81221 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -66.812  |proj g|=      0.53311
At iterate     1  f =      -77.575  |proj g|=        3.6315
At iterate     2  f =      -79.851  |proj g|=        3.5992
At iterate     3  f =      -82.439  |proj g|=        3.5537
At iterate     4  f =      -84.095  |proj g|=        3.5331
At iterate     5  f =      -84.104  |proj g|=         3.533
At iterate     6  f =      -84.107  |proj g|=        3.5327
At iterate     7  f =      -84.108  |proj g|=        3.5324
At iterate     8  f =      -84.123  |proj g|=        3.5284
At iterate     9  f =       -84.15  |proj g|=        3.5199
At iterate    10  f =      -84.236  |proj g|=        3.4918
At iterate    11  f =       -84.45  |proj g|=        3.4206
At iterate    12  f =      -85.024  |proj g|=        3.2306
At iterate    13  f =      -86.441  |proj g|=        2.8144
At iterate    14  f =      -89.667  |proj g|=        1.8969
At iterate    15  f =      -90.217  |proj g|=        3.4654
At iterate    16  f =      -91.008  |proj g|=       0.62762
At iterate    17  f =      -91.241  |proj g|=       0.72125
At iterate    18  f =       -91.27  |proj g|=       0.43769
At iterate    19  f =      -91.271  |proj g|=      0.022441
At iterate    20  f =      -91.271  |proj g|=        0.4377
At iterate    21  f =      -91.271  |proj g|=      0.003989
At iterate    22  f =      -91.271  |proj g|=      0.003728

iterations 22
function evaluations 25
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00372804
final function value -91.2706

F = -91.2706
final  value -91.270601 
converged
 
INFO  [08:10:39.853] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:10:39.907] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:10:39.914] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:11:01.833] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:11:22.968] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:11:44.381] [mlr3]  Finished benchmark 
INFO  [08:11:44.446] [bbotk] Result of batch 15: 
INFO  [08:11:44.448] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:11:44.448] [bbotk]                   7              1746     0.09446945        0.418 -0.9071597 
INFO  [08:11:44.448] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:11:44.448] [bbotk]          <NA>   0.9794463 6258d03c-dd9a-42cc-a3e0-9836e5b85aaf 
DEBUG [08:11:45.088] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.065249e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.004065249 0.4338543 
  - best initial criterion value(s) :  73.00852 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -73.009  |proj g|=       5.0168
At iterate     1  f =      -73.375  |proj g|=        3.1994
At iterate     2  f =      -76.761  |proj g|=        4.5778
At iterate     3  f =      -79.293  |proj g|=        4.1094
At iterate     4  f =      -79.938  |proj g|=        4.0309
At iterate     5  f =      -81.805  |proj g|=        3.4267
At iterate     6  f =      -83.923  |proj g|=       0.79033
At iterate     7  f =      -87.308  |proj g|=        3.7173
At iterate     8  f =      -88.654  |proj g|=        3.7088
At iterate     9  f =       -89.36  |proj g|=       0.51185
At iterate    10  f =      -89.386  |proj g|=       0.16951
At iterate    11  f =      -89.387  |proj g|=       0.42555
At iterate    12  f =      -89.387  |proj g|=     0.0042488
At iterate    13  f =      -89.387  |proj g|=     0.0042483

iterations 13
function evaluations 22
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0042483
final function value -89.3874

F = -89.3874
final  value -89.387393 
converged
 
INFO  [08:11:45.092] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:11:45.155] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:11:45.161] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:12:27.714] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:13:09.575] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:13:51.328] [mlr3]  Finished benchmark 
INFO  [08:13:51.395] [bbotk] Result of batch 16: 
INFO  [08:13:51.397] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:13:51.397] [bbotk]                   6              3540     0.04952768        0.452 -0.9076999 
INFO  [08:13:51.397] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:13:51.397] [bbotk]          <NA>   0.9793332 d8903580-497d-415d-b63e-c301c2e3abea 
DEBUG [08:13:52.029] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.004996e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.004004996 0.4371063 
  - best initial criterion value(s) :  86.53733 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -86.537  |proj g|=       5.5437
At iterate     1  f =      -91.249  |proj g|=        3.2754
At iterate     2  f =      -94.443  |proj g|=        2.1438
At iterate     3  f =      -94.778  |proj g|=         2.134
At iterate     4  f =      -94.834  |proj g|=       0.85166
At iterate     5  f =      -96.131  |proj g|=        1.2662
At iterate     6  f =      -101.14  |proj g|=        2.0409
At iterate     7  f =      -101.43  |proj g|=       0.10378
At iterate     8  f =      -101.47  |proj g|=       0.42947
At iterate     9  f =      -101.47  |proj g|=     0.0037523
At iterate    10  f =      -101.47  |proj g|=     0.0037347
At iterate    11  f =      -101.47  |proj g|=     0.0021667

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00216665
final function value -101.471

F = -101.471
final  value -101.471390 
converged
 
INFO  [08:13:52.033] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:13:52.087] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:13:52.094] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:14:43.353] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:15:35.685] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:16:26.028] [mlr3]  Finished benchmark 
INFO  [08:16:26.092] [bbotk] Result of batch 17: 
INFO  [08:16:26.094] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:16:26.094] [bbotk]                   6              4216       0.468042        0.445 -0.9046446 
INFO  [08:16:26.094] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:16:26.094] [bbotk]          <NA>   0.9785103 e89f73a0-0c63-4da8-8f2a-f776d534a0d9 
DEBUG [08:16:26.717] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.945016e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.003945016 0.4358988 
  - best initial criterion value(s) :  68.52739 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -68.527  |proj g|=       2.5805
At iterate     1  f =      -80.432  |proj g|=        3.4823
At iterate     2  f =       -80.87  |proj g|=        3.7379
At iterate     3  f =      -81.134  |proj g|=        3.7845
At iterate     4  f =      -81.389  |proj g|=        3.9535
At iterate     5  f =      -81.547  |proj g|=        4.1191
At iterate     6  f =      -81.817  |proj g|=        4.1854
At iterate     7  f =      -82.412  |proj g|=        3.7242
At iterate     8  f =       -83.33  |proj g|=        2.9741
At iterate     9  f =      -84.229  |proj g|=        2.2106
At iterate    10  f =      -93.998  |proj g|=        4.5525
At iterate    11  f =      -94.816  |proj g|=        3.9965
At iterate    12  f =      -95.441  |proj g|=       0.34597
At iterate    13  f =      -95.463  |proj g|=       0.42807
At iterate    14  f =       -95.47  |proj g|=      0.054712
At iterate    15  f =       -95.47  |proj g|=     0.0041243
At iterate    16  f =       -95.47  |proj g|=      0.040119
At iterate    17  f =       -95.47  |proj g|=     0.0041244

iterations 17
function evaluations 24
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00412443
final function value -95.47

F = -95.47
final  value -95.469971 
converged
 
INFO  [08:16:26.721] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:16:26.777] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:16:26.783] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:16:31.200] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:16:35.303] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:16:39.611] [mlr3]  Finished benchmark 
INFO  [08:16:39.695] [bbotk] Result of batch 18: 
INFO  [08:16:39.697] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:16:39.697] [bbotk]                   6               251      0.2531401        0.436 -0.9074628 
INFO  [08:16:39.697] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:16:39.697] [bbotk]          <NA>   0.9769229 d610d37f-6080-4b40-90a2-2f8fdcde4c34 
DEBUG [08:16:40.336] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.885024e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9322 0.9552241 
  - variance bounds :  0.003885024 0.4185228 
  - best initial criterion value(s) :  80.15363 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -80.154  |proj g|=       1.9391
At iterate     1  f =      -91.097  |proj g|=        2.5837
At iterate     2  f =      -92.907  |proj g|=        1.8146
At iterate     3  f =      -92.989  |proj g|=        2.2239
At iterate     4  f =      -93.002  |proj g|=        2.2229
At iterate     5  f =      -93.032  |proj g|=        2.2108
At iterate     6  f =      -93.333  |proj g|=       0.79089
At iterate     7  f =      -93.503  |proj g|=       0.25736
At iterate     8  f =      -93.553  |proj g|=       0.31858
At iterate     9  f =      -93.557  |proj g|=      0.036725
At iterate    10  f =      -93.557  |proj g|=       0.41029
At iterate    11  f =      -93.557  |proj g|=      0.005573
At iterate    12  f =      -93.557  |proj g|=     0.0055731

iterations 12
function evaluations 17
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00557307
final function value -93.5572

F = -93.5572
final  value -93.557215 
converged
 
INFO  [08:16:40.340] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:16:40.394] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:16:40.401] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:17:38.948] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:18:38.200] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:19:38.187] [mlr3]  Finished benchmark 
INFO  [08:19:38.252] [bbotk] Result of batch 19: 
INFO  [08:19:38.254] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:19:38.254] [bbotk]                   5              4969      0.3643411        0.461 -0.9075196 
INFO  [08:19:38.254] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:19:38.254] [bbotk]          <NA>   0.9789184 62307fe6-98b2-4281-9e21-91925691fabb 
DEBUG [08:19:38.887] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.827339e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9552241 
  - variance bounds :  0.003827339 0.4112385 
  - best initial criterion value(s) :  78.66485 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -78.665  |proj g|=       2.2645
At iterate     1  f =      -81.758  |proj g|=        2.9885
At iterate     2  f =      -82.279  |proj g|=         2.715
At iterate     3  f =      -82.578  |proj g|=        2.5367
At iterate     4  f =      -82.933  |proj g|=        1.9853
At iterate     5  f =      -83.351  |proj g|=        1.9268
At iterate     6  f =      -86.065  |proj g|=        2.1317
At iterate     7  f =      -87.383  |proj g|=        2.1272
At iterate     8  f =      -87.958  |proj g|=      0.047316
At iterate     9  f =      -87.974  |proj g|=       0.35899
At iterate    10  f =      -87.981  |proj g|=       0.40251
At iterate    11  f =      -87.982  |proj g|=     0.0085927
At iterate    12  f =      -87.982  |proj g|=      0.062084
At iterate    13  f =      -87.982  |proj g|=     0.0085934

iterations 13
function evaluations 18
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00859344
final function value -87.982

F = -87.982
final  value -87.982009 
converged
 
INFO  [08:19:38.891] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:19:38.944] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:19:38.952] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:20:19.198] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:20:58.936] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:21:38.700] [mlr3]  Finished benchmark 
INFO  [08:21:38.775] [bbotk] Result of batch 20: 
INFO  [08:21:38.776] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:21:38.776] [bbotk]                   7              3262      0.3261202        0.452 -0.9089124 
INFO  [08:21:38.776] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:21:38.776] [bbotk]          <NA>   0.9788962 b49f56ac-6d7f-4865-a218-f2dee3dd1e38 
DEBUG [08:21:39.421] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.770706e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9552241 
  - variance bounds :  0.003770706 0.4163468 
  - best initial criterion value(s) :  77.84707 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -77.847  |proj g|=       6.1669
At iterate     1  f =      -79.134  |proj g|=        2.6277
At iterate     2  f =      -87.905  |proj g|=        2.8453
At iterate     3  f =      -91.369  |proj g|=        5.0071
At iterate     4  f =      -94.135  |proj g|=        4.7751
At iterate     5  f =      -99.747  |proj g|=        3.8857
At iterate     6  f =      -101.92  |proj g|=        3.7707
At iterate     7  f =      -102.36  |proj g|=         3.687
At iterate     8  f =      -105.35  |proj g|=       0.65672
At iterate     9  f =      -107.49  |proj g|=        1.9625
At iterate    10  f =         -110  |proj g|=        2.9554
At iterate    11  f =      -110.78  |proj g|=        1.6657
At iterate    12  f =      -110.88  |proj g|=      0.013374
At iterate    13  f =      -110.89  |proj g|=         0.409
At iterate    14  f =      -110.89  |proj g|=      0.021216
At iterate    15  f =      -110.89  |proj g|=     0.0037051

iterations 15
function evaluations 24
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00370514
final function value -110.89

F = -110.89
final  value -110.889638 
converged
 
INFO  [08:21:39.425] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:21:39.479] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:21:39.486] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:22:02.778] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:22:26.153] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:22:48.707] [mlr3]  Finished benchmark 
INFO  [08:22:48.773] [bbotk] Result of batch 21: 
INFO  [08:22:48.774] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:22:48.774] [bbotk]                   7              1836      0.1468069        0.452 -0.9050639 
INFO  [08:22:48.774] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:22:48.774] [bbotk]          <NA>   0.9797219 3f195325-5f34-4689-a83f-089d8a076f4a 
DEBUG [08:22:49.417] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.715623e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9552241 
  - variance bounds :  0.003715623 0.4032123 
  - best initial criterion value(s) :  90.58622 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -90.586  |proj g|=      0.58564
At iterate     1  f =       -110.8  |proj g|=         3.195
At iterate     2  f =      -115.85  |proj g|=      0.060929
At iterate     3  f =      -119.13  |proj g|=        2.9915
At iterate     4  f =      -119.15  |proj g|=        2.9913
At iterate     5  f =      -119.15  |proj g|=        2.9912
At iterate     6  f =      -119.16  |proj g|=        2.9894
At iterate     7  f =      -119.17  |proj g|=        2.9852
At iterate     8  f =      -119.22  |proj g|=        2.9717
At iterate     9  f =      -119.34  |proj g|=        2.9366
At iterate    10  f =      -119.65  |proj g|=        2.8429
At iterate    11  f =       -120.4  |proj g|=        2.6256
At iterate    12  f =      -122.12  |proj g|=        2.1775
At iterate    13  f =      -123.77  |proj g|=       0.94581
At iterate    14  f =      -123.81  |proj g|=        0.1608
At iterate    15  f =      -123.82  |proj g|=     0.0053784
At iterate    16  f =      -123.82  |proj g|=     0.0047618
At iterate    17  f =      -123.82  |proj g|=      0.003235
At iterate    18  f =      -123.82  |proj g|=     0.0023818

iterations 18
function evaluations 21
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00238181
final function value -123.815

F = -123.815
final  value -123.815479 
converged
 
INFO  [08:22:49.421] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:22:49.477] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:22:49.484] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:22:50.269] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:22:51.196] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:22:51.951] [mlr3]  Finished benchmark 
INFO  [08:22:52.028] [bbotk] Result of batch 22: 
INFO  [08:22:52.030] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:22:52.030] [bbotk]                   9              1309      0.1680756        0.445 -0.9022304 
INFO  [08:22:52.030] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:22:52.030] [bbotk]          <NA>         0.5 60098a06-29d9-4f09-9cf4-ea9c89dd961d 
DEBUG [08:22:52.662] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.923454e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9552241 
  - variance bounds :  0.003923454 0.427767 
  - best initial criterion value(s) :  105.7875 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -105.79  |proj g|=       3.5853
At iterate     1  f =      -110.46  |proj g|=        3.7968
At iterate     2  f =      -113.71  |proj g|=        3.2532
At iterate     3  f =      -115.25  |proj g|=        2.8879
At iterate     4  f =       -117.9  |proj g|=        2.1767
At iterate     5  f =      -118.47  |proj g|=        1.6448
At iterate     6  f =      -118.51  |proj g|=       0.59276
At iterate     7  f =      -118.56  |proj g|=        1.1627
At iterate     8  f =      -118.68  |proj g|=        1.9239
At iterate     9  f =      -119.23  |proj g|=        2.1155
At iterate    10  f =      -121.45  |proj g|=        2.4046
At iterate    11  f =      -121.49  |proj g|=        2.4087
At iterate    12  f =      -121.91  |proj g|=        2.4319
At iterate    13  f =      -122.71  |proj g|=        2.2283
At iterate    14  f =      -123.29  |proj g|=        1.0985
At iterate    15  f =      -123.66  |proj g|=       0.30409
At iterate    16  f =       -123.7  |proj g|=      0.049782
At iterate    17  f =       -123.7  |proj g|=        0.4209
At iterate    18  f =       -123.7  |proj g|=     0.0032046
At iterate    19  f =       -123.7  |proj g|=     0.0032047
At iterate    20  f =       -123.7  |proj g|=     0.0032047

iterations 20
function evaluations 28
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00320467
final function value -123.703

F = -123.703
final  value -123.703348 
converged
 
INFO  [08:22:52.666] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:22:52.719] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:22:52.726] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:23:48.563] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:24:45.597] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:25:42.370] [mlr3]  Finished benchmark 
INFO  [08:25:42.436] [bbotk] Result of batch 23: 
INFO  [08:25:42.437] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:25:42.437] [bbotk]                   5              4751    0.009738834        0.444 -0.9029125 
INFO  [08:25:42.437] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:25:42.437] [bbotk]          <NA>   0.9758467 9f42f462-aa57-4e14-a1c5-bad2f5856059 
DEBUG [08:25:43.089] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.868222e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9749561 
  - variance bounds :  0.003868222 0.4214016 
  - best initial criterion value(s) :  103.1595 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -103.16  |proj g|=       5.8956
At iterate     1  f =      -105.97  |proj g|=        3.2592
At iterate     2  f =       -108.6  |proj g|=        4.9637
At iterate     3  f =      -110.41  |proj g|=        5.0019
At iterate     4  f =      -111.48  |proj g|=        4.8174
At iterate     5  f =      -115.83  |proj g|=        4.2314
At iterate     6  f =      -117.26  |proj g|=        4.1063
At iterate     7  f =      -118.81  |proj g|=         3.835
At iterate     8  f =      -121.15  |proj g|=         1.712
At iterate     9  f =      -124.78  |proj g|=        2.3372
At iterate    10  f =      -129.34  |proj g|=        4.5527
At iterate    11  f =      -129.68  |proj g|=         2.456
At iterate    12  f =      -130.02  |proj g|=      0.063597
At iterate    13  f =      -130.03  |proj g|=      0.032489
At iterate    14  f =      -130.03  |proj g|=       0.41472
At iterate    15  f =      -130.03  |proj g|=     0.0029701
At iterate    16  f =      -130.03  |proj g|=     0.0029701

iterations 16
function evaluations 27
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00297008
final function value -130.026

F = -130.026
final  value -130.026133 
converged
 
INFO  [08:25:43.093] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:25:43.148] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:25:43.163] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:25:57.959] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:26:12.590] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:26:27.584] [mlr3]  Finished benchmark 
INFO  [08:26:27.660] [bbotk] Result of batch 24: 
INFO  [08:26:27.661] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:26:27.661] [bbotk]                   7              1160     0.06731576        0.446 -0.9013607 
INFO  [08:26:27.661] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:26:27.661] [bbotk]          <NA>   0.9778572 5548f70a-961c-4679-849b-ed9e5c4b75c1 
DEBUG [08:26:28.318] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.815085e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9749561 
  - variance bounds :  0.003815084 0.4083868 
  - best initial criterion value(s) :  100.673 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -100.67  |proj g|=        3.971
At iterate     1  f =      -110.56  |proj g|=        2.6719
At iterate     2  f =      -114.65  |proj g|=       0.65417
At iterate     3  f =      -115.33  |proj g|=        1.3055
At iterate     4  f =      -115.36  |proj g|=        1.0516
At iterate     5  f =      -115.36  |proj g|=        1.2923
At iterate     6  f =      -117.31  |proj g|=       0.97848
At iterate     7  f =      -117.37  |proj g|=       0.29305
At iterate     8  f =      -117.37  |proj g|=       0.40125
At iterate     9  f =      -117.37  |proj g|=     0.0069453
At iterate    10  f =      -117.37  |proj g|=     0.0069453

iterations 10
function evaluations 18
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00694531
final function value -117.366

F = -117.366
final  value -117.366045 
converged
 
INFO  [08:26:28.324] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:26:28.379] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:26:28.386] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:26:29.153] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:26:29.886] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:26:30.753] [mlr3]  Finished benchmark 
INFO  [08:26:30.817] [bbotk] Result of batch 25: 
INFO  [08:26:30.819] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [08:26:30.819] [bbotk]                  10              2478     0.08147736        0.462  -0.90333 
INFO  [08:26:30.819] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:26:30.819] [bbotk]          <NA>         0.5 515c601a-2d58-4112-96fc-17e64af00be9 
DEBUG [08:26:31.473] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.003622e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9749561 
  - variance bounds :  0.004003622 0.4236708 
  - best initial criterion value(s) :  114.733 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -114.73  |proj g|=       4.4651
At iterate     1  f =      -126.91  |proj g|=        4.9472
At iterate     2  f =      -135.73  |proj g|=        1.2828
At iterate     3  f =      -135.74  |proj g|=        1.3178
At iterate     4  f =      -135.74  |proj g|=        1.5648
At iterate     5  f =      -135.75  |proj g|=        1.4984
At iterate     6  f =      -135.85  |proj g|=        1.0605
At iterate     7  f =      -136.09  |proj g|=       0.45732
At iterate     8  f =       -136.7  |proj g|=       0.36512
At iterate     9  f =      -137.48  |proj g|=        1.2909
At iterate    10  f =      -137.67  |proj g|=        1.9963
At iterate    11  f =      -137.84  |proj g|=        1.7568
At iterate    12  f =      -137.96  |proj g|=       0.41729
At iterate    13  f =      -137.96  |proj g|=      0.056557
At iterate    14  f =      -137.96  |proj g|=       0.24813
At iterate    15  f =      -137.96  |proj g|=     0.0033772
At iterate    16  f =      -137.96  |proj g|=     0.0033772

iterations 16
function evaluations 22
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00337723
final function value -137.963

F = -137.963
final  value -137.963224 
converged
 
INFO  [08:26:31.477] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:26:31.531] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:26:31.537] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:27:23.433] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:28:14.680] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:29:06.417] [mlr3]  Finished benchmark 
INFO  [08:29:06.491] [bbotk] Result of batch 26: 
INFO  [08:29:06.493] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:29:06.493] [bbotk]                   3              4301      0.1391687        0.458 -0.8978333 
INFO  [08:29:06.493] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:29:06.493] [bbotk]          <NA>   0.9779989 846e2022-3957-47b6-866c-1143dd3070b8 
DEBUG [08:29:07.162] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.952453e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9749561 
  - variance bounds :  0.003952453 0.4221171 
  - best initial criterion value(s) :  106.3036 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -106.3  |proj g|=       6.2699
At iterate     1  f =      -119.19  |proj g|=        3.9257
At iterate     2  f =      -121.26  |proj g|=        3.2331
At iterate     3  f =      -122.31  |proj g|=        2.8291
At iterate     4  f =      -122.63  |proj g|=        2.5731
At iterate     5  f =      -122.79  |proj g|=        2.3621
At iterate     6  f =      -123.32  |proj g|=        2.4067
At iterate     7  f =      -126.99  |proj g|=        2.6207
At iterate     8  f =      -133.31  |proj g|=        2.6909
At iterate     9  f =      -142.44  |proj g|=        2.4996
At iterate    10  f =      -144.02  |proj g|=        2.0735
At iterate    11  f =      -145.14  |proj g|=       0.41591
At iterate    12  f =      -145.15  |proj g|=      0.095142
At iterate    13  f =      -145.15  |proj g|=      0.003094
At iterate    14  f =      -145.15  |proj g|=     0.0030425
At iterate    15  f =      -145.15  |proj g|=     0.0030425

iterations 15
function evaluations 21
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00304248
final function value -145.148

F = -145.148
final  value -145.147597 
converged
 
INFO  [08:29:07.166] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:29:07.219] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:29:07.225] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:30:06.272] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:31:04.878] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:32:03.644] [mlr3]  Finished benchmark 
INFO  [08:32:03.709] [bbotk] Result of batch 27: 
INFO  [08:32:03.711] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:32:03.711] [bbotk]                   6              4866      0.3547986        0.468 -0.8964237 
INFO  [08:32:03.711] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:32:03.711] [bbotk]          <NA>   0.9786464 a7c4e7ce-6841-433f-9667-4d90b760651c 
DEBUG [08:32:04.384] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.902429e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9749561 
  - variance bounds :  0.003902429 0.4161804 
  - best initial criterion value(s) :  113.39 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -113.39  |proj g|=       5.7317
At iterate     1  f =      -120.39  |proj g|=        4.3302
At iterate     2  f =      -123.47  |proj g|=        3.9181
At iterate     3  f =       -125.5  |proj g|=         3.573
At iterate     4  f =      -128.14  |proj g|=        3.0876
At iterate     5  f =      -131.57  |proj g|=        2.5739
At iterate     6  f =      -136.99  |proj g|=        1.3132
At iterate     7  f =      -137.93  |proj g|=       0.24999
At iterate     8  f =      -138.53  |proj g|=       0.16675
At iterate     9  f =      -138.56  |proj g|=       0.12017
At iterate    10  f =      -138.56  |proj g|=      0.037067
At iterate    11  f =      -138.56  |proj g|=        0.4097
At iterate    12  f =      -138.56  |proj g|=     0.0049916
At iterate    13  f =      -138.56  |proj g|=      0.034516

iterations 13
function evaluations 22
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0345158
final function value -138.558

F = -138.558
final  value -138.558244 
converged
 
INFO  [08:32:04.388] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:32:04.442] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:32:04.449] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:32:24.779] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:32:46.908] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:33:08.169] [mlr3]  Finished benchmark 
INFO  [08:33:08.235] [bbotk] Result of batch 28: 
INFO  [08:33:08.237] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:33:08.237] [bbotk]                   5              1669      0.2066199        0.472 -0.8980377 
INFO  [08:33:08.237] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:33:08.237] [bbotk]          <NA>   0.9795748 a94a4d08-346e-49da-b27f-153ba5c2778d 
DEBUG [08:33:08.920] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.853672e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9749561 
  - variance bounds :  0.003853672 0.4058734 
  - best initial criterion value(s) :  112.9578 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -112.96  |proj g|=        4.263
At iterate     1  f =      -134.09  |proj g|=        2.6628
At iterate     2  f =      -145.04  |proj g|=       0.48743
At iterate     3  f =      -145.34  |proj g|=       0.42915
At iterate     4  f =      -145.55  |proj g|=        3.0674
At iterate     5  f =      -145.56  |proj g|=        3.1262
At iterate     6  f =      -145.56  |proj g|=        3.0917
At iterate     7  f =      -145.59  |proj g|=        2.9069
At iterate     8  f =      -145.64  |proj g|=        2.6798
At iterate     9  f =      -145.81  |proj g|=        2.1865
At iterate    10  f =      -146.23  |proj g|=        1.1405
At iterate    11  f =      -147.39  |proj g|=       0.94218
At iterate    12  f =      -147.98  |proj g|=       0.40095
At iterate    13  f =       -148.4  |proj g|=       0.89304
At iterate    14  f =      -148.47  |proj g|=        1.2829
At iterate    15  f =      -148.48  |proj g|=          1.43
At iterate    16  f =      -148.48  |proj g|=        1.4576
At iterate    17  f =      -148.48  |proj g|=        1.4663
At iterate    18  f =      -148.49  |proj g|=        1.4243
At iterate    19  f =       -148.5  |proj g|=        1.2311
At iterate    20  f =      -148.53  |proj g|=       0.72221
At iterate    21  f =      -148.55  |proj g|=       0.39975
At iterate    22  f =      -148.55  |proj g|=     0.0040823
At iterate    23  f =      -148.55  |proj g|=      0.037122
At iterate    24  f =      -148.55  |proj g|=     0.0040824

iterations 24
function evaluations 33
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00408238
final function value -148.551

F = -148.551
final  value -148.551460 
converged
 
INFO  [08:33:08.924] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:33:08.978] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:33:08.985] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:33:09.869] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:33:10.622] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:33:11.371] [mlr3]  Finished benchmark 
INFO  [08:33:11.435] [bbotk] Result of batch 29: 
INFO  [08:33:11.437] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:33:11.437] [bbotk]                  10              4117      0.3848401        0.485 -0.8960737 
INFO  [08:33:11.437] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:33:11.437] [bbotk]          <NA>         0.5 9e6457a5-5b77-42a4-b71e-2fd16d0ed7e2 
DEBUG [08:33:12.119] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.026991e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9749561 
  - variance bounds :  0.004026991 0.4156591 
  - best initial criterion value(s) :  115.4336 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -115.43  |proj g|=        3.234
At iterate     1  f =      -125.04  |proj g|=        2.1561
At iterate     2  f =      -130.65  |proj g|=        5.7208
At iterate     3  f =      -131.44  |proj g|=        1.6089
At iterate     4  f =      -131.57  |proj g|=       0.70441
At iterate     5  f =      -131.58  |proj g|=       0.30867
At iterate     6  f =      -131.59  |proj g|=       0.40891
At iterate     7  f =      -131.59  |proj g|=       0.40896
At iterate     8  f =       -131.6  |proj g|=       0.41064
At iterate     9  f =      -131.62  |proj g|=       0.51697
At iterate    10  f =      -131.69  |proj g|=        0.7818
At iterate    11  f =      -131.78  |proj g|=        1.1234
At iterate    12  f =      -131.86  |proj g|=       0.92006
At iterate    13  f =       -131.9  |proj g|=       0.44856
At iterate    14  f =       -131.9  |proj g|=      0.094787
At iterate    15  f =       -131.9  |proj g|=       0.40883
At iterate    16  f =       -131.9  |proj g|=      0.082453
At iterate    17  f =       -131.9  |proj g|=     0.0088849

iterations 17
function evaluations 25
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00888486
final function value -131.903

F = -131.903
final  value -131.903184 
converged
 
INFO  [08:33:12.123] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:33:12.178] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:33:12.184] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:33:12.917] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:33:13.785] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:33:14.516] [mlr3]  Finished benchmark 
INFO  [08:33:14.592] [bbotk] Result of batch 30: 
INFO  [08:33:14.594] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:33:14.594] [bbotk]                  10              1273      0.3718013        0.478 -0.8957555 
INFO  [08:33:14.594] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:33:14.594] [bbotk]          <NA>         0.5 c0e89e8e-8301-4e5b-8471-21034b634767 
DEBUG [08:33:15.296] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.184432e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9749561 
  - variance bounds :  0.004184432 0.4354532 
  - best initial criterion value(s) :  106.5649 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -106.56  |proj g|=       3.3175
At iterate     1  f =       -114.4  |proj g|=         3.369
At iterate     2  f =      -117.73  |proj g|=        4.2306
At iterate     3  f =      -119.02  |proj g|=        4.0699
At iterate     4  f =      -121.92  |proj g|=        3.5704
At iterate     5  f =      -127.02  |proj g|=        2.6731
At iterate     6  f =      -129.76  |proj g|=         2.184
At iterate     7  f =      -129.99  |proj g|=        1.9991
At iterate     8  f =      -130.08  |proj g|=       0.94052
At iterate     9  f =      -130.11  |proj g|=        1.5487
At iterate    10  f =      -130.11  |proj g|=        1.6627
At iterate    11  f =      -130.14  |proj g|=        1.9342
At iterate    12  f =      -130.19  |proj g|=        1.9429
At iterate    13  f =      -130.32  |proj g|=        1.9506
At iterate    14  f =      -130.67  |proj g|=        1.9519
At iterate    15  f =      -131.61  |proj g|=         1.932
At iterate    16  f =      -134.12  |proj g|=        1.8498
At iterate    17  f =      -136.66  |proj g|=        1.8054
At iterate    18  f =      -137.27  |proj g|=        1.3683
At iterate    19  f =      -137.39  |proj g|=       0.58267
At iterate    20  f =      -137.41  |proj g|=       0.42872
At iterate    21  f =      -137.41  |proj g|=       0.20328
At iterate    22  f =      -137.41  |proj g|=        0.1989
At iterate    23  f =      -137.41  |proj g|=       0.19437
At iterate    24  f =      -137.41  |proj g|=       0.18316
At iterate    25  f =      -137.41  |proj g|=       0.15607
At iterate    26  f =      -137.41  |proj g|=       0.11104
At iterate    27  f =      -137.41  |proj g|=      0.041841
At iterate    28  f =      -137.41  |proj g|=      0.016282
At iterate    29  f =      -137.41  |proj g|=      0.010051
At iterate    30  f =      -137.41  |proj g|=     0.0084168
At iterate    31  f =      -137.41  |proj g|=     0.0084169

iterations 31
function evaluations 41
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00841686
final function value -137.409

F = -137.409
final  value -137.409109 
converged
 
INFO  [08:33:15.300] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:33:15.354] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:33:15.361] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:33:33.932] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:33:52.614] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:34:10.592] [mlr3]  Finished benchmark 
INFO  [08:34:10.657] [bbotk] Result of batch 31: 
INFO  [08:34:10.659] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:34:10.659] [bbotk]                   6              1402       0.390764        0.481 -0.8909946 
INFO  [08:34:10.659] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:34:10.659] [bbotk]          <NA>   0.9797172 138e61a2-d2e9-490b-8989-0da9a4f58a52 
DEBUG [08:34:11.442] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.138507e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9749561 
  - variance bounds :  0.004138507 0.4249906 
  - best initial criterion value(s) :  136.9846 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -136.98  |proj g|=        4.399
At iterate     1  f =      -147.54  |proj g|=        5.8841
At iterate     2  f =         -158  |proj g|=         1.381
At iterate     3  f =      -158.01  |proj g|=        1.0846
At iterate     4  f =      -158.01  |proj g|=       0.86799
At iterate     5  f =      -159.54  |proj g|=       0.69226
At iterate     6  f =      -159.57  |proj g|=       0.41888
At iterate     7  f =      -159.57  |proj g|=       0.33674
At iterate     8  f =      -159.57  |proj g|=     0.0044766

iterations 8
function evaluations 16
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00447662
final function value -159.57

F = -159.57
final  value -159.570437 
converged
 
INFO  [08:34:11.446] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:34:11.502] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:34:11.509] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:34:59.801] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:35:49.629] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:36:38.203] [mlr3]  Finished benchmark 
INFO  [08:36:38.269] [bbotk] Result of batch 32: 
INFO  [08:36:38.271] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:36:38.271] [bbotk]                   3              4041      0.4260835         0.58 -0.8867471 
INFO  [08:36:38.271] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:36:38.271] [bbotk]          <NA>   0.9788509 6321b1f2-04f3-4f7d-8349-bdd3837afb19 
DEBUG [08:36:38.966] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.092693e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9749561 
  - variance bounds :  0.004092693 0.4237707 
  - best initial criterion value(s) :  141.3251 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -141.33  |proj g|=      0.15334
At iterate     1  f =      -150.59  |proj g|=        4.0741
At iterate     2  f =      -151.22  |proj g|=        4.0712
At iterate     3  f =      -154.18  |proj g|=        4.0029
At iterate     4  f =      -154.19  |proj g|=        4.0025
At iterate     5  f =      -154.19  |proj g|=        4.0015
At iterate     6  f =       -154.2  |proj g|=        3.9998
At iterate     7  f =      -154.24  |proj g|=        3.9919
At iterate     8  f =      -154.34  |proj g|=         3.973
At iterate     9  f =       -154.6  |proj g|=        3.9177
At iterate    10  f =      -155.27  |proj g|=        3.7774
At iterate    11  f =      -157.03  |proj g|=        3.4281
At iterate    12  f =      -161.79  |proj g|=        2.6925
At iterate    13  f =      -168.53  |proj g|=        1.8836
At iterate    14  f =      -168.82  |proj g|=       0.73558
At iterate    15  f =       -168.9  |proj g|=       0.67716
At iterate    16  f =      -168.91  |proj g|=      0.032849
At iterate    17  f =      -168.91  |proj g|=       0.41784
At iterate    18  f =      -168.91  |proj g|=      0.003977
At iterate    19  f =      -168.91  |proj g|=      0.003977

iterations 19
function evaluations 25
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00397695
final function value -168.914

F = -168.914
final  value -168.914275 
converged
 
INFO  [08:36:38.970] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:36:39.024] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:36:39.031] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:36:53.525] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:37:07.894] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:37:22.374] [mlr3]  Finished benchmark 
INFO  [08:37:22.440] [bbotk] Result of batch 33: 
INFO  [08:37:22.442] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:37:22.442] [bbotk]                   3              1130       0.135424        0.473 -0.8857657 
INFO  [08:37:22.442] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:37:22.442] [bbotk]          <NA>   0.9754093 597ff0db-2027-40e3-b861-71d2adf8e422 
DEBUG [08:37:23.218] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.045914e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9749561 
  - variance bounds :  0.004045914 0.4132449 
  - best initial criterion value(s) :  156.3757 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -156.38  |proj g|=      0.25379
At iterate     1  f =      -161.11  |proj g|=        3.0327
At iterate     2  f =      -161.91  |proj g|=        3.0724
At iterate     3  f =      -161.93  |proj g|=        3.0749
At iterate     4  f =      -162.27  |proj g|=        3.1473
At iterate     5  f =      -162.37  |proj g|=        3.1656
At iterate     6  f =       -162.4  |proj g|=        3.1641
At iterate     7  f =      -162.41  |proj g|=        3.1624
At iterate     8  f =      -162.44  |proj g|=        3.1568
At iterate     9  f =      -162.53  |proj g|=        3.1397
At iterate    10  f =      -162.75  |proj g|=         3.094
At iterate    11  f =      -163.32  |proj g|=        2.9736
At iterate    12  f =      -164.72  |proj g|=        2.6943
At iterate    13  f =      -167.99  |proj g|=        2.1244
At iterate    14  f =      -169.96  |proj g|=         2.754
At iterate    15  f =       -170.2  |proj g|=       0.29951
At iterate    16  f =      -170.22  |proj g|=        0.4074
At iterate    17  f =      -170.23  |proj g|=     0.0046076
At iterate    18  f =      -170.23  |proj g|=      0.049887
At iterate    19  f =      -170.23  |proj g|=     0.0046076

iterations 19
function evaluations 22
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00460763
final function value -170.225

F = -170.225
final  value -170.225229 
converged
 
INFO  [08:37:23.222] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:37:23.275] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:37:23.282] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:37:29.658] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:37:36.512] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:37:42.917] [mlr3]  Finished benchmark 
INFO  [08:37:42.990] [bbotk] Result of batch 34: 
INFO  [08:37:42.992] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:37:42.992] [bbotk]                   7               413      0.3156729        0.568 -0.8854109 
INFO  [08:37:42.992] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:37:42.992] [bbotk]          <NA>   0.9791746 83371ecb-4b50-4ccc-83f4-f6be457cb44b 
DEBUG [08:37:43.682] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.001492e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9749561 
  - variance bounds :  0.004001492 0.4072227 
  - best initial criterion value(s) :  135.0282 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -135.03  |proj g|=       4.4542
At iterate     1  f =      -170.53  |proj g|=        1.2497
At iterate     2  f =      -172.77  |proj g|=        3.3298
At iterate     3  f =      -177.54  |proj g|=         2.838
At iterate     4  f =      -178.11  |proj g|=        2.7703
At iterate     5  f =      -180.04  |proj g|=        2.5089
At iterate     6  f =      -181.84  |proj g|=        2.1892
At iterate     7  f =      -182.46  |proj g|=        3.6195
At iterate     8  f =      -182.67  |proj g|=       0.78182
At iterate     9  f =      -182.92  |proj g|=        1.1945
At iterate    10  f =      -182.96  |proj g|=        0.4016
At iterate    11  f =      -182.96  |proj g|=       0.40161
At iterate    12  f =      -182.96  |proj g|=      0.003657
At iterate    13  f =      -182.96  |proj g|=     0.0036571

iterations 13
function evaluations 21
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00365705
final function value -182.962

F = -182.962
final  value -182.962275 
converged
 
INFO  [08:37:43.686] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:37:43.746] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:37:43.754] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:38:36.122] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:39:27.823] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:40:19.360] [mlr3]  Finished benchmark 
INFO  [08:40:19.425] [bbotk] Result of batch 35: 
INFO  [08:40:19.427] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [08:40:19.427] [bbotk]                   7              4254      0.4995521        0.492 -0.884328 
INFO  [08:40:19.427] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:40:19.427] [bbotk]          <NA>   0.9779432 5e319a0e-dde2-4613-bc7c-d8f903289124 
DEBUG [08:40:20.154] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.957163e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9796266 
  - variance bounds :  0.003957163 0.4072376 
  - best initial criterion value(s) :  149.1675 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -149.17  |proj g|=       4.1026
At iterate     1  f =      -156.14  |proj g|=        4.4394
At iterate     2  f =       -160.3  |proj g|=        3.8942
At iterate     3  f =      -162.04  |proj g|=        3.5835
At iterate     4  f =      -164.71  |proj g|=        3.0851
At iterate     5  f =      -168.42  |proj g|=        2.5067
At iterate     6  f =      -169.89  |proj g|=        1.3919
At iterate     7  f =      -170.29  |proj g|=        1.4699
At iterate     8  f =      -170.41  |proj g|=        1.9738
At iterate     9  f =      -170.45  |proj g|=        1.9365
At iterate    10  f =      -170.59  |proj g|=        1.1601
At iterate    11  f =      -171.07  |proj g|=       0.47174
At iterate    12  f =      -172.02  |proj g|=        2.2272
At iterate    13  f =       -174.2  |proj g|=        3.9669
At iterate    14  f =      -177.38  |proj g|=        5.4823
At iterate    15  f =      -179.08  |proj g|=        7.5808
At iterate    16  f =      -179.63  |proj g|=        7.8044
At iterate    17  f =      -180.89  |proj g|=        3.3567
At iterate    18  f =      -181.25  |proj g|=      0.071254
At iterate    19  f =      -181.26  |proj g|=       0.40159
At iterate    20  f =      -181.26  |proj g|=     0.0044886
At iterate    21  f =      -181.26  |proj g|=     0.0057656
At iterate    22  f =      -181.26  |proj g|=     0.0044887

iterations 22
function evaluations 31
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00448868
final function value -181.256

F = -181.256
final  value -181.256295 
converged
 
INFO  [08:40:20.156] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:40:20.200] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:40:20.206] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:40:20.979] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:40:21.750] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:40:22.956] [mlr3]  Finished benchmark 
INFO  [08:40:23.029] [bbotk] Result of batch 36: 
INFO  [08:40:23.031] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:40:23.031] [bbotk]                   9              4586      0.4303095        0.514 -0.8864642 
INFO  [08:40:23.031] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:40:23.031] [bbotk]          <NA>         0.5 c6fcbc77-723b-4951-84c7-456bff8a96b8 
DEBUG [08:40:23.742] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.105624e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9486 0.9796266 
  - variance bounds :  0.004105624 0.4214102 
  - best initial criterion value(s) :  141.0036 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -141  |proj g|=      0.34343
At iterate     1  f =      -152.66  |proj g|=        4.2725
At iterate     2  f =      -153.43  |proj g|=        4.2433
At iterate     3  f =      -155.03  |proj g|=        4.1852
At iterate     4  f =      -156.63  |proj g|=        4.1155
At iterate     5  f =      -156.69  |proj g|=        4.1087
At iterate     6  f =      -156.78  |proj g|=        4.0937
At iterate     7  f =      -156.93  |proj g|=        4.0669
At iterate     8  f =      -157.52  |proj g|=        3.9506
At iterate     9  f =      -158.74  |proj g|=        3.7433
At iterate    10  f =       -160.7  |proj g|=         3.488
At iterate    11  f =      -165.25  |proj g|=        3.0064
At iterate    12  f =      -172.71  |proj g|=        1.7072
At iterate    13  f =      -174.11  |proj g|=        2.9106
At iterate    14  f =      -174.31  |proj g|=        1.2043
At iterate    15  f =      -174.35  |proj g|=      0.017235
At iterate    16  f =      -174.36  |proj g|=      0.038256
At iterate    17  f =      -174.36  |proj g|=       0.41557
At iterate    18  f =      -174.36  |proj g|=     0.0064517
At iterate    19  f =      -174.36  |proj g|=     0.0087785

iterations 19
function evaluations 28
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00877846
final function value -174.356

F = -174.356
final  value -174.356360 
converged
 
INFO  [08:40:23.746] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:40:23.800] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:40:23.806] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:41:24.045] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:42:25.250] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:43:24.684] [mlr3]  Finished benchmark 
INFO  [08:43:24.750] [bbotk] Result of batch 37: 
INFO  [08:43:24.752] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:43:24.752] [bbotk]                   7              4981      0.1875149        0.499 -0.8881195 
INFO  [08:43:24.752] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:43:24.752] [bbotk]          <NA>   0.9790696 865ec30d-ac9f-4433-b1ce-3bc0b2db43ea 
DEBUG [08:43:25.469] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.063162e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004063162 0.4201007 
  - best initial criterion value(s) :  148.4228 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -148.42  |proj g|=       3.5906
At iterate     1  f =      -154.43  |proj g|=        5.3121
At iterate     2  f =      -163.67  |proj g|=        1.5337
At iterate     3  f =      -163.72  |proj g|=       0.17508
At iterate     4  f =      -163.73  |proj g|=       0.41398
At iterate     5  f =      -163.84  |proj g|=       0.41409
At iterate     6  f =      -163.84  |proj g|=       0.41401
At iterate     7  f =      -163.84  |proj g|=       0.41394
At iterate     8  f =      -163.84  |proj g|=      0.050049
At iterate     9  f =      -163.84  |proj g|=     0.0097933

iterations 9
function evaluations 18
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00979329
final function value -163.842

F = -163.842
final  value -163.841713 
converged
 
INFO  [08:43:25.473] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:43:25.534] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:43:25.541] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:43:45.477] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:44:04.704] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:44:23.737] [mlr3]  Finished benchmark 
INFO  [08:44:23.802] [bbotk] Result of batch 38: 
INFO  [08:44:23.804] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:44:23.804] [bbotk]                   4              1545     0.09574929        0.527 -0.8913157 
INFO  [08:44:23.804] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:44:23.804] [bbotk]          <NA>   0.9781898 3fb4959b-acbe-4b47-b931-a6fc87fbda60 
DEBUG [08:44:24.544] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.020881e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004020881 0.4117471 
  - best initial criterion value(s) :  140.3809 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -140.38  |proj g|=       6.3564
At iterate     1  f =      -142.44  |proj g|=        4.0943
At iterate     2  f =      -165.04  |proj g|=        3.9344
At iterate     3  f =      -171.43  |proj g|=        1.5881
At iterate     4  f =      -177.67  |proj g|=        2.8928
At iterate     5  f =      -179.16  |proj g|=        2.8495
At iterate     6  f =      -179.66  |proj g|=        2.7327
At iterate     7  f =      -181.04  |proj g|=        2.6057
At iterate     8  f =      -184.16  |proj g|=        2.1122
At iterate     9  f =      -184.58  |proj g|=        1.5252
At iterate    10  f =      -184.87  |proj g|=       0.74857
At iterate    11  f =      -184.96  |proj g|=       0.30574
At iterate    12  f =      -184.97  |proj g|=       0.40611
At iterate    13  f =      -184.97  |proj g|=       0.01454
At iterate    14  f =      -184.97  |proj g|=     0.0059804
At iterate    15  f =      -184.97  |proj g|=     0.0059804

iterations 15
function evaluations 24
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00598038
final function value -184.974

F = -184.974
final  value -184.974029 
converged
 
INFO  [08:44:24.548] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:44:24.613] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:44:24.620] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:45:16.629] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:46:08.604] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:47:01.327] [mlr3]  Finished benchmark 
INFO  [08:47:01.415] [bbotk] Result of batch 39: 
INFO  [08:47:01.417] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:47:01.417] [bbotk]                   7              4337       0.243491        0.531 -0.8872911 
INFO  [08:47:01.417] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:47:01.417] [bbotk]          <NA>   0.9788915 ee120aec-875b-4dac-a5d8-9f37569de88c 
DEBUG [08:47:02.119] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.979458e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.003979458 0.4110792 
  - best initial criterion value(s) :  164.7455 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -164.75  |proj g|=       1.4318
At iterate     1  f =         -190  |proj g|=        3.0851
At iterate     2  f =      -193.75  |proj g|=        2.8433
At iterate     3  f =      -193.81  |proj g|=        2.8413
At iterate     4  f =      -194.11  |proj g|=        2.8047
At iterate     5  f =      -194.97  |proj g|=        2.6313
At iterate     6  f =      -196.49  |proj g|=        2.4079
At iterate     7  f =      -198.79  |proj g|=        4.9699
At iterate     8  f =      -199.32  |proj g|=       0.19595
At iterate     9  f =      -199.52  |proj g|=       0.51326
At iterate    10  f =      -199.54  |proj g|=       0.40573
At iterate    11  f =      -199.54  |proj g|=       0.03517
At iterate    12  f =      -199.54  |proj g|=       0.40568
At iterate    13  f =      -199.54  |proj g|=     0.0045094
At iterate    14  f =      -199.54  |proj g|=     0.0045094

iterations 14
function evaluations 21
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00450935
final function value -199.539

F = -199.539
final  value -199.538572 
converged
 
INFO  [08:47:02.123] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:47:02.179] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:47:02.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:47:02.960] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:47:03.715] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:47:04.596] [mlr3]  Finished benchmark 
INFO  [08:47:04.660] [bbotk] Result of batch 40: 
INFO  [08:47:04.662] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:47:04.662] [bbotk]                   9               664      0.2036003        0.502 -0.8858169 
INFO  [08:47:04.662] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:47:04.662] [bbotk]          <NA>         0.5 75131967-4cf4-452c-94f6-c8c1aed2207b 
DEBUG [08:47:05.383] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.118311e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004118311 0.4316875 
  - best initial criterion value(s) :  150.6877 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -150.69  |proj g|=       4.3552
At iterate     1  f =      -163.57  |proj g|=        5.0369
At iterate     2  f =      -177.85  |proj g|=        5.8645
At iterate     3  f =      -178.56  |proj g|=       0.89712
At iterate     4  f =      -178.57  |proj g|=       0.83593
At iterate     5  f =      -178.58  |proj g|=       0.57963
At iterate     6  f =      -178.69  |proj g|=       0.42605
At iterate     7  f =      -179.39  |proj g|=        1.1602
At iterate     8  f =      -179.51  |proj g|=       0.98411
At iterate     9  f =      -179.56  |proj g|=       0.42589
At iterate    10  f =      -179.56  |proj g|=       0.42583
At iterate    11  f =      -179.56  |proj g|=       0.21362
At iterate    12  f =      -179.56  |proj g|=     0.0094352
At iterate    13  f =      -179.56  |proj g|=     0.0094352
At iterate    14  f =      -179.56  |proj g|=     0.0094352

iterations 14
function evaluations 24
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00943524
final function value -179.564

F = -179.564
final  value -179.564073 
converged
 
INFO  [08:47:05.387] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:47:05.453] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:47:05.460] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:47:37.238] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:48:09.391] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:48:40.841] [mlr3]  Finished benchmark 
INFO  [08:48:40.914] [bbotk] Result of batch 41: 
INFO  [08:48:40.916] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:48:40.916] [bbotk]                   5              2628      0.1197201        0.512 -0.8888579 
INFO  [08:48:40.916] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:48:40.916] [bbotk]          <NA>     0.97956 646f1635-bc83-4cf6-a918-e1fac88a28ee 
DEBUG [08:48:41.659] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.078376e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004078376 0.4262177 
  - best initial criterion value(s) :  178.0872 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -178.09  |proj g|=       5.8165
At iterate     1  f =      -183.93  |proj g|=       0.97398
At iterate     2  f =      -193.66  |proj g|=        3.3173
At iterate     3  f =      -196.96  |proj g|=        2.9424
At iterate     4  f =      -201.26  |proj g|=        2.4238
At iterate     5  f =       -202.9  |proj g|=        2.1922
At iterate     6  f =      -203.75  |proj g|=        1.9821
At iterate     7  f =      -204.02  |proj g|=       0.77147
At iterate     8  f =      -204.08  |proj g|=       0.24709
At iterate     9  f =       -204.1  |proj g|=       0.64721
At iterate    10  f =      -204.13  |proj g|=       0.94954
At iterate    11  f =       -204.3  |proj g|=        1.8182
At iterate    12  f =      -204.68  |proj g|=        1.8359
At iterate    13  f =      -205.76  |proj g|=          1.88
At iterate    14  f =      -206.23  |proj g|=        1.8729
At iterate    15  f =       -206.6  |proj g|=        1.8608
At iterate    16  f =      -206.64  |proj g|=        1.3494
At iterate    17  f =      -206.64  |proj g|=        1.1659
At iterate    18  f =      -206.64  |proj g|=        1.1338
At iterate    19  f =      -206.64  |proj g|=        1.0143
At iterate    20  f =      -206.65  |proj g|=       0.78818
At iterate    21  f =      -206.66  |proj g|=       0.41814
At iterate    22  f =      -206.68  |proj g|=      0.022583
At iterate    23  f =      -206.69  |proj g|=       0.30372
At iterate    24  f =      -206.69  |proj g|=       0.42092
At iterate    25  f =      -206.69  |proj g|=     0.0051855
At iterate    26  f =      -206.69  |proj g|=     0.0074995

iterations 26
function evaluations 36
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00749954
final function value -206.692

F = -206.692
final  value -206.691837 
converged
 
INFO  [08:48:41.663] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:48:41.714] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:48:41.721] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:48:42.445] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:48:43.163] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:48:44.012] [mlr3]  Finished benchmark 
INFO  [08:48:44.077] [bbotk] Result of batch 42: 
INFO  [08:48:44.078] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:48:44.078] [bbotk]                  10              1883       0.451375         0.52 -0.8845638 
INFO  [08:48:44.078] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:48:44.078] [bbotk]          <NA>         0.5 4aeca350-97e4-424d-859f-517f7b9517b2 
DEBUG [08:48:44.809] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.207409e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004207409 0.4369535 
  - best initial criterion value(s) :  143.3083 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -143.31  |proj g|=       7.6457
At iterate     1  f =      -155.68  |proj g|=        2.0789
At iterate     2  f =      -165.86  |proj g|=        6.3262
At iterate     3  f =       -171.2  |proj g|=        6.0456
At iterate     4  f =      -178.91  |proj g|=         5.244
At iterate     5  f =      -187.19  |proj g|=        4.6621
At iterate     6  f =      -193.35  |proj g|=        3.9822
At iterate     7  f =      -208.39  |proj g|=        2.3721
At iterate     8  f =      -210.19  |proj g|=       0.57653
At iterate     9  f =      -210.56  |proj g|=        2.9157
At iterate    10  f =       -210.8  |proj g|=        1.2846
At iterate    11  f =      -210.84  |proj g|=       0.43172
At iterate    12  f =      -210.84  |proj g|=       0.43171
At iterate    13  f =      -210.84  |proj g|=       0.43171
At iterate    14  f =      -210.84  |proj g|=     0.0053509
At iterate    15  f =      -210.84  |proj g|=      0.017309

iterations 15
function evaluations 27
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.017309
final function value -210.837

F = -210.837
final  value -210.836528 
converged
 
INFO  [08:48:44.813] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:48:44.868] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:48:44.874] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:49:30.898] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:50:17.207] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:51:02.888] [mlr3]  Finished benchmark 
INFO  [08:51:02.953] [bbotk] Result of batch 43: 
INFO  [08:51:02.955] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:51:02.955] [bbotk]                   4              3816      0.4899165        0.518 -0.8836891 
INFO  [08:51:02.955] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:51:02.955] [bbotk]          <NA>   0.9789465 42697fe9-14b8-434c-a36e-54221b70b821 
DEBUG [08:51:03.704] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.168454e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004168454 0.435917 
  - best initial criterion value(s) :  156.7194 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -156.72  |proj g|=       4.5417
At iterate     1  f =      -157.12  |proj g|=        4.4151
At iterate     2  f =      -157.85  |proj g|=        4.4321
At iterate     3  f =      -158.55  |proj g|=         4.397
At iterate     4  f =      -159.36  |proj g|=        4.3386
At iterate     5  f =      -164.31  |proj g|=        3.8212
At iterate     6  f =      -171.73  |proj g|=        3.0608
At iterate     7  f =      -173.16  |proj g|=          3.05
At iterate     8  f =      -174.07  |proj g|=        3.0084
At iterate     9  f =      -174.51  |proj g|=        2.9461
At iterate    10  f =      -175.95  |proj g|=        2.7181
At iterate    11  f =      -178.49  |proj g|=        2.0819
At iterate    12  f =      -181.42  |proj g|=        2.1242
At iterate    13  f =      -181.54  |proj g|=       0.18763
At iterate    14  f =      -181.56  |proj g|=       0.42999
At iterate    15  f =      -181.56  |proj g|=      0.084286
At iterate    16  f =      -181.56  |proj g|=      0.012593

iterations 16
function evaluations 21
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0125928
final function value -181.564

F = -181.564
final  value -181.563613 
converged
 
INFO  [08:51:03.708] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:51:03.769] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:51:03.776] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:51:23.839] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:51:43.842] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:52:03.059] [mlr3]  Finished benchmark 
INFO  [08:52:03.125] [bbotk] Result of batch 44: 
INFO  [08:52:03.127] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:52:03.127] [bbotk]                   7              1570      0.4778754        0.539 -0.8897902 
INFO  [08:52:03.127] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:52:03.127] [bbotk]          <NA>   0.9793412 afb53acd-0337-4f40-b13f-77661480e004 
DEBUG [08:52:03.998] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.130072e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004130072 0.4263688 
  - best initial criterion value(s) :  174.7231 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -174.72  |proj g|=       6.8634
At iterate     1  f =      -174.78  |proj g|=       0.32794
At iterate     2  f =      -184.48  |proj g|=        5.9541
At iterate     3  f =      -188.19  |proj g|=        5.6967
At iterate     4  f =      -195.98  |proj g|=        4.8145
At iterate     5  f =      -200.18  |proj g|=        4.6791
At iterate     6  f =      -216.34  |proj g|=        3.0571
At iterate     7  f =      -218.85  |proj g|=        2.7543
At iterate     8  f =      -222.66  |proj g|=        2.3194
At iterate     9  f =         -224  |proj g|=        2.0533
At iterate    10  f =      -224.41  |proj g|=        1.2602
At iterate    11  f =       -224.5  |proj g|=       0.36046
At iterate    12  f =      -224.53  |proj g|=       0.42129
At iterate    13  f =      -224.53  |proj g|=       0.42133
At iterate    14  f =      -224.53  |proj g|=     0.0046724
At iterate    15  f =      -224.53  |proj g|=     0.0047741

iterations 15
function evaluations 27
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00477409
final function value -224.535

F = -224.535
final  value -224.534882 
converged
 
INFO  [08:52:04.002] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:52:04.063] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:52:04.070] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:52:50.745] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:53:37.950] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:54:24.891] [mlr3]  Finished benchmark 
INFO  [08:54:24.957] [bbotk] Result of batch 45: 
INFO  [08:54:24.959] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:54:24.959] [bbotk]                   3              3915      0.3122435        0.484 -0.8821152 
INFO  [08:54:24.959] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:54:24.959] [bbotk]          <NA>   0.9787654 59ec5209-c0d8-4f0d-bade-0583aa657d55 
DEBUG [08:54:25.655] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.091904e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004091904 0.4259393 
  - best initial criterion value(s) :  181.1978 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -181.2  |proj g|=       3.6723
At iterate     1  f =      -202.33  |proj g|=       0.42185
At iterate     2  f =      -204.89  |proj g|=     0.0044756
At iterate     3  f =      -205.36  |proj g|=     0.0045042
At iterate     4  f =      -205.66  |proj g|=     0.0045459
At iterate     5  f =      -205.67  |proj g|=       0.41981
At iterate     6  f =      -205.68  |proj g|=     0.0045567
At iterate     7  f =      -205.68  |proj g|=     0.0045569
At iterate     8  f =      -205.68  |proj g|=      0.004557

iterations 8
function evaluations 11
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00455695
final function value -205.676

F = -205.676
final  value -205.675797 
converged
 
INFO  [08:54:25.659] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:54:25.713] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:54:25.727] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:54:44.732] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:55:04.629] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:55:23.301] [mlr3]  Finished benchmark 
INFO  [08:55:23.366] [bbotk] Result of batch 46: 
INFO  [08:55:23.368] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:55:23.368] [bbotk]                   3              1480      0.3389795        0.507 -0.9161121 
INFO  [08:55:23.368] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:55:23.368] [bbotk]          <NA>   0.9777028 1b53003f-b86f-40df-94a4-c7e8ad2f37b0 
DEBUG [08:55:24.062] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.053807e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004053807 0.4178116 
  - best initial criterion value(s) :  174.2213 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -174.22  |proj g|=       6.5169
At iterate     1  f =      -175.47  |proj g|=         4.781
At iterate     2  f =      -197.01  |proj g|=        4.4168
At iterate     3  f =      -204.79  |proj g|=        3.7508
At iterate     4  f =      -207.15  |proj g|=        3.6919
At iterate     5  f =      -207.95  |proj g|=        3.6199
At iterate     6  f =      -209.08  |proj g|=         3.483
At iterate     7  f =      -212.53  |proj g|=        3.0304
At iterate     8  f =      -218.39  |proj g|=        2.1233
At iterate     9  f =      -222.18  |proj g|=       0.56717
At iterate    10  f =      -222.18  |proj g|=       0.34278
At iterate    11  f =      -222.19  |proj g|=     0.0066503
At iterate    12  f =      -222.19  |proj g|=     0.0066506
At iterate    13  f =      -222.19  |proj g|=     0.0066507
At iterate    14  f =      -222.19  |proj g|=     0.0066507

iterations 14
function evaluations 26
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00665071
final function value -222.189

F = -222.189
final  value -222.189123 
converged
 
INFO  [08:55:24.066] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:55:24.127] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:55:24.133] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:55:24.858] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:55:25.572] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:55:26.472] [mlr3]  Finished benchmark 
INFO  [08:55:26.537] [bbotk] Result of batch 47: 
INFO  [08:55:26.538] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:55:26.538] [bbotk]                   9              3176      0.3017791        0.484 -0.8831996 
INFO  [08:55:26.538] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:55:26.538] [bbotk]          <NA>         0.5 d1986d08-5c5a-4d75-9a9d-122245b67e1b 
DEBUG [08:55:27.247] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.176176e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004176176 0.4278394 
  - best initial criterion value(s) :  172.7625 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -172.76  |proj g|=       6.0956
At iterate     1  f =      -178.06  |proj g|=        4.2087
At iterate     2  f =      -181.82  |proj g|=        5.5544
At iterate     3  f =      -183.81  |proj g|=        5.3486
At iterate     4  f =      -189.32  |proj g|=        4.5932
At iterate     5  f =      -209.93  |proj g|=        3.2404
At iterate     6  f =      -211.22  |proj g|=        3.1874
At iterate     7  f =      -214.13  |proj g|=        2.8897
At iterate     8  f =      -215.58  |proj g|=         2.701
At iterate     9  f =      -219.93  |proj g|=        1.9001
At iterate    10  f =      -220.34  |proj g|=        4.0907
At iterate    11  f =      -221.08  |proj g|=       0.67021
At iterate    12  f =      -221.18  |proj g|=       0.61405
At iterate    13  f =      -221.23  |proj g|=      0.058328
At iterate    14  f =      -221.23  |proj g|=     0.0098693
At iterate    15  f =      -221.23  |proj g|=       0.13649
At iterate    16  f =      -221.23  |proj g|=     0.0078862

iterations 16
function evaluations 26
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00788619
final function value -221.229

F = -221.229
final  value -221.229399 
converged
 
INFO  [08:55:27.251] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:55:27.305] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:55:27.312] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:55:49.635] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:56:13.455] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:56:36.615] [mlr3]  Finished benchmark 
INFO  [08:56:36.681] [bbotk] Result of batch 48: 
INFO  [08:56:36.683] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:56:36.683] [bbotk]                   3              1839      0.2682427        0.495 -0.8837281 
INFO  [08:56:36.683] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:56:36.683] [bbotk]          <NA>   0.9777214 39644e8a-a441-4231-9b2d-c7d44ce3f829 
DEBUG [08:56:37.497] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.139141e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004139141 0.4207837 
  - best initial criterion value(s) :  211.3477 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -211.35  |proj g|=      0.91335
At iterate     1  f =      -217.75  |proj g|=        4.3487
At iterate     2  f =      -219.45  |proj g|=        4.3381
At iterate     3  f =      -220.81  |proj g|=        4.1262
At iterate     4  f =      -223.54  |proj g|=        3.6625
At iterate     5  f =       -225.4  |proj g|=        3.3875
At iterate     6  f =      -230.78  |proj g|=        2.5606
At iterate     7  f =      -231.52  |proj g|=        2.2596
At iterate     8  f =       -231.8  |proj g|=        2.1359
At iterate     9  f =      -231.81  |proj g|=         2.098
At iterate    10  f =      -232.13  |proj g|=        2.1478
At iterate    11  f =      -234.99  |proj g|=        2.3868
At iterate    12  f =      -239.59  |proj g|=        2.5769
At iterate    13  f =      -242.11  |proj g|=        2.2994
At iterate    14  f =      -244.21  |proj g|=        2.2664
At iterate    15  f =      -244.27  |proj g|=        2.5983
At iterate    16  f =      -244.42  |proj g|=       0.41605
At iterate    17  f =      -244.42  |proj g|=     0.0050153
At iterate    18  f =      -244.42  |proj g|=     0.0050154
At iterate    19  f =      -244.42  |proj g|=     0.0050154

iterations 19
function evaluations 30
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00501544
final function value -244.419

F = -244.419
final  value -244.418719 
converged
 
INFO  [08:56:37.501] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:56:37.553] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:56:37.559] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:56:38.292] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:56:39.016] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:56:39.891] [mlr3]  Finished benchmark 
INFO  [08:56:39.968] [bbotk] Result of batch 49: 
INFO  [08:56:39.970] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:56:39.970] [bbotk]                   9               858      0.1996602        0.595 -0.8801063 
INFO  [08:56:39.970] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:56:39.970] [bbotk]          <NA>         0.5 14ce490b-2500-4083-937f-f9466394b83f 
DEBUG [08:56:40.709] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.253682e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004253682 0.4369284 
  - best initial criterion value(s) :  200.4728 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -200.47  |proj g|=       1.6762
At iterate     1  f =       -208.1  |proj g|=        4.8507
At iterate     2  f =      -210.63  |proj g|=        4.7485
At iterate     3  f =      -212.31  |proj g|=        4.4789
At iterate     4  f =      -214.75  |proj g|=        4.0519
At iterate     5  f =      -220.38  |proj g|=        3.2097
At iterate     6  f =      -226.93  |proj g|=        2.3723
At iterate     7  f =      -227.34  |proj g|=        2.1509
At iterate     8  f =      -227.55  |proj g|=        2.0681
At iterate     9  f =      -227.55  |proj g|=        2.0504
At iterate    10  f =      -227.58  |proj g|=         2.034
At iterate    11  f =      -227.85  |proj g|=        1.9365
At iterate    12  f =      -228.31  |proj g|=        1.8545
At iterate    13  f =      -229.99  |proj g|=       0.82697
At iterate    14  f =      -233.04  |proj g|=       0.98259
At iterate    15  f =      -239.74  |proj g|=       0.43267
At iterate    16  f =      -239.98  |proj g|=         1.837
At iterate    17  f =      -242.38  |proj g|=        1.3512
At iterate    18  f =      -242.42  |proj g|=       0.43224
At iterate    19  f =      -242.43  |proj g|=       0.43219
At iterate    20  f =      -242.43  |proj g|=       0.43219
At iterate    21  f =      -242.43  |proj g|=      0.054797

iterations 21
function evaluations 33
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0547973
final function value -242.427

F = -242.427
final  value -242.427268 
converged
 
INFO  [08:56:40.713] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:56:40.766] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:56:40.772] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:56:41.519] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:57:13.158] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:57:44.681] [mlr3]  Finished benchmark 
INFO  [08:57:44.754] [bbotk] Result of batch 50: 
INFO  [08:57:44.756] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:57:44.756] [bbotk]                   8              2567      0.1432812         0.51 -0.8810699 
INFO  [08:57:44.756] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:57:44.756] [bbotk]          <NA>   0.8193976 aff45600-901e-4d8d-8716-7a1ac3441dbf 
DEBUG [08:57:45.655] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.195713e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004195713 0.4319225 
  - best initial criterion value(s) :  186.5371 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -186.54  |proj g|=       4.6057
At iterate     1  f =      -186.69  |proj g|=        4.5625
At iterate     2  f =      -187.07  |proj g|=        4.5486
At iterate     3  f =      -188.44  |proj g|=        4.4615
At iterate     4  f =      -190.46  |proj g|=        4.2578
At iterate     5  f =      -193.76  |proj g|=        3.7745
At iterate     6  f =      -207.47  |proj g|=        2.8284
At iterate     7  f =      -209.93  |proj g|=       0.58599
At iterate     8  f =      -212.83  |proj g|=        2.4644
At iterate     9  f =      -214.47  |proj g|=          2.45
At iterate    10  f =      -214.59  |proj g|=        2.4409
At iterate    11  f =      -214.66  |proj g|=        2.4309
At iterate    12  f =      -215.49  |proj g|=        2.2564
At iterate    13  f =      -216.41  |proj g|=        2.1114
At iterate    14  f =      -217.45  |proj g|=        2.8398
At iterate    15  f =      -217.83  |proj g|=       0.49722
At iterate    16  f =      -217.84  |proj g|=       0.42675
At iterate    17  f =      -217.84  |proj g|=      0.012891
At iterate    18  f =      -217.84  |proj g|=       0.10123
At iterate    19  f =      -217.84  |proj g|=      0.035568

iterations 19
function evaluations 26
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0355683
final function value -217.839

F = -217.839
final  value -217.839177 
converged
 
INFO  [08:57:45.658] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:57:45.712] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:57:45.720] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:58:12.904] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:58:39.578] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:59:06.443] [mlr3]  Finished benchmark 
INFO  [08:59:06.510] [bbotk] Result of batch 51: 
INFO  [08:59:06.512] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:59:06.512] [bbotk]                   6              2205      0.2027944         0.64 -0.8857551 
INFO  [08:59:06.512] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:59:06.512] [bbotk]          <NA>   0.9798385 4eb66ded-98bc-4883-8897-043652d74b7c 
DEBUG [08:59:07.453] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.161913e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004161913 0.4257135 
  - best initial criterion value(s) :  201.089 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -201.09  |proj g|=       11.754
At iterate     1  f =       -218.4  |proj g|=       0.51263
At iterate     2  f =      -230.34  |proj g|=        3.7273
At iterate     3  f =       -236.9  |proj g|=        3.0977
At iterate     4  f =      -242.24  |proj g|=        2.5436
At iterate     5  f =      -244.75  |proj g|=        2.2512
At iterate     6  f =      -245.49  |proj g|=        1.8903
At iterate     7  f =      -245.93  |proj g|=        1.5117
At iterate     8  f =      -246.12  |proj g|=       0.84866
At iterate     9  f =      -246.14  |proj g|=        1.0131
At iterate    10  f =      -246.15  |proj g|=       0.94295
At iterate    11  f =      -246.17  |proj g|=       0.61104
At iterate    12  f =      -246.24  |proj g|=       0.22186
At iterate    13  f =      -246.41  |proj g|=       0.52584
At iterate    14  f =      -246.82  |proj g|=        1.6747
At iterate    15  f =      -247.71  |proj g|=        3.3163
At iterate    16  f =      -249.59  |proj g|=        5.4486
At iterate    17  f =      -253.22  |proj g|=        6.8345
At iterate    18  f =       -256.8  |proj g|=        1.7603
At iterate    19  f =      -257.47  |proj g|=       0.81263
At iterate    20  f =      -257.55  |proj g|=        1.9106
At iterate    21  f =      -257.58  |proj g|=        1.8989
At iterate    22  f =      -257.61  |proj g|=        1.5522
At iterate    23  f =      -257.69  |proj g|=       0.22413
At iterate    24  f =      -257.72  |proj g|=       0.20014
At iterate    25  f =      -257.72  |proj g|=      0.075077
At iterate    26  f =      -257.72  |proj g|=     0.0061463
At iterate    27  f =      -257.72  |proj g|=     0.0059974
At iterate    28  f =      -257.72  |proj g|=      0.038756

iterations 28
function evaluations 38
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0387556
final function value -257.723

F = -257.723
final  value -257.722921 
converged
 
INFO  [08:59:07.457] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:59:07.511] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:59:07.517] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [08:59:08.319] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [08:59:31.413] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [08:59:53.760] [mlr3]  Finished benchmark 
INFO  [08:59:53.824] [bbotk] Result of batch 52: 
INFO  [08:59:53.826] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [08:59:53.826] [bbotk]                   8              1866      0.2911716        0.656 -0.8792904 
INFO  [08:59:53.826] [bbotk]  errors.model classif.auc                                uhash 
INFO  [08:59:53.826] [bbotk]          <NA>   0.8191141 636bd71b-2c60-47fb-a093-83bd29162043 
DEBUG [08:59:54.813] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.106883e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004106883 0.4206735 
  - best initial criterion value(s) :  217.1837 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -217.18  |proj g|=       4.7502
At iterate     1  f =      -226.84  |proj g|=        1.2323
At iterate     2  f =      -251.48  |proj g|=        2.0703
At iterate     3  f =      -252.59  |proj g|=        3.8044
At iterate     4  f =       -252.6  |proj g|=        4.2432
At iterate     5  f =      -252.73  |proj g|=       0.41605
At iterate     6  f =      -252.86  |proj g|=        1.6068
At iterate     7  f =      -253.02  |proj g|=        2.7552
At iterate     8  f =      -255.18  |proj g|=        3.5169
At iterate     9  f =      -255.46  |proj g|=       0.92346
At iterate    10  f =      -255.46  |proj g|=        1.0114
At iterate    11  f =      -255.48  |proj g|=       0.41606
At iterate    12  f =      -255.48  |proj g|=       0.41605
At iterate    13  f =      -255.48  |proj g|=      0.026389

iterations 13
function evaluations 21
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0263893
final function value -255.485

F = -255.485
final  value -255.484658 
converged
 
INFO  [08:59:54.817] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:59:54.878] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:59:54.890] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:00:25.106] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:00:54.650] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:01:24.937] [mlr3]  Finished benchmark 
INFO  [09:01:25.002] [bbotk] Result of batch 53: 
INFO  [09:01:25.004] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:01:25.004] [bbotk]                   5              2439      0.2945839        0.699 -0.8797893 
INFO  [09:01:25.004] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:01:25.004] [bbotk]          <NA>   0.9795889 58058d59-2f83-4ce9-8f8e-017d0cca95a7 
DEBUG [09:01:25.907] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.07461e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.00407461 0.420201 
  - best initial criterion value(s) :  184.4784 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -184.48  |proj g|=      0.34392
At iterate     1  f =      -190.94  |proj g|=        4.4933
At iterate     2  f =      -193.44  |proj g|=        4.6155
At iterate     3  f =      -194.32  |proj g|=        4.5286
At iterate     4  f =      -194.84  |proj g|=        4.4978
At iterate     5  f =      -215.31  |proj g|=        2.6615
At iterate     6  f =      -216.91  |proj g|=        2.4289
At iterate     7  f =      -220.16  |proj g|=        1.9417
At iterate     8  f =      -220.45  |proj g|=       0.56003
At iterate     9  f =      -220.46  |proj g|=      0.063733
At iterate    10  f =      -220.46  |proj g|=       0.41494
At iterate    11  f =      -220.46  |proj g|=      0.030165
At iterate    12  f =      -220.46  |proj g|=       0.01691
At iterate    13  f =      -220.46  |proj g|=       0.16888

iterations 13
function evaluations 21
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.168878
final function value -220.463

F = -220.463
final  value -220.462906 
converged
 
INFO  [09:01:25.911] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:01:25.966] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:01:25.972] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:02:09.871] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:02:10.666] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:02:53.079] [mlr3]  Finished benchmark 
INFO  [09:02:53.144] [bbotk] Result of batch 54: 
INFO  [09:02:53.146] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:02:53.146] [bbotk]                   8              3525      0.1652829        0.636 -0.8864695 
INFO  [09:02:53.146] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:02:53.146] [bbotk]          <NA>    0.819077 5a792160-3092-4437-ac5f-48c042eaa7a1 
DEBUG [09:02:53.910] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.022286e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004022286 0.4156314 
  - best initial criterion value(s) :  224.393 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -224.39  |proj g|=       2.4884
At iterate     1  f =      -230.42  |proj g|=        4.1692
At iterate     2  f =      -235.57  |proj g|=        3.5773
At iterate     3  f =      -238.25  |proj g|=        3.1422
At iterate     4  f =      -242.68  |proj g|=        1.1708
At iterate     5  f =      -243.56  |proj g|=       0.86647
At iterate     6  f =      -243.86  |proj g|=        2.3141
At iterate     7  f =      -244.31  |proj g|=        2.1083
At iterate     8  f =      -244.34  |proj g|=        2.0918
At iterate     9  f =      -244.49  |proj g|=        2.0103
At iterate    10  f =      -244.61  |proj g|=        1.9895
At iterate    11  f =      -246.13  |proj g|=        1.8157
At iterate    12  f =      -248.22  |proj g|=        1.7579
At iterate    13  f =      -257.73  |proj g|=        2.0596
At iterate    14  f =      -258.69  |proj g|=       0.35332
At iterate    15  f =      -259.06  |proj g|=       0.35519
At iterate    16  f =      -259.12  |proj g|=        0.4112
At iterate    17  f =      -259.14  |proj g|=      0.014564
At iterate    18  f =      -259.14  |proj g|=     0.0092026
At iterate    19  f =      -259.14  |proj g|=       0.41103
At iterate    20  f =      -259.14  |proj g|=       0.11148

iterations 20
function evaluations 25
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.11148
final function value -259.137

F = -259.137
final  value -259.137007 
converged
 
INFO  [09:02:53.914] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:02:53.970] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:02:53.977] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:02:54.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:02:55.601] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:02:56.337] [mlr3]  Finished benchmark 
INFO  [09:02:56.402] [bbotk] Result of batch 55: 
INFO  [09:02:56.403] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:02:56.403] [bbotk]                  10              1468      0.3806629        0.521 -0.8801911 
INFO  [09:02:56.403] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:02:56.403] [bbotk]          <NA>         0.5 7a841c7e-1868-44b7-b5ed-9069661395f0 
DEBUG [09:02:57.160] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.127256e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004127256 0.4267227 
  - best initial criterion value(s) :  222.1074 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -222.11  |proj g|=       4.3273
At iterate     1  f =      -237.74  |proj g|=       0.69231
At iterate     2  f =      -266.17  |proj g|=        2.6324
At iterate     3  f =      -266.59  |proj g|=        2.5944
At iterate     4  f =      -274.78  |proj g|=        1.8677
At iterate     5  f =      -275.54  |proj g|=        9.4082
At iterate     6  f =      -276.11  |proj g|=        5.1665
At iterate     7  f =      -276.14  |proj g|=         4.532
At iterate     8  f =      -276.19  |proj g|=        3.8524
At iterate     9  f =      -276.38  |proj g|=        2.1409
At iterate    10  f =      -277.07  |proj g|=       0.42595
At iterate    11  f =      -280.95  |proj g|=        1.9652
At iterate    12  f =      -281.12  |proj g|=        1.9968
At iterate    13  f =      -281.38  |proj g|=        1.9164
At iterate    14  f =      -281.57  |proj g|=       0.42242
At iterate    15  f =      -281.57  |proj g|=       0.42237
At iterate    16  f =      -281.57  |proj g|=       0.28854
At iterate    17  f =      -281.57  |proj g|=      0.011201

iterations 17
function evaluations 25
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0112014
final function value -281.571

F = -281.571
final  value -281.570783 
converged
 
INFO  [09:02:57.164] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:02:57.224] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:02:57.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:03:20.603] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:03:21.350] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:03:44.577] [mlr3]  Finished benchmark 
INFO  [09:03:44.669] [bbotk] Result of batch 56: 
INFO  [09:03:44.671] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:03:44.671] [bbotk]                   8              1862       0.216417        0.529 -0.8772002 
INFO  [09:03:44.671] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:03:44.671] [bbotk]          <NA>   0.8193234 7bec5df4-8467-4054-ac9b-70e10b4561f6 
DEBUG [09:03:45.423] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.075222e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004075222 0.4224413 
  - best initial criterion value(s) :  240.6648 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -240.66  |proj g|=       1.4929
At iterate     1  f =      -267.22  |proj g|=        4.0757
At iterate     2  f =      -270.98  |proj g|=        3.7994
At iterate     3  f =      -271.99  |proj g|=        3.7984
At iterate     4  f =      -273.17  |proj g|=        3.6921
At iterate     5  f =      -275.26  |proj g|=        3.4443
At iterate     6  f =      -277.78  |proj g|=        2.8698
At iterate     7  f =      -287.99  |proj g|=        2.3488
At iterate     8  f =      -290.59  |proj g|=        1.8412
At iterate     9  f =      -290.71  |proj g|=       0.85442
At iterate    10  f =      -290.74  |proj g|=       0.29698
At iterate    11  f =      -290.74  |proj g|=      0.005844
At iterate    12  f =      -290.74  |proj g|=     0.0058443
At iterate    13  f =      -290.74  |proj g|=     0.0058443

iterations 13
function evaluations 20
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00584428
final function value -290.74

F = -290.74
final  value -290.740232 
converged
 
INFO  [09:03:45.427] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:03:45.485] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:03:45.493] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:03:59.850] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:04:13.893] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:04:28.091] [mlr3]  Finished benchmark 
INFO  [09:04:28.156] [bbotk] Result of batch 57: 
INFO  [09:04:28.158] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:04:28.158] [bbotk]                   5              1100      0.4447317        0.536 -0.8763137 
INFO  [09:04:28.158] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:04:28.158] [bbotk]          <NA>   0.9796592 8e306908-110c-4caf-9709-3f0ecef26d05 
DEBUG [09:04:28.939] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.046185e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004046185 0.4157989 
  - best initial criterion value(s) :  215.3701 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -215.37  |proj g|=        5.357
At iterate     1  f =       -223.6  |proj g|=        1.3089
At iterate     2  f =      -256.12  |proj g|=        2.0377
At iterate     3  f =      -257.31  |proj g|=        2.1008
At iterate     4  f =      -258.63  |proj g|=        1.3377
At iterate     5  f =      -258.72  |proj g|=        1.3087
At iterate     6  f =      -258.81  |proj g|=       0.51362
At iterate     7  f =      -258.91  |proj g|=       0.41153
At iterate     8  f =      -259.59  |proj g|=        1.4718
At iterate     9  f =      -260.08  |proj g|=        1.2403
At iterate    10  f =      -260.27  |proj g|=       0.41135
At iterate    11  f =      -260.29  |proj g|=       0.43981
At iterate    12  f =      -260.29  |proj g|=       0.51601
At iterate    13  f =      -260.29  |proj g|=       0.52711
At iterate    14  f =      -260.29  |proj g|=       0.54325
At iterate    15  f =      -260.29  |proj g|=       0.54854
At iterate    16  f =      -260.29  |proj g|=       0.52447
At iterate    17  f =      -260.29  |proj g|=       0.42776
At iterate    18  f =      -260.29  |proj g|=       0.21067
At iterate    19  f =      -260.29  |proj g|=       0.41117
At iterate    20  f =      -260.29  |proj g|=      0.019934

iterations 20
function evaluations 29
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0199344
final function value -260.295

F = -260.295
final  value -260.294879 
converged
 
INFO  [09:04:28.943] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:04:28.996] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:04:29.003] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:04:46.324] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:05:04.071] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:05:04.855] [mlr3]  Finished benchmark 
INFO  [09:05:04.932] [bbotk] Result of batch 58: 
INFO  [09:05:04.934] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:05:04.934] [bbotk]                   8              1390      0.1903229        0.549 -0.8814857 
INFO  [09:05:04.934] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:05:04.934] [bbotk]          <NA>   0.8193671 a733f16a-c6d2-4827-a30e-1bcafbbfcb36 
DEBUG [09:05:05.710] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.996553e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.003996553 0.411665 
  - best initial criterion value(s) :  255.3576 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -255.36  |proj g|=       7.5097
At iterate     1  f =      -263.71  |proj g|=        1.9204
At iterate     2  f =      -272.74  |proj g|=        3.3021
At iterate     3  f =      -273.37  |proj g|=        3.2415
At iterate     4  f =      -277.08  |proj g|=        2.8136
At iterate     5  f =      -281.48  |proj g|=       0.97689
At iterate     6  f =      -301.31  |proj g|=        1.4061
At iterate     7  f =      -301.55  |proj g|=        1.8285
At iterate     8  f =      -301.67  |proj g|=        0.4709
At iterate     9  f =      -301.67  |proj g|=      0.028673
At iterate    10  f =      -301.67  |proj g|=       0.40749
At iterate    11  f =      -301.67  |proj g|=     0.0060342
At iterate    12  f =      -301.67  |proj g|=     0.0060342

iterations 12
function evaluations 20
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00603417
final function value -301.673

F = -301.673
final  value -301.672950 
converged
 
INFO  [09:05:05.714] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:05:05.770] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:05:05.777] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:05:38.342] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:06:10.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:06:43.434] [mlr3]  Finished benchmark 
INFO  [09:06:43.502] [bbotk] Result of batch 59: 
INFO  [09:06:43.504] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:06:43.504] [bbotk]                   6              2624      0.2134635        0.533 -0.8758304 
INFO  [09:06:43.504] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:06:43.504] [bbotk]          <NA>    0.979718 7b50922f-806a-4936-84b2-34a3fbb006d8 
DEBUG [09:06:44.602] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.968794e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.003968794 0.4082952 
  - best initial criterion value(s) :  203.2119 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -203.21  |proj g|=       2.7914
At iterate     1  f =      -240.36  |proj g|=        2.5864
At iterate     2  f =      -240.65  |proj g|=        2.5686
At iterate     3  f =      -241.78  |proj g|=        2.4602
At iterate     4  f =      -244.46  |proj g|=        2.0957
At iterate     5  f =      -245.18  |proj g|=        1.9319
At iterate     6  f =      -245.46  |proj g|=        1.8449
At iterate     7  f =      -245.53  |proj g|=      0.019832
At iterate     8  f =      -245.53  |proj g|=       0.40332
At iterate     9  f =      -245.53  |proj g|=      0.019859
At iterate    10  f =      -245.53  |proj g|=      0.019859

iterations 10
function evaluations 17
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0198591
final function value -245.53

F = -245.53
final  value -245.530152 
converged
 
INFO  [09:06:44.606] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:06:44.672] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:06:44.679] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:07:02.586] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:07:21.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:07:39.316] [mlr3]  Finished benchmark 
INFO  [09:07:39.381] [bbotk] Result of batch 60: 
INFO  [09:07:39.382] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:07:39.382] [bbotk]                   5              1419     0.08431703        0.858 -0.8851053 
INFO  [09:07:39.382] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:07:39.382] [bbotk]          <NA>   0.9787242 586d37a9-41e2-4dda-8994-5f486112c150 
DEBUG [09:07:40.141] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.940886e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.003940885 0.4023509 
  - best initial criterion value(s) :  248.3186 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -248.32  |proj g|=       2.7772
At iterate     1  f =      -255.85  |proj g|=         4.526
At iterate     2  f =      -261.34  |proj g|=        3.8861
At iterate     3  f =      -265.13  |proj g|=        3.3255
At iterate     4  f =      -272.07  |proj g|=        2.4877
At iterate     5  f =      -272.67  |proj g|=        2.2641
At iterate     6  f =      -272.81  |proj g|=         1.972
At iterate     7  f =      -273.02  |proj g|=        2.0993
At iterate     8  f =      -273.04  |proj g|=        2.0937
At iterate     9  f =       -273.1  |proj g|=        2.0856
At iterate    10  f =      -273.28  |proj g|=        2.0733
At iterate    11  f =      -273.73  |proj g|=        2.0517
At iterate    12  f =      -275.04  |proj g|=        2.0358
At iterate    13  f =      -277.45  |proj g|=        2.0399
At iterate    14  f =      -292.41  |proj g|=        0.9392
At iterate    15  f =      -292.45  |proj g|=       0.39816
At iterate    16  f =      -292.46  |proj g|=       0.39809
At iterate    17  f =      -292.46  |proj g|=       0.39808
At iterate    18  f =      -292.46  |proj g|=      0.055917
At iterate    19  f =      -292.46  |proj g|=      0.021154
At iterate    20  f =      -292.46  |proj g|=       0.39808
At iterate    21  f =      -292.46  |proj g|=       0.01835
At iterate    22  f =      -292.46  |proj g|=     0.0095438

iterations 22
function evaluations 27
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00954375
final function value -292.461

F = -292.461
final  value -292.460756 
converged
 
INFO  [09:07:40.145] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:07:40.210] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:07:40.216] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:07:41.105] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:07:41.862] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:07:42.594] [mlr3]  Finished benchmark 
INFO  [09:07:42.658] [bbotk] Result of batch 61: 
INFO  [09:07:42.660] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:07:42.660] [bbotk]                  10              1381      0.2717886        0.529 -0.8781287 
INFO  [09:07:42.660] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:07:42.660] [bbotk]          <NA>         0.5 ef0c6d61-0db0-4fd3-9630-68c68eeb02cb 
DEBUG [09:07:43.407] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.03914e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.00403914 0.4128882 
  - best initial criterion value(s) :  226.2356 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -226.24  |proj g|=       7.2316
At iterate     1  f =      -227.92  |proj g|=        1.7082
At iterate     2  f =      -247.08  |proj g|=        6.0207
At iterate     3  f =      -252.22  |proj g|=        5.7065
At iterate     4  f =      -264.11  |proj g|=        4.9247
At iterate     5  f =      -286.24  |proj g|=        3.6843
At iterate     6  f =      -286.89  |proj g|=        3.6387
At iterate     7  f =      -296.66  |proj g|=        2.8757
At iterate     8  f =      -300.72  |proj g|=        2.2854
At iterate     9  f =      -301.33  |proj g|=        12.741
At iterate    10  f =      -304.91  |proj g|=       0.40885
At iterate    11  f =      -304.92  |proj g|=       0.38797
At iterate    12  f =      -304.92  |proj g|=       0.40874
At iterate    13  f =      -304.92  |proj g|=     0.0082316
At iterate    14  f =      -304.92  |proj g|=     0.0082316

iterations 14
function evaluations 27
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00823161
final function value -304.918

F = -304.918
final  value -304.918128 
converged
 
INFO  [09:07:43.411] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:07:43.465] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:07:43.471] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:08:36.124] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:09:29.357] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:10:22.926] [mlr3]  Finished benchmark 
INFO  [09:10:22.991] [bbotk] Result of batch 62: 
INFO  [09:10:22.993] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:10:22.993] [bbotk]                   3              4446     0.01329084        0.518 -0.8765536 
INFO  [09:10:22.993] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:10:22.993] [bbotk]          <NA>   0.9716699 4e062208-0e4f-4f2e-9c9d-dcbe3395ebf2 
DEBUG [09:10:23.745] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.009719e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.004009719 0.4114709 
  - best initial criterion value(s) :  228.3108 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -228.31  |proj g|=       9.3454
At iterate     1  f =      -239.68  |proj g|=       0.41825
At iterate     2  f =      -253.52  |proj g|=        3.6711
At iterate     3  f =      -257.41  |proj g|=        3.3298
At iterate     4  f =      -268.64  |proj g|=       0.34802
At iterate     5  f =      -270.28  |proj g|=        0.7165
At iterate     6  f =      -270.34  |proj g|=          1.19
At iterate     7  f =       -270.6  |proj g|=        1.1407
At iterate     8  f =      -270.62  |proj g|=        1.1086
At iterate     9  f =      -270.63  |proj g|=        1.0765
At iterate    10  f =      -270.64  |proj g|=        1.0153
At iterate    11  f =      -270.67  |proj g|=       0.68386
At iterate    12  f =      -270.72  |proj g|=       0.20847
At iterate    13  f =      -270.83  |proj g|=       0.82656
At iterate    14  f =      -271.08  |proj g|=         2.211
At iterate    15  f =      -271.73  |proj g|=         4.407
At iterate    16  f =      -273.38  |proj g|=        7.6398
At iterate    17  f =       -277.1  |proj g|=        12.468
At iterate    18  f =      -279.29  |proj g|=        11.108
At iterate    19  f =      -279.99  |proj g|=        9.1779
At iterate    20  f =      -280.61  |proj g|=        6.7781
At iterate    21  f =      -281.35  |proj g|=       0.40746
At iterate    22  f =      -281.51  |proj g|=       0.40712
At iterate    23  f =      -281.51  |proj g|=       0.40706
At iterate    24  f =      -281.51  |proj g|=       0.40705
At iterate    25  f =      -281.51  |proj g|=      0.063312

iterations 25
function evaluations 32
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0633124
final function value -281.511

F = -281.511
final  value -281.511470 
converged
 
INFO  [09:10:23.749] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:10:23.804] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:10:23.811] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:11:12.873] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:12:01.577] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:12:51.844] [mlr3]  Finished benchmark 
INFO  [09:12:51.910] [bbotk] Result of batch 63: 
INFO  [09:12:51.912] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:12:51.912] [bbotk]                   4              4089      0.3951424        0.527 -0.8795278 
INFO  [09:12:51.912] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:12:51.912] [bbotk]          <NA>   0.9790234 e8ec03bb-3feb-4df2-8145-79c9f43e4d8d 
DEBUG [09:12:52.684] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.982752e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.003982752 0.4110783 
  - best initial criterion value(s) :  264.6465 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -264.65  |proj g|=       2.8484
At iterate     1  f =      -306.41  |proj g|=        2.3818
At iterate     2  f =      -309.08  |proj g|=        2.4026
At iterate     3  f =      -309.24  |proj g|=        2.3802
At iterate     4  f =      -309.46  |proj g|=        2.3387
At iterate     5  f =      -310.03  |proj g|=        2.2291
At iterate     6  f =       -311.1  |proj g|=         2.044
At iterate     7  f =      -312.26  |proj g|=        1.6181
At iterate     8  f =      -312.31  |proj g|=       0.40702
At iterate     9  f =      -312.31  |proj g|=         0.407
At iterate    10  f =      -312.31  |proj g|=      0.012949
At iterate    11  f =      -312.31  |proj g|=     0.0086475

iterations 11
function evaluations 19
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00864755
final function value -312.312

F = -312.312
final  value -312.312204 
converged
 
INFO  [09:12:52.688] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:12:52.746] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:12:52.755] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:13:28.044] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:14:02.943] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:14:37.568] [mlr3]  Finished benchmark 
INFO  [09:14:37.633] [bbotk] Result of batch 64: 
INFO  [09:14:37.635] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:14:37.635] [bbotk]                   7              2878      0.1525373        0.568 -0.8754525 
INFO  [09:14:37.635] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:14:37.635] [bbotk]          <NA>   0.9797396 eaa502bf-c642-4f46-8eea-945171df762c 
DEBUG [09:14:38.401] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.956169e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.003956169 0.4086034 
  - best initial criterion value(s) :  263.6305 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -263.63  |proj g|=       2.9482
At iterate     1  f =      -276.39  |proj g|=        5.1052
At iterate     2  f =      -278.14  |proj g|=        4.9449
At iterate     3  f =      -279.58  |proj g|=        4.6045
At iterate     4  f =      -281.69  |proj g|=        4.1117
At iterate     5  f =      -283.57  |proj g|=        3.7908
At iterate     6  f =      -302.66  |proj g|=        2.4758
At iterate     7  f =      -311.05  |proj g|=        12.776
At iterate     8  f =      -320.24  |proj g|=        3.8187
At iterate     9  f =      -325.32  |proj g|=        2.0706
At iterate    10  f =      -325.88  |proj g|=        2.1057
At iterate    11  f =      -326.52  |proj g|=       0.43709
At iterate    12  f =      -326.52  |proj g|=       0.40465
At iterate    13  f =      -326.53  |proj g|=     0.0073296
At iterate    14  f =      -326.53  |proj g|=       0.40463
At iterate    15  f =      -326.53  |proj g|=       0.17477
At iterate    16  f =      -326.53  |proj g|=     0.0073311

iterations 16
function evaluations 22
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00733115
final function value -326.526

F = -326.526
final  value -326.525684 
converged
 
INFO  [09:14:38.405] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:14:38.471] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:14:38.477] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:14:51.538] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:15:04.819] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:15:17.714] [mlr3]  Finished benchmark 
INFO  [09:15:17.779] [bbotk] Result of batch 65: 
INFO  [09:15:17.781] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:15:17.781] [bbotk]                   4              1005       0.100009         0.54 -0.8738263 
INFO  [09:15:17.781] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:15:17.781] [bbotk]          <NA>   0.9773294 fa626de8-6227-408f-bf3f-cf11101a4b8d 
DEBUG [09:15:18.608] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.929051e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.003929051 0.4030416 
  - best initial criterion value(s) :  280.0564 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -280.06  |proj g|=       11.314
At iterate     1  f =      -295.14  |proj g|=        1.3616
At iterate     2  f =      -311.18  |proj g|=        3.8449
At iterate     3  f =       -314.5  |proj g|=         3.526
At iterate     4  f =      -325.91  |proj g|=        2.6893
At iterate     5  f =      -331.66  |proj g|=        2.0387
At iterate     6  f =      -331.94  |proj g|=        1.8354
At iterate     7  f =      -332.55  |proj g|=       0.43814
At iterate     8  f =      -332.55  |proj g|=       0.39911
At iterate     9  f =      -332.55  |proj g|=       0.00732
At iterate    10  f =      -332.55  |proj g|=     0.0073204
At iterate    11  f =      -332.55  |proj g|=     0.0073204

iterations 11
function evaluations 20
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00732036
final function value -332.55

F = -332.55
final  value -332.550458 
converged
 
INFO  [09:15:18.612] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:15:18.667] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:15:18.674] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:16:13.804] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:17:08.744] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:17:09.511] [mlr3]  Finished benchmark 
INFO  [09:17:09.574] [bbotk] Result of batch 66: 
INFO  [09:17:09.576] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:17:09.576] [bbotk]                   8              4564      0.1594811        0.605 -0.8733082 
INFO  [09:17:09.576] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:17:09.576] [bbotk]          <NA>   0.8189139 1e9914ff-5c73-4553-a83e-b3a6e5fb2943 
DEBUG [09:17:10.371] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.885609e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.003885609 0.3976186 
  - best initial criterion value(s) :  288.7387 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -288.74  |proj g|=         5.23
At iterate     1  f =      -292.55  |proj g|=        2.8789
At iterate     2  f =      -307.02  |proj g|=        3.0329
At iterate     3  f =       -313.2  |proj g|=        2.2919
At iterate     4  f =      -317.53  |proj g|=        1.9292
At iterate     5  f =       -317.7  |proj g|=       0.59363
At iterate     6  f =      -317.75  |proj g|=      0.046032
At iterate     7  f =      -317.75  |proj g|=      0.098622
At iterate     8  f =      -317.76  |proj g|=       0.47182
At iterate     9  f =      -317.79  |proj g|=       0.97995
At iterate    10  f =      -317.86  |proj g|=        1.7752
At iterate    11  f =      -317.98  |proj g|=        2.1987
At iterate    12  f =      -318.04  |proj g|=        1.6734
At iterate    13  f =      -318.09  |proj g|=       0.43158
At iterate    14  f =      -318.09  |proj g|=       0.47717
At iterate    15  f =       -318.1  |proj g|=       0.38303
At iterate    16  f =       -318.1  |proj g|=       0.18456
At iterate    17  f =       -318.1  |proj g|=       0.39356
At iterate    18  f =       -318.1  |proj g|=       0.28321
At iterate    19  f =       -318.1  |proj g|=      0.010733

iterations 19
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0107333
final function value -318.101

F = -318.101
final  value -318.101363 
converged
 
INFO  [09:17:10.375] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:17:10.430] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:17:10.437] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:17:30.458] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:17:50.868] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:18:10.832] [mlr3]  Finished benchmark 
INFO  [09:18:10.898] [bbotk] Result of batch 67: 
INFO  [09:18:10.900] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:18:10.900] [bbotk]                   5              1583      0.3343212        0.559 -0.8756466 
INFO  [09:18:10.900] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:18:10.900] [bbotk]          <NA>   0.9796926 9cf7539e-676d-4127-91f2-445202542360 
DEBUG [09:18:11.645] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.860263e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.003860263 0.3937965 
  - best initial criterion value(s) :  312.226 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -312.23  |proj g|=       2.3485
At iterate     1  f =      -345.49  |proj g|=         12.65
At iterate     2  f =      -346.74  |proj g|=        10.703
At iterate     3  f =      -348.66  |proj g|=       0.12789
At iterate     4  f =      -348.66  |proj g|=     0.0067135
At iterate     5  f =      -348.66  |proj g|=     0.0067135

iterations 5
function evaluations 6
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00671354
final function value -348.658

F = -348.658
final  value -348.657874 
converged
 
INFO  [09:18:11.649] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:18:11.713] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:18:11.720] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:18:12.562] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:18:13.298] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:18:14.171] [mlr3]  Finished benchmark 
INFO  [09:18:14.235] [bbotk] Result of batch 68: 
INFO  [09:18:14.237] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:18:14.237] [bbotk]                  10              4099     0.02184159         0.55 -0.8721669 
INFO  [09:18:14.237] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:18:14.237] [bbotk]          <NA>         0.5 8ec850b5-57c4-4b7c-9043-8327c198b185 
DEBUG [09:18:15.024] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.954102e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.003954102 0.4017384 
  - best initial criterion value(s) :  288.4416 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -288.44  |proj g|=       6.6773
At iterate     1  f =       -295.8  |proj g|=        5.5468
At iterate     2  f =      -300.17  |proj g|=        6.0976
At iterate     3  f =      -302.62  |proj g|=        5.8926
At iterate     4  f =      -308.91  |proj g|=        5.3204
At iterate     5  f =      -313.24  |proj g|=        5.1687
At iterate     6  f =      -315.56  |proj g|=        4.9671
At iterate     7  f =      -319.97  |proj g|=           4.4
At iterate     8  f =      -326.45  |proj g|=       0.96926
At iterate     9  f =      -350.78  |proj g|=        9.0913
At iterate    10  f =      -352.16  |proj g|=        1.3116
At iterate    11  f =      -352.19  |proj g|=      0.023778
At iterate    12  f =      -352.19  |proj g|=     0.0068774
At iterate    13  f =      -352.19  |proj g|=     0.0068774

iterations 13
function evaluations 18
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0068774
final function value -352.189

F = -352.189
final  value -352.189197 
converged
 
INFO  [09:18:15.028] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:18:15.081] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:18:15.088] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:18:54.272] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:19:31.991] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:20:10.302] [mlr3]  Finished benchmark 
INFO  [09:20:10.368] [bbotk] Result of batch 69: 
INFO  [09:20:10.369] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:20:10.369] [bbotk]                   4              3106      0.1853109        0.561 -0.8721645 
INFO  [09:20:10.369] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:20:10.369] [bbotk]          <NA>   0.9796564 6d10000f-ab86-471d-b546-b0afed53adfa 
DEBUG [09:20:11.129] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.929245e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9796266 
  - variance bounds :  0.003929245 0.4007852 
  - best initial criterion value(s) :  275.3729 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -275.37  |proj g|=       5.8644
At iterate     1  f =      -303.67  |proj g|=       0.39686
At iterate     2  f =      -304.56  |proj g|=      0.009805
At iterate     3  f =      -304.62  |proj g|=      0.009843
At iterate     4  f =      -304.63  |proj g|=       0.39601
At iterate     5  f =      -304.63  |proj g|=     0.0098631
At iterate     6  f =      -304.63  |proj g|=     0.0098632

iterations 6
function evaluations 9
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00986316
final function value -304.633

F = -304.633
final  value -304.633305 
converged
 
INFO  [09:20:11.133] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:20:11.189] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:20:11.195] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:20:12.074] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:20:12.795] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:20:13.524] [mlr3]  Finished benchmark 
INFO  [09:20:13.599] [bbotk] Result of batch 70: 
INFO  [09:20:13.601] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:20:13.601] [bbotk]                  10              2865    0.006931059        0.562 -0.9074376 
INFO  [09:20:13.601] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:20:13.601] [bbotk]          <NA>         0.5 3bbb571a-3268-480f-bbdc-30164a66d8e4 
DEBUG [09:20:14.427] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.018471e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.004018471 0.4079577 
  - best initial criterion value(s) :  268.1778 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -268.18  |proj g|=       7.2622
At iterate     1  f =      -269.68  |proj g|=        3.5902
At iterate     2  f =      -292.85  |proj g|=        6.1682
At iterate     3  f =      -300.44  |proj g|=        5.8044
At iterate     4  f =      -314.25  |proj g|=        5.0375
At iterate     5  f =      -339.59  |proj g|=        3.7854
At iterate     6  f =       -344.1  |proj g|=        3.0899
At iterate     7  f =      -357.23  |proj g|=        2.4541
At iterate     8  f =      -357.61  |proj g|=        2.3955
At iterate     9  f =      -360.37  |proj g|=        2.0283
At iterate    10  f =      -360.72  |proj g|=        1.9371
At iterate    11  f =      -360.83  |proj g|=      0.032748
At iterate    12  f =      -360.83  |proj g|=     0.0072996
At iterate    13  f =      -360.83  |proj g|=     0.0072996

iterations 13
function evaluations 24
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00729958
final function value -360.825

F = -360.825
final  value -360.825370 
converged
 
INFO  [09:20:14.431] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:20:14.485] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:20:14.491] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:20:42.338] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:21:10.136] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:21:38.434] [mlr3]  Finished benchmark 
INFO  [09:21:38.509] [bbotk] Result of batch 71: 
INFO  [09:21:38.511] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:21:38.511] [bbotk]                   6              2295     0.04853769        0.585 -0.8709755 
INFO  [09:21:38.511] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:21:38.511] [bbotk]          <NA>     0.97841 f6fe9652-a638-4471-a874-107601b69c6a 
DEBUG [09:21:39.317] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.993767e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003993767 0.4049638 
  - best initial criterion value(s) :  311.48 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -311.48  |proj g|=       2.7088
At iterate     1  f =      -317.36  |proj g|=        5.4074
At iterate     2  f =      -326.46  |proj g|=        4.8076
At iterate     3  f =      -329.89  |proj g|=         4.491
At iterate     4  f =      -339.11  |proj g|=        3.8342
At iterate     5  f =      -361.34  |proj g|=        2.0482
At iterate     6  f =      -361.65  |proj g|=         1.841
At iterate     7  f =      -361.74  |proj g|=         1.963
At iterate     8  f =      -361.78  |proj g|=        1.9485
At iterate     9  f =      -361.93  |proj g|=       0.02348
At iterate    10  f =      -361.93  |proj g|=     0.0080549
At iterate    11  f =      -361.93  |proj g|=     0.0080549

iterations 11
function evaluations 17
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00805487
final function value -361.926

F = -361.926
final  value -361.925763 
converged
 
INFO  [09:21:39.321] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:21:39.375] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:21:39.382] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:21:57.340] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:22:15.404] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:22:33.225] [mlr3]  Finished benchmark 
INFO  [09:22:33.293] [bbotk] Result of batch 72: 
INFO  [09:22:33.295] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:22:33.295] [bbotk]                   5              1432      0.3493084        0.577 -0.8709314 
INFO  [09:22:33.295] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:22:33.295] [bbotk]          <NA>   0.9796796 d3b590c3-1af8-4ad1-9792-29a4abe0d004 
DEBUG [09:22:34.278] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.969554e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003969554 0.401417 
  - best initial criterion value(s) :  262.4356 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -262.44  |proj g|=       11.554
At iterate     1  f =      -285.62  |proj g|=        1.1449
At iterate     2  f =      -297.31  |proj g|=        4.1258
At iterate     3  f =      -298.23  |proj g|=        4.1107
At iterate     4  f =      -307.28  |proj g|=        3.3676
At iterate     5  f =      -320.95  |proj g|=         2.124
At iterate     6  f =      -321.89  |proj g|=       0.33909
At iterate     7  f =      -322.58  |proj g|=        1.6527
At iterate     8  f =       -322.7  |proj g|=        1.4345
At iterate     9  f =      -322.74  |proj g|=        1.0047
At iterate    10  f =      -322.88  |proj g|=       0.33756
At iterate    11  f =      -324.39  |proj g|=       0.39745
At iterate    12  f =       -331.9  |proj g|=        2.1881
At iterate    13  f =       -347.3  |proj g|=       0.75822
At iterate    14  f =      -347.31  |proj g|=      0.011847
At iterate    15  f =      -347.31  |proj g|=      0.011847

iterations 15
function evaluations 28
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0118465
final function value -347.306

F = -347.306
final  value -347.306101 
converged
 
INFO  [09:22:34.282] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:22:34.335] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:22:34.342] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:22:57.645] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:23:20.462] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:23:45.859] [mlr3]  Finished benchmark 
INFO  [09:23:45.933] [bbotk] Result of batch 73: 
INFO  [09:23:45.935] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:23:45.935] [bbotk]                   3              1901      0.4626201         0.73 -0.8724255 
INFO  [09:23:45.935] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:23:45.935] [bbotk]          <NA>   0.9784944 69602026-5c4e-4b4b-ad17-79da846595a4 
DEBUG [09:23:46.720] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.945154e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003945154 0.3989443 
  - best initial criterion value(s) :  319.244 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -319.24  |proj g|=       7.1097
At iterate     1  f =      -327.95  |proj g|=         2.124
At iterate     2  f =       -341.8  |proj g|=        3.8171
At iterate     3  f =      -347.69  |proj g|=        3.3209
At iterate     4  f =      -358.75  |proj g|=       0.21586
At iterate     5  f =      -360.98  |proj g|=        1.6535
At iterate     6  f =      -360.99  |proj g|=        1.9187
At iterate     7  f =      -362.38  |proj g|=        2.0256
At iterate     8  f =      -367.06  |proj g|=        2.1624
At iterate     9  f =      -375.04  |proj g|=        2.2609
At iterate    10  f =      -376.28  |proj g|=        2.0989
At iterate    11  f =      -377.17  |proj g|=        1.1451
At iterate    12  f =      -377.19  |proj g|=      0.020477
At iterate    13  f =      -377.19  |proj g|=     0.0076852
At iterate    14  f =      -377.19  |proj g|=     0.0076852

iterations 14
function evaluations 24
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00768523
final function value -377.195

F = -377.195
final  value -377.194663 
converged
 
INFO  [09:23:46.724] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:23:46.791] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:23:46.798] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:23:47.603] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:23:48.396] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:23:49.364] [mlr3]  Finished benchmark 
INFO  [09:23:49.436] [bbotk] Result of batch 74: 
INFO  [09:23:49.438] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:23:49.438] [bbotk]                  10              4891      0.0687675        0.548 -0.8704946 
INFO  [09:23:49.438] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:23:49.438] [bbotk]          <NA>         0.5 5f849795-1b1b-4c8c-a7bf-64ff4b437f02 
DEBUG [09:23:50.240] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.03082e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.004030819 0.408932 
  - best initial criterion value(s) :  288.1547 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -288.15  |proj g|=       1.0588
At iterate     1  f =      -326.55  |proj g|=        4.5994
At iterate     2  f =      -331.43  |proj g|=        4.7358
At iterate     3  f =      -335.58  |proj g|=        4.8639
At iterate     4  f =      -343.63  |proj g|=        5.1765
At iterate     5  f =      -343.82  |proj g|=        5.1737
At iterate     6  f =      -343.87  |proj g|=        5.1709
At iterate     7  f =       -343.9  |proj g|=         5.168
At iterate     8  f =      -343.97  |proj g|=         5.159
At iterate     9  f =      -344.14  |proj g|=        5.1352
At iterate    10  f =      -344.57  |proj g|=        5.0719
At iterate    11  f =      -345.57  |proj g|=        4.9185
At iterate    12  f =      -347.95  |proj g|=        4.4166
At iterate    13  f =       -354.2  |proj g|=        1.1825
At iterate    14  f =      -384.23  |proj g|=        9.0543
ys=-5.431e+00  -gs= 1.950e+01, BFGS update SKIPPED
At iterate    15  f =      -385.24  |proj g|=        2.0403
At iterate    16  f =      -385.65  |proj g|=       0.10436
At iterate    17  f =      -385.65  |proj g|=     0.0072949
At iterate    18  f =      -385.65  |proj g|=     0.0072949

iterations 18
function evaluations 21
segments explored during Cauchy searches 21
BFGS updates skipped 1
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00729491
final function value -385.649

F = -385.649
final  value -385.648835 
converged
 
INFO  [09:23:50.245] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:23:50.306] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:23:50.313] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:24:00.319] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:24:10.314] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:24:21.151] [mlr3]  Finished benchmark 
INFO  [09:24:21.218] [bbotk] Result of batch 75: 
INFO  [09:24:21.219] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:24:21.219] [bbotk]                   3               737       0.262483        0.578 -0.8703811 
INFO  [09:24:21.219] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:24:21.219] [bbotk]          <NA>   0.9759396 a200dbcc-8870-44e4-8a22-12059271e9eb 
DEBUG [09:24:22.042] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.006219e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.004006219 0.4047249 
  - best initial criterion value(s) :  291.3853 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -291.39  |proj g|=       5.4665
At iterate     1  f =      -314.08  |proj g|=        5.5322
At iterate     2  f =      -321.47  |proj g|=         4.179
At iterate     3  f =      -323.86  |proj g|=        3.6401
At iterate     4  f =      -327.03  |proj g|=        2.8207
At iterate     5  f =      -327.45  |proj g|=        2.6842
At iterate     6  f =      -328.14  |proj g|=        2.6368
At iterate     7  f =      -334.68  |proj g|=        2.4052
At iterate     8  f =      -351.59  |proj g|=        2.6869
At iterate     9  f =      -373.83  |proj g|=        2.2145
At iterate    10  f =      -380.77  |proj g|=        2.0649
At iterate    11  f =      -388.85  |proj g|=        1.4903
At iterate    12  f =      -388.88  |proj g|=       0.41464
At iterate    13  f =      -388.88  |proj g|=     0.0077523
At iterate    14  f =      -388.88  |proj g|=     0.0077523

iterations 14
function evaluations 24
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00775225
final function value -388.884

F = -388.884
final  value -388.884207 
converged
 
INFO  [09:24:22.046] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:24:22.099] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:24:22.106] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:24:22.874] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:24:23.784] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:24:24.547] [mlr3]  Finished benchmark 
INFO  [09:24:24.612] [bbotk] Result of batch 76: 
INFO  [09:24:24.614] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:24:24.614] [bbotk]                  10              2417     0.08840119        0.581 -0.8701593 
INFO  [09:24:24.614] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:24:24.614] [bbotk]          <NA>         0.5 5b1dbc77-ea0f-4d22-9560-bc1cceab6414 
DEBUG [09:24:25.423] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.087916e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.004087916 0.4100629 
  - best initial criterion value(s) :  314.8058 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -314.81  |proj g|=       12.768
At iterate     1  f =      -346.53  |proj g|=        5.1088
At iterate     2  f =       -372.9  |proj g|=        3.1844
At iterate     3  f =      -384.42  |proj g|=        12.624
At iterate     4  f =      -388.11  |proj g|=        1.9555
At iterate     5  f =       -388.2  |proj g|=       0.14717
At iterate     6  f =      -388.22  |proj g|=       0.20448
At iterate     7  f =       -388.5  |proj g|=        2.3133
At iterate     8  f =      -389.09  |proj g|=        4.9876
At iterate     9  f =      -390.48  |proj g|=        6.0693
At iterate    10  f =      -390.93  |proj g|=        3.2465
At iterate    11  f =      -391.11  |proj g|=      0.045963
At iterate    12  f =      -391.11  |proj g|=     0.0085165
At iterate    13  f =      -391.11  |proj g|=     0.0085165

iterations 13
function evaluations 19
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00851649
final function value -391.109

F = -391.109
final  value -391.109407 
converged
 
INFO  [09:24:25.427] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:24:25.480] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:24:25.487] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:24:33.172] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:24:41.606] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:24:49.576] [mlr3]  Finished benchmark 
INFO  [09:24:49.648] [bbotk] Result of batch 77: 
INFO  [09:24:49.650] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:24:49.650] [bbotk]                   7               548      0.2297516        0.571 -0.8709502 
INFO  [09:24:49.650] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:24:49.650] [bbotk]          <NA>   0.9790586 3eea4824-5e09-4a36-b30a-3a85958e29e6 
DEBUG [09:24:50.480] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.06464e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.00406464 0.4071357 
  - best initial criterion value(s) :  302.7934 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -302.79  |proj g|=       6.7841
At iterate     1  f =      -311.45  |proj g|=        1.7593
At iterate     2  f =      -329.74  |proj g|=        4.1871
At iterate     3  f =       -338.4  |proj g|=        3.4862
At iterate     4  f =      -358.46  |proj g|=        7.9655
At iterate     5  f =      -359.46  |proj g|=        1.9169
At iterate     6  f =       -359.6  |proj g|=       0.29648
At iterate     7  f =      -359.63  |proj g|=       0.14248
At iterate     8  f =      -359.93  |proj g|=         2.356
At iterate     9  f =      -360.58  |proj g|=        5.2595
At iterate    10  f =      -362.28  |proj g|=         9.782
At iterate    11  f =      -363.16  |proj g|=        7.6242
At iterate    12  f =      -364.11  |proj g|=      0.057851
At iterate    13  f =      -364.11  |proj g|=      0.014545
At iterate    14  f =      -364.11  |proj g|=      0.014545

iterations 14
function evaluations 22
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0145452
final function value -364.114

F = -364.114
final  value -364.114381 
converged
 
INFO  [09:24:50.484] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:24:50.539] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:24:50.545] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:24:56.531] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:25:02.534] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:25:08.325] [mlr3]  Finished benchmark 
INFO  [09:25:08.403] [bbotk] Result of batch 78: 
INFO  [09:25:08.405] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:25:08.405] [bbotk]                   7               397       0.215883        0.584 -0.8733435 
INFO  [09:25:08.405] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:25:08.405] [bbotk]          <NA>   0.9781234 5ea11ab0-7d90-4239-9206-3f6326a4af00 
DEBUG [09:25:09.301] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.04123e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.004026278 0.404123 
  - best initial criterion value(s) :  342.9181 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -342.92  |proj g|=       6.1285
At iterate     1  f =      -373.76  |proj g|=        0.4001
At iterate     2  f =      -373.84  |proj g|=       0.00764
At iterate     3  f =      -373.85  |proj g|=     0.0076462
At iterate     4  f =      -373.85  |proj g|=       0.39985
At iterate     5  f =      -373.85  |proj g|=      0.007647

iterations 5
function evaluations 8
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00764699
final function value -373.848

F = -373.848
final  value -373.848255 
converged
 
INFO  [09:25:09.305] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:25:09.360] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:25:09.366] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:25:10.126] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:25:18.733] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:25:27.089] [mlr3]  Finished benchmark 
INFO  [09:25:27.155] [bbotk] Result of batch 79: 
INFO  [09:25:27.157] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [09:25:27.157] [bbotk]                   8               612     0.03028465        0.665 -0.902309 
INFO  [09:25:27.157] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:25:27.157] [bbotk]          <NA>      0.8152 67cac1cd-99c0-49b0-bea6-965215498f06 
DEBUG [09:25:28.126] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.00224e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.00398505 0.400224 
  - best initial criterion value(s) :  337.8522 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -337.85  |proj g|=       12.013
At iterate     1  f =      -356.67  |proj g|=        2.0205
At iterate     2  f =       -372.2  |proj g|=        3.1462
At iterate     3  f =      -378.02  |proj g|=         2.541
At iterate     4  f =         -385  |proj g|=       0.60203
At iterate     5  f =         -385  |proj g|=       0.89805
At iterate     6  f =      -385.03  |proj g|=        1.4982
At iterate     7  f =       -385.1  |proj g|=        1.9331
At iterate     8  f =      -385.26  |proj g|=         1.983
At iterate     9  f =       -385.7  |proj g|=        2.0624
At iterate    10  f =      -395.51  |proj g|=        2.1607
At iterate    11  f =      -396.25  |proj g|=        2.0667
At iterate    12  f =      -396.63  |proj g|=        1.9919
At iterate    13  f =      -396.89  |proj g|=      0.061268
At iterate    14  f =      -396.89  |proj g|=      0.010448
At iterate    15  f =      -396.89  |proj g|=      0.010448

iterations 15
function evaluations 26
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0104482
final function value -396.887

F = -396.887
final  value -396.886820 
converged
 
INFO  [09:25:28.130] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:25:28.191] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:25:28.201] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:26:20.903] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:26:21.675] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:27:15.088] [mlr3]  Finished benchmark 
INFO  [09:27:15.165] [bbotk] Result of batch 80: 
INFO  [09:27:15.167] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:27:15.167] [bbotk]                   8              4337      0.1414575        0.676 -0.8709246 
INFO  [09:27:15.167] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:27:15.167] [bbotk]          <NA>   0.8190622 a2f93a06-9705-4a94-8752-95a9ba21dc54 
DEBUG [09:27:15.973] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.963769e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003945497 0.3963769 
  - best initial criterion value(s) :  296.5643 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -296.56  |proj g|=       4.5983
At iterate     1  f =      -365.36  |proj g|=       0.52832
At iterate     2  f =      -370.63  |proj g|=        3.2432
At iterate     3  f =      -382.28  |proj g|=        2.4029
At iterate     4  f =      -387.55  |proj g|=      0.057487
At iterate     5  f =      -387.55  |proj g|=      0.013513
At iterate     6  f =      -387.55  |proj g|=      0.013513

iterations 6
function evaluations 12
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0135129
final function value -387.555

F = -387.555
final  value -387.554591 
converged
 
INFO  [09:27:15.989] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:27:16.043] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:27:16.051] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:28:01.327] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:28:45.805] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:29:31.183] [mlr3]  Finished benchmark 
INFO  [09:29:31.249] [bbotk] Result of batch 81: 
INFO  [09:29:31.250] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:29:31.250] [bbotk]                   5              3722      0.3049901        0.581 -0.8718549 
INFO  [09:29:31.250] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:29:31.250] [bbotk]          <NA>   0.9793283 434ada41-2105-40f2-8873-0341f862f729 
DEBUG [09:29:32.127] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.94215e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003931836 0.394215 
  - best initial criterion value(s) :  290.4874 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -290.49  |proj g|=        2.945
At iterate     1  f =      -301.33  |proj g|=        5.2494
At iterate     2  f =      -306.41  |proj g|=        4.8567
At iterate     3  f =      -309.34  |proj g|=          4.49
At iterate     4  f =      -315.35  |proj g|=        3.8214
At iterate     5  f =      -328.69  |proj g|=        2.2572
At iterate     6  f =      -330.62  |proj g|=        2.0244
At iterate     7  f =      -330.95  |proj g|=        2.1427
At iterate     8  f =      -331.02  |proj g|=        2.0584
At iterate     9  f =      -331.05  |proj g|=        2.0857
At iterate    10  f =      -331.61  |proj g|=        2.0337
At iterate    11  f =      -334.81  |proj g|=        1.8724
At iterate    12  f =      -337.57  |proj g|=        1.8026
At iterate    13  f =      -342.31  |proj g|=       0.39028
At iterate    14  f =       -347.3  |proj g|=        1.0108
At iterate    15  f =       -358.6  |proj g|=       0.83684
At iterate    16  f =      -358.61  |proj g|=       0.18678
At iterate    17  f =      -358.61  |proj g|=      0.021997
At iterate    18  f =      -358.61  |proj g|=      0.021997

iterations 18
function evaluations 27
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0219973
final function value -358.614

F = -358.614
final  value -358.614194 
converged
 
INFO  [09:29:32.131] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:29:32.185] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:29:32.192] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:30:21.782] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:31:10.752] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:31:11.497] [mlr3]  Finished benchmark 
INFO  [09:31:11.561] [bbotk] Result of batch 82: 
INFO  [09:31:11.563] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:31:11.563] [bbotk]                   8              4089      0.3233179        0.605 -0.8743398 
INFO  [09:31:11.563] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:31:11.563] [bbotk]          <NA>   0.8181529 5f18e3b6-b6bb-40d3-9f78-22ca6a020957 
DEBUG [09:31:12.414] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.905103e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003888614 0.3905103 
  - best initial criterion value(s) :  359.2152 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -359.22  |proj g|=       9.6923
At iterate     1  f =      -370.69  |proj g|=        2.2686
At iterate     2  f =      -392.39  |proj g|=        4.1043
At iterate     3  f =       -399.8  |proj g|=        3.5127
At iterate     4  f =      -422.68  |proj g|=        3.3451
At iterate     5  f =      -422.83  |proj g|=       0.57143
At iterate     6  f =      -422.86  |proj g|=       0.17409
At iterate     7  f =      -422.88  |proj g|=       0.69769
At iterate     8  f =      -422.94  |proj g|=        1.6737
At iterate     9  f =      -423.07  |proj g|=        2.5239
At iterate    10  f =      -423.12  |proj g|=         1.818
At iterate    11  f =      -423.18  |proj g|=      0.010407
At iterate    12  f =      -423.18  |proj g|=     0.0093303
At iterate    13  f =      -423.18  |proj g|=     0.0093303

iterations 13
function evaluations 20
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00933025
final function value -423.175

F = -423.175
final  value -423.175457 
converged
 
INFO  [09:31:12.418] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:31:12.472] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:31:12.479] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:31:13.225] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:31:14.102] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:31:14.831] [mlr3]  Finished benchmark 
INFO  [09:31:14.900] [bbotk] Result of batch 83: 
INFO  [09:31:14.904] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [09:31:14.904] [bbotk]                  10              4163      0.4809266        0.598 -0.869377 
INFO  [09:31:14.904] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:31:14.904] [bbotk]          <NA>         0.5 316edf4b-f070-46e4-9535-21e3bfdc62b6 
DEBUG [09:31:15.972] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.982083e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003954122 0.3982083 
  - best initial criterion value(s) :  319.9831 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -319.98  |proj g|=      0.42285
At iterate     1  f =      -352.58  |proj g|=        4.8221
At iterate     2  f =       -354.4  |proj g|=        4.7889
At iterate     3  f =      -363.11  |proj g|=         4.655
At iterate     4  f =      -363.22  |proj g|=         4.654
At iterate     5  f =      -363.24  |proj g|=        4.6534
At iterate     6  f =      -363.25  |proj g|=        4.6525
At iterate     7  f =      -363.28  |proj g|=        4.6491
At iterate     8  f =      -363.35  |proj g|=        4.6404
At iterate     9  f =      -363.55  |proj g|=        4.6162
At iterate    10  f =      -364.02  |proj g|=        4.5558
At iterate    11  f =      -365.18  |proj g|=        4.4018
At iterate    12  f =      -368.01  |proj g|=        4.0236
At iterate    13  f =      -375.59  |proj g|=        2.3565
At iterate    14  f =      -400.82  |proj g|=        9.3195
At iterate    15  f =      -402.03  |proj g|=        3.4527
At iterate    16  f =      -402.21  |proj g|=      0.061323
At iterate    17  f =      -402.21  |proj g|=      0.014044
At iterate    18  f =      -402.21  |proj g|=      0.014044

iterations 18
function evaluations 24
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0140438
final function value -402.213

F = -402.213
final  value -402.213215 
converged
 
INFO  [09:31:15.977] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:31:16.045] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:31:16.053] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:31:35.588] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:31:54.450] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:32:12.923] [mlr3]  Finished benchmark 
INFO  [09:32:12.990] [bbotk] Result of batch 84: 
INFO  [09:32:12.992] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:32:12.992] [bbotk]                   7              1485       0.316699        0.803 -0.8713155 
INFO  [09:32:12.992] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:32:12.992] [bbotk]          <NA>   0.9796589 97f9a762-343a-4ba0-acea-a75434281e38 
DEBUG [09:32:13.817] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.961564e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003938281 0.3961564 
  - best initial criterion value(s) :  345.7207 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -345.72  |proj g|=        4.806
At iterate     1  f =      -387.08  |proj g|=       0.39222
At iterate     2  f =      -387.16  |proj g|=       0.01096
At iterate     3  f =      -387.16  |proj g|=       0.01097
At iterate     4  f =      -387.16  |proj g|=       0.34371
At iterate     5  f =      -387.16  |proj g|=      0.010971

iterations 5
function evaluations 8
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0109707
final function value -387.165

F = -387.165
final  value -387.164769 
converged
 
INFO  [09:32:13.821] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:32:13.873] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:32:13.880] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:32:44.207] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:33:14.419] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:33:15.224] [mlr3]  Finished benchmark 
INFO  [09:33:15.289] [bbotk] Result of batch 85: 
INFO  [09:33:15.291] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:33:15.291] [bbotk]                   8              2492      0.2284845        0.613 -0.9010987 
INFO  [09:33:15.291] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:33:15.291] [bbotk]          <NA>   0.8190938 de01b4d5-b572-43c6-8f17-30022f2c97e4 
DEBUG [09:33:16.099] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.925204e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003918313 0.3925203 
  - best initial criterion value(s) :  347.8528 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -347.85  |proj g|=       6.3148
At iterate     1  f =      -383.56  |proj g|=        0.3886
At iterate     2  f =      -383.68  |proj g|=      0.012771
At iterate     3  f =      -383.69  |proj g|=      0.012783
At iterate     4  f =      -383.69  |proj g|=       0.38833
At iterate     5  f =      -383.69  |proj g|=      0.012785

iterations 5
function evaluations 8
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0127853
final function value -383.686

F = -383.686
final  value -383.686500 
converged
 
INFO  [09:33:16.103] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:33:16.156] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:33:16.163] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:34:13.225] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:35:10.018] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:36:07.231] [mlr3]  Finished benchmark 
INFO  [09:36:07.298] [bbotk] Result of batch 86: 
INFO  [09:36:07.300] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:36:07.300] [bbotk]                   6              4679      0.1299714         0.59 -0.9016209 
INFO  [09:36:07.300] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:36:07.300] [bbotk]          <NA>   0.9796819 2420ca4e-128e-4d2b-9322-d5e1ebe1bea0 
DEBUG [09:36:08.152] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.905349e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003879278 0.3905349 
  - best initial criterion value(s) :  376.1807 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -376.18  |proj g|=       6.3865
At iterate     1  f =      -414.03  |proj g|=       0.38666
At iterate     2  f =      -414.05  |proj g|=     0.0086568
At iterate     3  f =      -414.05  |proj g|=     0.0086586
At iterate     4  f =      -414.05  |proj g|=      0.020118
At iterate     5  f =      -414.05  |proj g|=     0.0086587

iterations 5
function evaluations 8
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00865872
final function value -414.051

F = -414.051
final  value -414.051186 
converged
 
INFO  [09:36:08.156] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:36:08.209] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:36:08.215] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:36:39.684] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:37:11.126] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:37:42.369] [mlr3]  Finished benchmark 
INFO  [09:37:42.445] [bbotk] Result of batch 87: 
INFO  [09:37:42.447] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [09:37:42.447] [bbotk]                   7              2551      0.2042191        0.611 -0.899064 
INFO  [09:37:42.447] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:37:42.447] [bbotk]          <NA>   0.9795839 cad8fc44-dd7a-4933-a883-6ab0755e45ec 
DEBUG [09:37:43.301] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.885538e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003874913 0.3885538 
  - best initial criterion value(s) :  331.0319 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -331.03  |proj g|=      0.82406
At iterate     1  f =      -358.05  |proj g|=        5.3318
At iterate     2  f =      -365.95  |proj g|=         5.484
At iterate     3  f =       -369.2  |proj g|=        5.6165
At iterate     4  f =      -374.21  |proj g|=        5.7856
At iterate     5  f =      -374.41  |proj g|=        5.7823
At iterate     6  f =       -374.5  |proj g|=        5.7769
At iterate     7  f =      -374.56  |proj g|=        5.7708
At iterate     8  f =      -374.66  |proj g|=        5.7576
At iterate     9  f =      -374.93  |proj g|=        5.7216
At iterate    10  f =      -375.58  |proj g|=        5.6299
At iterate    11  f =      -377.12  |proj g|=        5.4046
At iterate    12  f =      -380.95  |proj g|=        3.3898
At iterate    13  f =      -392.23  |proj g|=        4.5754
At iterate    14  f =      -430.49  |proj g|=        7.9488
ys=-1.719e+01  -gs= 2.125e+01, BFGS update SKIPPED
At iterate    15  f =      -431.48  |proj g|=       0.20059
At iterate    16  f =      -431.48  |proj g|=       0.01336
At iterate    17  f =      -431.48  |proj g|=       0.01336

iterations 17
function evaluations 20
segments explored during Cauchy searches 20
BFGS updates skipped 1
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0133599
final function value -431.478

F = -431.478
final  value -431.477872 
converged
 
INFO  [09:37:43.306] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:37:43.375] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:37:43.383] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:37:44.188] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:37:45.155] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:37:45.963] [mlr3]  Finished benchmark 
INFO  [09:37:46.035] [bbotk] Result of batch 88: 
INFO  [09:37:46.037] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:37:46.037] [bbotk]                  10              1900     0.05705279        0.596 -0.8700323 
INFO  [09:37:46.037] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:37:46.037] [bbotk]          <NA>         0.5 207218dd-9ce5-45f1-b281-737d611fcff8 
DEBUG [09:37:46.885] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.95935e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003948402 0.395935 
  - best initial criterion value(s) :  339.3104 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -339.31  |proj g|=       13.382
At iterate     1  f =      -409.83  |proj g|=        4.8372
At iterate     2  f =      -439.39  |proj g|=        3.4533
At iterate     3  f =      -441.71  |proj g|=        3.2387
At iterate     4  f =      -458.75  |proj g|=        2.1557
At iterate     5  f =      -459.61  |proj g|=        2.7543
At iterate     6  f =      -459.72  |proj g|=       0.67689
At iterate     7  f =      -459.76  |proj g|=      0.062189
At iterate     8  f =       -459.9  |proj g|=        1.5362
At iterate     9  f =      -460.18  |proj g|=        2.0433
At iterate    10  f =      -460.97  |proj g|=        2.1513
At iterate    11  f =      -462.83  |proj g|=        2.2677
At iterate    12  f =      -463.46  |proj g|=        2.2019
At iterate    13  f =      -464.57  |proj g|=       0.24042
At iterate    14  f =      -464.57  |proj g|=     0.0090127
At iterate    15  f =      -464.57  |proj g|=     0.0090127

iterations 15
function evaluations 22
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00901265
final function value -464.566

F = -464.566
final  value -464.566054 
converged
 
INFO  [09:37:46.889] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:37:46.948] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:37:46.956] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:38:10.373] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:38:33.806] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:38:34.550] [mlr3]  Finished benchmark 
INFO  [09:38:34.615] [bbotk] Result of batch 89: 
INFO  [09:38:34.617] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [09:38:34.617] [bbotk]                   8              1864      0.3931641        0.594 -0.868622 
INFO  [09:38:34.617] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:38:34.617] [bbotk]          <NA>    0.818913 f815b9aa-a08f-4a7e-abde-75936a1469e3 
DEBUG [09:38:35.517] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.924284e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003911602 0.3924284 
  - best initial criterion value(s) :  341.3615 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -341.36  |proj g|=       10.831
At iterate     1  f =      -356.16  |proj g|=        6.5593
At iterate     2  f =      -369.31  |proj g|=        4.3939
At iterate     3  f =      -387.09  |proj g|=        3.7024
At iterate     4  f =      -393.76  |proj g|=        2.6795
At iterate     5  f =      -399.99  |proj g|=        2.2711
At iterate     6  f =      -400.34  |proj g|=        2.0902
At iterate     7  f =      -400.44  |proj g|=        2.1196
At iterate     8  f =      -400.99  |proj g|=        2.0039
At iterate     9  f =      -430.36  |proj g|=        1.4617
At iterate    10  f =      -460.96  |proj g|=        1.4635
At iterate    11  f =         -461  |proj g|=        0.1082
At iterate    12  f =         -461  |proj g|=      0.010468
At iterate    13  f =         -461  |proj g|=      0.010468

iterations 13
function evaluations 22
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0104675
final function value -460.997

F = -460.997
final  value -460.996796 
converged
 
INFO  [09:38:35.522] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:38:35.575] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:38:35.582] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:39:27.958] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:40:19.683] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:41:11.828] [mlr3]  Finished benchmark 
INFO  [09:41:11.904] [bbotk] Result of batch 90: 
INFO  [09:41:11.905] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:41:11.905] [bbotk]                   3              4327      0.2850331         0.63 -0.8689618 
INFO  [09:41:11.905] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:41:11.905] [bbotk]          <NA>   0.9787413 9d1ed819-671a-4e3b-b345-7d780bdfdd4a 
DEBUG [09:41:12.772] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.905149e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003903985 0.3905149 
  - best initial criterion value(s) :  412.7981 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -412.8  |proj g|=       5.3934
At iterate     1  f =      -437.91  |proj g|=     0.0090102
At iterate     2  f =       -441.7  |proj g|=             0

iterations 2
function evaluations 16
segments explored during Cauchy searches 5
BFGS updates skipped 0
active bounds at final generalized Cauchy point 3
norm of the final projected gradient 0
final function value -441.696

F = -441.696
final  value -441.695907 
converged
 
INFO  [09:41:12.776] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:41:12.829] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:41:12.836] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:41:53.760] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:41:54.528] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:42:35.597] [mlr3]  Finished benchmark 
INFO  [09:42:35.674] [bbotk] Result of batch 91: 
INFO  [09:42:35.676] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [09:42:35.676] [bbotk]                   8              3381       0.137722        0.625 -0.898097 
INFO  [09:42:35.676] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:42:35.676] [bbotk]          <NA>   0.8192494 95dcba43-7ad2-4b77-b533-d8109a00346b 
DEBUG [09:42:36.562] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.871212e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003871212 0.387399 
  - best initial criterion value(s) :  364.9204 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -364.92  |proj g|=       6.5738
At iterate     1  f =      -374.73  |proj g|=        6.0984
At iterate     2  f =      -422.18  |proj g|=        2.3039
At iterate     3  f =      -422.84  |proj g|=         2.101
At iterate     4  f =      -423.77  |proj g|=        2.0778
At iterate     5  f =      -423.92  |proj g|=        1.9852
At iterate     6  f =      -444.47  |proj g|=        1.9791
At iterate     7  f =      -453.08  |proj g|=       0.25698
At iterate     8  f =      -453.08  |proj g|=       0.01565
At iterate     9  f =      -453.08  |proj g|=      0.014363
At iterate    10  f =      -453.08  |proj g|=      0.014363

iterations 10
function evaluations 22
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0143626
final function value -453.083

F = -453.083
final  value -453.083446 
converged
 
INFO  [09:42:36.566] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:42:36.619] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:42:36.626] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:42:37.455] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:42:48.312] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:42:59.268] [mlr3]  Finished benchmark 
INFO  [09:42:59.333] [bbotk] Result of batch 92: 
INFO  [09:42:59.335] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:42:59.335] [bbotk]                   8               837      0.2280586        0.619 -0.8698815 
INFO  [09:42:59.335] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:42:59.335] [bbotk]          <NA>   0.8194414 90621126-a297-4076-bd54-be3a82259810 
DEBUG [09:43:00.214] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.837851e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003836108 0.3837851 
  - best initial criterion value(s) :  402.4555 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -402.46  |proj g|=       1.1158
At iterate     1  f =      -432.08  |proj g|=        4.5828
At iterate     2  f =      -436.29  |proj g|=        4.3666
At iterate     3  f =      -437.14  |proj g|=        4.3515
At iterate     4  f =      -437.69  |proj g|=        4.3192
At iterate     5  f =      -440.53  |proj g|=        4.0887
At iterate     6  f =      -444.94  |proj g|=        3.6355
At iterate     7  f =      -454.71  |proj g|=        4.3892
At iterate     8  f =       -472.6  |proj g|=        7.3029
At iterate     9  f =      -473.37  |proj g|=        1.9849
At iterate    10  f =      -473.44  |proj g|=      0.038045
At iterate    11  f =      -473.44  |proj g|=      0.011761
At iterate    12  f =      -473.44  |proj g|=      0.011761

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0117612
final function value -473.435

F = -473.435
final  value -473.435367 
converged
 
INFO  [09:43:00.218] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:43:00.273] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:43:00.280] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:43:01.064] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:43:01.831] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:43:02.733] [mlr3]  Finished benchmark 
INFO  [09:43:02.811] [bbotk] Result of batch 93: 
INFO  [09:43:02.813] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:43:02.813] [bbotk]                  10              3039      0.4971593        0.633 -0.8684607 
INFO  [09:43:02.813] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:43:02.813] [bbotk]          <NA>         0.5 e982f2ae-2be7-4df2-bde4-f38799d01333 
DEBUG [09:43:03.900] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.907329e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003892363 0.3907329 
  - best initial criterion value(s) :  393.7291 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -393.73  |proj g|=       4.9023
At iterate     1  f =      -412.82  |proj g|=        5.6581
At iterate     2  f =       -423.2  |proj g|=        4.2322
At iterate     3  f =      -425.98  |proj g|=         3.762
At iterate     4  f =      -431.54  |proj g|=         1.986
At iterate     5  f =       -432.4  |proj g|=        2.5112
At iterate     6  f =      -433.16  |proj g|=        2.7286
At iterate     7  f =      -433.87  |proj g|=        2.5015
At iterate     8  f =      -433.95  |proj g|=          2.48
At iterate     9  f =      -434.32  |proj g|=        2.4256
At iterate    10  f =      -434.98  |proj g|=        2.3826
At iterate    11  f =      -436.66  |proj g|=        2.3478
At iterate    12  f =      -440.45  |proj g|=       0.42705
At iterate    13  f =      -448.25  |proj g|=        5.5121
At iterate    14  f =      -459.85  |proj g|=        10.992
At iterate    15  f =      -474.09  |proj g|=        8.3643
ys=-4.832e-03  -gs= 1.093e+01, BFGS update SKIPPED
At iterate    16  f =      -493.52  |proj g|=        12.493
At iterate    17  f =      -494.15  |proj g|=        12.445
At iterate    18  f =      -496.69  |proj g|=       0.44447
At iterate    19  f =      -496.69  |proj g|=      0.014944
At iterate    20  f =      -496.69  |proj g|=      0.008982
At iterate    21  f =      -496.69  |proj g|=      0.008982

iterations 21
function evaluations 30
segments explored during Cauchy searches 23
BFGS updates skipped 1
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00898201
final function value -496.691

F = -496.691
final  value -496.690567 
converged
 
INFO  [09:43:03.904] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:43:03.960] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:43:03.966] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:43:39.777] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:44:14.005] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:44:49.546] [mlr3]  Finished benchmark 
INFO  [09:44:49.612] [bbotk] Result of batch 94: 
INFO  [09:44:49.614] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:44:49.614] [bbotk]                   3              2874      0.4342505        0.786 -0.8672266 
INFO  [09:44:49.614] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:44:49.614] [bbotk]          <NA>    0.978759 7e1a6703-fc98-4767-8879-e291acc550d4 
DEBUG [09:44:50.487] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.88953e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003870171 0.388953 
  - best initial criterion value(s) :  382.8852 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -382.89  |proj g|=       11.555
At iterate     1  f =      -399.73  |proj g|=        1.6693
At iterate     2  f =      -422.06  |proj g|=        3.4019
At iterate     3  f =      -427.74  |proj g|=         2.787
At iterate     4  f =      -437.82  |proj g|=        12.686
At iterate     5  f =      -442.93  |proj g|=        1.4827
At iterate     6  f =      -442.97  |proj g|=      0.036471
At iterate     7  f =      -442.98  |proj g|=        0.2299
At iterate     8  f =      -443.03  |proj g|=         1.263
At iterate     9  f =      -443.14  |proj g|=        1.9461
At iterate    10  f =      -443.46  |proj g|=        2.0121
At iterate    11  f =      -443.85  |proj g|=        2.0189
At iterate    12  f =      -444.16  |proj g|=        1.9301
At iterate    13  f =      -444.22  |proj g|=       0.02399
At iterate    14  f =      -444.22  |proj g|=       0.02005
At iterate    15  f =      -444.22  |proj g|=       0.02005

iterations 15
function evaluations 21
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0200497
final function value -444.219

F = -444.219
final  value -444.218729 
converged
 
INFO  [09:44:50.491] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:44:50.544] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:44:50.551] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:45:09.456] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:45:10.242] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:45:29.880] [mlr3]  Finished benchmark 
INFO  [09:45:29.948] [bbotk] Result of batch 95: 
INFO  [09:45:29.950] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:45:29.950] [bbotk]                   8              1523      0.1343584         0.61 -0.8705167 
INFO  [09:45:29.950] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:45:29.950] [bbotk]          <NA>   0.8194682 5d081996-8c4e-404b-8e40-5721571508b7 
DEBUG [09:45:30.813] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.85678e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003847161 0.385678 
  - best initial criterion value(s) :  388.2083 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -388.21  |proj g|=        1.552
At iterate     1  f =      -436.04  |proj g|=        4.5855
At iterate     2  f =      -451.12  |proj g|=        5.2128
At iterate     3  f =      -454.48  |proj g|=        5.4364
At iterate     4  f =      -454.86  |proj g|=        5.4362
At iterate     5  f =      -454.94  |proj g|=        5.4341
At iterate     6  f =       -455.6  |proj g|=        5.3917
At iterate     7  f =      -463.59  |proj g|=        4.7474
At iterate     8  f =      -485.07  |proj g|=        4.6669
At iterate     9  f =      -509.62  |proj g|=        4.4098
ys=-4.377e+00  -gs= 1.833e+01, BFGS update SKIPPED
At iterate    10  f =      -509.88  |proj g|=        1.5988
At iterate    11  f =      -509.92  |proj g|=      0.019685
At iterate    12  f =      -509.92  |proj g|=     0.0090205
At iterate    13  f =      -509.92  |proj g|=     0.0090205

iterations 13
function evaluations 17
segments explored during Cauchy searches 15
BFGS updates skipped 1
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00902046
final function value -509.924

F = -509.924
final  value -509.924105 
converged
 
INFO  [09:45:30.817] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:45:30.873] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:45:30.880] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:45:43.100] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:45:56.519] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:46:09.204] [mlr3]  Finished benchmark 
INFO  [09:46:09.270] [bbotk] Result of batch 96: 
INFO  [09:46:09.272] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:46:09.272] [bbotk]                   5               943      0.2119092        0.607 -0.8667722 
INFO  [09:46:09.272] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:46:09.272] [bbotk]          <NA>   0.9792325 c243be51-f855-477e-8fcc-418ea849f266 
DEBUG [09:46:10.173] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.839602e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003812352 0.3839602 
  - best initial criterion value(s) :  436.9695 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -436.97  |proj g|=       5.9251
At iterate     1  f =      -444.49  |proj g|=        3.6444
At iterate     2  f =       -462.2  |proj g|=        3.8398
At iterate     3  f =      -472.96  |proj g|=        2.8837
At iterate     4  f =      -486.42  |proj g|=        1.9987
At iterate     5  f =      -486.43  |proj g|=        2.0085
At iterate     6  f =      -486.46  |proj g|=        2.0264
At iterate     7  f =      -486.52  |proj g|=         2.058
At iterate     8  f =      -486.69  |proj g|=        2.1057
At iterate     9  f =      -487.13  |proj g|=        2.1825
At iterate    10  f =      -488.23  |proj g|=        2.2996
At iterate    11  f =      -495.65  |proj g|=        2.3106
At iterate    12  f =      -496.36  |proj g|=         2.256
At iterate    13  f =      -504.33  |proj g|=       0.37444
At iterate    14  f =      -504.33  |proj g|=      0.022604
At iterate    15  f =      -504.33  |proj g|=      0.010793
At iterate    16  f =      -504.33  |proj g|=      0.010793

iterations 16
function evaluations 24
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0107928
final function value -504.33

F = -504.33
final  value -504.329685 
converged
 
INFO  [09:46:10.177] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:46:10.240] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:46:10.247] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:46:41.008] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:46:41.783] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:47:12.743] [mlr3]  Finished benchmark 
INFO  [09:47:12.820] [bbotk] Result of batch 97: 
INFO  [09:47:12.822] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:47:12.822] [bbotk]                   8              2558      0.1031569        0.624 -0.8671704 
INFO  [09:47:12.822] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:47:12.822] [bbotk]          <NA>   0.8193809 08c216e8-6403-438e-9e0c-8dbf3abec468 
DEBUG [09:47:13.720] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.807863e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003793854 0.3807863 
  - best initial criterion value(s) :  377.6365 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -377.64  |proj g|=       10.005
At iterate     1  f =      -413.73  |proj g|=         0.997
At iterate     2  f =      -423.41  |proj g|=        3.1394
At iterate     3  f =       -438.4  |proj g|=        7.1526
At iterate     4  f =      -457.69  |proj g|=        5.9079
At iterate     5  f =      -491.36  |proj g|=          3.88
At iterate     6  f =      -511.42  |proj g|=        2.7097
At iterate     7  f =         -518  |proj g|=        2.2394
At iterate     8  f =      -519.95  |proj g|=        2.2214
At iterate     9  f =      -520.57  |proj g|=        5.7698
At iterate    10  f =      -521.09  |proj g|=       0.13918
At iterate    11  f =      -521.09  |proj g|=     0.0093689
At iterate    12  f =      -521.09  |proj g|=     0.0093689

iterations 12
function evaluations 21
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00936885
final function value -521.086

F = -521.086
final  value -521.086423 
converged
 
INFO  [09:47:13.724] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:47:13.776] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:47:13.783] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:47:56.327] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:48:38.632] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:49:21.609] [mlr3]  Finished benchmark 
INFO  [09:49:21.675] [bbotk] Result of batch 98: 
INFO  [09:49:21.676] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:49:21.676] [bbotk]                   7              3539      0.1573996        0.627 -0.8664035 
INFO  [09:49:21.676] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:49:21.676] [bbotk]          <NA>   0.9795849 d0db5757-645d-49ec-a638-ad9a7df3ce9b 
DEBUG [09:49:22.735] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.791251e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003791251 0.3791376 
  - best initial criterion value(s) :  392.7495 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -392.75  |proj g|=       4.8622
At iterate     1  f =       -457.4  |proj g|=        13.044
At iterate     2  f =      -462.23  |proj g|=        12.873
At iterate     3  f =      -471.98  |proj g|=       0.16591
At iterate     4  f =      -471.98  |proj g|=      0.019627
At iterate     5  f =      -471.98  |proj g|=      0.019626

iterations 5
function evaluations 8
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0196264
final function value -471.984

F = -471.984
final  value -471.984405 
converged
 
INFO  [09:49:22.739] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:49:22.794] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:49:22.801] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:49:23.524] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:49:24.322] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:49:25.281] [mlr3]  Finished benchmark 
INFO  [09:49:25.345] [bbotk] Result of batch 99: 
INFO  [09:49:25.347] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:49:25.347] [bbotk]                  10              2610      0.3414462        0.783 -0.8695203 
INFO  [09:49:25.347] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:49:25.347] [bbotk]          <NA>         0.5 2be561ec-7baf-4bcb-b5ef-83d6b30ddd6c 
DEBUG [09:49:26.447] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.85773e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003839538 0.385773 
  - best initial criterion value(s) :  421.4136 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -421.41  |proj g|=       4.8935
At iterate     1  f =      -448.38  |proj g|=      0.016935
At iterate     2  f =      -470.77  |proj g|=      0.012694
At iterate     3  f =      -492.69  |proj g|=             0

iterations 3
function evaluations 17
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 4
norm of the final projected gradient 0
final function value -492.686

F = -492.686
final  value -492.686266 
converged
 
INFO  [09:49:26.451] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:49:26.504] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:49:26.511] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:49:27.324] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:50:17.110] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:51:06.294] [mlr3]  Finished benchmark 
INFO  [09:51:06.378] [bbotk] Result of batch 100: 
INFO  [09:51:06.380] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:51:06.380] [bbotk]                   8              4081      0.1590876        0.787 -0.8974641 
INFO  [09:51:06.380] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:51:06.380] [bbotk]          <NA>   0.8190233 307e00d9-e9bc-4975-bda1-df90974a8cbb 
DEBUG [09:51:07.289] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.826562e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003813735 0.3826562 
  - best initial criterion value(s) :  444.1077 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -444.11  |proj g|=       5.7851
At iterate     1  f =      -445.04  |proj g|=        5.6594
At iterate     2  f =      -446.41  |proj g|=        5.6425
At iterate     3  f =      -450.41  |proj g|=         5.504
At iterate     4  f =      -453.63  |proj g|=        5.1132
At iterate     5  f =      -469.27  |proj g|=        4.6521
At iterate     6  f =      -510.76  |proj g|=        2.9275
At iterate     7  f =      -511.26  |proj g|=          2.92
At iterate     8  f =      -514.06  |proj g|=        2.7481
At iterate     9  f =      -519.44  |proj g|=        2.3978
At iterate    10  f =      -522.21  |proj g|=        2.1461
At iterate    11  f =      -522.83  |proj g|=       0.26616
At iterate    12  f =      -522.83  |proj g|=      0.012224
At iterate    13  f =      -522.83  |proj g|=      0.012224

iterations 13
function evaluations 19
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0122238
final function value -522.829

F = -522.829
final  value -522.829367 
converged
 
INFO  [09:51:07.293] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:51:07.351] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:51:07.358] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:51:46.141] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:51:46.885] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:52:24.284] [mlr3]  Finished benchmark 
INFO  [09:52:24.350] [bbotk] Result of batch 101: 
INFO  [09:52:24.352] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:52:24.352] [bbotk]                   8              3155     0.09297914        0.639 -0.8666883 
INFO  [09:52:24.352] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:52:24.352] [bbotk]          <NA>   0.8195134 37b5a488-1033-443b-a270-f20e46de5a1e 
DEBUG [09:52:25.398] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.795875e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003785421 0.3795875 
  - best initial criterion value(s) :  409.3499 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -409.35  |proj g|=       3.5582
At iterate     1  f =      -415.14  |proj g|=        5.6909
At iterate     2  f =      -439.53  |proj g|=        4.2631
At iterate     3  f =      -462.87  |proj g|=         2.829
At iterate     4  f =      -477.96  |proj g|=        2.1759
At iterate     5  f =      -478.57  |proj g|=        2.1414
At iterate     6  f =       -479.8  |proj g|=      0.022412
At iterate     7  f =       -479.8  |proj g|=      0.022412
At iterate     8  f =       -479.8  |proj g|=      0.022412

iterations 8
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.022412
final function value -479.795

F = -479.795
final  value -479.795057 
converged
 
INFO  [09:52:25.402] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:52:25.461] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:52:25.467] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:52:35.635] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:52:45.924] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:52:56.821] [mlr3]  Finished benchmark 
INFO  [09:52:56.896] [bbotk] Result of batch 102: 
INFO  [09:52:56.898] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:52:56.898] [bbotk]                   4               805    0.008407705        0.795 -0.8690313 
INFO  [09:52:56.898] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:52:56.898] [bbotk]          <NA>   0.9606228 4fdebb6a-2848-4084-9c1d-70dcf6661be9 
DEBUG [09:52:57.812] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.776476e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003762453 0.3776476 
  - best initial criterion value(s) :  404.9869 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -404.99  |proj g|=       9.5574
At iterate     1  f =      -429.03  |proj g|=        1.0799
At iterate     2  f =      -450.08  |proj g|=        7.7185
At iterate     3  f =      -459.75  |proj g|=        7.0345
At iterate     4  f =      -472.03  |proj g|=        6.5116
At iterate     5  f =      -492.14  |proj g|=        5.1221
At iterate     6  f =      -532.25  |proj g|=        2.9806
At iterate     7  f =      -540.56  |proj g|=           2.4
At iterate     8  f =      -541.77  |proj g|=        2.3093
At iterate     9  f =      -543.22  |proj g|=        2.1756
At iterate    10  f =      -544.03  |proj g|=        2.3349
At iterate    11  f =      -544.11  |proj g|=      0.052174
At iterate    12  f =      -544.11  |proj g|=     0.0096464
At iterate    13  f =      -544.11  |proj g|=     0.0096464

iterations 13
function evaluations 24
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0096464
final function value -544.107

F = -544.107
final  value -544.107245 
converged
 
INFO  [09:52:57.815] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:52:57.866] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:52:57.874] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:52:58.733] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:52:59.598] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:53:00.611] [mlr3]  Finished benchmark 
INFO  [09:53:00.679] [bbotk] Result of batch 103: 
INFO  [09:53:00.681] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:53:00.681] [bbotk]                  10               779      0.3416666        0.631 -0.8602504 
INFO  [09:53:00.681] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:53:00.681] [bbotk]          <NA>         0.5 dab25074-e653-4460-8705-2ad82db68c65 
DEBUG [09:53:01.598] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.839735e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9852421 
  - variance bounds :  0.003839039 0.3839734 
  - best initial criterion value(s) :  429.6115 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -429.61  |proj g|=       12.948
At iterate     1  f =      -481.62  |proj g|=         5.019
At iterate     2  f =      -485.96  |proj g|=        4.7799
At iterate     3  f =      -496.43  |proj g|=        4.1056
At iterate     4  f =      -518.57  |proj g|=        2.8094
At iterate     5  f =       -530.2  |proj g|=        2.2328
At iterate     6  f =      -530.29  |proj g|=        2.2306
At iterate     7  f =      -531.37  |proj g|=        3.8821
At iterate     8  f =       -531.6  |proj g|=      0.071428
At iterate     9  f =      -531.61  |proj g|=      0.068988
At iterate    10  f =      -531.67  |proj g|=        1.2254
At iterate    11  f =      -531.79  |proj g|=        2.0277
At iterate    12  f =      -532.14  |proj g|=         2.098
At iterate    13  f =       -532.6  |proj g|=        2.1079
At iterate    14  f =      -532.92  |proj g|=        2.0246
At iterate    15  f =         -533  |proj g|=      0.036021
At iterate    16  f =         -533  |proj g|=      0.012427
At iterate    17  f =         -533  |proj g|=      0.012427

iterations 17
function evaluations 22
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0124271
final function value -532.999

F = -532.999
final  value -532.999137 
converged
 
INFO  [09:53:01.602] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:53:01.658] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:53:01.665] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:53:13.983] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:53:25.817] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:53:38.065] [mlr3]  Finished benchmark 
INFO  [09:53:38.140] [bbotk] Result of batch 104: 
INFO  [09:53:38.143] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:53:38.143] [bbotk]                   4               959    0.001811446        0.632 -0.8619285 
INFO  [09:53:38.143] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:53:38.143] [bbotk]          <NA>   0.9362131 e4818334-2044-4e45-a9f5-dbf5149143c3 
DEBUG [09:53:39.069] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.81648e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9954813 
  - variance bounds :  0.003809492 0.381648 
  - best initial criterion value(s) :  399.1571 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -399.16  |proj g|=       2.9686
At iterate     1  f =      -410.49  |proj g|=        1.8533
At iterate     2  f =      -415.12  |proj g|=        2.6641
At iterate     3  f =      -416.78  |proj g|=        1.1226
At iterate     4  f =      -417.01  |proj g|=        1.2444
At iterate     5  f =      -417.03  |proj g|=        1.4259
At iterate     6  f =      -417.31  |proj g|=       0.62969
At iterate     7  f =      -417.71  |proj g|=       0.36313
At iterate     8  f =      -417.72  |proj g|=       0.36289
At iterate     9  f =      -417.72  |proj g|=      0.023279
At iterate    10  f =      -417.72  |proj g|=        0.3628
At iterate    11  f =      -417.72  |proj g|=     0.0088161
At iterate    12  f =      -417.72  |proj g|=     0.0020364

iterations 12
function evaluations 19
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00203637
final function value -417.719

F = -417.719
final  value -417.719483 
converged
 
INFO  [09:53:39.073] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:53:39.130] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:53:39.137] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:53:46.461] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:53:53.857] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:54:01.278] [mlr3]  Finished benchmark 
INFO  [09:54:01.344] [bbotk] Result of batch 105: 
INFO  [09:54:01.346] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:54:01.346] [bbotk]                   3               544     0.07859861        0.648 -0.9137188 
INFO  [09:54:01.346] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:54:01.346] [bbotk]          <NA>    0.970065 fa1ad9d4-e6c9-4367-9358-37d0c2c3aae9 
DEBUG [09:54:02.263] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.799401e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9954813 
  - variance bounds :  0.003783758 0.3799401 
  - best initial criterion value(s) :  379.0824 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -379.08  |proj g|=       5.8614
At iterate     1  f =      -406.34  |proj g|=        3.4466
At iterate     2  f =      -407.98  |proj g|=         1.137
At iterate     3  f =      -408.83  |proj g|=        2.4567
At iterate     4  f =      -408.92  |proj g|=        2.6144
At iterate     5  f =      -409.03  |proj g|=        3.0428
At iterate     6  f =       -409.9  |proj g|=        5.1469
At iterate     7  f =      -411.58  |proj g|=        7.3099
At iterate     8  f =       -412.7  |proj g|=        6.8368
At iterate     9  f =      -415.23  |proj g|=        1.1029
At iterate    10  f =      -415.74  |proj g|=       0.42937
At iterate    11  f =      -415.79  |proj g|=       0.44678
At iterate    12  f =      -415.82  |proj g|=       0.35394
At iterate    13  f =      -415.82  |proj g|=       0.35377
At iterate    14  f =      -415.82  |proj g|=      0.092244
At iterate    15  f =      -415.82  |proj g|=     0.0015354

iterations 15
function evaluations 19
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00153544
final function value -415.816

F = -415.816
final  value -415.816332 
converged
 
INFO  [09:54:02.267] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:54:02.323] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:54:02.330] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:54:32.234] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:55:02.216] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:55:32.177] [mlr3]  Finished benchmark 
INFO  [09:55:32.243] [bbotk] Result of batch 106: 
INFO  [09:55:32.244] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:55:32.244] [bbotk]                   7              2450      0.1795805         0.64 -0.9285225 
INFO  [09:55:32.244] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:55:32.244] [bbotk]          <NA>   0.9797284 54575055-0b57-4fa6-b5d3-4316729c9f4a 
DEBUG [09:55:33.165] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.784376e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9954813 
  - variance bounds :  0.003769933 0.3784376 
  - best initial criterion value(s) :  407.2387 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -407.24  |proj g|=       11.934
At iterate     1  f =      -418.89  |proj g|=       0.16887
At iterate     2  f =      -419.87  |proj g|=        3.0338
At iterate     3  f =      -420.26  |proj g|=       0.54481
At iterate     4  f =      -420.29  |proj g|=       0.35993
At iterate     5  f =      -420.37  |proj g|=      0.061008
At iterate     6  f =      -420.78  |proj g|=      0.045944
At iterate     7  f =      -421.77  |proj g|=      0.020924
At iterate     8  f =      -421.91  |proj g|=       0.55478
At iterate     9  f =      -422.31  |proj g|=         1.361
At iterate    10  f =      -422.37  |proj g|=       0.35836
At iterate    11  f =      -422.38  |proj g|=      0.022147
At iterate    12  f =      -422.38  |proj g|=       0.01591
At iterate    13  f =      -422.38  |proj g|=     0.0011155

iterations 13
function evaluations 16
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00111547
final function value -422.381

F = -422.381
final  value -422.381395 
converged
 
INFO  [09:55:33.169] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:55:33.224] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:55:33.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:55:37.583] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:55:42.066] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:55:46.572] [mlr3]  Finished benchmark 
INFO  [09:55:46.638] [bbotk] Result of batch 107: 
INFO  [09:55:46.640] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:55:46.640] [bbotk]                   7               275      0.3214339         0.65 -0.9164601 
INFO  [09:55:46.640] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:55:46.640] [bbotk]          <NA>   0.9782386 f5960b38-3e99-43f9-a03a-217ef40e5e1b 
DEBUG [09:55:47.582] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.76905e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9954813 
  - variance bounds :  0.003751845 0.376905 
  - best initial criterion value(s) :  403.9379 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -403.94  |proj g|=      0.76509
At iterate     1  f =      -414.44  |proj g|=        4.8613
At iterate     2  f =      -418.61  |proj g|=        1.4697
At iterate     3  f =      -419.92  |proj g|=       0.52581
At iterate     4  f =      -423.21  |proj g|=        1.4335
At iterate     5  f =      -424.72  |proj g|=        2.3099
At iterate     6  f =      -424.74  |proj g|=        2.2302
At iterate     7  f =      -424.79  |proj g|=        1.6556
At iterate     8  f =      -424.92  |proj g|=        1.3339
At iterate     9  f =      -425.65  |proj g|=       0.29581
At iterate    10  f =       -425.8  |proj g|=       0.32894
At iterate    11  f =      -425.84  |proj g|=       0.28607
At iterate    12  f =      -425.85  |proj g|=       0.28488
At iterate    13  f =      -425.85  |proj g|=       0.03553
At iterate    14  f =      -425.85  |proj g|=     0.0010457

iterations 14
function evaluations 17
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00104572
final function value -425.848

F = -425.848
final  value -425.848186 
converged
 
INFO  [09:55:47.586] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:55:47.641] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:55:47.648] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:55:48.435] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:55:49.177] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:55:50.058] [mlr3]  Finished benchmark 
INFO  [09:55:50.125] [bbotk] Result of batch 108: 
INFO  [09:55:50.126] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [09:55:50.126] [bbotk]                  10              2660     0.06850733        0.664 -1.008202 
INFO  [09:55:50.126] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:55:50.126] [bbotk]          <NA>         0.5 3e97f43b-feba-4644-9f37-03b07c464302 
DEBUG [09:55:51.071] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.830559e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9954813 
  - variance bounds :  0.003801787 0.3830559 
  - best initial criterion value(s) :  414.8047 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -414.8  |proj g|=       3.1905
At iterate     1  f =      -421.68  |proj g|=        3.2325
At iterate     2  f =      -423.21  |proj g|=        7.6589
At iterate     3  f =      -424.47  |proj g|=        4.6069
At iterate     4  f =      -424.73  |proj g|=        2.9404
At iterate     5  f =      -424.82  |proj g|=        3.7009
At iterate     6  f =       -424.9  |proj g|=         4.355
At iterate     7  f =      -425.56  |proj g|=        5.0847
At iterate     8  f =      -425.95  |proj g|=        4.5959
At iterate     9  f =      -426.83  |proj g|=        3.7215
At iterate    10  f =      -428.78  |proj g|=        4.1278
At iterate    11  f =      -430.62  |proj g|=        1.1331
At iterate    12  f =      -430.81  |proj g|=       0.34823
At iterate    13  f =      -430.99  |proj g|=       0.34506
At iterate    14  f =      -431.02  |proj g|=       0.34328
At iterate    15  f =      -431.02  |proj g|=       0.10943
At iterate    16  f =      -431.02  |proj g|=      0.036436
At iterate    17  f =      -431.02  |proj g|=     0.0044021

iterations 17
function evaluations 20
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00440211
final function value -431.023

F = -431.023
final  value -431.022961 
converged
 
INFO  [09:55:51.076] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:55:51.141] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:55:51.148] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:56:30.050] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:57:09.211] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:57:48.007] [mlr3]  Finished benchmark 
INFO  [09:57:48.074] [bbotk] Result of batch 109: 
INFO  [09:57:48.076] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:57:48.076] [bbotk]                   5              3160      0.1864182        0.654 -0.9501366 
INFO  [09:57:48.076] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:57:48.076] [bbotk]          <NA>   0.9796713 df841eaa-290e-4309-ba30-43d4fc621705 
DEBUG [09:57:49.194] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.815741e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.9954813 
  - variance bounds :  0.003791598 0.3815741 
  - best initial criterion value(s) :  422.8023 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -422.8  |proj g|=       5.5148
At iterate     1  f =       -424.7  |proj g|=        1.8525
At iterate     2  f =      -426.25  |proj g|=        3.1391
At iterate     3  f =      -428.52  |proj g|=        3.8383
At iterate     4  f =      -430.91  |proj g|=       0.89842
At iterate     5  f =      -431.88  |proj g|=        1.9087
At iterate     6  f =      -432.02  |proj g|=        2.4558
At iterate     7  f =      -433.08  |proj g|=        3.7462
At iterate     8  f =      -433.95  |proj g|=        3.6104
At iterate     9  f =      -435.54  |proj g|=        0.3264
At iterate    10  f =      -435.57  |proj g|=       0.32431
At iterate    11  f =      -435.57  |proj g|=      0.053816
At iterate    12  f =      -435.57  |proj g|=      0.029489
At iterate    13  f =      -435.57  |proj g|=    0.00093547

iterations 13
function evaluations 18
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.000935473
final function value -435.57

F = -435.57
final  value -435.569572 
converged
 
INFO  [09:57:49.198] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:57:49.264] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:57:49.271] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [09:58:16.894] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [09:58:43.714] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [09:59:12.482] [mlr3]  Finished benchmark 
INFO  [09:59:12.555] [bbotk] Result of batch 110: 
INFO  [09:59:12.557] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [09:59:12.557] [bbotk]                   7              2170    0.001331101        0.833 -0.9721654 
INFO  [09:59:12.557] [bbotk]  errors.model classif.auc                                uhash 
INFO  [09:59:12.557] [bbotk]          <NA>   0.9550191 76779c28-0f24-4a08-bae3-9112abceff2e 
DEBUG [09:59:13.573] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.796312e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003770067 0.3796312 
  - best initial criterion value(s) :  427.8795 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -427.88  |proj g|=       1.5176
At iterate     1  f =      -431.42  |proj g|=        3.0334
At iterate     2  f =      -433.57  |proj g|=       0.43201
At iterate     3  f =      -434.97  |proj g|=        1.7589
At iterate     4  f =      -435.47  |proj g|=        2.9452
At iterate     5  f =       -435.8  |proj g|=        3.7684
At iterate     6  f =      -436.23  |proj g|=        4.3643
At iterate     7  f =      -436.27  |proj g|=        3.8944
At iterate     8  f =       -436.3  |proj g|=        4.2397
At iterate     9  f =      -438.43  |proj g|=        2.6153
At iterate    10  f =      -440.18  |proj g|=       0.29087
At iterate    11  f =      -440.24  |proj g|=       0.28716
At iterate    12  f =      -440.25  |proj g|=       0.28483
At iterate    13  f =      -440.25  |proj g|=       0.28423
At iterate    14  f =      -440.25  |proj g|=     0.0051729
At iterate    15  f =      -440.25  |proj g|=     0.0023089

iterations 15
function evaluations 21
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00230895
final function value -440.252

F = -440.252
final  value -440.251692 
converged
 
INFO  [09:59:13.577] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:59:13.638] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:59:13.646] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:00:10.997] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:01:06.708] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:02:01.651] [mlr3]  Finished benchmark 
INFO  [10:02:01.739] [bbotk] Result of batch 111: 
INFO  [10:02:01.741] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [10:02:01.741] [bbotk]                   4              4467       0.287281        0.705 -1.013194 
INFO  [10:02:01.741] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:02:01.741] [bbotk]          <NA>   0.9791422 0ca8d1b0-09cf-49ca-8a4a-23b6422f65f1 
DEBUG [10:02:02.690] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.781482e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003759087 0.3781482 
  - best initial criterion value(s) :  436.0908 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -436.09  |proj g|=       2.6551
At iterate     1  f =      -439.25  |proj g|=        3.0357
At iterate     2  f =      -439.53  |proj g|=        2.2907
At iterate     3  f =      -440.43  |proj g|=       0.54409
At iterate     4  f =      -441.82  |proj g|=       0.80395
At iterate     5  f =      -442.45  |proj g|=       0.32532
At iterate     6  f =         -443  |proj g|=        1.7396
At iterate     7  f =      -443.04  |proj g|=        2.1909
At iterate     8  f =      -443.05  |proj g|=        2.3225
At iterate     9  f =      -443.05  |proj g|=        2.3891
At iterate    10  f =      -443.07  |proj g|=        2.5379
At iterate    11  f =      -443.09  |proj g|=        2.6849
At iterate    12  f =      -443.17  |proj g|=        2.8729
At iterate    13  f =      -443.33  |proj g|=        2.9548
At iterate    14  f =      -443.66  |proj g|=        2.6095
At iterate    15  f =      -444.25  |proj g|=       0.98426
At iterate    16  f =      -444.36  |proj g|=       0.10006
At iterate    17  f =      -444.36  |proj g|=       0.17024
At iterate    18  f =      -444.36  |proj g|=      0.021145
At iterate    19  f =      -444.36  |proj g|=     0.0010186

iterations 19
function evaluations 23
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00101862
final function value -444.361

F = -444.361
final  value -444.361270 
converged
 
INFO  [10:02:02.694] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:02:02.748] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:02:02.755] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:02:03.529] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:02:04.440] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:02:05.194] [mlr3]  Finished benchmark 
INFO  [10:02:05.260] [bbotk] Result of batch 112: 
INFO  [10:02:05.262] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:02:05.262] [bbotk]                   9              2964       0.326209        0.644 -0.9950117 
INFO  [10:02:05.262] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:02:05.262] [bbotk]          <NA>         0.5 c23f8e7b-18b2-45ad-8679-a29c4f36e50b 
DEBUG [10:02:06.228] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.841222e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003815002 0.3841222 
  - best initial criterion value(s) :  410.4937 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -410.49  |proj g|=         6.23
At iterate     1  f =      -429.84  |proj g|=        5.4865
At iterate     2  f =      -430.14  |proj g|=         5.862
At iterate     3  f =      -430.91  |proj g|=        5.9428
At iterate     4  f =      -431.53  |proj g|=        5.9719
At iterate     5  f =       -435.6  |proj g|=        6.0946
At iterate     6  f =      -440.82  |proj g|=        6.1907
At iterate     7  f =      -447.21  |proj g|=        3.4559
At iterate     8  f =      -449.64  |proj g|=        2.6912
At iterate     9  f =       -449.8  |proj g|=        1.9636
At iterate    10  f =      -449.82  |proj g|=        1.8526
At iterate    11  f =      -449.95  |proj g|=        1.3329
At iterate    12  f =      -450.15  |proj g|=       0.65493
At iterate    13  f =      -450.43  |proj g|=       0.13325
At iterate    14  f =      -450.67  |proj g|=        0.3831
At iterate    15  f =       -450.7  |proj g|=      0.090988
At iterate    16  f =       -450.7  |proj g|=      0.088848
At iterate    17  f =       -450.7  |proj g|=       0.29148
At iterate    18  f =       -450.7  |proj g|=     0.0014082
At iterate    19  f =       -450.7  |proj g|=     0.0014082

iterations 19
function evaluations 22
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00140822
final function value -450.701

F = -450.701
final  value -450.701208 
converged
 
INFO  [10:02:06.232] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:02:06.317] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:02:06.324] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:02:33.088] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:02:59.776] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:03:25.235] [mlr3]  Finished benchmark 
INFO  [10:03:25.301] [bbotk] Result of batch 113: 
INFO  [10:03:25.303] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [10:03:25.303] [bbotk]                   3              2117      0.2439943        0.659  -1.01067 
INFO  [10:03:25.303] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:03:25.303] [bbotk]          <NA>   0.9777845 259d001b-1dd7-4d65-8b2b-9418f6facf1d 
DEBUG [10:03:26.233] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.826317e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003799962 0.3826317 
  - best initial criterion value(s) :  441.1732 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -441.17  |proj g|=       4.3387
At iterate     1  f =      -446.09  |proj g|=        2.2021
At iterate     2  f =       -446.3  |proj g|=        2.5725
At iterate     3  f =      -447.82  |proj g|=        4.6413
At iterate     4  f =      -448.98  |proj g|=        4.4238
At iterate     5  f =      -452.08  |proj g|=        3.5137
At iterate     6  f =      -453.49  |proj g|=         1.094
At iterate     7  f =      -454.16  |proj g|=       0.14002
At iterate     8  f =      -454.78  |proj g|=       0.31514
At iterate     9  f =      -454.86  |proj g|=       0.18607
At iterate    10  f =      -454.89  |proj g|=      0.070459
At iterate    11  f =      -454.89  |proj g|=       0.30901
At iterate    12  f =      -454.89  |proj g|=     0.0073411
At iterate    13  f =      -454.89  |proj g|=    0.00095944

iterations 13
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.000959436
final function value -454.886

F = -454.886
final  value -454.886198 
converged
 
INFO  [10:03:26.237] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:03:26.294] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:03:26.301] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:03:57.700] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:04:28.050] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:04:58.440] [mlr3]  Finished benchmark 
INFO  [10:04:58.516] [bbotk] Result of batch 114: 
INFO  [10:04:58.519] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:04:58.519] [bbotk]                   6              2516      0.1332233        0.653 -0.9893822 
INFO  [10:04:58.519] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:04:58.519] [bbotk]          <NA>   0.9796762 61a9be1b-563d-455f-a02b-aa5142d12c55 
DEBUG [10:04:59.489] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.81181e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003780492 0.3811809 
  - best initial criterion value(s) :  454.3302 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -454.33  |proj g|=       4.2308
At iterate     1  f =      -455.87  |proj g|=        0.5637
At iterate     2  f =      -456.06  |proj g|=       0.38301
At iterate     3  f =      -456.14  |proj g|=        1.0784
At iterate     4  f =      -456.21  |proj g|=        1.2862
At iterate     5  f =      -456.71  |proj g|=        2.2018
At iterate     6  f =       -457.5  |proj g|=        2.5146
At iterate     7  f =      -459.24  |proj g|=        1.2877
At iterate     8  f =      -459.81  |proj g|=       0.66151
At iterate     9  f =      -459.83  |proj g|=       0.46795
At iterate    10  f =      -459.84  |proj g|=       0.34208
At iterate    11  f =      -459.85  |proj g|=       0.16266
At iterate    12  f =      -459.85  |proj g|=      0.035085
At iterate    13  f =      -459.85  |proj g|=     0.0011237

iterations 13
function evaluations 17
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00112372
final function value -459.847

F = -459.847
final  value -459.846622 
converged
 
INFO  [10:04:59.493] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:04:59.544] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:04:59.551] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:05:53.863] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:06:48.109] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:07:42.048] [mlr3]  Finished benchmark 
INFO  [10:07:42.115] [bbotk] Result of batch 115: 
INFO  [10:07:42.116] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:07:42.116] [bbotk]                   6              4449      0.3727102        0.679 -0.9443279 
INFO  [10:07:42.116] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:07:42.116] [bbotk]          <NA>   0.9786992 1a2cf227-04a9-4ae1-933e-ad7d1fc360b9 
DEBUG [10:07:43.088] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.797126e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003773047 0.3797126 
  - best initial criterion value(s) :  455.1031 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -455.1  |proj g|=       5.4189
At iterate     1  f =       -456.2  |proj g|=        2.9454
At iterate     2  f =      -457.26  |proj g|=         3.884
At iterate     3  f =      -459.81  |proj g|=        4.4611
At iterate     4  f =      -462.69  |proj g|=        3.0696
At iterate     5  f =      -464.77  |proj g|=       0.84883
At iterate     6  f =      -464.84  |proj g|=       0.45432
At iterate     7  f =      -464.91  |proj g|=        0.3459
At iterate     8  f =      -464.91  |proj g|=      0.042936
At iterate     9  f =      -464.91  |proj g|=      0.020721
At iterate    10  f =      -464.91  |proj g|=     0.0010722

iterations 10
function evaluations 16
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00107223
final function value -464.906

F = -464.906
final  value -464.906420 
converged
 
INFO  [10:07:43.092] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:07:43.145] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:07:43.152] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:08:11.319] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:08:40.123] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:09:08.086] [mlr3]  Finished benchmark 
INFO  [10:09:08.156] [bbotk] Result of batch 116: 
INFO  [10:09:08.158] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:09:08.158] [bbotk]                   5              2288      0.3338912         0.68 -0.9369198 
INFO  [10:09:08.158] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:09:08.158] [bbotk]          <NA>   0.9795434 f5efa128-8a47-48f3-ba89-3d24a7592ad2 
DEBUG [10:09:09.280] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.782631e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003760005 0.3782631 
  - best initial criterion value(s) :  470.5537 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -470.55  |proj g|=      0.73928
At iterate     1  f =      -470.84  |proj g|=        1.5388
At iterate     2  f =      -470.88  |proj g|=        1.6917
At iterate     3  f =      -471.07  |proj g|=        2.1278
At iterate     4  f =      -471.19  |proj g|=        1.6031
At iterate     5  f =      -471.36  |proj g|=        0.3627
At iterate     6  f =      -471.36  |proj g|=      0.047129
At iterate     7  f =      -471.36  |proj g|=      0.011988
At iterate     8  f =      -471.36  |proj g|=      0.003266

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00326601
final function value -471.359

F = -471.359
final  value -471.359107 
converged
 
INFO  [10:09:09.284] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:09:09.340] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:09:09.347] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:09:20.270] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:09:31.266] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:09:41.828] [mlr3]  Finished benchmark 
INFO  [10:09:41.895] [bbotk] Result of batch 117: 
INFO  [10:09:41.896] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [10:09:41.896] [bbotk]                   3               814      0.4935703        0.852 -0.902737 
INFO  [10:09:41.896] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:09:41.896] [bbotk]          <NA>   0.9772103 1f94c0dd-02c4-4df7-8314-5b5ceab48602 
DEBUG [10:09:42.865] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.767719e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003736813 0.3767719 
  - best initial criterion value(s) :  466.1294 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -466.13  |proj g|=        4.482
At iterate     1  f =      -470.57  |proj g|=        0.9833
At iterate     2  f =      -470.85  |proj g|=       0.33639
At iterate     3  f =      -471.84  |proj g|=        1.4994
At iterate     4  f =      -473.09  |proj g|=        3.0349
At iterate     5  f =      -473.94  |proj g|=        2.3949
At iterate     6  f =      -474.72  |proj g|=       0.63768
At iterate     7  f =       -474.8  |proj g|=       0.30313
At iterate     8  f =       -474.8  |proj g|=       0.30234
At iterate     9  f =       -474.8  |proj g|=      0.088984
At iterate    10  f =       -474.8  |proj g|=      0.091913
At iterate    11  f =       -474.8  |proj g|=       0.10336
At iterate    12  f =       -474.8  |proj g|=       0.11086
At iterate    13  f =       -474.8  |proj g|=       0.11231
At iterate    14  f =       -474.8  |proj g|=      0.091185
At iterate    15  f =      -474.81  |proj g|=      0.071622
At iterate    16  f =      -474.81  |proj g|=      0.071575
At iterate    17  f =      -474.81  |proj g|=     0.0035899

iterations 17
function evaluations 21
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00358991
final function value -474.806

F = -474.806
final  value -474.805812 
converged
 
INFO  [10:09:42.869] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:09:42.922] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:09:42.929] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:09:43.744] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:09:44.736] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:09:45.563] [mlr3]  Finished benchmark 
INFO  [10:09:45.637] [bbotk] Result of batch 118: 
INFO  [10:09:45.639] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [10:09:45.639] [bbotk]                   9              4496     0.01658832        0.663 -0.991213 
INFO  [10:09:45.639] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:09:45.639] [bbotk]          <NA>         0.5 03a42abf-0b63-4311-a663-1868bd8ee27a 
DEBUG [10:09:46.583] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.826163e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003803203 0.3826163 
  - best initial criterion value(s) :  473.6092 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -473.61  |proj g|=       3.9462
At iterate     1  f =      -475.34  |proj g|=       0.54562
At iterate     2  f =      -475.44  |proj g|=       0.91265
At iterate     3  f =      -475.67  |proj g|=        1.2984
At iterate     4  f =       -475.8  |proj g|=       0.74609
At iterate     5  f =      -476.61  |proj g|=       0.34586
At iterate     6  f =      -477.07  |proj g|=       0.75681
At iterate     7  f =      -477.11  |proj g|=       0.35187
At iterate     8  f =      -477.12  |proj g|=       0.34314
At iterate     9  f =      -477.12  |proj g|=      0.035713
At iterate    10  f =      -477.12  |proj g|=     0.0014892

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00148923
final function value -477.12

F = -477.12
final  value -477.119507 
converged
 
INFO  [10:09:46.587] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:09:46.649] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:09:46.657] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:10:09.718] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:10:10.517] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:10:34.818] [mlr3]  Finished benchmark 
INFO  [10:10:34.895] [bbotk] Result of batch 119: 
INFO  [10:10:34.897] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:10:34.897] [bbotk]                   8              1862      0.2775196        0.674 -0.9459352 
INFO  [10:10:34.897] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:10:34.897] [bbotk]          <NA>   0.8191326 a2bf090c-6475-4201-8448-30baf1a96e23 
DEBUG [10:10:36.059] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.799479e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003788314 0.3799479 
  - best initial criterion value(s) :  461.5188 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -461.52  |proj g|=        5.635
At iterate     1  f =      -465.27  |proj g|=        2.7829
At iterate     2  f =      -465.99  |proj g|=        3.4353
At iterate     3  f =      -468.97  |proj g|=        5.1699
At iterate     4  f =      -471.77  |proj g|=        4.7508
At iterate     5  f =      -476.85  |proj g|=        4.0941
At iterate     6  f =      -480.66  |proj g|=        2.1564
At iterate     7  f =      -480.99  |proj g|=         2.816
At iterate     8  f =      -481.27  |proj g|=         3.149
At iterate     9  f =      -482.47  |proj g|=        3.9009
At iterate    10  f =      -483.42  |proj g|=      0.062993
At iterate    11  f =      -483.42  |proj g|=      0.033332
At iterate    12  f =      -483.43  |proj g|=       0.34326
At iterate    13  f =      -483.43  |proj g|=     0.0010566
At iterate    14  f =      -483.43  |proj g|=    0.00069195

iterations 14
function evaluations 18
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.000691954
final function value -483.425

F = -483.425
final  value -483.425481 
converged
 
INFO  [10:10:36.063] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:10:36.118] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:10:36.125] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:11:24.991] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:12:13.367] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:13:02.165] [mlr3]  Finished benchmark 
INFO  [10:13:02.231] [bbotk] Result of batch 120: 
INFO  [10:13:02.233] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:13:02.233] [bbotk]                   3              4115      0.1987649        0.814 -0.9412548 
INFO  [10:13:02.233] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:13:02.233] [bbotk]          <NA>   0.9784768 3c962912-1ffd-425b-957a-45c73ea8c8eb 
DEBUG [10:13:03.279] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.785316e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003771923 0.3785316 
  - best initial criterion value(s) :  443.0181 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -443.02  |proj g|=       10.723
At iterate     1  f =      -462.43  |proj g|=        4.0592
At iterate     2  f =      -464.84  |proj g|=        4.6777
At iterate     3  f =      -466.52  |proj g|=        4.1883
At iterate     4  f =      -468.17  |proj g|=        3.5606
At iterate     5  f =      -486.31  |proj g|=        0.1667
At iterate     6  f =       -487.3  |proj g|=       0.48825
At iterate     7  f =      -488.67  |proj g|=       0.23364
At iterate     8  f =      -488.72  |proj g|=         0.354
At iterate     9  f =      -488.72  |proj g|=      0.073665
At iterate    10  f =      -488.72  |proj g|=      0.068996
At iterate    11  f =      -488.72  |proj g|=     0.0051617

iterations 11
function evaluations 18
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00516174
final function value -488.722

F = -488.722
final  value -488.721909 
converged
 
INFO  [10:13:03.283] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:13:03.337] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:13:03.343] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:13:53.307] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:14:42.013] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:15:31.121] [mlr3]  Finished benchmark 
INFO  [10:15:31.188] [bbotk] Result of batch 121: 
INFO  [10:15:31.190] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:15:31.190] [bbotk]                   5              4079      0.4914903        0.735 -0.9203055 
INFO  [10:15:31.190] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:15:31.190] [bbotk]          <NA>   0.9788648 7fa181e1-6128-4710-9ffe-1669dd9a90ad 
DEBUG [10:15:32.384] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.771249e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003758671 0.3771249 
  - best initial criterion value(s) :  437.8232 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -437.82  |proj g|=       7.2044
At iterate     1  f =      -441.54  |proj g|=        6.5882
At iterate     2  f =      -472.07  |proj g|=        4.8656
At iterate     3  f =      -479.27  |proj g|=        4.1543
At iterate     4  f =      -488.48  |proj g|=        2.9117
At iterate     5  f =      -489.17  |proj g|=        3.2716
At iterate     6  f =      -489.31  |proj g|=        3.2467
At iterate     7  f =      -490.44  |proj g|=        2.9408
At iterate     8  f =      -491.63  |proj g|=        2.6726
At iterate     9  f =       -492.6  |proj g|=        1.5129
At iterate    10  f =      -492.68  |proj g|=       0.36532
At iterate    11  f =      -492.68  |proj g|=      0.021128
At iterate    12  f =      -492.68  |proj g|=     0.0081317
At iterate    13  f =      -492.68  |proj g|=      0.037943

iterations 13
function evaluations 22
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0379428
final function value -492.678

F = -492.678
final  value -492.678463 
converged
 
INFO  [10:15:32.388] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:15:32.443] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:15:32.450] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:16:02.213] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:16:32.055] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:17:02.006] [mlr3]  Finished benchmark 
INFO  [10:17:02.072] [bbotk] Result of batch 122: 
INFO  [10:17:02.074] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [10:17:02.074] [bbotk]                   4              2450      0.1846131        0.667 -0.893494 
INFO  [10:17:02.074] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:17:02.074] [bbotk]          <NA>   0.9797208 384f8012-f904-440f-b14e-151ab5926bc7 
DEBUG [10:17:03.067] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.757364e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003745929 0.3757364 
  - best initial criterion value(s) :  481.9344 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -481.93  |proj g|=       8.5832
At iterate     1  f =      -488.32  |proj g|=        1.5877
At iterate     2  f =      -490.56  |proj g|=        3.6449
At iterate     3  f =      -491.22  |proj g|=        3.3238
At iterate     4  f =      -491.66  |proj g|=       0.66801
At iterate     5  f =      -491.77  |proj g|=       0.78441
At iterate     6  f =       -491.8  |proj g|=        1.0381
At iterate     7  f =      -492.31  |proj g|=        1.9195
At iterate     8  f =       -495.7  |proj g|=         3.551
At iterate     9  f =      -496.99  |proj g|=        3.6013
At iterate    10  f =      -497.86  |proj g|=        1.5534
At iterate    11  f =      -498.54  |proj g|=       0.48507
At iterate    12  f =      -498.55  |proj g|=        0.3561
At iterate    13  f =      -498.55  |proj g|=      0.016088
At iterate    14  f =      -498.55  |proj g|=      0.016041
At iterate    15  f =      -498.55  |proj g|=       0.04809
At iterate    16  f =      -498.55  |proj g|=      0.004958

iterations 16
function evaluations 20
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00495797
final function value -498.55

F = -498.55
final  value -498.549843 
converged
 
INFO  [10:17:03.071] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:17:03.125] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:17:03.132] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:17:33.652] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:18:03.469] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:18:33.461] [mlr3]  Finished benchmark 
INFO  [10:18:33.537] [bbotk] Result of batch 123: 
INFO  [10:18:33.539] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:18:33.539] [bbotk]                   7              2503      0.3338848        0.678 -0.9118014 
INFO  [10:18:33.539] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:18:33.539] [bbotk]          <NA>   0.9791548 02fbfb64-83ff-4427-8b46-d6b238323a87 
DEBUG [10:18:34.568] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.743401e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003738847 0.3743401 
  - best initial criterion value(s) :  459.9369 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -459.94  |proj g|=       4.7036
At iterate     1  f =      -460.88  |proj g|=        1.7184
At iterate     2  f =      -463.36  |proj g|=         4.387
At iterate     3  f =      -466.93  |proj g|=        4.4913
At iterate     4  f =      -470.33  |proj g|=        4.3482
At iterate     5  f =      -488.91  |proj g|=        3.2318
At iterate     6  f =      -495.55  |proj g|=        5.1131
At iterate     7  f =       -497.3  |proj g|=        6.4742
At iterate     8  f =      -497.53  |proj g|=        5.9081
At iterate     9  f =      -497.58  |proj g|=         6.281
At iterate    10  f =      -497.78  |proj g|=        7.1641
At iterate    11  f =      -498.34  |proj g|=        8.4087
At iterate    12  f =      -499.67  |proj g|=         9.544
At iterate    13  f =      -501.51  |proj g|=        6.9254
At iterate    14  f =      -502.86  |proj g|=        3.0365
At iterate    15  f =      -503.31  |proj g|=       0.82723
At iterate    16  f =      -503.44  |proj g|=       0.39133
At iterate    17  f =      -503.45  |proj g|=       0.35253
At iterate    18  f =      -503.45  |proj g|=       0.35263
At iterate    19  f =      -503.45  |proj g|=       0.01798
At iterate    20  f =      -503.45  |proj g|=     0.0009093
At iterate    21  f =      -503.45  |proj g|=      0.016566

iterations 21
function evaluations 28
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.016566
final function value -503.447

F = -503.447
final  value -503.446727 
converged
 
INFO  [10:18:34.572] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:18:34.628] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:18:34.634] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:18:35.362] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:18:36.081] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:18:36.948] [mlr3]  Finished benchmark 
INFO  [10:18:37.013] [bbotk] Result of batch 124: 
INFO  [10:18:37.014] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:18:37.014] [bbotk]                   9               887      0.3171993        0.673 -0.9154606 
INFO  [10:18:37.014] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:18:37.014] [bbotk]          <NA>         0.5 b49e39fe-9b49-4a48-bc48-ff6fbca16c2d 
DEBUG [10:18:38.035] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.800132e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003799799 0.3800132 
  - best initial criterion value(s) :  486.9775 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -486.98  |proj g|=       1.3065
At iterate     1  f =      -493.58  |proj g|=        3.8733
At iterate     2  f =      -495.76  |proj g|=        3.7519
At iterate     3  f =      -505.67  |proj g|=        1.8288
At iterate     4  f =      -507.62  |proj g|=        1.4024
At iterate     5  f =      -507.76  |proj g|=       0.74758
At iterate     6  f =      -507.78  |proj g|=       0.42748
At iterate     7  f =      -507.78  |proj g|=       0.38691
At iterate     8  f =      -507.78  |proj g|=       0.37506
At iterate     9  f =      -507.78  |proj g|=       0.32533
At iterate    10  f =      -507.78  |proj g|=       0.25996
At iterate    11  f =      -507.78  |proj g|=       0.14807
At iterate    12  f =      -507.79  |proj g|=      0.079036
At iterate    13  f =      -507.81  |proj g|=       0.13197
At iterate    14  f =      -507.82  |proj g|=       0.21839
At iterate    15  f =      -507.82  |proj g|=       0.14018
At iterate    16  f =      -507.82  |proj g|=      0.010795
At iterate    17  f =      -507.82  |proj g|=     0.0085482

iterations 17
function evaluations 21
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00854825
final function value -507.817

F = -507.817
final  value -507.817155 
converged
 
INFO  [10:18:38.039] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:18:38.093] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:18:38.108] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:19:02.206] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:19:26.561] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:19:50.888] [mlr3]  Finished benchmark 
INFO  [10:19:50.955] [bbotk] Result of batch 125: 
INFO  [10:19:50.957] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:19:50.957] [bbotk]                   7              1960     0.08563836        0.695 -0.9992493 
INFO  [10:19:50.957] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:19:50.957] [bbotk]          <NA>   0.9794761 3616dac5-c685-483a-9c48-62cfada0be74 
DEBUG [10:19:51.944] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.78639e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003785626 0.378639 
  - best initial criterion value(s) :  473.2461 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -473.25  |proj g|=       2.6338
At iterate     1  f =      -503.18  |proj g|=        3.0298
At iterate     2  f =       -506.4  |proj g|=        2.5262
At iterate     3  f =      -506.55  |proj g|=        2.5121
At iterate     4  f =      -506.86  |proj g|=         2.414
At iterate     5  f =      -507.17  |proj g|=       0.36973
At iterate     6  f =      -507.19  |proj g|=      0.041989
At iterate     7  f =      -507.19  |proj g|=      0.010255
At iterate     8  f =      -507.19  |proj g|=      0.010249
At iterate     9  f =      -507.19  |proj g|=      0.033645

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0336448
final function value -507.193

F = -507.193
final  value -507.192991 
converged
 
INFO  [10:19:51.948] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:19:52.011] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:19:52.018] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:19:52.791] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:19:53.668] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:19:54.428] [mlr3]  Finished benchmark 
INFO  [10:19:54.494] [bbotk] Result of batch 126: 
INFO  [10:19:54.496] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:19:54.496] [bbotk]                  10              2835      0.4411138        0.699 -0.8841225 
INFO  [10:19:54.496] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:19:54.496] [bbotk]          <NA>         0.5 08ec5d05-42a2-48e2-a66b-88df83bc111f 
DEBUG [10:19:55.736] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.84139e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9510 0.996442 
  - variance bounds :  0.003832425 0.384139 
  - best initial criterion value(s) :  509.5989 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -509.6  |proj g|=       3.7388
At iterate     1  f =      -512.08  |proj g|=        5.2758
At iterate     2  f =      -514.86  |proj g|=         2.481
At iterate     3  f =      -516.55  |proj g|=        1.9114
At iterate     4  f =       -516.6  |proj g|=        2.7158
At iterate     5  f =      -517.24  |proj g|=        3.3567
At iterate     6  f =      -517.32  |proj g|=        2.5771
At iterate     7  f =      -517.35  |proj g|=        2.0309
At iterate     8  f =      -517.36  |proj g|=        1.8625
At iterate     9  f =       -517.4  |proj g|=        1.3527
At iterate    10  f =      -517.49  |proj g|=       0.68789
At iterate    11  f =      -517.67  |proj g|=       0.30347
At iterate    12  f =      -517.94  |proj g|=        1.0828
At iterate    13  f =      -518.04  |proj g|=        1.0757
At iterate    14  f =      -518.09  |proj g|=      0.094714
At iterate    15  f =      -518.09  |proj g|=       0.01838
At iterate    16  f =      -518.09  |proj g|=      0.041303

iterations 16
function evaluations 23
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0413029
final function value -518.087

F = -518.087
final  value -518.087240 
converged
 
INFO  [10:19:55.740] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:19:55.795] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:19:55.802] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:19:56.562] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:20:31.382] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:21:05.828] [mlr3]  Finished benchmark 
INFO  [10:21:05.894] [bbotk] Result of batch 127: 
INFO  [10:21:05.895] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:21:05.895] [bbotk]                   8              2869      0.1901462        0.903 -0.9160806 
INFO  [10:21:05.895] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:21:05.895] [bbotk]          <NA>    0.819129 cc21b05a-2f5f-4097-8fa6-547bf2c2376a 
DEBUG [10:21:05.968] [bbotk]  
INFO  [10:21:05.979] [bbotk] Finished optimizing after 150 evaluation(s) 
INFO  [10:21:05.980] [bbotk] Result: 
INFO  [10:21:05.982] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu learner_param_vals 
INFO  [10:21:05.982] [bbotk]                   6              2205      0.2027944         <list[15]> 
INFO  [10:21:05.982] [bbotk]   x_domain classif.auc 
INFO  [10:21:05.982] [bbotk]  <list[3]>   0.9798385 
INFO  [10:21:40.968] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost.tuned' on task 'spam' (iter 5/5) 
INFO  [10:21:41.067] [bbotk] Starting to optimize 3 parameter(s) with '<OptimizerInterMBO>' and '<TerminatorEvals> [n_evals=150]' 
DEBUG [10:21:41.134] [bbotk]  
INFO  [10:21:41.139] [bbotk] Evaluating 24 configuration(s) 
INFO  [10:21:41.996] [mlr3]  Running benchmark with 72 resampling iterations 
INFO  [10:21:42.003] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:21:42.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:22:21.805] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:23:02.540] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:23:03.314] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:23:14.121] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:23:45.408] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:24:24.626] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:24:54.136] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:25:33.730] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:26:30.015] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:26:56.351] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:27:17.156] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:27:24.815] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:27:25.698] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:27:26.486] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:27:27.258] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:28:06.537] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:29:06.828] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:29:34.444] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:29:35.226] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:30:00.864] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:30:01.650] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:30:02.434] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:30:03.527] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:30:14.882] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:30:20.606] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:30:46.248] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:30:58.299] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:31:48.831] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:32:16.129] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:32:16.918] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:32:17.692] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:32:18.481] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:32:35.836] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:32:36.637] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:33:22.463] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:34:17.890] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:34:49.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:34:50.014] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:35:40.714] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:35:57.347] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:35:58.401] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:36:20.614] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:37:15.506] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:37:50.721] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:38:43.836] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:39:29.389] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:39:30.228] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:39:51.053] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:40:26.610] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:40:27.528] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:40:34.221] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:40:45.669] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:40:52.659] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:41:46.951] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:41:58.579] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:42:43.895] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:43:11.364] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:43:16.860] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:43:17.595] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:43:57.515] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:44:32.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:45:07.006] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:46:02.372] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:46:37.896] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:46:48.235] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:47:47.907] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:48:04.003] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:48:09.793] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:49:08.713] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:49:58.017] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:50:32.188] [mlr3]  Finished benchmark 
INFO  [10:50:33.470] [bbotk] Result of batch 1: 
INFO  [10:50:33.473] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu classif.auc 
INFO  [10:50:33.473] [bbotk]                   9              3989     0.23331179   0.5000000 
INFO  [10:50:33.473] [bbotk]                   4              3169     0.27473326   0.9750664 
INFO  [10:50:33.473] [bbotk]                   5              3256     0.35887713   0.9755134 
INFO  [10:50:33.473] [bbotk]                   7              4098     0.12190093   0.9760784 
INFO  [10:50:33.473] [bbotk]                   8               867     0.07351484   0.9728961 
INFO  [10:50:33.473] [bbotk]                  10              1990     0.34806844   0.5000000 
INFO  [10:50:33.473] [bbotk]                   6              1676     0.01409022   0.9710265 
INFO  [10:50:33.473] [bbotk]                   8              3729     0.25998898   0.9736045 
INFO  [10:50:33.473] [bbotk]                   4              2855     0.30128667   0.9750720 
INFO  [10:50:33.473] [bbotk]                   6              4564     0.04938378   0.9763387 
INFO  [10:50:33.473] [bbotk]                   3               789     0.47724861   0.9731624 
INFO  [10:50:33.473] [bbotk]                   7              2417     0.38159303   0.9752340 
INFO  [10:50:33.473] [bbotk]                  10              1510     0.21825028   0.5000000 
INFO  [10:50:33.473] [bbotk]                   7              1263     0.18811769   0.9763786 
INFO  [10:50:33.473] [bbotk]                  10              3443     0.42467414   0.5000000 
INFO  [10:50:33.473] [bbotk]                   5               470     0.33295644   0.9751750 
INFO  [10:50:33.473] [bbotk]                   8              2245     0.03071404   0.9730686 
INFO  [10:50:33.473] [bbotk]                   6              4390     0.41003581   0.9749784 
INFO  [10:50:33.473] [bbotk]                   5              2791     0.18823812   0.9759123 
INFO  [10:50:33.473] [bbotk]                   3              2048     0.44205876   0.9739334 
INFO  [10:50:33.473] [bbotk]                   9              4720     0.15478735   0.5000000 
INFO  [10:50:33.473] [bbotk]                   4               367     0.09069778   0.9702662 
INFO  [10:50:33.473] [bbotk]                   9              1107     0.48520532   0.5000000 
INFO  [10:50:33.473] [bbotk]                   3              4859     0.12748074   0.9735453 
INFO  [10:50:33.473] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu classif.auc 
INFO  [10:50:33.473] [bbotk]                                 uhash 
INFO  [10:50:33.473] [bbotk]  0699e049-7762-4119-bb72-03095070ed29 
INFO  [10:50:33.473] [bbotk]  1e96f05d-c281-4140-8dbe-9016a003489e 
INFO  [10:50:33.473] [bbotk]  e38ad3e0-4041-4aeb-a7ef-65676c18d18e 
INFO  [10:50:33.473] [bbotk]  465d562b-dc0b-462f-9442-c90321ff0cd3 
INFO  [10:50:33.473] [bbotk]  8ece808f-4571-4cdb-9039-f72d61399c22 
INFO  [10:50:33.473] [bbotk]  8bbaf463-8830-4f36-8974-bfa29fe1d740 
INFO  [10:50:33.473] [bbotk]  15605fb2-ba5f-44b0-8289-dc0b9e6ed82e 
INFO  [10:50:33.473] [bbotk]  9d6c0be2-6447-441b-9566-56a5d659a6d8 
INFO  [10:50:33.473] [bbotk]  3862f9db-46c1-4905-8438-417edde8d308 
INFO  [10:50:33.473] [bbotk]  ade5c3c0-2df2-455d-b149-d73af8177cfe 
INFO  [10:50:33.473] [bbotk]  cb60611f-7a51-4612-9c1c-e19151992ec0 
INFO  [10:50:33.473] [bbotk]  6e33bcc7-df7e-4020-a665-057162e26bbb 
INFO  [10:50:33.473] [bbotk]  5c74b418-49ad-4703-bc92-adbeca9790cc 
INFO  [10:50:33.473] [bbotk]  12a2c83b-fae1-4897-8234-d81934c807ca 
INFO  [10:50:33.473] [bbotk]  1bcfad27-e927-4628-bae8-353f41e6280d 
INFO  [10:50:33.473] [bbotk]  a514b9f7-d2cc-4c47-9cb1-16bf3c0bfa8b 
INFO  [10:50:33.473] [bbotk]  643f5b52-77c0-421b-b27c-fb627ec7ba45 
INFO  [10:50:33.473] [bbotk]  bcf31b3d-6344-4a94-89c3-14cd2b56d7e4 
INFO  [10:50:33.473] [bbotk]  9d5d58a0-0cba-4430-a1de-5e0f687ce190 
INFO  [10:50:33.473] [bbotk]  702b17c0-a60d-475d-8127-8c0e613a237f 
INFO  [10:50:33.473] [bbotk]  46022a22-0aa9-489a-a1f4-ca62d027e4aa 
INFO  [10:50:33.473] [bbotk]  7363db34-8b03-40fb-8eae-d850d92e46cd 
INFO  [10:50:33.473] [bbotk]  092a48ce-2332-4047-a820-523d4d683b58 
INFO  [10:50:33.473] [bbotk]  29b228ee-b535-4211-a0aa-5dcf6c346d77 
INFO  [10:50:33.473] [bbotk]                                 uhash 
DEBUG [10:50:34.109] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.401472e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8984 0.9422302 
  - variance bounds :  0.004073388 0.4401472 
  - best initial criterion value(s) :  17.19379 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -17.194  |proj g|=       2.8765
At iterate     1  f =      -18.499  |proj g|=        1.8756
At iterate     2  f =      -18.685  |proj g|=        2.2771
At iterate     3  f =      -19.088  |proj g|=        2.6572
At iterate     4  f =       -19.41  |proj g|=        2.5003
At iterate     5  f =      -20.224  |proj g|=        2.3892
At iterate     6  f =      -24.073  |proj g|=      0.068275
At iterate     7  f =      -24.648  |proj g|=        1.3572
At iterate     8  f =      -24.772  |proj g|=        1.0384
At iterate     9  f =      -24.788  |proj g|=       0.42228
At iterate    10  f =      -24.798  |proj g|=       0.42232
At iterate    11  f =      -24.812  |proj g|=       0.62303
At iterate    12  f =      -24.863  |proj g|=        1.0494
At iterate    13  f =      -24.889  |proj g|=        1.1009
At iterate    14  f =       -24.92  |proj g|=       0.68032
At iterate    15  f =      -24.944  |proj g|=      0.064298
At iterate    16  f =      -24.945  |proj g|=       0.42212
At iterate    17  f =      -24.945  |proj g|=      0.014003
At iterate    18  f =      -24.945  |proj g|=     0.0041802
At iterate    19  f =      -24.945  |proj g|=     0.0041803

iterations 19
function evaluations 25
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00418025
final function value -24.945

F = -24.945
final  value -24.944995 
converged
 
INFO  [10:50:34.113] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:50:34.166] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:50:34.172] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:50:34.918] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:50:35.650] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:50:36.561] [mlr3]  Finished benchmark 
INFO  [10:50:36.638] [bbotk] Result of batch 2: 
INFO  [10:50:36.639] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:50:36.639] [bbotk]                   9              3409     0.08093665        0.404 -0.9746971 
INFO  [10:50:36.639] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:50:36.639] [bbotk]          <NA>         0.5 a257b2b5-cf5d-46f5-8b20-6d420512ca47 
DEBUG [10:50:37.247] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.724221e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 8984 0.9422302 
  - variance bounds :  0.004270646 0.4724221 
  - best initial criterion value(s) :  23.4798 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -23.48  |proj g|=        2.349
At iterate     1  f =      -35.473  |proj g|=        2.6658
At iterate     2  f =      -37.137  |proj g|=        3.1583
At iterate     3  f =      -37.515  |proj g|=        3.4011
At iterate     4  f =       -37.52  |proj g|=        3.2889
At iterate     5  f =      -37.553  |proj g|=        2.7795
At iterate     6  f =      -37.636  |proj g|=        2.1548
At iterate     7  f =      -37.907  |proj g|=       0.53153
At iterate     8  f =      -38.437  |proj g|=        1.1515
At iterate     9  f =      -39.698  |proj g|=        1.3286
At iterate    10  f =      -40.142  |proj g|=        1.3046
At iterate    11  f =      -40.224  |proj g|=        1.1541
At iterate    12  f =      -40.317  |proj g|=       0.14829
At iterate    13  f =      -40.318  |proj g|=     0.0098238
At iterate    14  f =      -40.318  |proj g|=      0.049848
At iterate    15  f =      -40.318  |proj g|=     0.0011044

iterations 15
function evaluations 19
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00110437
final function value -40.3181

F = -40.3181
final  value -40.318112 
converged
 
INFO  [10:50:37.251] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:50:37.321] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:50:37.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:50:43.147] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:50:48.472] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:50:53.810] [mlr3]  Finished benchmark 
INFO  [10:50:53.877] [bbotk] Result of batch 3: 
INFO  [10:50:53.879] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:50:53.879] [bbotk]                   4               342      0.3409155        0.414 -0.9512126 
INFO  [10:50:53.879] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:50:53.879] [bbotk]          <NA>   0.9732576 ede55dce-22fb-41c7-8e4e-18c07e7694bd 
DEBUG [10:50:54.646] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.602031e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.00416047 0.4602031 
  - best initial criterion value(s) :  30.2747 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -30.275  |proj g|=       2.5441
At iterate     1  f =       -32.89  |proj g|=        1.2122
At iterate     2  f =      -34.105  |proj g|=        2.4127
At iterate     3  f =      -34.505  |proj g|=        2.3392
At iterate     4  f =      -38.538  |proj g|=       0.36332
At iterate     5  f =      -41.855  |proj g|=       0.72594
At iterate     6  f =      -41.879  |proj g|=       0.70501
At iterate     7  f =      -41.887  |proj g|=         1.759
At iterate     8  f =      -41.915  |proj g|=        1.3346
At iterate     9  f =      -42.005  |proj g|=       0.50104
At iterate    10  f =      -42.021  |proj g|=      0.083367
At iterate    11  f =      -42.022  |proj g|=     0.0095821
At iterate    12  f =      -42.022  |proj g|=      0.061674
At iterate    13  f =      -42.022  |proj g|=     0.0015932

iterations 13
function evaluations 21
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00159318
final function value -42.0217

F = -42.0217
final  value -42.021702 
converged
 
INFO  [10:50:54.650] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:50:54.703] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:50:54.717] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:51:08.992] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:51:22.686] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:51:36.326] [mlr3]  Finished benchmark 
INFO  [10:51:36.392] [bbotk] Result of batch 4: 
INFO  [10:51:36.394] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:51:36.394] [bbotk]                   5              1070      0.3102688        0.546 -0.9499079 
INFO  [10:51:36.394] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:51:36.394] [bbotk]          <NA>   0.9759829 ebc64ebb-bbfd-4740-8542-da00f614a8de 
DEBUG [10:51:37.157] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.48707e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004110336 0.448707 
  - best initial criterion value(s) :  35.53109 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -35.531  |proj g|=       3.6291
At iterate     1  f =      -37.955  |proj g|=        2.2212
At iterate     2  f =      -40.793  |proj g|=        1.3918
At iterate     3  f =      -41.085  |proj g|=        1.2676
At iterate     4  f =      -41.096  |proj g|=        1.2684
At iterate     5  f =      -41.151  |proj g|=         1.263
At iterate     6  f =      -41.387  |proj g|=       0.88124
At iterate     7  f =      -41.859  |proj g|=        0.3022
At iterate     8  f =      -42.694  |proj g|=       0.84589
At iterate     9  f =      -43.915  |proj g|=        1.4067
At iterate    10  f =      -45.052  |proj g|=       0.85335
At iterate    11  f =      -45.727  |proj g|=       0.30169
At iterate    12  f =      -45.757  |proj g|=       0.60249
At iterate    13  f =      -45.758  |proj g|=       0.58447
At iterate    14  f =      -45.768  |proj g|=       0.43561
At iterate    15  f =       -45.77  |proj g|=       0.43557
At iterate    16  f =       -45.77  |proj g|=       0.40729
At iterate    17  f =       -45.77  |proj g|=      0.011594
At iterate    18  f =       -45.77  |proj g|=     0.0015696

iterations 18
function evaluations 23
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00156962
final function value -45.7698

F = -45.7698
final  value -45.769804 
converged
 
INFO  [10:51:37.161] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:51:37.214] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:51:37.220] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:51:37.965] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:51:38.715] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:51:39.467] [mlr3]  Finished benchmark 
INFO  [10:51:39.532] [bbotk] Result of batch 5: 
INFO  [10:51:39.534] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:51:39.534] [bbotk]                  10               737      0.2479036        0.539 -0.9487466 
INFO  [10:51:39.534] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:51:39.534] [bbotk]          <NA>         0.5 1c334318-d9d5-4390-841d-30435500fa6f 
DEBUG [10:51:40.117] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.761768e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004403098 0.4761768 
  - best initial criterion value(s) :  30.63791 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -30.638  |proj g|=       1.9875
At iterate     1  f =      -30.653  |proj g|=        1.9631
At iterate     2  f =      -30.867  |proj g|=        1.9614
At iterate     3  f =       -31.34  |proj g|=        1.9229
At iterate     4  f =      -34.183  |proj g|=        1.6819
At iterate     5  f =      -37.274  |proj g|=        1.3182
At iterate     6  f =      -38.806  |proj g|=       0.46404
At iterate     7  f =       -39.33  |proj g|=        4.2054
At iterate     8  f =      -39.438  |proj g|=         4.041
At iterate     9  f =      -39.759  |proj g|=        1.6045
At iterate    10  f =      -39.911  |proj g|=       0.66347
At iterate    11  f =      -39.967  |proj g|=       0.46228
At iterate    12  f =       -39.97  |proj g|=       0.46202
At iterate    13  f =       -39.97  |proj g|=       0.13285
At iterate    14  f =       -39.97  |proj g|=     0.0035062
At iterate    15  f =       -39.97  |proj g|=     0.0040714

iterations 15
function evaluations 22
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00407135
final function value -39.9701

F = -39.9701
final  value -39.970092 
converged
 
INFO  [10:51:40.121] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:51:40.174] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:51:40.180] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:51:40.923] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:51:41.663] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:51:42.592] [mlr3]  Finished benchmark 
INFO  [10:51:42.658] [bbotk] Result of batch 6: 
INFO  [10:51:42.659] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:51:42.659] [bbotk]                   9              2159      0.2331533        0.405 -0.9525281 
INFO  [10:51:42.659] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:51:42.659] [bbotk]          <NA>         0.5 da901f4e-4cb2-40cf-bb8c-6d24c25cb8e2 
DEBUG [10:51:43.240] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.987524e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004653184 0.4987524 
  - best initial criterion value(s) :  25.30028 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=        -25.3  |proj g|=        2.614
At iterate     1  f =       -25.62  |proj g|=        2.5069
At iterate     2  f =      -26.109  |proj g|=        2.5061
At iterate     3  f =      -27.064  |proj g|=        2.4569
At iterate     4  f =      -28.117  |proj g|=         2.302
At iterate     5  f =      -32.176  |proj g|=        1.8114
At iterate     6  f =      -36.144  |proj g|=         8.339
At iterate     7  f =      -36.488  |proj g|=        4.2633
At iterate     8  f =       -37.26  |proj g|=        3.9959
At iterate     9  f =      -38.051  |proj g|=        2.9425
At iterate    10  f =      -38.216  |proj g|=        1.2713
At iterate    11  f =      -38.325  |proj g|=       0.48434
At iterate    12  f =      -38.328  |proj g|=       0.48415
At iterate    13  f =      -38.328  |proj g|=      0.068244
At iterate    14  f =      -38.328  |proj g|=     0.0049973
At iterate    15  f =      -38.328  |proj g|=     0.0051036

iterations 15
function evaluations 21
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00510357
final function value -38.3278

F = -38.3278
final  value -38.327758 
converged
 
INFO  [10:51:43.244] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:51:43.299] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:51:43.306] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:51:44.044] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:51:44.804] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:51:45.539] [mlr3]  Finished benchmark 
INFO  [10:51:45.605] [bbotk] Result of batch 7: 
INFO  [10:51:45.606] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:51:45.606] [bbotk]                  10              1980     0.04601606        0.402 -0.9561079 
INFO  [10:51:45.606] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:51:45.606] [bbotk]          <NA>         0.5 6b90e026-1a90-4e4a-a686-b56f446c6903 
DEBUG [10:51:46.208] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.172233e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004819506 0.5172233 
  - best initial criterion value(s) :  35.30967 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -35.31  |proj g|=      0.39697
At iterate     1  f =       -40.76  |proj g|=        2.2951
At iterate     2  f =      -42.935  |proj g|=        2.3073
At iterate     3  f =       -43.52  |proj g|=        2.3067
At iterate     4  f =      -44.703  |proj g|=        2.2741
At iterate     5  f =      -46.163  |proj g|=        2.0981
At iterate     6  f =      -50.117  |proj g|=         1.423
At iterate     7  f =      -50.584  |proj g|=        1.2282
At iterate     8  f =      -50.705  |proj g|=       0.33964
At iterate     9  f =      -50.709  |proj g|=      0.019496
At iterate    10  f =      -50.709  |proj g|=       0.50454
At iterate    11  f =      -50.709  |proj g|=     0.0078727
At iterate    12  f =      -50.709  |proj g|=      0.004494

iterations 12
function evaluations 19
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00449395
final function value -50.7088

F = -50.7088
final  value -50.708767 
converged
 
INFO  [10:51:46.212] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:51:46.267] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:51:46.273] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:51:47.019] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:51:47.925] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:51:48.713] [mlr3]  Finished benchmark 
INFO  [10:51:48.801] [bbotk] Result of batch 8: 
INFO  [10:51:48.803] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:51:48.803] [bbotk]                   9              3821      0.2277283        0.423 -0.9401579 
INFO  [10:51:48.803] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:51:48.803] [bbotk]          <NA>         0.5 99d932b5-8641-41d6-baef-b8bafe9c35eb 
DEBUG [10:51:49.388] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.322383e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004991132 0.5322382 
  - best initial criterion value(s) :  43.32508 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -43.325  |proj g|=        1.399
At iterate     1  f =      -46.925  |proj g|=       0.65764
At iterate     2  f =      -59.182  |proj g|=        1.0775
At iterate     3  f =      -60.021  |proj g|=        8.0593
At iterate     4  f =      -60.157  |proj g|=        7.4061
At iterate     5  f =      -60.403  |proj g|=        5.0865
At iterate     6  f =      -60.462  |proj g|=        5.7153
At iterate     7  f =      -60.598  |proj g|=          6.25
At iterate     8  f =      -60.818  |proj g|=        6.5989
At iterate     9  f =      -61.339  |proj g|=        4.5893
At iterate    10  f =      -61.947  |proj g|=       0.32215
At iterate    11  f =          -62  |proj g|=       0.32657
At iterate    12  f =      -62.005  |proj g|=       0.52053
At iterate    13  f =      -62.005  |proj g|=     0.0067281
At iterate    14  f =      -62.005  |proj g|=      0.018143
At iterate    15  f =      -62.005  |proj g|=     0.0017027

iterations 15
function evaluations 22
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00170274
final function value -62.0055

F = -62.0055
final  value -62.005452 
converged
 
INFO  [10:51:49.392] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:51:49.446] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:51:49.453] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:52:18.292] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:52:46.987] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:53:15.667] [mlr3]  Finished benchmark 
INFO  [10:53:15.741] [bbotk] Result of batch 9: 
INFO  [10:53:15.742] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:53:15.742] [bbotk]                   7              2316     0.06421486        0.404 -0.9345546 
INFO  [10:53:15.742] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:53:15.742] [bbotk]          <NA>   0.9758668 6745414d-966c-42e3-98b7-1eb9ca5b220d 
DEBUG [10:53:16.334] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.240847e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004896967 0.5240847 
  - best initial criterion value(s) :  14.42758 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -14.428  |proj g|=       4.1577
At iterate     1  f =      -30.319  |proj g|=        2.0397
At iterate     2  f =      -38.075  |proj g|=        2.7709
At iterate     3  f =      -43.026  |proj g|=        3.0943
At iterate     4  f =      -48.991  |proj g|=        2.7873
At iterate     5  f =      -56.959  |proj g|=        1.6653
At iterate     6  f =      -58.232  |proj g|=       0.66104
At iterate     7  f =      -58.945  |proj g|=       0.28918
At iterate     8  f =      -58.992  |proj g|=       0.11131
At iterate     9  f =      -58.992  |proj g|=      0.074606
At iterate    10  f =      -58.992  |proj g|=       0.42709
At iterate    11  f =      -58.992  |proj g|=     0.0070313
At iterate    12  f =      -58.992  |proj g|=     0.0028751

iterations 12
function evaluations 22
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00287509
final function value -58.9919

F = -58.9919
final  value -58.991899 
converged
 
INFO  [10:53:16.338] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:53:16.392] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:53:16.399] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:54:01.739] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:54:47.708] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:55:33.041] [mlr3]  Finished benchmark 
INFO  [10:55:33.107] [bbotk] Result of batch 10: 
INFO  [10:55:33.122] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [10:55:33.122] [bbotk]                   6              3715      0.2942473        0.406 -0.936572 
INFO  [10:55:33.122] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:55:33.122] [bbotk]          <NA>   0.9754329 69cc978f-8c91-4cfb-86bc-94550890e38b 
DEBUG [10:55:33.783] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.158682e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004857054 0.5158682 
  - best initial criterion value(s) :  58.57475 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -58.575  |proj g|=       2.3985
At iterate     1  f =      -64.588  |proj g|=        2.8006
At iterate     2  f =      -67.012  |proj g|=        1.6836
At iterate     3  f =      -67.485  |proj g|=        1.3269
At iterate     4  f =      -67.504  |proj g|=       0.53754
At iterate     5  f =      -67.509  |proj g|=       0.67021
At iterate     6  f =      -67.594  |proj g|=        0.9082
At iterate     7  f =      -68.103  |proj g|=        1.6897
At iterate     8  f =      -68.187  |proj g|=       0.88935
At iterate     9  f =      -68.234  |proj g|=       0.50491
At iterate    10  f =      -68.235  |proj g|=      0.027582
At iterate    11  f =      -68.235  |proj g|=       0.27537
At iterate    12  f =      -68.235  |proj g|=     0.0062294
At iterate    13  f =      -68.235  |proj g|=     0.0018779

iterations 13
function evaluations 21
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00187793
final function value -68.2352

F = -68.2352
final  value -68.235218 
converged
 
INFO  [10:55:33.788] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:55:33.845] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:55:33.851] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:56:08.769] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:56:44.057] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:57:18.325] [mlr3]  Finished benchmark 
INFO  [10:57:18.390] [bbotk] Result of batch 11: 
INFO  [10:57:18.392] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:57:18.392] [bbotk]                   5              2860      0.2404591        0.479 -0.9347661 
INFO  [10:57:18.392] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:57:18.392] [bbotk]          <NA>   0.9757568 794796c5-9fcc-4040-8aff-27e6c8e24416 
DEBUG [10:57:19.039] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.077145e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004740818 0.5077145 
  - best initial criterion value(s) :  64.0477 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -64.048  |proj g|=       2.3482
At iterate     1  f =      -69.563  |proj g|=        1.9167
At iterate     2  f =      -71.398  |proj g|=       0.34748
At iterate     3  f =      -71.691  |proj g|=          0.91
At iterate     4  f =      -71.719  |proj g|=       0.49697
At iterate     5  f =      -71.817  |proj g|=       0.16265
At iterate     6  f =      -71.819  |proj g|=      0.041343
At iterate     7  f =      -71.819  |proj g|=       0.16867
At iterate     8  f =      -71.819  |proj g|=     0.0020866

iterations 8
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00208659
final function value -71.819

F = -71.819
final  value -71.818964 
converged
 
INFO  [10:57:19.043] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:57:19.107] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:57:19.113] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:58:02.827] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [10:58:45.749] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:59:28.577] [mlr3]  Finished benchmark 
INFO  [10:59:28.662] [bbotk] Result of batch 12: 
INFO  [10:59:28.664] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [10:59:28.664] [bbotk]                   8              3589      0.2341888        0.463 -0.9338263 
INFO  [10:59:28.664] [bbotk]  errors.model classif.auc                                uhash 
INFO  [10:59:28.664] [bbotk]          <NA>   0.9738248 c0740409-b4b2-4d0d-9c4a-942fb83dae44 
DEBUG [10:59:29.290] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.994559e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004734264 0.4994559 
  - best initial criterion value(s) :  62.05602 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -62.056  |proj g|=       1.5056
At iterate     1  f =      -65.293  |proj g|=        2.2637
At iterate     2  f =      -66.747  |proj g|=        2.0232
At iterate     3  f =      -67.723  |proj g|=        1.7391
At iterate     4  f =      -68.687  |proj g|=         1.418
At iterate     5  f =      -68.704  |proj g|=        1.3814
At iterate     6  f =      -68.805  |proj g|=        1.4263
At iterate     7  f =      -75.111  |proj g|=        1.1789
At iterate     8  f =      -75.152  |proj g|=      0.060652
At iterate     9  f =      -75.152  |proj g|=       0.48878
At iterate    10  f =      -75.152  |proj g|=     0.0059532
At iterate    11  f =      -75.152  |proj g|=     0.0030076
At iterate    12  f =      -75.152  |proj g|=     0.0023757

iterations 12
function evaluations 19
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00237567
final function value -75.1517

F = -75.1517
final  value -75.151681 
converged
 
INFO  [10:59:29.294] [bbotk] Evaluating 1 configuration(s) 
INFO  [10:59:29.347] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [10:59:29.354] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [10:59:43.407] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [10:59:57.834] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:00:12.235] [mlr3]  Finished benchmark 
INFO  [11:00:12.301] [bbotk] Result of batch 13: 
INFO  [11:00:12.302] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:00:12.302] [bbotk]                   6              1087      0.4653356         0.42 -0.9350746 
INFO  [11:00:12.302] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:00:12.302] [bbotk]          <NA>   0.9759429 0416602b-a440-42ce-b00f-62c1c321178b 
DEBUG [11:00:12.921] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.914849e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004643517 0.4914849 
  - best initial criterion value(s) :  49.65188 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -49.652  |proj g|=      0.42364
At iterate     1  f =       -65.15  |proj g|=       0.48031
At iterate     2  f =       -65.93  |proj g|=      0.010484
At iterate     3  f =       -66.33  |proj g|=     0.0079854
At iterate     4  f =       -66.34  |proj g|=       0.47968
At iterate     5  f =      -66.346  |proj g|=     0.0074887
At iterate     6  f =      -66.346  |proj g|=     0.0074636
At iterate     7  f =      -66.346  |proj g|=     0.0034699

iterations 7
function evaluations 11
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00346992
final function value -66.3459

F = -66.3459
final  value -66.345925 
converged
 
INFO  [11:00:12.925] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:00:12.979] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:00:12.985] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:01:01.476] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:01:49.964] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:02:39.319] [mlr3]  Finished benchmark 
INFO  [11:02:39.405] [bbotk] Result of batch 14: 
INFO  [11:02:39.408] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:02:39.408] [bbotk]                   6              4032       0.338931        0.444 -0.9611026 
INFO  [11:02:39.408] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:02:39.408] [bbotk]          <NA>   0.9752644 1324f930-429e-4661-bd57-1dd81137ed56 
DEBUG [11:02:40.039] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.835722e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004596018 0.4835722 
  - best initial criterion value(s) :  68.89248 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -68.892  |proj g|=      0.42371
At iterate     1  f =       -76.83  |proj g|=        1.7597
At iterate     2  f =      -79.344  |proj g|=        1.9477
At iterate     3  f =      -80.391  |proj g|=        1.9469
At iterate     4  f =      -80.402  |proj g|=        1.9467
At iterate     5  f =      -80.408  |proj g|=        1.9462
At iterate     6  f =      -80.411  |proj g|=        1.9458
At iterate     7  f =      -80.426  |proj g|=        1.9431
At iterate     8  f =      -80.456  |proj g|=        1.9368
At iterate     9  f =      -80.535  |proj g|=        1.9192
At iterate    10  f =      -80.719  |proj g|=        1.8755
At iterate    11  f =      -81.147  |proj g|=        1.7704
At iterate    12  f =      -82.117  |proj g|=        1.2264
At iterate    13  f =      -84.103  |proj g|=        3.4609
At iterate    14  f =      -84.813  |proj g|=        1.3583
At iterate    15  f =      -84.852  |proj g|=       0.10299
At iterate    16  f =      -84.857  |proj g|=      0.013918
At iterate    17  f =      -84.857  |proj g|=       0.03366
At iterate    18  f =      -84.857  |proj g|=      0.002142

iterations 18
function evaluations 23
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00214196
final function value -84.8568

F = -84.8568
final  value -84.856755 
converged
 
INFO  [11:02:40.041] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:02:40.086] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:02:40.093] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:03:22.166] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:04:03.262] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:04:46.751] [mlr3]  Finished benchmark 
INFO  [11:04:46.826] [bbotk] Result of batch 15: 
INFO  [11:04:46.828] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:04:46.828] [bbotk]                   7              3438     0.09818652        0.439 -0.9327589 
INFO  [11:04:46.828] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:04:46.828] [bbotk]          <NA>   0.9763426 7939f3ac-5f0e-4aaf-8f35-c95116d6cd7d 
DEBUG [11:04:47.450] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.75874e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004553948 0.475874 
  - best initial criterion value(s) :  68.35772 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -68.358  |proj g|=       6.2905
At iterate     1  f =      -75.764  |proj g|=        1.6957
At iterate     2  f =      -79.874  |proj g|=        1.7416
At iterate     3  f =      -81.892  |proj g|=        1.6538
At iterate     4  f =      -82.798  |proj g|=        1.5236
At iterate     5  f =      -83.581  |proj g|=        1.1139
At iterate     6  f =      -84.005  |proj g|=        1.0351
At iterate     7  f =      -84.181  |proj g|=       0.49905
At iterate     8  f =      -84.292  |proj g|=        1.0047
At iterate     9  f =      -84.382  |proj g|=       0.91176
At iterate    10  f =      -84.752  |proj g|=       0.46748
At iterate    11  f =      -85.449  |proj g|=        1.6708
At iterate    12  f =      -87.917  |proj g|=        4.3612
At iterate    13  f =      -89.043  |proj g|=        4.9798
At iterate    14  f =      -89.355  |proj g|=         3.929
At iterate    15  f =      -89.669  |proj g|=        1.7441
At iterate    16  f =      -89.737  |proj g|=       0.19564
At iterate    17  f =      -89.738  |proj g|=       0.00516
At iterate    18  f =      -89.738  |proj g|=     0.0051597

iterations 18
function evaluations 24
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00515971
final function value -89.7375

F = -89.7375
final  value -89.737501 
converged
 
INFO  [11:04:47.454] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:04:47.508] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:04:47.515] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:05:00.431] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:05:13.287] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:05:26.230] [mlr3]  Finished benchmark 
INFO  [11:05:26.297] [bbotk] Result of batch 16: 
INFO  [11:05:26.299] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:05:26.299] [bbotk]                   7               995      0.3543709        0.431 -0.9313473 
INFO  [11:05:26.299] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:05:26.299] [bbotk]          <NA>   0.9762079 cd0c7ef2-bfe5-4f25-bda2-d4285e149dfa 
DEBUG [11:05:26.946] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.683032e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004473325 0.4683032 
  - best initial criterion value(s) :  69.10451 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -69.105  |proj g|=       3.3883
At iterate     1  f =      -81.853  |proj g|=        2.1362
At iterate     2  f =       -89.41  |proj g|=        1.4302
At iterate     3  f =      -89.422  |proj g|=        0.7407
At iterate     4  f =      -90.074  |proj g|=       0.67855
At iterate     5  f =      -90.365  |proj g|=      0.058791
At iterate     6  f =      -90.365  |proj g|=      0.005189
At iterate     7  f =      -90.365  |proj g|=     0.0051705
At iterate     8  f =      -90.365  |proj g|=     0.0051699

iterations 8
function evaluations 15
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00516992
final function value -90.3654

F = -90.3654
final  value -90.365383 
converged
 
INFO  [11:05:26.950] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:05:27.004] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:05:27.011] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:05:27.962] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:05:28.739] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:05:29.510] [mlr3]  Finished benchmark 
INFO  [11:05:29.575] [bbotk] Result of batch 17: 
INFO  [11:05:29.577] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:05:29.577] [bbotk]                   9              1997      0.1348935        0.452 -0.9322401 
INFO  [11:05:29.577] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:05:29.577] [bbotk]          <NA>         0.5 8c61821d-5994-4b8a-86da-4d71f33a1bd0 
DEBUG [11:05:30.250] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.853313e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004590328 0.4853313 
  - best initial criterion value(s) :  79.56163 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -79.562  |proj g|=       3.0326
At iterate     1  f =      -81.192  |proj g|=        1.7193
At iterate     2  f =      -83.805  |proj g|=        1.5003
At iterate     3  f =      -84.297  |proj g|=        1.4392
At iterate     4  f =       -84.92  |proj g|=        1.2033
At iterate     5  f =      -85.039  |proj g|=       0.36792
At iterate     6  f =      -85.089  |proj g|=        0.2331
At iterate     7  f =       -85.28  |proj g|=       0.47585
At iterate     8  f =      -85.667  |proj g|=       0.47661
At iterate     9  f =      -87.149  |proj g|=       0.62886
At iterate    10  f =      -87.677  |proj g|=       0.47685
At iterate    11  f =      -87.823  |proj g|=       0.66486
At iterate    12  f =      -87.852  |proj g|=       0.71451
At iterate    13  f =      -87.857  |proj g|=       0.66613
At iterate    14  f =      -87.859  |proj g|=       0.60143
At iterate    15  f =      -87.861  |proj g|=       0.49619
At iterate    16  f =      -87.865  |proj g|=       0.22476
At iterate    17  f =      -87.867  |proj g|=       0.47556
At iterate    18  f =      -87.867  |proj g|=     0.0042627
At iterate    19  f =      -87.867  |proj g|=     0.0042627

iterations 19
function evaluations 25
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00426273
final function value -87.8667

F = -87.8667
final  value -87.866712 
converged
 
INFO  [11:05:30.254] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:05:30.317] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:05:30.324] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:06:20.625] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:07:11.193] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:08:03.251] [mlr3]  Finished benchmark 
INFO  [11:08:03.328] [bbotk] Result of batch 18: 
INFO  [11:08:03.330] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:08:03.330] [bbotk]                   5              4168      0.3301224        0.466 -0.9343557 
INFO  [11:08:03.330] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:08:03.330] [bbotk]          <NA>   0.9754497 8b1c139d-b3a6-4cc1-ad69-77550037694a 
DEBUG [11:08:03.973] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.781975e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.00455939 0.4781975 
  - best initial criterion value(s) :  66.41882 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -66.419  |proj g|=       3.6305
At iterate     1  f =      -73.575  |proj g|=        3.2794
At iterate     2  f =      -74.994  |proj g|=        3.2887
At iterate     3  f =      -75.876  |proj g|=        3.2146
At iterate     4  f =      -76.964  |proj g|=         3.097
At iterate     5  f =      -79.538  |proj g|=        2.7833
At iterate     6  f =      -82.033  |proj g|=        2.4641
At iterate     7  f =      -87.078  |proj g|=        1.9053
At iterate     8  f =      -92.576  |proj g|=         1.314
At iterate     9  f =      -93.164  |proj g|=      0.093012
At iterate    10  f =      -93.197  |proj g|=         0.488
At iterate    11  f =      -93.204  |proj g|=       0.46877
At iterate    12  f =      -93.204  |proj g|=      0.004879
At iterate    13  f =      -93.204  |proj g|=      0.010798
At iterate    14  f =      -93.204  |proj g|=     0.0039675

iterations 14
function evaluations 24
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00396753
final function value -93.2037

F = -93.2037
final  value -93.203675 
converged
 
INFO  [11:08:03.977] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:08:04.036] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:08:04.057] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:08:15.876] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:08:27.582] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:08:39.313] [mlr3]  Finished benchmark 
INFO  [11:08:39.399] [bbotk] Result of batch 19: 
INFO  [11:08:39.402] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:08:39.402] [bbotk]                   7               849      0.1086975        0.454 -0.9323761 
INFO  [11:08:39.402] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:08:39.402] [bbotk]          <NA>   0.9750475 4d686e5d-95ca-494a-bfe0-bfc19ea31181 
DEBUG [11:08:40.042] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.711528e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004452412 0.4711528 
  - best initial criterion value(s) :  83.05251 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -83.053  |proj g|=       2.2131
At iterate     1  f =      -89.171  |proj g|=        4.3395
At iterate     2  f =      -92.654  |proj g|=        4.1282
At iterate     3  f =      -93.325  |proj g|=        1.2059
At iterate     4  f =      -93.458  |proj g|=       0.93863
At iterate     5  f =      -93.514  |proj g|=        1.2949
At iterate     6  f =      -93.525  |proj g|=       0.70855
At iterate     7  f =       -93.53  |proj g|=       0.59591
At iterate     8  f =      -93.569  |proj g|=        0.4621
At iterate     9  f =      -93.639  |proj g|=       0.72458
At iterate    10  f =      -93.858  |proj g|=        1.1457
At iterate    11  f =       -94.09  |proj g|=        1.1573
At iterate    12  f =      -94.234  |proj g|=       0.59843
At iterate    13  f =      -94.239  |proj g|=       0.28569
At iterate    14  f =       -94.24  |proj g|=       0.14354
At iterate    15  f =      -94.241  |proj g|=      0.027751
At iterate    16  f =      -94.241  |proj g|=      0.021911
At iterate    17  f =      -94.241  |proj g|=      0.010067
At iterate    18  f =      -94.241  |proj g|=     0.0049015
At iterate    19  f =      -94.241  |proj g|=     0.0046805

iterations 19
function evaluations 24
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00468046
final function value -94.2411

F = -94.2411
final  value -94.241149 
converged
 
INFO  [11:08:40.047] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:08:40.105] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:08:40.113] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:08:40.960] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:08:41.768] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:08:42.582] [mlr3]  Finished benchmark 
INFO  [11:08:42.667] [bbotk] Result of batch 20: 
INFO  [11:08:42.669] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:08:42.669] [bbotk]                  10              4542      0.4531439        0.455 -0.9323717 
INFO  [11:08:42.669] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:08:42.669] [bbotk]          <NA>         0.5 f82d351a-f0f0-423d-8947-327c3e511bae 
DEBUG [11:08:43.324] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.866743e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9422302 
  - variance bounds :  0.004669277 0.4866743 
  - best initial criterion value(s) :  66.52933 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -66.529  |proj g|=       4.9006
At iterate     1  f =      -70.412  |proj g|=       0.50529
At iterate     2  f =      -77.778  |proj g|=        1.8914
At iterate     3  f =      -80.152  |proj g|=        1.5198
At iterate     4  f =      -81.555  |proj g|=       0.34494
At iterate     5  f =      -81.821  |proj g|=        1.1331
At iterate     6  f =      -81.908  |proj g|=       0.69639
At iterate     7  f =      -81.931  |proj g|=       0.76622
At iterate     8  f =      -81.971  |proj g|=       0.65664
At iterate     9  f =      -82.037  |proj g|=       0.59425
At iterate    10  f =      -82.303  |proj g|=       0.51831
At iterate    11  f =      -82.912  |proj g|=       0.47846
At iterate    12  f =      -84.399  |proj g|=       0.47878
At iterate    13  f =      -84.836  |proj g|=        2.2951
At iterate    14  f =      -84.913  |proj g|=        2.1015
At iterate    15  f =      -85.031  |proj g|=         1.076
At iterate    16  f =      -85.051  |proj g|=       0.41972
At iterate    17  f =      -85.055  |proj g|=      0.055096
At iterate    18  f =      -85.055  |proj g|=     0.0079879
At iterate    19  f =      -85.055  |proj g|=     0.0079889
At iterate    20  f =      -85.055  |proj g|=      0.007989
At iterate    21  f =      -85.055  |proj g|=      0.007989

iterations 21
function evaluations 28
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00798901
final function value -85.0552

F = -85.0552
final  value -85.055213 
converged
 
INFO  [11:08:43.328] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:08:43.383] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:08:43.390] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:08:44.117] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:08:45.018] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:08:45.737] [mlr3]  Finished benchmark 
INFO  [11:08:45.802] [bbotk] Result of batch 21: 
INFO  [11:08:45.803] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:08:45.803] [bbotk]                   9              1835    0.003511114        0.465 -0.9348296 
INFO  [11:08:45.803] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:08:45.803] [bbotk]          <NA>         0.5 3643e37c-c929-494c-be2e-9943b01a7239 
DEBUG [11:08:46.449] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.002867e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.004785522 0.5002867 
  - best initial criterion value(s) :  85.32135 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -85.321  |proj g|=       7.1614
At iterate     1  f =      -92.483  |proj g|=        1.7462
At iterate     2  f =      -101.49  |proj g|=        2.0008
At iterate     3  f =      -103.83  |proj g|=        1.6929
At iterate     4  f =       -107.2  |proj g|=        1.2639
At iterate     5  f =      -107.44  |proj g|=         1.033
At iterate     6  f =      -107.48  |proj g|=       0.49146
At iterate     7  f =       -109.8  |proj g|=        4.1155
At iterate     8  f =      -111.59  |proj g|=        4.6981
At iterate     9  f =      -111.97  |proj g|=        1.5901
At iterate    10  f =         -112  |proj g|=       0.59306
At iterate    11  f =      -112.01  |proj g|=      0.020047
At iterate    12  f =      -112.01  |proj g|=     0.0038701
At iterate    13  f =      -112.01  |proj g|=     0.0029162

iterations 13
function evaluations 23
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00291618
final function value -112.014

F = -112.014
final  value -112.013913 
converged
 
INFO  [11:08:46.453] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:08:46.506] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:08:46.513] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:09:27.251] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:10:08.213] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:10:47.355] [mlr3]  Finished benchmark 
INFO  [11:10:47.419] [bbotk] Result of batch 22: 
INFO  [11:10:47.421] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:10:47.421] [bbotk]                   3              3259      0.4488872        0.449 -0.9220334 
INFO  [11:10:47.421] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:10:47.421] [bbotk]          <NA>   0.9744533 97bc18ae-7b77-46c0-8304-eadecd491967 
DEBUG [11:10:48.087] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.939687e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.004709216 0.4939687 
  - best initial criterion value(s) :  91.0642 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -91.064  |proj g|=        4.825
At iterate     1  f =      -95.489  |proj g|=        1.2866
At iterate     2  f =      -103.05  |proj g|=        2.0413
At iterate     3  f =       -106.1  |proj g|=        1.6286
At iterate     4  f =      -108.28  |proj g|=        1.2889
At iterate     5  f =      -108.61  |proj g|=       0.63566
At iterate     6  f =      -108.67  |proj g|=        1.1725
At iterate     7  f =       -108.7  |proj g|=        1.2025
At iterate     8  f =      -108.79  |proj g|=        1.2247
At iterate     9  f =      -109.34  |proj g|=        1.3217
At iterate    10  f =      -110.33  |proj g|=        1.4161
At iterate    11  f =      -113.08  |proj g|=         1.566
At iterate    12  f =      -114.71  |proj g|=        1.5515
At iterate    13  f =      -115.67  |proj g|=        1.4147
At iterate    14  f =      -116.55  |proj g|=       0.12837
At iterate    15  f =      -116.64  |proj g|=     0.0073582
At iterate    16  f =      -116.64  |proj g|=       0.48556
At iterate    17  f =      -116.64  |proj g|=      0.003705
At iterate    18  f =      -116.64  |proj g|=     0.0028412

iterations 18
function evaluations 27
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0028412
final function value -116.637

F = -116.637
final  value -116.636690 
converged
 
INFO  [11:10:48.091] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:10:48.146] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:10:48.152] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:11:25.164] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:12:02.219] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:12:39.127] [mlr3]  Finished benchmark 
INFO  [11:12:39.192] [bbotk] Result of batch 23: 
INFO  [11:12:39.194] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:12:39.194] [bbotk]                   3              3045       0.456436        0.477 -0.9212784 
INFO  [11:12:39.194] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:12:39.194] [bbotk]          <NA>   0.9744172 3f233cda-62fc-48e5-966b-3c7fa1e2c54e 
DEBUG [11:12:39.841] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.877144e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.00468298 0.4877144 
  - best initial criterion value(s) :  66.17645 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -66.176  |proj g|=       5.1285
At iterate     1  f =      -82.715  |proj g|=        1.4083
At iterate     2  f =      -89.608  |proj g|=          3.96
At iterate     3  f =      -96.599  |proj g|=        3.5817
At iterate     4  f =      -101.62  |proj g|=        3.1581
At iterate     5  f =      -106.01  |proj g|=        2.8209
At iterate     6  f =      -121.38  |proj g|=        1.3182
At iterate     7  f =      -121.71  |proj g|=        1.1863
At iterate     8  f =      -121.88  |proj g|=      0.038632
At iterate     9  f =      -121.88  |proj g|=       0.07394
At iterate    10  f =      -121.88  |proj g|=      0.053993
At iterate    11  f =      -121.88  |proj g|=     0.0029774

iterations 11
function evaluations 22
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00297739
final function value -121.88

F = -121.88
final  value -121.880374 
converged
 
INFO  [11:12:39.845] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:12:39.901] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:12:39.908] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:13:18.830] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:13:57.639] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:14:37.660] [mlr3]  Finished benchmark 
INFO  [11:14:37.735] [bbotk] Result of batch 24: 
INFO  [11:14:37.737] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:14:37.737] [bbotk]                   7              3202      0.1511413        0.464 -0.9206441 
INFO  [11:14:37.737] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:14:37.737] [bbotk]          <NA>   0.9760858 0cfc1bfb-d34e-4217-8e8c-e2182ef3c4c0 
DEBUG [11:14:38.395] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.816384e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.004651116 0.4816384 
  - best initial criterion value(s) :  96.01035 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -96.01  |proj g|=       2.9736
At iterate     1  f =      -101.13  |proj g|=        2.6762
At iterate     2  f =      -105.94  |proj g|=        2.0063
At iterate     3  f =      -109.86  |proj g|=        1.0637
At iterate     4  f =      -111.33  |proj g|=        1.0365
At iterate     5  f =      -123.43  |proj g|=       0.47454
At iterate     6  f =      -123.63  |proj g|=       0.19861
At iterate     7  f =      -123.63  |proj g|=       0.47349
At iterate     8  f =      -123.64  |proj g|=     0.0035699
At iterate     9  f =      -123.64  |proj g|=       0.00357
At iterate    10  f =      -123.64  |proj g|=       0.00357

iterations 10
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00356998
final function value -123.635

F = -123.635
final  value -123.635206 
converged
 
INFO  [11:14:38.399] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:14:38.453] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:14:38.460] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:14:39.196] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:14:39.926] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:14:40.835] [mlr3]  Finished benchmark 
INFO  [11:14:40.908] [bbotk] Result of batch 25: 
INFO  [11:14:40.909] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:14:40.909] [bbotk]                   9              2383      0.4080004        0.468 -0.9204061 
INFO  [11:14:40.909] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:14:40.909] [bbotk]          <NA>         0.5 cfdd2d92-2e18-4a21-83cf-0ac2711d0a45 
DEBUG [11:14:41.613] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.945387e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.004792636 0.4945387 
  - best initial criterion value(s) :  90.29078 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -90.291  |proj g|=       0.3285
At iterate     1  f =      -103.58  |proj g|=       0.16585
At iterate     2  f =      -106.69  |proj g|=       0.34041
At iterate     3  f =      -107.18  |proj g|=       0.63477
At iterate     4  f =      -108.07  |proj g|=       0.53327
At iterate     5  f =      -108.19  |proj g|=       0.50003
At iterate     6  f =      -108.21  |proj g|=       0.48501
At iterate     7  f =      -108.21  |proj g|=       0.48494
At iterate     8  f =      -108.21  |proj g|=       0.47909
At iterate     9  f =      -108.21  |proj g|=        0.4791
At iterate    10  f =      -108.21  |proj g|=       0.47962
At iterate    11  f =      -108.21  |proj g|=       0.48104
At iterate    12  f =      -108.21  |proj g|=       0.48628
At iterate    13  f =      -108.22  |proj g|=        0.5011
At iterate    14  f =      -108.22  |proj g|=       0.54768
At iterate    15  f =      -108.22  |proj g|=       0.72228
At iterate    16  f =      -110.05  |proj g|=        7.1455
At iterate    17  f =      -110.08  |proj g|=        6.3332
At iterate    18  f =      -114.49  |proj g|=        7.0001
At iterate    19  f =      -115.69  |proj g|=        1.6199
At iterate    20  f =      -115.72  |proj g|=        0.6475
At iterate    21  f =      -115.73  |proj g|=       0.48623
At iterate    22  f =      -115.74  |proj g|=      0.010956
At iterate    23  f =      -115.74  |proj g|=     0.0058543
At iterate    24  f =      -115.74  |proj g|=     0.0058543

iterations 24
function evaluations 34
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00585435
final function value -115.738

F = -115.738
final  value -115.737927 
converged
 
INFO  [11:14:41.617] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:14:41.671] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:14:41.678] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:15:08.935] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:15:35.518] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:16:01.565] [mlr3]  Finished benchmark 
INFO  [11:16:01.630] [bbotk] Result of batch 26: 
INFO  [11:16:01.632] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:16:01.632] [bbotk]                   7              2144      0.4294964        0.496 -0.9227537 
INFO  [11:16:01.632] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:16:01.632] [bbotk]          <NA>    0.975195 fd879e7e-c84d-4643-9638-a212eecb831a 
DEBUG [11:16:02.364] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.887549e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.004731395 0.4887549 
  - best initial criterion value(s) :  98.13283 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -98.133  |proj g|=       3.3231
At iterate     1  f =      -101.82  |proj g|=        2.9454
At iterate     2  f =      -124.53  |proj g|=        1.3374
At iterate     3  f =      -125.23  |proj g|=        1.2134
At iterate     4  f =      -125.78  |proj g|=       0.64421
At iterate     5  f =       -125.8  |proj g|=        1.7715
At iterate     6  f =      -125.82  |proj g|=        1.6738
At iterate     7  f =      -126.15  |proj g|=       0.38625
At iterate     8  f =      -126.84  |proj g|=       0.56797
At iterate     9  f =      -127.08  |proj g|=        1.1838
At iterate    10  f =      -127.23  |proj g|=       0.60707
At iterate    11  f =      -127.25  |proj g|=       0.35908
At iterate    12  f =      -127.25  |proj g|=       0.48078
At iterate    13  f =      -127.25  |proj g|=        0.4808
At iterate    14  f =      -127.25  |proj g|=     0.0044673
At iterate    15  f =      -127.25  |proj g|=     0.0044673

iterations 15
function evaluations 24
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00446731
final function value -127.253

F = -127.253
final  value -127.253456 
converged
 
INFO  [11:16:02.369] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:16:02.430] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:16:02.441] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:16:34.567] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:17:05.952] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:17:36.950] [mlr3]  Finished benchmark 
INFO  [11:17:37.039] [bbotk] Result of batch 27: 
INFO  [11:17:37.041] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:17:37.041] [bbotk]                   5              2541      0.2892205        0.537 -0.9201204 
INFO  [11:17:37.041] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:17:37.041] [bbotk]          <NA>   0.9756818 7bb9b1b2-449c-467e-a442-db5a0a33b3ac 
DEBUG [11:17:37.706] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.830586e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.004675175 0.4830586 
  - best initial criterion value(s) :  100.4256 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -100.43  |proj g|=       2.7784
At iterate     1  f =       -100.6  |proj g|=        2.6928
At iterate     2  f =      -101.81  |proj g|=        2.6893
At iterate     3  f =      -103.69  |proj g|=        2.6488
At iterate     4  f =      -105.83  |proj g|=        2.5253
At iterate     5  f =      -113.82  |proj g|=        1.9874
At iterate     6  f =      -132.14  |proj g|=        3.8554
At iterate     7  f =      -132.14  |proj g|=        3.7431
At iterate     8  f =      -132.18  |proj g|=        3.2253
At iterate     9  f =       -132.3  |proj g|=        1.5069
At iterate    10  f =      -132.38  |proj g|=       0.47559
At iterate    11  f =      -132.39  |proj g|=       0.47536
At iterate    12  f =      -132.39  |proj g|=       0.47529
At iterate    13  f =      -132.39  |proj g|=       0.11315
At iterate    14  f =      -132.39  |proj g|=      0.004559

iterations 14
function evaluations 20
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.004559
final function value -132.394

F = -132.394
final  value -132.393736 
converged
 
INFO  [11:17:37.710] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:17:37.767] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:17:37.785] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:18:07.648] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:18:36.870] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:19:06.088] [mlr3]  Finished benchmark 
INFO  [11:19:06.165] [bbotk] Result of batch 28: 
INFO  [11:19:06.167] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:19:06.167] [bbotk]                   3              2406      0.3311906         0.47 -0.9191156 
INFO  [11:19:06.167] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:19:06.167] [bbotk]          <NA>   0.9738593 9629fb72-a940-4fb8-a02f-473c7a7b4b72 
DEBUG [11:19:06.906] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.773239e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.00457982 0.4773239 
  - best initial criterion value(s) :  102.8614 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -102.86  |proj g|=        3.941
At iterate     1  f =       -107.2  |proj g|=        3.5019
At iterate     2  f =      -132.21  |proj g|=        1.4721
At iterate     3  f =         -134  |proj g|=       0.28392
At iterate     4  f =      -134.22  |proj g|=       0.29128
At iterate     5  f =      -134.23  |proj g|=       0.26506
At iterate     6  f =      -134.33  |proj g|=       0.46976
At iterate     7  f =      -134.33  |proj g|=       0.46969
At iterate     8  f =      -134.33  |proj g|=       0.46966
At iterate     9  f =      -134.33  |proj g|=      0.055192
At iterate    10  f =      -134.33  |proj g|=     0.0049398

iterations 10
function evaluations 20
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00493979
final function value -134.334

F = -134.334
final  value -134.333600 
converged
 
INFO  [11:19:06.910] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:19:06.966] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:19:06.972] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:20:02.549] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:20:58.850] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:21:54.013] [mlr3]  Finished benchmark 
INFO  [11:21:54.079] [bbotk] Result of batch 29: 
INFO  [11:21:54.081] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:21:54.081] [bbotk]                   6              4598      0.0447495        0.531 -0.9192984 
INFO  [11:21:54.081] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:21:54.081] [bbotk]          <NA>     0.97626 7bcdd9c5-0e41-4f33-86d5-2af06bd40987 
DEBUG [11:21:54.951] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.717953e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.004503192 0.4717953 
  - best initial criterion value(s) :  113.1906 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -113.19  |proj g|=       6.6716
At iterate     1  f =      -119.42  |proj g|=        2.2623
At iterate     2  f =      -128.84  |proj g|=        1.8306
At iterate     3  f =      -131.38  |proj g|=         1.485
At iterate     4  f =      -133.23  |proj g|=        1.1938
At iterate     5  f =      -133.39  |proj g|=       0.46425
At iterate     6  f =      -133.49  |proj g|=        1.1512
At iterate     7  f =      -133.52  |proj g|=        1.1516
At iterate     8  f =      -133.77  |proj g|=        1.1434
At iterate     9  f =      -134.14  |proj g|=        1.1439
At iterate    10  f =      -135.87  |proj g|=         1.171
At iterate    11  f =      -139.54  |proj g|=        1.2175
At iterate    12  f =      -142.56  |proj g|=        1.2382
At iterate    13  f =      -142.98  |proj g|=        1.2355
At iterate    14  f =      -143.11  |proj g|=        1.2319
At iterate    15  f =      -143.12  |proj g|=        1.2302
At iterate    16  f =      -143.12  |proj g|=        1.2297
At iterate    17  f =      -143.12  |proj g|=        1.2293
At iterate    18  f =      -143.13  |proj g|=        1.2278
At iterate    19  f =      -143.14  |proj g|=        1.2236
At iterate    20  f =      -143.16  |proj g|=        1.2112
At iterate    21  f =      -143.21  |proj g|=        1.1832
At iterate    22  f =       -143.3  |proj g|=       0.41822
At iterate    23  f =      -143.39  |proj g|=       0.56255
At iterate    24  f =       -143.4  |proj g|=       0.46438
At iterate    25  f =       -143.4  |proj g|=     0.0063413
At iterate    26  f =       -143.4  |proj g|=       0.10614
At iterate    27  f =       -143.4  |proj g|=     0.0045687

iterations 27
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0045687
final function value -143.398

F = -143.398
final  value -143.398424 
converged
 
INFO  [11:21:54.955] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:21:55.011] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:21:55.018] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:22:28.124] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:23:01.232] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:23:34.305] [mlr3]  Finished benchmark 
INFO  [11:23:34.379] [bbotk] Result of batch 30: 
INFO  [11:23:34.380] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:23:34.380] [bbotk]                   8              2717     0.09336727        0.605 -0.9184812 
INFO  [11:23:34.380] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:23:34.380] [bbotk]          <NA>   0.9747067 b67f69f8-3ee1-407b-bc11-a464f3344b13 
DEBUG [11:23:35.335] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.662568e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.004447742 0.4662568 
  - best initial criterion value(s) :  98.61661 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -98.617  |proj g|=       7.6393
At iterate     1  f =       -105.2  |proj g|=       0.57421
At iterate     2  f =      -115.67  |proj g|=        1.5867
At iterate     3  f =      -117.56  |proj g|=        1.2992
At iterate     4  f =      -118.39  |proj g|=        1.2835
At iterate     5  f =      -118.68  |proj g|=        1.0456
At iterate     6  f =      -118.71  |proj g|=       0.45782
At iterate     7  f =      -118.71  |proj g|=       0.45774
At iterate     8  f =      -118.71  |proj g|=       0.14538
At iterate     9  f =      -118.73  |proj g|=       0.47532
At iterate    10  f =      -118.76  |proj g|=       0.98098
At iterate    11  f =      -118.85  |proj g|=        1.7129
At iterate    12  f =      -118.95  |proj g|=        1.9579
At iterate    13  f =      -119.02  |proj g|=        1.5998
At iterate    14  f =      -119.04  |proj g|=         1.114
At iterate    15  f =      -119.05  |proj g|=       0.70623
At iterate    16  f =      -119.07  |proj g|=       0.45781
At iterate    17  f =      -119.07  |proj g|=       0.45776
At iterate    18  f =      -119.07  |proj g|=       0.26995
At iterate    19  f =      -119.07  |proj g|=      0.011948

iterations 19
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0119478
final function value -119.066

F = -119.066
final  value -119.065943 
converged
 
INFO  [11:23:35.339] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:23:35.393] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:23:35.400] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:23:36.306] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:23:37.033] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:23:37.759] [mlr3]  Finished benchmark 
INFO  [11:23:37.832] [bbotk] Result of batch 31: 
INFO  [11:23:37.834] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:23:37.834] [bbotk]                   9              1584      0.2919227        0.693 -0.9261112 
INFO  [11:23:37.834] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:23:37.834] [bbotk]          <NA>         0.5 bcd43789-8ce0-4dea-9064-86b5ce72a339 
DEBUG [11:23:38.522] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.789199e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.004538631 0.4789199 
  - best initial criterion value(s) :  129.8025 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -129.8  |proj g|=       3.0082
At iterate     1  f =      -134.37  |proj g|=        2.5482
At iterate     2  f =      -153.89  |proj g|=        1.1886
At iterate     3  f =      -153.99  |proj g|=        1.1811
At iterate     4  f =      -154.24  |proj g|=       0.80428
At iterate     5  f =      -154.79  |proj g|=         2.049
At iterate     6  f =         -155  |proj g|=        2.4475
At iterate     7  f =      -155.11  |proj g|=       0.66973
At iterate     8  f =      -155.11  |proj g|=       0.06867
At iterate     9  f =      -155.11  |proj g|=     0.0042595
At iterate    10  f =      -155.11  |proj g|=     0.0042595

iterations 10
function evaluations 19
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00425954
final function value -155.113

F = -155.113
final  value -155.113025 
converged
 
INFO  [11:23:38.526] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:23:38.581] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:23:38.587] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:24:27.905] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:25:16.179] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:26:03.529] [mlr3]  Finished benchmark 
INFO  [11:26:03.594] [bbotk] Result of batch 32: 
INFO  [11:26:03.596] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:26:03.596] [bbotk]                   8              3957      0.2866433         0.49 -0.9160275 
INFO  [11:26:03.596] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:26:03.596] [bbotk]          <NA>   0.9733258 a7bbd17f-972d-4994-876b-cb39d6b11407 
DEBUG [11:26:04.303] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.735745e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.004524452 0.4735745 
  - best initial criterion value(s) :  90.27347 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -90.273  |proj g|=       3.0982
At iterate     1  f =      -98.563  |proj g|=        2.5788
At iterate     2  f =      -117.69  |proj g|=        1.5769
At iterate     3  f =      -121.04  |proj g|=        1.2217
At iterate     4  f =       -122.3  |proj g|=        4.1075
At iterate     5  f =      -122.74  |proj g|=        5.0133
At iterate     6  f =      -122.79  |proj g|=        3.0559
At iterate     7  f =       -122.8  |proj g|=        3.2218
At iterate     8  f =       -122.8  |proj g|=        3.3732
At iterate     9  f =      -122.83  |proj g|=        3.8734
At iterate    10  f =      -122.89  |proj g|=        4.6455
At iterate    11  f =      -123.06  |proj g|=        5.7254
At iterate    12  f =      -123.46  |proj g|=        7.2697
At iterate    13  f =      -124.19  |proj g|=        8.8434
At iterate    14  f =      -124.31  |proj g|=         5.203
At iterate    15  f =      -125.42  |proj g|=        3.5539
At iterate    16  f =      -125.73  |proj g|=        1.5991
At iterate    17  f =      -125.77  |proj g|=       0.46527
At iterate    18  f =      -125.77  |proj g|=      0.013062
At iterate    19  f =      -125.77  |proj g|=       0.29674
At iterate    20  f =      -125.77  |proj g|=      0.013065
At iterate    21  f =      -125.77  |proj g|=      0.013065

iterations 21
function evaluations 29
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0130651
final function value -125.771

F = -125.771
final  value -125.771400 
converged
 
INFO  [11:26:04.307] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:26:04.707] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:26:04.713] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:26:35.225] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:27:05.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:27:36.177] [mlr3]  Finished benchmark 
INFO  [11:27:36.243] [bbotk] Result of batch 33: 
INFO  [11:27:36.245] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:27:36.245] [bbotk]                   5              2486      0.2587999        0.489 -0.9256128 
INFO  [11:27:36.245] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:27:36.245] [bbotk]          <NA>   0.9757613 97912f68-7673-4f71-94b3-9d0fa680ff0b 
DEBUG [11:27:36.919] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.684199e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.004477363 0.4684199 
  - best initial criterion value(s) :  123.1997 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -123.2  |proj g|=       8.7086
At iterate     1  f =       -136.7  |proj g|=        3.3698
At iterate     2  f =      -147.53  |proj g|=        2.3254
At iterate     3  f =      -154.74  |proj g|=        2.2187
At iterate     4  f =      -156.29  |proj g|=        2.1766
At iterate     5  f =      -162.54  |proj g|=        1.8848
At iterate     6  f =      -167.66  |proj g|=        1.4394
At iterate     7  f =      -168.61  |proj g|=        1.3143
At iterate     8  f =      -169.22  |proj g|=        3.2718
At iterate     9  f =      -169.42  |proj g|=       0.22884
At iterate    10  f =      -169.49  |proj g|=       0.39435
At iterate    11  f =      -169.49  |proj g|=       0.46166
At iterate    12  f =      -169.49  |proj g|=     0.0038827
At iterate    13  f =      -169.49  |proj g|=       0.03766

iterations 13
function evaluations 20
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0376597
final function value -169.495

F = -169.495
final  value -169.494872 
converged
 
INFO  [11:27:36.923] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:27:36.976] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:27:36.982] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:28:22.676] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:29:08.220] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:29:52.194] [mlr3]  Finished benchmark 
INFO  [11:29:52.260] [bbotk] Result of batch 34: 
INFO  [11:29:52.262] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:29:52.262] [bbotk]                   4              3667      0.3696913        0.484 -0.9149266 
INFO  [11:29:52.262] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:29:52.262] [bbotk]          <NA>   0.9749497 b17e9f1e-d266-4fa0-a533-02c4af38b68f 
DEBUG [11:29:53.013] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.632915e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.004475676 0.4632915 
  - best initial criterion value(s) :  109.9128 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -109.91  |proj g|=      0.42395
At iterate     1  f =      -123.92  |proj g|=        2.7338
At iterate     2  f =      -129.37  |proj g|=        2.7581
At iterate     3  f =      -131.23  |proj g|=        2.7587
At iterate     4  f =      -134.35  |proj g|=        2.7294
At iterate     5  f =      -135.52  |proj g|=        2.6791
At iterate     6  f =      -136.97  |proj g|=        2.5602
At iterate     7  f =      -138.81  |proj g|=         2.322
At iterate     8  f =      -140.89  |proj g|=        2.0005
At iterate     9  f =      -146.18  |proj g|=        3.9873
At iterate    10  f =      -151.05  |proj g|=        7.4832
At iterate    11  f =       -153.5  |proj g|=       0.60226
At iterate    12  f =      -153.63  |proj g|=        0.2417
At iterate    13  f =      -153.63  |proj g|=     0.0078154
At iterate    14  f =      -153.63  |proj g|=       0.45609
At iterate    15  f =      -153.63  |proj g|=     0.0078192
At iterate    16  f =      -153.63  |proj g|=     0.0078193

iterations 16
function evaluations 24
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00781925
final function value -153.629

F = -153.629
final  value -153.628635 
converged
 
INFO  [11:29:53.017] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:29:53.072] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:29:53.079] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:30:02.211] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:30:10.831] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:30:19.638] [mlr3]  Finished benchmark 
INFO  [11:30:19.713] [bbotk] Result of batch 35: 
INFO  [11:30:19.715] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:30:19.715] [bbotk]                   5               652      0.3023239         0.54 -0.9188173 
INFO  [11:30:19.715] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:30:19.715] [bbotk]          <NA>   0.9756283 a29a00e4-0d7d-4cf7-9fa2-4b65a68fe9bd 
DEBUG [11:30:20.442] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.582647e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.004420082 0.4582647 
  - best initial criterion value(s) :  145.9704 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -145.97  |proj g|=       2.7665
At iterate     1  f =      -145.98  |proj g|=          2.71
At iterate     2  f =       -146.6  |proj g|=        2.7186
At iterate     3  f =      -147.19  |proj g|=        2.6991
At iterate     4  f =      -150.55  |proj g|=        2.5062
At iterate     5  f =      -158.79  |proj g|=         2.023
At iterate     6  f =      -159.09  |proj g|=        2.0131
At iterate     7  f =      -159.52  |proj g|=        1.9596
At iterate     8  f =      -159.87  |proj g|=        1.9562
At iterate     9  f =      -160.76  |proj g|=        1.8986
At iterate    10  f =      -164.67  |proj g|=        1.4974
At iterate    11  f =      -167.31  |proj g|=        3.3375
At iterate    12  f =      -167.87  |proj g|=        1.0104
At iterate    13  f =      -167.88  |proj g|=       0.73125
At iterate    14  f =      -167.89  |proj g|=        0.4515
At iterate    15  f =      -167.89  |proj g|=         0.109
At iterate    16  f =      -167.89  |proj g|=      0.043999
At iterate    17  f =      -167.89  |proj g|=     0.0059764

iterations 17
function evaluations 24
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00597637
final function value -167.891

F = -167.891
final  value -167.890784 
converged
 
INFO  [11:30:20.446] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:30:20.500] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:30:20.507] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:31:12.913] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:32:06.447] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:32:59.415] [mlr3]  Finished benchmark 
INFO  [11:32:59.479] [bbotk] Result of batch 36: 
INFO  [11:32:59.481] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:32:59.481] [bbotk]                   5              4379      0.3872848        0.509 -0.9159607 
INFO  [11:32:59.481] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:32:59.481] [bbotk]          <NA>    0.975297 b5a0e629-fd8f-4b01-8227-654cc0de8fdc 
DEBUG [11:33:00.194] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.532932e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9034 0.9633884 
  - variance bounds :  0.004362735 0.4532931 
  - best initial criterion value(s) :  123.8471 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -123.85  |proj g|=       3.6905
At iterate     1  f =      -131.37  |proj g|=        3.1291
At iterate     2  f =      -160.79  |proj g|=        1.5182
At iterate     3  f =       -164.7  |proj g|=        0.8692
At iterate     4  f =      -164.85  |proj g|=      0.082436
At iterate     5  f =      -164.95  |proj g|=        2.9636
At iterate     6  f =      -167.28  |proj g|=        2.1744
At iterate     7  f =      -167.42  |proj g|=       0.44652
At iterate     8  f =      -167.42  |proj g|=       0.44647
At iterate     9  f =      -167.42  |proj g|=       0.33661
At iterate    10  f =      -167.42  |proj g|=      0.007147

iterations 10
function evaluations 19
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00714696
final function value -167.423

F = -167.423
final  value -167.422513 
converged
 
INFO  [11:33:00.198] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:33:00.253] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:33:00.260] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:33:00.985] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:33:01.718] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:33:02.439] [mlr3]  Finished benchmark 
INFO  [11:33:02.512] [bbotk] Result of batch 37: 
INFO  [11:33:02.513] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:33:02.513] [bbotk]                  10               311     0.02589988        0.517 -0.9165701 
INFO  [11:33:02.513] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:33:02.513] [bbotk]          <NA>         0.5 76c7d621-e16c-4190-b77f-5cd551fe1277 
DEBUG [11:33:03.291] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.655692e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9096 0.9633884 
  - variance bounds :  0.004545941 0.4655692 
  - best initial criterion value(s) :  138.9554 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -138.96  |proj g|=       9.5379
At iterate     1  f =      -149.31  |proj g|=       0.10625
At iterate     2  f =      -163.14  |proj g|=        1.8365
At iterate     3  f =      -164.92  |proj g|=         1.648
At iterate     4  f =      -169.42  |proj g|=        1.2393
At iterate     5  f =      -169.68  |proj g|=         1.372
At iterate     6  f =      -169.76  |proj g|=        2.0454
At iterate     7  f =      -169.92  |proj g|=       0.19438
At iterate     8  f =      -169.93  |proj g|=       0.45882
At iterate     9  f =      -169.94  |proj g|=       0.45882
At iterate    10  f =      -169.99  |proj g|=        1.1797
At iterate    11  f =       -170.1  |proj g|=        2.0702
At iterate    12  f =      -170.13  |proj g|=        1.4607
At iterate    13  f =      -170.16  |proj g|=       0.45882
At iterate    14  f =      -170.16  |proj g|=       0.45879
At iterate    15  f =      -170.16  |proj g|=     0.0074785
At iterate    16  f =      -170.16  |proj g|=     0.0074785
At iterate    17  f =      -170.16  |proj g|=     0.0074783
At iterate    18  f =      -170.16  |proj g|=      0.016835
At iterate    19  f =      -170.16  |proj g|=       0.03134
At iterate    20  f =      -170.16  |proj g|=      0.064819
At iterate    21  f =      -170.16  |proj g|=      0.041112
At iterate    22  f =      -170.16  |proj g|=      0.096629
At iterate    23  f =      -170.16  |proj g|=       0.27743
At iterate    24  f =      -170.16  |proj g|=        0.4985
At iterate    25  f =      -170.17  |proj g|=       0.90522
At iterate    26  f =       -170.2  |proj g|=        1.1212
At iterate    27  f =      -170.26  |proj g|=        1.1387
At iterate    28  f =      -170.39  |proj g|=        1.1631
At iterate    29  f =      -170.99  |proj g|=        1.2479
At iterate    30  f =      -172.15  |proj g|=        1.3506
At iterate    31  f =      -175.24  |proj g|=        1.5083
At iterate    32  f =      -181.06  |proj g|=        1.7328
At iterate    33  f =      -183.86  |proj g|=        1.7215
At iterate    34  f =      -186.73  |proj g|=        1.4776
At iterate    35  f =      -188.68  |proj g|=       0.41567
At iterate    36  f =      -188.86  |proj g|=        1.7536
At iterate    37  f =      -188.92  |proj g|=       0.12336
At iterate    38  f =      -188.92  |proj g|=       0.45923
At iterate    39  f =      -188.92  |proj g|=     0.0017947
At iterate    40  f =      -188.92  |proj g|=      0.001808

iterations 40
function evaluations 54
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00180799
final function value -188.92

F = -188.92
final  value -188.919500 
converged
 
INFO  [11:33:03.295] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:33:03.347] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:33:03.354] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:33:56.049] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:34:49.212] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:35:40.416] [mlr3]  Finished benchmark 
INFO  [11:35:40.497] [bbotk] Result of batch 38: 
INFO  [11:35:40.499] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:35:40.499] [bbotk]                   3              4270      0.4758666        0.531 -0.9117807 
INFO  [11:35:40.499] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:35:40.499] [bbotk]          <NA>   0.9746453 b7bd84d0-accf-42da-9bc0-8d3d921c37e1 
DEBUG [11:35:41.199] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.607691e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9096 0.9633884 
  - variance bounds :  0.00451993 0.4607691 
  - best initial criterion value(s) :  139.6254 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -139.63  |proj g|=       2.8183
At iterate     1  f =      -140.38  |proj g|=        2.7845
At iterate     2  f =      -143.48  |proj g|=        2.6021
ys=-8.518e-02  -gs= 3.050e+00, BFGS update SKIPPED
At iterate     3  f =      -146.26  |proj g|=         2.361
At iterate     4  f =      -158.66  |proj g|=        1.1531
At iterate     5  f =       -161.5  |proj g|=       0.84137
At iterate     6  f =      -161.66  |proj g|=       0.75164
At iterate     7  f =      -161.67  |proj g|=      0.010648
At iterate     8  f =      -161.67  |proj g|=       0.45373
At iterate     9  f =      -161.67  |proj g|=      0.012736
At iterate    10  f =      -161.67  |proj g|=      0.010651

iterations 10
function evaluations 21
segments explored during Cauchy searches 13
BFGS updates skipped 1
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0106506
final function value -161.672

F = -161.672
final  value -161.672309 
converged
 
INFO  [11:35:41.203] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:35:41.259] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:35:41.266] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:36:04.534] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:36:27.426] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:36:50.798] [mlr3]  Finished benchmark 
INFO  [11:36:50.873] [bbotk] Result of batch 39: 
INFO  [11:36:50.875] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:36:50.875] [bbotk]                   4              1824      0.4962353        0.502 -0.9165648 
INFO  [11:36:50.875] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:36:50.875] [bbotk]          <NA>   0.9750358 6b88edb6-bae2-46c8-8d5f-66a9e0b43b90 
DEBUG [11:36:51.584] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.560491e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9096 0.9854484 
  - variance bounds :  0.00446002 0.4560491 
  - best initial criterion value(s) :  136.0926 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -136.09  |proj g|=         5.98
At iterate     1  f =      -140.98  |proj g|=        2.3142
At iterate     2  f =      -157.06  |proj g|=        2.2973
At iterate     3  f =      -159.01  |proj g|=        2.1231
At iterate     4  f =       -167.9  |proj g|=        1.5503
At iterate     5  f =      -170.38  |proj g|=        6.3101
At iterate     6  f =      -170.73  |proj g|=        6.3939
At iterate     7  f =      -171.16  |proj g|=        4.0246
At iterate     8  f =      -171.35  |proj g|=        0.4496
At iterate     9  f =      -171.38  |proj g|=       0.44942
At iterate    10  f =      -171.38  |proj g|=       0.44933
At iterate    11  f =      -171.38  |proj g|=       0.11828
At iterate    12  f =      -171.38  |proj g|=     0.0092847

iterations 12
function evaluations 20
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00928473
final function value -171.379

F = -171.379
final  value -171.379095 
converged
 
INFO  [11:36:51.588] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:36:51.646] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:36:51.654] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:37:51.525] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:38:52.487] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:39:51.917] [mlr3]  Finished benchmark 
INFO  [11:39:51.982] [bbotk] Result of batch 40: 
INFO  [11:39:51.984] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [11:39:51.984] [bbotk]                   5              4996      0.4453425        0.504 -0.914962 
INFO  [11:39:51.984] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:39:51.984] [bbotk]          <NA>   0.9751601 011f8c8f-0b33-43e9-9352-5e1f0e8b3aa5 
DEBUG [11:39:52.712] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.51398e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004388049 0.451398 
  - best initial criterion value(s) :  160.4591 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -160.46  |proj g|=       9.4001
At iterate     1  f =      -167.19  |proj g|=        0.1691
At iterate     2  f =      -176.93  |proj g|=        1.4887
At iterate     3  f =      -178.25  |proj g|=        1.2622
At iterate     4  f =      -179.05  |proj g|=       0.79555
At iterate     5  f =      -179.07  |proj g|=       0.44489
At iterate     6  f =      -179.08  |proj g|=       0.65779
At iterate     7  f =      -179.14  |proj g|=        1.1224
At iterate     8  f =      -179.37  |proj g|=        1.1808
At iterate     9  f =      -179.85  |proj g|=        1.2543
At iterate    10  f =      -181.17  |proj g|=        1.3836
At iterate    11  f =      -181.59  |proj g|=        1.3517
At iterate    12  f =      -183.66  |proj g|=        1.4052
At iterate    13  f =      -185.08  |proj g|=        1.2416
At iterate    14  f =       -185.5  |proj g|=      0.065291
At iterate    15  f =       -185.5  |proj g|=       0.44505
At iterate    16  f =       -185.5  |proj g|=     0.0071186
At iterate    17  f =       -185.5  |proj g|=     0.0071186

iterations 17
function evaluations 26
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00711865
final function value -185.499

F = -185.499
final  value -185.499252 
converged
 
INFO  [11:39:52.716] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:39:52.770] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:39:52.777] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:40:49.909] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:41:46.570] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:42:43.605] [mlr3]  Finished benchmark 
INFO  [11:42:43.671] [bbotk] Result of batch 41: 
INFO  [11:42:43.672] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:42:43.672] [bbotk]                   4              4736      0.1772706        0.511 -0.9136555 
INFO  [11:42:43.672] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:42:43.672] [bbotk]          <NA>   0.9750812 b0aa49a7-dc23-4443-81b9-1ab95013a76c 
DEBUG [11:42:44.403] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.468083e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004327129 0.4468083 
  - best initial criterion value(s) :  126.1874 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -126.19  |proj g|=       4.1709
At iterate     1  f =      -126.52  |proj g|=        2.2478
At iterate     2  f =      -157.03  |proj g|=        3.0281
At iterate     3  f =      -161.09  |proj g|=          2.83
At iterate     4  f =      -188.74  |proj g|=        1.7493
At iterate     5  f =       -188.9  |proj g|=        1.7296
At iterate     6  f =      -193.06  |proj g|=        1.3684
At iterate     7  f =      -194.02  |proj g|=        1.1708
At iterate     8  f =      -194.16  |proj g|=        1.8266
At iterate     9  f =      -194.23  |proj g|=       0.20973
At iterate    10  f =      -194.23  |proj g|=       0.44065
At iterate    11  f =      -194.23  |proj g|=     0.0062071
At iterate    12  f =      -194.23  |proj g|=      0.022885

iterations 12
function evaluations 22
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0228847
final function value -194.235

F = -194.235
final  value -194.234521 
converged
 
INFO  [11:42:44.407] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:42:44.461] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:42:44.483] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:43:01.088] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:43:17.848] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:43:34.919] [mlr3]  Finished benchmark 
INFO  [11:43:34.984] [bbotk] Result of batch 42: 
INFO  [11:43:34.986] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:43:34.986] [bbotk]                   3              1332      0.2296097        0.531 -0.9122385 
INFO  [11:43:34.986] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:43:34.986] [bbotk]          <NA>   0.9730153 68713d80-3fae-4470-8a37-9506465dcd3c 
DEBUG [11:43:36.331] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.422042e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004258534 0.4422042 
  - best initial criterion value(s) :  150.8068 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -150.81  |proj g|=      0.95674
At iterate     1  f =      -202.78  |proj g|=        2.0345
ys=-7.665e+00  -gs= 3.558e+01, BFGS update SKIPPED
At iterate     2  f =      -202.94  |proj g|=        1.2839
At iterate     3  f =      -203.61  |proj g|=        1.1805
At iterate     4  f =       -203.7  |proj g|=       0.43633
At iterate     5  f =      -204.64  |proj g|=       0.40855
At iterate     6  f =      -204.65  |proj g|=         0.235
At iterate     7  f =      -204.65  |proj g|=       0.03347
At iterate     8  f =      -204.65  |proj g|=       0.43627
At iterate     9  f =      -204.65  |proj g|=     0.0051367
At iterate    10  f =      -204.65  |proj g|=     0.0051367

iterations 10
function evaluations 18
segments explored during Cauchy searches 14
BFGS updates skipped 1
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00513673
final function value -204.65

F = -204.65
final  value -204.649895 
converged
 
INFO  [11:43:36.335] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:43:36.390] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:43:36.397] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:43:59.509] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:44:23.400] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:44:46.710] [mlr3]  Finished benchmark 
INFO  [11:44:46.776] [bbotk] Result of batch 43: 
INFO  [11:44:46.777] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [11:44:46.777] [bbotk]                   4              1898      0.2844605        1.069 -0.910708 
INFO  [11:44:46.777] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:44:46.777] [bbotk]          <NA>    0.975058 a86dca86-98bd-48f5-acd4-e5ee9bb445a5 
DEBUG [11:44:47.660] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.377474e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004215656 0.4377473 
  - best initial criterion value(s) :  130.3172 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -130.32  |proj g|=       7.9631
At iterate     1  f =      -137.82  |proj g|=        2.3837
At iterate     2  f =      -150.12  |proj g|=        1.9352
At iterate     3  f =      -153.26  |proj g|=        1.5991
At iterate     4  f =      -156.44  |proj g|=        1.2601
At iterate     5  f =      -156.67  |proj g|=        1.1646
At iterate     6  f =       -156.7  |proj g|=        1.1641
At iterate     7  f =      -156.83  |proj g|=        1.1766
At iterate     8  f =      -157.05  |proj g|=        1.1908
At iterate     9  f =      -157.83  |proj g|=        1.2245
At iterate    10  f =      -159.65  |proj g|=        1.2869
At iterate    11  f =      -164.11  |proj g|=        1.4157
At iterate    12  f =      -168.51  |proj g|=        1.4816
At iterate    13  f =      -169.64  |proj g|=        1.4376
At iterate    14  f =       -170.2  |proj g|=        1.3837
At iterate    15  f =      -170.43  |proj g|=         1.339
At iterate    16  f =      -170.75  |proj g|=        1.2615
At iterate    17  f =      -171.19  |proj g|=       0.39837
At iterate    18  f =      -171.45  |proj g|=         1.136
At iterate    19  f =      -171.47  |proj g|=       0.43104
At iterate    20  f =      -171.48  |proj g|=      0.013979
At iterate    21  f =      -171.48  |proj g|=       0.43095
At iterate    22  f =      -171.48  |proj g|=      0.013983
At iterate    23  f =      -171.48  |proj g|=      0.013983

iterations 23
function evaluations 32
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.013983
final function value -171.476

F = -171.476
final  value -171.476353 
converged
 
INFO  [11:44:47.664] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:44:47.718] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:44:47.725] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:45:02.537] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:45:17.299] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:45:31.701] [mlr3]  Finished benchmark 
INFO  [11:45:31.767] [bbotk] Result of batch 44: 
INFO  [11:45:31.769] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:45:31.769] [bbotk]                   3              1134      0.4897967        0.606 -0.9162385 
INFO  [11:45:31.769] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:45:31.769] [bbotk]          <NA>   0.9733091 c0316a75-6360-44f3-99e5-9d7452d1b584 
DEBUG [11:45:32.640] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.33293e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004150584 0.433293 
  - best initial criterion value(s) :  166.3479 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -166.35  |proj g|=      0.51301
At iterate     1  f =      -208.94  |proj g|=        13.322
At iterate     2  f =      -209.46  |proj g|=        13.306
At iterate     3  f =      -210.17  |proj g|=        13.285
At iterate     4  f =      -210.52  |proj g|=        13.278
At iterate     5  f =      -210.57  |proj g|=        13.274
At iterate     6  f =      -210.74  |proj g|=        13.256
At iterate     7  f =      -210.98  |proj g|=        12.379
At iterate     8  f =      -211.44  |proj g|=        10.132
At iterate     9  f =      -212.17  |proj g|=        6.4181
At iterate    10  f =       -213.2  |proj g|=        1.6332
At iterate    11  f =      -213.23  |proj g|=       0.42755
At iterate    12  f =      -213.23  |proj g|=     0.0055955
At iterate    13  f =      -213.23  |proj g|=     0.0055969
At iterate    14  f =      -213.23  |proj g|=       0.01551

iterations 14
function evaluations 19
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0155102
final function value -213.234

F = -213.234
final  value -213.233743 
converged
 
INFO  [11:45:32.644] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:45:32.698] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:45:32.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:45:33.435] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:45:34.240] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:45:35.073] [mlr3]  Finished benchmark 
INFO  [11:45:35.145] [bbotk] Result of batch 45: 
INFO  [11:45:35.147] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:45:35.147] [bbotk]                  10              3446      0.2760912        0.641 -0.9097811 
INFO  [11:45:35.147] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:45:35.147] [bbotk]          <NA>         0.5 4adde1f6-d06c-488d-a128-4b85ad0a7463 
DEBUG [11:45:36.034] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.452867e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004263587 0.4452867 
  - best initial criterion value(s) :  174.7986 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -174.8  |proj g|=       11.584
At iterate     1  f =      -191.26  |proj g|=       0.37445
At iterate     2  f =      -207.43  |proj g|=         2.162
At iterate     3  f =       -210.2  |proj g|=        1.9389
At iterate     4  f =       -215.1  |proj g|=        1.6619
At iterate     5  f =      -217.67  |proj g|=        1.4741
At iterate     6  f =      -219.08  |proj g|=        1.3147
At iterate     7  f =      -219.59  |proj g|=        4.5597
At iterate     8  f =      -219.61  |proj g|=        4.8274
At iterate     9  f =      -219.89  |proj g|=       0.43966
At iterate    10  f =       -219.9  |proj g|=      0.028561
At iterate    11  f =       -219.9  |proj g|=       0.23798
At iterate    12  f =       -219.9  |proj g|=      0.034065

iterations 12
function evaluations 21
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0340653
final function value -219.896

F = -219.896
final  value -219.895572 
converged
 
INFO  [11:45:36.039] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:45:36.102] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:45:36.110] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:46:26.380] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:47:17.117] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:48:05.626] [mlr3]  Finished benchmark 
INFO  [11:48:05.705] [bbotk] Result of batch 46: 
INFO  [11:48:05.707] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:48:05.707] [bbotk]                   8              4078      0.2054102        0.631 -0.9088408 
INFO  [11:48:05.707] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:48:05.707] [bbotk]          <NA>   0.9737941 f2df425a-4fc2-41ab-8ac3-0127fea20f76 
DEBUG [11:48:06.588] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.40992e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004235806 0.4409919 
  - best initial criterion value(s) :  158.0539 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -158.05  |proj g|=       3.0612
At iterate     1  f =      -158.37  |proj g|=        2.9852
At iterate     2  f =      -159.64  |proj g|=        2.9759
At iterate     3  f =       -162.4  |proj g|=        2.9068
At iterate     4  f =      -165.17  |proj g|=        2.7018
At iterate     5  f =      -177.97  |proj g|=        2.3042
At iterate     6  f =       -196.6  |proj g|=        1.3003
At iterate     7  f =      -201.74  |proj g|=        1.0277
At iterate     8  f =      -203.11  |proj g|=        4.3054
At iterate     9  f =      -203.18  |proj g|=        3.7472
At iterate    10  f =      -203.19  |proj g|=        3.4631
At iterate    11  f =       -203.2  |proj g|=        3.4599
At iterate    12  f =      -203.24  |proj g|=        3.0455
At iterate    13  f =       -203.3  |proj g|=         1.993
At iterate    14  f =      -203.34  |proj g|=       0.65963
At iterate    15  f =      -203.35  |proj g|=      0.016573
At iterate    16  f =      -203.35  |proj g|=      0.044416
At iterate    17  f =      -203.35  |proj g|=       0.26387
At iterate    18  f =      -203.35  |proj g|=     0.0092638

iterations 18
function evaluations 24
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00926378
final function value -203.354

F = -203.354
final  value -203.354047 
converged
 
INFO  [11:48:06.592] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:48:06.647] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:48:06.653] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:48:07.439] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:48:08.208] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:48:09.168] [mlr3]  Finished benchmark 
INFO  [11:48:09.235] [bbotk] Result of batch 47: 
INFO  [11:48:09.237] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:48:09.237] [bbotk]                   9              4183      0.3773324        0.616 -0.9112619 
INFO  [11:48:09.237] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:48:09.237] [bbotk]          <NA>         0.5 60d46fd2-127a-4448-8cc2-ab3dc2158c5f 
DEBUG [11:48:10.141] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.521912e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.00434023 0.4521912 
  - best initial criterion value(s) :  171.1616 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -171.16  |proj g|=       4.7179
At iterate     1  f =      -175.64  |proj g|=        4.3648
At iterate     2  f =      -191.88  |proj g|=        3.4703
ys=-4.723e+00  -gs= 1.417e+01, BFGS update SKIPPED
At iterate     3  f =      -194.72  |proj g|=        3.3425
At iterate     4  f =      -197.46  |proj g|=        3.1639
At iterate     5  f =       -200.4  |proj g|=        2.9211
At iterate     6  f =      -206.65  |proj g|=        2.4817
At iterate     7  f =      -222.53  |proj g|=        1.4086
At iterate     8  f =      -227.24  |proj g|=         3.928
At iterate     9  f =      -227.65  |proj g|=        1.9059
At iterate    10  f =      -227.74  |proj g|=       0.44693
At iterate    11  f =      -227.77  |proj g|=       0.86493
At iterate    12  f =      -227.78  |proj g|=       0.36724
At iterate    13  f =      -227.79  |proj g|=       0.25101
At iterate    14  f =      -227.79  |proj g|=      0.080176
At iterate    15  f =      -227.79  |proj g|=     0.0056007
At iterate    16  f =      -227.79  |proj g|=      0.081608

iterations 16
function evaluations 28
segments explored during Cauchy searches 20
BFGS updates skipped 1
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0816078
final function value -227.786

F = -227.786
final  value -227.785846 
converged
 
INFO  [11:48:10.146] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:48:10.201] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:48:10.208] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:49:02.674] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:49:55.861] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:50:48.519] [mlr3]  Finished benchmark 
INFO  [11:50:48.585] [bbotk] Result of batch 48: 
INFO  [11:50:48.587] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:50:48.587] [bbotk]                   5              4408      0.1924708        0.634 -0.9076913 
INFO  [11:50:48.587] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:50:48.587] [bbotk]          <NA>   0.9756836 782d1f60-f9cb-403e-adfb-b9bdd4d0a0a3 
DEBUG [11:50:49.485] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.481041e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004300028 0.4481041 
  - best initial criterion value(s) :  166.4361 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -166.44  |proj g|=        11.13
At iterate     1  f =      -177.22  |proj g|=        1.5578
At iterate     2  f =      -187.39  |proj g|=        1.7652
At iterate     3  f =      -187.75  |proj g|=        1.7404
At iterate     4  f =      -190.18  |proj g|=        1.5065
At iterate     5  f =      -191.63  |proj g|=        2.9686
At iterate     6  f =      -214.93  |proj g|=        5.1444
At iterate     7  f =      -215.24  |proj g|=         0.794
At iterate     8  f =      -215.24  |proj g|=       0.44235
At iterate     9  f =      -215.24  |proj g|=       0.02082
At iterate    10  f =      -215.24  |proj g|=     0.0088344
At iterate    11  f =      -215.24  |proj g|=     0.0088344

iterations 11
function evaluations 21
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00883436
final function value -215.243

F = -215.243
final  value -215.243322 
converged
 
INFO  [11:50:49.489] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:50:49.544] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:50:49.550] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:51:01.531] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:51:13.722] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:51:25.766] [mlr3]  Finished benchmark 
INFO  [11:51:25.841] [bbotk] Result of batch 49: 
INFO  [11:51:25.843] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:51:25.843] [bbotk]                   7               926      0.3200982        0.633 -0.9094092 
INFO  [11:51:25.843] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:51:25.843] [bbotk]          <NA>    0.976334 55b0b3c2-196e-4005-91ba-74bf1c30f130 
DEBUG [11:51:26.765] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.440902e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004241068 0.4440902 
  - best initial criterion value(s) :  149.6639 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -149.66  |proj g|=       4.1723
At iterate     1  f =      -151.82  |proj g|=        6.8188
At iterate     2  f =      -167.94  |proj g|=        2.0425
At iterate     3  f =      -175.71  |proj g|=        3.6304
At iterate     4  f =      -180.11  |proj g|=        3.5431
At iterate     5  f =      -181.68  |proj g|=        3.4921
At iterate     6  f =      -184.91  |proj g|=        3.3979
At iterate     7  f =       -212.6  |proj g|=        1.7337
At iterate     8  f =       -218.7  |proj g|=        1.3218
At iterate     9  f =      -219.08  |proj g|=        1.2261
At iterate    10  f =      -219.64  |proj g|=      0.030631
At iterate    11  f =      -219.64  |proj g|=      0.017547
At iterate    12  f =      -219.64  |proj g|=      0.016195
At iterate    13  f =      -219.64  |proj g|=     0.0091288

iterations 13
function evaluations 26
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00912881
final function value -219.641

F = -219.641
final  value -219.640591 
converged
 
INFO  [11:51:26.770] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:51:26.830] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:51:26.838] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:52:18.825] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:53:09.013] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:53:59.137] [mlr3]  Finished benchmark 
INFO  [11:53:59.210] [bbotk] Result of batch 50: 
INFO  [11:53:59.212] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:53:59.212] [bbotk]                   3              4165     0.08731557        0.656 -0.9090823 
INFO  [11:53:59.212] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:53:59.212] [bbotk]          <NA>   0.9732263 5738e2a4-98e1-40a4-bc23-8fe660be981a 
DEBUG [11:54:00.157] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.400192e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004218614 0.4400191 
  - best initial criterion value(s) :  172.9228 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -172.92  |proj g|=      0.29573
At iterate     1  f =      -192.54  |proj g|=        2.8537
At iterate     2  f =      -195.12  |proj g|=        2.8456
At iterate     3  f =      -196.36  |proj g|=        2.8354
At iterate     4  f =       -199.3  |proj g|=        2.8152
At iterate     5  f =      -199.63  |proj g|=        2.8066
At iterate     6  f =      -199.92  |proj g|=        2.7885
At iterate     7  f =      -200.36  |proj g|=        2.7477
At iterate     8  f =      -200.96  |proj g|=        2.6798
At iterate     9  f =      -202.25  |proj g|=         2.523
At iterate    10  f =      -205.05  |proj g|=        2.1834
At iterate    11  f =      -214.15  |proj g|=        6.1032
At iterate    12  f =       -220.8  |proj g|=        10.492
At iterate    13  f =      -223.84  |proj g|=         6.286
At iterate    14  f =      -224.84  |proj g|=        1.8484
At iterate    15  f =      -224.86  |proj g|=       0.26529
At iterate    16  f =      -224.87  |proj g|=       0.43449
At iterate    17  f =      -224.88  |proj g|=     0.0096287
At iterate    18  f =      -224.88  |proj g|=     0.0089673
At iterate    19  f =      -224.88  |proj g|=     0.0089673

iterations 19
function evaluations 29
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00896733
final function value -224.877

F = -224.877
final  value -224.876508 
converged
 
INFO  [11:54:00.161] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:54:00.213] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:54:00.219] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:54:51.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:55:42.417] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:56:33.172] [mlr3]  Finished benchmark 
INFO  [11:56:33.238] [bbotk] Result of batch 51: 
INFO  [11:56:33.240] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:56:33.240] [bbotk]                   8              4245     0.01033111        0.659 -0.9083727 
INFO  [11:56:33.240] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:56:33.240] [bbotk]          <NA>   0.9720499 d51b1ef7-dd2c-4b4d-8759-81b0e5eb3e56 
DEBUG [11:56:34.138] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.359651e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004188521 0.4359651 
  - best initial criterion value(s) :  199.0565 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -199.06  |proj g|=       2.9184
At iterate     1  f =       -206.5  |proj g|=        2.2512
At iterate     2  f =      -228.23  |proj g|=       0.57044
At iterate     3  f =       -228.5  |proj g|=       0.55077
At iterate     4  f =      -228.55  |proj g|=        1.3825
At iterate     5  f =      -228.57  |proj g|=       0.43045
At iterate     6  f =      -228.57  |proj g|=     0.0090794
At iterate     7  f =      -228.57  |proj g|=       0.43043
At iterate     8  f =      -228.57  |proj g|=     0.0090802
At iterate     9  f =      -228.57  |proj g|=     0.0090802

iterations 9
function evaluations 15
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00908024
final function value -228.568

F = -228.568
final  value -228.567993 
converged
 
INFO  [11:56:34.142] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:56:34.196] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:56:34.203] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [11:57:11.507] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [11:57:48.202] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:58:24.939] [mlr3]  Finished benchmark 
INFO  [11:58:25.005] [bbotk] Result of batch 52: 
INFO  [11:58:25.007] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [11:58:25.007] [bbotk]                   5              3006     0.02864964        0.649 -0.9090261 
INFO  [11:58:25.007] [bbotk]  errors.model classif.auc                                uhash 
INFO  [11:58:25.007] [bbotk]          <NA>    0.974492 5f615d1a-a284-446f-a7e3-42f37f9c7a57 
DEBUG [11:58:25.946] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.320471e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004149943 0.4320471 
  - best initial criterion value(s) :  220.2483 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -220.25  |proj g|=       3.1866
At iterate     1  f =      -220.52  |proj g|=        3.0676
At iterate     2  f =      -221.92  |proj g|=        3.0886
At iterate     3  f =      -223.27  |proj g|=        3.0778
At iterate     4  f =      -224.39  |proj g|=        3.0197
At iterate     5  f =      -225.89  |proj g|=        2.9501
ys=-4.336e-03  -gs= 1.494e+00, BFGS update SKIPPED
At iterate     6  f =       -231.4  |proj g|=        2.6091
At iterate     7  f =       -247.3  |proj g|=        2.0261
At iterate     8  f =      -254.23  |proj g|=      0.048416
At iterate     9  f =      -254.24  |proj g|=       0.19799
At iterate    10  f =      -254.25  |proj g|=      0.012952
At iterate    11  f =      -254.25  |proj g|=       0.42691
At iterate    12  f =      -254.25  |proj g|=      0.005292

iterations 12
function evaluations 21
segments explored during Cauchy searches 15
BFGS updates skipped 1
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00529198
final function value -254.245

F = -254.245
final  value -254.245079 
converged
 
INFO  [11:58:25.950] [bbotk] Evaluating 1 configuration(s) 
INFO  [11:58:26.003] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [11:58:26.010] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [11:59:24.125] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:00:23.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:01:23.129] [mlr3]  Finished benchmark 
INFO  [12:01:23.195] [bbotk] Result of batch 53: 
INFO  [12:01:23.197] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:01:23.197] [bbotk]                   4              4912      0.0858485        0.671 -0.9059198 
INFO  [12:01:23.197] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:01:23.197] [bbotk]          <NA>   0.9749739 cc713caf-c94d-4774-bf25-27acfec51618 
DEBUG [12:01:24.172] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.281977e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004126315 0.4281977 
  - best initial criterion value(s) :  154.5586 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -154.56  |proj g|=       12.479
At iterate     1  f =      -178.66  |proj g|=        3.0741
At iterate     2  f =       -192.2  |proj g|=         2.643
At iterate     3  f =      -202.11  |proj g|=        1.9688
At iterate     4  f =      -209.08  |proj g|=        1.4759
At iterate     5  f =      -210.78  |proj g|=        1.2698
At iterate     6  f =      -211.12  |proj g|=         1.176
At iterate     7  f =       -214.3  |proj g|=        1.9285
At iterate     8  f =      -225.93  |proj g|=        7.8288
At iterate     9  f =       -245.3  |proj g|=        9.6459
At iterate    10  f =      -255.33  |proj g|=        1.2208
At iterate    11  f =      -256.04  |proj g|=       0.81586
At iterate    12  f =      -256.05  |proj g|=       0.18542
At iterate    13  f =      -256.05  |proj g|=       0.42309
At iterate    14  f =      -256.05  |proj g|=      0.012579
At iterate    15  f =      -256.05  |proj g|=     0.0056948
At iterate    16  f =      -256.05  |proj g|=       0.16539

iterations 16
function evaluations 28
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.165394
final function value -256.05

F = -256.05
final  value -256.050407 
converged
 
INFO  [12:01:24.176] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:01:24.239] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:01:24.246] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:01:30.721] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:01:37.874] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:01:44.802] [mlr3]  Finished benchmark 
INFO  [12:01:44.878] [bbotk] Result of batch 54: 
INFO  [12:01:44.881] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:01:44.881] [bbotk]                   4               470      0.0095166        0.688 -0.9059781 
INFO  [12:01:44.881] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:01:44.881] [bbotk]          <NA>   0.9520588 b7621852-e6bd-4bc5-84f1-ee199ae957d4 
DEBUG [12:01:45.790] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.237608e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004079887 0.4237608 
  - best initial criterion value(s) :  194.1629 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -194.16  |proj g|=       3.5274
At iterate     1  f =      -208.98  |proj g|=        8.4207
At iterate     2  f =      -229.13  |proj g|=        13.443
At iterate     3  f =      -235.34  |proj g|=        3.5708
At iterate     4  f =      -235.37  |proj g|=        2.8642
At iterate     5  f =      -235.49  |proj g|=       0.41795
At iterate     6  f =      -235.49  |proj g|=     0.0094086
At iterate     7  f =      -235.49  |proj g|=     0.0094088
At iterate     8  f =      -235.49  |proj g|=     0.0094088

iterations 8
function evaluations 18
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00940878
final function value -235.491

F = -235.491
final  value -235.490607 
converged
 
INFO  [12:01:45.792] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:01:45.841] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:01:45.849] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:02:31.289] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:03:16.212] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:04:03.123] [mlr3]  Finished benchmark 
INFO  [12:04:03.189] [bbotk] Result of batch 55: 
INFO  [12:04:03.191] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:04:03.191] [bbotk]                   6              3745     0.08104326        0.672 -0.9070866 
INFO  [12:04:03.191] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:04:03.191] [bbotk]          <NA>   0.9763656 4d108d8e-8cae-4fde-847d-9e93c89cd10a 
DEBUG [12:04:04.127] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.200753e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004059684 0.4200753 
  - best initial criterion value(s) :  196.3244 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -196.32  |proj g|=       4.1323
At iterate     1  f =      -198.59  |proj g|=        3.9225
At iterate     2  f =      -219.78  |proj g|=        3.2093
At iterate     3  f =      -225.86  |proj g|=        2.9174
At iterate     4  f =      -256.03  |proj g|=        1.7843
At iterate     5  f =      -256.54  |proj g|=        1.7568
At iterate     6  f =      -260.16  |proj g|=        1.4892
At iterate     7  f =      -261.54  |proj g|=        1.3128
At iterate     8  f =      -262.26  |proj g|=        2.7663
At iterate     9  f =      -262.35  |proj g|=       0.17617
At iterate    10  f =      -262.35  |proj g|=        0.4146
At iterate    11  f =      -262.35  |proj g|=     0.0079513
At iterate    12  f =      -262.35  |proj g|=      0.005595
At iterate    13  f =      -262.35  |proj g|=       0.03728

iterations 13
function evaluations 24
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0372804
final function value -262.354

F = -262.354
final  value -262.354058 
converged
 
INFO  [12:04:04.131] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:04:04.186] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:04:04.193] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:04:13.280] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:04:22.449] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:04:31.786] [mlr3]  Finished benchmark 
INFO  [12:04:31.854] [bbotk] Result of batch 56: 
INFO  [12:04:31.856] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:04:31.856] [bbotk]                   3               695     0.04857913        0.657 -0.9029256 
INFO  [12:04:31.856] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:04:31.856] [bbotk]          <NA>   0.9647966 49d1d126-8dd8-4b0f-8e5f-72e30fcdd593 
DEBUG [12:04:32.813] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.161115e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004005298 0.4161115 
  - best initial criterion value(s) :  175.0201 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -175.02  |proj g|=      0.62397
At iterate     1  f =      -207.29  |proj g|=        1.2828
At iterate     2  f =      -232.31  |proj g|=          1.82
At iterate     3  f =         -237  |proj g|=        1.7678
At iterate     4  f =      -245.25  |proj g|=        1.6335
At iterate     5  f =      -245.75  |proj g|=        1.6348
At iterate     6  f =      -245.77  |proj g|=        1.6346
At iterate     7  f =      -245.77  |proj g|=        1.6343
At iterate     8  f =      -245.77  |proj g|=        1.6341
At iterate     9  f =      -245.78  |proj g|=        1.6331
At iterate    10  f =       -245.8  |proj g|=        1.6306
At iterate    11  f =      -245.85  |proj g|=        1.6235
At iterate    12  f =      -245.99  |proj g|=        1.6051
At iterate    13  f =      -246.35  |proj g|=        1.5573
At iterate    14  f =      -247.18  |proj g|=        1.4483
At iterate    15  f =      -248.75  |proj g|=        1.2544
At iterate    16  f =      -249.21  |proj g|=         3.231
At iterate    17  f =      -249.82  |proj g|=       0.85262
At iterate    18  f =      -249.87  |proj g|=       0.41071
At iterate    19  f =      -249.89  |proj g|=      0.028279
At iterate    20  f =      -249.89  |proj g|=     0.0083602
At iterate    21  f =      -249.89  |proj g|=      0.028536
At iterate    22  f =      -249.89  |proj g|=     0.0099597

iterations 22
function evaluations 27
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00995966
final function value -249.89

F = -249.89
final  value -249.890062 
converged
 
INFO  [12:04:32.817] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:04:32.893] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:04:32.903] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:05:18.199] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:06:04.778] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:06:50.247] [mlr3]  Finished benchmark 
INFO  [12:06:50.313] [bbotk] Result of batch 57: 
INFO  [12:06:50.314] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:06:50.314] [bbotk]                   3              3763     0.02614108        0.677 -0.9058947 
INFO  [12:06:50.314] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:06:50.314] [bbotk]          <NA>   0.9702528 16b78190-b5be-4a15-870c-0244acdca276 
DEBUG [12:06:51.272] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.123595e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003995202 0.4123595 
  - best initial criterion value(s) :  226.2459 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -226.25  |proj g|=       5.3549
At iterate     1  f =       -230.4  |proj g|=        2.6706
At iterate     2  f =      -245.79  |proj g|=        2.0978
At iterate     3  f =      -249.45  |proj g|=        1.8543
At iterate     4  f =      -254.74  |proj g|=        1.4163
At iterate     5  f =      -256.07  |proj g|=        1.3141
At iterate     6  f =      -256.79  |proj g|=        1.2179
At iterate     7  f =      -256.88  |proj g|=        1.1254
At iterate     8  f =      -264.66  |proj g|=        1.2247
At iterate     9  f =       -267.6  |proj g|=        1.2232
At iterate    10  f =      -267.86  |proj g|=       0.47594
At iterate    11  f =      -267.86  |proj g|=         0.407
At iterate    12  f =      -267.86  |proj g|=      0.040126
At iterate    13  f =      -267.86  |proj g|=     0.0060131
At iterate    14  f =      -267.86  |proj g|=     0.0060131

iterations 14
function evaluations 24
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00601312
final function value -267.861

F = -267.861
final  value -267.861033 
converged
 
INFO  [12:06:51.276] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:06:51.329] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:06:51.336] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:07:38.436] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:08:24.381] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:09:11.895] [mlr3]  Finished benchmark 
INFO  [12:09:11.969] [bbotk] Result of batch 58: 
INFO  [12:09:11.971] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:09:11.971] [bbotk]                   4              3817      0.3941577        0.674 -0.9050375 
INFO  [12:09:11.971] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:09:11.971] [bbotk]          <NA>    0.974921 f49e8c49-b07e-42e3-afff-b206bab0d99a 
DEBUG [12:09:12.929] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.087923e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003973152 0.4087922 
  - best initial criterion value(s) :  235.9578 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -235.96  |proj g|=       3.1386
At iterate     1  f =      -247.55  |proj g|=        2.2611
At iterate     2  f =      -267.94  |proj g|=        1.2712
At iterate     3  f =      -267.98  |proj g|=        1.2661
At iterate     4  f =      -268.46  |proj g|=       0.73625
At iterate     5  f =       -268.6  |proj g|=       0.30951
At iterate     6  f =       -268.6  |proj g|=      0.078124
At iterate     7  f =       -268.6  |proj g|=       0.02819
At iterate     8  f =       -268.6  |proj g|=      0.012176
At iterate     9  f =       -268.6  |proj g|=      0.006902

iterations 9
function evaluations 16
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00690199
final function value -268.603

F = -268.603
final  value -268.602974 
converged
 
INFO  [12:09:12.934] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:09:12.992] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:09:13.000] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:10:01.943] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:10:51.365] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:11:41.172] [mlr3]  Finished benchmark 
INFO  [12:11:41.238] [bbotk] Result of batch 59: 
INFO  [12:11:41.240] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [12:11:41.240] [bbotk]                   6              4032       0.121023        0.709 -0.905246 
INFO  [12:11:41.240] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:11:41.240] [bbotk]          <NA>   0.9760124 7d60737b-e080-4a26-8cfa-ce2bd5182586 
DEBUG [12:11:42.409] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.053048e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003959314 0.4053048 
  - best initial criterion value(s) :  194.8416 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -194.84  |proj g|=       3.9519
At iterate     1  f =      -198.74  |proj g|=        2.5215
At iterate     2  f =      -212.71  |proj g|=        1.9739
At iterate     3  f =      -216.62  |proj g|=        1.7061
At iterate     4  f =      -218.81  |proj g|=        1.4077
At iterate     5  f =      -220.62  |proj g|=        1.2533
At iterate     6  f =      -221.46  |proj g|=         1.193
At iterate     7  f =      -221.48  |proj g|=        1.1618
At iterate     8  f =       -221.5  |proj g|=        1.1729
At iterate     9  f =      -221.52  |proj g|=        1.1783
At iterate    10  f =       -221.7  |proj g|=        1.2043
At iterate    11  f =      -222.12  |proj g|=        1.2462
At iterate    12  f =      -223.12  |proj g|=        1.3153
At iterate    13  f =      -225.02  |proj g|=        1.4154
At iterate    14  f =      -227.23  |proj g|=         1.666
At iterate    15  f =      -228.02  |proj g|=        1.5839
At iterate    16  f =      -232.66  |proj g|=        4.5071
At iterate    17  f =      -232.93  |proj g|=        2.5351
At iterate    18  f =         -233  |proj g|=      0.098252
At iterate    19  f =         -233  |proj g|=       0.39944
At iterate    20  f =         -233  |proj g|=      0.016438
At iterate    21  f =         -233  |proj g|=      0.016438

iterations 21
function evaluations 33
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.016438
final function value -233.002

F = -233.002
final  value -233.002452 
converged
 
INFO  [12:11:42.413] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:11:42.469] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:11:42.475] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:12:15.681] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:12:49.575] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:13:22.968] [mlr3]  Finished benchmark 
INFO  [12:13:23.036] [bbotk] Result of batch 60: 
INFO  [12:13:23.037] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [12:13:23.037] [bbotk]                   3              2724      0.3819166        0.875 -0.910632 
INFO  [12:13:23.037] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:13:23.037] [bbotk]          <NA>   0.9741233 4675a5d5-8ed0-4a6d-baca-6b4518918681 
DEBUG [12:13:23.960] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.01815e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003916787 0.401815 
  - best initial criterion value(s) :  198.7893 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -198.79  |proj g|=       9.0514
At iterate     1  f =      -223.06  |proj g|=        5.8461
At iterate     2  f =      -232.35  |proj g|=        2.4456
At iterate     3  f =      -240.28  |proj g|=        1.9665
At iterate     4  f =      -243.84  |proj g|=        1.6927
At iterate     5  f =      -248.02  |proj g|=         1.215
At iterate     6  f =         -249  |proj g|=        1.1472
At iterate     7  f =      -251.51  |proj g|=        1.2171
At iterate     8  f =      -268.07  |proj g|=        1.3736
At iterate     9  f =      -279.45  |proj g|=        1.3539
At iterate    10  f =      -280.55  |proj g|=        1.1643
At iterate    11  f =      -280.67  |proj g|=       0.39662
At iterate    12  f =      -280.67  |proj g|=      0.028266
At iterate    13  f =      -280.67  |proj g|=     0.0067817
At iterate    14  f =      -280.67  |proj g|=     0.0067817

iterations 14
function evaluations 23
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00678169
final function value -280.674

F = -280.674
final  value -280.673693 
converged
 
INFO  [12:13:23.964] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:13:24.018] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:13:24.024] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:13:59.711] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:14:36.173] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:15:11.134] [mlr3]  Finished benchmark 
INFO  [12:15:11.200] [bbotk] Result of batch 61: 
INFO  [12:15:11.202] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:15:11.202] [bbotk]                   8              2907      0.2483936        0.652 -0.9041389 
INFO  [12:15:11.202] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:15:11.202] [bbotk]          <NA>   0.9739775 61e62e47-24c4-483f-b114-5554d1ce8375 
DEBUG [12:15:12.133] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.983712e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003880538 0.3983712 
  - best initial criterion value(s) :  222.1455 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -222.15  |proj g|=       3.1502
At iterate     1  f =      -229.99  |proj g|=        3.4962
At iterate     2  f =      -236.38  |proj g|=         2.838
At iterate     3  f =       -248.5  |proj g|=        1.8344
At iterate     4  f =      -249.78  |proj g|=        1.5921
At iterate     5  f =      -250.67  |proj g|=        1.4484
At iterate     6  f =      -250.73  |proj g|=        1.4023
At iterate     7  f =      -250.94  |proj g|=         1.422
At iterate     8  f =      -251.64  |proj g|=        1.4608
At iterate     9  f =      -254.19  |proj g|=        1.5435
At iterate    10  f =      -259.67  |proj g|=        1.6526
At iterate    11  f =      -272.61  |proj g|=        1.6341
At iterate    12  f =      -279.11  |proj g|=        1.6362
At iterate    13  f =      -280.92  |proj g|=        1.5197
At iterate    14  f =      -283.74  |proj g|=        1.6658
At iterate    15  f =      -283.78  |proj g|=       0.20654
At iterate    16  f =      -283.78  |proj g|=       0.39319
At iterate    17  f =      -283.78  |proj g|=     0.0072067
At iterate    18  f =      -283.78  |proj g|=     0.0072067

iterations 18
function evaluations 26
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0072067
final function value -283.779

F = -283.779
final  value -283.779323 
converged
 
INFO  [12:15:12.137] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:15:12.191] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:15:12.198] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:15:13.270] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:15:14.147] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:15:15.005] [mlr3]  Finished benchmark 
INFO  [12:15:15.122] [bbotk] Result of batch 62: 
INFO  [12:15:15.125] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:15:15.125] [bbotk]                   9               846      0.2150384        0.655 -0.9040823 
INFO  [12:15:15.125] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:15:15.125] [bbotk]          <NA>         0.5 8fd250f1-57bd-4148-86c9-7838104a2447 
DEBUG [12:15:15.898] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.094679e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.00404811 0.4094679 
  - best initial criterion value(s) :  251.1004 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -251.1  |proj g|=       7.6571
At iterate     1  f =      -255.94  |proj g|=        2.5001
At iterate     2  f =      -273.29  |proj g|=        1.9747
At iterate     3  f =      -275.11  |proj g|=        1.8503
At iterate     4  f =      -282.69  |proj g|=        1.1885
At iterate     5  f =      -282.88  |proj g|=         1.158
At iterate     6  f =       -282.9  |proj g|=        1.1369
At iterate     7  f =      -283.14  |proj g|=        0.5219
At iterate     8  f =       -285.7  |proj g|=        6.5521
At iterate     9  f =      -289.91  |proj g|=         12.64
At iterate    10  f =      -294.83  |proj g|=        5.9935
At iterate    11  f =       -295.7  |proj g|=        2.4048
At iterate    12  f =      -296.02  |proj g|=       0.38692
At iterate    13  f =      -296.07  |proj g|=       0.43157
At iterate    14  f =      -296.07  |proj g|=      0.041356
At iterate    15  f =      -296.07  |proj g|=      0.031277
At iterate    16  f =      -296.07  |proj g|=       0.40439
At iterate    17  f =      -296.07  |proj g|=       0.20217

iterations 17
function evaluations 27
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.202173
final function value -296.075

F = -296.075
final  value -296.074731 
converged
 
INFO  [12:15:15.903] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:15:15.965] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:15:15.973] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:16:00.558] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:16:45.049] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:17:28.778] [mlr3]  Finished benchmark 
INFO  [12:17:28.843] [bbotk] Result of batch 63: 
INFO  [12:17:28.845] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:17:28.845] [bbotk]                   6              3664      0.4198066        0.536 -0.9027681 
INFO  [12:17:28.845] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:17:28.845] [bbotk]          <NA>   0.9751561 2ff2e208-3f95-45a5-b4bc-15d8733e21cc 
DEBUG [12:17:29.598] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.061236e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004035383 0.4061236 
  - best initial criterion value(s) :  236.8749 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -236.87  |proj g|=       8.4141
At iterate     1  f =      -262.15  |proj g|=        2.3909
At iterate     2  f =      -287.03  |proj g|=        1.4552
At iterate     3  f =      -289.14  |proj g|=        0.2247
At iterate     4  f =      -289.19  |proj g|=       0.52475
At iterate     5  f =      -289.19  |proj g|=       0.40104
At iterate     6  f =      -289.21  |proj g|=       0.22295
At iterate     7  f =      -289.21  |proj g|=       0.40101
At iterate     8  f =      -289.21  |proj g|=       0.40101
At iterate     9  f =      -289.21  |proj g|=     0.0087234
At iterate    10  f =      -289.21  |proj g|=     0.0081185

iterations 10
function evaluations 19
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00811848
final function value -289.215

F = -289.215
final  value -289.214844 
converged
 
INFO  [12:17:29.602] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:17:29.656] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:17:29.662] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:18:08.112] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:18:46.327] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:19:25.308] [mlr3]  Finished benchmark 
INFO  [12:19:25.373] [bbotk] Result of batch 64: 
INFO  [12:19:25.375] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:19:25.375] [bbotk]                   3              3202      0.2286166        0.534 -0.9038988 
INFO  [12:19:25.375] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:19:25.375] [bbotk]          <NA>   0.9737352 b69fb801-e283-4666-b7df-b0ddbb265123 
DEBUG [12:19:26.124] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.027875e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004008676 0.4027874 
  - best initial criterion value(s) :  257.5931 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -257.59  |proj g|=       3.4267
At iterate     1  f =      -273.86  |proj g|=        2.2731
At iterate     2  f =      -298.05  |proj g|=        1.2953
At iterate     3  f =      -298.83  |proj g|=       0.50739
At iterate     4  f =      -298.84  |proj g|=       0.22053
At iterate     5  f =      -298.85  |proj g|=       0.81223
At iterate     6  f =      -299.32  |proj g|=        1.1411
At iterate     7  f =      -299.36  |proj g|=       0.92165
At iterate     8  f =      -299.37  |proj g|=       0.39778
At iterate     9  f =      -299.37  |proj g|=       0.26212
At iterate    10  f =      -299.37  |proj g|=     0.0074421

iterations 10
function evaluations 20
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00744212
final function value -299.372

F = -299.372
final  value -299.371807 
converged
 
INFO  [12:19:26.128] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:19:26.183] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:19:26.190] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:20:10.960] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:20:54.654] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:21:38.114] [mlr3]  Finished benchmark 
INFO  [12:21:38.180] [bbotk] Result of batch 65: 
INFO  [12:21:38.182] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:21:38.182] [bbotk]                   3              3629       0.298283        0.528 -0.9028312 
INFO  [12:21:38.182] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:21:38.182] [bbotk]          <NA>   0.9741512 84ee76f9-aa27-4bac-8a32-60d51b2e629b 
DEBUG [12:21:38.954] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.995072e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003995072 0.4015807 
  - best initial criterion value(s) :  206.0575 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -206.06  |proj g|=       4.3181
At iterate     1  f =      -207.12  |proj g|=        4.1739
At iterate     2  f =      -224.46  |proj g|=        3.3893
ys=-3.359e+00  -gs= 1.530e+01, BFGS update SKIPPED
At iterate     3  f =      -228.39  |proj g|=        3.1462
At iterate     4  f =      -256.76  |proj g|=        1.8543
At iterate     5  f =      -260.03  |proj g|=        1.6511
At iterate     6  f =      -264.45  |proj g|=        1.2767
At iterate     7  f =      -265.76  |proj g|=       0.86978
At iterate     8  f =      -265.77  |proj g|=       0.39635
At iterate     9  f =      -265.78  |proj g|=      0.019913
At iterate    10  f =      -265.78  |proj g|=      0.015768
At iterate    11  f =      -265.78  |proj g|=      0.015769

iterations 11
function evaluations 22
segments explored during Cauchy searches 14
BFGS updates skipped 1
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0157686
final function value -265.781

F = -265.781
final  value -265.781350 
converged
 
INFO  [12:21:38.958] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:21:39.021] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:21:39.027] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:21:39.756] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:21:40.503] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:21:41.430] [mlr3]  Finished benchmark 
INFO  [12:21:41.496] [bbotk] Result of batch 66: 
INFO  [12:21:41.498] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:21:41.498] [bbotk]                   9              4832       0.243752        0.538 -0.9075014 
INFO  [12:21:41.498] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:21:41.498] [bbotk]          <NA>         0.5 95fb5734-e688-40ef-a38a-ad0ab9ccbe09 
DEBUG [12:21:42.272] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.100528e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004100528 0.4121039 
  - best initial criterion value(s) :  238.9087 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -238.91  |proj g|=       3.0805
At iterate     1  f =      -250.59  |proj g|=        1.7677
At iterate     2  f =      -277.68  |proj g|=         1.083
At iterate     3  f =      -277.98  |proj g|=       0.40696
At iterate     4  f =      -278.01  |proj g|=         1.832
At iterate     5  f =      -278.08  |proj g|=        1.9642
At iterate     6  f =      -278.62  |proj g|=        2.3869
At iterate     7  f =      -278.73  |proj g|=       0.78537
At iterate     8  f =      -278.78  |proj g|=       0.40697
At iterate     9  f =      -278.79  |proj g|=       0.40692
At iterate    10  f =      -278.79  |proj g|=       0.40691
At iterate    11  f =      -278.79  |proj g|=      0.043214

iterations 11
function evaluations 18
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0432139
final function value -278.786

F = -278.786
final  value -278.786101 
converged
 
INFO  [12:21:42.276] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:21:42.347] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:21:42.353] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:22:06.848] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:22:31.267] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:22:55.893] [mlr3]  Finished benchmark 
INFO  [12:22:55.971] [bbotk] Result of batch 67: 
INFO  [12:22:55.973] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:22:55.973] [bbotk]                   6              1978      0.3627329        0.554 -0.9057849 
INFO  [12:22:55.973] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:22:55.973] [bbotk]          <NA>   0.9757811 6abbc200-2e03-450e-9660-ab340ccf66ed 
DEBUG [12:22:56.792] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.068764e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004068764 0.4092656 
  - best initial criterion value(s) :  244.63 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -244.63  |proj g|=       12.612
At iterate     1  f =      -256.19  |proj g|=        2.3844
At iterate     2  f =      -272.88  |proj g|=        2.0008
At iterate     3  f =       -275.3  |proj g|=        1.8394
At iterate     4  f =       -282.3  |proj g|=        1.3115
At iterate     5  f =      -282.78  |proj g|=        1.2292
At iterate     6  f =      -282.91  |proj g|=        1.1538
At iterate     7  f =      -283.47  |proj g|=        1.1638
At iterate     8  f =       -291.7  |proj g|=       0.32316
At iterate     9  f =      -305.96  |proj g|=        1.6206
At iterate    10  f =      -311.64  |proj g|=        0.3069
At iterate    11  f =       -314.3  |proj g|=       0.66933
At iterate    12  f =      -314.93  |proj g|=        1.1741
At iterate    13  f =      -314.98  |proj g|=        1.1519
At iterate    14  f =      -315.03  |proj g|=       0.40446
At iterate    15  f =      -315.03  |proj g|=     0.0074799
At iterate    16  f =      -315.03  |proj g|=     0.0074805
At iterate    17  f =      -315.03  |proj g|=     0.0074805

iterations 17
function evaluations 29
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00748051
final function value -315.029

F = -315.029
final  value -315.029048 
converged
 
INFO  [12:22:56.796] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:22:56.851] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:22:56.858] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:22:57.603] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:22:58.531] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:22:59.283] [mlr3]  Finished benchmark 
INFO  [12:22:59.349] [bbotk] Result of batch 68: 
INFO  [12:22:59.350] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:22:59.350] [bbotk]                   9              1854      0.3185345         0.56 -0.9014326 
INFO  [12:22:59.350] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:22:59.350] [bbotk]          <NA>         0.5 19a7f63e-88f8-4d22-979a-3c957d998eeb 
DEBUG [12:23:00.138] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.168804e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004168804 0.4194686 
  - best initial criterion value(s) :  218.8683 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -218.87  |proj g|=       4.9278
At iterate     1  f =      -225.89  |proj g|=        5.5337
At iterate     2  f =      -248.45  |proj g|=        4.2026
At iterate     3  f =      -253.02  |proj g|=        4.0207
At iterate     4  f =       -277.4  |proj g|=         2.815
At iterate     5  f =      -286.91  |proj g|=        2.7029
At iterate     6  f =      -290.35  |proj g|=        2.7116
At iterate     7  f =      -291.14  |proj g|=         2.674
At iterate     8  f =      -294.52  |proj g|=        2.4899
At iterate     9  f =      -316.24  |proj g|=        10.098
At iterate    10  f =      -316.87  |proj g|=        5.3276
At iterate    11  f =      -317.29  |proj g|=        1.1922
At iterate    12  f =       -317.5  |proj g|=       0.18799
At iterate    13  f =      -317.51  |proj g|=     0.0096349
At iterate    14  f =      -317.51  |proj g|=       0.41467
At iterate    15  f =      -317.51  |proj g|=     0.0081164

iterations 15
function evaluations 21
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00811643
final function value -317.509

F = -317.509
final  value -317.508812 
converged
 
INFO  [12:23:00.142] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:23:00.197] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:23:00.204] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:23:23.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:23:45.965] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:24:08.621] [mlr3]  Finished benchmark 
INFO  [12:24:08.694] [bbotk] Result of batch 69: 
INFO  [12:24:08.696] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:24:08.696] [bbotk]                   6              1826      0.3703782        0.558 -0.9014486 
INFO  [12:24:08.696] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:24:08.696] [bbotk]          <NA>   0.9757847 02b9bc9c-9a5e-4e26-9dc9-38a5d7220bbd 
DEBUG [12:24:09.511] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.137674e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004137674 0.4161938 
  - best initial criterion value(s) :  161.3202 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -161.32  |proj g|=       4.4887
At iterate     1  f =      -161.54  |proj g|=        1.4858
At iterate     2  f =      -189.94  |proj g|=        3.4751
At iterate     3  f =       -193.2  |proj g|=        3.3085
At iterate     4  f =      -216.88  |proj g|=        2.5065
At iterate     5  f =      -239.04  |proj g|=        1.6931
At iterate     6  f =      -242.35  |proj g|=        1.6865
At iterate     7  f =      -242.42  |proj g|=        1.6832
At iterate     8  f =      -242.53  |proj g|=          1.68
At iterate     9  f =       -242.8  |proj g|=        1.6628
At iterate    10  f =       -243.2  |proj g|=        1.6322
At iterate    11  f =      -244.71  |proj g|=        1.4816
At iterate    12  f =      -246.91  |proj g|=        1.3203
At iterate    13  f =      -249.02  |proj g|=       0.47047
At iterate    14  f =      -249.04  |proj g|=        0.3172
At iterate    15  f =      -249.04  |proj g|=       0.41044
At iterate    16  f =      -249.04  |proj g|=      0.028674
At iterate    17  f =      -249.04  |proj g|=      0.028674

iterations 17
function evaluations 27
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0286743
final function value -249.036

F = -249.036
final  value -249.036244 
converged
 
INFO  [12:24:09.515] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:24:09.568] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:24:09.575] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:24:34.030] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:24:58.359] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:25:22.601] [mlr3]  Finished benchmark 
INFO  [12:25:22.677] [bbotk] Result of batch 70: 
INFO  [12:25:22.679] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:25:22.679] [bbotk]                   3              1981     0.04066412         0.56 -0.9114175 
INFO  [12:25:22.679] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:25:22.679] [bbotk]          <NA>    0.969378 52b641d2-a13f-4ea5-99b3-55209a3d187f 
DEBUG [12:25:23.605] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.105369e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004105369 0.4139315 
  - best initial criterion value(s) :  239.7021 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -239.7  |proj g|=       4.0571
At iterate     1  f =      -248.23  |proj g|=        4.0383
At iterate     2  f =      -256.83  |proj g|=        3.1673
At iterate     3  f =      -279.18  |proj g|=        1.6736
At iterate     4  f =      -279.57  |proj g|=       0.89555
At iterate     5  f =      -280.49  |proj g|=        1.2074
At iterate     6  f =      -280.96  |proj g|=         1.402
At iterate     7  f =      -285.86  |proj g|=        1.2048
At iterate     8  f =      -297.42  |proj g|=        5.6362
At iterate     9  f =      -320.41  |proj g|=        4.4308
At iterate    10  f =      -320.61  |proj g|=        4.0276
At iterate    11  f =      -320.78  |proj g|=       0.92271
At iterate    12  f =      -320.79  |proj g|=       0.40919
At iterate    13  f =      -320.79  |proj g|=       0.40918
At iterate    14  f =      -320.79  |proj g|=     0.0097063

iterations 14
function evaluations 23
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00970628
final function value -320.787

F = -320.787
final  value -320.786657 
converged
 
INFO  [12:25:23.609] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:25:23.680] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:25:23.687] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:25:39.204] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:25:55.653] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:26:11.097] [mlr3]  Finished benchmark 
INFO  [12:26:11.170] [bbotk] Result of batch 71: 
INFO  [12:26:11.172] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:26:11.172] [bbotk]                   5              1221      0.3691518        0.677 -0.9013714 
INFO  [12:26:11.172] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:26:11.172] [bbotk]          <NA>   0.9758465 ab0e7160-f057-4213-881b-e923fb10602c 
DEBUG [12:26:12.207] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.075015e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004075015 0.4083777 
  - best initial criterion value(s) :  228.0143 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -228.01  |proj g|=       12.783
At iterate     1  f =      -257.46  |proj g|=        3.1392
At iterate     2  f =      -277.47  |proj g|=        2.7156
At iterate     3  f =       -285.7  |proj g|=        2.2519
At iterate     4  f =      -302.45  |proj g|=        13.255
At iterate     5  f =      -303.34  |proj g|=        13.192
At iterate     6  f =      -306.51  |proj g|=        1.7088
At iterate     7  f =      -306.85  |proj g|=        1.1338
At iterate     8  f =      -307.23  |proj g|=        1.1879
At iterate     9  f =      -308.09  |proj g|=        1.2803
At iterate    10  f =       -309.7  |proj g|=        1.4023
At iterate    11  f =      -311.14  |proj g|=        1.7298
At iterate    12  f =      -316.95  |proj g|=        1.7798
At iterate    13  f =      -323.07  |proj g|=        1.8089
At iterate    14  f =      -328.78  |proj g|=        1.7938
At iterate    15  f =      -334.21  |proj g|=        7.0487
At iterate    16  f =      -336.02  |proj g|=        7.6165
At iterate    17  f =       -337.3  |proj g|=        1.1479
At iterate    18  f =      -337.71  |proj g|=       0.71678
At iterate    19  f =      -337.87  |proj g|=        1.5292
At iterate    20  f =      -337.88  |proj g|=        1.0055
At iterate    21  f =      -337.89  |proj g|=      0.011734
At iterate    22  f =      -337.89  |proj g|=       0.40376
At iterate    23  f =      -337.89  |proj g|=     0.0078435

iterations 23
function evaluations 33
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0078435
final function value -337.889

F = -337.889
final  value -337.889464 
converged
 
INFO  [12:26:12.211] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:26:12.266] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:26:12.273] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:26:51.486] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:27:31.073] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:28:11.392] [mlr3]  Finished benchmark 
INFO  [12:28:11.458] [bbotk] Result of batch 72: 
INFO  [12:28:11.460] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:28:11.460] [bbotk]                   4              3268      0.1266454         0.71 -0.8996199 
INFO  [12:28:11.460] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:28:11.460] [bbotk]          <NA>   0.9749572 e456645f-9191-4d1f-9cbd-2ae21d014399 
DEBUG [12:28:12.345] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.044809e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004044809 0.4078132 
  - best initial criterion value(s) :  282.9961 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -283  |proj g|=       2.5769
At iterate     1  f =      -294.82  |proj g|=        4.5778
At iterate     2  f =      -314.56  |proj g|=        5.1001
At iterate     3  f =      -314.85  |proj g|=       0.74269
At iterate     4  f =      -314.86  |proj g|=        1.0789
At iterate     5  f =      -314.87  |proj g|=        0.8518
At iterate     6  f =      -314.88  |proj g|=       0.52699
At iterate     7  f =      -314.91  |proj g|=       0.40319
At iterate     8  f =      -314.99  |proj g|=        1.1056
At iterate     9  f =      -315.22  |proj g|=        1.1303
At iterate    10  f =      -315.62  |proj g|=        1.1533
At iterate    11  f =      -315.81  |proj g|=         1.154
At iterate    12  f =      -315.89  |proj g|=        1.1488
At iterate    13  f =      -315.91  |proj g|=        1.1425
At iterate    14  f =      -315.92  |proj g|=        1.1313
At iterate    15  f =      -315.93  |proj g|=       0.43273
At iterate    16  f =      -315.94  |proj g|=       0.10607
At iterate    17  f =      -315.95  |proj g|=       0.15029
At iterate    18  f =      -315.95  |proj g|=      0.029761
At iterate    19  f =      -315.95  |proj g|=      0.069381
At iterate    20  f =      -315.95  |proj g|=      0.012914

iterations 20
function evaluations 26
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0129135
final function value -315.948

F = -315.948
final  value -315.948330 
converged
 
INFO  [12:28:12.349] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:28:12.402] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:28:12.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:28:46.069] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:29:18.428] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:29:51.527] [mlr3]  Finished benchmark 
INFO  [12:29:51.594] [bbotk] Result of batch 73: 
INFO  [12:29:51.595] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:29:51.595] [bbotk]                   3              2681      0.1753138        0.611 -0.9026636 
INFO  [12:29:51.595] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:29:51.595] [bbotk]          <NA>   0.9733603 c099306c-97b8-412c-bfb9-9f6a378b19ca 
DEBUG [12:29:52.462] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.014603e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004014603 0.4031626 
  - best initial criterion value(s) :  234.8886 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -234.89  |proj g|=        4.688
At iterate     1  f =      -303.43  |proj g|=        2.9444
At iterate     2  f =      -328.83  |proj g|=        2.2191
At iterate     3  f =      -338.54  |proj g|=        1.6087
At iterate     4  f =      -349.28  |proj g|=       0.97895
At iterate     5  f =      -349.49  |proj g|=        1.8074
At iterate     6  f =      -349.95  |proj g|=       0.39883
At iterate     7  f =       -352.4  |proj g|=        1.1459
At iterate     8  f =       -353.2  |proj g|=        1.1519
At iterate     9  f =      -353.39  |proj g|=       0.39871
At iterate    10  f =      -353.39  |proj g|=       0.39866
At iterate    11  f =      -353.39  |proj g|=       0.39865
At iterate    12  f =      -353.39  |proj g|=      0.010855
At iterate    13  f =      -353.39  |proj g|=     0.0070738
At iterate    14  f =      -353.39  |proj g|=      0.065667

iterations 14
function evaluations 23
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0656672
final function value -353.392

F = -353.392
final  value -353.392206 
converged
 
INFO  [12:29:52.466] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:29:52.520] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:29:52.527] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:30:37.174] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:31:21.511] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:32:07.400] [mlr3]  Finished benchmark 
INFO  [12:32:07.466] [bbotk] Result of batch 74: 
INFO  [12:32:07.468] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:32:07.468] [bbotk]                   5              3764      0.3487044         0.62 -0.8989445 
INFO  [12:32:07.468] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:32:07.468] [bbotk]          <NA>   0.9754515 922271fa-d678-463d-9143-46b48957aed8 
DEBUG [12:32:08.400] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.985243e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003985243 0.4016496 
  - best initial criterion value(s) :  268.1683 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -268.17  |proj g|=       4.8654
At iterate     1  f =      -273.32  |proj g|=        4.5427
At iterate     2  f =      -280.29  |proj g|=        4.2168
ys=-7.112e-01  -gs= 6.627e+00, BFGS update SKIPPED
At iterate     3  f =      -294.23  |proj g|=        3.5236
At iterate     4  f =      -300.53  |proj g|=        3.1506
At iterate     5  f =      -330.04  |proj g|=        1.6524
At iterate     6  f =      -340.35  |proj g|=        2.3737
At iterate     7  f =       -341.5  |proj g|=        5.2179
At iterate     8  f =      -342.42  |proj g|=        2.5681
At iterate     9  f =       -342.5  |proj g|=       0.98326
At iterate    10  f =      -342.52  |proj g|=       0.01319
At iterate    11  f =      -342.52  |proj g|=        0.3971
At iterate    12  f =      -342.52  |proj g|=        0.3971
At iterate    13  f =      -342.52  |proj g|=      0.072972

iterations 13
function evaluations 24
segments explored during Cauchy searches 17
BFGS updates skipped 1
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0729722
final function value -342.516

F = -342.516
final  value -342.516187 
converged
 
INFO  [12:32:08.404] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:32:08.456] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:32:08.463] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:32:45.029] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:33:20.484] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:33:56.967] [mlr3]  Finished benchmark 
INFO  [12:33:57.033] [bbotk] Result of batch 75: 
INFO  [12:33:57.035] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:33:57.035] [bbotk]                   8              2947     0.04946102        0.654 -0.9002552 
INFO  [12:33:57.035] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:33:57.035] [bbotk]          <NA>   0.9743442 0ef1fc30-20b8-4178-83bf-bf5394e3e4e5 
DEBUG [12:33:58.004] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.955993e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003955993 0.4001706 
  - best initial criterion value(s) :  233.5025 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -233.5  |proj g|=       8.9103
At iterate     1  f =      -236.84  |proj g|=       0.93869
At iterate     2  f =      -256.14  |proj g|=        1.4456
At iterate     3  f =      -257.46  |proj g|=        1.2946
At iterate     4  f =      -259.02  |proj g|=        1.1123
At iterate     5  f =      -259.05  |proj g|=       0.39454
At iterate     6  f =      -259.44  |proj g|=       0.32244
At iterate     7  f =      -260.65  |proj g|=       0.66438
At iterate     8  f =      -260.76  |proj g|=       0.39975
At iterate     9  f =      -260.83  |proj g|=       0.39457
At iterate    10  f =      -260.83  |proj g|=      0.036348
At iterate    11  f =      -260.83  |proj g|=      0.036358
At iterate    12  f =      -260.83  |proj g|=      0.038009

iterations 12
function evaluations 21
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0380092
final function value -260.83

F = -260.83
final  value -260.830239 
converged
 
INFO  [12:33:58.008] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:33:58.063] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:33:58.070] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:34:34.099] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:35:10.114] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:35:46.335] [mlr3]  Finished benchmark 
INFO  [12:35:46.411] [bbotk] Result of batch 76: 
INFO  [12:35:46.413] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [12:35:46.413] [bbotk]                   4              2942      0.4286223         0.73 -0.911288 
INFO  [12:35:46.413] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:35:46.413] [bbotk]          <NA>    0.974971 a8ba02a1-3a03-4837-82d2-37e1618b68d2 
DEBUG [12:35:47.181] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.927238e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003927238 0.399067 
  - best initial criterion value(s) :  308.7496 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -308.75  |proj g|=       3.2787
At iterate     1  f =       -355.5  |proj g|=       0.39514
At iterate     2  f =      -356.68  |proj g|=      0.007209
At iterate     3  f =       -356.7  |proj g|=     0.0072145
At iterate     4  f =       -356.7  |proj g|=       0.39421
At iterate     5  f =       -356.7  |proj g|=     0.0072175
At iterate     6  f =       -356.7  |proj g|=     0.0072175

iterations 6
function evaluations 9
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00721749
final function value -356.7

F = -356.7
final  value -356.700009 
converged
 
INFO  [12:35:47.185] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:35:47.256] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:35:47.264] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:35:57.125] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:36:06.985] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:36:16.944] [mlr3]  Finished benchmark 
INFO  [12:36:17.011] [bbotk] Result of batch 77: 
INFO  [12:36:17.012] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:36:17.012] [bbotk]                   7               752      0.1084072         0.56 -0.9184068 
INFO  [12:36:17.012] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:36:17.012] [bbotk]          <NA>   0.9747565 073c30e4-042f-4e47-88fb-cb54b20bed00 
DEBUG [12:36:17.995] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.898788e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003898788 0.3932758 
  - best initial criterion value(s) :  274.8051 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -274.81  |proj g|=       4.6029
At iterate     1  f =      -283.35  |proj g|=        4.2402
At iterate     2  f =      -301.51  |proj g|=        3.7271
At iterate     3  f =      -305.51  |proj g|=        3.5388
At iterate     4  f =      -314.92  |proj g|=        3.1396
At iterate     5  f =      -343.51  |proj g|=        2.2419
At iterate     6  f =      -346.36  |proj g|=        2.1792
At iterate     7  f =      -353.37  |proj g|=        1.8537
At iterate     8  f =      -357.99  |proj g|=        1.4685
At iterate     9  f =      -363.86  |proj g|=       0.38916
At iterate    10  f =      -363.91  |proj g|=        1.1415
At iterate    11  f =      -363.96  |proj g|=       0.24257
At iterate    12  f =      -363.97  |proj g|=       0.38887
At iterate    13  f =      -363.97  |proj g|=       0.38887
At iterate    14  f =      -363.97  |proj g|=      0.035916

iterations 14
function evaluations 27
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0359163
final function value -363.966

F = -363.966
final  value -363.965741 
converged
 
INFO  [12:36:17.999] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:36:18.065] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:36:18.072] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:37:05.186] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:37:51.264] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:38:37.428] [mlr3]  Finished benchmark 
INFO  [12:38:37.514] [bbotk] Result of batch 78: 
INFO  [12:38:37.516] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:38:37.516] [bbotk]                   6              3840      0.1801541        0.728 -0.8991986 
INFO  [12:38:37.516] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:38:37.516] [bbotk]          <NA>   0.9757681 54a7ccae-9cc7-4e44-8edc-74cfb2e443ca 
DEBUG [12:38:38.355] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.870899e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003870899 0.392658 
  - best initial criterion value(s) :  278.0832 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -278.08  |proj g|=       4.1533
At iterate     1  f =      -279.91  |proj g|=        4.0014
At iterate     2  f =      -290.29  |proj g|=        3.6921
At iterate     3  f =      -294.84  |proj g|=        3.4924
At iterate     4  f =      -301.32  |proj g|=        3.1846
At iterate     5  f =      -318.31  |proj g|=        2.5225
At iterate     6  f =      -334.85  |proj g|=        2.1287
At iterate     7  f =       -335.3  |proj g|=        2.1205
At iterate     8  f =      -335.87  |proj g|=         2.086
At iterate     9  f =       -336.3  |proj g|=        2.0749
At iterate    10  f =      -341.24  |proj g|=        1.8484
At iterate    11  f =      -349.39  |proj g|=      0.036121
At iterate    12  f =      -351.18  |proj g|=        2.3863
At iterate    13  f =      -351.62  |proj g|=        1.2716
At iterate    14  f =      -351.66  |proj g|=       0.38825
At iterate    15  f =      -351.67  |proj g|=      0.015847
At iterate    16  f =      -351.67  |proj g|=      0.013065
At iterate    17  f =      -351.67  |proj g|=      0.013065

iterations 17
function evaluations 27
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0130655
final function value -351.67

F = -351.67
final  value -351.670017 
converged
 
INFO  [12:38:38.359] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:38:38.420] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:38:38.428] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:39:14.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:39:50.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:40:25.326] [mlr3]  Finished benchmark 
INFO  [12:40:25.391] [bbotk] Result of batch 79: 
INFO  [12:40:25.393] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:40:25.393] [bbotk]                   5              2929      0.4912175        0.563 -0.9007921 
INFO  [12:40:25.393] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:40:25.393] [bbotk]          <NA>   0.9754099 e24dcd68-7cea-40d1-922f-2dc15b01f24b 
DEBUG [12:40:26.171] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.843273e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003843273 0.3903015 
  - best initial criterion value(s) :  259.7406 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -259.74  |proj g|=       2.3817
At iterate     1  f =      -333.22  |proj g|=       0.38646
At iterate     2  f =      -335.09  |proj g|=      0.014324
At iterate     3  f =       -335.1  |proj g|=      0.014331
At iterate     4  f =       -335.1  |proj g|=       0.38532
At iterate     5  f =       -335.1  |proj g|=      0.014336

iterations 5
function evaluations 8
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0143365
final function value -335.096

F = -335.096
final  value -335.096033 
converged
 
INFO  [12:40:26.175] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:40:26.237] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:40:26.244] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:40:35.857] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:40:45.475] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:40:54.919] [mlr3]  Finished benchmark 
INFO  [12:40:54.984] [bbotk] Result of batch 80: 
INFO  [12:40:54.986] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:40:54.986] [bbotk]                   3               694      0.1375271        0.569 -0.9215203 
INFO  [12:40:54.986] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:40:54.986] [bbotk]          <NA>   0.9700722 449ae190-9aeb-4ce9-a627-b18c10d4b2c0 
DEBUG [12:40:55.843] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.814939e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003814939 0.38563 
  - best initial criterion value(s) :  307.9375 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -307.94  |proj g|=       3.4685
At iterate     1  f =      -314.47  |proj g|=        3.2473
At iterate     2  f =      -327.48  |proj g|=        2.8898
At iterate     3  f =      -328.79  |proj g|=        2.8015
At iterate     4  f =      -336.81  |proj g|=        2.3087
At iterate     5  f =      -351.05  |proj g|=        1.3864
At iterate     6  f =      -352.92  |proj g|=        1.2353
At iterate     7  f =      -353.41  |proj g|=        1.2257
At iterate     8  f =      -353.49  |proj g|=        1.2392
At iterate     9  f =      -353.51  |proj g|=        1.2397
At iterate    10  f =      -353.52  |proj g|=         1.234
At iterate    11  f =      -353.57  |proj g|=        1.2151
At iterate    12  f =      -353.71  |proj g|=        1.1767
At iterate    13  f =      -354.11  |proj g|=       0.73934
At iterate    14  f =      -355.49  |proj g|=        5.7369
At iterate    15  f =         -358  |proj g|=        11.581
At iterate    16  f =      -363.12  |proj g|=        13.302
At iterate    17  f =      -369.57  |proj g|=        13.438
At iterate    18  f =      -369.97  |proj g|=        13.437
At iterate    19  f =      -374.62  |proj g|=        13.246
At iterate    20  f =      -377.08  |proj g|=        7.9713
At iterate    21  f =      -377.82  |proj g|=        0.6875
At iterate    22  f =      -377.86  |proj g|=       0.38138
At iterate    23  f =      -377.87  |proj g|=       0.38135
At iterate    24  f =      -377.87  |proj g|=      0.010013
At iterate    25  f =      -377.87  |proj g|=      0.091103

iterations 25
function evaluations 35
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0911035
final function value -377.865

F = -377.865
final  value -377.865063 
converged
 
INFO  [12:40:55.847] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:40:55.903] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:40:55.910] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:41:39.831] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:42:23.722] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:43:06.714] [mlr3]  Finished benchmark 
INFO  [12:43:06.792] [bbotk] Result of batch 81: 
INFO  [12:43:06.794] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:43:06.794] [bbotk]                   7              3609      0.4543374        0.577 -0.8983886 
INFO  [12:43:06.794] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:43:06.794] [bbotk]          <NA>    0.974408 a5c09faf-e1d0-4097-82a4-08d13d6e671b 
DEBUG [12:43:07.617] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.787804e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003787804 0.3848742 
  - best initial criterion value(s) :  254.5398 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -254.54  |proj g|=       3.3537
At iterate     1  f =      -348.68  |proj g|=       0.38109
At iterate     2  f =      -350.29  |proj g|=      0.013073
At iterate     3  f =      -350.37  |proj g|=      0.013115
At iterate     4  f =      -350.39  |proj g|=       0.38005
At iterate     5  f =      -350.39  |proj g|=      0.013145
At iterate     6  f =      -350.39  |proj g|=      0.013145
At iterate     7  f =      -350.39  |proj g|=      0.013145

iterations 7
function evaluations 10
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0131449
final function value -350.387

F = -350.387
final  value -350.387042 
converged
 
INFO  [12:43:07.621] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:43:07.674] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:43:07.681] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:43:51.500] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:44:36.452] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:45:21.612] [mlr3]  Finished benchmark 
INFO  [12:45:21.688] [bbotk] Result of batch 82: 
INFO  [12:45:21.690] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:45:21.690] [bbotk]                   8              3639      0.4313805        0.607 -0.9204528 
INFO  [12:45:21.690] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:45:21.690] [bbotk]          <NA>   0.9725972 0285b146-a3cb-4c9a-8975-4739d89d300f 
DEBUG [12:45:22.544] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.760662e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003760662 0.3836944 
  - best initial criterion value(s) :  269.7172 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -269.72  |proj g|=       3.3991
At iterate     1  f =      -310.71  |proj g|=        9.2977
At iterate     2  f =      -353.89  |proj g|=        1.4812
At iterate     3  f =      -358.29  |proj g|=        1.2612
At iterate     4  f =      -363.44  |proj g|=        7.9454
At iterate     5  f =      -363.45  |proj g|=        8.8401
At iterate     6  f =       -363.5  |proj g|=        10.697
At iterate     7  f =      -363.51  |proj g|=        10.555
At iterate     8  f =      -363.54  |proj g|=        9.8172
At iterate     9  f =      -363.59  |proj g|=        9.0337
At iterate    10  f =      -363.76  |proj g|=        7.3376
At iterate    11  f =      -364.08  |proj g|=         5.776
At iterate    12  f =       -365.1  |proj g|=        3.1057
At iterate    13  f =      -371.74  |proj g|=         0.494
At iterate    14  f =      -372.07  |proj g|=        1.1264
At iterate    15  f =      -372.17  |proj g|=       0.40253
At iterate    16  f =      -372.18  |proj g|=        0.3794
At iterate    17  f =      -372.18  |proj g|=       0.37939
At iterate    18  f =      -372.18  |proj g|=       0.37939
At iterate    19  f =      -372.18  |proj g|=      0.012634

iterations 19
function evaluations 29
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0126341
final function value -372.175

F = -372.175
final  value -372.175196 
converged
 
INFO  [12:45:22.548] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:45:22.603] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:45:22.610] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:45:31.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:45:41.090] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:45:50.257] [mlr3]  Finished benchmark 
INFO  [12:45:50.323] [bbotk] Result of batch 83: 
INFO  [12:45:50.325] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:45:50.325] [bbotk]                   4               676      0.4384643        0.588 -0.9005526 
INFO  [12:45:50.325] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:45:50.325] [bbotk]          <NA>   0.9745711 2826accd-cab7-4080-a61f-e93b4df1a1a2 
DEBUG [12:45:51.201] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.73423e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.00373423 0.3785386 
  - best initial criterion value(s) :  291.4732 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -291.47  |proj g|=       5.3123
At iterate     1  f =       -302.3  |proj g|=        4.7072
At iterate     2  f =       -312.4  |proj g|=        1.0263
At iterate     3  f =      -326.13  |proj g|=        4.2083
At iterate     4  f =      -330.78  |proj g|=        4.0074
At iterate     5  f =      -336.82  |proj g|=        3.6654
At iterate     6  f =       -345.8  |proj g|=        3.2026
At iterate     7  f =      -363.99  |proj g|=        2.4365
At iterate     8  f =      -389.23  |proj g|=        13.234
At iterate     9  f =      -389.88  |proj g|=        13.182
At iterate    10  f =      -391.52  |proj g|=        1.1613
At iterate    11  f =      -392.25  |proj g|=         1.912
At iterate    12  f =      -392.29  |proj g|=       0.28063
At iterate    13  f =      -392.29  |proj g|=      0.018143
At iterate    14  f =      -392.29  |proj g|=     0.0098945
At iterate    15  f =      -392.29  |proj g|=        0.3198

iterations 15
function evaluations 29
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.319799
final function value -392.288

F = -392.288
final  value -392.287595 
converged
 
INFO  [12:45:51.205] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:45:51.269] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:45:51.276] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:46:03.491] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:46:16.255] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:46:28.230] [mlr3]  Finished benchmark 
INFO  [12:46:28.296] [bbotk] Result of batch 84: 
INFO  [12:46:28.298] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:46:28.298] [bbotk]                   8               929      0.1974253        0.591 -0.8981295 
INFO  [12:46:28.298] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:46:28.298] [bbotk]          <NA>   0.9745064 b9f3abf9-1136-491f-8661-7bda7d750c08 
DEBUG [12:46:29.164] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.708112e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003708112 0.3742384 
  - best initial criterion value(s) :  317.9348 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -317.93  |proj g|=       4.5607
At iterate     1  f =      -325.85  |proj g|=        4.2237
At iterate     2  f =       -345.3  |proj g|=        3.7033
At iterate     3  f =      -349.68  |proj g|=        3.5063
At iterate     4  f =      -361.62  |proj g|=        3.0491
At iterate     5  f =      -389.11  |proj g|=        2.3012
At iterate     6  f =      -389.84  |proj g|=         2.279
At iterate     7  f =      -391.93  |proj g|=        2.1734
At iterate     8  f =      -401.63  |proj g|=        1.5658
At iterate     9  f =      -409.98  |proj g|=        9.3229
At iterate    10  f =      -410.64  |proj g|=        4.8602
At iterate    11  f =      -410.88  |proj g|=        1.1188
At iterate    12  f =       -410.9  |proj g|=      0.070971
At iterate    13  f =       -410.9  |proj g|=     0.0077729
At iterate    14  f =       -410.9  |proj g|=      0.007773
At iterate    15  f =       -410.9  |proj g|=      0.012835

iterations 15
function evaluations 25
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0128352
final function value -410.905

F = -410.905
final  value -410.904585 
converged
 
INFO  [12:46:29.168] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:46:29.232] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:46:29.238] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:47:13.290] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:47:56.530] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:48:39.730] [mlr3]  Finished benchmark 
INFO  [12:48:39.806] [bbotk] Result of batch 85: 
INFO  [12:48:39.808] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:48:39.808] [bbotk]                   7              3590      0.4027824        0.604 -0.8962906 
INFO  [12:48:39.808] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:48:39.808] [bbotk]          <NA>   0.9746229 2399996c-bdc5-401f-ae05-97b6150fce1a 
DEBUG [12:48:40.762] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.682336e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003682336 0.3730952 
  - best initial criterion value(s) :  289.425 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -289.42  |proj g|=       4.9734
At iterate     1  f =       -301.8  |proj g|=        7.5985
At iterate     2  f =      -324.06  |proj g|=        4.2998
At iterate     3  f =      -339.44  |proj g|=        3.9465
At iterate     4  f =      -350.04  |proj g|=        3.4735
At iterate     5  f =      -360.43  |proj g|=        3.2458
At iterate     6  f =      -405.92  |proj g|=        5.2762
At iterate     7  f =      -406.23  |proj g|=        4.8821
At iterate     8  f =      -406.42  |proj g|=       0.36898
At iterate     9  f =      -406.42  |proj g|=       0.36897
At iterate    10  f =      -406.42  |proj g|=       0.01058
At iterate    11  f =      -406.42  |proj g|=     0.0094033

iterations 11
function evaluations 22
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00940325
final function value -406.425

F = -406.425
final  value -406.424572 
converged
 
INFO  [12:48:40.764] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:48:40.814] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:48:40.822] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:48:41.635] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:48:42.446] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:48:43.288] [mlr3]  Finished benchmark 
INFO  [12:48:43.378] [bbotk] Result of batch 86: 
INFO  [12:48:43.380] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:48:43.380] [bbotk]                  10              3134      0.1911022        0.695 -0.8971133 
INFO  [12:48:43.380] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:48:43.380] [bbotk]          <NA>         0.5 db2edb49-42cf-43cc-911c-61fea6891770 
DEBUG [12:48:44.355] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.779052e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003779052 0.3788256 
  - best initial criterion value(s) :  297.2846 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -297.28  |proj g|=       12.283
At iterate     1  f =      -316.33  |proj g|=        3.0687
At iterate     2  f =      -339.09  |proj g|=        2.5963
At iterate     3  f =      -344.94  |proj g|=        2.2822
At iterate     4  f =      -367.73  |proj g|=        1.0798
At iterate     5  f =      -368.04  |proj g|=       0.59545
At iterate     6  f =      -368.24  |proj g|=        1.1429
At iterate     7  f =      -369.05  |proj g|=        1.1993
At iterate     8  f =      -373.41  |proj g|=        1.3947
At iterate     9  f =      -380.59  |proj g|=        1.5862
At iterate    10  f =      -393.22  |proj g|=        1.7573
At iterate    11  f =      -396.69  |proj g|=        1.6417
At iterate    12  f =      -400.52  |proj g|=        1.4318
At iterate    13  f =      -402.11  |proj g|=        1.2668
At iterate    14  f =      -403.62  |proj g|=        3.9238
At iterate    15  f =      -403.77  |proj g|=       0.42846
At iterate    16  f =      -403.78  |proj g|=       0.37475
At iterate    17  f =      -403.78  |proj g|=      0.034571
At iterate    18  f =      -403.78  |proj g|=      0.010781
At iterate    19  f =      -403.78  |proj g|=       0.33037

iterations 19
function evaluations 27
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.330368
final function value -403.779

F = -403.779
final  value -403.778824 
converged
 
INFO  [12:48:44.359] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:48:44.424] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:48:44.431] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:48:56.548] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:49:09.165] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:49:20.936] [mlr3]  Finished benchmark 
INFO  [12:49:21.001] [bbotk] Result of batch 87: 
INFO  [12:49:21.003] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:49:21.003] [bbotk]                   8               926      0.2141966        0.666 -0.8972525 
INFO  [12:49:21.003] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:49:21.003] [bbotk]          <NA>   0.9746287 043d98c7-9bf1-4f7e-a5e3-8aa3dda02004 
DEBUG [12:49:21.857] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.753562e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.00375003 0.3753562 
  - best initial criterion value(s) :  201.5297 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -201.53  |proj g|=       6.1095
At iterate     1  f =      -222.52  |proj g|=       0.37161
At iterate     2  f =      -411.36  |proj g|=       0.37161
At iterate     3  f =      -412.19  |proj g|=     0.0078203
At iterate     4  f =      -412.19  |proj g|=     0.0078222
At iterate     5  f =      -412.19  |proj g|=       0.37091
At iterate     6  f =      -412.19  |proj g|=      0.007823

iterations 6
function evaluations 17
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00782303
final function value -412.193

F = -412.193
final  value -412.193261 
converged
 
INFO  [12:49:21.861] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:49:21.918] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:49:21.924] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:49:22.650] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:49:23.372] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:49:24.107] [mlr3]  Finished benchmark 
INFO  [12:49:24.172] [bbotk] Result of batch 88: 
INFO  [12:49:24.174] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [12:49:24.174] [bbotk]                  10               744      0.2355855        0.608 -0.915778 
INFO  [12:49:24.174] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:49:24.174] [bbotk]          <NA>         0.5 9f7a4ae1-6432-42bf-93d2-ba9826b5dab9 
DEBUG [12:49:25.209] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.846164e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003846164 0.3878121 
  - best initial criterion value(s) :  313.925 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -313.92  |proj g|=       4.7892
At iterate     1  f =      -322.71  |proj g|=         4.392
At iterate     2  f =      -374.58  |proj g|=        3.0245
At iterate     3  f =       -409.3  |proj g|=       0.16806
At iterate     4  f =      -419.43  |proj g|=        1.8421
At iterate     5  f =       -419.7  |proj g|=        1.8391
At iterate     6  f =      -424.07  |proj g|=        1.5529
At iterate     7  f =      -429.35  |proj g|=        1.2704
At iterate     8  f =      -430.54  |proj g|=       0.45831
At iterate     9  f =      -430.54  |proj g|=        0.3838
At iterate    10  f =      -430.54  |proj g|=     0.0096123
At iterate    11  f =      -430.54  |proj g|=     0.0086545
At iterate    12  f =      -430.54  |proj g|=     0.0086545

iterations 12
function evaluations 24
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00865453
final function value -430.545

F = -430.545
final  value -430.544958 
converged
 
INFO  [12:49:25.213] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:49:25.290] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:49:25.296] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:49:26.048] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:49:26.782] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:49:27.515] [mlr3]  Finished benchmark 
INFO  [12:49:27.579] [bbotk] Result of batch 89: 
INFO  [12:49:27.581] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:49:27.581] [bbotk]                  10              1370     0.08425456        0.763 -0.8949701 
INFO  [12:49:27.581] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:49:27.581] [bbotk]          <NA>         0.5 67021530-05c2-407a-84de-91b667aebbb0 
DEBUG [12:49:28.418] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.934855e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003934855 0.3982274 
  - best initial criterion value(s) :  357.4124 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -357.41  |proj g|=       3.1021
At iterate     1  f =      -375.32  |proj g|=        9.6411
At iterate     2  f =      -407.34  |proj g|=        13.252
At iterate     3  f =      -410.45  |proj g|=        1.7292
At iterate     4  f =      -410.47  |proj g|=        2.0684
At iterate     5  f =      -410.48  |proj g|=       0.98401
At iterate     6  f =      -410.49  |proj g|=       0.69565
At iterate     7  f =      -410.62  |proj g|=        1.1027
At iterate     8  f =      -410.84  |proj g|=        1.1378
At iterate     9  f =       -411.3  |proj g|=         1.177
At iterate    10  f =      -411.44  |proj g|=        1.1613
At iterate    11  f =      -411.58  |proj g|=        1.1152
At iterate    12  f =      -411.61  |proj g|=       0.39417
At iterate    13  f =      -411.61  |proj g|=      0.012964
At iterate    14  f =      -411.61  |proj g|=      0.012964
At iterate    15  f =      -411.61  |proj g|=      0.012964

iterations 15
function evaluations 19
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0129642
final function value -411.609

F = -411.609
final  value -411.609063 
converged
 
INFO  [12:49:28.422] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:49:28.474] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:49:28.481] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:50:14.689] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:51:00.318] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:51:46.791] [mlr3]  Finished benchmark 
INFO  [12:51:46.867] [bbotk] Result of batch 90: 
INFO  [12:51:46.870] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:51:46.870] [bbotk]                   4              3795     0.02418964        0.588 -0.8963337 
INFO  [12:51:46.870] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:51:46.870] [bbotk]          <NA>   0.9732989 5c44ba46-7f5c-4d95-859c-3119fc426c77 
DEBUG [12:51:47.705] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.909468e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003909468 0.3972049 
  - best initial criterion value(s) :  389.0996 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -389.1  |proj g|=       2.9086
At iterate     1  f =      -406.91  |proj g|=        10.167
At iterate     2  f =      -434.47  |proj g|=        12.256
At iterate     3  f =      -435.17  |proj g|=        5.2169
At iterate     4  f =      -435.41  |proj g|=       0.93697
At iterate     5  f =       -435.5  |proj g|=        1.6352
At iterate     6  f =       -435.5  |proj g|=         2.123
At iterate     7  f =       -435.6  |proj g|=        2.8439
At iterate     8  f =      -436.61  |proj g|=        7.5166
At iterate     9  f =      -436.98  |proj g|=           8.7
At iterate    10  f =      -437.39  |proj g|=        6.0088
At iterate    11  f =      -437.71  |proj g|=       0.61662
At iterate    12  f =      -437.71  |proj g|=       0.39283
At iterate    13  f =      -437.71  |proj g|=       0.39283
At iterate    14  f =      -437.71  |proj g|=     0.0071013

iterations 14
function evaluations 19
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00710126
final function value -437.711

F = -437.711
final  value -437.711360 
converged
 
INFO  [12:51:47.708] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:51:47.759] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:51:47.767] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:52:11.104] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:52:33.345] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:52:56.009] [mlr3]  Finished benchmark 
INFO  [12:52:56.083] [bbotk] Result of batch 91: 
INFO  [12:52:56.084] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:52:56.084] [bbotk]                   5              1802        0.23878        0.587 -0.8946848 
INFO  [12:52:56.084] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:52:56.084] [bbotk]          <NA>   0.9759365 20103c68-3152-43e1-86b6-a8e3a9e76fab 
DEBUG [12:52:56.910] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.884849e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003884849 0.394515 
  - best initial criterion value(s) :  336.1898 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -336.19  |proj g|=       3.4376
At iterate     1  f =      -421.84  |proj g|=       0.39063
At iterate     2  f =      -422.71  |proj g|=     0.0082723
At iterate     3  f =      -422.74  |proj g|=     0.0082575
At iterate     4  f =      -422.74  |proj g|=        0.3899
At iterate     5  f =      -422.74  |proj g|=     0.0082511
At iterate     6  f =      -422.74  |proj g|=     0.0082511

iterations 6
function evaluations 9
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00825109
final function value -422.738

F = -422.738
final  value -422.738031 
converged
 
INFO  [12:52:56.914] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:52:56.968] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:52:56.975] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:53:09.038] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:53:20.692] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:53:32.424] [mlr3]  Finished benchmark 
INFO  [12:53:32.502] [bbotk] Result of batch 92: 
INFO  [12:53:32.504] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:53:32.504] [bbotk]                   5               892       0.370454        0.604 -0.9158043 
INFO  [12:53:32.504] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:53:32.504] [bbotk]          <NA>   0.9759932 74c763d7-e26a-4dcc-8242-ab4f95747df4 
DEBUG [12:53:33.387] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.8605e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.0038605 0.3897331 
  - best initial criterion value(s) :  337.4895 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -337.49  |proj g|=       5.3696
At iterate     1  f =      -344.07  |proj g|=        4.3443
At iterate     2  f =      -366.12  |proj g|=         4.404
At iterate     3  f =      -377.28  |proj g|=         4.248
At iterate     4  f =      -382.27  |proj g|=        4.1224
At iterate     5  f =      -394.27  |proj g|=        3.7967
At iterate     6  f =      -395.99  |proj g|=        3.7196
At iterate     7  f =      -410.95  |proj g|=        2.8515
At iterate     8  f =      -450.46  |proj g|=        1.3254
At iterate     9  f =      -450.76  |proj g|=        1.8126
At iterate    10  f =      -450.77  |proj g|=        1.1503
At iterate    11  f =      -450.79  |proj g|=     0.0080255
At iterate    12  f =      -450.79  |proj g|=     0.0070598
At iterate    13  f =      -450.79  |proj g|=     0.0070597

iterations 13
function evaluations 24
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00705968
final function value -450.791

F = -450.791
final  value -450.791171 
converged
 
INFO  [12:53:33.389] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:53:33.439] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:53:33.447] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:53:34.265] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:53:35.182] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:53:35.924] [mlr3]  Finished benchmark 
INFO  [12:53:36.000] [bbotk] Result of batch 93: 
INFO  [12:53:36.002] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:53:36.002] [bbotk]                   9               699      0.4951686        0.608 -0.8940302 
INFO  [12:53:36.002] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:53:36.002] [bbotk]          <NA>         0.5 615444b4-5152-4b1b-a645-ce6415567f0d 
DEBUG [12:53:36.885] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.945676e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.003945676 0.401201 
  - best initial criterion value(s) :  385.9028 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -385.9  |proj g|=       2.3765
At iterate     1  f =      -392.25  |proj g|=        3.3378
At iterate     2  f =      -422.95  |proj g|=        1.6953
At iterate     3  f =      -426.33  |proj g|=         1.288
At iterate     4  f =      -426.57  |proj g|=        1.2668
At iterate     5  f =      -426.63  |proj g|=        1.3043
At iterate     6  f =      -426.77  |proj g|=        1.2781
At iterate     7  f =      -427.42  |proj g|=        1.2383
At iterate     8  f =      -432.06  |proj g|=       0.77683
At iterate     9  f =      -436.66  |proj g|=        2.4324
At iterate    10  f =      -450.69  |proj g|=        3.9829
At iterate    11  f =      -450.72  |proj g|=        2.7617
At iterate    12  f =      -450.82  |proj g|=       0.79442
At iterate    13  f =      -450.83  |proj g|=       0.39698
At iterate    14  f =      -450.83  |proj g|=       0.39697
At iterate    15  f =      -450.83  |proj g|=       0.00818

iterations 15
function evaluations 24
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00818003
final function value -450.826

F = -450.826
final  value -450.825852 
converged
 
INFO  [12:53:36.889] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:53:36.943] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:53:36.950] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:53:37.693] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:53:38.445] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:53:39.232] [mlr3]  Finished benchmark 
INFO  [12:53:39.311] [bbotk] Result of batch 94: 
INFO  [12:53:39.313] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:53:39.313] [bbotk]                  10               720      0.1140489        0.603 -0.8936038 
INFO  [12:53:39.313] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:53:39.313] [bbotk]          <NA>         0.5 480e0d9e-9ded-4ad4-904a-c7bf789c6959 
DEBUG [12:53:40.372] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.027371e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9854484 
  - variance bounds :  0.004027371 0.4136046 
  - best initial criterion value(s) :  380.6304 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -380.63  |proj g|=       6.8341
At iterate     1  f =      -384.66  |proj g|=        3.1088
At iterate     2  f =      -415.11  |proj g|=        2.4128
At iterate     3  f =      -417.49  |proj g|=        2.2805
At iterate     4  f =      -438.56  |proj g|=         1.385
At iterate     5  f =      -440.51  |proj g|=        1.2439
At iterate     6  f =      -441.52  |proj g|=       0.99483
At iterate     7  f =      -441.55  |proj g|=       0.75076
At iterate     8  f =      -441.55  |proj g|=       0.62386
At iterate     9  f =      -441.56  |proj g|=       0.40958
At iterate    10  f =      -441.74  |proj g|=        1.1119
At iterate    11  f =      -442.39  |proj g|=        1.1406
At iterate    12  f =      -442.44  |proj g|=        1.1239
At iterate    13  f =      -442.46  |proj g|=      0.060928
At iterate    14  f =      -442.46  |proj g|=      0.011193
At iterate    15  f =      -442.46  |proj g|=      0.014765
At iterate    16  f =      -442.46  |proj g|=      0.011193
At iterate    17  f =      -442.46  |proj g|=      0.041945
At iterate    18  f =      -442.51  |proj g|=       0.35433
At iterate    19  f =       -442.6  |proj g|=       0.74752
At iterate    20  f =      -442.87  |proj g|=        1.3619
At iterate    21  f =       -443.5  |proj g|=        2.0632
At iterate    22  f =      -445.03  |proj g|=        2.5257
At iterate    23  f =      -448.55  |proj g|=        1.2981
At iterate    24  f =      -455.21  |proj g|=        1.7858
At iterate    25  f =      -455.67  |proj g|=        1.7399
At iterate    26  f =      -457.99  |proj g|=        1.5493
At iterate    27  f =      -462.82  |proj g|=         4.319
At iterate    28  f =      -463.22  |proj g|=       0.40958
At iterate    29  f =      -463.29  |proj g|=        0.8932
At iterate    30  f =      -463.31  |proj g|=       0.40051
At iterate    31  f =      -463.31  |proj g|=       0.40933
At iterate    32  f =      -463.31  |proj g|=    0.00083431
At iterate    33  f =      -463.31  |proj g|=     0.0006616

iterations 33
function evaluations 50
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000661605
final function value -463.314

F = -463.314
final  value -463.313528 
converged
 
INFO  [12:53:40.377] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:53:40.433] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:53:40.440] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:53:41.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:53:41.937] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:53:42.711] [mlr3]  Finished benchmark 
INFO  [12:53:42.778] [bbotk] Result of batch 95: 
INFO  [12:53:42.780] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:53:42.780] [bbotk]                  10              3685      0.4990166        0.684 -0.8929499 
INFO  [12:53:42.780] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:53:42.780] [bbotk]          <NA>         0.5 3dbbaec0-a145-4a02-a737-37f77aa94aa0 
DEBUG [12:53:43.703] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.105725e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004105725 0.418021 
  - best initial criterion value(s) :  375.5496 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -375.55  |proj g|=       3.3063
At iterate     1  f =      -448.55  |proj g|=       0.41392
At iterate     2  f =      -448.88  |proj g|=     0.0076068
At iterate     3  f =      -448.88  |proj g|=        0.0076
At iterate     4  f =      -448.88  |proj g|=       0.40845
At iterate     5  f =      -448.88  |proj g|=     0.0075984

iterations 5
function evaluations 8
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0075984
final function value -448.878

F = -448.878
final  value -448.878495 
converged
 
INFO  [12:53:43.707] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:53:43.761] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:53:43.768] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:54:16.892] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:54:49.485] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:55:22.501] [mlr3]  Finished benchmark 
INFO  [12:55:22.577] [bbotk] Result of batch 96: 
INFO  [12:55:22.579] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:55:22.579] [bbotk]                   4              2650      0.1936976        0.702 -0.9135275 
INFO  [12:55:22.579] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:55:22.579] [bbotk]          <NA>   0.9750887 3abffa48-75d4-4d8b-96b4-a40058749a39 
DEBUG [12:55:23.483] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.081734e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004081734 0.4148556 
  - best initial criterion value(s) :  364.7771 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -364.78  |proj g|=       1.1086
At iterate     1  f =      -452.23  |proj g|=        1.3265
At iterate     2  f =      -452.53  |proj g|=        1.3262
At iterate     3  f =      -452.61  |proj g|=        1.3262
At iterate     4  f =      -452.61  |proj g|=        1.3261
At iterate     5  f =      -452.62  |proj g|=        1.3249
At iterate     6  f =      -452.74  |proj g|=        1.3099
At iterate     7  f =      -452.96  |proj g|=        1.2734
At iterate     8  f =      -453.34  |proj g|=        1.1999
At iterate     9  f =      -453.69  |proj g|=        1.1836
At iterate    10  f =      -453.84  |proj g|=       0.54151
At iterate    11  f =      -453.85  |proj g|=      0.011007
At iterate    12  f =      -453.85  |proj g|=      0.011007

iterations 12
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0110067
final function value -453.845

F = -453.845
final  value -453.845388 
converged
 
INFO  [12:55:23.487] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:55:23.542] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:55:23.549] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:55:24.279] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:55:25.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:55:25.922] [mlr3]  Finished benchmark 
INFO  [12:55:25.996] [bbotk] Result of batch 97: 
INFO  [12:55:25.998] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:55:25.998] [bbotk]                   9              3878    0.007922917        0.644 -0.8925093 
INFO  [12:55:25.998] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:55:25.998] [bbotk]          <NA>         0.5 331b13bf-d6b7-433d-a964-48a88ece92df 
DEBUG [12:55:27.065] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.157034e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004157034 0.4204505 
  - best initial criterion value(s) :  292.6587 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -292.66  |proj g|=       4.9852
At iterate     1  f =      -323.92  |proj g|=        10.593
At iterate     2  f =      -341.85  |proj g|=        3.4412
At iterate     3  f =      -359.04  |proj g|=        4.1817
At iterate     4  f =      -370.87  |proj g|=        4.1976
At iterate     5  f =      -375.76  |proj g|=         4.141
At iterate     6  f =      -386.01  |proj g|=        3.9296
At iterate     7  f =      -391.26  |proj g|=        3.6955
At iterate     8  f =      -448.79  |proj g|=        1.4459
At iterate     9  f =      -450.63  |proj g|=         1.294
At iterate    10  f =      -452.35  |proj g|=        1.1933
At iterate    11  f =      -452.58  |proj g|=        1.0316
At iterate    12  f =      -452.59  |proj g|=      0.017654
At iterate    13  f =      -452.59  |proj g|=      0.012471
At iterate    14  f =      -452.59  |proj g|=      0.012471

iterations 14
function evaluations 21
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0124706
final function value -452.586

F = -452.586
final  value -452.586443 
converged
 
INFO  [12:55:27.069] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:55:27.122] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:55:27.129] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:55:47.764] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:56:07.123] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:56:26.492] [mlr3]  Finished benchmark 
INFO  [12:56:26.559] [bbotk] Result of batch 98: 
INFO  [12:56:26.561] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:56:26.561] [bbotk]                   3              1550      0.3252653        0.798 -0.8929464 
INFO  [12:56:26.561] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:56:26.561] [bbotk]          <NA>   0.9733482 a806bed7-d330-4c18-9a4d-1e1f1ba339a0 
DEBUG [12:56:27.422] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.133079e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004133079 0.417515 
  - best initial criterion value(s) :  381.1349 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -381.13  |proj g|=       2.3976
At iterate     1  f =       -444.5  |proj g|=        13.191
At iterate     2  f =      -447.17  |proj g|=       0.32677
At iterate     3  f =      -447.17  |proj g|=      0.017929
At iterate     4  f =      -447.17  |proj g|=      0.015127
At iterate     5  f =      -447.17  |proj g|=      0.015127

iterations 5
function evaluations 9
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0151267
final function value -447.173

F = -447.173
final  value -447.173379 
converged
 
INFO  [12:56:27.426] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:56:27.479] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:56:27.490] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:56:43.032] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:56:58.489] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:57:13.503] [mlr3]  Finished benchmark 
INFO  [12:57:13.569] [bbotk] Result of batch 99: 
INFO  [12:57:13.570] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:57:13.570] [bbotk]                   8              1197    0.009953895        0.612 -0.8935814 
INFO  [12:57:13.570] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:57:13.570] [bbotk]          <NA>   0.9668756 10823491-9927-4105-b0f2-191e3a04b1a4 
DEBUG [12:57:14.466] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.108183e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004108183 0.4136624 
  - best initial criterion value(s) :  299.3967 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -299.4  |proj g|=       13.367
At iterate     1  f =      -346.77  |proj g|=        2.6285
At iterate     2  f =      -365.17  |proj g|=        2.2371
At iterate     3  f =      -373.87  |proj g|=        1.6371
At iterate     4  f =      -382.45  |proj g|=        1.2522
At iterate     5  f =      -382.53  |proj g|=        1.2105
At iterate     6  f =      -388.41  |proj g|=        0.5524
At iterate     7  f =      -412.74  |proj g|=        13.155
At iterate     8  f =      -436.27  |proj g|=        13.292
At iterate     9  f =      -453.85  |proj g|=        13.128
At iterate    10  f =      -455.32  |proj g|=        1.1649
At iterate    11  f =      -455.46  |proj g|=       0.80976
At iterate    12  f =      -455.46  |proj g|=       0.01388
At iterate    13  f =      -455.46  |proj g|=       0.01388

iterations 13
function evaluations 22
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0138801
final function value -455.462

F = -455.462
final  value -455.461868 
converged
 
INFO  [12:57:14.470] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:57:14.525] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:57:14.541] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:57:15.267] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:57:15.994] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:57:16.732] [mlr3]  Finished benchmark 
INFO  [12:57:16.796] [bbotk] Result of batch 100: 
INFO  [12:57:16.798] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:57:16.798] [bbotk]                  10              4418      0.2667979        0.615 -0.8920924 
INFO  [12:57:16.798] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:57:16.798] [bbotk]          <NA>         0.5 924af8b7-7eaa-4bae-9d05-feb0a307e6e1 
DEBUG [12:57:17.676] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.180723e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004180723 0.4218914 
  - best initial criterion value(s) :  380.1165 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -380.12  |proj g|=       1.5558
At iterate     1  f =      -464.91  |proj g|=         1.613
At iterate     2  f =      -465.62  |proj g|=        1.5614
At iterate     3  f =      -466.13  |proj g|=        1.4185
At iterate     4  f =      -466.52  |proj g|=        1.3825
At iterate     5  f =      -469.07  |proj g|=        1.2356
At iterate     6  f =      -473.08  |proj g|=      0.024431
At iterate     7  f =      -473.08  |proj g|=      0.011082
At iterate     8  f =      -473.08  |proj g|=      0.011082

iterations 8
function evaluations 15
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0110816
final function value -473.081

F = -473.081
final  value -473.080785 
converged
 
INFO  [12:57:17.680] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:57:17.733] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:57:17.740] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:57:30.703] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [12:57:43.933] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:57:56.901] [mlr3]  Finished benchmark 
INFO  [12:57:56.967] [bbotk] Result of batch 101: 
INFO  [12:57:56.969] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [12:57:56.969] [bbotk]                   6               979      0.1338975        0.628 -0.8910706 
INFO  [12:57:56.969] [bbotk]  errors.model classif.auc                                uhash 
INFO  [12:57:56.969] [bbotk]          <NA>   0.9758198 286e4be4-bb34-4d1b-8014-3e3138ec54ea 
DEBUG [12:57:57.932] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.157832e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004157832 0.4188925 
  - best initial criterion value(s) :  431.8674 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -431.87  |proj g|=       3.5408
At iterate     1  f =      -472.12  |proj g|=       0.41473
At iterate     2  f =      -472.26  |proj g|=     0.0087293
At iterate     3  f =      -472.27  |proj g|=     0.0087065
At iterate     4  f =      -472.27  |proj g|=       0.41444
At iterate     5  f =      -472.27  |proj g|=      0.008703

iterations 5
function evaluations 8
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00870304
final function value -472.274

F = -472.274
final  value -472.274013 
converged
 
INFO  [12:57:57.936] [bbotk] Evaluating 1 configuration(s) 
INFO  [12:57:57.990] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [12:57:57.997] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [12:58:45.711] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [12:59:34.070] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:00:23.453] [mlr3]  Finished benchmark 
INFO  [13:00:23.519] [bbotk] Result of batch 102: 
INFO  [13:00:23.520] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:00:23.520] [bbotk]                   4              4026      0.4919876        0.728 -0.9127001 
INFO  [13:00:23.520] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:00:23.520] [bbotk]          <NA>   0.9749362 a1225047-861b-4293-947a-b51e0ea0f4da 
DEBUG [13:00:24.448] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.13497e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.00413497 0.4174292 
  - best initial criterion value(s) :  396.8405 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -396.84  |proj g|=       12.452
At iterate     1  f =       -407.1  |proj g|=       0.39685
At iterate     2  f =      -436.45  |proj g|=        1.9285
At iterate     3  f =      -437.83  |proj g|=        1.8634
At iterate     4  f =      -448.99  |proj g|=        1.3426
At iterate     5  f =      -456.47  |proj g|=        1.2596
At iterate     6  f =       -457.2  |proj g|=        1.2048
At iterate     7  f =      -457.31  |proj g|=        1.1844
At iterate     8  f =      -457.49  |proj g|=      0.086165
At iterate     9  f =      -457.49  |proj g|=      0.017023
At iterate    10  f =      -457.49  |proj g|=      0.017023

iterations 10
function evaluations 17
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.017023
final function value -457.486

F = -457.486
final  value -457.486298 
converged
 
INFO  [13:00:24.452] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:00:24.507] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:00:24.514] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:00:34.050] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:00:44.280] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:00:54.231] [mlr3]  Finished benchmark 
INFO  [13:00:54.298] [bbotk] Result of batch 103: 
INFO  [13:00:54.300] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:00:54.300] [bbotk]                   7               704       0.230495        0.653 -0.8928742 
INFO  [13:00:54.300] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:00:54.300] [bbotk]          <NA>   0.9759567 52cddbce-0b7f-4f5f-8afd-492952eb48fc 
DEBUG [13:00:55.239] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.112493e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004112493 0.4143132 
  - best initial criterion value(s) :  405.2458 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -405.25  |proj g|=      0.62161
At iterate     1  f =      -452.36  |proj g|=        3.0931
At iterate     2  f =      -459.69  |proj g|=        2.9713
At iterate     3  f =      -459.93  |proj g|=        2.9698
At iterate     4  f =      -459.99  |proj g|=        2.9679
At iterate     5  f =      -460.08  |proj g|=        2.9634
At iterate     6  f =      -460.47  |proj g|=          2.94
At iterate     7  f =      -461.32  |proj g|=        2.8877
At iterate     8  f =      -463.81  |proj g|=        2.7234
At iterate     9  f =      -469.97  |proj g|=        2.4044
At iterate    10  f =      -489.78  |proj g|=         1.682
At iterate    11  f =      -490.12  |proj g|=        13.293
At iterate    12  f =      -498.68  |proj g|=         11.98
At iterate    13  f =      -499.88  |proj g|=       0.11188
At iterate    14  f =      -499.88  |proj g|=     0.0087666
At iterate    15  f =      -499.88  |proj g|=     0.0087666

iterations 15
function evaluations 19
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00876657
final function value -499.885

F = -499.885
final  value -499.884681 
converged
 
INFO  [13:00:55.243] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:00:55.321] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:00:55.328] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:01:09.568] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:01:23.640] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:01:37.599] [mlr3]  Finished benchmark 
INFO  [13:01:37.666] [bbotk] Result of batch 104: 
INFO  [13:01:37.668] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:01:37.668] [bbotk]                   6              1080      0.2296973        0.664 -0.8888122 
INFO  [13:01:37.668] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:01:37.668] [bbotk]          <NA>   0.9762599 177224b4-4a81-4537-bcef-68e5b8301cdc 
DEBUG [13:01:38.659] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.090261e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004090261 0.410909 
  - best initial criterion value(s) :  321.8392 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -321.84  |proj g|=       11.415
At iterate     1  f =      -329.53  |proj g|=        2.7915
At iterate     2  f =      -362.27  |proj g|=        2.2073
At iterate     3  f =      -363.94  |proj g|=        2.1203
At iterate     4  f =      -381.74  |proj g|=        1.3871
At iterate     5  f =      -385.56  |proj g|=        1.1608
At iterate     6  f =      -385.79  |proj g|=        1.0205
At iterate     7  f =      -385.92  |proj g|=        1.0848
At iterate     8  f =      -385.93  |proj g|=        1.0573
At iterate     9  f =      -385.96  |proj g|=        1.0032
At iterate    10  f =      -386.01  |proj g|=       0.89219
At iterate    11  f =      -386.15  |proj g|=       0.71009
At iterate    12  f =      -389.58  |proj g|=        7.9352
At iterate    13  f =      -402.66  |proj g|=        13.107
At iterate    14  f =      -406.97  |proj g|=         1.267
At iterate    15  f =      -408.57  |proj g|=      0.068738
At iterate    16  f =      -408.58  |proj g|=       0.07845
At iterate    17  f =      -408.58  |proj g|=       0.40664
At iterate    18  f =      -408.58  |proj g|=      0.035618
At iterate    19  f =      -408.58  |proj g|=      0.035618

iterations 19
function evaluations 30
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0356177
final function value -408.581

F = -408.581
final  value -408.580895 
converged
 
INFO  [13:01:38.663] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:01:38.723] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:01:38.734] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:01:39.488] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:01:40.224] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:01:40.958] [mlr3]  Finished benchmark 
INFO  [13:01:41.024] [bbotk] Result of batch 105: 
INFO  [13:01:41.026] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:01:41.026] [bbotk]                  10               708      0.2605789        0.657 -0.8977324 
INFO  [13:01:41.026] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:01:41.026] [bbotk]          <NA>         0.5 2f3ce381-feef-4b81-93e0-07a1c5b44391 
DEBUG [13:01:42.247] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.160545e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004160545 0.4194416 
  - best initial criterion value(s) :  377.794 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -377.79  |proj g|=       13.087
At iterate     1  f =      -418.11  |proj g|=        9.9818
At iterate     2  f =      -445.08  |proj g|=        2.8636
At iterate     3  f =      -465.85  |proj g|=        2.8211
At iterate     4  f =      -471.92  |proj g|=        2.7346
At iterate     5  f =      -487.03  |proj g|=        2.4754
At iterate     6  f =      -503.63  |proj g|=        1.7903
At iterate     7  f =      -510.24  |proj g|=         13.18
At iterate     8  f =      -513.47  |proj g|=       0.40078
At iterate     9  f =      -513.47  |proj g|=      0.032641
At iterate    10  f =      -513.47  |proj g|=     0.0086547
At iterate    11  f =      -513.47  |proj g|=     0.0086547

iterations 11
function evaluations 17
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00865475
final function value -513.47

F = -513.47
final  value -513.469745 
converged
 
INFO  [13:01:42.251] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:01:42.304] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:01:42.310] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:02:35.023] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:03:27.355] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:04:19.879] [mlr3]  Finished benchmark 
INFO  [13:04:19.947] [bbotk] Result of batch 106: 
INFO  [13:04:19.949] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [13:04:19.949] [bbotk]                   4              4377      0.1212858        0.931 -0.888809 
INFO  [13:04:19.949] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:04:19.949] [bbotk]          <NA>    0.975109 33a8cc52-1761-4259-b0ee-2e0ad1534c1a 
DEBUG [13:04:20.817] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.138425e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004138425 0.417315 
  - best initial criterion value(s) :  406.5012 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -406.5  |proj g|=       4.6309
At iterate     1  f =      -487.43  |proj g|=       0.41318
At iterate     2  f =      -487.47  |proj g|=      0.011096
At iterate     3  f =      -487.49  |proj g|=      0.011079
At iterate     4  f =      -487.49  |proj g|=       0.41299
At iterate     5  f =      -487.49  |proj g|=      0.011077

iterations 5
function evaluations 8
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0110769
final function value -487.488

F = -487.488
final  value -487.488418 
converged
 
INFO  [13:04:20.821] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:04:20.874] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:04:20.881] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:04:26.806] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:04:32.906] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:04:39.482] [mlr3]  Finished benchmark 
INFO  [13:04:39.549] [bbotk] Result of batch 107: 
INFO  [13:04:39.551] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:04:39.551] [bbotk]                   6               406      0.2720939        0.635 -0.9137191 
INFO  [13:04:39.551] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:04:39.551] [bbotk]          <NA>   0.9755082 9ef0cf9a-baf7-49c1-bf12-58f2aa6d3ba3 
DEBUG [13:04:40.504] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.11656e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.00411656 0.4147508 
  - best initial criterion value(s) :  402.7978 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -402.8  |proj g|=       6.6889
At iterate     1  f =      -408.01  |proj g|=        3.1517
At iterate     2  f =      -437.98  |proj g|=        2.4728
At iterate     3  f =      -442.31  |proj g|=         2.255
At iterate     4  f =      -466.23  |proj g|=        1.3209
At iterate     5  f =      -467.02  |proj g|=        1.2179
At iterate     6  f =      -467.15  |proj g|=        1.1641
At iterate     7  f =      -467.17  |proj g|=         1.157
At iterate     8  f =      -467.31  |proj g|=        1.1968
At iterate     9  f =       -467.6  |proj g|=         4.048
At iterate    10  f =      -468.43  |proj g|=        9.0239
At iterate    11  f =      -470.38  |proj g|=        13.102
At iterate    12  f =      -474.77  |proj g|=         13.24
At iterate    13  f =      -481.09  |proj g|=        13.159
At iterate    14  f =      -483.94  |proj g|=       0.78254
At iterate    15  f =      -483.95  |proj g|=      0.052424
At iterate    16  f =      -483.95  |proj g|=      0.017444
At iterate    17  f =      -483.95  |proj g|=      0.017444

iterations 17
function evaluations 24
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0174444
final function value -483.945

F = -483.945
final  value -483.945484 
converged
 
INFO  [13:04:40.508] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:04:40.562] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:04:40.569] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:05:26.911] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:06:13.500] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:07:01.599] [mlr3]  Finished benchmark 
INFO  [13:07:01.689] [bbotk] Result of batch 108: 
INFO  [13:07:01.691] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:07:01.691] [bbotk]                   5              3919     0.01705322        0.649 -0.8921718 
INFO  [13:07:01.691] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:07:01.691] [bbotk]          <NA>   0.9739729 88e85396-2d7f-4760-9bf6-f790e0f4e586 
DEBUG [13:07:02.562] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.09461e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.00409461 0.4134347 
  - best initial criterion value(s) :  417.23 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -417.23  |proj g|=       3.6461
At iterate     1  f =      -484.35  |proj g|=       0.40934
At iterate     2  f =      -484.38  |proj g|=      0.014026
At iterate     3  f =      -484.38  |proj g|=      0.014026
At iterate     4  f =      -484.38  |proj g|=      0.014026

iterations 4
function evaluations 7
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.014026
final function value -484.377

F = -484.377
final  value -484.377142 
converged
 
INFO  [13:07:02.567] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:07:02.625] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:07:02.633] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:07:03.460] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:07:04.488] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:07:05.257] [mlr3]  Finished benchmark 
INFO  [13:07:05.335] [bbotk] Result of batch 109: 
INFO  [13:07:05.336] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:07:05.336] [bbotk]                   9              4658     0.09666262        0.644 -0.9135805 
INFO  [13:07:05.336] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:07:05.336] [bbotk]          <NA>         0.5 7d496e7c-4057-434b-bc0d-c8de31d303bf 
DEBUG [13:07:06.273] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.162638e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004162638 0.4221851 
  - best initial criterion value(s) :  301.4739 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -301.47  |proj g|=      0.51271
At iterate     1  f =       -361.9  |proj g|=        3.0464
At iterate     2  f =      -377.86  |proj g|=        2.9804
At iterate     3  f =      -384.86  |proj g|=         2.925
At iterate     4  f =      -392.12  |proj g|=        2.8697
At iterate     5  f =      -393.17  |proj g|=        2.8587
At iterate     6  f =      -397.76  |proj g|=        2.6686
At iterate     7  f =      -410.27  |proj g|=        2.0581
At iterate     8  f =      -437.93  |proj g|=         8.614
At iterate     9  f =      -438.41  |proj g|=        1.1248
At iterate    10  f =      -438.44  |proj g|=      0.043428
At iterate    11  f =      -438.44  |proj g|=      0.034626
At iterate    12  f =      -438.44  |proj g|=      0.034626

iterations 12
function evaluations 18
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0346257
final function value -438.442

F = -438.442
final  value -438.442088 
converged
 
INFO  [13:07:06.277] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:07:06.330] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:07:06.337] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:08:01.929] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:08:56.987] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:09:53.008] [mlr3]  Finished benchmark 
INFO  [13:09:53.073] [bbotk] Result of batch 110: 
INFO  [13:09:53.075] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:09:53.075] [bbotk]                   4              4655     0.02373932        0.651 -0.8962973 
INFO  [13:09:53.075] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:09:53.075] [bbotk]          <NA>   0.9735464 db776791-3ed5-40bd-9534-4915821331fc 
DEBUG [13:09:54.154] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.140921e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004140921 0.4196685 
  - best initial criterion value(s) :  465.7462 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -465.75  |proj g|=       2.7783
At iterate     1  f =       -522.1  |proj g|=       0.41553
At iterate     2  f =      -522.12  |proj g|=     0.0086234
At iterate     3  f =      -522.15  |proj g|=     0.0085787
At iterate     4  f =      -522.15  |proj g|=       0.41536
At iterate     5  f =      -522.15  |proj g|=     0.0085748

iterations 5
function evaluations 7
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00857478
final function value -522.152

F = -522.152
final  value -522.152114 
converged
 
INFO  [13:09:54.158] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:09:54.212] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:09:54.218] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:10:29.121] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:11:04.416] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:11:39.803] [mlr3]  Finished benchmark 
INFO  [13:11:39.870] [bbotk] Result of batch 111: 
INFO  [13:11:39.878] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:11:39.878] [bbotk]                   8              2889     0.05774461        0.803 -0.9124069 
INFO  [13:11:39.878] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:11:39.878] [bbotk]          <NA>   0.9744999 5bcc5bee-5dcc-42f0-a808-ec54104852ac 
DEBUG [13:11:40.850] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.119548e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004119548 0.4177452 
  - best initial criterion value(s) :  403.0949 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -403.09  |proj g|=       6.1775
At iterate     1  f =      -430.95  |proj g|=        5.6525
At iterate     2  f =      -436.74  |proj g|=        2.9207
At iterate     3  f =      -460.27  |proj g|=        4.8072
At iterate     4  f =      -464.95  |proj g|=        4.6112
At iterate     5  f =      -474.15  |proj g|=        4.1616
At iterate     6  f =      -487.69  |proj g|=        3.5731
At iterate     7  f =      -518.98  |proj g|=        2.3898
At iterate     8  f =       -528.8  |proj g|=     0.0087883
At iterate     9  f =      -528.86  |proj g|=       0.41363
At iterate    10  f =      -528.91  |proj g|=     0.0087079
At iterate    11  f =      -528.91  |proj g|=     0.0087016
At iterate    12  f =      -528.91  |proj g|=       0.04615
At iterate    13  f =      -528.91  |proj g|=     0.0087011

iterations 13
function evaluations 23
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00870107
final function value -528.908

F = -528.908
final  value -528.908184 
converged
 
INFO  [13:11:40.855] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:11:40.908] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:11:40.914] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:11:41.657] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:11:42.399] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:11:43.129] [mlr3]  Finished benchmark 
INFO  [13:11:43.195] [bbotk] Result of batch 112: 
INFO  [13:11:43.197] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:11:43.197] [bbotk]                  10              4348      0.3420176        0.661 -0.9122562 
INFO  [13:11:43.197] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:11:43.197] [bbotk]          <NA>         0.5 b58f176a-55ea-4fb5-b4d0-5a413cfb26ed 
DEBUG [13:11:44.189] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.185331e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004185331 0.425213 
  - best initial criterion value(s) :  411.8243 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -411.82  |proj g|=       3.5775
At iterate     1  f =      -417.28  |proj g|=        3.0453
At iterate     2  f =      -423.71  |proj g|=        3.0404
At iterate     3  f =      -426.39  |proj g|=        2.9657
At iterate     4  f =      -434.04  |proj g|=        2.6162
At iterate     5  f =       -451.3  |proj g|=        1.8487
At iterate     6  f =      -467.91  |proj g|=        1.2501
At iterate     7  f =      -468.01  |proj g|=        1.2057
At iterate     8  f =      -468.02  |proj g|=        1.1981
At iterate     9  f =       -468.1  |proj g|=        1.1742
At iterate    10  f =      -468.26  |proj g|=        0.8432
At iterate    11  f =      -468.73  |proj g|=        3.0812
At iterate    12  f =      -469.86  |proj g|=        8.8751
At iterate    13  f =      -472.58  |proj g|=        13.122
At iterate    14  f =      -478.32  |proj g|=        13.269
At iterate    15  f =      -485.41  |proj g|=        13.151
At iterate    16  f =      -488.07  |proj g|=        1.0964
At iterate    17  f =      -488.08  |proj g|=      0.064282
At iterate    18  f =      -488.08  |proj g|=      0.024446
At iterate    19  f =      -488.08  |proj g|=      0.024446

iterations 19
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0244458
final function value -488.082

F = -488.082
final  value -488.081589 
converged
 
INFO  [13:11:44.193] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:11:44.249] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:11:44.256] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:12:41.243] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:13:38.610] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:14:35.579] [mlr3]  Finished benchmark 
INFO  [13:14:35.646] [bbotk] Result of batch 113: 
INFO  [13:14:35.648] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:14:35.648] [bbotk]                   7              4708      0.1891983        0.662 -0.8934577 
INFO  [13:14:35.648] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:14:35.648] [bbotk]          <NA>   0.9754355 c7b332b3-a1ae-447c-ad30-533efffc5afb 
DEBUG [13:14:36.831] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.164415e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9370 0.9910109 
  - variance bounds :  0.004164415 0.4221219 
  - best initial criterion value(s) :  403.4681 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -403.47  |proj g|=       12.372
At iterate     1  f =      -423.93  |proj g|=       0.88093
At iterate     2  f =      -458.36  |proj g|=        2.4728
At iterate     3  f =      -461.26  |proj g|=        2.3422
At iterate     4  f =      -486.21  |proj g|=        1.5324
At iterate     5  f =      -491.31  |proj g|=        1.2135
At iterate     6  f =      -492.25  |proj g|=        2.6724
At iterate     7  f =       -492.3  |proj g|=        1.2504
At iterate     8  f =      -492.38  |proj g|=       0.43053
At iterate     9  f =      -492.55  |proj g|=        1.1777
At iterate    10  f =         -493  |proj g|=        1.2332
At iterate    11  f =      -494.07  |proj g|=        1.3098
At iterate    12  f =         -495  |proj g|=        1.3083
At iterate    13  f =      -495.48  |proj g|=        1.2629
At iterate    14  f =      -496.02  |proj g|=       0.30106
At iterate    15  f =      -496.03  |proj g|=       0.02354
At iterate    16  f =      -496.03  |proj g|=      0.023539

iterations 16
function evaluations 27
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0235394
final function value -496.025

F = -496.025
final  value -496.025315 
converged
 
INFO  [13:14:36.835] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:14:36.891] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:14:36.898] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:14:40.899] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:14:44.653] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:14:48.309] [mlr3]  Finished benchmark 
INFO  [13:14:48.376] [bbotk] Result of batch 114: 
INFO  [13:14:48.378] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:14:48.378] [bbotk]                   7               208       0.431303        0.642 -0.8934815 
INFO  [13:14:48.378] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:14:48.378] [bbotk]          <NA>   0.9748156 54b1d20d-7213-4326-adaa-0a740fafde59 
DEBUG [13:14:49.301] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.143556e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9576 0.9910109 
  - variance bounds :  0.004143556 0.4181406 
  - best initial criterion value(s) :  448.6666 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -448.67  |proj g|=       4.8044
At iterate     1  f =      -451.12  |proj g|=        4.6359
At iterate     2  f =      -471.63  |proj g|=        3.9906
At iterate     3  f =      -478.14  |proj g|=        3.7886
At iterate     4  f =      -497.76  |proj g|=        2.2883
At iterate     5  f =      -545.66  |proj g|=        1.2921
At iterate     6  f =      -546.13  |proj g|=      0.012398
At iterate     7  f =      -546.13  |proj g|=      0.012398

iterations 7
function evaluations 14
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0123979
final function value -546.131

F = -546.131
final  value -546.131444 
converged
 
INFO  [13:14:49.305] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:14:49.360] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:14:49.366] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:14:50.105] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:14:50.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:14:51.622] [mlr3]  Finished benchmark 
INFO  [13:14:51.688] [bbotk] Result of batch 115: 
INFO  [13:14:51.690] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:14:51.690] [bbotk]                  10               443       0.297905        0.657 -0.8899703 
INFO  [13:14:51.690] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:14:51.690] [bbotk]          <NA>         0.5 476fbc15-4d62-43e7-83ec-13cb048af357 
DEBUG [13:14:52.676] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.207233e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9576 0.9910109 
  - variance bounds :  0.004207233 0.4271368 
  - best initial criterion value(s) :  428.5455 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -428.55  |proj g|=       11.888
At iterate     1  f =      -456.05  |proj g|=        3.7977
At iterate     2  f =      -487.94  |proj g|=        3.2355
At iterate     3  f =      -496.82  |proj g|=        2.8711
At iterate     4  f =      -539.47  |proj g|=        1.5869
At iterate     5  f =      -540.76  |proj g|=        1.4512
At iterate     6  f =      -543.96  |proj g|=        1.3952
At iterate     7  f =      -545.58  |proj g|=        1.1929
At iterate     8  f =      -554.94  |proj g|=       0.80832
At iterate     9  f =      -564.54  |proj g|=       0.30889
At iterate    10  f =      -564.54  |proj g|=      0.025256
At iterate    11  f =      -564.54  |proj g|=     0.0098553
At iterate    12  f =      -564.54  |proj g|=     0.0098553

iterations 12
function evaluations 23
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00985535
final function value -564.537

F = -564.537
final  value -564.537099 
converged
 
INFO  [13:14:52.680] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:14:52.735] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:14:52.741] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:15:11.292] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:15:29.259] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:15:47.918] [mlr3]  Finished benchmark 
INFO  [13:15:48.006] [bbotk] Result of batch 116: 
INFO  [13:15:48.008] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:15:48.008] [bbotk]                   7              1409      0.4246715        0.672 -0.8884874 
INFO  [13:15:48.008] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:15:48.008] [bbotk]          <NA>   0.9756999 cf07bc0f-6063-4a59-91a7-2432c75d0ed5 
DEBUG [13:15:49.001] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.186813e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9576 0.9910109 
  - variance bounds :  0.004186813 0.4245299 
  - best initial criterion value(s) :  372.1092 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -372.11  |proj g|=       5.5014
At iterate     1  f =      -392.86  |proj g|=        4.8592
At iterate     2  f =      -399.78  |proj g|=        4.1689
At iterate     3  f =      -412.96  |proj g|=        3.6951
At iterate     4  f =      -416.47  |proj g|=         3.485
At iterate     5  f =      -423.81  |proj g|=        3.1169
At iterate     6  f =      -437.09  |proj g|=         2.659
At iterate     7  f =      -476.01  |proj g|=        1.3221
At iterate     8  f =      -476.97  |proj g|=        2.2821
At iterate     9  f =      -477.26  |proj g|=        1.1257
At iterate    10  f =      -477.87  |proj g|=        1.2131
At iterate    11  f =      -479.53  |proj g|=        1.3158
At iterate    12  f =      -483.42  |proj g|=        1.4573
At iterate    13  f =      -493.63  |proj g|=        1.4996
At iterate    14  f =      -496.37  |proj g|=        1.4253
At iterate    15  f =      -512.64  |proj g|=        1.3056
At iterate    16  f =      -539.76  |proj g|=         1.193
At iterate    17  f =      -539.78  |proj g|=       0.34213
At iterate    18  f =      -539.78  |proj g|=      0.016511
At iterate    19  f =      -539.78  |proj g|=      0.016511

iterations 19
function evaluations 27
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0165106
final function value -539.779

F = -539.779
final  value -539.778950 
converged
 
INFO  [13:15:49.005] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:15:49.066] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:15:49.074] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:16:10.667] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:16:32.526] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:16:53.610] [mlr3]  Finished benchmark 
INFO  [13:16:53.676] [bbotk] Result of batch 117: 
INFO  [13:16:53.678] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:16:53.678] [bbotk]                   7              1721       0.224199        0.655 -0.8918055 
INFO  [13:16:53.678] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:16:53.678] [bbotk]          <NA>   0.9762405 c44f9c88-e640-4eb0-9ca0-fa40cface34d 
DEBUG [13:16:54.809] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.166634e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9576 0.9910109 
  - variance bounds :  0.004166634 0.4223805 
  - best initial criterion value(s) :  453.8587 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -453.86  |proj g|=       3.5469
At iterate     1  f =      -564.12  |proj g|=     0.0085318
At iterate     2  f =      -566.65  |proj g|=       0.41821
At iterate     3  f =      -566.65  |proj g|=    1.7556e-05
At iterate     4  f =      -566.65  |proj g|=    1.7455e-05

iterations 4
function evaluations 20
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 3
norm of the final projected gradient 1.7455e-05
final function value -566.648

F = -566.648
final  value -566.647669 
converged
 
INFO  [13:16:54.813] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:16:54.869] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:16:54.876] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:17:31.161] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:18:06.836] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:18:42.412] [mlr3]  Finished benchmark 
INFO  [13:18:42.478] [bbotk] Result of batch 118: 
INFO  [13:18:42.480] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:18:42.480] [bbotk]                   3              2925      0.3478282        0.837 -0.9112477 
INFO  [13:18:42.480] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:18:42.480] [bbotk]          <NA>   0.9740891 87d52532-c276-405f-8920-df423e3c8cef 
DEBUG [13:18:43.455] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.14625e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9576 0.9910109 
  - variance bounds :  0.00414625 0.4209501 
  - best initial criterion value(s) :  443.2512 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -443.25  |proj g|=       11.993
At iterate     1  f =      -462.47  |proj g|=        2.5308
At iterate     2  f =      -497.78  |proj g|=        2.7568
At iterate     3  f =      -503.68  |proj g|=        2.5085
At iterate     4  f =      -537.22  |proj g|=        1.4962
At iterate     5  f =      -541.05  |proj g|=       0.62541
At iterate     6  f =       -541.1  |proj g|=       0.29738
At iterate     7  f =      -541.33  |proj g|=        3.4156
At iterate     8  f =      -541.73  |proj g|=        6.6253
At iterate     9  f =      -542.88  |proj g|=        12.118
At iterate    10  f =      -545.49  |proj g|=        13.142
At iterate    11  f =      -549.55  |proj g|=        13.173
At iterate    12  f =      -552.11  |proj g|=        11.362
At iterate    13  f =      -553.15  |proj g|=        1.0819
At iterate    14  f =      -553.16  |proj g|=      0.047949
At iterate    15  f =      -553.16  |proj g|=      0.016382
At iterate    16  f =      -553.16  |proj g|=      0.016382

iterations 16
function evaluations 22
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0163822
final function value -553.158

F = -553.158
final  value -553.158007 
converged
 
INFO  [13:18:43.459] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:18:43.514] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:18:43.521] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:19:06.847] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:19:30.569] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:19:55.352] [mlr3]  Finished benchmark 
INFO  [13:19:55.419] [bbotk] Result of batch 119: 
INFO  [13:19:55.421] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:19:55.421] [bbotk]                   8              1893      0.3541851        0.663 -0.8912813 
INFO  [13:19:55.421] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:19:55.421] [bbotk]          <NA>   0.9740014 34c01ed7-2c9d-42d1-af36-9cd7cdc51430 
DEBUG [13:19:56.400] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.12601e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9576 0.9910109 
  - variance bounds :  0.00412601 0.4195528 
  - best initial criterion value(s) :  490.2879 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -490.29  |proj g|=       2.7008
At iterate     1  f =       -573.8  |proj g|=     0.0089115
At iterate     2  f =      -577.65  |proj g|=       0.41543
At iterate     3  f =      -577.65  |proj g|=    3.2411e-07

iterations 3
function evaluations 20
segments explored during Cauchy searches 6
BFGS updates skipped 0
active bounds at final generalized Cauchy point 3
norm of the final projected gradient 3.24111e-07
final function value -577.652

F = -577.652
final  value -577.651946 
converged
 
INFO  [13:19:56.404] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:19:56.461] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:19:56.467] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:20:33.174] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:21:09.770] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:21:46.213] [mlr3]  Finished benchmark 
INFO  [13:21:46.290] [bbotk] Result of batch 120: 
INFO  [13:21:46.292] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:21:46.292] [bbotk]                   8              2982      0.4232974         0.67 -0.9108935 
INFO  [13:21:46.292] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:21:46.292] [bbotk]          <NA>   0.9730664 a61e2567-4045-4f00-b696-f9bdfeeaf0e9 
DEBUG [13:21:47.304] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.10578e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9576 0.9910109 
  - variance bounds :  0.00410578 0.4185447 
  - best initial criterion value(s) :  477.2838 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -477.28  |proj g|=       11.777
At iterate     1  f =      -490.93  |proj g|=        3.2355
At iterate     2  f =      -523.15  |proj g|=         2.641
At iterate     3  f =       -528.3  |proj g|=        2.4027
At iterate     4  f =      -556.86  |proj g|=        1.4733
At iterate     5  f =      -557.85  |proj g|=        1.4141
At iterate     6  f =      -559.33  |proj g|=        1.2242
At iterate     7  f =      -559.38  |proj g|=        1.0688
At iterate     8  f =      -559.51  |proj g|=         1.118
At iterate     9  f =      -559.81  |proj g|=        4.0877
At iterate    10  f =      -560.64  |proj g|=        8.9789
At iterate    11  f =      -562.63  |proj g|=        13.056
At iterate    12  f =      -567.25  |proj g|=        13.211
At iterate    13  f =       -587.5  |proj g|=        13.161
At iterate    14  f =      -591.05  |proj g|=        5.7247
At iterate    15  f =      -591.31  |proj g|=       0.61612
At iterate    16  f =      -591.31  |proj g|=      0.014902
At iterate    17  f =      -591.31  |proj g|=       0.01069
At iterate    18  f =      -591.31  |proj g|=       0.01069

iterations 18
function evaluations 25
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0106897
final function value -591.313

F = -591.313
final  value -591.312674 
converged
 
INFO  [13:21:47.308] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:21:47.360] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:21:47.367] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:22:41.851] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:23:35.364] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:24:29.694] [mlr3]  Finished benchmark 
INFO  [13:24:29.761] [bbotk] Result of batch 121: 
INFO  [13:24:29.762] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:24:29.762] [bbotk]                   4              4415    0.007364487        0.671 -0.8878013 
INFO  [13:24:29.762] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:24:29.762] [bbotk]          <NA>   0.9700411 423a8fea-4744-4bc4-83ed-3282215aaacd 
DEBUG [13:24:30.772] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.085248e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9576 0.9910109 
  - variance bounds :  0.004085248 0.4163302 
  - best initial criterion value(s) :  432.6319 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -432.63  |proj g|=       12.717
At iterate     1  f =      -467.79  |proj g|=        1.6991
At iterate     2  f =      -501.61  |proj g|=        2.6064
At iterate     3  f =         -507  |proj g|=        2.4277
At iterate     4  f =       -538.1  |proj g|=         1.437
At iterate     5  f =      -540.97  |proj g|=       0.74881
At iterate     6  f =      -541.03  |proj g|=        0.5428
At iterate     7  f =      -541.18  |proj g|=        2.9726
At iterate     8  f =      -541.48  |proj g|=        5.9428
At iterate     9  f =      -542.27  |proj g|=        10.673
At iterate    10  f =      -544.18  |proj g|=        13.104
At iterate    11  f =      -548.41  |proj g|=        13.196
At iterate    12  f =      -550.62  |proj g|=        13.079
At iterate    13  f =      -552.49  |proj g|=        1.1848
At iterate    14  f =      -552.51  |proj g|=      0.092804
At iterate    15  f =      -552.51  |proj g|=      0.020212
At iterate    16  f =      -552.51  |proj g|=      0.020212

iterations 16
function evaluations 22
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0202119
final function value -552.51

F = -552.51
final  value -552.509987 
converged
 
INFO  [13:24:30.776] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:24:30.830] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:24:30.837] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:25:10.247] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:25:48.061] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:26:26.469] [mlr3]  Finished benchmark 
INFO  [13:26:26.544] [bbotk] Result of batch 122: 
INFO  [13:26:26.546] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:26:26.546] [bbotk]                   6              3171      0.3091509        0.673 -0.8901077 
INFO  [13:26:26.546] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:26:26.546] [bbotk]          <NA>   0.9755385 db6acc4d-1b57-434a-b4a3-4119ba867fba 
DEBUG [13:26:27.550] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.065728e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9576 0.9910109 
  - variance bounds :  0.004065728 0.4151357 
  - best initial criterion value(s) :  481.263 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -481.26  |proj g|=       12.687
At iterate     1  f =         -520  |proj g|=        8.6717
At iterate     2  f =      -548.23  |proj g|=        3.0563
At iterate     3  f =       -555.7  |proj g|=        2.9772
At iterate     4  f =       -559.6  |proj g|=        2.8593
At iterate     5  f =      -572.59  |proj g|=        2.2878
At iterate     6  f =      -599.53  |proj g|=        1.3126
At iterate     7  f =      -599.97  |proj g|=        0.1328
At iterate     8  f =      -599.97  |proj g|=      0.019073
At iterate     9  f =      -599.97  |proj g|=      0.011094
At iterate    10  f =      -599.97  |proj g|=      0.011094

iterations 10
function evaluations 20
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0110941
final function value -599.972

F = -599.972
final  value -599.971541 
converged
 
INFO  [13:26:27.554] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:26:27.608] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:26:27.615] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:26:51.316] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:27:15.175] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:27:39.701] [mlr3]  Finished benchmark 
INFO  [13:27:39.778] [bbotk] Result of batch 123: 
INFO  [13:27:39.780] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:27:39.780] [bbotk]                   4              1945      0.4123796        0.687 -0.8847398 
INFO  [13:27:39.780] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:27:39.780] [bbotk]          <NA>   0.9750904 584d8e0a-32e1-4573-8d19-0efa2381ef2f 
DEBUG [13:27:40.838] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.046288e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9576 0.9910109 
  - variance bounds :  0.004046288 0.4141796 
  - best initial criterion value(s) :  476.9949 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -476.99  |proj g|=       5.5135
At iterate     1  f =      -477.26  |proj g|=        4.4649
At iterate     2  f =      -515.86  |proj g|=        4.5747
At iterate     3  f =      -525.74  |proj g|=        4.3335
At iterate     4  f =      -560.63  |proj g|=        3.3361
At iterate     5  f =      -567.54  |proj g|=        3.2585
At iterate     6  f =      -568.81  |proj g|=          3.25
At iterate     7  f =      -571.52  |proj g|=        3.1929
At iterate     8  f =      -573.07  |proj g|=        3.1168
At iterate     9  f =      -578.89  |proj g|=        2.8179
At iterate    10  f =      -590.42  |proj g|=        2.0882
At iterate    11  f =       -616.6  |proj g|=        13.066
At iterate    12  f =      -618.98  |proj g|=        3.7088
At iterate    13  f =      -619.08  |proj g|=       0.33625
At iterate    14  f =      -619.08  |proj g|=     0.0087436
At iterate    15  f =      -619.08  |proj g|=     0.0087436

iterations 15
function evaluations 23
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00874363
final function value -619.084

F = -619.084
final  value -619.083821 
converged
 
INFO  [13:27:40.842] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:27:40.913] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:27:40.926] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:28:12.361] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:28:43.432] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:29:14.161] [mlr3]  Finished benchmark 
INFO  [13:29:14.228] [bbotk] Result of batch 124: 
INFO  [13:29:14.230] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time crit.vals 
INFO  [13:29:14.230] [bbotk]                   6              2545      0.4150089        0.684 -0.882828 
INFO  [13:29:14.230] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:29:14.230] [bbotk]          <NA>    0.975457 8f7922e2-b064-4993-83e8-67f9fbcd028e 
DEBUG [13:29:15.339] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.027054e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9576 0.9910109 
  - variance bounds :  0.004027054 0.4127527 
  - best initial criterion value(s) :  369.9954 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -370  |proj g|=       3.2228
At iterate     1  f =      -475.48  |proj g|=       0.40873
At iterate     2  f =      -475.57  |proj g|=       0.04432
At iterate     3  f =      -475.57  |proj g|=      0.044342
At iterate     4  f =      -475.57  |proj g|=      0.047098
At iterate     5  f =      -475.57  |proj g|=      0.044345

iterations 5
function evaluations 8
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0443449
final function value -475.571

F = -475.571
final  value -475.571308 
converged
 
INFO  [13:29:15.343] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:29:15.406] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:29:15.412] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:29:54.770] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:30:33.121] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:31:12.143] [mlr3]  Finished benchmark 
INFO  [13:31:12.218] [bbotk] Result of batch 125: 
INFO  [13:31:12.220] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:31:12.220] [bbotk]                   5              3176      0.1815434         0.85 -0.9166823 
INFO  [13:31:12.220] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:31:12.220] [bbotk]          <NA>   0.9758568 93c6f85b-9d29-49e0-bf79-41e6144aba8a 
DEBUG [13:31:13.232] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.008027e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9576 0.9910109 
  - variance bounds :  0.004008027 0.4112982 
  - best initial criterion value(s) :  429.0758 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -429.08  |proj g|=       12.763
At iterate     1  f =      -482.97  |proj g|=        5.1396
At iterate     2  f =      -523.66  |proj g|=        3.3517
At iterate     3  f =      -541.13  |proj g|=         3.123
At iterate     4  f =      -560.45  |proj g|=        2.7841
At iterate     5  f =      -565.37  |proj g|=        2.6085
At iterate     6  f =      -582.81  |proj g|=        1.8841
At iterate     7  f =      -594.31  |proj g|=        13.255
At iterate     8  f =      -600.45  |proj g|=        5.2532
At iterate     9  f =      -600.66  |proj g|=       0.81298
At iterate    10  f =      -600.66  |proj g|=      0.017375
At iterate    11  f =      -600.66  |proj g|=      0.014878
At iterate    12  f =      -600.66  |proj g|=      0.014878

iterations 12
function evaluations 20
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0148783
final function value -600.662

F = -600.662
final  value -600.661558 
converged
 
INFO  [13:31:13.237] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:31:13.292] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:31:13.299] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:31:23.958] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:31:35.025] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:31:46.161] [mlr3]  Finished benchmark 
INFO  [13:31:46.246] [bbotk] Result of batch 126: 
INFO  [13:31:46.248] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:31:46.248] [bbotk]                   6               784      0.4281601        0.678 -0.8862381 
INFO  [13:31:46.248] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:31:46.248] [bbotk]          <NA>   0.9762244 19a7d65f-af69-4b8d-b2eb-7de283983f8e 
DEBUG [13:31:47.275] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.989201e-10 
  - parameters lower bounds :  1e-10 1e-10 1e-10 
  - parameters upper bounds :  14 9576 0.9910109 
  - variance bounds :  0.003989201 0.4082485 
  - best initial criterion value(s) :  494.0229 

N = 4, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -494.02  |proj g|=       12.704
At iterate     1  f =      -517.44  |proj g|=       0.75963
At iterate     2  f =      -551.09  |proj g|=        2.1619
At iterate     3  f =       -553.7  |proj g|=          2.04
At iterate     4  f =      -571.29  |proj g|=        1.4411
At iterate     5  f =      -573.36  |proj g|=        1.3063
At iterate     6  f =      -574.08  |proj g|=        0.1265
At iterate     7  f =      -574.09  |proj g|=       0.53358
At iterate     8  f =      -574.11  |proj g|=        1.2764
At iterate     9  f =      -574.16  |proj g|=        2.6482
At iterate    10  f =       -574.3  |proj g|=        4.7364
At iterate    11  f =      -574.67  |proj g|=         7.761
At iterate    12  f =      -574.84  |proj g|=        6.0884
At iterate    13  f =      -575.11  |proj g|=       0.17922
At iterate    14  f =      -575.11  |proj g|=      0.022258
At iterate    15  f =      -575.11  |proj g|=      0.022258

iterations 15
function evaluations 22
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0222582
final function value -575.112

F = -575.112
final  value -575.111693 
converged
 
INFO  [13:31:47.279] [bbotk] Evaluating 1 configuration(s) 
INFO  [13:31:47.334] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [13:31:47.342] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 3/3) 
INFO  [13:31:56.695] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 2/3) 
INFO  [13:32:05.788] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_gamboost' on task 'spam' (iter 1/3) 
INFO  [13:32:15.215] [mlr3]  Finished benchmark 
INFO  [13:32:15.292] [bbotk] Result of batch 127: 
INFO  [13:32:15.294] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu propose.time  crit.vals 
INFO  [13:32:15.294] [bbotk]                   5               681      0.4393814        0.691 -0.8894266 
INFO  [13:32:15.294] [bbotk]  errors.model classif.auc                                uhash 
INFO  [13:32:15.294] [bbotk]          <NA>   0.9759293 1ac54455-f8d4-4b7a-95a4-42d11696a703 
DEBUG [13:32:15.364] [bbotk]  
INFO  [13:32:15.377] [bbotk] Finished optimizing after 150 evaluation(s) 
INFO  [13:32:15.379] [bbotk] Result: 
INFO  [13:32:15.381] [bbotk]  ps_gamboost.dfbase ps_gamboost.mstop ps_gamboost.nu learner_param_vals 
INFO  [13:32:15.381] [bbotk]                   7              1263      0.1881177         <list[15]> 
INFO  [13:32:15.381] [bbotk]   x_domain classif.auc 
INFO  [13:32:15.381] [bbotk]  <list[3]>   0.9763786 
INFO  [13:32:36.346] [mlr3]  Finished benchmark 

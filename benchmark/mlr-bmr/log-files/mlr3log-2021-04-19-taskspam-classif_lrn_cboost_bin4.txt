INFO  [04:27:47.465] [mlr3]  Running benchmark with 5 resampling iterations 
INFO  [04:27:47.566] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2.tuned' on task 'spam' (iter 4/5) 
INFO  [04:27:47.745] [bbotk] Starting to optimize 4 parameter(s) with '<OptimizerInterMBO>' and '<TerminatorEvals> [n_evals=200]' 
DEBUG [04:27:48.477] [bbotk]  
INFO  [04:27:48.497] [bbotk] Evaluating 32 configuration(s) 
INFO  [04:27:50.941] [mlr3]  Running benchmark with 96 resampling iterations 
INFO  [04:27:50.958] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:27:59.788] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:28:06.211] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:28:09.444] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:28:16.261] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:28:17.980] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:28:32.162] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:28:38.666] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:28:47.755] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:28:50.429] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:28:57.677] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:29:08.748] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:29:10.330] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:29:19.428] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:29:29.171] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:29:41.282] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:29:50.445] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:29:57.003] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:29:59.678] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:30:11.477] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:30:19.173] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:30:20.592] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:30:26.286] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:30:31.585] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:30:36.481] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:30:42.214] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:30:45.031] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:30:54.259] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:30:57.217] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:31:02.557] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:31:15.167] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:31:23.065] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:31:28.107] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:31:34.317] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:31:37.114] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:31:41.682] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:31:52.135] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:31:58.623] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:32:02.857] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:32:04.389] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:32:11.284] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:32:17.032] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:32:23.314] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:32:24.886] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:32:27.717] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:32:28.646] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:32:32.155] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:32:33.478] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:32:35.755] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:32:43.013] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:32:49.930] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:32:54.818] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:32:57.366] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:32:59.869] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:33:06.096] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:33:11.480] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:33:12.662] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:33:23.709] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:33:26.539] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:33:29.520] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:33:30.590] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:33:33.645] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:33:35.396] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:33:42.976] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:33:46.214] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:33:51.792] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:34:02.096] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:34:02.986] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:34:04.201] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:34:13.021] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:34:19.016] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:34:29.048] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:34:34.420] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:34:40.576] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:34:46.241] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:34:52.217] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:34:57.045] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:35:08.719] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:35:21.319] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:35:28.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:35:32.426] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:35:43.130] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:35:47.631] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:35:55.593] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:36:01.976] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:36:10.884] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:36:14.366] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:36:15.938] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:36:27.283] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:36:37.614] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:36:42.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:36:47.624] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:36:49.460] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:36:56.586] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:36:59.853] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:37:03.276] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:37:13.722] [mlr3]  Finished benchmark 
INFO  [04:37:16.376] [bbotk] Result of batch 1: 
INFO  [04:37:16.380] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:37:16.380] [bbotk]              4.152874                 8.959057                     0.168180978 
INFO  [04:37:16.380] [bbotk]              4.819695                 6.618220                     0.085913133 
INFO  [04:37:16.380] [bbotk]              5.552188                 8.444031                     0.462831400 
INFO  [04:37:16.380] [bbotk]              6.493104                 6.784911                     0.293487833 
INFO  [04:37:16.380] [bbotk]              7.344239                 5.031688                     0.392523442 
INFO  [04:37:16.380] [bbotk]              4.696148                 4.013402                     0.326326890 
INFO  [04:37:16.380] [bbotk]              8.536073                 3.530680                     0.377190753 
INFO  [04:37:16.380] [bbotk]              3.106622                 7.311592                     0.099607948 
INFO  [04:37:16.380] [bbotk]              9.083282                 8.669608                     0.238282478 
INFO  [04:37:16.380] [bbotk]              7.162224                 7.021630                     0.416587132 
INFO  [04:37:16.380] [bbotk]              5.986315                 3.403962                     0.234176299 
INFO  [04:37:16.380] [bbotk]              2.800148                 9.843598                     0.436498176 
INFO  [04:37:16.380] [bbotk]              9.350186                 5.480585                     0.141810995 
INFO  [04:37:16.380] [bbotk]              6.863931                 5.741304                     0.193337259 
INFO  [04:37:16.380] [bbotk]              8.310616                 8.077128                     0.019601991 
INFO  [04:37:16.380] [bbotk]              5.183952                 3.080761                     0.128141096 
INFO  [04:37:16.380] [bbotk]              6.724025                 4.741754                     0.471906857 
INFO  [04:37:16.380] [bbotk]              3.676510                 5.858597                     0.208586580 
INFO  [04:37:16.380] [bbotk]              5.495065                 9.141424                     0.184020680 
INFO  [04:37:16.380] [bbotk]              6.061086                 4.826894                     0.114884249 
INFO  [04:37:16.380] [bbotk]              8.068744                 2.683896                     0.304687116 
INFO  [04:37:16.380] [bbotk]              2.050413                 3.790852                     0.055034365 
INFO  [04:37:16.380] [bbotk]              2.695118                 4.340108                     0.443071272 
INFO  [04:37:16.380] [bbotk]              9.973115                 6.200862                     0.251814492 
INFO  [04:37:16.380] [bbotk]              3.386641                 6.343807                     0.270232046 
INFO  [04:37:16.380] [bbotk]              2.410865                 2.426261                     0.337928873 
INFO  [04:37:16.380] [bbotk]              9.604876                 9.290427                     0.033996118 
INFO  [04:37:16.380] [bbotk]              8.925028                 2.759242                     0.008841257 
INFO  [04:37:16.380] [bbotk]              7.637683                 7.576833                     0.365019013 
INFO  [04:37:16.380] [bbotk]              3.789919                 7.779337                     0.484604679 
INFO  [04:37:16.380] [bbotk]              7.963314                 2.034819                     0.349922121 
INFO  [04:37:16.380] [bbotk]              4.287181                 9.502664                     0.064141008 
INFO  [04:37:16.380] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:37:16.380] [bbotk]  ps_cboost_anneal2.mstop classif.auc                                uhash 
INFO  [04:37:16.380] [bbotk]                     1228   0.9653148 734c9095-b942-43a3-a629-40c00810b33e 
INFO  [04:37:16.380] [bbotk]                     3893   0.9705012 8781d6e6-88e8-488e-9f5b-971ba1d57133 
INFO  [04:37:16.380] [bbotk]                     2440   0.9756187 f2687f43-0448-4871-829d-c6d5a7b1fdaf 
INFO  [04:37:16.380] [bbotk]                     1615   0.9733399 d8730416-206d-4fbe-a192-7c7775bf8db4 
INFO  [04:37:16.380] [bbotk]                     3671   0.9759968 ad79c850-a5a0-46bc-aae0-f21182a8e67e 
INFO  [04:37:16.380] [bbotk]                     4397   0.9757061 a22fb16b-2fe1-4297-b74c-d71178d9c458 
INFO  [04:37:16.380] [bbotk]                     2113   0.9752682 b75ed1f3-a2ab-4d76-8a17-07ec4b44ba13 
INFO  [04:37:16.380] [bbotk]                     3977   0.9651381 de0b1a8f-206d-468c-83bd-01fabbb9a818 
INFO  [04:37:16.380] [bbotk]                     1021   0.9709469 62df8627-0149-4438-a80d-a9ce2c8e8e6c 
INFO  [04:37:16.380] [bbotk]                     1985   0.9749255 32d84576-d416-4b7d-95d0-c7b4e464003c 
INFO  [04:37:16.380] [bbotk]                      689   0.9664031 19fc1322-16ab-4052-a870-d4355ec4f273 
INFO  [04:37:16.380] [bbotk]                     3557   0.9703766 ede6e4f0-376b-4ab9-bf48-bbb0b00a507c 
INFO  [04:37:16.380] [bbotk]                     2764   0.9735603 1a1e62f4-cf07-4140-bd7f-2cc58133a56b 
INFO  [04:37:16.380] [bbotk]                     4996   0.9750939 42046c54-058f-4977-955a-afb37f6b8e41 
INFO  [04:37:16.380] [bbotk]                     3338   0.9588611 7d3c6dcf-8328-4235-b481-c46b74261144 
INFO  [04:37:16.380] [bbotk]                     4425   0.9733513 e8c1095e-57be-44fb-b80c-53528c1bb279 
INFO  [04:37:16.380] [bbotk]                     2190   0.9752375 29c15f20-6c28-42ae-ba7c-f6c98e65c67a 
INFO  [04:37:16.380] [bbotk]                      913   0.9624346 a69cb6ca-4269-438f-b8c8-87cac10826c9 
INFO  [04:37:16.380] [bbotk]                     1525   0.9703532 08a73ed6-c9de-4685-ae61-a674866e7620 
INFO  [04:37:16.380] [bbotk]                     2573   0.9710742 18e0f6ff-09e6-4171-827d-29df13a7556e 
INFO  [04:37:16.380] [bbotk]                     4229   0.9759459 69e8f26d-4bbb-4c5f-a198-80e3dfeb711b 
INFO  [04:37:16.380] [bbotk]                     2601   0.9381711 d2a5eee2-486c-4ef4-a451-5007ebbff010 
INFO  [04:37:16.380] [bbotk]                      373   0.9494848 bf90d391-9c76-4996-847c-588d3e837a98 
INFO  [04:37:16.380] [bbotk]                     1308   0.9726198 7a65553a-340c-485c-ba96-840877507f15 
INFO  [04:37:16.380] [bbotk]                     4644   0.9731441 82e29d40-964d-4af3-82a7-14175422be00 
INFO  [04:37:16.380] [bbotk]                     2966   0.9635847 ebd9b7c7-a8da-4ba2-bb5b-0d34ea070c26 
INFO  [04:37:16.380] [bbotk]                      549   0.9362228 fbd63eb7-da8c-4405-843f-4ef111b28798 
INFO  [04:37:16.380] [bbotk]                     3051   0.9451207 213e955c-e7d7-48b3-95ba-7d66de98e514 
INFO  [04:37:16.380] [bbotk]                     4781   0.9763538 6ee2f6b4-1f82-4006-a82e-430e7227bc19 
INFO  [04:37:16.380] [bbotk]                     1800   0.9731093 619f1f95-dcb9-4aeb-a5a1-b90cbf1f0698 
INFO  [04:37:16.380] [bbotk]                      273   0.9624090 24b8d37b-140b-4ea8-b61d-345bbb0b8685 
INFO  [04:37:16.380] [bbotk]                     3444   0.9663699 4f0c7295-2ccc-4a7d-9bb0-8f46e5bab629 
INFO  [04:37:16.380] [bbotk]  ps_cboost_anneal2.mstop classif.auc                                uhash 
DEBUG [04:37:18.140] [bbotk]  
DEBUG [04:37:18.144] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.177128e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.177128e-05 0.001206676 
  - best initial criterion value(s) :  107.5902 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -107.59  |proj g|=       1.4918
At iterate     1  f =      -109.53  |proj g|=        1.8207
At iterate     2  f =      -110.21  |proj g|=        1.9592
At iterate     3  f =      -110.33  |proj g|=        1.9244
At iterate     4  f =      -110.38  |proj g|=        1.8529
At iterate     5  f =      -110.39  |proj g|=        1.8726
At iterate     6  f =      -110.39  |proj g|=        1.8693
At iterate     7  f =      -110.39  |proj g|=        1.8682
At iterate     8  f =      -110.39  |proj g|=        1.8678
At iterate     9  f =      -110.39  |proj g|=        1.8679
At iterate    10  f =      -110.39  |proj g|=        1.8681
At iterate    11  f =      -110.39  |proj g|=        1.8683
At iterate    12  f =      -110.39  |proj g|=        1.8686
At iterate    13  f =      -110.39  |proj g|=         1.869
At iterate    14  f =      -110.39  |proj g|=        1.8695
At iterate    15  f =      -110.39  |proj g|=        1.8695
At iterate    16  f =      -110.39  |proj g|=        1.8676
At iterate    17  f =      -110.39  |proj g|=        1.8634
At iterate    18  f =      -110.39  |proj g|=        1.8626
At iterate    19  f =      -110.39  |proj g|=        1.8554
At iterate    20  f =      -110.41  |proj g|=        1.8353
At iterate    21  f =      -110.43  |proj g|=        1.8055
At iterate    22  f =      -110.49  |proj g|=         1.744
At iterate    23  f =      -110.64  |proj g|=        1.6361
At iterate    24  f =      -110.97  |proj g|=        1.4637
At iterate    25  f =      -111.71  |proj g|=        1.2052
At iterate    26  f =      -113.07  |proj g|=       0.88222
At iterate    27  f =       -114.8  |proj g|=       0.52148
At iterate    28  f =      -116.73  |proj g|=       0.50314
At iterate    29  f =      -117.92  |proj g|=       0.59861
At iterate    30  f =      -118.79  |proj g|=        0.7432
At iterate    31  f =      -118.84  |proj g|=        0.7341
At iterate    32  f =      -118.85  |proj g|=       0.71203
At iterate    33  f =      -118.85  |proj g|=       0.71167
At iterate    34  f =      -118.85  |proj g|=       0.71182
At iterate    35  f =      -118.85  |proj g|=       0.71182

iterations 35
function evaluations 38
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.71182
final function value -118.845

F = -118.845
final  value -118.845144 
converged
 
INFO  [04:37:18.148] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:37:18.235] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:37:18.242] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:37:23.332] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:37:30.579] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:37:37.641] [mlr3]  Finished benchmark 
INFO  [04:37:37.742] [bbotk] Result of batch 2: 
INFO  [04:37:37.744] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:37:37.744] [bbotk]              8.471689                  8.99554                       0.4734656 
INFO  [04:37:37.744] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:37:37.744] [bbotk]                     2311        0.634 -0.9632149         <NA>   0.9757002 
INFO  [04:37:37.744] [bbotk]                                 uhash 
INFO  [04:37:37.744] [bbotk]  ad85ecf4-12dc-4036-8ff3-c1cf8f86e4b5 
DEBUG [04:37:38.727] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.161975e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.161975e-05 0.001191466 
  - best initial criterion value(s) :  122.0879 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -122.09  |proj g|=      0.83114
At iterate     1  f =      -122.25  |proj g|=       0.96345
At iterate     2  f =      -122.31  |proj g|=       0.93143
At iterate     3  f =      -122.36  |proj g|=       0.91402
At iterate     4  f =      -122.36  |proj g|=       0.93257
At iterate     5  f =      -122.36  |proj g|=       0.92946
At iterate     6  f =      -122.36  |proj g|=       0.92933

iterations 6
function evaluations 11
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.929331
final function value -122.362

F = -122.362
final  value -122.362083 
converged
 
INFO  [04:37:38.730] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:37:38.820] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:37:38.827] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:37:40.265] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:37:42.021] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:37:44.820] [mlr3]  Finished benchmark 
INFO  [04:37:44.922] [bbotk] Result of batch 3: 
INFO  [04:37:44.924] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:37:44.924] [bbotk]              3.635566                 2.939693                       0.3567618 
INFO  [04:37:44.924] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:37:44.924] [bbotk]                      477        0.619 -0.9646019         <NA>   0.9609825 
INFO  [04:37:44.924] [bbotk]                                 uhash 
INFO  [04:37:44.924] [bbotk]  41aba641-20c6-4255-b7f3-b939b9fa5103 
DEBUG [04:37:45.841] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.139285e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.139285e-05 0.001181924 
  - best initial criterion value(s) :  119.4082 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -119.41  |proj g|=      0.82918
At iterate     1  f =      -119.76  |proj g|=        1.2746
At iterate     2  f =      -120.91  |proj g|=        1.0982
At iterate     3  f =      -121.11  |proj g|=       0.97599
At iterate     4  f =      -121.41  |proj g|=        1.0195
At iterate     5  f =      -121.49  |proj g|=        1.0185
At iterate     6  f =      -121.49  |proj g|=        1.0301
At iterate     7  f =       -121.5  |proj g|=         1.025
At iterate     8  f =       -121.5  |proj g|=        1.0255
At iterate     9  f =       -121.5  |proj g|=        1.0254
At iterate    10  f =       -121.5  |proj g|=        1.0253
At iterate    11  f =       -121.5  |proj g|=        1.0251
At iterate    12  f =       -121.5  |proj g|=        1.0247
At iterate    13  f =       -121.5  |proj g|=        1.0241
At iterate    14  f =       -121.5  |proj g|=        1.0232
At iterate    15  f =       -121.5  |proj g|=        1.0213
At iterate    16  f =       -121.5  |proj g|=        1.0206
At iterate    17  f =       -121.5  |proj g|=        1.0144
At iterate    18  f =      -121.51  |proj g|=        1.0127
At iterate    19  f =      -121.55  |proj g|=        0.9989
At iterate    20  f =      -121.67  |proj g|=       0.96173
At iterate    21  f =      -122.06  |proj g|=       0.84915
At iterate    22  f =      -123.12  |proj g|=       0.76991
At iterate    23  f =      -123.61  |proj g|=       0.77566
At iterate    24  f =      -125.75  |proj g|=       0.72827
At iterate    25  f =      -126.15  |proj g|=       0.70679
At iterate    26  f =      -126.41  |proj g|=        0.3118
At iterate    27  f =      -126.42  |proj g|=       0.31305
At iterate    28  f =      -126.43  |proj g|=       0.28434
At iterate    29  f =      -126.43  |proj g|=       0.28629
At iterate    30  f =      -126.43  |proj g|=       0.28632
At iterate    31  f =      -126.43  |proj g|=       0.28629

iterations 31
function evaluations 40
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.286286
final function value -126.427

F = -126.427
final  value -126.426655 
converged
 
INFO  [04:37:45.845] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:37:45.992] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:37:45.999] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:37:53.850] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:37:58.404] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:38:05.201] [mlr3]  Finished benchmark 
INFO  [04:38:05.303] [bbotk] Result of batch 4: 
INFO  [04:38:05.305] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:38:05.305] [bbotk]              3.707933                 9.282808                       0.1829142 
INFO  [04:38:05.305] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:38:05.305] [bbotk]                     2373        0.651 -0.9627561         <NA>   0.9695952 
INFO  [04:38:05.305] [bbotk]                                 uhash 
INFO  [04:38:05.305] [bbotk]  e93046d5-4e2f-4169-a225-f813ca72b6e3 
DEBUG [04:38:06.014] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.107261e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.107261e-05 0.001147225 
  - best initial criterion value(s) :  124.0022 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -124  |proj g|=      0.87191
At iterate     1  f =      -126.59  |proj g|=       0.61603
At iterate     2  f =      -127.39  |proj g|=       0.72594
At iterate     3  f =      -127.61  |proj g|=       0.72997
At iterate     4  f =      -127.78  |proj g|=       0.55943
At iterate     5  f =      -127.78  |proj g|=       0.37199
At iterate     6  f =      -127.78  |proj g|=       0.37277
At iterate     7  f =      -127.78  |proj g|=       0.37305
At iterate     8  f =      -127.78  |proj g|=       0.37318
At iterate     9  f =      -127.78  |proj g|=       0.37317
At iterate    10  f =      -127.78  |proj g|=       0.37316

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.37316
final function value -127.784

F = -127.784
final  value -127.784381 
converged
 
INFO  [04:38:06.018] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:38:06.110] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:38:06.134] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:38:14.483] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:38:21.754] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:38:29.781] [mlr3]  Finished benchmark 
INFO  [04:38:29.882] [bbotk] Result of batch 5: 
INFO  [04:38:29.884] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:38:29.884] [bbotk]              5.380889                 9.822874                       0.3450262 
INFO  [04:38:29.884] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:38:29.884] [bbotk]                     3214        0.515 -0.9667583         <NA>    0.975531 
INFO  [04:38:29.884] [bbotk]                                 uhash 
INFO  [04:38:29.884] [bbotk]  c9ad7bb4-9db9-4803-86ca-4dab1203ac61 
DEBUG [04:38:30.793] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.094079e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.094079e-05 0.001172096 
  - best initial criterion value(s) :  126.4464 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -126.45  |proj g|=       1.1537
At iterate     1  f =      -126.58  |proj g|=        1.2438
At iterate     2  f =      -126.66  |proj g|=        1.2216
At iterate     3  f =      -126.75  |proj g|=        1.1724
At iterate     4  f =      -126.78  |proj g|=        1.1691
At iterate     5  f =      -126.79  |proj g|=        1.1676
At iterate     6  f =      -126.79  |proj g|=        1.1671
At iterate     7  f =      -126.79  |proj g|=        1.1671
At iterate     8  f =      -126.79  |proj g|=        1.1671

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.16709
final function value -126.794

F = -126.794
final  value -126.794395 
converged
 
INFO  [04:38:30.798] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:38:30.887] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:38:30.907] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:38:42.624] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:38:52.602] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:39:02.470] [mlr3]  Finished benchmark 
INFO  [04:39:02.570] [bbotk] Result of batch 6: 
INFO  [04:39:02.571] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:39:02.571] [bbotk]              4.009185                 6.248174                      0.07845961 
INFO  [04:39:02.571] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:39:02.571] [bbotk]                     4789        0.647 -0.9688988         <NA>   0.9697745 
INFO  [04:39:02.571] [bbotk]                                 uhash 
INFO  [04:39:02.571] [bbotk]  9e491a9d-32ca-47fe-9189-487c1f674d89 
DEBUG [04:39:03.449] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.064958e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.064958e-05 0.001122934 
  - best initial criterion value(s) :  129.2755 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -129.28  |proj g|=       1.4651
At iterate     1  f =      -133.21  |proj g|=        1.4065
At iterate     2  f =      -133.76  |proj g|=        1.3244
At iterate     3  f =       -134.2  |proj g|=        1.1607
At iterate     4  f =      -134.21  |proj g|=        1.0886
At iterate     5  f =      -134.22  |proj g|=        1.1104
At iterate     6  f =      -134.22  |proj g|=        1.1091
At iterate     7  f =      -134.22  |proj g|=        1.1035
At iterate     8  f =      -134.22  |proj g|=         1.101
At iterate     9  f =      -134.22  |proj g|=        1.1023
At iterate    10  f =      -134.22  |proj g|=        1.1038
At iterate    11  f =      -134.22  |proj g|=        1.1041
At iterate    12  f =      -134.22  |proj g|=        1.1041

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.10415
final function value -134.219

F = -134.219
final  value -134.219183 
converged
 
INFO  [04:39:03.453] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:39:03.555] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:39:03.562] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:39:14.402] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:39:26.365] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:39:39.653] [mlr3]  Finished benchmark 
INFO  [04:39:39.749] [bbotk] Result of batch 7: 
INFO  [04:39:39.751] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:39:39.751] [bbotk]              9.298708                 4.331201                      0.08033476 
INFO  [04:39:39.751] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:39:39.751] [bbotk]                     4599        0.509 -0.9643771         <NA>   0.9732495 
INFO  [04:39:39.751] [bbotk]                                 uhash 
INFO  [04:39:39.751] [bbotk]  e74e2d1c-94b6-49f4-89da-3801d77964e5 
DEBUG [04:39:40.449] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.044381e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.044381e-05 0.001127364 
  - best initial criterion value(s) :  128.9092 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -128.91  |proj g|=      0.72955
At iterate     1  f =      -132.04  |proj g|=        1.9196
At iterate     2  f =      -132.09  |proj g|=        1.8767
At iterate     3  f =      -132.16  |proj g|=        1.7405
At iterate     4  f =       -132.3  |proj g|=        1.6983
At iterate     5  f =      -132.64  |proj g|=        1.3498
At iterate     6  f =      -132.71  |proj g|=        1.4854
At iterate     7  f =      -132.72  |proj g|=        1.4464
At iterate     8  f =      -132.72  |proj g|=        1.4478
At iterate     9  f =      -132.72  |proj g|=        1.4472
At iterate    10  f =      -132.72  |proj g|=         1.447
At iterate    11  f =      -132.72  |proj g|=        1.4463
At iterate    12  f =      -132.72  |proj g|=         1.445
At iterate    13  f =      -132.72  |proj g|=         1.443
At iterate    14  f =      -132.72  |proj g|=        1.4394
At iterate    15  f =      -132.72  |proj g|=         1.434
At iterate    16  f =      -132.72  |proj g|=        1.4241
At iterate    17  f =      -132.72  |proj g|=        1.4118
At iterate    18  f =      -132.72  |proj g|=        1.3997
At iterate    19  f =      -132.73  |proj g|=        1.3834
At iterate    20  f =      -132.79  |proj g|=        1.3292
At iterate    21  f =      -133.37  |proj g|=        1.0605
At iterate    22  f =      -135.36  |proj g|=       0.88719
At iterate    23  f =      -136.03  |proj g|=        1.0545
At iterate    24  f =      -136.51  |proj g|=        1.1764
At iterate    25  f =      -136.94  |proj g|=         1.389
At iterate    26  f =      -137.26  |proj g|=        1.3127
At iterate    27  f =      -137.38  |proj g|=        1.1021
At iterate    28  f =      -137.49  |proj g|=        1.1357
At iterate    29  f =      -137.49  |proj g|=        1.1283
At iterate    30  f =      -137.49  |proj g|=        1.1272
At iterate    31  f =      -137.49  |proj g|=        1.1266
At iterate    32  f =      -137.49  |proj g|=        1.1268

iterations 32
function evaluations 43
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.12676
final function value -137.487

F = -137.487
final  value -137.487092 
converged
 
INFO  [04:39:40.453] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:39:40.555] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:39:40.561] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:39:54.517] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:40:04.823] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:40:14.614] [mlr3]  Finished benchmark 
INFO  [04:40:14.724] [bbotk] Result of batch 8: 
INFO  [04:40:14.725] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:40:14.725] [bbotk]              8.054318                 7.683593                        0.292585 
INFO  [04:40:14.725] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:40:14.725] [bbotk]                     4264         0.49 -0.9664862         <NA>   0.9758838 
INFO  [04:40:14.725] [bbotk]                                 uhash 
INFO  [04:40:14.725] [bbotk]  35aabb85-8645-4443-afd3-f3ba2e7d451b 
DEBUG [04:40:15.421] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.033602e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.033602e-05 0.001131927 
  - best initial criterion value(s) :  139.4557 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -139.46  |proj g|=       1.0091
At iterate     1  f =      -141.76  |proj g|=       0.93076
At iterate     2  f =      -142.96  |proj g|=       0.90255
At iterate     3  f =       -144.3  |proj g|=       0.79223
At iterate     4  f =      -144.35  |proj g|=       0.76016
At iterate     5  f =      -144.35  |proj g|=       0.75903
At iterate     6  f =      -144.35  |proj g|=         0.756
At iterate     7  f =      -144.35  |proj g|=       0.75458
At iterate     8  f =      -144.35  |proj g|=       0.75576
At iterate     9  f =      -144.35  |proj g|=        0.7565
At iterate    10  f =      -144.35  |proj g|=       0.75662
At iterate    11  f =      -144.35  |proj g|=       0.75663

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.756631
final function value -144.35

F = -144.35
final  value -144.350466 
converged
 
INFO  [04:40:15.425] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:40:15.510] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:40:15.516] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:40:24.891] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:40:33.283] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:40:42.978] [mlr3]  Finished benchmark 
INFO  [04:40:43.102] [bbotk] Result of batch 9: 
INFO  [04:40:43.104] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:40:43.104] [bbotk]              7.906805                 7.830098                       0.2035971 
INFO  [04:40:43.104] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:40:43.104] [bbotk]                     3732        0.483 -0.9665851         <NA>   0.9751167 
INFO  [04:40:43.104] [bbotk]                                 uhash 
INFO  [04:40:43.104] [bbotk]  c0ba3ef9-3ab9-44fe-b454-580e8e65de1c 
DEBUG [04:40:43.820] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.019692e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.019692e-05 0.001114181 
  - best initial criterion value(s) :  148.4381 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -148.44  |proj g|=      0.60619
At iterate     1  f =      -149.37  |proj g|=       0.76121
At iterate     2  f =      -149.38  |proj g|=       0.76045
At iterate     3  f =      -149.39  |proj g|=       0.75936
At iterate     4  f =      -149.39  |proj g|=        0.7583
At iterate     5  f =      -149.41  |proj g|=       0.75296
At iterate     6  f =      -149.44  |proj g|=        0.7451
At iterate     7  f =      -149.47  |proj g|=       0.75065
At iterate     8  f =      -149.48  |proj g|=       0.75174
At iterate     9  f =      -149.48  |proj g|=       0.75223
At iterate    10  f =      -149.48  |proj g|=       0.75233
At iterate    11  f =      -149.48  |proj g|=       0.75249
At iterate    12  f =      -149.48  |proj g|=       0.75265
At iterate    13  f =      -149.48  |proj g|=       0.75276
At iterate    14  f =      -149.48  |proj g|=        0.7533
At iterate    15  f =      -149.48  |proj g|=       0.75336
At iterate    16  f =      -149.48  |proj g|=       0.75355
At iterate    17  f =      -149.48  |proj g|=        0.7536
At iterate    18  f =      -149.49  |proj g|=       0.75278
At iterate    19  f =      -149.51  |proj g|=       0.74868
At iterate    20  f =      -149.54  |proj g|=       0.71987
At iterate    21  f =      -149.61  |proj g|=       0.71348
At iterate    22  f =      -149.85  |proj g|=       0.67353
At iterate    23  f =      -150.42  |proj g|=       0.57233
At iterate    24  f =      -150.98  |proj g|=       0.45521
At iterate    25  f =      -151.28  |proj g|=       0.49477
At iterate    26  f =      -151.28  |proj g|=       0.48461
At iterate    27  f =      -151.43  |proj g|=       0.52657
At iterate    28  f =      -151.46  |proj g|=       0.73172
At iterate    29  f =      -151.46  |proj g|=       0.43013
At iterate    30  f =      -151.46  |proj g|=       0.43217
At iterate    31  f =      -151.46  |proj g|=       0.43241
At iterate    32  f =      -151.46  |proj g|=       0.43228

iterations 32
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.432282
final function value -151.464

F = -151.464
final  value -151.464329 
converged
 
INFO  [04:40:43.825] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:40:43.912] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:40:43.919] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:40:48.014] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:40:51.288] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:40:54.418] [mlr3]  Finished benchmark 
INFO  [04:40:54.515] [bbotk] Result of batch 10: 
INFO  [04:40:54.517] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:40:54.517] [bbotk]              9.126417                 4.035766                        0.351168 
INFO  [04:40:54.517] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:40:54.517] [bbotk]                     1541        0.489 -0.9667027         <NA>   0.9744192 
INFO  [04:40:54.517] [bbotk]                                 uhash 
INFO  [04:40:54.517] [bbotk]  5d2e8213-7a6a-4bf9-9fc1-ebcfb20940a5 
DEBUG [04:40:55.205] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.003643e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.003643e-05 0.001076299 
  - best initial criterion value(s) :  150.5884 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -150.59  |proj g|=      0.83983
At iterate     1  f =      -152.74  |proj g|=       0.95153
At iterate     2  f =      -153.86  |proj g|=       0.84181
At iterate     3  f =      -155.08  |proj g|=       0.82992
At iterate     4  f =      -156.44  |proj g|=       0.54324
At iterate     5  f =      -157.21  |proj g|=       0.53257
At iterate     6  f =      -158.12  |proj g|=       0.46942
At iterate     7  f =      -158.81  |proj g|=        0.3504
At iterate     8  f =      -159.09  |proj g|=       0.31012
At iterate     9  f =      -159.09  |proj g|=        0.3217
At iterate    10  f =       -159.1  |proj g|=       0.19748
At iterate    11  f =       -159.1  |proj g|=       0.17124
At iterate    12  f =       -159.1  |proj g|=       0.17138

iterations 12
function evaluations 16
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.171383
final function value -159.098

F = -159.098
final  value -159.097556 
converged
 
INFO  [04:40:55.209] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:40:55.296] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:40:55.303] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:41:01.966] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:41:09.929] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:41:16.849] [mlr3]  Finished benchmark 
INFO  [04:41:16.950] [bbotk] Result of batch 11: 
INFO  [04:41:16.952] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:41:16.952] [bbotk]              9.928964                 5.073277                       0.1337915 
INFO  [04:41:16.952] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:41:16.952] [bbotk]                     3044        0.502 -0.9634522         <NA>   0.9735328 
INFO  [04:41:16.952] [bbotk]                                 uhash 
INFO  [04:41:16.952] [bbotk]  09f6243c-cf9f-423e-9dbd-140ec36d9513 
DEBUG [04:41:17.664] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.855634e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  9.855634e-06 0.001061485 
  - best initial criterion value(s) :  154.1903 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -154.19  |proj g|=      0.38807
At iterate     1  f =      -156.88  |proj g|=        2.0738
At iterate     2  f =      -158.19  |proj g|=         1.923
At iterate     3  f =      -159.89  |proj g|=        1.3964
At iterate     4  f =      -159.91  |proj g|=        1.3198
At iterate     5  f =      -159.92  |proj g|=        1.3163
At iterate     6  f =      -159.94  |proj g|=        1.3419
At iterate     7  f =      -159.94  |proj g|=        1.3467
At iterate     8  f =      -159.94  |proj g|=        1.3435
At iterate     9  f =      -159.94  |proj g|=        1.3436

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.34355
final function value -159.94

F = -159.94
final  value -159.939794 
converged
 
INFO  [04:41:17.669] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:41:17.753] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:41:17.760] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:41:26.572] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:41:37.394] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:41:45.511] [mlr3]  Finished benchmark 
INFO  [04:41:45.673] [bbotk] Result of batch 12: 
INFO  [04:41:45.675] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:41:45.675] [bbotk]              2.464472                 2.800858                       0.3641473 
INFO  [04:41:45.675] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:41:45.675] [bbotk]                     3812        0.512 -0.9663933         <NA>   0.9662071 
INFO  [04:41:45.675] [bbotk]                                 uhash 
INFO  [04:41:45.675] [bbotk]  d0a17a93-caa0-4e0d-9305-02d0659cea23 
DEBUG [04:41:46.400] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.632907e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  9.632906e-06 0.001057956 
  - best initial criterion value(s) :  157.8975 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -157.9  |proj g|=       2.5795
At iterate     1  f =      -158.17  |proj g|=        2.8325
At iterate     2  f =      -159.35  |proj g|=        2.6537
At iterate     3  f =         -160  |proj g|=         2.392
At iterate     4  f =       -160.2  |proj g|=         2.242
At iterate     5  f =      -160.32  |proj g|=        2.1899
At iterate     6  f =      -160.32  |proj g|=        2.1701
At iterate     7  f =      -160.33  |proj g|=        2.1708
At iterate     8  f =      -160.33  |proj g|=        2.1685
At iterate     9  f =      -160.33  |proj g|=         2.168
At iterate    10  f =      -160.33  |proj g|=        2.1679

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.16788
final function value -160.325

F = -160.325
final  value -160.325210 
converged
 
INFO  [04:41:46.404] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:41:46.490] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:41:46.497] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:41:48.017] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:41:49.536] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:41:52.429] [mlr3]  Finished benchmark 
INFO  [04:41:52.530] [bbotk] Result of batch 13: 
INFO  [04:41:52.532] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:41:52.532] [bbotk]              3.849245                 5.029328                      0.02724298 
INFO  [04:41:52.532] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:41:52.532] [bbotk]                      573        0.517 -0.9684275         <NA>   0.9136885 
INFO  [04:41:52.532] [bbotk]                                 uhash 
INFO  [04:41:52.532] [bbotk]  89092412-cff6-4812-b769-c1c97282ec62 
DEBUG [04:41:53.241] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.621676e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.621676e-05 0.00197532 
  - best initial criterion value(s) :  160.6286 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -160.63  |proj g|=      0.85073
At iterate     1  f =       -166.9  |proj g|=       0.74966
At iterate     2  f =      -167.49  |proj g|=       0.84732
At iterate     3  f =      -167.73  |proj g|=       0.79277
At iterate     4  f =      -167.83  |proj g|=       0.66884
At iterate     5  f =      -167.85  |proj g|=       0.72083
At iterate     6  f =      -167.86  |proj g|=       0.71293
At iterate     7  f =      -167.86  |proj g|=       0.71195
At iterate     8  f =      -167.86  |proj g|=       0.71182
At iterate     9  f =      -167.86  |proj g|=        0.7118
At iterate    10  f =      -167.86  |proj g|=       0.71198
At iterate    11  f =      -167.86  |proj g|=       0.71215
At iterate    12  f =      -167.86  |proj g|=        0.7122

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.712199
final function value -167.856

F = -167.856
final  value -167.856149 
converged
 
INFO  [04:41:53.245] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:41:53.344] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:41:53.350] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:41:55.918] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:41:59.201] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:42:01.907] [mlr3]  Finished benchmark 
INFO  [04:42:02.006] [bbotk] Result of batch 14: 
INFO  [04:42:02.008] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:42:02.008] [bbotk]              3.273313                 2.907062                       0.0441811 
INFO  [04:42:02.008] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:42:02.008] [bbotk]                     1153        0.521 -0.9651583         <NA>   0.9386865 
INFO  [04:42:02.008] [bbotk]                                 uhash 
INFO  [04:42:02.008] [bbotk]  58fd22f4-ec51-4812-a105-85e1fd106182 
DEBUG [04:42:02.715] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.76518e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.76518e-05 0.002122398 
  - best initial criterion value(s) :  161.0487 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -161.05  |proj g|=      0.38636
At iterate     1  f =      -161.25  |proj g|=        0.3999
At iterate     2  f =      -161.72  |proj g|=       0.35721
At iterate     3  f =      -162.16  |proj g|=        0.2735
At iterate     4  f =      -162.17  |proj g|=       0.68836
At iterate     5  f =      -162.17  |proj g|=       0.40006
At iterate     6  f =      -162.17  |proj g|=       0.41025
At iterate     7  f =      -162.17  |proj g|=         0.408

iterations 7
function evaluations 13
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.407998
final function value -162.171

F = -162.171
final  value -162.170870 
converged
 
INFO  [04:42:02.720] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:42:02.824] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:42:02.831] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:42:05.750] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:42:08.034] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:42:10.623] [mlr3]  Finished benchmark 
INFO  [04:42:10.739] [bbotk] Result of batch 15: 
INFO  [04:42:10.741] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:42:10.741] [bbotk]              2.720777                 4.554217                       0.1940739 
INFO  [04:42:10.741] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:42:10.741] [bbotk]                     1120        0.519 -0.9676269         <NA>   0.9537945 
INFO  [04:42:10.741] [bbotk]                                 uhash 
INFO  [04:42:10.741] [bbotk]  bea60f1b-2566-4ae3-ac30-5b927570d148 
DEBUG [04:42:11.470] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.761282e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.761282e-05 0.002105599 
  - best initial criterion value(s) :  162.0217 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -162.02  |proj g|=      0.74767
At iterate     1  f =      -162.51  |proj g|=         0.696
At iterate     2  f =      -162.74  |proj g|=       0.68215
At iterate     3  f =      -163.01  |proj g|=       0.64097
At iterate     4  f =      -163.04  |proj g|=       0.41527
At iterate     5  f =      -163.04  |proj g|=       0.39714
At iterate     6  f =      -163.04  |proj g|=       0.34833
At iterate     7  f =      -163.04  |proj g|=        0.3464
At iterate     8  f =      -163.04  |proj g|=       0.34642

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.346424
final function value -163.045

F = -163.045
final  value -163.044570 
converged
 
INFO  [04:42:11.474] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:42:11.559] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:42:11.566] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:42:18.499] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:42:26.695] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:42:35.402] [mlr3]  Finished benchmark 
INFO  [04:42:35.639] [bbotk] Result of batch 16: 
INFO  [04:42:35.641] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:42:35.641] [bbotk]              5.586653                 9.553373                       0.2024118 
INFO  [04:42:35.641] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:42:35.641] [bbotk]                     3522        0.531 -0.9673604         <NA>   0.9744082 
INFO  [04:42:35.641] [bbotk]                                 uhash 
INFO  [04:42:35.641] [bbotk]  c2d84d74-3e7e-446a-8562-4d86275f3918 
DEBUG [04:42:36.367] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.737101e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.737101e-05 0.002095473 
  - best initial criterion value(s) :  163.8706 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -163.87  |proj g|=       2.8915
At iterate     1  f =      -164.02  |proj g|=        3.0942
At iterate     2  f =      -164.95  |proj g|=        2.8918
At iterate     3  f =      -165.61  |proj g|=        2.4864
At iterate     4  f =      -165.74  |proj g|=        2.3526
At iterate     5  f =      -165.88  |proj g|=        2.1559
At iterate     6  f =      -165.89  |proj g|=        2.0435
At iterate     7  f =       -165.9  |proj g|=        2.0451
At iterate     8  f =       -165.9  |proj g|=        2.0449
At iterate     9  f =       -165.9  |proj g|=        2.0449

iterations 9
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.04486
final function value -165.895

F = -165.895
final  value -165.895166 
converged
 
INFO  [04:42:36.372] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:42:36.458] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:42:36.465] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:42:39.805] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:42:43.286] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:42:46.754] [mlr3]  Finished benchmark 
INFO  [04:42:46.852] [bbotk] Result of batch 17: 
INFO  [04:42:46.854] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:42:46.854] [bbotk]              2.126466                 5.692124                       0.2990415 
INFO  [04:42:46.854] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:42:46.854] [bbotk]                     2198        0.535 -0.9679646         <NA>   0.9570824 
INFO  [04:42:46.854] [bbotk]                                 uhash 
INFO  [04:42:46.854] [bbotk]  ec7f9106-5322-4bf5-bc67-273aea0d61a3 
DEBUG [04:42:47.572] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.718378e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.718378e-05 0.002069163 
  - best initial criterion value(s) :  168.4536 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -168.45  |proj g|=       1.5568
At iterate     1  f =      -168.83  |proj g|=        1.3977
At iterate     2  f =      -169.17  |proj g|=        1.2297
At iterate     3  f =      -169.34  |proj g|=        1.0677
At iterate     4  f =      -169.35  |proj g|=        1.0906
At iterate     5  f =      -169.35  |proj g|=        1.0822
At iterate     6  f =      -169.35  |proj g|=        1.0824
At iterate     7  f =      -169.35  |proj g|=        1.0824

iterations 7
function evaluations 11
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.0824
final function value -169.351

F = -169.351
final  value -169.350848 
converged
 
INFO  [04:42:47.576] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:42:47.662] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:42:47.669] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:42:53.678] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:42:59.629] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:43:05.726] [mlr3]  Finished benchmark 
INFO  [04:43:05.824] [bbotk] Result of batch 18: 
INFO  [04:43:05.826] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:43:05.826] [bbotk]              3.848113                 5.671214                       0.1178292 
INFO  [04:43:05.826] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:43:05.826] [bbotk]                     3891        0.529 -0.9691151         <NA>     0.97039 
INFO  [04:43:05.826] [bbotk]                                 uhash 
INFO  [04:43:05.826] [bbotk]  1a02c570-3980-4146-8b3b-00d29b0fac42 
DEBUG [04:43:06.557] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.686087e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.686087e-05 0.002054383 
  - best initial criterion value(s) :  171.0316 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -171.03  |proj g|=       1.0287
At iterate     1  f =      -173.61  |proj g|=       0.85263
At iterate     2  f =      -174.41  |proj g|=        1.2134
At iterate     3  f =      -174.59  |proj g|=        1.1542
At iterate     4  f =      -174.67  |proj g|=        1.0307
At iterate     5  f =      -174.69  |proj g|=        1.0746
At iterate     6  f =      -174.69  |proj g|=        1.0687
At iterate     7  f =      -174.69  |proj g|=         1.067
At iterate     8  f =      -174.69  |proj g|=        1.0668
At iterate     9  f =      -174.69  |proj g|=        1.0673
At iterate    10  f =      -174.69  |proj g|=        1.0678
At iterate    11  f =      -174.69  |proj g|=        1.0678

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.06782
final function value -174.686

F = -174.686
final  value -174.686298 
converged
 
INFO  [04:43:06.562] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:43:06.648] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:43:06.655] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:43:08.989] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:43:10.905] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:43:12.812] [mlr3]  Finished benchmark 
INFO  [04:43:12.923] [bbotk] Result of batch 19: 
INFO  [04:43:12.925] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:43:12.925] [bbotk]              4.260011                 4.907764                       0.4977725 
INFO  [04:43:12.925] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:43:12.925] [bbotk]                     1153        0.542 -0.9688706         <NA>   0.9723108 
INFO  [04:43:12.925] [bbotk]                                 uhash 
INFO  [04:43:12.925] [bbotk]  ecc51c1e-4a85-4006-80d0-c1b4294e055a 
DEBUG [04:43:13.830] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.658836e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.658836e-05 0.001981242 
  - best initial criterion value(s) :  175.7174 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -175.72  |proj g|=       2.7976
At iterate     1  f =      -176.19  |proj g|=        2.4779
At iterate     2  f =      -176.69  |proj g|=        2.6617
At iterate     3  f =      -176.89  |proj g|=        2.6699
At iterate     4  f =         -177  |proj g|=        2.6413
At iterate     5  f =      -177.04  |proj g|=        2.6057
At iterate     6  f =      -177.06  |proj g|=        2.5752
At iterate     7  f =      -177.06  |proj g|=        2.5834
At iterate     8  f =      -177.06  |proj g|=        2.5385
At iterate     9  f =      -177.06  |proj g|=        2.5517
At iterate    10  f =      -177.06  |proj g|=        2.5522
At iterate    11  f =      -177.06  |proj g|=        2.5528
At iterate    12  f =      -177.06  |proj g|=        2.5544
At iterate    13  f =      -177.06  |proj g|=        2.5568
At iterate    14  f =      -177.06  |proj g|=        2.5606
At iterate    15  f =      -177.06  |proj g|=        2.5663
At iterate    16  f =      -177.06  |proj g|=        2.5773
At iterate    17  f =      -177.07  |proj g|=        2.5882
At iterate    18  f =      -177.07  |proj g|=        2.6095
At iterate    19  f =      -177.07  |proj g|=        2.6122
At iterate    20  f =      -177.09  |proj g|=        2.6086
At iterate    21  f =      -177.15  |proj g|=        2.5802
At iterate    22  f =      -177.38  |proj g|=        2.4031
At iterate    23  f =      -178.15  |proj g|=         1.848
At iterate    24  f =      -180.51  |proj g|=       0.65632
At iterate    25  f =      -180.67  |proj g|=       0.67041
At iterate    26  f =      -181.97  |proj g|=       0.36603
At iterate    27  f =      -183.27  |proj g|=       0.25064
At iterate    28  f =      -183.47  |proj g|=       0.42652
At iterate    29  f =      -184.95  |proj g|=       0.56497
At iterate    30  f =      -185.37  |proj g|=        0.4875
At iterate    31  f =      -185.38  |proj g|=       0.23068
At iterate    32  f =      -185.39  |proj g|=        0.0267
At iterate    33  f =      -185.39  |proj g|=      0.028619
At iterate    34  f =      -185.39  |proj g|=      0.028694

iterations 34
function evaluations 40
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0286943
final function value -185.385

F = -185.385
final  value -185.385162 
converged
 
INFO  [04:43:13.834] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:43:13.920] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:43:13.927] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:43:19.305] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:43:24.690] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:43:29.858] [mlr3]  Finished benchmark 
INFO  [04:43:29.958] [bbotk] Result of batch 20: 
INFO  [04:43:29.960] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:43:29.960] [bbotk]              8.888722                 6.157772                       0.2420968 
INFO  [04:43:29.960] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:43:29.960] [bbotk]                     3386         0.64 -0.965406         <NA>   0.9752526 
INFO  [04:43:29.960] [bbotk]                                 uhash 
INFO  [04:43:29.960] [bbotk]  305e225f-3195-4ca0-8780-02def62f38a2 
DEBUG [04:43:30.737] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.64086e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.64086e-05 0.001989488 
  - best initial criterion value(s) :  178.8559 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -178.86  |proj g|=      0.52873
At iterate     1  f =      -181.63  |proj g|=        2.0329
At iterate     2  f =       -182.5  |proj g|=        1.9016
At iterate     3  f =      -183.33  |proj g|=        1.5484
At iterate     4  f =      -183.46  |proj g|=        1.4206
At iterate     5  f =      -183.83  |proj g|=        1.1777
At iterate     6  f =      -184.36  |proj g|=       0.90982
At iterate     7  f =       -184.4  |proj g|=        1.0288
At iterate     8  f =      -184.43  |proj g|=       0.94546
At iterate     9  f =      -184.43  |proj g|=       0.93656
At iterate    10  f =      -184.43  |proj g|=       0.93642
At iterate    11  f =      -184.43  |proj g|=       0.93606
At iterate    12  f =      -184.43  |proj g|=       0.93539
At iterate    13  f =      -184.43  |proj g|=       0.93437
At iterate    14  f =      -184.43  |proj g|=       0.93273
At iterate    15  f =      -184.43  |proj g|=       0.93024
At iterate    16  f =      -184.43  |proj g|=       0.92652
At iterate    17  f =      -184.44  |proj g|=        0.9215
At iterate    18  f =      -184.44  |proj g|=       0.91649
At iterate    19  f =      -184.44  |proj g|=       0.91745
At iterate    20  f =      -184.45  |proj g|=       0.93869
At iterate    21  f =      -184.46  |proj g|=       0.97981
At iterate    22  f =      -184.46  |proj g|=       0.99787
At iterate    23  f =      -184.47  |proj g|=        1.0125
At iterate    24  f =      -184.53  |proj g|=        1.0472
At iterate    25  f =      -184.67  |proj g|=        1.0558
At iterate    26  f =      -184.96  |proj g|=       0.99327
At iterate    27  f =      -185.49  |proj g|=       0.80798
At iterate    28  f =      -185.83  |proj g|=       0.65173
At iterate    29  f =      -186.39  |proj g|=       0.50925
At iterate    30  f =      -186.76  |proj g|=       0.49564
At iterate    31  f =      -187.32  |proj g|=        0.4224
At iterate    32  f =       -187.6  |proj g|=       0.56371
At iterate    33  f =      -187.64  |proj g|=       0.56437
At iterate    34  f =      -187.64  |proj g|=       0.37527
At iterate    35  f =      -187.64  |proj g|=       0.37785
At iterate    36  f =      -187.64  |proj g|=       0.37778

iterations 36
function evaluations 48
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.377783
final function value -187.639

F = -187.639
final  value -187.638822 
converged
 
INFO  [04:43:30.741] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:43:30.846] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:43:30.852] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:43:33.506] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:43:36.481] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:43:39.026] [mlr3]  Finished benchmark 
INFO  [04:43:39.137] [bbotk] Result of batch 21: 
INFO  [04:43:39.139] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:43:39.139] [bbotk]              2.121966                 5.968024                       0.1697684 
INFO  [04:43:39.139] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:43:39.139] [bbotk]                     1636        0.533 -0.9652322         <NA>   0.9495764 
INFO  [04:43:39.139] [bbotk]                                 uhash 
INFO  [04:43:39.139] [bbotk]  82ee900b-c1a6-4f4a-ae85-2329595061a0 
DEBUG [04:43:39.930] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.664551e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.664551e-05 0.0020028 
  - best initial criterion value(s) :  185.7632 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -185.76  |proj g|=      0.51282
At iterate     1  f =      -187.33  |proj g|=       0.79959
At iterate     2  f =      -187.48  |proj g|=       0.79795
At iterate     3  f =      -187.55  |proj g|=       0.79541
At iterate     4  f =      -187.56  |proj g|=       0.79531
At iterate     5  f =      -187.63  |proj g|=       0.79318
At iterate     6  f =      -187.78  |proj g|=       0.78507
At iterate     7  f =      -188.11  |proj g|=       0.76317
At iterate     8  f =      -188.61  |proj g|=       0.71921
At iterate     9  f =      -189.03  |proj g|=       0.66285
At iterate    10  f =      -189.24  |proj g|=       0.33613
At iterate    11  f =      -189.38  |proj g|=        0.3206
At iterate    12  f =      -189.39  |proj g|=       0.35974
At iterate    13  f =      -189.39  |proj g|=       0.35805
At iterate    14  f =      -189.39  |proj g|=       0.35811
At iterate    15  f =      -189.39  |proj g|=       0.35811

iterations 15
function evaluations 18
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.358107
final function value -189.388

F = -189.388
final  value -189.388300 
converged
 
INFO  [04:43:39.935] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:43:40.055] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:43:40.064] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:43:43.414] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:43:46.737] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:43:50.012] [mlr3]  Finished benchmark 
INFO  [04:43:50.124] [bbotk] Result of batch 22: 
INFO  [04:43:50.125] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:43:50.125] [bbotk]              3.797631                 3.512038                      0.04401039 
INFO  [04:43:50.125] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:43:50.125] [bbotk]                     2141        0.574 -0.9667335         <NA>   0.9553278 
INFO  [04:43:50.125] [bbotk]                                 uhash 
INFO  [04:43:50.125] [bbotk]  b06b431c-f4e2-4979-b492-13d65cfe751d 
DEBUG [04:43:50.990] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.655226e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.655226e-05 0.002011788 
  - best initial criterion value(s) :  179.7878 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -179.79  |proj g|=       2.8555
At iterate     1  f =       -183.8  |proj g|=        1.1196
At iterate     2  f =      -185.75  |proj g|=        1.0718
At iterate     3  f =      -188.63  |proj g|=       0.84937
At iterate     4  f =      -188.83  |proj g|=       0.94886
At iterate     5  f =      -189.05  |proj g|=        0.8517
At iterate     6  f =      -189.97  |proj g|=       0.90707
At iterate     7  f =      -190.99  |proj g|=        1.0244
At iterate     8  f =      -191.39  |proj g|=        1.0544
At iterate     9  f =      -191.44  |proj g|=        1.0624
At iterate    10  f =      -191.44  |proj g|=        1.0657
At iterate    11  f =      -191.44  |proj g|=        1.0671
At iterate    12  f =      -191.44  |proj g|=        1.0674
At iterate    13  f =      -191.45  |proj g|=        1.0716
At iterate    14  f =      -191.52  |proj g|=        1.0791
At iterate    15  f =      -191.75  |proj g|=        1.0898
At iterate    16  f =      -192.12  |proj g|=        1.0921
At iterate    17  f =      -192.12  |proj g|=        1.0854
At iterate    18  f =      -192.44  |proj g|=        1.0533
At iterate    19  f =      -192.72  |proj g|=       0.99021
At iterate    20  f =      -192.77  |proj g|=        0.9759
At iterate    21  f =      -192.79  |proj g|=       0.97543
At iterate    22  f =      -192.79  |proj g|=       0.97762
At iterate    23  f =      -192.79  |proj g|=       0.97614
At iterate    24  f =      -192.79  |proj g|=       0.97642
At iterate    25  f =      -192.79  |proj g|=       0.97644

iterations 25
function evaluations 35
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.976435
final function value -192.794

F = -192.794
final  value -192.794365 
converged
 
INFO  [04:43:50.994] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:43:51.081] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:43:51.088] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:43:54.111] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:43:55.723] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:43:57.623] [mlr3]  Finished benchmark 
INFO  [04:43:57.719] [bbotk] Result of batch 23: 
INFO  [04:43:57.721] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:43:57.721] [bbotk]              4.311038                 5.006709                       0.2838396 
INFO  [04:43:57.721] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:43:57.721] [bbotk]                      700        0.622 -0.9651774         <NA>   0.9654295 
INFO  [04:43:57.721] [bbotk]                                 uhash 
INFO  [04:43:57.721] [bbotk]  adc7c126-3beb-46f1-b9d0-ba14916f60bc 
DEBUG [04:43:58.592] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.624075e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.624075e-05 0.001928584 
  - best initial criterion value(s) :  187.5444 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -187.54  |proj g|=        2.142
At iterate     1  f =      -189.56  |proj g|=        1.1641
At iterate     2  f =       -192.2  |proj g|=        1.9869
At iterate     3  f =      -192.31  |proj g|=        1.9194
At iterate     4  f =      -192.46  |proj g|=        1.7038
At iterate     5  f =      -192.49  |proj g|=        1.7735
At iterate     6  f =      -192.49  |proj g|=        1.7646
At iterate     7  f =      -192.49  |proj g|=        1.7525
At iterate     8  f =      -192.49  |proj g|=        1.7578
At iterate     9  f =      -192.49  |proj g|=        1.7605
At iterate    10  f =      -192.49  |proj g|=        1.7679
At iterate    11  f =       -192.5  |proj g|=        1.7766
At iterate    12  f =       -192.5  |proj g|=        1.7874
At iterate    13  f =      -192.53  |proj g|=        1.7944
At iterate    14  f =      -192.58  |proj g|=        1.7813
At iterate    15  f =       -192.7  |proj g|=        1.7071
At iterate    16  f =      -192.93  |proj g|=        1.5029
At iterate    17  f =      -193.23  |proj g|=        1.0974
At iterate    18  f =      -193.28  |proj g|=       0.93333
At iterate    19  f =      -193.29  |proj g|=       0.96851
At iterate    20  f =      -193.35  |proj g|=        1.0486
At iterate    21  f =      -193.48  |proj g|=        1.1196
At iterate    22  f =      -193.78  |proj g|=        1.1282
At iterate    23  f =      -194.25  |proj g|=       0.95673
At iterate    24  f =      -194.25  |proj g|=       0.95723
At iterate    25  f =      -194.83  |proj g|=       0.79786
At iterate    26  f =      -195.51  |proj g|=       0.69531
At iterate    27  f =      -195.73  |proj g|=       0.61815
At iterate    28  f =      -195.77  |proj g|=       0.59295
At iterate    29  f =      -195.77  |proj g|=       0.59096
At iterate    30  f =      -195.77  |proj g|=       0.59612
At iterate    31  f =      -195.78  |proj g|=       0.58536
At iterate    32  f =      -195.78  |proj g|=       0.58364
At iterate    33  f =      -195.78  |proj g|=       0.58327
At iterate    34  f =      -195.78  |proj g|=        0.5828
At iterate    35  f =      -195.78  |proj g|=       0.58153
At iterate    36  f =      -195.78  |proj g|=       0.57493
At iterate    37  f =      -195.78  |proj g|=       0.57573
At iterate    38  f =      -195.78  |proj g|=       0.57623
At iterate    39  f =       -195.8  |proj g|=        0.5912
At iterate    40  f =      -195.82  |proj g|=       0.59829
At iterate    41  f =      -195.86  |proj g|=       0.61221
At iterate    42  f =      -195.88  |proj g|=       0.62635
At iterate    43  f =       -195.9  |proj g|=       0.62759
At iterate    44  f =       -195.9  |proj g|=       0.62415
At iterate    45  f =      -195.91  |proj g|=       0.63112
At iterate    46  f =      -195.91  |proj g|=       0.63067
At iterate    47  f =      -195.91  |proj g|=       0.63015
At iterate    48  f =      -195.91  |proj g|=       0.62987
At iterate    49  f =      -195.91  |proj g|=       0.62838
At iterate    50  f =      -195.91  |proj g|=       0.62668
At iterate    51  f =      -195.92  |proj g|=       0.62197
At iterate    52  f =      -195.94  |proj g|=       0.61752
At iterate    53  f =      -196.01  |proj g|=       0.61088
At iterate    54  f =      -196.13  |proj g|=       0.59607
At iterate    55  f =      -196.21  |proj g|=       0.51679
At iterate    56  f =      -196.45  |proj g|=        0.5109
At iterate    57  f =      -196.99  |proj g|=       0.60443
At iterate    58  f =      -197.26  |proj g|=       0.63342
At iterate    59  f =      -197.35  |proj g|=       0.66292
At iterate    60  f =      -197.38  |proj g|=       0.65648
At iterate    61  f =      -197.41  |proj g|=       0.65205
At iterate    62  f =      -197.48  |proj g|=       0.64653
At iterate    63  f =      -197.69  |proj g|=       0.62451
At iterate    64  f =      -197.87  |proj g|=       0.59753
At iterate    65  f =      -197.96  |proj g|=       0.31467
At iterate    66  f =      -197.97  |proj g|=        0.2969
At iterate    67  f =      -197.97  |proj g|=       0.35338
At iterate    68  f =      -197.97  |proj g|=     0.0040248
At iterate    69  f =      -197.97  |proj g|=     0.0040236
At iterate    70  f =      -197.97  |proj g|=     0.0040236

iterations 70
function evaluations 82
segments explored during Cauchy searches 72
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0040236
final function value -197.972

F = -197.972
final  value -197.971759 
converged
 
INFO  [04:43:58.596] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:43:58.685] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:43:58.693] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:44:09.345] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:44:18.593] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:44:28.076] [mlr3]  Finished benchmark 
INFO  [04:44:28.172] [bbotk] Result of batch 24: 
INFO  [04:44:28.174] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:44:28.174] [bbotk]              6.236425                 8.250717                       0.4850933 
INFO  [04:44:28.174] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:44:28.174] [bbotk]                     4404        0.563 -0.9653875         <NA>   0.9764217 
INFO  [04:44:28.174] [bbotk]                                 uhash 
INFO  [04:44:28.174] [bbotk]  4b9b3716-6a4e-478a-9fa7-fce248378257 
DEBUG [04:44:29.127] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.613469e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.613469e-05 0.001935483 
  - best initial criterion value(s) :  184.8266 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -184.83  |proj g|=       3.5145
At iterate     1  f =      -188.19  |proj g|=        3.0212
At iterate     2  f =      -188.24  |proj g|=        2.9485
At iterate     3  f =      -188.29  |proj g|=        2.9886
At iterate     4  f =       -188.3  |proj g|=        2.9889
At iterate     5  f =       -188.3  |proj g|=        2.9932
At iterate     6  f =       -188.3  |proj g|=        2.9972
At iterate     7  f =       -188.3  |proj g|=        2.9982
At iterate     8  f =       -188.3  |proj g|=        2.9994
At iterate     9  f =       -188.3  |proj g|=        3.0002
At iterate    10  f =       -188.3  |proj g|=        3.0022
At iterate    11  f =       -188.3  |proj g|=        3.0054
At iterate    12  f =       -188.3  |proj g|=        3.0111
At iterate    13  f =       -188.3  |proj g|=        3.0203
At iterate    14  f =       -188.3  |proj g|=        3.0346
At iterate    15  f =      -188.31  |proj g|=        3.0501
At iterate    16  f =      -188.33  |proj g|=        3.0643
At iterate    17  f =      -188.41  |proj g|=        3.0859
At iterate    18  f =      -188.55  |proj g|=         3.067
At iterate    19  f =      -188.57  |proj g|=        3.0516
At iterate    20  f =      -188.94  |proj g|=        2.9057
At iterate    21  f =       -191.3  |proj g|=        1.9907
At iterate    22  f =      -194.91  |proj g|=       0.97358
At iterate    23  f =      -196.82  |proj g|=       0.56174
At iterate    24  f =      -197.15  |proj g|=       0.71391
At iterate    25  f =      -197.18  |proj g|=       0.71313
At iterate    26  f =      -198.42  |proj g|=       0.66564
At iterate    27  f =      -198.93  |proj g|=       0.17474
At iterate    28  f =      -198.94  |proj g|=        0.1515
At iterate    29  f =      -198.94  |proj g|=       0.12776
At iterate    30  f =      -198.94  |proj g|=        0.1259
At iterate    31  f =      -198.94  |proj g|=       0.12576

iterations 31
function evaluations 39
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.125762
final function value -198.941

F = -198.941
final  value -198.941436 
converged
 
INFO  [04:44:29.131] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:44:29.234] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:44:29.241] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:44:38.364] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:44:47.857] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:44:55.947] [mlr3]  Finished benchmark 
INFO  [04:44:56.056] [bbotk] Result of batch 25: 
INFO  [04:44:56.057] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:44:56.057] [bbotk]              7.065953                 9.442858                       0.4578454 
INFO  [04:44:56.057] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:44:56.057] [bbotk]                     3690        0.531 -0.9672447         <NA>   0.9761927 
INFO  [04:44:56.057] [bbotk]                                 uhash 
INFO  [04:44:56.057] [bbotk]  6d30e1e9-6f56-430b-affa-e354b9357956 
DEBUG [04:44:56.794] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.601744e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.601744e-05 0.001941847 
  - best initial criterion value(s) :  198.3642 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -198.36  |proj g|=      0.90526
At iterate     1  f =      -199.54  |proj g|=       0.63769
At iterate     2  f =      -199.73  |proj g|=       0.70703
At iterate     3  f =      -199.74  |proj g|=       0.72403
At iterate     4  f =      -199.75  |proj g|=       0.71349
At iterate     5  f =      -199.75  |proj g|=       0.71298
At iterate     6  f =      -199.75  |proj g|=       0.71536
At iterate     7  f =       -199.8  |proj g|=        0.7254
At iterate     8  f =      -199.89  |proj g|=       0.72188
At iterate     9  f =      -200.16  |proj g|=       0.67464
At iterate    10  f =      -200.68  |proj g|=       0.63412
At iterate    11  f =       -200.9  |proj g|=       0.43803
At iterate    12  f =      -201.12  |proj g|=       0.41313
At iterate    13  f =      -201.42  |proj g|=       0.37638
At iterate    14  f =      -201.95  |proj g|=       0.66138
At iterate    15  f =      -202.34  |proj g|=       0.65172
At iterate    16  f =      -202.37  |proj g|=       0.31658
At iterate    17  f =      -202.38  |proj g|=       0.23561
At iterate    18  f =      -202.38  |proj g|=       0.24161
At iterate    19  f =      -202.38  |proj g|=       0.24217
At iterate    20  f =      -202.38  |proj g|=       0.24216

iterations 20
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.24216
final function value -202.381

F = -202.381
final  value -202.380644 
converged
 
INFO  [04:44:56.799] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:44:56.884] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:44:56.891] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:45:08.957] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:45:19.481] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:45:30.630] [mlr3]  Finished benchmark 
INFO  [04:45:30.741] [bbotk] Result of batch 26: 
INFO  [04:45:30.743] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:45:30.743] [bbotk]              9.605915                 7.795481                       0.1606644 
INFO  [04:45:30.743] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:45:30.743] [bbotk]                     4859        0.532 -0.967802         <NA>    0.975604 
INFO  [04:45:30.743] [bbotk]                                 uhash 
INFO  [04:45:30.743] [bbotk]  609d9de3-70fe-42cf-ac36-32211f841a4e 
DEBUG [04:45:31.652] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.587878e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.587877e-05 0.001944417 
  - best initial criterion value(s) :  201.7841 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -201.78  |proj g|=      0.81821
At iterate     1  f =      -206.24  |proj g|=       0.69559
At iterate     2  f =      -206.52  |proj g|=       0.65965
At iterate     3  f =       -206.6  |proj g|=       0.64978
At iterate     4  f =      -206.62  |proj g|=        0.3741
At iterate     5  f =      -206.62  |proj g|=       0.37576
At iterate     6  f =      -206.62  |proj g|=       0.37658
At iterate     7  f =      -206.62  |proj g|=       0.37659

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.376593
final function value -206.617

F = -206.617
final  value -206.616904 
converged
 
INFO  [04:45:31.656] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:45:31.742] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:45:31.749] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:45:38.771] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:45:46.264] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:45:52.140] [mlr3]  Finished benchmark 
INFO  [04:45:52.236] [bbotk] Result of batch 27: 
INFO  [04:45:52.237] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:45:52.237] [bbotk]              6.455009                 5.752921                      0.06745166 
INFO  [04:45:52.237] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:45:52.237] [bbotk]                     2803         0.68 -0.9676044         <NA>   0.9682367 
INFO  [04:45:52.237] [bbotk]                                 uhash 
INFO  [04:45:52.237] [bbotk]  76a98685-4c55-4ef7-8149-cd9da241dfcd 
DEBUG [04:45:52.981] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.560482e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.560482e-05 0.001918858 
  - best initial criterion value(s) :  202.1691 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -202.17  |proj g|=       2.0856
At iterate     1  f =      -210.69  |proj g|=       0.70801
At iterate     2  f =      -210.96  |proj g|=       0.70556
At iterate     3  f =      -211.25  |proj g|=        0.6947
At iterate     4  f =      -211.34  |proj g|=       0.69825
At iterate     5  f =      -211.36  |proj g|=       0.69709
At iterate     6  f =      -211.38  |proj g|=       0.69459
At iterate     7  f =      -211.43  |proj g|=        0.6884
At iterate     8  f =      -211.56  |proj g|=       0.67093
At iterate     9  f =      -211.77  |proj g|=       0.38654
At iterate    10  f =      -211.91  |proj g|=       0.63313
At iterate    11  f =      -212.01  |proj g|=       0.60355
At iterate    12  f =      -212.01  |proj g|=        0.4736
At iterate    13  f =      -212.01  |proj g|=       0.47448
At iterate    14  f =      -212.01  |proj g|=       0.47481
At iterate    15  f =      -212.01  |proj g|=       0.47485

iterations 15
function evaluations 19
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.474851
final function value -212.009

F = -212.009
final  value -212.009446 
converged
 
INFO  [04:45:52.985] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:45:53.071] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:45:53.078] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:45:58.996] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:46:04.114] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:46:09.723] [mlr3]  Finished benchmark 
INFO  [04:46:09.823] [bbotk] Result of batch 28: 
INFO  [04:46:09.825] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:46:09.825] [bbotk]              4.894359                 4.202327                       0.2629322 
INFO  [04:46:09.825] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:46:09.825] [bbotk]                     2293        0.541 -0.9661421         <NA>   0.9732596 
INFO  [04:46:09.825] [bbotk]                                 uhash 
INFO  [04:46:09.825] [bbotk]  76d995d9-95f2-463b-b30a-246696e8d877 
DEBUG [04:46:10.558] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.541031e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.541031e-05 0.001896621 
  - best initial criterion value(s) :  213.3757 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -213.38  |proj g|=      0.81846
At iterate     1  f =      -217.71  |proj g|=       0.70731
At iterate     2  f =      -219.56  |proj g|=       0.75747
At iterate     3  f =       -219.7  |proj g|=       0.80337
At iterate     4  f =      -219.74  |proj g|=       0.83769
At iterate     5  f =      -219.74  |proj g|=       0.84145
At iterate     6  f =      -219.74  |proj g|=       0.84177
At iterate     7  f =      -219.74  |proj g|=       0.84225

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.842252
final function value -219.742

F = -219.742
final  value -219.742309 
converged
 
INFO  [04:46:10.563] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:46:10.672] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:46:10.679] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:46:16.277] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:46:22.015] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:46:27.424] [mlr3]  Finished benchmark 
INFO  [04:46:27.524] [bbotk] Result of batch 29: 
INFO  [04:46:27.526] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:46:27.526] [bbotk]              9.010043                 3.550083                       0.2229186 
INFO  [04:46:27.526] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:46:27.526] [bbotk]                     2537        0.543 -0.9632296         <NA>   0.9744371 
INFO  [04:46:27.526] [bbotk]                                 uhash 
INFO  [04:46:27.526] [bbotk]  73fd065b-c85f-440d-b263-79f1554f3aeb 
DEBUG [04:46:28.300] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.524784e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.524784e-05 0.001898509 
  - best initial criterion value(s) :  210.1871 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -210.19  |proj g|=       2.7924
At iterate     1  f =      -210.69  |proj g|=         2.959
At iterate     2  f =      -211.68  |proj g|=        2.6679
At iterate     3  f =       -214.3  |proj g|=        1.4684
At iterate     4  f =      -216.06  |proj g|=       0.83072
At iterate     5  f =      -216.14  |proj g|=        1.0449
At iterate     6  f =      -216.15  |proj g|=       0.97169
At iterate     7  f =      -216.15  |proj g|=       0.96657
At iterate     8  f =      -216.15  |proj g|=       0.96657
At iterate     9  f =      -216.15  |proj g|=       0.96662

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.966621
final function value -216.151

F = -216.151
final  value -216.150943 
converged
 
INFO  [04:46:28.304] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:46:28.392] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:46:28.399] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:46:37.890] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:46:46.448] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:46:54.836] [mlr3]  Finished benchmark 
INFO  [04:46:54.937] [bbotk] Result of batch 30: 
INFO  [04:46:54.939] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:46:54.939] [bbotk]              6.589633                 3.527603                       0.3857315 
INFO  [04:46:54.939] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:46:54.939] [bbotk]                     3720        0.553 -0.968206         <NA>   0.9758973 
INFO  [04:46:54.939] [bbotk]                                 uhash 
INFO  [04:46:54.939] [bbotk]  909cba2e-9c5d-49f3-a24f-b37f162bbc7d 
DEBUG [04:46:55.791] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.512734e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.512734e-05 0.001894883 
  - best initial criterion value(s) :  216.8742 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -216.87  |proj g|=       3.1796
At iterate     1  f =      -218.87  |proj g|=        3.7653
At iterate     2  f =      -219.64  |proj g|=        3.7184
At iterate     3  f =       -220.2  |proj g|=         3.492
At iterate     4  f =      -220.37  |proj g|=        3.1574
At iterate     5  f =      -220.49  |proj g|=        3.0427
At iterate     6  f =      -220.69  |proj g|=        2.5173
At iterate     7  f =       -220.7  |proj g|=        2.5731
At iterate     8  f =       -220.7  |proj g|=        2.5695
At iterate     9  f =       -220.7  |proj g|=        2.5682
At iterate    10  f =       -220.7  |proj g|=        2.5624
At iterate    11  f =       -220.7  |proj g|=        2.5553
At iterate    12  f =       -220.7  |proj g|=        2.5429
At iterate    13  f =       -220.7  |proj g|=        2.5232
At iterate    14  f =       -220.7  |proj g|=        2.4882
At iterate    15  f =      -220.72  |proj g|=        2.4242
At iterate    16  f =      -220.76  |proj g|=        2.2981
At iterate    17  f =      -220.86  |proj g|=        2.0559
At iterate    18  f =      -221.07  |proj g|=        1.6694
At iterate    19  f =      -221.28  |proj g|=        1.3966
At iterate    20  f =      -221.31  |proj g|=        1.4112
At iterate    21  f =      -221.33  |proj g|=        1.4672
At iterate    22  f =      -221.37  |proj g|=        1.5232
At iterate    23  f =      -221.44  |proj g|=        1.6056
At iterate    24  f =      -221.61  |proj g|=        1.7214
At iterate    25  f =      -221.97  |proj g|=         1.839
At iterate    26  f =      -222.78  |proj g|=        1.9049
At iterate    27  f =      -224.67  |proj g|=        1.7811
At iterate    28  f =      -226.26  |proj g|=        1.3183
At iterate    29  f =      -226.43  |proj g|=        1.1526
At iterate    30  f =      -226.46  |proj g|=         1.114
At iterate    31  f =      -226.51  |proj g|=        0.9695
At iterate    32  f =      -226.61  |proj g|=       0.99317
At iterate    33  f =      -227.21  |proj g|=        1.0822
At iterate    34  f =      -227.51  |proj g|=        1.0779
At iterate    35  f =      -227.82  |proj g|=        1.1617
At iterate    36  f =      -227.86  |proj g|=        1.2065
At iterate    37  f =      -227.86  |proj g|=        1.2104
At iterate    38  f =      -227.87  |proj g|=        1.2226
At iterate    39  f =      -227.87  |proj g|=        1.2243
At iterate    40  f =      -227.87  |proj g|=        1.2243

iterations 40
function evaluations 50
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.22432
final function value -227.867

F = -227.867
final  value -227.867124 
converged
 
INFO  [04:46:55.796] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:46:55.882] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:46:55.889] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:47:04.120] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:47:09.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:47:14.041] [mlr3]  Finished benchmark 
INFO  [04:47:14.203] [bbotk] Result of batch 31: 
INFO  [04:47:14.205] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:47:14.205] [bbotk]              8.014087                 4.891383                       0.2911558 
INFO  [04:47:14.205] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:47:14.205] [bbotk]                     2259        0.587 -0.9590863         <NA>   0.9747805 
INFO  [04:47:14.205] [bbotk]                                 uhash 
INFO  [04:47:14.205] [bbotk]  d10510d1-0935-4b42-ab30-d6b543f91636 
DEBUG [04:47:14.991] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.497657e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.497657e-05 0.001876545 
  - best initial criterion value(s) :  227.472 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -227.47  |proj g|=       0.4869
At iterate     1  f =      -227.65  |proj g|=       0.72508
At iterate     2  f =      -227.72  |proj g|=       0.67814
At iterate     3  f =       -228.2  |proj g|=       0.34331
At iterate     4  f =       -228.4  |proj g|=       0.35957
At iterate     5  f =      -228.43  |proj g|=       0.66851
At iterate     6  f =      -228.44  |proj g|=       0.45325
At iterate     7  f =      -228.44  |proj g|=       0.49945
At iterate     8  f =      -228.44  |proj g|=       0.49845

iterations 8
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.498446
final function value -228.436

F = -228.436
final  value -228.436368 
converged
 
INFO  [04:47:14.995] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:47:15.084] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:47:15.091] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:47:17.713] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:47:21.574] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:47:24.824] [mlr3]  Finished benchmark 
INFO  [04:47:24.935] [bbotk] Result of batch 32: 
INFO  [04:47:24.937] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:47:24.937] [bbotk]              6.423639                 3.133694                         0.26561 
INFO  [04:47:24.937] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:47:24.937] [bbotk]                     1421        0.583 -0.9674523         <NA>   0.9724552 
INFO  [04:47:24.937] [bbotk]                                 uhash 
INFO  [04:47:24.937] [bbotk]  22f40da1-988a-404a-8f1e-30fdb9962b4b 
DEBUG [04:47:25.690] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.477982e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.477982e-05 0.001825641 
  - best initial criterion value(s) :  218.2262 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -218.23  |proj g|=      0.95471
At iterate     1  f =      -218.63  |proj g|=       0.94999
At iterate     2  f =      -219.19  |proj g|=        0.8906
At iterate     3  f =      -220.38  |proj g|=        1.0538
At iterate     4  f =      -220.94  |proj g|=       0.88006
At iterate     5  f =      -221.17  |proj g|=       0.86049
At iterate     6  f =      -221.18  |proj g|=        0.8832
At iterate     7  f =      -221.18  |proj g|=       0.88914
At iterate     8  f =      -221.18  |proj g|=       0.89016
At iterate     9  f =      -221.18  |proj g|=       0.89038
At iterate    10  f =      -221.18  |proj g|=       0.89037

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.890368
final function value -221.182

F = -221.182
final  value -221.181831 
converged
 
INFO  [04:47:25.695] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:47:25.782] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:47:25.789] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:47:27.078] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:47:28.615] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:47:30.033] [mlr3]  Finished benchmark 
INFO  [04:47:30.149] [bbotk] Result of batch 33: 
INFO  [04:47:30.151] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:47:30.151] [bbotk]              5.159304                 9.813425                       0.2463851 
INFO  [04:47:30.151] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:47:30.151] [bbotk]                      476        0.572  -0.97077         <NA>   0.9618482 
INFO  [04:47:30.151] [bbotk]                                 uhash 
INFO  [04:47:30.151] [bbotk]  29eec45c-9579-448a-b6fc-d0ca4724af84 
DEBUG [04:47:30.999] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.459042e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.459042e-05 0.001788652 
  - best initial criterion value(s) :  228.0102 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -228.01  |proj g|=       3.7187
At iterate     1  f =      -231.23  |proj g|=        2.9136
At iterate     2  f =      -231.29  |proj g|=        2.8534
At iterate     3  f =      -231.32  |proj g|=        2.9012
At iterate     4  f =      -231.32  |proj g|=        2.9275
At iterate     5  f =      -231.32  |proj g|=        2.9248
At iterate     6  f =      -231.32  |proj g|=        2.9248
At iterate     7  f =      -231.32  |proj g|=        2.9248
At iterate     8  f =      -231.32  |proj g|=        2.9251
At iterate     9  f =      -231.32  |proj g|=        2.9253
At iterate    10  f =      -231.32  |proj g|=        2.9257
At iterate    11  f =      -231.32  |proj g|=        2.9262
At iterate    12  f =      -231.32  |proj g|=        2.9261
At iterate    13  f =      -231.32  |proj g|=        2.9239
At iterate    14  f =      -231.32  |proj g|=        2.9185
At iterate    15  f =      -231.32  |proj g|=        2.9102
At iterate    16  f =      -231.33  |proj g|=        2.8726
At iterate    17  f =      -231.34  |proj g|=        2.8626
At iterate    18  f =      -231.37  |proj g|=        2.8308
At iterate    19  f =       -231.7  |proj g|=        2.4927
At iterate    20  f =      -232.23  |proj g|=        2.0237
At iterate    21  f =      -233.26  |proj g|=        1.3527
At iterate    22  f =      -234.37  |proj g|=        1.1228
At iterate    23  f =      -236.52  |proj g|=       0.86425
At iterate    24  f =       -237.3  |proj g|=       0.61297
At iterate    25  f =      -237.46  |proj g|=       0.68761
At iterate    26  f =      -237.47  |proj g|=       0.67538
At iterate    27  f =      -237.47  |proj g|=        0.6721
At iterate    28  f =      -237.47  |proj g|=       0.67229
At iterate    29  f =      -237.47  |proj g|=       0.67244
At iterate    30  f =      -237.47  |proj g|=       0.67264
At iterate    31  f =      -237.47  |proj g|=       0.67282
At iterate    32  f =      -237.47  |proj g|=       0.67267
At iterate    33  f =      -237.47  |proj g|=       0.67275

iterations 33
function evaluations 37
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.672749
final function value -237.467

F = -237.467
final  value -237.466539 
converged
 
INFO  [04:47:31.003] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:47:31.090] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:47:31.097] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:47:40.365] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:47:49.128] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:47:57.660] [mlr3]  Finished benchmark 
INFO  [04:47:57.761] [bbotk] Result of batch 34: 
INFO  [04:47:57.763] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:47:57.763] [bbotk]              6.192534                 9.229502                       0.3847479 
INFO  [04:47:57.763] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:47:57.763] [bbotk]                     3892        0.596 -0.9668843         <NA>   0.9759708 
INFO  [04:47:57.763] [bbotk]                                 uhash 
INFO  [04:47:57.763] [bbotk]  66169203-e0a5-47aa-9c06-d6fa8118c331 
DEBUG [04:47:58.745] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.448235e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.448235e-05 0.001785673 
  - best initial criterion value(s) :  236.2504 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -236.25  |proj g|=       1.9419
At iterate     1  f =      -242.72  |proj g|=       0.64978
At iterate     2  f =      -242.76  |proj g|=       0.64836
At iterate     3  f =      -242.78  |proj g|=       0.64553
At iterate     4  f =      -242.79  |proj g|=       0.64564
At iterate     5  f =      -242.79  |proj g|=       0.64544
At iterate     6  f =      -242.79  |proj g|=       0.64374
At iterate     7  f =      -242.79  |proj g|=       0.64055
At iterate     8  f =       -242.8  |proj g|=       0.63577
At iterate     9  f =       -242.8  |proj g|=       0.63356
At iterate    10  f =       -242.8  |proj g|=       0.63347
At iterate    11  f =       -242.8  |proj g|=        0.6336
At iterate    12  f =       -242.8  |proj g|=       0.63363

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.633631
final function value -242.797

F = -242.797
final  value -242.796818 
converged
 
INFO  [04:47:58.749] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:47:58.853] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:47:58.860] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:48:10.543] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:48:21.873] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:48:32.917] [mlr3]  Finished benchmark 
INFO  [04:48:33.033] [bbotk] Result of batch 35: 
INFO  [04:48:33.035] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:48:33.035] [bbotk]              8.036883                 5.227056                       0.4751861 
INFO  [04:48:33.035] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:48:33.035] [bbotk]                     4788        0.732 -0.9666859         <NA>   0.9766318 
INFO  [04:48:33.035] [bbotk]                                 uhash 
INFO  [04:48:33.035] [bbotk]  76f7daee-63ae-4ab5-aa4c-05de1d1d8cb3 
DEBUG [04:48:34.025] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.439211e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.439211e-05 0.001778297 
  - best initial criterion value(s) :  246.5053 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -246.51  |proj g|=      0.79691
At iterate     1  f =      -247.37  |proj g|=       0.68361
At iterate     2  f =      -247.77  |proj g|=       0.67431
At iterate     3  f =      -248.42  |proj g|=       0.63015
At iterate     4  f =      -248.54  |proj g|=       0.61334
At iterate     5  f =      -248.58  |proj g|=       0.46908
At iterate     6  f =      -248.59  |proj g|=       0.47183
At iterate     7  f =      -248.59  |proj g|=       0.47228
At iterate     8  f =      -248.59  |proj g|=       0.47233

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.472329
final function value -248.586

F = -248.586
final  value -248.586363 
converged
 
INFO  [04:48:34.030] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:48:34.116] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:48:34.123] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:48:39.330] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:48:44.559] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:48:50.615] [mlr3]  Finished benchmark 
INFO  [04:48:50.736] [bbotk] Result of batch 36: 
INFO  [04:48:50.737] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:48:50.737] [bbotk]               2.64994                 6.216846                       0.0785962 
INFO  [04:48:50.737] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:48:50.737] [bbotk]                     2165        0.735 -0.9661063         <NA>   0.9491723 
INFO  [04:48:50.737] [bbotk]                                 uhash 
INFO  [04:48:50.737] [bbotk]  825204b2-8583-4160-a96a-4816b6eeb5ae 
DEBUG [04:48:51.726] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.467102e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.467102e-05 0.001812567 
  - best initial criterion value(s) :  246.7898 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -246.79  |proj g|=       2.4908
At iterate     1  f =      -246.84  |proj g|=        3.5128
At iterate     2  f =      -248.73  |proj g|=        3.3722
At iterate     3  f =      -250.84  |proj g|=        2.6352
At iterate     4  f =      -251.59  |proj g|=         2.323
At iterate     5  f =       -253.3  |proj g|=         1.616
At iterate     6  f =      -253.45  |proj g|=        1.3018
At iterate     7  f =      -253.46  |proj g|=         1.236
At iterate     8  f =      -253.46  |proj g|=        1.2414
At iterate     9  f =      -253.46  |proj g|=        1.2435
At iterate    10  f =      -253.46  |proj g|=         1.243

iterations 10
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.24301
final function value -253.458

F = -253.458
final  value -253.458429 
converged
 
INFO  [04:48:51.730] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:48:51.820] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:48:51.827] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:49:02.367] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:49:11.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:49:20.129] [mlr3]  Finished benchmark 
INFO  [04:49:20.232] [bbotk] Result of batch 37: 
INFO  [04:49:20.234] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:49:20.234] [bbotk]              6.533393                 4.340649                        0.321948 
INFO  [04:49:20.234] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:49:20.234] [bbotk]                     4333        0.734  -0.96524         <NA>   0.9758539 
INFO  [04:49:20.234] [bbotk]                                 uhash 
INFO  [04:49:20.234] [bbotk]  173b3a3f-9c69-494a-8792-4550f9517601 
DEBUG [04:49:21.450] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.456352e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.456352e-05 0.00179828 
  - best initial criterion value(s) :  240.0872 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -240.09  |proj g|=       5.3401
At iterate     1  f =       -241.6  |proj g|=        5.2675
At iterate     2  f =      -242.82  |proj g|=        5.1713
At iterate     3  f =      -245.36  |proj g|=        4.7826
At iterate     4  f =      -246.21  |proj g|=        4.4396
At iterate     5  f =       -247.4  |proj g|=         3.931
At iterate     6  f =      -247.58  |proj g|=        3.7377
At iterate     7  f =      -247.62  |proj g|=        3.6447
At iterate     8  f =      -247.62  |proj g|=        3.6257
At iterate     9  f =      -247.62  |proj g|=        3.6263
At iterate    10  f =      -247.62  |proj g|=        3.6268
At iterate    11  f =      -247.62  |proj g|=         3.627
At iterate    12  f =      -247.62  |proj g|=        3.6276
At iterate    13  f =      -247.62  |proj g|=        3.6285
At iterate    14  f =      -247.62  |proj g|=          3.63
At iterate    15  f =      -247.62  |proj g|=        3.6324
At iterate    16  f =      -247.62  |proj g|=        3.6369
At iterate    17  f =      -247.62  |proj g|=        3.6455
At iterate    18  f =      -247.63  |proj g|=        3.6628
At iterate    19  f =      -247.64  |proj g|=         3.696
At iterate    20  f =      -247.65  |proj g|=        3.7455
At iterate    21  f =      -247.65  |proj g|=        3.7334
At iterate    22  f =      -247.66  |proj g|=        3.7699
At iterate    23  f =      -249.23  |proj g|=        3.4165
At iterate    24  f =      -256.28  |proj g|=        1.2799
At iterate    25  f =       -259.3  |proj g|=        1.3147
At iterate    26  f =      -260.41  |proj g|=         1.293
At iterate    27  f =      -261.02  |proj g|=       0.56957
At iterate    28  f =      -261.67  |proj g|=        1.2326
At iterate    29  f =      -261.68  |proj g|=        1.1699
At iterate    30  f =      -261.68  |proj g|=        1.1336
At iterate    31  f =      -261.68  |proj g|=        1.1364
At iterate    32  f =      -261.68  |proj g|=        1.1364

iterations 32
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.13635
final function value -261.679

F = -261.679
final  value -261.679354 
converged
 
INFO  [04:49:21.454] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:49:21.543] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:49:21.551] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:49:25.973] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:49:30.876] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:49:33.822] [mlr3]  Finished benchmark 
INFO  [04:49:33.931] [bbotk] Result of batch 38: 
INFO  [04:49:33.933] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:49:33.933] [bbotk]               6.75529                 8.840634                       0.2552616 
INFO  [04:49:33.933] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:49:33.933] [bbotk]                     1640        0.908 -0.9644188         <NA>    0.972943 
INFO  [04:49:33.933] [bbotk]                                 uhash 
INFO  [04:49:33.933] [bbotk]  ae07f952-7264-4ef5-9447-16f8188fd624 
DEBUG [04:49:34.741] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.43959e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.43959e-05 0.00176809 
  - best initial criterion value(s) :  245.4509 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -245.45  |proj g|=      0.86358
At iterate     1  f =       -248.8  |proj g|=         3.247
At iterate     2  f =       -253.2  |proj g|=        3.9421
At iterate     3  f =      -255.37  |proj g|=        4.2143
At iterate     4  f =      -258.58  |proj g|=         3.831
At iterate     5  f =       -260.6  |proj g|=         3.109
At iterate     6  f =      -260.86  |proj g|=        2.6395
At iterate     7  f =      -261.01  |proj g|=        3.0257
At iterate     8  f =      -261.14  |proj g|=        2.9821
At iterate     9  f =      -261.15  |proj g|=        2.9192
At iterate    10  f =      -261.15  |proj g|=        2.9238
At iterate    11  f =      -261.15  |proj g|=        2.9236

iterations 11
function evaluations 13
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.92359
final function value -261.151

F = -261.151
final  value -261.151051 
converged
 
INFO  [04:49:34.745] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:49:34.833] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:49:34.840] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:49:42.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:49:52.826] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:49:58.600] [mlr3]  Finished benchmark 
INFO  [04:49:58.698] [bbotk] Result of batch 39: 
INFO  [04:49:58.700] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:49:58.700] [bbotk]              3.207952                 3.193903                        0.154196 
INFO  [04:49:58.700] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:49:58.700] [bbotk]                     2828        0.591 -0.9600127         <NA>   0.9668361 
INFO  [04:49:58.700] [bbotk]                                 uhash 
INFO  [04:49:58.700] [bbotk]  a8623958-c91c-4b90-9615-670e01db98bc 
DEBUG [04:49:59.567] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.418766e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.418766e-05 0.001745951 
  - best initial criterion value(s) :  258.9832 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -258.98  |proj g|=        4.854
At iterate     1  f =      -262.44  |proj g|=        5.2689
At iterate     2  f =      -262.98  |proj g|=        4.7967
At iterate     3  f =      -263.65  |proj g|=        3.5329
At iterate     4  f =      -263.99  |proj g|=        3.2692
At iterate     5  f =      -264.11  |proj g|=        2.9576
At iterate     6  f =      -264.11  |proj g|=        2.9874
At iterate     7  f =      -264.11  |proj g|=        2.9888
At iterate     8  f =      -264.11  |proj g|=        2.9894
At iterate     9  f =      -264.11  |proj g|=        2.9913
At iterate    10  f =      -264.11  |proj g|=        2.9936
At iterate    11  f =      -264.12  |proj g|=        2.9977
At iterate    12  f =      -264.12  |proj g|=        3.0035
At iterate    13  f =      -264.12  |proj g|=        3.0111
At iterate    14  f =      -264.12  |proj g|=        3.0174
At iterate    15  f =      -264.13  |proj g|=        3.0108
At iterate    16  f =      -264.16  |proj g|=        2.9577
At iterate    17  f =      -264.22  |proj g|=        2.7948
At iterate    18  f =      -264.31  |proj g|=        2.4485
At iterate    19  f =      -264.32  |proj g|=        2.3085
At iterate    20  f =      -264.32  |proj g|=        2.3147
At iterate    21  f =      -264.32  |proj g|=        2.3406
At iterate    22  f =      -264.33  |proj g|=        2.3699
At iterate    23  f =      -264.34  |proj g|=        2.4243
At iterate    24  f =      -264.38  |proj g|=        2.5043
At iterate    25  f =      -264.47  |proj g|=        2.5463
At iterate    26  f =      -264.69  |proj g|=        2.7585
At iterate    27  f =      -264.92  |proj g|=        2.3749
At iterate    28  f =      -265.72  |proj g|=        2.6525
At iterate    29  f =       -268.4  |proj g|=        2.5702
At iterate    30  f =      -271.41  |proj g|=        1.7345
At iterate    31  f =      -274.11  |proj g|=        0.6035
At iterate    32  f =      -275.15  |proj g|=       0.58768
At iterate    33  f =      -275.27  |proj g|=       0.68209
At iterate    34  f =      -275.67  |proj g|=       0.68776
At iterate    35  f =      -275.81  |proj g|=       0.70247
At iterate    36  f =      -275.83  |proj g|=       0.71145
At iterate    37  f =      -275.85  |proj g|=       0.72864
At iterate    38  f =      -275.85  |proj g|=       0.74209
At iterate    39  f =      -275.85  |proj g|=       0.74352
At iterate    40  f =      -275.85  |proj g|=       0.74367
At iterate    41  f =      -275.85  |proj g|=       0.74365
At iterate    42  f =      -275.85  |proj g|=       0.74354
At iterate    43  f =      -275.85  |proj g|=       0.74332
At iterate    44  f =      -275.85  |proj g|=       0.74496
At iterate    45  f =      -275.85  |proj g|=       0.74065
At iterate    46  f =      -275.85  |proj g|=       0.74343
At iterate    47  f =      -275.85  |proj g|=       0.74448
At iterate    48  f =      -275.85  |proj g|=       0.74443
At iterate    49  f =      -275.85  |proj g|=       0.74412
At iterate    50  f =      -275.85  |proj g|=       0.74405
At iterate    51  f =      -275.85  |proj g|=       0.74419

iterations 51
function evaluations 62
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.744191
final function value -275.85

F = -275.85
final  value -275.850461 
converged
 
INFO  [04:49:59.571] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:49:59.659] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:49:59.666] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:50:02.003] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:50:04.287] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:50:06.501] [mlr3]  Finished benchmark 
INFO  [04:50:06.603] [bbotk] Result of batch 40: 
INFO  [04:50:06.605] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:50:06.605] [bbotk]              4.174998                 7.125338                       0.1055547 
INFO  [04:50:06.605] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:50:06.605] [bbotk]                      860        0.577 -0.9573797         <NA>   0.9566602 
INFO  [04:50:06.605] [bbotk]                                 uhash 
INFO  [04:50:06.605] [bbotk]  b489958d-7168-4592-adc3-2312b1b3a12c 
DEBUG [04:50:07.415] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.414593e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.414593e-05 0.001738532 
  - best initial criterion value(s) :  247.5346 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -247.53  |proj g|=       7.7373
At iterate     1  f =      -256.56  |proj g|=        5.4606
At iterate     2  f =      -259.82  |proj g|=        5.1528
At iterate     3  f =       -262.2  |proj g|=        3.9873
At iterate     4  f =      -264.05  |proj g|=        2.6791
At iterate     5  f =      -264.28  |proj g|=        2.2416
At iterate     6  f =      -264.33  |proj g|=        2.1053
At iterate     7  f =      -264.36  |proj g|=         2.222
At iterate     8  f =      -264.37  |proj g|=         2.136
At iterate     9  f =      -266.34  |proj g|=        2.2095
At iterate    10  f =      -268.16  |proj g|=        1.4828
At iterate    11  f =      -269.95  |proj g|=       0.65375
At iterate    12  f =      -270.13  |proj g|=       0.79324
At iterate    13  f =      -270.21  |proj g|=       0.82351
At iterate    14  f =      -270.23  |proj g|=       0.78497
At iterate    15  f =      -270.23  |proj g|=       0.79477
At iterate    16  f =      -270.23  |proj g|=       0.79442
At iterate    17  f =      -270.23  |proj g|=       0.79403
At iterate    18  f =      -270.23  |proj g|=       0.79401

iterations 18
function evaluations 26
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.794007
final function value -270.229

F = -270.229
final  value -270.228510 
converged
 
INFO  [04:50:07.419] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:50:07.509] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:50:07.516] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:50:16.258] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:50:24.900] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:50:32.992] [mlr3]  Finished benchmark 
INFO  [04:50:33.111] [bbotk] Result of batch 41: 
INFO  [04:50:33.113] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:50:33.113] [bbotk]              4.349335                 6.151719                       0.3219447 
INFO  [04:50:33.113] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:50:33.113] [bbotk]                     3926        0.568 -0.9605316         <NA>   0.9751741 
INFO  [04:50:33.113] [bbotk]                                 uhash 
INFO  [04:50:33.113] [bbotk]  72259924-2604-4b5b-8ac0-0ece1fb66735 
DEBUG [04:50:33.945] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.403501e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.403501e-05 0.00173585 
  - best initial criterion value(s) :  258.633 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -258.63  |proj g|=       4.0239
At iterate     1  f =      -259.19  |proj g|=        3.5862
At iterate     2  f =      -259.68  |proj g|=        3.5414
At iterate     3  f =       -259.9  |proj g|=        3.4392
At iterate     4  f =      -259.94  |proj g|=        3.4019
At iterate     5  f =      -259.95  |proj g|=        3.3942
At iterate     6  f =      -259.95  |proj g|=        3.3952
At iterate     7  f =      -259.95  |proj g|=        3.3965
At iterate     8  f =      -259.95  |proj g|=        3.3965
At iterate     9  f =      -259.95  |proj g|=        3.3966
At iterate    10  f =      -259.95  |proj g|=        3.3966
At iterate    11  f =      -259.95  |proj g|=        3.3964
At iterate    12  f =      -259.95  |proj g|=        3.3955
At iterate    13  f =      -259.95  |proj g|=        3.3922
At iterate    14  f =      -259.95  |proj g|=        3.3833
At iterate    15  f =      -259.95  |proj g|=        3.3717
At iterate    16  f =      -259.97  |proj g|=        3.3283
At iterate    17  f =      -259.97  |proj g|=        3.3494
At iterate    18  f =      -259.99  |proj g|=        3.2921
At iterate    19  f =      -260.08  |proj g|=        3.1486
At iterate    20  f =      -260.33  |proj g|=        2.8704
At iterate    21  f =      -261.04  |proj g|=        2.3409
At iterate    22  f =      -262.56  |proj g|=         1.593
At iterate    23  f =      -262.71  |proj g|=        1.4277
At iterate    24  f =      -265.15  |proj g|=        1.2155
At iterate    25  f =      -267.47  |proj g|=       0.98093
At iterate    26  f =      -270.02  |proj g|=        1.1949
At iterate    27  f =      -272.76  |proj g|=        1.1137
At iterate    28  f =      -273.02  |proj g|=       0.96356
At iterate    29  f =      -273.15  |proj g|=       0.68659
At iterate    30  f =      -273.22  |proj g|=       0.68564
At iterate    31  f =      -273.23  |proj g|=       0.62807
At iterate    32  f =      -273.23  |proj g|=        0.6076
At iterate    33  f =      -273.23  |proj g|=       0.60875
At iterate    34  f =      -273.23  |proj g|=       0.60861
At iterate    35  f =      -273.23  |proj g|=       0.60855

iterations 35
function evaluations 47
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.608553
final function value -273.229

F = -273.229
final  value -273.229365 
converged
 
INFO  [04:50:33.949] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:50:34.038] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:50:34.045] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:50:44.055] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:50:55.015] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:51:04.486] [mlr3]  Finished benchmark 
INFO  [04:51:04.585] [bbotk] Result of batch 42: 
INFO  [04:51:04.587] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:51:04.587] [bbotk]              5.730619                 7.980496                       0.1036907 
INFO  [04:51:04.587] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:51:04.587] [bbotk]                     4086        0.573 -0.9642593         <NA>   0.9726184 
INFO  [04:51:04.587] [bbotk]                                 uhash 
INFO  [04:51:04.587] [bbotk]  15370e16-ea53-4f9f-bd09-d89f30bc745c 
DEBUG [04:51:05.414] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.387868e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.387868e-05 0.001728406 
  - best initial criterion value(s) :  272.9977 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -273  |proj g|=       1.1978
At iterate     1  f =      -275.26  |proj g|=         2.752
At iterate     2  f =      -276.63  |proj g|=        2.5773
At iterate     3  f =      -279.09  |proj g|=        1.7776
At iterate     4  f =      -279.25  |proj g|=        1.4928
At iterate     5  f =       -279.4  |proj g|=        1.3608
At iterate     6  f =      -279.47  |proj g|=        1.2762
At iterate     7  f =      -279.48  |proj g|=        1.2769
At iterate     8  f =      -279.48  |proj g|=        1.2765
At iterate     9  f =      -279.48  |proj g|=        1.2763

iterations 9
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.27635
final function value -279.476

F = -279.476
final  value -279.476425 
converged
 
INFO  [04:51:05.419] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:51:05.511] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:51:05.518] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:51:14.519] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:51:24.260] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:51:34.755] [mlr3]  Finished benchmark 
INFO  [04:51:34.858] [bbotk] Result of batch 43: 
INFO  [04:51:34.859] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:51:34.859] [bbotk]              9.739895                 5.716943                       0.4384364 
INFO  [04:51:34.859] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:51:34.859] [bbotk]                     4432        0.616 -0.9626937         <NA>   0.9761668 
INFO  [04:51:34.859] [bbotk]                                 uhash 
INFO  [04:51:34.859] [bbotk]  a72e9d6f-e2c8-4671-81e4-399a1381cd1b 
DEBUG [04:51:35.679] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.379282e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.379282e-05 0.001728613 
  - best initial criterion value(s) :  266.0159 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -266.02  |proj g|=      0.89187
At iterate     1  f =      -278.83  |proj g|=        4.0946
At iterate     2  f =      -279.82  |proj g|=        3.5976
At iterate     3  f =      -280.33  |proj g|=        3.6565
At iterate     4  f =      -281.33  |proj g|=        3.2095
At iterate     5  f =      -281.51  |proj g|=        2.7993
At iterate     6  f =      -281.53  |proj g|=        2.9919
At iterate     7  f =      -281.53  |proj g|=        2.9389
At iterate     8  f =      -281.53  |proj g|=        2.9309
At iterate     9  f =      -281.53  |proj g|=        2.9324
At iterate    10  f =      -281.53  |proj g|=        2.9325

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.93248
final function value -281.532

F = -281.532
final  value -281.531656 
converged
 
INFO  [04:51:35.683] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:51:35.783] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:51:35.790] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:51:44.777] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:51:53.982] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:52:01.670] [mlr3]  Finished benchmark 
INFO  [04:52:01.771] [bbotk] Result of batch 44: 
INFO  [04:52:01.772] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:52:01.772] [bbotk]              6.948564                 6.939342                       0.4093143 
INFO  [04:52:01.772] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:52:01.772] [bbotk]                     3818        0.608 -0.9630322         <NA>   0.9760398 
INFO  [04:52:01.772] [bbotk]                                 uhash 
INFO  [04:52:01.772] [bbotk]  c19e144d-1310-4174-adbe-98d82ce8d74e 
DEBUG [04:52:02.607] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.370363e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.370363e-05 0.001728386 
  - best initial criterion value(s) :  279.2801 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -279.28  |proj g|=       1.5597
At iterate     1  f =      -282.18  |proj g|=        2.5334
At iterate     2  f =      -285.62  |proj g|=        2.0129
At iterate     3  f =      -286.54  |proj g|=        1.2273
At iterate     4  f =      -286.85  |proj g|=        1.5722
At iterate     5  f =      -287.03  |proj g|=         1.539
At iterate     6  f =      -287.09  |proj g|=           1.5
At iterate     7  f =       -287.1  |proj g|=        1.5186
At iterate     8  f =       -287.1  |proj g|=        1.5162
At iterate     9  f =       -287.1  |proj g|=        1.5161

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.51608
final function value -287.099

F = -287.099
final  value -287.099237 
converged
 
INFO  [04:52:02.611] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:52:02.712] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:52:02.719] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:52:08.628] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:52:14.396] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:52:18.823] [mlr3]  Finished benchmark 
INFO  [04:52:18.920] [bbotk] Result of batch 45: 
INFO  [04:52:18.922] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:52:18.922] [bbotk]              4.325891                 8.739813                      0.02179853 
INFO  [04:52:18.922] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:52:18.922] [bbotk]                     2301        0.602 -0.9620893         <NA>   0.9478787 
INFO  [04:52:18.922] [bbotk]                                 uhash 
INFO  [04:52:18.922] [bbotk]  84e83ae7-fd1e-476e-92fd-653f2f059ba9 
DEBUG [04:52:19.728] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.403348e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.403348e-05 0.001751435 
  - best initial criterion value(s) :  280.3167 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -280.32  |proj g|=      0.34346
At iterate     1  f =       -280.6  |proj g|=       0.33755
At iterate     2  f =       -280.8  |proj g|=       0.32249
At iterate     3  f =      -281.11  |proj g|=       0.36973
At iterate     4  f =      -281.19  |proj g|=       0.27063
At iterate     5  f =      -281.19  |proj g|=        0.3828
At iterate     6  f =      -281.19  |proj g|=        0.3492
At iterate     7  f =      -281.19  |proj g|=       0.35747

iterations 7
function evaluations 12
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.357475
final function value -281.19

F = -281.19
final  value -281.190120 
converged
 
INFO  [04:52:19.733] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:52:19.820] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:52:19.827] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:52:28.384] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:52:36.259] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:52:45.842] [mlr3]  Finished benchmark 
INFO  [04:52:45.960] [bbotk] Result of batch 46: 
INFO  [04:52:45.962] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:52:45.962] [bbotk]              6.734048                 4.441135                       0.1757973 
INFO  [04:52:45.962] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:52:45.962] [bbotk]                     3832        0.595 -0.9683552         <NA>   0.9746419 
INFO  [04:52:45.962] [bbotk]                                 uhash 
INFO  [04:52:45.962] [bbotk]  81354095-e1b1-484e-9271-26bafe39a7b8 
DEBUG [04:52:46.900] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.391777e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.391777e-05 0.00174673 
  - best initial criterion value(s) :  278.5393 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -278.54  |proj g|=       4.8882
At iterate     1  f =      -289.64  |proj g|=        1.5164
At iterate     2  f =      -291.48  |proj g|=        1.4495
At iterate     3  f =      -293.75  |proj g|=          1.91
At iterate     4  f =      -294.49  |proj g|=        1.5016
At iterate     5  f =      -295.54  |proj g|=        1.3175
At iterate     6  f =      -298.57  |proj g|=        1.4503
At iterate     7  f =      -300.25  |proj g|=        1.4454
At iterate     8  f =      -300.55  |proj g|=        1.6178
At iterate     9  f =       -300.6  |proj g|=        1.5588
At iterate    10  f =       -300.6  |proj g|=        1.5347
At iterate    11  f =       -300.6  |proj g|=        1.5372
At iterate    12  f =      -300.61  |proj g|=        1.5484
At iterate    13  f =      -300.61  |proj g|=        1.5429
At iterate    14  f =      -301.01  |proj g|=        1.5111
At iterate    15  f =      -302.23  |proj g|=        1.4908
At iterate    16  f =      -302.37  |proj g|=        1.5143
At iterate    17  f =      -302.39  |proj g|=        1.5352
At iterate    18  f =      -302.39  |proj g|=        1.5432
At iterate    19  f =      -302.39  |proj g|=        1.5467
At iterate    20  f =      -302.39  |proj g|=        1.5463
At iterate    21  f =      -302.39  |proj g|=        1.5456
At iterate    22  f =      -302.39  |proj g|=         1.544
At iterate    23  f =      -302.39  |proj g|=        1.5407
At iterate    24  f =      -302.39  |proj g|=        1.5354
At iterate    25  f =      -302.39  |proj g|=        1.5268
At iterate    26  f =       -302.4  |proj g|=         1.512
At iterate    27  f =      -302.41  |proj g|=        1.4863
At iterate    28  f =      -302.45  |proj g|=        1.4398
At iterate    29  f =      -302.55  |proj g|=        1.3548
At iterate    30  f =      -302.83  |proj g|=        1.2041
At iterate    31  f =      -303.46  |proj g|=       0.98145
At iterate    32  f =      -304.39  |proj g|=         0.812
At iterate    33  f =      -304.92  |proj g|=       0.82939
At iterate    34  f =      -305.02  |proj g|=       0.84865
At iterate    35  f =      -305.03  |proj g|=       0.87367
At iterate    36  f =      -305.05  |proj g|=       0.90108
At iterate    37  f =      -305.08  |proj g|=       0.93704
At iterate    38  f =      -305.15  |proj g|=       0.98619
At iterate    39  f =      -305.86  |proj g|=       0.87942
At iterate    40  f =      -306.24  |proj g|=       0.79898
At iterate    41  f =      -308.17  |proj g|=       0.51528
At iterate    42  f =      -308.27  |proj g|=       0.53308
At iterate    43  f =      -308.32  |proj g|=      0.056122
At iterate    44  f =      -308.32  |proj g|=       0.14321
At iterate    45  f =      -308.32  |proj g|=      0.080071
At iterate    46  f =      -308.32  |proj g|=      0.079871

iterations 46
function evaluations 61
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0798708
final function value -308.321

F = -308.321
final  value -308.320971 
converged
 
INFO  [04:52:46.904] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:52:46.993] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:52:47.000] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:52:53.779] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:52:59.306] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:53:05.473] [mlr3]  Finished benchmark 
INFO  [04:53:05.572] [bbotk] Result of batch 47: 
INFO  [04:53:05.574] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:53:05.574] [bbotk]              5.688093                 9.276144                       0.4262953 
INFO  [04:53:05.574] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:53:05.574] [bbotk]                     2457        0.619 -0.9525327         <NA>   0.9754296 
INFO  [04:53:05.574] [bbotk]                                 uhash 
INFO  [04:53:05.574] [bbotk]  2290f874-8c85-4afa-93d8-6dd6dc3b023d 
DEBUG [04:53:06.494] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.381864e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.381864e-05 0.001732359 
  - best initial criterion value(s) :  287.55 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -287.55  |proj g|=       1.8655
At iterate     1  f =      -293.89  |proj g|=        1.5483
At iterate     2  f =      -304.25  |proj g|=        1.0244
At iterate     3  f =      -304.87  |proj g|=       0.88743
At iterate     4  f =      -306.32  |proj g|=       0.75732
At iterate     5  f =      -306.44  |proj g|=       0.84342
At iterate     6  f =      -306.44  |proj g|=       0.84315
At iterate     7  f =      -306.44  |proj g|=       0.84321
At iterate     8  f =      -306.44  |proj g|=       0.84322
At iterate     9  f =      -306.44  |proj g|=       0.84328
At iterate    10  f =      -306.44  |proj g|=       0.84336
At iterate    11  f =      -306.44  |proj g|=       0.84417
At iterate    12  f =      -306.44  |proj g|=       0.84263
At iterate    13  f =      -306.44  |proj g|=       0.84685
At iterate    14  f =      -306.44  |proj g|=       0.84131
At iterate    15  f =      -306.46  |proj g|=       0.83334
At iterate    16  f =      -306.52  |proj g|=       0.80442
At iterate    17  f =      -306.63  |proj g|=        0.7593
At iterate    18  f =      -306.84  |proj g|=       0.68423
At iterate    19  f =      -307.12  |proj g|=       0.61307
At iterate    20  f =      -307.12  |proj g|=       0.63671
At iterate    21  f =       -307.4  |proj g|=       0.58971
At iterate    22  f =      -307.47  |proj g|=       0.65366
At iterate    23  f =      -307.48  |proj g|=       0.62499
At iterate    24  f =      -307.48  |proj g|=       0.62212
At iterate    25  f =      -307.48  |proj g|=       0.62262
At iterate    26  f =      -307.48  |proj g|=       0.62255

iterations 26
function evaluations 37
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.622548
final function value -307.482

F = -307.482
final  value -307.482081 
converged
 
INFO  [04:53:06.498] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:53:06.585] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:53:06.592] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:53:14.400] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:53:23.458] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:53:33.015] [mlr3]  Finished benchmark 
INFO  [04:53:33.130] [bbotk] Result of batch 48: 
INFO  [04:53:33.132] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:53:33.132] [bbotk]              5.825662                 2.442166                       0.1807336 
INFO  [04:53:33.132] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:53:33.132] [bbotk]                     3631        0.633 -0.9597947         <NA>   0.9742802 
INFO  [04:53:33.132] [bbotk]                                 uhash 
INFO  [04:53:33.132] [bbotk]  c9527568-8948-4011-8f43-295f1bc6560e 
DEBUG [04:53:34.196] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.369876e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.369876e-05 0.001732232 
  - best initial criterion value(s) :  282.3263 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -282.33  |proj g|=       3.3538
At iterate     1  f =       -285.2  |proj g|=         5.396
At iterate     2  f =      -288.44  |proj g|=        4.7252
At iterate     3  f =      -290.35  |proj g|=        3.9025
At iterate     4  f =      -293.87  |proj g|=         3.185
At iterate     5  f =      -296.48  |proj g|=        3.0634
At iterate     6  f =       -296.5  |proj g|=        3.0474
At iterate     7  f =      -296.51  |proj g|=        3.0663
At iterate     8  f =      -296.51  |proj g|=        3.0621
At iterate     9  f =      -296.51  |proj g|=        3.0604
At iterate    10  f =      -296.51  |proj g|=        3.0574
At iterate    11  f =      -296.51  |proj g|=        3.0525
At iterate    12  f =      -296.51  |proj g|=        3.0446
At iterate    13  f =      -296.51  |proj g|=        3.0325
At iterate    14  f =      -296.52  |proj g|=        3.0114
At iterate    15  f =      -296.53  |proj g|=        2.9842
At iterate    16  f =      -296.54  |proj g|=        2.9582
At iterate    17  f =      -296.58  |proj g|=         2.924
At iterate    18  f =      -297.24  |proj g|=        2.7717
At iterate    19  f =      -308.78  |proj g|=        1.2154
At iterate    20  f =      -313.16  |proj g|=       0.65046
At iterate    21  f =      -315.28  |proj g|=       0.89125
At iterate    22  f =      -315.85  |proj g|=       0.86158
At iterate    23  f =      -317.14  |proj g|=       0.61794
At iterate    24  f =      -317.17  |proj g|=       0.61664
At iterate    25  f =      -317.19  |proj g|=       0.61388
At iterate    26  f =      -317.21  |proj g|=       0.61111
At iterate    27  f =      -317.26  |proj g|=       0.60225
At iterate    28  f =      -317.34  |proj g|=       0.39005
At iterate    29  f =      -317.43  |proj g|=       0.56869
At iterate    30  f =      -317.44  |proj g|=       0.39174
At iterate    31  f =      -317.44  |proj g|=      0.038831
At iterate    32  f =      -317.44  |proj g|=      0.038631

iterations 32
function evaluations 41
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0386312
final function value -317.436

F = -317.436
final  value -317.436450 
converged
 
INFO  [04:53:34.200] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:53:34.283] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:53:34.290] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:53:41.832] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:53:47.541] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:53:53.441] [mlr3]  Finished benchmark 
INFO  [04:53:53.575] [bbotk] Result of batch 49: 
INFO  [04:53:53.578] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:53:53.578] [bbotk]              5.309148                 6.449847                       0.3152909 
INFO  [04:53:53.578] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:53:53.578] [bbotk]                     3629        0.773 -0.9551451         <NA>   0.9755681 
INFO  [04:53:53.578] [bbotk]                                 uhash 
INFO  [04:53:53.578] [bbotk]  5b93d629-e026-44f1-b796-12cacfa05b56 
DEBUG [04:53:54.687] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.360397e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.360397e-05 0.001734766 
  - best initial criterion value(s) :  290.2457 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -290.25  |proj g|=       4.0497
At iterate     1  f =      -294.97  |proj g|=        5.4855
At iterate     2  f =      -298.17  |proj g|=        4.2177
At iterate     3  f =      -300.08  |proj g|=        4.1513
At iterate     4  f =      -303.18  |proj g|=        2.8781
At iterate     5  f =      -303.75  |proj g|=         2.487
At iterate     6  f =      -303.97  |proj g|=        2.7355
At iterate     7  f =      -303.99  |proj g|=        2.6934
At iterate     8  f =         -304  |proj g|=        2.6871
At iterate     9  f =         -304  |proj g|=        2.6873
At iterate    10  f =         -304  |proj g|=        2.6882
At iterate    11  f =         -304  |proj g|=        2.6893
At iterate    12  f =         -304  |proj g|=        2.6913
At iterate    13  f =         -304  |proj g|=        2.6942
At iterate    14  f =         -304  |proj g|=        2.6976
At iterate    15  f =         -304  |proj g|=        2.7149
At iterate    16  f =      -304.01  |proj g|=        2.7145
At iterate    17  f =      -304.03  |proj g|=        2.7131
At iterate    18  f =       -304.1  |proj g|=        2.7118
At iterate    19  f =       -304.3  |proj g|=        2.7116
At iterate    20  f =      -305.03  |proj g|=        2.7139
At iterate    21  f =      -305.38  |proj g|=        2.5096
At iterate    22  f =       -307.1  |proj g|=         2.573
At iterate    23  f =      -309.08  |proj g|=        2.5123
At iterate    24  f =      -310.46  |proj g|=        2.4444
At iterate    25  f =      -311.19  |proj g|=        2.4236
At iterate    26  f =      -311.58  |proj g|=         2.455
At iterate    27  f =      -311.65  |proj g|=        2.6017
At iterate    28  f =      -311.76  |proj g|=        2.5861
At iterate    29  f =      -311.78  |proj g|=        2.5629
At iterate    30  f =       -311.8  |proj g|=        2.5769
At iterate    31  f =       -311.8  |proj g|=         2.586
At iterate    32  f =       -311.8  |proj g|=        2.5877
At iterate    33  f =       -311.8  |proj g|=         2.588
At iterate    34  f =       -311.8  |proj g|=        2.5879

iterations 34
function evaluations 41
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.58791
final function value -311.797

F = -311.797
final  value -311.797281 
converged
 
INFO  [04:53:54.692] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:53:54.794] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:53:54.801] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:54:00.424] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:54:05.997] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:54:11.568] [mlr3]  Finished benchmark 
INFO  [04:54:11.668] [bbotk] Result of batch 50: 
INFO  [04:54:11.670] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:54:11.670] [bbotk]               9.55525                 2.649367                       0.2112195 
INFO  [04:54:11.670] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:54:11.670] [bbotk]                     3612        0.798 -0.9571335         <NA>   0.9755439 
INFO  [04:54:11.670] [bbotk]                                 uhash 
INFO  [04:54:11.670] [bbotk]  6058a06b-0d54-4ea1-98a6-d6fd1ee1826e 
DEBUG [04:54:12.561] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.350916e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.350916e-05 0.001728905 
  - best initial criterion value(s) :  311.7044 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -311.7  |proj g|=       1.1003
At iterate     1  f =       -312.2  |proj g|=        1.5126
At iterate     2  f =      -312.25  |proj g|=        1.4412
At iterate     3  f =      -312.45  |proj g|=        1.1496
At iterate     4  f =      -312.64  |proj g|=       0.94226
At iterate     5  f =      -312.79  |proj g|=       0.91821
At iterate     6  f =      -312.79  |proj g|=       0.92136
At iterate     7  f =      -312.79  |proj g|=       0.92263
At iterate     8  f =      -312.79  |proj g|=       0.92264

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.922642
final function value -312.793

F = -312.793
final  value -312.792554 
converged
 
INFO  [04:54:12.565] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:54:12.653] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:54:12.661] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:54:19.609] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:54:26.366] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:54:33.516] [mlr3]  Finished benchmark 
INFO  [04:54:33.642] [bbotk] Result of batch 51: 
INFO  [04:54:33.644] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:54:33.644] [bbotk]                7.1771                 4.754874                       0.3146963 
INFO  [04:54:33.644] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:54:33.644] [bbotk]                     4548        0.654 -0.9646694         <NA>   0.9759518 
INFO  [04:54:33.644] [bbotk]                                 uhash 
INFO  [04:54:33.644] [bbotk]  8c7c096f-d832-4687-9f1f-f6560d017d73 
DEBUG [04:54:34.746] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.342275e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.342275e-05 0.001732943 
  - best initial criterion value(s) :  287.4381 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -287.44  |proj g|=       8.6036
At iterate     1  f =      -298.76  |proj g|=        7.0608
At iterate     2  f =      -302.14  |proj g|=        5.6703
At iterate     3  f =      -306.22  |proj g|=        3.6805
At iterate     4  f =      -308.41  |proj g|=        2.9709
At iterate     5  f =      -308.57  |proj g|=        2.6977
At iterate     6  f =      -308.59  |proj g|=        2.7066
At iterate     7  f =      -308.59  |proj g|=         2.748
At iterate     8  f =      -308.59  |proj g|=        2.7306
At iterate     9  f =      -308.59  |proj g|=        2.7273
At iterate    10  f =      -308.59  |proj g|=        2.7208
At iterate    11  f =       -308.6  |proj g|=        2.7078
At iterate    12  f =       -308.6  |proj g|=        2.6925
At iterate    13  f =      -308.62  |proj g|=        2.6668
At iterate    14  f =      -308.68  |proj g|=        2.6284
At iterate    15  f =      -308.81  |proj g|=         2.585
At iterate    16  f =      -309.13  |proj g|=        2.5694
At iterate    17  f =      -309.64  |proj g|=        2.6796
At iterate    18  f =      -309.92  |proj g|=        2.9273
At iterate    19  f =      -309.96  |proj g|=        2.9989
At iterate    20  f =      -309.99  |proj g|=         3.066
At iterate    21  f =      -310.03  |proj g|=        3.1233
At iterate    22  f =      -310.11  |proj g|=        3.1902
At iterate    23  f =       -310.3  |proj g|=        3.2563
At iterate    24  f =      -310.68  |proj g|=        3.2702
At iterate    25  f =      -311.65  |proj g|=        3.2874
At iterate    26  f =       -313.6  |proj g|=        3.9356
At iterate    27  f =      -314.85  |proj g|=        4.1863
At iterate    28  f =      -316.33  |proj g|=        4.0356
At iterate    29  f =       -317.7  |proj g|=        3.5704
At iterate    30  f =       -319.3  |proj g|=        3.7968
At iterate    31  f =      -321.37  |proj g|=        4.4635
At iterate    32  f =      -321.65  |proj g|=        4.4584
At iterate    33  f =      -321.69  |proj g|=        4.4049
At iterate    34  f =      -321.71  |proj g|=        4.3775
At iterate    35  f =      -321.71  |proj g|=        4.3631
At iterate    36  f =      -321.71  |proj g|=        4.3644
At iterate    37  f =      -321.71  |proj g|=        4.3647
At iterate    38  f =      -321.71  |proj g|=        4.3659
At iterate    39  f =      -321.71  |proj g|=        4.3676
At iterate    40  f =      -321.72  |proj g|=        4.3704
At iterate    41  f =      -321.72  |proj g|=        4.3749
At iterate    42  f =      -321.72  |proj g|=        4.3821
At iterate    43  f =      -321.72  |proj g|=        4.3937
At iterate    44  f =      -321.72  |proj g|=        4.4112
At iterate    45  f =      -321.73  |proj g|=        4.4308
At iterate    46  f =      -321.74  |proj g|=         4.439
At iterate    47  f =      -321.74  |proj g|=        4.4469
At iterate    48  f =      -321.75  |proj g|=        4.4154
At iterate    49  f =      -321.76  |proj g|=        4.4269
At iterate    50  f =       -324.2  |proj g|=        3.5591
At iterate    51  f =      -328.85  |proj g|=         2.015
At iterate    52  f =      -332.62  |proj g|=       0.94081
At iterate    53  f =      -334.73  |proj g|=       0.43801
At iterate    54  f =      -335.11  |proj g|=       0.52604
At iterate    55  f =      -335.36  |proj g|=       0.52634
At iterate    56  f =      -335.41  |proj g|=       0.52378
At iterate    57  f =      -335.41  |proj g|=       0.52326
At iterate    58  f =      -335.42  |proj g|=       0.52201
At iterate    59  f =      -335.42  |proj g|=       0.39246
At iterate    60  f =      -335.42  |proj g|=       0.33545
At iterate    61  f =      -335.42  |proj g|=     0.0069125
At iterate    62  f =      -335.42  |proj g|=      0.011884
At iterate    63  f =      -335.42  |proj g|=     0.0012506

iterations 63
function evaluations 73
segments explored during Cauchy searches 66
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00125062
final function value -335.425

F = -335.425
final  value -335.424648 
converged
 
INFO  [04:54:34.748] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:54:34.828] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:54:34.835] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:54:38.425] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:54:41.892] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:54:45.278] [mlr3]  Finished benchmark 
INFO  [04:54:45.381] [bbotk] Result of batch 52: 
INFO  [04:54:45.383] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:54:45.383] [bbotk]              6.522559                  2.10797                       0.2449991 
INFO  [04:54:45.383] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:54:45.383] [bbotk]                     2163        0.676 -0.9518131         <NA>   0.9738191 
INFO  [04:54:45.383] [bbotk]                                 uhash 
INFO  [04:54:45.383] [bbotk]  eb24330b-51e8-485f-9967-59be2e147734 
DEBUG [04:54:46.493] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.330081e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.330081e-05 0.001710643 
  - best initial criterion value(s) :  319.8409 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -319.84  |proj g|=       1.1142
At iterate     1  f =       -319.9  |proj g|=        1.0449
At iterate     2  f =      -319.93  |proj g|=        1.1135
At iterate     3  f =      -319.94  |proj g|=        1.1696
At iterate     4  f =      -319.94  |proj g|=         1.176
At iterate     5  f =      -319.94  |proj g|=        1.1764

iterations 5
function evaluations 8
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.17637
final function value -319.938

F = -319.938
final  value -319.937908 
converged
 
INFO  [04:54:46.497] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:54:46.611] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:54:46.618] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:54:49.227] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:54:51.947] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:54:54.726] [mlr3]  Finished benchmark 
INFO  [04:54:54.827] [bbotk] Result of batch 53: 
INFO  [04:54:54.829] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:54:54.829] [bbotk]              2.899477                 5.374839                      0.05315208 
INFO  [04:54:54.829] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:54:54.829] [bbotk]                     1675         0.84 -0.9663015         <NA>   0.9435633 
INFO  [04:54:54.829] [bbotk]                                 uhash 
INFO  [04:54:54.829] [bbotk]  84a67b13-7860-409a-b1c3-40d84b3d4057 
DEBUG [04:54:55.963] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.385166e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.385166e-05 0.001770061 
  - best initial criterion value(s) :  326.113 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -326.11  |proj g|=       3.4285
At iterate     1  f =      -332.68  |proj g|=       0.97614
At iterate     2  f =      -335.35  |proj g|=       0.99938
At iterate     3  f =      -337.68  |proj g|=        1.0347
At iterate     4  f =      -338.15  |proj g|=        0.9894
At iterate     5  f =      -339.38  |proj g|=        1.0264
At iterate     6  f =      -340.72  |proj g|=        1.0643
At iterate     7  f =       -341.1  |proj g|=        1.0905
At iterate     8  f =      -341.23  |proj g|=        1.1149
At iterate     9  f =      -341.26  |proj g|=        1.1319
At iterate    10  f =      -341.26  |proj g|=        1.1419
At iterate    11  f =      -341.26  |proj g|=        1.1451
At iterate    12  f =      -341.26  |proj g|=        1.1455
At iterate    13  f =      -341.26  |proj g|=        1.1456
At iterate    14  f =      -341.26  |proj g|=        1.1458
At iterate    15  f =      -341.26  |proj g|=        1.1462
At iterate    16  f =      -341.26  |proj g|=        1.1466
At iterate    17  f =      -341.26  |proj g|=        1.1474
At iterate    18  f =      -341.27  |proj g|=        1.1483
At iterate    19  f =      -341.27  |proj g|=        1.1512
At iterate    20  f =      -341.27  |proj g|=        1.1524
At iterate    21  f =      -341.27  |proj g|=        1.1572
At iterate    22  f =      -341.29  |proj g|=        1.1568
At iterate    23  f =      -341.29  |proj g|=        1.1634
At iterate    24  f =      -341.32  |proj g|=        1.1568
At iterate    25  f =      -341.46  |proj g|=        1.0685
At iterate    26  f =      -341.46  |proj g|=        1.0934
At iterate    27  f =      -341.46  |proj g|=        1.0882
At iterate    28  f =      -341.46  |proj g|=        1.0878
At iterate    29  f =      -341.46  |proj g|=        1.0877

iterations 29
function evaluations 36
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.08774
final function value -341.464

F = -341.464
final  value -341.463858 
converged
 
INFO  [04:54:55.968] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:54:56.075] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:54:56.084] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:55:03.408] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:55:10.952] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:55:18.540] [mlr3]  Finished benchmark 
INFO  [04:55:18.673] [bbotk] Result of batch 54: 
INFO  [04:55:18.675] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:55:18.675] [bbotk]              4.779159                 4.442299                       0.1054285 
INFO  [04:55:18.675] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:55:18.675] [bbotk]                     2931        0.777 -0.9557585         <NA>   0.9700319 
INFO  [04:55:18.675] [bbotk]                                 uhash 
INFO  [04:55:18.675] [bbotk]  b7dcc2be-6cb3-4743-ae38-7828bce86494 
DEBUG [04:55:19.519] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.369309e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.369308e-05 0.001753114 
  - best initial criterion value(s) :  328.1044 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -328.1  |proj g|=      0.94042
At iterate     1  f =       -329.6  |proj g|=        2.5325
At iterate     2  f =      -332.46  |proj g|=        2.2412
At iterate     3  f =      -333.76  |proj g|=        1.6789
At iterate     4  f =      -333.83  |proj g|=        1.6826
At iterate     5  f =      -333.89  |proj g|=        1.8417
At iterate     6  f =       -333.9  |proj g|=          1.87
At iterate     7  f =       -333.9  |proj g|=        1.8746
At iterate     8  f =       -333.9  |proj g|=        1.8747

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.87465
final function value -333.896

F = -333.896
final  value -333.896435 
converged
 
INFO  [04:55:19.523] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:55:19.611] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:55:19.618] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:55:27.423] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:55:35.403] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:55:44.950] [mlr3]  Finished benchmark 
INFO  [04:55:45.076] [bbotk] Result of batch 55: 
INFO  [04:55:45.079] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:55:45.079] [bbotk]               9.45567                  9.61629                       0.3958253 
INFO  [04:55:45.079] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:55:45.079] [bbotk]                     3482        0.625 -0.9643057         <NA>   0.9763879 
INFO  [04:55:45.079] [bbotk]                                 uhash 
INFO  [04:55:45.079] [bbotk]  9fb9a12e-4355-43df-9d05-88c0cb899930 
DEBUG [04:55:46.143] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.361895e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.361895e-05 0.001749748 
  - best initial criterion value(s) :  336.3791 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -336.38  |proj g|=       1.2426
At iterate     1  f =      -340.08  |proj g|=        1.5427
At iterate     2  f =       -340.2  |proj g|=        1.5272
At iterate     3  f =      -340.33  |proj g|=        1.5016
At iterate     4  f =      -340.43  |proj g|=        1.4978
At iterate     5  f =       -341.2  |proj g|=        1.4997
At iterate     6  f =      -342.06  |proj g|=        1.5327
At iterate     7  f =       -342.8  |proj g|=        1.7107
At iterate     8  f =      -342.95  |proj g|=        1.7031
At iterate     9  f =      -342.98  |proj g|=        1.6987
At iterate    10  f =      -342.98  |proj g|=        1.7002
At iterate    11  f =      -342.98  |proj g|=        1.7025
At iterate    12  f =      -342.98  |proj g|=        1.7022
At iterate    13  f =      -342.98  |proj g|=        1.7019
At iterate    14  f =      -342.98  |proj g|=        1.7014
At iterate    15  f =      -342.98  |proj g|=        1.7006
At iterate    16  f =      -342.98  |proj g|=        1.6994
At iterate    17  f =      -342.98  |proj g|=        1.6977
At iterate    18  f =      -342.98  |proj g|=        1.6956
At iterate    19  f =      -342.99  |proj g|=        1.6937
At iterate    20  f =      -342.99  |proj g|=        1.6905
At iterate    21  f =      -343.01  |proj g|=        1.6791
At iterate    22  f =      -343.03  |proj g|=         1.683
At iterate    23  f =      -343.06  |proj g|=        1.6543
At iterate    24  f =      -343.21  |proj g|=        1.6605
At iterate    25  f =      -343.38  |proj g|=        1.8824
At iterate    26  f =      -343.52  |proj g|=        2.1872
At iterate    27  f =      -343.53  |proj g|=        2.2327
At iterate    28  f =      -343.53  |proj g|=        2.2279
At iterate    29  f =      -343.53  |proj g|=        2.2252
At iterate    30  f =      -343.53  |proj g|=        2.2234
At iterate    31  f =      -343.53  |proj g|=        2.2253
At iterate    32  f =      -343.53  |proj g|=        2.2252
At iterate    33  f =      -343.53  |proj g|=        2.2266
At iterate    34  f =      -343.53  |proj g|=        2.2261
At iterate    35  f =      -343.53  |proj g|=        2.2247
At iterate    36  f =      -343.53  |proj g|=        2.2231
At iterate    37  f =      -343.53  |proj g|=        2.2204
At iterate    38  f =      -343.53  |proj g|=        2.2169
At iterate    39  f =      -343.53  |proj g|=        2.2159
At iterate    40  f =      -343.53  |proj g|=        2.1971
At iterate    41  f =      -343.55  |proj g|=        2.2062
At iterate    42  f =      -343.89  |proj g|=        2.9856
At iterate    43  f =      -343.93  |proj g|=        2.9574
At iterate    44  f =      -343.93  |proj g|=        2.9456
At iterate    45  f =      -343.93  |proj g|=        2.9479
At iterate    46  f =      -343.94  |proj g|=        2.9662
At iterate    47  f =      -343.95  |proj g|=        2.9919
At iterate    48  f =      -343.95  |proj g|=        2.9553
At iterate    49  f =      -343.96  |proj g|=        2.9501
At iterate    50  f =      -343.99  |proj g|=        2.8358
At iterate    51  f =         -344  |proj g|=         2.786
At iterate    52  f =         -344  |proj g|=        2.7612
At iterate    53  f =      -344.01  |proj g|=        2.7143
At iterate    54  f =      -344.03  |proj g|=        2.5832
At iterate    55  f =      -344.05  |proj g|=        2.5882
At iterate    56  f =      -344.25  |proj g|=        2.2137
At iterate    57  f =       -344.8  |proj g|=        1.7788
At iterate    58  f =      -346.79  |proj g|=        1.2141
At iterate    59  f =      -349.07  |proj g|=        1.0047
At iterate    60  f =      -351.66  |proj g|=       0.35576
At iterate    61  f =      -352.47  |proj g|=       0.61927
At iterate    62  f =      -352.48  |proj g|=       0.62021
At iterate    63  f =       -352.5  |proj g|=       0.61836
At iterate    64  f =       -352.5  |proj g|=       0.61561
At iterate    65  f =       -352.5  |proj g|=        0.4486
At iterate    66  f =       -352.5  |proj g|=      0.095329
At iterate    67  f =       -352.5  |proj g|=      0.020483
At iterate    68  f =       -352.5  |proj g|=      0.025927
At iterate    69  f =       -352.5  |proj g|=     0.0026672
At iterate    70  f =       -352.5  |proj g|=     0.0019772

iterations 70
function evaluations 82
segments explored during Cauchy searches 72
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0019772
final function value -352.5

F = -352.5
final  value -352.499654 
converged
 
INFO  [04:55:46.148] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:55:46.246] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:55:46.253] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:55:48.668] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:55:51.034] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:55:53.503] [mlr3]  Finished benchmark 
INFO  [04:55:53.608] [bbotk] Result of batch 56: 
INFO  [04:55:53.610] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:55:53.610] [bbotk]              4.893937                 2.602725                       0.3224199 
INFO  [04:55:53.610] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:55:53.610] [bbotk]                      960        0.638 -0.9556555         <NA>    0.970231 
INFO  [04:55:53.610] [bbotk]                                 uhash 
INFO  [04:55:53.610] [bbotk]  98bff916-6206-42c5-a726-e32431c79047 
DEBUG [04:55:54.574] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.346716e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.346716e-05 0.001713127 
  - best initial criterion value(s) :  329.8106 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -329.81  |proj g|=       9.7977
At iterate     1  f =      -332.16  |proj g|=        7.4121
At iterate     2  f =      -339.55  |proj g|=        5.6462
At iterate     3  f =       -344.7  |proj g|=        3.5198
At iterate     4  f =      -346.41  |proj g|=         1.343
At iterate     5  f =      -346.43  |proj g|=        1.3164
At iterate     6  f =      -346.76  |proj g|=        1.3606
At iterate     7  f =      -346.77  |proj g|=        1.2793
At iterate     8  f =      -346.77  |proj g|=        1.2871
At iterate     9  f =      -346.77  |proj g|=        1.2859
At iterate    10  f =      -346.77  |proj g|=        1.2845
At iterate    11  f =      -346.77  |proj g|=        1.2823
At iterate    12  f =      -346.77  |proj g|=        1.2781
At iterate    13  f =      -346.77  |proj g|=        1.2723
At iterate    14  f =      -346.77  |proj g|=         1.262
At iterate    15  f =      -346.77  |proj g|=        1.2466
At iterate    16  f =      -346.78  |proj g|=        1.2215
At iterate    17  f =      -346.78  |proj g|=        1.2118
At iterate    18  f =      -346.78  |proj g|=        1.1805
At iterate    19  f =      -346.81  |proj g|=        1.1106
At iterate    20  f =      -347.11  |proj g|=       0.97102
At iterate    21  f =      -348.31  |proj g|=        0.9998
At iterate    22  f =      -349.96  |proj g|=        1.0094
At iterate    23  f =      -350.05  |proj g|=        1.0558
At iterate    24  f =      -350.66  |proj g|=        1.0353
At iterate    25  f =      -350.85  |proj g|=        1.0248
At iterate    26  f =      -350.92  |proj g|=        1.0263
At iterate    27  f =      -350.94  |proj g|=        1.0304
At iterate    28  f =      -350.94  |proj g|=        1.0317
At iterate    29  f =      -350.94  |proj g|=        1.0301
At iterate    30  f =      -350.94  |proj g|=        1.0317
At iterate    31  f =      -350.94  |proj g|=        1.0314
At iterate    32  f =      -350.94  |proj g|=        1.0313

iterations 32
function evaluations 38
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.03131
final function value -350.937

F = -350.937
final  value -350.936972 
converged
 
INFO  [04:55:54.578] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:55:54.677] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:55:54.685] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:56:00.003] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:56:05.658] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:56:11.221] [mlr3]  Finished benchmark 
INFO  [04:56:11.323] [bbotk] Result of batch 57: 
INFO  [04:56:11.325] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:56:11.325] [bbotk]              3.666036                 6.828636                       0.2096104 
INFO  [04:56:11.325] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:56:11.325] [bbotk]                     2572        0.672 -0.959821         <NA>    0.970629 
INFO  [04:56:11.325] [bbotk]                                 uhash 
INFO  [04:56:11.325] [bbotk]  8ad7330e-47fa-4e9b-833f-0128de44a22a 
DEBUG [04:56:12.384] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.332103e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.332103e-05 0.001697468 
  - best initial criterion value(s) :  334.7606 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -334.76  |proj g|=       1.0664
At iterate     1  f =      -336.93  |proj g|=        2.8673
At iterate     2  f =       -338.7  |proj g|=        2.6565
At iterate     3  f =      -340.27  |proj g|=        2.2338
At iterate     4  f =       -340.7  |proj g|=        2.0522
At iterate     5  f =      -341.87  |proj g|=        1.9417
At iterate     6  f =      -343.35  |proj g|=        2.0376
At iterate     7  f =      -343.58  |proj g|=        2.3132
At iterate     8  f =      -343.76  |proj g|=        2.2277
At iterate     9  f =      -343.77  |proj g|=        2.2215
At iterate    10  f =      -343.77  |proj g|=        2.2264
At iterate    11  f =      -343.77  |proj g|=        2.2257
At iterate    12  f =      -343.77  |proj g|=        2.2256

iterations 12
function evaluations 17
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.22564
final function value -343.767

F = -343.767
final  value -343.767399 
converged
 
INFO  [04:56:12.388] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:56:12.486] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:56:12.492] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:56:19.930] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:56:27.762] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:56:36.386] [mlr3]  Finished benchmark 
INFO  [04:56:36.498] [bbotk] Result of batch 58: 
INFO  [04:56:36.500] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:56:36.500] [bbotk]              2.840182                 9.842803                       0.3032247 
INFO  [04:56:36.500] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:56:36.500] [bbotk]                     3753         0.82 -0.9638951         <NA>    0.968951 
INFO  [04:56:36.500] [bbotk]                                 uhash 
INFO  [04:56:36.500] [bbotk]  9c4566f9-2bd8-46a2-808f-20d8bc8e33e6 
DEBUG [04:56:37.445] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.31709e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.31709e-05 0.001683973 
  - best initial criterion value(s) :  331.9544 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -331.95  |proj g|=       5.6213
At iterate     1  f =       -340.8  |proj g|=        1.5502
At iterate     2  f =      -349.06  |proj g|=        3.8618
At iterate     3  f =      -350.42  |proj g|=        4.4721
At iterate     4  f =      -350.74  |proj g|=        4.4593
At iterate     5  f =      -350.82  |proj g|=        4.5243
At iterate     6  f =      -350.82  |proj g|=        4.5904
At iterate     7  f =      -350.82  |proj g|=        4.5833
At iterate     8  f =      -350.82  |proj g|=         4.573
At iterate     9  f =      -350.83  |proj g|=        4.5609
At iterate    10  f =      -350.83  |proj g|=        4.5129
At iterate    11  f =      -350.84  |proj g|=         4.532
At iterate    12  f =      -350.86  |proj g|=        4.4626
At iterate    13  f =      -350.92  |proj g|=        4.3245
At iterate    14  f =      -351.05  |proj g|=        4.1114
At iterate    15  f =       -351.4  |proj g|=        3.7735
At iterate    16  f =      -352.27  |proj g|=         3.208
At iterate    17  f =      -352.51  |proj g|=        2.8112
At iterate    18  f =      -354.52  |proj g|=        2.2024
At iterate    19  f =      -358.81  |proj g|=        1.3878
At iterate    20  f =      -367.27  |proj g|=        1.4448
At iterate    21  f =      -367.76  |proj g|=        1.4743
At iterate    22  f =      -367.91  |proj g|=        1.4736
At iterate    23  f =      -367.94  |proj g|=        1.4392
At iterate    24  f =      -367.94  |proj g|=        1.4363
At iterate    25  f =      -367.94  |proj g|=        1.4365
At iterate    26  f =      -367.94  |proj g|=        1.4364
At iterate    27  f =      -367.94  |proj g|=        1.4298
At iterate    28  f =      -367.95  |proj g|=        1.4308
At iterate    29  f =      -367.95  |proj g|=        1.4318
At iterate    30  f =      -367.95  |proj g|=        1.4329
At iterate    31  f =      -367.96  |proj g|=        1.4342
At iterate    32  f =      -367.97  |proj g|=         1.425
At iterate    33  f =      -368.09  |proj g|=        1.3508
At iterate    34  f =       -368.3  |proj g|=        1.1084
At iterate    35  f =         -369  |proj g|=       0.60963
At iterate    36  f =      -369.24  |proj g|=       0.61318
At iterate    37  f =      -369.68  |proj g|=       0.58159
At iterate    38  f =      -369.93  |proj g|=       0.54504
At iterate    39  f =      -369.94  |proj g|=       0.34715
At iterate    40  f =      -369.94  |proj g|=       0.06629
At iterate    41  f =      -369.94  |proj g|=      0.065095
At iterate    42  f =      -369.94  |proj g|=      0.064983

iterations 42
function evaluations 53
segments explored during Cauchy searches 45
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.064983
final function value -369.944

F = -369.944
final  value -369.943722 
converged
 
INFO  [04:56:37.449] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:56:37.536] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:56:37.543] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:56:49.537] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:57:00.847] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:57:12.243] [mlr3]  Finished benchmark 
INFO  [04:57:12.346] [bbotk] Result of batch 59: 
INFO  [04:57:12.348] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:57:12.348] [bbotk]              2.485621                  9.73579                      0.07242238 
INFO  [04:57:12.348] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:57:12.348] [bbotk]                     4711        0.627 -0.949401         <NA>   0.9561011 
INFO  [04:57:12.348] [bbotk]                                 uhash 
INFO  [04:57:12.348] [bbotk]  a9ae9511-3e03-44e3-bb4a-1474f948e1d3 
DEBUG [04:57:13.267] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.317788e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.317788e-05 0.00167313 
  - best initial criterion value(s) :  331.948 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -331.95  |proj g|=       8.1691
At iterate     1  f =      -341.47  |proj g|=        3.2967
At iterate     2  f =      -346.27  |proj g|=        2.6275
At iterate     3  f =      -348.59  |proj g|=        2.4117
At iterate     4  f =      -349.06  |proj g|=        2.6743
At iterate     5  f =      -349.14  |proj g|=        2.9584
At iterate     6  f =      -349.14  |proj g|=        2.9757
At iterate     7  f =      -349.14  |proj g|=        2.9677
At iterate     8  f =      -349.14  |proj g|=         2.968
At iterate     9  f =      -349.14  |proj g|=        2.9681
At iterate    10  f =      -349.14  |proj g|=        2.9684
At iterate    11  f =      -349.14  |proj g|=        2.9689
At iterate    12  f =      -349.15  |proj g|=        2.9697
At iterate    13  f =      -349.15  |proj g|=        2.9717
At iterate    14  f =      -349.15  |proj g|=          2.98
At iterate    15  f =      -349.16  |proj g|=        3.0029
At iterate    16  f =      -349.18  |proj g|=        3.0459
At iterate    17  f =      -349.22  |proj g|=        3.1184
At iterate    18  f =      -349.33  |proj g|=        3.2649
At iterate    19  f =      -349.34  |proj g|=        3.2057
At iterate    20  f =      -349.61  |proj g|=        3.3763
At iterate    21  f =      -354.08  |proj g|=        3.1868
At iterate    22  f =       -362.5  |proj g|=        2.0467
At iterate    23  f =      -367.38  |proj g|=        2.5519
At iterate    24  f =      -368.49  |proj g|=        1.7206
At iterate    25  f =      -368.72  |proj g|=        1.6471
At iterate    26  f =      -368.74  |proj g|=        1.7609
At iterate    27  f =      -368.74  |proj g|=        1.6954
At iterate    28  f =      -368.74  |proj g|=        1.7086
At iterate    29  f =      -368.74  |proj g|=        1.7082
At iterate    30  f =      -368.74  |proj g|=        1.7081

iterations 30
function evaluations 38
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.7081
final function value -368.744

F = -368.744
final  value -368.743856 
converged
 
INFO  [04:57:13.271] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:57:13.375] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:57:13.382] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:57:17.262] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:57:22.010] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:57:25.089] [mlr3]  Finished benchmark 
INFO  [04:57:25.192] [bbotk] Result of batch 60: 
INFO  [04:57:25.194] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:57:25.194] [bbotk]              2.000079                 9.153194                       0.3778514 
INFO  [04:57:25.194] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:57:25.194] [bbotk]                     1614         0.62 -0.9597649         <NA>   0.9552909 
INFO  [04:57:25.194] [bbotk]                                 uhash 
INFO  [04:57:25.194] [bbotk]  8fd354f5-e18d-4548-9fe4-d25ee3345625 
DEBUG [04:57:26.276] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.320286e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.61756 0.9778625 9446 
  - variance bounds :  1.320286e-05 0.00167181 
  - best initial criterion value(s) :  351.159 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -351.16  |proj g|=       2.8504
At iterate     1  f =      -354.65  |proj g|=        2.3249
At iterate     2  f =      -354.76  |proj g|=        2.5481
At iterate     3  f =      -354.78  |proj g|=        2.5751
At iterate     4  f =      -354.78  |proj g|=        2.5568
At iterate     5  f =      -354.78  |proj g|=        2.5817
At iterate     6  f =      -354.78  |proj g|=        2.5839
At iterate     7  f =      -354.78  |proj g|=         2.585
At iterate     8  f =      -354.78  |proj g|=        2.5864
At iterate     9  f =      -354.78  |proj g|=        2.5918
At iterate    10  f =      -354.78  |proj g|=        2.6012
At iterate    11  f =      -354.79  |proj g|=        2.6065
At iterate    12  f =      -354.79  |proj g|=        2.6319
At iterate    13  f =      -354.79  |proj g|=        2.6298
At iterate    14  f =      -354.82  |proj g|=        2.6136
At iterate    15  f =      -354.89  |proj g|=        2.5713
At iterate    16  f =       -355.1  |proj g|=        2.4372
At iterate    17  f =      -355.59  |proj g|=        2.1163
At iterate    18  f =       -355.9  |proj g|=        1.0584
At iterate    19  f =      -356.98  |proj g|=        1.1047
At iterate    20  f =      -358.54  |proj g|=        1.1394
At iterate    21  f =      -361.51  |proj g|=        1.1485
At iterate    22  f =      -362.55  |proj g|=       0.99816
At iterate    23  f =      -362.63  |proj g|=       0.93121
At iterate    24  f =      -362.64  |proj g|=       0.96364
At iterate    25  f =       -362.7  |proj g|=        0.9405
At iterate    26  f =      -362.71  |proj g|=       0.92686
At iterate    27  f =      -362.71  |proj g|=       0.91523
At iterate    28  f =      -362.71  |proj g|=       0.91186
At iterate    29  f =      -362.71  |proj g|=       0.91148
At iterate    30  f =      -362.71  |proj g|=       0.91149

iterations 30
function evaluations 37
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.911486
final function value -362.711

F = -362.711
final  value -362.710701 
converged
 
INFO  [04:57:26.281] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:57:26.392] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:57:26.399] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:57:35.495] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:57:43.752] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:57:53.634] [mlr3]  Finished benchmark 
INFO  [04:57:53.735] [bbotk] Result of batch 61: 
INFO  [04:57:53.737] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:57:53.737] [bbotk]              8.450557                 2.384316                      0.02314944 
INFO  [04:57:53.737] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:57:53.737] [bbotk]                     4159         0.79 -0.9600995         <NA>   0.9626433 
INFO  [04:57:53.737] [bbotk]                                 uhash 
INFO  [04:57:53.737] [bbotk]  52ead2e9-62f0-4c74-b63f-89dd35d131c6 
DEBUG [04:57:54.587] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.308494e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.61756 0.9778625 9446 
  - variance bounds :  1.308494e-05 0.001655212 
  - best initial criterion value(s) :  359.2752 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -359.28  |proj g|=       2.9021
At iterate     1  f =      -369.51  |proj g|=        2.0563
At iterate     2  f =      -371.87  |proj g|=         1.697
At iterate     3  f =      -374.21  |proj g|=        1.4325
At iterate     4  f =      -374.23  |proj g|=        1.3962
At iterate     5  f =      -374.24  |proj g|=        1.4086
At iterate     6  f =      -374.25  |proj g|=        1.4118
At iterate     7  f =      -374.27  |proj g|=        1.4248
At iterate     8  f =      -374.29  |proj g|=        1.4293
At iterate     9  f =       -374.3  |proj g|=        1.4191
At iterate    10  f =       -374.3  |proj g|=        1.4181
At iterate    11  f =       -374.3  |proj g|=        1.4181

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.41806
final function value -374.305

F = -374.305
final  value -374.304876 
converged
 
INFO  [04:57:54.592] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:57:54.681] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:57:54.700] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:57:57.775] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:58:00.508] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:58:04.146] [mlr3]  Finished benchmark 
INFO  [04:58:04.248] [bbotk] Result of batch 62: 
INFO  [04:58:04.250] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:58:04.250] [bbotk]              8.471373                 9.915361                       0.3115008 
INFO  [04:58:04.250] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:58:04.250] [bbotk]                      981        0.621 -0.9594733         <NA>   0.9719326 
INFO  [04:58:04.250] [bbotk]                                 uhash 
INFO  [04:58:04.250] [bbotk]  9c6044ce-5f61-4ef1-88cf-cd2da64cbe2d 
DEBUG [04:58:05.206] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.296301e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.296301e-05 0.001622669 
  - best initial criterion value(s) :  328.7305 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -328.73  |proj g|=       8.6617
At iterate     1  f =      -370.31  |proj g|=        1.6879
At iterate     2  f =      -372.28  |proj g|=        1.6832
At iterate     3  f =      -375.15  |proj g|=        2.1643
At iterate     4  f =      -376.11  |proj g|=        1.6261
At iterate     5  f =      -376.27  |proj g|=        1.6167
At iterate     6  f =       -376.6  |proj g|=        1.6133
At iterate     7  f =      -377.15  |proj g|=        1.6415
At iterate     8  f =      -377.53  |proj g|=        1.7648
At iterate     9  f =      -377.95  |proj g|=        1.7683
At iterate    10  f =      -377.98  |proj g|=         1.774
At iterate    11  f =      -377.98  |proj g|=        1.7795
At iterate    12  f =      -377.98  |proj g|=        1.7835
At iterate    13  f =      -377.98  |proj g|=        1.7857
At iterate    14  f =      -377.98  |proj g|=        1.7865
At iterate    15  f =      -377.98  |proj g|=        1.7892
At iterate    16  f =      -377.99  |proj g|=        1.7928
At iterate    17  f =      -377.99  |proj g|=        1.7991
At iterate    18  f =      -378.01  |proj g|=        1.8083
At iterate    19  f =      -378.02  |proj g|=        1.8068
At iterate    20  f =      -378.03  |proj g|=        1.7895
At iterate    21  f =      -378.03  |proj g|=        1.7913
At iterate    22  f =      -378.03  |proj g|=        1.7897
At iterate    23  f =      -378.03  |proj g|=        1.7911
At iterate    24  f =      -378.03  |proj g|=        1.7902
At iterate    25  f =      -378.13  |proj g|=        1.7735
At iterate    26  f =      -378.67  |proj g|=        1.7117
At iterate    27  f =      -379.49  |proj g|=        1.6502
At iterate    28  f =      -380.25  |proj g|=         1.618
At iterate    29  f =      -380.53  |proj g|=        1.6212
At iterate    30  f =      -380.61  |proj g|=         1.642
At iterate    31  f =      -380.62  |proj g|=        1.6602
At iterate    32  f =      -380.62  |proj g|=        1.6649
At iterate    33  f =      -380.62  |proj g|=         1.665
At iterate    34  f =      -380.62  |proj g|=        1.6651

iterations 34
function evaluations 39
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.66505
final function value -380.621

F = -380.621
final  value -380.621381 
converged
 
INFO  [04:58:05.237] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:58:05.324] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:58:05.331] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:58:11.347] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:58:17.470] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:58:24.476] [mlr3]  Finished benchmark 
INFO  [04:58:24.578] [bbotk] Result of batch 63: 
INFO  [04:58:24.580] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:58:24.580] [bbotk]              6.702378                 4.709435                       0.2795442 
INFO  [04:58:24.580] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:58:24.580] [bbotk]                     2953        0.654 -0.9543806         <NA>   0.9747941 
INFO  [04:58:24.580] [bbotk]                                 uhash 
INFO  [04:58:24.580] [bbotk]  60b6e445-9770-40fc-85c2-375e3868f346 
DEBUG [04:58:25.434] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.287815e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.287815e-05 0.001615814 
  - best initial criterion value(s) :  372.9593 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -372.96  |proj g|=       2.3661
At iterate     1  f =      -387.09  |proj g|=        1.6113
At iterate     2  f =      -387.75  |proj g|=        1.7525
At iterate     3  f =      -388.12  |proj g|=        1.5696
At iterate     4  f =      -388.61  |proj g|=         1.214
At iterate     5  f =      -388.61  |proj g|=        1.2241
At iterate     6  f =      -388.62  |proj g|=        1.2209
At iterate     7  f =      -388.62  |proj g|=         1.221
At iterate     8  f =      -388.62  |proj g|=         1.221

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.221
final function value -388.615

F = -388.615
final  value -388.615050 
converged
 
INFO  [04:58:25.438] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:58:25.545] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:58:25.557] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:58:34.328] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:58:41.278] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:58:48.207] [mlr3]  Finished benchmark 
INFO  [04:58:48.310] [bbotk] Result of batch 64: 
INFO  [04:58:48.312] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:58:48.312] [bbotk]              9.723509                 8.891292                       0.1623257 
INFO  [04:58:48.312] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:58:48.312] [bbotk]                     3097        0.646 -0.9581978         <NA>    0.974226 
INFO  [04:58:48.312] [bbotk]                                 uhash 
INFO  [04:58:48.312] [bbotk]  4df59bcb-94aa-490b-934a-6290e7397a22 
DEBUG [04:58:49.274] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.278582e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.278582e-05 0.001607535 
  - best initial criterion value(s) :  354.6935 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -354.69  |proj g|=       7.2549
At iterate     1  f =      -356.91  |proj g|=        6.5792
At iterate     2  f =      -365.12  |proj g|=        6.3148
At iterate     3  f =      -372.74  |proj g|=        3.8536
At iterate     4  f =      -375.23  |proj g|=        2.0439
At iterate     5  f =      -376.32  |proj g|=       0.93406
At iterate     6  f =      -376.33  |proj g|=        1.0398
At iterate     7  f =      -376.33  |proj g|=        1.0041
At iterate     8  f =      -376.33  |proj g|=        1.0027
At iterate     9  f =      -376.33  |proj g|=        1.0026
At iterate    10  f =      -376.33  |proj g|=        1.0025
At iterate    11  f =      -376.33  |proj g|=        1.0037
At iterate    12  f =      -376.33  |proj g|=        1.0059
At iterate    13  f =      -376.33  |proj g|=       0.99999
At iterate    14  f =      -376.33  |proj g|=        1.0103
At iterate    15  f =      -376.34  |proj g|=        1.0465
At iterate    16  f =      -376.37  |proj g|=        1.1266
At iterate    17  f =      -376.46  |proj g|=         1.227
At iterate    18  f =      -376.68  |proj g|=        1.2918
At iterate    19  f =      -376.69  |proj g|=        1.3662
At iterate    20  f =      -377.07  |proj g|=        1.2147
At iterate    21  f =       -377.5  |proj g|=       0.93403
At iterate    22  f =      -377.81  |proj g|=       0.92231
At iterate    23  f =      -378.06  |proj g|=       0.92728
At iterate    24  f =      -378.09  |proj g|=       0.92912
At iterate    25  f =      -378.09  |proj g|=       0.92541
At iterate    26  f =       -378.1  |proj g|=       0.92406
At iterate    27  f =       -378.1  |proj g|=       0.92299
At iterate    28  f =       -378.1  |proj g|=         0.923

iterations 28
function evaluations 41
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.922998
final function value -378.097

F = -378.097
final  value -378.096542 
converged
 
INFO  [04:58:49.278] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:58:49.397] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:58:49.406] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:58:56.267] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:59:04.669] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:59:12.061] [mlr3]  Finished benchmark 
INFO  [04:59:12.165] [bbotk] Result of batch 65: 
INFO  [04:59:12.167] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:59:12.167] [bbotk]              4.507128                  4.15478                       0.2273431 
INFO  [04:59:12.167] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:59:12.167] [bbotk]                     3163         0.65 -0.9627422         <NA>   0.9735484 
INFO  [04:59:12.167] [bbotk]                                 uhash 
INFO  [04:59:12.167] [bbotk]  cc71aad4-582b-44d1-9f54-cb1d4fc7dcb8 
DEBUG [04:59:13.035] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.26859e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.26859e-05 0.001605065 
  - best initial criterion value(s) :  386.2087 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -386.21  |proj g|=       1.4114
At iterate     1  f =      -386.95  |proj g|=        1.5683
At iterate     2  f =      -387.58  |proj g|=        1.5041
At iterate     3  f =      -387.94  |proj g|=        1.3866
At iterate     4  f =      -387.97  |proj g|=        1.3973
At iterate     5  f =      -387.98  |proj g|=        1.3964
At iterate     6  f =      -387.98  |proj g|=        1.3963
At iterate     7  f =      -387.98  |proj g|=        1.3963

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.3963
final function value -387.977

F = -387.977
final  value -387.977022 
converged
 
INFO  [04:59:13.039] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:59:13.141] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:59:13.148] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [04:59:22.015] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:59:29.260] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:59:37.390] [mlr3]  Finished benchmark 
INFO  [04:59:37.490] [bbotk] Result of batch 66: 
INFO  [04:59:37.492] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [04:59:37.492] [bbotk]              7.559236                 4.054129                       0.1111206 
INFO  [04:59:37.492] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:59:37.492] [bbotk]                     3591        0.634 -0.9613698         <NA>   0.9728991 
INFO  [04:59:37.492] [bbotk]                                 uhash 
INFO  [04:59:37.492] [bbotk]  8ee78ee0-af45-417c-bd50-49b7153efef3 
DEBUG [04:59:38.527] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.258014e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.258014e-05 0.001598587 
  - best initial criterion value(s) :  375.1339 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -375.13  |proj g|=       2.2843
At iterate     1  f =      -381.41  |proj g|=        1.5858
At iterate     2  f =      -384.32  |proj g|=        1.3652
At iterate     3  f =      -385.65  |proj g|=        1.0932
At iterate     4  f =      -385.91  |proj g|=        1.0036
At iterate     5  f =      -386.19  |proj g|=         1.034
At iterate     6  f =       -386.2  |proj g|=        1.0795
At iterate     7  f =      -386.21  |proj g|=        1.0693
At iterate     8  f =      -386.21  |proj g|=        1.0692

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.06924
final function value -386.206

F = -386.206
final  value -386.205644 
converged
 
INFO  [04:59:38.531] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:59:38.632] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:59:38.638] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [04:59:47.900] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [04:59:57.651] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:00:08.695] [mlr3]  Finished benchmark 
INFO  [05:00:08.807] [bbotk] Result of batch 67: 
INFO  [05:00:08.809] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:00:08.809] [bbotk]              9.710642                 7.395955                       0.2596031 
INFO  [05:00:08.809] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:00:08.809] [bbotk]                     4316        0.808  -0.96109         <NA>   0.9761038 
INFO  [05:00:08.809] [bbotk]                                 uhash 
INFO  [05:00:08.809] [bbotk]  d7e7cc17-9e98-4560-833d-becc73debd3d 
DEBUG [05:00:09.753] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.251926e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.251926e-05 0.00160036 
  - best initial criterion value(s) :  372.7303 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -372.73  |proj g|=       6.2128
At iterate     1  f =      -379.55  |proj g|=        4.1131
At iterate     2  f =      -379.63  |proj g|=        4.0569
At iterate     3  f =      -379.71  |proj g|=        3.8285
At iterate     4  f =      -379.71  |proj g|=        3.8487
At iterate     5  f =      -379.71  |proj g|=        3.8096
At iterate     6  f =      -379.72  |proj g|=        3.8049
At iterate     7  f =      -379.72  |proj g|=        3.7908
At iterate     8  f =      -379.72  |proj g|=        3.7734
At iterate     9  f =      -379.72  |proj g|=        3.7408
At iterate    10  f =      -379.72  |proj g|=        3.7169
At iterate    11  f =      -379.73  |proj g|=        3.6716
At iterate    12  f =      -379.76  |proj g|=          3.59
At iterate    13  f =      -379.83  |proj g|=        3.4516
At iterate    14  f =         -380  |proj g|=        3.2227
At iterate    15  f =      -380.39  |proj g|=        2.8587
At iterate    16  f =      -381.03  |proj g|=        2.0088
At iterate    17  f =      -382.22  |proj g|=        1.4956
At iterate    18  f =       -383.1  |proj g|=        1.2133
At iterate    19  f =      -386.74  |proj g|=        1.0204
At iterate    20  f =      -387.68  |proj g|=       0.96261
At iterate    21  f =      -387.81  |proj g|=        1.0227
At iterate    22  f =      -387.81  |proj g|=        1.0176
At iterate    23  f =      -387.81  |proj g|=        1.0192
At iterate    24  f =      -387.81  |proj g|=          1.02
At iterate    25  f =      -387.81  |proj g|=        1.0217
At iterate    26  f =      -387.81  |proj g|=        1.0219
At iterate    27  f =      -387.81  |proj g|=        1.0219

iterations 27
function evaluations 36
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.02186
final function value -387.81

F = -387.81
final  value -387.809854 
converged
 
INFO  [05:00:09.757] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:00:09.845] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:00:09.853] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:00:12.712] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:00:16.945] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:00:19.896] [mlr3]  Finished benchmark 
INFO  [05:00:19.997] [bbotk] Result of batch 68: 
INFO  [05:00:19.999] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:00:19.999] [bbotk]              7.635892                 9.160866                       0.4120057 
INFO  [05:00:19.999] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:00:19.999] [bbotk]                     1121        0.645 -0.9635539         <NA>   0.9734533 
INFO  [05:00:19.999] [bbotk]                                 uhash 
INFO  [05:00:19.999] [bbotk]  24d19fb8-bcd9-4ad5-83de-dba54ef382da 
DEBUG [05:00:20.953] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.242182e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.242182e-05 0.001571319 
  - best initial criterion value(s) :  377.617 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -377.62  |proj g|=       7.1093
At iterate     1  f =      -380.48  |proj g|=        6.6995
At iterate     2  f =      -382.32  |proj g|=        6.3764
At iterate     3  f =      -386.32  |proj g|=        5.0513
At iterate     4  f =      -388.69  |proj g|=        4.0838
At iterate     5  f =      -389.72  |proj g|=        3.3227
At iterate     6  f =      -390.52  |proj g|=        3.5547
At iterate     7  f =      -390.55  |proj g|=        3.4672
At iterate     8  f =      -390.55  |proj g|=        3.4551
At iterate     9  f =      -390.55  |proj g|=        3.4549
At iterate    10  f =      -390.55  |proj g|=         3.455
At iterate    11  f =      -390.55  |proj g|=         3.455
At iterate    12  f =      -390.55  |proj g|=         3.455
At iterate    13  f =      -390.56  |proj g|=        3.4548
At iterate    14  f =      -390.56  |proj g|=        3.4552
At iterate    15  f =      -390.56  |proj g|=        3.4588
At iterate    16  f =      -390.58  |proj g|=        3.4728
At iterate    17  f =      -390.61  |proj g|=        3.5092
At iterate    18  f =      -390.64  |proj g|=        3.5363
At iterate    19  f =      -390.74  |proj g|=        3.6313
At iterate    20  f =      -390.85  |proj g|=        3.6676
At iterate    21  f =      -390.87  |proj g|=        3.7369
At iterate    22  f =       -391.4  |proj g|=        3.7503
At iterate    23  f =      -392.45  |proj g|=        3.6105
At iterate    24  f =      -394.78  |proj g|=        3.0741
At iterate    25  f =      -397.87  |proj g|=        2.2713
At iterate    26  f =      -401.38  |proj g|=        1.5983
At iterate    27  f =      -401.71  |proj g|=        1.3888
At iterate    28  f =      -406.59  |proj g|=        1.2252
At iterate    29  f =      -408.09  |proj g|=        1.5761
At iterate    30  f =      -408.88  |proj g|=        1.3909
At iterate    31  f =      -409.04  |proj g|=       0.97873
At iterate    32  f =      -409.06  |proj g|=        1.0384
At iterate    33  f =      -409.06  |proj g|=        1.0248
At iterate    34  f =      -409.06  |proj g|=        1.0266
At iterate    35  f =      -409.06  |proj g|=         1.026

iterations 35
function evaluations 41
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.02604
final function value -409.06

F = -409.06
final  value -409.060313 
converged
 
INFO  [05:00:20.958] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:00:21.047] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:00:21.054] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:00:32.213] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:00:41.957] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:00:52.831] [mlr3]  Finished benchmark 
INFO  [05:00:52.950] [bbotk] Result of batch 69: 
INFO  [05:00:52.953] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:00:52.953] [bbotk]              3.110574                  5.65238                       0.2647504 
INFO  [05:00:52.953] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:00:52.953] [bbotk]                     4956        0.637 -0.9603152         <NA>   0.9718912 
INFO  [05:00:52.953] [bbotk]                                 uhash 
INFO  [05:00:52.953] [bbotk]  5756e29a-edf3-4b1f-9508-110d762cd027 
DEBUG [05:00:53.903] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.231125e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.231125e-05 0.0015576 
  - best initial criterion value(s) :  392.5999 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -392.6  |proj g|=       5.1637
At iterate     1  f =      -404.56  |proj g|=          1.98
At iterate     2  f =      -407.66  |proj g|=        1.9264
At iterate     3  f =      -411.16  |proj g|=        1.7105
At iterate     4  f =      -411.24  |proj g|=         1.637
At iterate     5  f =      -411.29  |proj g|=        1.6614
At iterate     6  f =      -411.37  |proj g|=        1.6846
At iterate     7  f =      -411.58  |proj g|=        1.7239
At iterate     8  f =      -411.79  |proj g|=        1.7447
At iterate     9  f =      -411.85  |proj g|=        1.6996
At iterate    10  f =      -411.88  |proj g|=        1.7137
At iterate    11  f =      -411.88  |proj g|=         1.715
At iterate    12  f =      -411.88  |proj g|=        1.7167
At iterate    13  f =      -411.88  |proj g|=        1.7193
At iterate    14  f =      -411.89  |proj g|=         1.725
At iterate    15  f =      -411.91  |proj g|=        1.7254
At iterate    16  f =      -411.92  |proj g|=         1.742
At iterate    17  f =      -411.96  |proj g|=        1.7401
At iterate    18  f =      -412.55  |proj g|=         1.697
At iterate    19  f =      -413.31  |proj g|=        1.5568
At iterate    20  f =      -413.32  |proj g|=        1.5604
At iterate    21  f =      -413.33  |proj g|=        1.5549
At iterate    22  f =      -413.33  |proj g|=        1.5562
At iterate    23  f =      -413.33  |proj g|=        1.5555
At iterate    24  f =      -413.33  |proj g|=        1.5556

iterations 24
function evaluations 32
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.5556
final function value -413.328

F = -413.328
final  value -413.327672 
converged
 
INFO  [05:00:53.908] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:00:53.996] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:00:54.003] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:00:55.737] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:00:57.748] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:01:00.797] [mlr3]  Finished benchmark 
INFO  [05:01:00.900] [bbotk] Result of batch 70: 
INFO  [05:01:00.902] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:01:00.902] [bbotk]              8.256745                  6.83636                       0.3948994 
INFO  [05:01:00.902] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:01:00.902] [bbotk]                      912        0.656 -0.9586858         <NA>   0.9726412 
INFO  [05:01:00.902] [bbotk]                                 uhash 
INFO  [05:01:00.902] [bbotk]  86e9524e-785a-471f-9bd1-609079b760a9 
DEBUG [05:01:01.892] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.220883e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.220883e-05 0.001530253 
  - best initial criterion value(s) :  395.3947 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -395.39  |proj g|=       5.0332
At iterate     1  f =      -398.17  |proj g|=        5.8288
At iterate     2  f =      -399.65  |proj g|=        5.4761
At iterate     3  f =      -403.29  |proj g|=         3.819
At iterate     4  f =      -405.58  |proj g|=        2.7168
At iterate     5  f =      -406.96  |proj g|=        3.0201
At iterate     6  f =      -407.21  |proj g|=        2.9827
At iterate     7  f =      -407.21  |proj g|=        2.9765
At iterate     8  f =      -407.21  |proj g|=         2.976
At iterate     9  f =      -407.21  |proj g|=         2.976
At iterate    10  f =      -407.22  |proj g|=        2.9742
At iterate    11  f =      -407.22  |proj g|=        2.9744
At iterate    12  f =      -407.22  |proj g|=        2.9745
At iterate    13  f =      -407.28  |proj g|=        2.9725
At iterate    14  f =      -407.49  |proj g|=        2.9622
At iterate    15  f =       -408.9  |proj g|=        2.8552
At iterate    16  f =       -408.9  |proj g|=        2.8589
At iterate    17  f =      -411.01  |proj g|=          2.66
At iterate    18  f =      -413.98  |proj g|=        2.3044
At iterate    19  f =      -415.59  |proj g|=        2.0105
At iterate    20  f =       -416.3  |proj g|=        1.8597
At iterate    21  f =      -416.88  |proj g|=        1.8042
At iterate    22  f =      -417.07  |proj g|=        1.9222
At iterate    23  f =      -417.35  |proj g|=        1.8458
At iterate    24  f =      -417.41  |proj g|=        1.8382
At iterate    25  f =      -417.42  |proj g|=        1.8488
At iterate    26  f =      -417.42  |proj g|=         1.854
At iterate    27  f =      -417.42  |proj g|=         1.857
At iterate    28  f =      -417.42  |proj g|=          1.86
At iterate    29  f =      -417.42  |proj g|=        1.8654
At iterate    30  f =      -417.42  |proj g|=        1.8643
At iterate    31  f =      -417.42  |proj g|=        1.8635
At iterate    32  f =      -417.42  |proj g|=        1.8635

iterations 32
function evaluations 43
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.86348
final function value -417.418

F = -417.418
final  value -417.418001 
converged
 
INFO  [05:01:01.896] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:01:01.988] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:01:01.996] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:01:06.987] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:01:11.981] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:01:17.951] [mlr3]  Finished benchmark 
INFO  [05:01:18.052] [bbotk] Result of batch 71: 
INFO  [05:01:18.054] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:01:18.054] [bbotk]              6.195335                 9.567694                       0.4245838 
INFO  [05:01:18.054] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:01:18.054] [bbotk]                     2196        0.657 -0.9554071         <NA>   0.9749369 
INFO  [05:01:18.054] [bbotk]                                 uhash 
INFO  [05:01:18.054] [bbotk]  96e03a6c-7073-4969-86bd-db34f744e3e8 
DEBUG [05:01:19.180] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.213357e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.213357e-05 0.001517645 
  - best initial criterion value(s) :  395.4751 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -395.48  |proj g|=       2.3584
At iterate     1  f =      -397.05  |proj g|=         2.063
At iterate     2  f =      -397.15  |proj g|=        2.1035
At iterate     3  f =      -397.17  |proj g|=        2.1012
At iterate     4  f =      -397.17  |proj g|=        2.0994
At iterate     5  f =      -397.17  |proj g|=        2.0993
At iterate     6  f =      -397.17  |proj g|=        2.0992
At iterate     7  f =      -397.17  |proj g|=        2.0984
At iterate     8  f =      -397.17  |proj g|=        2.0984
At iterate     9  f =      -397.17  |proj g|=        2.0983
At iterate    10  f =      -397.17  |proj g|=        2.0983
At iterate    11  f =      -397.17  |proj g|=         2.098
At iterate    12  f =      -397.17  |proj g|=        2.0975
At iterate    13  f =      -397.18  |proj g|=        2.0953
At iterate    14  f =      -397.18  |proj g|=         2.124
At iterate    15  f =      -397.19  |proj g|=        2.0998
At iterate    16  f =      -397.23  |proj g|=        2.0693
At iterate    17  f =      -397.32  |proj g|=        2.0076
At iterate    18  f =      -397.54  |proj g|=        1.8963
At iterate    19  f =      -398.05  |proj g|=        1.6985
At iterate    20  f =      -399.06  |proj g|=         1.398
At iterate    21  f =      -400.93  |proj g|=        1.0202
At iterate    22  f =      -401.11  |proj g|=       0.90925
At iterate    23  f =      -403.77  |proj g|=       0.66272
At iterate    24  f =      -406.55  |proj g|=       0.98969
At iterate    25  f =      -406.93  |proj g|=        0.9099
At iterate    26  f =      -407.09  |proj g|=       0.79825
At iterate    27  f =       -407.1  |proj g|=       0.74888
At iterate    28  f =       -407.1  |proj g|=       0.72792
At iterate    29  f =       -407.1  |proj g|=       0.72667
At iterate    30  f =       -407.1  |proj g|=       0.72665

iterations 30
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.726648
final function value -407.098

F = -407.098
final  value -407.098339 
converged
 
INFO  [05:01:19.184] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:01:19.289] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:01:19.300] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:01:27.485] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:01:37.992] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:01:46.532] [mlr3]  Finished benchmark 
INFO  [05:01:46.661] [bbotk] Result of batch 72: 
INFO  [05:01:46.663] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:01:46.663] [bbotk]              6.624457                 8.731073                       0.1146085 
INFO  [05:01:46.663] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:01:46.663] [bbotk]                     3765        0.809 -0.9632193         <NA>   0.9730432 
INFO  [05:01:46.663] [bbotk]                                 uhash 
INFO  [05:01:46.663] [bbotk]  87531949-00b0-48eb-919f-7af5a6cea4a6 
DEBUG [05:01:47.609] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.203756e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.203756e-05 0.001511776 
  - best initial criterion value(s) :  400.1993 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -400.2  |proj g|=       5.4556
At iterate     1  f =      -400.44  |proj g|=        5.7534
At iterate     2  f =      -402.22  |proj g|=        5.5957
At iterate     3  f =      -404.38  |proj g|=        5.1059
At iterate     4  f =       -406.3  |proj g|=        4.7676
At iterate     5  f =      -408.84  |proj g|=        3.6695
At iterate     6  f =      -409.76  |proj g|=         4.163
At iterate     7  f =      -409.83  |proj g|=        4.0594
At iterate     8  f =      -409.84  |proj g|=        4.0391
At iterate     9  f =      -409.84  |proj g|=        4.0397
At iterate    10  f =      -409.84  |proj g|=        4.0216
At iterate    11  f =      -409.86  |proj g|=        3.9977
At iterate    12  f =      -409.89  |proj g|=        3.9509
At iterate    13  f =      -409.97  |proj g|=        3.8728
At iterate    14  f =      -410.17  |proj g|=        3.7369
At iterate    15  f =      -410.69  |proj g|=        3.4933
At iterate    16  f =      -410.72  |proj g|=        3.4766
At iterate    17  f =      -412.08  |proj g|=        3.0479
At iterate    18  f =      -423.17  |proj g|=        2.0665
At iterate    19  f =       -433.8  |proj g|=        1.5895
At iterate    20  f =      -435.31  |proj g|=        1.4418
At iterate    21  f =      -436.72  |proj g|=       0.93028
At iterate    22  f =      -437.79  |proj g|=        0.6534
At iterate    23  f =      -438.07  |proj g|=       0.62748
At iterate    24  f =      -438.11  |proj g|=       0.36265
At iterate    25  f =      -438.12  |proj g|=       0.36554
At iterate    26  f =      -438.12  |proj g|=       0.32186
At iterate    27  f =      -438.12  |proj g|=      0.065436
At iterate    28  f =      -438.12  |proj g|=      0.065438

iterations 28
function evaluations 34
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0654385
final function value -438.117

F = -438.117
final  value -438.117360 
converged
 
INFO  [05:01:47.613] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:01:47.705] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:01:47.712] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:01:53.189] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:01:59.878] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:02:06.626] [mlr3]  Finished benchmark 
INFO  [05:02:06.731] [bbotk] Result of batch 73: 
INFO  [05:02:06.733] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:02:06.733] [bbotk]              8.252142                 3.924746                       0.3793343 
INFO  [05:02:06.733] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:02:06.733] [bbotk]                     2538        0.644 -0.9554443         <NA>   0.9755696 
INFO  [05:02:06.733] [bbotk]                                 uhash 
INFO  [05:02:06.733] [bbotk]  eee06e9b-906b-4631-b468-7ad855f0f8d4 
DEBUG [05:02:07.608] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.19725e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.19725e-05 0.001502771 
  - best initial criterion value(s) :  409.8947 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -409.89  |proj g|=       1.7195
At iterate     1  f =       -411.5  |proj g|=        2.2737
At iterate     2  f =      -412.02  |proj g|=        2.1661
At iterate     3  f =      -413.89  |proj g|=        1.9555
At iterate     4  f =      -415.06  |proj g|=        1.7258
At iterate     5  f =      -415.96  |proj g|=        2.0072
At iterate     6  f =      -415.98  |proj g|=        1.9915
At iterate     7  f =      -415.99  |proj g|=        1.9694
At iterate     8  f =      -415.99  |proj g|=        1.9774
At iterate     9  f =      -415.99  |proj g|=        1.9772

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.97721
final function value -415.987

F = -415.987
final  value -415.986535 
converged
 
INFO  [05:02:07.612] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:02:07.731] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:02:07.739] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:02:17.893] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:02:27.903] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:02:38.605] [mlr3]  Finished benchmark 
INFO  [05:02:38.706] [bbotk] Result of batch 74: 
INFO  [05:02:38.708] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:02:38.708] [bbotk]               7.69269                 7.093738                       0.2105928 
INFO  [05:02:38.708] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:02:38.708] [bbotk]                     4401        0.638 -0.9640005         <NA>   0.9753321 
INFO  [05:02:38.708] [bbotk]                                 uhash 
INFO  [05:02:38.708] [bbotk]  f260594d-62e6-46a1-9732-4d9683384c3f 
DEBUG [05:02:39.722] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.190448e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.190448e-05 0.001502356 
  - best initial criterion value(s) :  397.2955 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -397.3  |proj g|=       5.7015
At iterate     1  f =      -402.53  |proj g|=       0.93324
At iterate     2  f =      -409.73  |proj g|=        3.5884
At iterate     3  f =      -409.85  |proj g|=        3.4327
At iterate     4  f =      -409.96  |proj g|=        3.3325
At iterate     5  f =      -410.01  |proj g|=        3.3685
At iterate     6  f =      -410.05  |proj g|=        3.5116
At iterate     7  f =      -410.05  |proj g|=        3.5392
At iterate     8  f =      -410.05  |proj g|=        3.5365
At iterate     9  f =      -410.05  |proj g|=        3.5361
At iterate    10  f =      -410.05  |proj g|=        3.5352
At iterate    11  f =      -410.05  |proj g|=        3.5333
At iterate    12  f =      -410.05  |proj g|=        3.5303
At iterate    13  f =      -410.05  |proj g|=        3.5251
At iterate    14  f =      -410.05  |proj g|=        3.5167
At iterate    15  f =      -410.05  |proj g|=        3.5051
At iterate    16  f =      -410.05  |proj g|=        3.5003
At iterate    17  f =      -410.05  |proj g|=        3.5015
At iterate    18  f =      -410.05  |proj g|=        3.5076
At iterate    19  f =      -410.05  |proj g|=        3.5133
At iterate    20  f =      -410.05  |proj g|=        3.5233
At iterate    21  f =      -410.06  |proj g|=        3.5392
At iterate    22  f =      -410.07  |proj g|=        3.5614
At iterate    23  f =      -410.11  |proj g|=        3.5872
At iterate    24  f =      -410.22  |proj g|=        3.5989
At iterate    25  f =      -410.49  |proj g|=        3.5314
At iterate    26  f =      -411.17  |proj g|=        3.2258
At iterate    27  f =      -412.76  |proj g|=        2.4282
At iterate    28  f =      -414.91  |proj g|=        1.5607
At iterate    29  f =      -416.32  |proj g|=        1.4347
At iterate    30  f =      -417.23  |proj g|=        1.1791
At iterate    31  f =       -418.3  |proj g|=        1.1578
At iterate    32  f =       -418.8  |proj g|=        1.1668
At iterate    33  f =      -418.85  |proj g|=        1.2196
At iterate    34  f =      -418.86  |proj g|=        1.2416
At iterate    35  f =      -418.86  |proj g|=        1.2452
At iterate    36  f =      -418.86  |proj g|=        1.2435
At iterate    37  f =      -418.86  |proj g|=        1.2436
At iterate    38  f =      -418.86  |proj g|=        1.2436

iterations 38
function evaluations 43
segments explored during Cauchy searches 41
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.24365
final function value -418.859

F = -418.859
final  value -418.859377 
converged
 
INFO  [05:02:39.726] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:02:39.827] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:02:39.833] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:02:50.170] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:03:03.322] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:03:12.810] [mlr3]  Finished benchmark 
INFO  [05:03:12.911] [bbotk] Result of batch 75: 
INFO  [05:03:12.913] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:03:12.913] [bbotk]              4.117816                 7.940697                       0.3110782 
INFO  [05:03:12.913] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:03:12.913] [bbotk]                     4518        0.675 -0.9638726         <NA>   0.9751474 
INFO  [05:03:12.913] [bbotk]                                 uhash 
INFO  [05:03:12.913] [bbotk]  397137c8-8d6e-4eea-8806-114cf68e07e2 
DEBUG [05:03:13.912] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.183449e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.183449e-05 0.00150229 
  - best initial criterion value(s) :  426.2935 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -426.29  |proj g|=       4.8647
At iterate     1  f =      -433.78  |proj g|=        6.7272
At iterate     2  f =      -435.97  |proj g|=        6.7131
At iterate     3  f =      -442.11  |proj g|=        5.0595
At iterate     4  f =      -443.51  |proj g|=        3.6266
At iterate     5  f =      -444.21  |proj g|=        2.5405
At iterate     6  f =      -444.23  |proj g|=        2.7059
At iterate     7  f =      -444.23  |proj g|=        2.6842
At iterate     8  f =      -444.23  |proj g|=        2.6846
At iterate     9  f =      -444.23  |proj g|=        2.6847
At iterate    10  f =      -444.23  |proj g|=        2.6852
At iterate    11  f =      -444.23  |proj g|=        2.6857
At iterate    12  f =      -444.23  |proj g|=        2.6865
At iterate    13  f =      -444.23  |proj g|=        2.6859
At iterate    14  f =      -444.24  |proj g|=        2.6748
At iterate    15  f =      -444.25  |proj g|=         2.634
At iterate    16  f =      -444.28  |proj g|=        2.5387
At iterate    17  f =      -444.33  |proj g|=        2.4311
At iterate    18  f =      -444.48  |proj g|=        2.0647
At iterate    19  f =      -444.56  |proj g|=        2.1162
At iterate    20  f =       -444.9  |proj g|=        1.7604
At iterate    21  f =       -446.6  |proj g|=        1.4362
At iterate    22  f =      -448.59  |proj g|=        1.4588
At iterate    23  f =      -450.43  |proj g|=        1.4713
At iterate    24  f =      -451.31  |proj g|=        1.4719
At iterate    25  f =      -451.32  |proj g|=        1.5074
At iterate    26  f =      -451.78  |proj g|=        1.4919
At iterate    27  f =      -451.95  |proj g|=        1.5109
At iterate    28  f =       -452.1  |proj g|=        1.5094
At iterate    29  f =      -452.12  |proj g|=        1.5146
At iterate    30  f =      -452.12  |proj g|=         1.519
At iterate    31  f =      -452.12  |proj g|=         1.522
At iterate    32  f =      -452.12  |proj g|=        1.5214
At iterate    33  f =      -452.12  |proj g|=        1.5214

iterations 33
function evaluations 42
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.52135
final function value -452.117

F = -452.117
final  value -452.117297 
converged
 
INFO  [05:03:13.916] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:03:14.016] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:03:14.023] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:03:24.584] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:03:35.446] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:03:45.999] [mlr3]  Finished benchmark 
INFO  [05:03:46.100] [bbotk] Result of batch 76: 
INFO  [05:03:46.101] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:03:46.101] [bbotk]              6.549645                 6.660308                       0.3075287 
INFO  [05:03:46.101] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:03:46.101] [bbotk]                     4951        0.663 -0.9558292         <NA>   0.9760206 
INFO  [05:03:46.101] [bbotk]                                 uhash 
INFO  [05:03:46.101] [bbotk]  ab6c3168-760a-4e44-a9ff-df0dd3e820a6 
DEBUG [05:03:47.010] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.177668e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.177668e-05 0.001501223 
  - best initial criterion value(s) :  425.5101 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -425.51  |proj g|=       2.8147
At iterate     1  f =         -439  |proj g|=        2.2248
At iterate     2  f =      -439.63  |proj g|=        2.3919
At iterate     3  f =      -439.82  |proj g|=         2.302
At iterate     4  f =      -439.88  |proj g|=        2.2212
At iterate     5  f =      -439.88  |proj g|=        2.2201
At iterate     6  f =      -439.88  |proj g|=          2.22
At iterate     7  f =      -439.88  |proj g|=          2.22

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.21999
final function value -439.881

F = -439.881
final  value -439.881100 
converged
 
INFO  [05:03:47.014] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:03:47.102] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:03:47.109] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:03:52.149] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:03:58.280] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:04:02.773] [mlr3]  Finished benchmark 
INFO  [05:04:02.894] [bbotk] Result of batch 77: 
INFO  [05:04:02.896] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:04:02.896] [bbotk]              7.584189                 9.951049                       0.2656233 
INFO  [05:04:02.896] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:04:02.896] [bbotk]                     2140         0.67 -0.9609501         <NA>    0.974192 
INFO  [05:04:02.896] [bbotk]                                 uhash 
INFO  [05:04:02.896] [bbotk]  3b1f7d12-816a-428a-b0b6-ea5c636380b0 
DEBUG [05:04:03.836] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.16966e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.16966e-05 0.001485673 
  - best initial criterion value(s) :  431.9435 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -431.94  |proj g|=      0.81797
At iterate     1  f =       -434.6  |proj g|=        1.2734
At iterate     2  f =      -435.31  |proj g|=       0.76564
At iterate     3  f =       -435.4  |proj g|=       0.68142
At iterate     4  f =      -435.41  |proj g|=       0.68325
At iterate     5  f =      -435.41  |proj g|=       0.68371
At iterate     6  f =      -435.41  |proj g|=       0.68378

iterations 6
function evaluations 9
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.683778
final function value -435.41

F = -435.41
final  value -435.409960 
converged
 
INFO  [05:04:03.840] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:04:03.928] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:04:03.935] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:04:07.753] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:04:10.798] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:04:13.940] [mlr3]  Finished benchmark 
INFO  [05:04:14.044] [bbotk] Result of batch 78: 
INFO  [05:04:14.046] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:04:14.046] [bbotk]              8.217674                 3.612304                     0.008937733 
INFO  [05:04:14.046] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:04:14.046] [bbotk]                     1335        0.707 -0.9634674         <NA>   0.9297988 
INFO  [05:04:14.046] [bbotk]                                 uhash 
INFO  [05:04:14.046] [bbotk]  e944b0c9-642b-4564-8864-bc25cbd8a986 
DEBUG [05:04:14.997] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.296626e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.296626e-05 0.00163882 
  - best initial criterion value(s) :  451.4868 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -451.49  |proj g|=      0.73856
At iterate     1  f =      -453.11  |proj g|=        2.5162
At iterate     2  f =       -455.6  |proj g|=        2.0099
At iterate     3  f =      -456.78  |proj g|=        1.2757
At iterate     4  f =      -456.82  |proj g|=        1.1739
At iterate     5  f =      -456.92  |proj g|=        1.0329
At iterate     6  f =      -457.17  |proj g|=       0.67954
At iterate     7  f =      -457.35  |proj g|=       0.61712
At iterate     8  f =      -457.39  |proj g|=       0.73855
At iterate     9  f =      -457.39  |proj g|=       0.73822
At iterate    10  f =      -457.39  |proj g|=       0.73729
At iterate    11  f =      -457.39  |proj g|=       0.73733

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.73733
final function value -457.39

F = -457.39
final  value -457.389914 
converged
 
INFO  [05:04:15.001] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:04:15.094] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:04:15.102] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:04:22.418] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:04:33.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:04:41.836] [mlr3]  Finished benchmark 
INFO  [05:04:41.938] [bbotk] Result of batch 79: 
INFO  [05:04:41.940] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:04:41.940] [bbotk]              9.797504                 6.617684                       0.0863161 
INFO  [05:04:41.940] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:04:41.940] [bbotk]                     3487        0.701 -0.960735         <NA>   0.9722474 
INFO  [05:04:41.940] [bbotk]                                 uhash 
INFO  [05:04:41.940] [bbotk]  59fbc9f7-e023-451e-a67b-8209d621987c 
DEBUG [05:04:43.047] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.286221e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.286221e-05 0.001631674 
  - best initial criterion value(s) :  410.8012 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -410.8  |proj g|=      0.44046
At iterate     1  f =       -439.9  |proj g|=        7.7385
At iterate     2  f =      -441.98  |proj g|=        7.5948
At iterate     3  f =      -447.18  |proj g|=         6.457
At iterate     4  f =      -447.45  |proj g|=        6.0728
At iterate     5  f =      -447.51  |proj g|=        5.9911
At iterate     6  f =      -447.77  |proj g|=        5.5085
At iterate     7  f =      -447.79  |proj g|=        5.6461
At iterate     8  f =      -447.79  |proj g|=        5.6314
At iterate     9  f =      -447.79  |proj g|=         5.631
At iterate    10  f =      -447.79  |proj g|=         5.631

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 5.63101
final function value -447.792

F = -447.792
final  value -447.791593 
converged
 
INFO  [05:04:43.051] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:04:43.163] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:04:43.170] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:04:47.080] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:04:51.811] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:04:56.670] [mlr3]  Finished benchmark 
INFO  [05:04:56.773] [bbotk] Result of batch 80: 
INFO  [05:04:56.775] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:04:56.775] [bbotk]              4.417012                 9.058009                       0.1284078 
INFO  [05:04:56.775] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:04:56.775] [bbotk]                     2180        0.825 -0.9622781         <NA>   0.9686914 
INFO  [05:04:56.775] [bbotk]                                 uhash 
INFO  [05:04:56.775] [bbotk]  8d1299c0-021b-4a17-aa70-143110917db1 
DEBUG [05:04:58.009] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.274547e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.274547e-05 0.001613288 
  - best initial criterion value(s) :  447.4699 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -447.47  |proj g|=       4.6958
At iterate     1  f =      -451.13  |proj g|=        3.4233
At iterate     2  f =      -456.08  |proj g|=        3.3331
At iterate     3  f =      -462.32  |proj g|=        2.8586
At iterate     4  f =      -462.46  |proj g|=        2.7568
At iterate     5  f =      -462.53  |proj g|=        2.7454
At iterate     6  f =      -462.68  |proj g|=        2.7681
At iterate     7  f =      -462.69  |proj g|=        2.8107
At iterate     8  f =      -462.69  |proj g|=        2.7986
At iterate     9  f =      -462.69  |proj g|=        2.7975
At iterate    10  f =      -462.69  |proj g|=        2.7976
At iterate    11  f =      -462.69  |proj g|=        2.7948
At iterate    12  f =      -462.69  |proj g|=        2.7963
At iterate    13  f =       -462.7  |proj g|=         2.798
At iterate    14  f =      -462.71  |proj g|=        2.8023
At iterate    15  f =      -462.73  |proj g|=        2.8062
At iterate    16  f =       -462.8  |proj g|=        2.8084
At iterate    17  f =      -462.91  |proj g|=        2.8629
At iterate    18  f =      -463.14  |proj g|=        2.7856
At iterate    19  f =      -463.57  |proj g|=        2.7051
At iterate    20  f =      -464.08  |proj g|=        2.3886
At iterate    21  f =       -464.3  |proj g|=         2.417
At iterate    22  f =      -464.39  |proj g|=        2.4152
At iterate    23  f =      -464.39  |proj g|=        2.4224
At iterate    24  f =      -464.39  |proj g|=        2.4233
At iterate    25  f =      -464.39  |proj g|=        2.4233
At iterate    26  f =      -464.39  |proj g|=        2.4234

iterations 26
function evaluations 35
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.42339
final function value -464.394

F = -464.394
final  value -464.394274 
converged
 
INFO  [05:04:58.012] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:04:58.113] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:04:58.120] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:05:01.371] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:05:03.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:05:08.262] [mlr3]  Finished benchmark 
INFO  [05:05:08.372] [bbotk] Result of batch 81: 
INFO  [05:05:08.374] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:05:08.374] [bbotk]              8.332804                 6.336363                       0.3143135 
INFO  [05:05:08.374] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:05:08.374] [bbotk]                     1127        0.898 -0.9592621         <NA>    0.972574 
INFO  [05:05:08.374] [bbotk]                                 uhash 
INFO  [05:05:08.374] [bbotk]  e69bf171-f7d7-46c2-9964-7b2005bca8b4 
DEBUG [05:05:09.327] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.264742e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.264742e-05 0.001587787 
  - best initial criterion value(s) :  442.9736 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -442.97  |proj g|=       6.7115
At iterate     1  f =      -459.95  |proj g|=        3.3448
At iterate     2  f =      -463.59  |proj g|=        3.2637
At iterate     3  f =      -468.67  |proj g|=        2.8915
At iterate     4  f =      -468.93  |proj g|=        2.7584
At iterate     5  f =      -469.04  |proj g|=        2.7464
At iterate     6  f =      -469.28  |proj g|=        2.7606
At iterate     7  f =      -469.29  |proj g|=        2.7795
At iterate     8  f =      -469.29  |proj g|=        2.7817
At iterate     9  f =      -469.29  |proj g|=        2.7818
At iterate    10  f =      -469.29  |proj g|=         2.778
At iterate    11  f =      -469.29  |proj g|=        2.7782
At iterate    12  f =      -469.56  |proj g|=        2.7673
At iterate    13  f =      -471.77  |proj g|=        2.6053
At iterate    14  f =      -472.47  |proj g|=        2.4143
At iterate    15  f =      -472.55  |proj g|=        2.4398
At iterate    16  f =      -472.55  |proj g|=        2.4518
At iterate    17  f =      -472.58  |proj g|=        2.4489
At iterate    18  f =      -472.58  |proj g|=        2.4476
At iterate    19  f =      -472.58  |proj g|=        2.4472
At iterate    20  f =      -472.58  |proj g|=        2.4473

iterations 20
function evaluations 30
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.44731
final function value -472.578

F = -472.578
final  value -472.578314 
converged
 
INFO  [05:05:09.332] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:05:09.421] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:05:09.428] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:05:16.323] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:05:24.047] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:05:29.707] [mlr3]  Finished benchmark 
INFO  [05:05:29.810] [bbotk] Result of batch 82: 
INFO  [05:05:29.812] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:05:29.812] [bbotk]              6.874088                 9.050013                       0.3686737 
INFO  [05:05:29.812] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:05:29.812] [bbotk]                     3020        0.667 -0.9580589         <NA>   0.9753946 
INFO  [05:05:29.812] [bbotk]                                 uhash 
INFO  [05:05:29.812] [bbotk]  6b29bbf4-e25b-4375-aefe-ab0179c45d19 
DEBUG [05:05:30.854] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.257931e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.257931e-05 0.001583144 
  - best initial criterion value(s) :  434.0355 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -434.04  |proj g|=       4.7244
At iterate     1  f =      -444.85  |proj g|=        4.4858
At iterate     2  f =      -460.03  |proj g|=        5.1489
At iterate     3  f =      -462.44  |proj g|=        4.6386
At iterate     4  f =      -465.66  |proj g|=        4.4501
At iterate     5  f =      -465.88  |proj g|=        3.9829
At iterate     6  f =      -465.91  |proj g|=        3.9216
At iterate     7  f =      -465.95  |proj g|=        4.0543
At iterate     8  f =      -465.95  |proj g|=        4.0646
At iterate     9  f =      -465.95  |proj g|=        4.0756
At iterate    10  f =      -465.95  |proj g|=        4.0921
At iterate    11  f =      -465.96  |proj g|=        4.1179
At iterate    12  f =      -465.97  |proj g|=        4.1559
At iterate    13  f =      -466.01  |proj g|=        4.2103
At iterate    14  f =      -466.11  |proj g|=        4.2833
At iterate    15  f =      -466.34  |proj g|=        4.3588
At iterate    16  f =      -466.79  |proj g|=        4.3695
At iterate    17  f =      -467.42  |proj g|=        4.2007
At iterate    18  f =      -468.09  |proj g|=        3.9554
At iterate    19  f =      -470.64  |proj g|=        2.9683
At iterate    20  f =      -472.99  |proj g|=        4.2159
At iterate    21  f =      -473.23  |proj g|=        4.4082
At iterate    22  f =      -473.38  |proj g|=         4.959
At iterate    23  f =      -473.38  |proj g|=        4.9431
At iterate    24  f =      -473.38  |proj g|=        4.9448
At iterate    25  f =      -473.38  |proj g|=        4.9452

iterations 25
function evaluations 28
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.94516
final function value -473.381

F = -473.381
final  value -473.380696 
converged
 
INFO  [05:05:30.856] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:05:30.932] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:05:30.939] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:05:41.245] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:05:53.744] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:06:03.570] [mlr3]  Finished benchmark 
INFO  [05:06:03.670] [bbotk] Result of batch 83: 
INFO  [05:06:03.672] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:06:03.672] [bbotk]              8.065062                 9.076748                       0.3837494 
INFO  [05:06:03.672] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:06:03.672] [bbotk]                     4482        0.706 -0.9599709         <NA>   0.9763548 
INFO  [05:06:03.672] [bbotk]                                 uhash 
INFO  [05:06:03.672] [bbotk]  5438204d-4a00-4ffe-acf1-0c8b1fd88c99 
DEBUG [05:06:04.612] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.252432e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.252432e-05 0.001584895 
  - best initial criterion value(s) :  436.9372 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -436.94  |proj g|=       5.0887
At iterate     1  f =       -453.3  |proj g|=         7.026
At iterate     2  f =      -460.87  |proj g|=        6.3397
At iterate     3  f =      -463.92  |proj g|=        4.8153
At iterate     4  f =      -472.16  |proj g|=        1.5925
At iterate     5  f =      -473.53  |proj g|=        1.8634
At iterate     6  f =      -473.59  |proj g|=        1.8226
At iterate     7  f =      -473.62  |proj g|=        1.8286
At iterate     8  f =      -473.62  |proj g|=        1.8267
At iterate     9  f =      -473.62  |proj g|=        1.8268

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.82679
final function value -473.62

F = -473.62
final  value -473.620227 
converged
 
INFO  [05:06:04.616] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:06:04.716] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:06:04.723] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:06:14.045] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:06:22.144] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:06:29.818] [mlr3]  Finished benchmark 
INFO  [05:06:29.921] [bbotk] Result of batch 84: 
INFO  [05:06:29.923] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:06:29.923] [bbotk]              3.469127                 7.227701                       0.4384169 
INFO  [05:06:29.923] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:06:29.923] [bbotk]                     3846        0.683 -0.962224         <NA>   0.9746068 
INFO  [05:06:29.923] [bbotk]                                 uhash 
INFO  [05:06:29.923] [bbotk]  60ef24e1-0974-4825-b29a-02d7657a4c04 
DEBUG [05:06:30.961] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.244783e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.244783e-05 0.001581526 
  - best initial criterion value(s) :  477.7748 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -477.77  |proj g|=        10.29
At iterate     1  f =      -479.56  |proj g|=        8.1953
At iterate     2  f =      -484.54  |proj g|=        7.2084
At iterate     3  f =      -489.88  |proj g|=        4.6264
At iterate     4  f =      -491.09  |proj g|=        2.8521
At iterate     5  f =      -491.27  |proj g|=        2.4257
At iterate     6  f =      -491.42  |proj g|=        2.3531
At iterate     7  f =      -491.42  |proj g|=        2.3166
At iterate     8  f =      -491.43  |proj g|=        2.3211
At iterate     9  f =      -491.43  |proj g|=        2.3222
At iterate    10  f =      -491.43  |proj g|=        2.3264
At iterate    11  f =      -491.43  |proj g|=        2.3317
At iterate    12  f =      -491.43  |proj g|=        2.3377
At iterate    13  f =      -491.43  |proj g|=        2.3399
At iterate    14  f =      -491.44  |proj g|=        2.3229
At iterate    15  f =      -491.46  |proj g|=         2.248
At iterate    16  f =      -491.49  |proj g|=        2.0625
At iterate    17  f =      -491.52  |proj g|=        1.9539
At iterate    18  f =       -491.6  |proj g|=        1.5755
At iterate    19  f =      -491.69  |proj g|=           1.4
At iterate    20  f =      -492.35  |proj g|=       0.80996
At iterate    21  f =      -493.51  |proj g|=       0.80379
At iterate    22  f =      -495.67  |proj g|=        1.1646
At iterate    23  f =      -497.63  |proj g|=        1.3635
At iterate    24  f =         -499  |proj g|=        2.1352
At iterate    25  f =      -500.48  |proj g|=        1.6216
At iterate    26  f =      -502.62  |proj g|=       0.66136
At iterate    27  f =      -502.98  |proj g|=       0.63656
At iterate    28  f =      -503.06  |proj g|=       0.35676
At iterate    29  f =      -503.07  |proj g|=       0.36021
At iterate    30  f =      -503.08  |proj g|=       0.61274
At iterate    31  f =      -503.08  |proj g|=       0.33041
At iterate    32  f =      -503.08  |proj g|=       0.33118
At iterate    33  f =      -503.08  |proj g|=       0.33114

iterations 33
function evaluations 38
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.331144
final function value -503.082

F = -503.082
final  value -503.081615 
converged
 
INFO  [05:06:30.965] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:06:31.092] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:06:31.099] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:06:36.349] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:06:46.857] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:06:56.774] [mlr3]  Finished benchmark 
INFO  [05:06:56.877] [bbotk] Result of batch 85: 
INFO  [05:06:56.879] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:06:56.879] [bbotk]              8.119499                  9.72976                       0.1808103 
INFO  [05:06:56.879] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:06:56.879] [bbotk]                     2482        0.688 -0.9545265         <NA>   0.9735023 
INFO  [05:06:56.879] [bbotk]                                 uhash 
INFO  [05:06:56.879] [bbotk]  2dbbaa5a-bac1-488e-8e48-823503be5e04 
DEBUG [05:06:58.006] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.236146e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.236146e-05 0.00156691 
  - best initial criterion value(s) :  451.7879 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -451.79  |proj g|=       6.8482
At iterate     1  f =      -487.81  |proj g|=        3.8339
At iterate     2  f =      -490.76  |proj g|=        3.7938
At iterate     3  f =      -495.16  |proj g|=        3.5615
At iterate     4  f =      -495.66  |proj g|=        3.4004
At iterate     5  f =      -495.87  |proj g|=        3.4239
At iterate     6  f =      -497.53  |proj g|=         3.501
At iterate     7  f =      -497.93  |proj g|=        3.5071
At iterate     8  f =      -498.01  |proj g|=         3.626
At iterate     9  f =      -498.04  |proj g|=        3.5843
At iterate    10  f =      -498.04  |proj g|=        3.5741
At iterate    11  f =      -498.04  |proj g|=        3.5743
At iterate    12  f =      -498.04  |proj g|=        3.5747
At iterate    13  f =      -498.04  |proj g|=        3.5759
At iterate    14  f =      -498.04  |proj g|=        3.5776
At iterate    15  f =      -498.04  |proj g|=        3.5799
At iterate    16  f =      -498.05  |proj g|=        3.5811
At iterate    17  f =      -498.05  |proj g|=        3.6061
At iterate    18  f =      -498.06  |proj g|=        3.5903
At iterate    19  f =      -498.11  |proj g|=        3.5384
At iterate    20  f =      -498.18  |proj g|=        3.4678
At iterate    21  f =      -498.24  |proj g|=        3.4014
At iterate    22  f =      -498.26  |proj g|=        3.4224
At iterate    23  f =      -498.27  |proj g|=        3.3977
At iterate    24  f =      -498.27  |proj g|=        3.4081
At iterate    25  f =      -498.27  |proj g|=        3.4086
At iterate    26  f =      -498.27  |proj g|=        3.4087
At iterate    27  f =      -498.27  |proj g|=        3.4093
At iterate    28  f =      -498.27  |proj g|=        3.4099
At iterate    29  f =      -498.27  |proj g|=        3.4109
At iterate    30  f =      -498.27  |proj g|=        3.4117
At iterate    31  f =      -498.27  |proj g|=        3.4149
At iterate    32  f =      -498.27  |proj g|=        3.4152
At iterate    33  f =      -498.28  |proj g|=        3.4169
At iterate    34  f =       -498.3  |proj g|=        3.4043
At iterate    35  f =       -498.3  |proj g|=        3.4246
At iterate    36  f =      -498.34  |proj g|=        3.3949
At iterate    37  f =      -498.62  |proj g|=        3.0547
At iterate    38  f =      -498.69  |proj g|=        3.0914
At iterate    39  f =      -498.74  |proj g|=        3.1059
At iterate    40  f =      -501.32  |proj g|=        2.8342
At iterate    41  f =      -505.62  |proj g|=        2.5122
At iterate    42  f =       -513.8  |proj g|=       0.61713
At iterate    43  f =      -514.09  |proj g|=        0.5845
At iterate    44  f =      -514.09  |proj g|=       0.40442
At iterate    45  f =      -514.09  |proj g|=       0.27645
At iterate    46  f =      -514.09  |proj g|=      0.045313
At iterate    47  f =      -514.09  |proj g|=       0.20168
At iterate    48  f =      -514.09  |proj g|=       0.39482
At iterate    49  f =      -514.09  |proj g|=       0.39453
At iterate    50  f =      -514.09  |proj g|=       0.39483
At iterate    51  f =      -514.09  |proj g|=       0.39417
At iterate    52  f =      -514.09  |proj g|=     0.0011282
At iterate    53  f =      -514.09  |proj g|=     0.0011282

iterations 53
function evaluations 61
segments explored during Cauchy searches 55
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0011282
final function value -514.091

F = -514.091
final  value -514.090571 
converged
 
INFO  [05:06:58.010] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:06:58.099] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:06:58.107] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:07:08.637] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:07:17.885] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:07:26.587] [mlr3]  Finished benchmark 
INFO  [05:07:26.690] [bbotk] Result of batch 86: 
INFO  [05:07:26.692] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:07:26.692] [bbotk]              5.843348                 3.434063                       0.4914546 
INFO  [05:07:26.692] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:07:26.692] [bbotk]                     4233        0.687 -0.9508595         <NA>   0.9764936 
INFO  [05:07:26.692] [bbotk]                                 uhash 
INFO  [05:07:26.692] [bbotk]  6aeef676-f106-4d99-a2c6-8310e9b2f605 
DEBUG [05:07:27.682] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.230939e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.230939e-05 0.001568308 
  - best initial criterion value(s) :  485.0419 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -485.04  |proj g|=        3.228
At iterate     1  f =      -487.76  |proj g|=        1.9548
At iterate     2  f =         -492  |proj g|=        1.6137
At iterate     3  f =      -495.26  |proj g|=        1.3188
At iterate     4  f =      -495.38  |proj g|=        1.2449
At iterate     5  f =      -495.39  |proj g|=        1.2358
At iterate     6  f =      -495.39  |proj g|=        1.2318
At iterate     7  f =       -495.4  |proj g|=        1.2209
At iterate     8  f =      -495.42  |proj g|=        1.2195
At iterate     9  f =      -495.42  |proj g|=        1.2299
At iterate    10  f =      -495.43  |proj g|=        1.2367
At iterate    11  f =      -495.43  |proj g|=        1.2379
At iterate    12  f =      -495.43  |proj g|=        1.2379

iterations 12
function evaluations 16
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.23791
final function value -495.426

F = -495.426
final  value -495.426185 
converged
 
INFO  [05:07:27.687] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:07:27.796] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:07:27.803] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:07:35.247] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:07:42.377] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:07:48.692] [mlr3]  Finished benchmark 
INFO  [05:07:48.795] [bbotk] Result of batch 87: 
INFO  [05:07:48.797] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:07:48.797] [bbotk]              2.605726                 9.025001                       0.4999184 
INFO  [05:07:48.797] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:07:48.797] [bbotk]                     2957        0.712 -0.959646         <NA>   0.9679987 
INFO  [05:07:48.797] [bbotk]                                 uhash 
INFO  [05:07:48.797] [bbotk]  42873a84-970c-4f60-a06c-4a74e0d200f1 
DEBUG [05:07:49.748] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.220447e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.220447e-05 0.001560023 
  - best initial criterion value(s) :  510.4219 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -510.42  |proj g|=      0.57858
At iterate     1  f =       -511.3  |proj g|=          2.84
At iterate     2  f =      -514.08  |proj g|=        2.2233
At iterate     3  f =      -515.03  |proj g|=        1.6325
At iterate     4  f =       -515.1  |proj g|=        1.4432
At iterate     5  f =      -515.26  |proj g|=        1.5146
At iterate     6  f =      -515.66  |proj g|=        1.8781
At iterate     7  f =      -515.68  |proj g|=        1.9701
At iterate     8  f =      -515.68  |proj g|=        2.0022
At iterate     9  f =      -515.68  |proj g|=        2.0061
At iterate    10  f =      -515.68  |proj g|=        2.0065

iterations 10
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.00647
final function value -515.682

F = -515.682
final  value -515.681677 
converged
 
INFO  [05:07:49.753] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:07:49.870] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:07:49.877] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:07:51.895] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:07:53.857] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:07:55.813] [mlr3]  Finished benchmark 
INFO  [05:07:55.917] [bbotk] Result of batch 88: 
INFO  [05:07:55.918] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:07:55.918] [bbotk]               6.75642                 2.762599                       0.2268347 
INFO  [05:07:55.918] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:07:55.918] [bbotk]                      816        0.694 -0.9574873         <NA>   0.9681058 
INFO  [05:07:55.918] [bbotk]                                 uhash 
INFO  [05:07:55.918] [bbotk]  3c193d49-7181-4e00-9a0e-9c414b2bcedd 
DEBUG [05:07:57.021] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.210122e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.210122e-05 0.001534044 
  - best initial criterion value(s) :  501.5667 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -501.57  |proj g|=       2.8023
At iterate     1  f =      -507.17  |proj g|=        5.0197
At iterate     2  f =      -507.84  |proj g|=        4.5293
At iterate     3  f =      -508.42  |proj g|=        4.2688
At iterate     4  f =      -508.85  |proj g|=        4.0885
At iterate     5  f =      -508.95  |proj g|=        4.1673
At iterate     6  f =      -508.96  |proj g|=        4.1452
At iterate     7  f =      -508.96  |proj g|=         4.145
At iterate     8  f =      -508.96  |proj g|=        4.1461
At iterate     9  f =      -508.96  |proj g|=        4.1484
At iterate    10  f =      -508.96  |proj g|=        4.1528
At iterate    11  f =      -508.96  |proj g|=        4.1587
At iterate    12  f =      -508.96  |proj g|=        4.1688
At iterate    13  f =      -508.97  |proj g|=        4.1846
At iterate    14  f =      -508.97  |proj g|=          4.21
At iterate    15  f =      -508.98  |proj g|=        4.2507
At iterate    16  f =      -509.02  |proj g|=        4.3131
At iterate    17  f =      -509.11  |proj g|=        4.3983
At iterate    18  f =      -509.33  |proj g|=        4.4715
At iterate    19  f =      -509.74  |proj g|=        4.3695
At iterate    20  f =      -509.97  |proj g|=        4.0941
At iterate    21  f =      -509.98  |proj g|=        4.0242
At iterate    22  f =      -509.98  |proj g|=        4.0138
At iterate    23  f =      -509.98  |proj g|=        3.9938
At iterate    24  f =      -509.99  |proj g|=        3.9696
At iterate    25  f =      -510.01  |proj g|=        3.9288
At iterate    26  f =      -510.07  |proj g|=        3.8723
At iterate    27  f =      -510.21  |proj g|=        3.7823
At iterate    28  f =      -510.56  |proj g|=        3.6416
At iterate    29  f =      -511.45  |proj g|=        3.4217
At iterate    30  f =      -511.69  |proj g|=        2.9708
At iterate    31  f =      -514.63  |proj g|=        2.3457
At iterate    32  f =      -527.94  |proj g|=       0.82468
At iterate    33  f =      -528.25  |proj g|=       0.88276
At iterate    34  f =      -528.28  |proj g|=       0.90861
At iterate    35  f =      -528.29  |proj g|=       0.93169
At iterate    36  f =      -528.29  |proj g|=       0.97232
At iterate    37  f =      -528.29  |proj g|=       0.97402
At iterate    38  f =      -528.29  |proj g|=       0.97407

iterations 38
function evaluations 43
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.97407
final function value -528.288

F = -528.288
final  value -528.288161 
converged
 
INFO  [05:07:57.025] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:07:57.117] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:07:57.124] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:08:05.762] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:08:12.930] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:08:19.417] [mlr3]  Finished benchmark 
INFO  [05:08:19.532] [bbotk] Result of batch 89: 
INFO  [05:08:19.535] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:08:19.535] [bbotk]              9.804406                 9.635071                       0.3310268 
INFO  [05:08:19.535] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:08:19.535] [bbotk]                     4158        0.705 -0.9530981         <NA>   0.9759903 
INFO  [05:08:19.535] [bbotk]                                 uhash 
INFO  [05:08:19.535] [bbotk]  bac5467e-77f9-4df1-b12e-19a653344af4 
DEBUG [05:08:21.253] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.204544e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.204544e-05 0.001533631 
  - best initial criterion value(s) :  495.2413 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -495.24  |proj g|=       6.6317
At iterate     1  f =      -497.02  |proj g|=        7.7289
At iterate     2  f =      -498.54  |proj g|=        7.4363
At iterate     3  f =      -503.35  |proj g|=        5.7195
At iterate     4  f =       -504.3  |proj g|=         5.169
At iterate     5  f =      -504.94  |proj g|=        4.7075
At iterate     6  f =       -505.1  |proj g|=        4.5699
At iterate     7  f =      -505.15  |proj g|=        4.6483
At iterate     8  f =      -505.15  |proj g|=        4.5832
At iterate     9  f =      -505.15  |proj g|=        4.5869
At iterate    10  f =      -505.15  |proj g|=         4.574
At iterate    11  f =      -505.15  |proj g|=        4.5647
At iterate    12  f =      -505.16  |proj g|=        4.5513
At iterate    13  f =      -505.16  |proj g|=        4.5153
At iterate    14  f =      -505.17  |proj g|=        4.4608
At iterate    15  f =      -505.18  |proj g|=        4.3575
At iterate    16  f =      -505.23  |proj g|=        4.2044
At iterate    17  f =      -505.25  |proj g|=        4.1008
At iterate    18  f =      -505.35  |proj g|=        3.9363
At iterate    19  f =      -508.29  |proj g|=        3.3573
At iterate    20  f =      -513.29  |proj g|=        1.9577
At iterate    21  f =      -515.68  |proj g|=        1.8688
At iterate    22  f =      -516.14  |proj g|=        1.8147
At iterate    23  f =      -516.14  |proj g|=        1.8512
At iterate    24  f =      -516.22  |proj g|=        1.7921
At iterate    25  f =      -516.22  |proj g|=        1.7838
At iterate    26  f =      -516.22  |proj g|=        1.7843
At iterate    27  f =      -516.22  |proj g|=        1.7845
At iterate    28  f =      -516.22  |proj g|=        1.7846
At iterate    29  f =      -516.22  |proj g|=        1.7842
At iterate    30  f =      -516.22  |proj g|=        1.7849
At iterate    31  f =      -516.22  |proj g|=        1.7843
At iterate    32  f =      -516.22  |proj g|=        1.7838
At iterate    33  f =      -516.22  |proj g|=        1.7836
At iterate    34  f =      -516.22  |proj g|=        1.7829
At iterate    35  f =      -516.22  |proj g|=         1.782
At iterate    36  f =      -516.22  |proj g|=        1.7807
At iterate    37  f =      -516.22  |proj g|=        1.7796
At iterate    38  f =      -516.22  |proj g|=        1.7792
At iterate    39  f =      -516.23  |proj g|=         1.772
At iterate    40  f =      -516.23  |proj g|=        1.7732
At iterate    41  f =      -516.24  |proj g|=        1.7672
At iterate    42  f =      -516.24  |proj g|=        1.7762
At iterate    43  f =      -516.24  |proj g|=        1.7693
At iterate    44  f =      -516.24  |proj g|=        1.7668
At iterate    45  f =      -516.24  |proj g|=        1.7659
At iterate    46  f =      -516.24  |proj g|=        1.7664
At iterate    47  f =      -516.24  |proj g|=        1.7705
At iterate    48  f =      -516.25  |proj g|=        1.7685
At iterate    49  f =      -516.25  |proj g|=        1.7733
At iterate    50  f =      -516.27  |proj g|=        1.7778
At iterate    51  f =      -516.32  |proj g|=         1.778
At iterate    52  f =      -516.43  |proj g|=        1.7612
At iterate    53  f =      -516.69  |proj g|=        1.7004
At iterate    54  f =      -516.73  |proj g|=        1.6287
At iterate    55  f =      -517.25  |proj g|=        1.5066
At iterate    56  f =      -517.91  |proj g|=        1.3021
At iterate    57  f =      -518.21  |proj g|=       0.78307
At iterate    58  f =      -518.26  |proj g|=       0.57225
At iterate    59  f =      -518.28  |proj g|=       0.51953
At iterate    60  f =      -518.29  |proj g|=       0.52097
At iterate    61  f =      -518.29  |proj g|=       0.52192
At iterate    62  f =      -518.29  |proj g|=       0.52284
At iterate    63  f =      -518.29  |proj g|=       0.52549
At iterate    64  f =       -518.3  |proj g|=       0.52936
At iterate    65  f =       -518.3  |proj g|=       0.52974
At iterate    66  f =       -518.3  |proj g|=       0.53268
At iterate    67  f =       -518.3  |proj g|=       0.53074
At iterate    68  f =       -518.3  |proj g|=       0.53153
At iterate    69  f =       -518.3  |proj g|=        0.5323
At iterate    70  f =       -518.3  |proj g|=       0.53391
At iterate    71  f =      -518.31  |proj g|=       0.53715
At iterate    72  f =      -518.31  |proj g|=        0.5377
At iterate    73  f =      -518.32  |proj g|=       0.53752
At iterate    74  f =      -518.35  |proj g|=        0.5367
At iterate    75  f =      -518.36  |proj g|=       0.53641
At iterate    76  f =      -518.36  |proj g|=       0.53604
At iterate    77  f =      -518.37  |proj g|=       0.53562
At iterate    78  f =      -518.38  |proj g|=       0.53507
At iterate    79  f =      -518.41  |proj g|=       0.53304
At iterate    80  f =      -518.48  |proj g|=       0.52817
At iterate    81  f =      -518.67  |proj g|=       0.63133
At iterate    82  f =       -519.1  |proj g|=       0.98313
At iterate    83  f =      -520.07  |proj g|=        1.4945
At iterate    84  f =      -520.55  |proj g|=        1.4948
At iterate    85  f =      -520.68  |proj g|=        1.1575
At iterate    86  f =      -520.79  |proj g|=       0.93866
At iterate    87  f =      -521.55  |proj g|=       0.68966
At iterate    88  f =      -521.78  |proj g|=        0.6405
At iterate    89  f =      -521.79  |proj g|=       0.34607
At iterate    90  f =      -521.79  |proj g|=      0.044984
At iterate    91  f =      -521.79  |proj g|=      0.010092
At iterate    92  f =      -521.79  |proj g|=      0.010092

iterations 92
function evaluations 110
segments explored during Cauchy searches 94
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0100916
final function value -521.791

F = -521.791
final  value -521.790833 
converged
 
INFO  [05:08:21.258] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:08:21.362] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:08:21.370] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:08:25.451] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:08:29.513] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:08:33.590] [mlr3]  Finished benchmark 
INFO  [05:08:33.693] [bbotk] Result of batch 90: 
INFO  [05:08:33.695] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:08:33.695] [bbotk]               7.10337                 7.361245                       0.2849593 
INFO  [05:08:33.695] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:08:33.695] [bbotk]                     2645        1.031 -0.956766         <NA>   0.9748721 
INFO  [05:08:33.695] [bbotk]                                 uhash 
INFO  [05:08:33.695] [bbotk]  7964c8b6-7ab3-447b-9446-a26dc8582da0 
DEBUG [05:08:34.720] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.197726e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.197726e-05 0.001523666 
  - best initial criterion value(s) :  492.3824 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -492.38  |proj g|=        3.332
At iterate     1  f =      -498.08  |proj g|=         2.467
At iterate     2  f =      -503.62  |proj g|=        2.8201
At iterate     3  f =      -503.99  |proj g|=        2.7802
At iterate     4  f =      -504.14  |proj g|=        2.7589
At iterate     5  f =      -504.15  |proj g|=        2.7666
At iterate     6  f =      -504.15  |proj g|=        2.7785
At iterate     7  f =      -504.15  |proj g|=        2.7879
At iterate     8  f =      -504.15  |proj g|=        2.7895
At iterate     9  f =      -504.15  |proj g|=        2.7896

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.78959
final function value -504.149

F = -504.149
final  value -504.148545 
converged
 
INFO  [05:08:34.725] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:08:34.825] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:08:34.832] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:08:38.030] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:08:41.268] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:08:44.521] [mlr3]  Finished benchmark 
INFO  [05:08:44.619] [bbotk] Result of batch 91: 
INFO  [05:08:44.621] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:08:44.621] [bbotk]              8.786089                 7.340512                       0.1451702 
INFO  [05:08:44.621] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:08:44.621] [bbotk]                     2154         0.75 -0.9602024         <NA>    0.972063 
INFO  [05:08:44.621] [bbotk]                                 uhash 
INFO  [05:08:44.621] [bbotk]  cee1dfb0-0e07-46c2-91a2-0ef284134d93 
DEBUG [05:08:45.608] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.188764e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.188764e-05 0.001509348 
  - best initial criterion value(s) :  516.3738 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -516.37  |proj g|=       1.9239
At iterate     1  f =      -521.34  |proj g|=        1.5082
At iterate     2  f =      -522.09  |proj g|=          1.61
At iterate     3  f =      -522.22  |proj g|=        1.5928
At iterate     4  f =      -522.23  |proj g|=         1.586
At iterate     5  f =      -522.23  |proj g|=         1.586
At iterate     6  f =      -522.23  |proj g|=        1.5862
At iterate     7  f =      -522.23  |proj g|=        1.5864

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.58637
final function value -522.232

F = -522.232
final  value -522.232053 
converged
 
INFO  [05:08:45.612] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:08:45.702] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:08:45.709] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:08:50.809] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:08:56.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:09:01.422] [mlr3]  Finished benchmark 
INFO  [05:09:01.526] [bbotk] Result of batch 92: 
INFO  [05:09:01.528] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:09:01.528] [bbotk]              5.365167                  2.90092                      0.01663369 
INFO  [05:09:01.528] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:09:01.528] [bbotk]                     3333        0.717 -0.9588608         <NA>   0.9533734 
INFO  [05:09:01.528] [bbotk]                                 uhash 
INFO  [05:09:01.528] [bbotk]  1b91536b-9bba-4709-8ac1-f46d38c8136e 
DEBUG [05:09:02.703] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.198142e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.198142e-05 0.001506669 
  - best initial criterion value(s) :  514.8706 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -514.87  |proj g|=       1.9508
At iterate     1  f =      -524.82  |proj g|=        5.6181
At iterate     2  f =      -526.19  |proj g|=        5.4003
At iterate     3  f =      -526.85  |proj g|=        4.3578
At iterate     4  f =      -527.21  |proj g|=        4.9014
At iterate     5  f =      -527.26  |proj g|=         4.787
At iterate     6  f =      -527.28  |proj g|=        4.7032
At iterate     7  f =      -527.32  |proj g|=        4.5646
At iterate     8  f =      -527.36  |proj g|=        4.3892
At iterate     9  f =      -527.38  |proj g|=        4.3491
At iterate    10  f =      -527.38  |proj g|=        4.3665
At iterate    11  f =      -527.38  |proj g|=        4.3709
At iterate    12  f =      -527.38  |proj g|=        4.3715
At iterate    13  f =      -527.38  |proj g|=        4.3764
At iterate    14  f =      -527.38  |proj g|=        4.3821
At iterate    15  f =      -527.38  |proj g|=        4.3927
At iterate    16  f =      -527.39  |proj g|=         4.409
At iterate    17  f =      -527.39  |proj g|=        4.4354
At iterate    18  f =      -527.39  |proj g|=        4.4735
At iterate    19  f =       -527.4  |proj g|=        4.5287
At iterate    20  f =      -527.42  |proj g|=        4.6019
At iterate    21  f =      -527.43  |proj g|=         4.643
At iterate    22  f =      -527.48  |proj g|=        4.7314
At iterate    23  f =      -531.81  |proj g|=        4.0947
At iterate    24  f =      -548.78  |proj g|=       0.71476
At iterate    25  f =      -550.82  |proj g|=       0.37882
At iterate    26  f =      -551.07  |proj g|=        0.4691
At iterate    27  f =      -551.21  |proj g|=       0.65232
At iterate    28  f =      -551.23  |proj g|=       0.74429
At iterate    29  f =      -551.24  |proj g|=       0.79454
At iterate    30  f =      -551.24  |proj g|=       0.79748
At iterate    31  f =      -551.24  |proj g|=       0.80053
At iterate    32  f =      -551.24  |proj g|=       0.80021

iterations 32
function evaluations 35
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.800211
final function value -551.243

F = -551.243
final  value -551.243499 
converged
 
INFO  [05:09:02.707] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:09:02.821] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:09:02.828] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:09:05.724] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:09:08.371] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:09:11.005] [mlr3]  Finished benchmark 
INFO  [05:09:11.122] [bbotk] Result of batch 93: 
INFO  [05:09:11.124] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:09:11.124] [bbotk]              9.476484                 7.351828                      0.05758663 
INFO  [05:09:11.124] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:09:11.124] [bbotk]                     1716        0.805 -0.9506702         <NA>   0.9636222 
INFO  [05:09:11.124] [bbotk]                                 uhash 
INFO  [05:09:11.124] [bbotk]  24f5d426-b1d8-4c9d-ae33-2567856e4e38 
DEBUG [05:09:12.367] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.190387e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.190387e-05 0.001491669 
  - best initial criterion value(s) :  490.3455 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -490.35  |proj g|=       11.738
At iterate     1  f =      -504.05  |proj g|=        5.1434
At iterate     2  f =      -506.47  |proj g|=        4.3329
At iterate     3  f =       -507.5  |proj g|=        3.1846
At iterate     4  f =      -507.79  |proj g|=        2.7843
At iterate     5  f =      -507.83  |proj g|=        2.6433
At iterate     6  f =      -507.84  |proj g|=        2.6203
At iterate     7  f =      -507.84  |proj g|=        2.6372
At iterate     8  f =      -507.84  |proj g|=        2.6368
At iterate     9  f =      -507.84  |proj g|=        2.6365
At iterate    10  f =      -507.84  |proj g|=        2.6357
At iterate    11  f =      -507.84  |proj g|=        2.6342
At iterate    12  f =      -507.84  |proj g|=        2.6305
At iterate    13  f =      -507.84  |proj g|=        2.6223
At iterate    14  f =      -507.84  |proj g|=         2.602
At iterate    15  f =      -507.85  |proj g|=        2.5745
At iterate    16  f =      -507.86  |proj g|=        2.5013
At iterate    17  f =      -507.86  |proj g|=        2.5251
At iterate    18  f =      -507.88  |proj g|=        2.4432
At iterate    19  f =      -509.97  |proj g|=        2.0586
At iterate    20  f =      -516.89  |proj g|=        1.9676
At iterate    21  f =      -518.06  |proj g|=        1.9166
At iterate    22  f =      -518.07  |proj g|=        1.9671
At iterate    23  f =      -518.08  |proj g|=        1.9426
At iterate    24  f =      -518.08  |proj g|=        1.9478
At iterate    25  f =      -518.08  |proj g|=        1.9474
At iterate    26  f =      -518.08  |proj g|=        1.9472
At iterate    27  f =      -518.08  |proj g|=        1.9473
At iterate    28  f =      -518.08  |proj g|=        1.9476
At iterate    29  f =      -518.08  |proj g|=        1.9479

iterations 29
function evaluations 37
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.94791
final function value -518.079

F = -518.079
final  value -518.079482 
converged
 
INFO  [05:09:12.372] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:09:12.506] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:09:12.514] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:09:23.527] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:09:34.452] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:09:46.587] [mlr3]  Finished benchmark 
INFO  [05:09:46.691] [bbotk] Result of batch 94: 
INFO  [05:09:46.693] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:09:46.693] [bbotk]              7.654452                 8.495489                       0.4972141 
INFO  [05:09:46.693] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:09:46.693] [bbotk]                     4962        0.818 -0.9606679         <NA>   0.9766631 
INFO  [05:09:46.693] [bbotk]                                 uhash 
INFO  [05:09:46.693] [bbotk]  1118c123-a59c-459b-85ce-9c6e41334297 
DEBUG [05:09:47.668] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.186059e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.186059e-05 0.001491076 
  - best initial criterion value(s) :  510.4416 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -510.44  |proj g|=      0.80029
At iterate     1  f =      -510.59  |proj g|=       0.86375
At iterate     2  f =      -510.66  |proj g|=       0.74796
At iterate     3  f =      -510.69  |proj g|=       0.75103
At iterate     4  f =      -510.69  |proj g|=       0.75317
At iterate     5  f =      -510.69  |proj g|=       0.75344
At iterate     6  f =      -510.69  |proj g|=       0.75345

iterations 6
function evaluations 9
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.75345
final function value -510.688

F = -510.688
final  value -510.688066 
converged
 
INFO  [05:09:47.673] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:09:47.812] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:09:47.820] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:10:00.375] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:10:12.365] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:10:22.033] [mlr3]  Finished benchmark 
INFO  [05:10:22.245] [bbotk] Result of batch 95: 
INFO  [05:10:22.247] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:10:22.247] [bbotk]              3.803254                 4.104927                      0.05707306 
INFO  [05:10:22.247] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:10:22.247] [bbotk]                     4247        0.724 -0.9641521         <NA>   0.9656417 
INFO  [05:10:22.247] [bbotk]                                 uhash 
INFO  [05:10:22.247] [bbotk]  c689612d-516b-484e-b834-8291b105bbf4 
DEBUG [05:10:23.334] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.17727e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.17727e-05 0.001481084 
  - best initial criterion value(s) :  512.4199 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -512.42  |proj g|=       5.6398
At iterate     1  f =      -534.85  |proj g|=        4.4264
At iterate     2  f =      -540.27  |proj g|=        3.9187
At iterate     3  f =      -550.26  |proj g|=        2.4849
At iterate     4  f =      -550.81  |proj g|=        2.3496
At iterate     5  f =      -551.76  |proj g|=        2.3279
At iterate     6  f =      -553.24  |proj g|=        2.3333
At iterate     7  f =      -553.48  |proj g|=          2.36
At iterate     8  f =      -553.54  |proj g|=        2.3813
At iterate     9  f =      -553.54  |proj g|=        2.3942
At iterate    10  f =      -553.54  |proj g|=        2.4026
At iterate    11  f =      -553.54  |proj g|=        2.4007
At iterate    12  f =      -553.54  |proj g|=        2.4006
At iterate    13  f =      -553.54  |proj g|=        2.4007
At iterate    14  f =      -553.54  |proj g|=        2.4007
At iterate    15  f =      -553.54  |proj g|=         2.412
At iterate    16  f =      -553.56  |proj g|=        2.4326
At iterate    17  f =      -553.63  |proj g|=        2.4614
At iterate    18  f =      -553.78  |proj g|=        2.5116
At iterate    19  f =      -553.91  |proj g|=        2.5217
At iterate    20  f =      -553.97  |proj g|=        2.4968
At iterate    21  f =      -553.97  |proj g|=        2.4853
At iterate    22  f =      -553.98  |proj g|=        2.4845
At iterate    23  f =      -553.98  |proj g|=        2.4855
At iterate    24  f =      -553.98  |proj g|=         2.486
At iterate    25  f =      -553.98  |proj g|=        2.4863
At iterate    26  f =      -553.98  |proj g|=        2.4864

iterations 26
function evaluations 33
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.48644
final function value -553.976

F = -553.976
final  value -553.975656 
converged
 
INFO  [05:10:23.338] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:10:23.428] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:10:23.436] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:10:25.114] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:10:26.523] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:10:27.943] [mlr3]  Finished benchmark 
INFO  [05:10:28.045] [bbotk] Result of batch 96: 
INFO  [05:10:28.047] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:10:28.047] [bbotk]              3.754493                 6.921304                       0.4521163 
INFO  [05:10:28.047] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:10:28.047] [bbotk]                      517        0.726 -0.9540482         <NA>   0.9650187 
INFO  [05:10:28.047] [bbotk]                                 uhash 
INFO  [05:10:28.047] [bbotk]  86349a5e-25f1-4e7b-9ec8-b8c314b2679b 
DEBUG [05:10:29.510] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.168929e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.168929e-05 0.001463402 
  - best initial criterion value(s) :  526.2362 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -526.24  |proj g|=       5.2922
At iterate     1  f =      -530.78  |proj g|=        5.5467
At iterate     2  f =      -535.64  |proj g|=         4.951
At iterate     3  f =      -536.94  |proj g|=        3.9501
At iterate     4  f =      -537.92  |proj g|=        4.0442
At iterate     5  f =      -538.76  |proj g|=        3.6627
At iterate     6  f =      -538.84  |proj g|=        3.8665
At iterate     7  f =      -538.84  |proj g|=        3.8846
At iterate     8  f =      -538.86  |proj g|=        3.8171
At iterate     9  f =      -538.86  |proj g|=        3.8228
At iterate    10  f =      -538.86  |proj g|=        3.8259
At iterate    11  f =      -538.86  |proj g|=        3.8339
At iterate    12  f =      -538.86  |proj g|=         3.845
At iterate    13  f =      -538.86  |proj g|=        3.8541
At iterate    14  f =      -538.87  |proj g|=        3.9159
At iterate    15  f =      -538.92  |proj g|=        3.8392
At iterate    16  f =      -539.08  |proj g|=        3.7413
At iterate    17  f =      -539.91  |proj g|=        3.3084
At iterate    18  f =      -541.55  |proj g|=        2.8055
At iterate    19  f =      -546.15  |proj g|=         2.533
At iterate    20  f =       -555.2  |proj g|=        2.4167
At iterate    21  f =      -556.69  |proj g|=         2.922
At iterate    22  f =      -557.45  |proj g|=        3.3194
At iterate    23  f =      -557.83  |proj g|=        3.4976
At iterate    24  f =      -558.12  |proj g|=        3.5986
At iterate    25  f =      -558.35  |proj g|=          3.57
At iterate    26  f =      -558.78  |proj g|=        3.2947
At iterate    27  f =      -559.17  |proj g|=        2.5292
At iterate    28  f =       -559.2  |proj g|=        2.6758
At iterate    29  f =      -559.21  |proj g|=        2.6568
At iterate    30  f =      -559.21  |proj g|=        2.6437
At iterate    31  f =      -559.21  |proj g|=        2.6431
At iterate    32  f =      -559.21  |proj g|=        2.6427
At iterate    33  f =      -559.21  |proj g|=        2.6422
At iterate    34  f =      -559.21  |proj g|=        2.6413
At iterate    35  f =      -559.21  |proj g|=        2.6383
At iterate    36  f =      -559.21  |proj g|=        2.6379
At iterate    37  f =      -559.21  |proj g|=        2.6372
At iterate    38  f =      -559.21  |proj g|=        2.6359
At iterate    39  f =      -559.21  |proj g|=        2.6335
At iterate    40  f =      -559.21  |proj g|=        2.6292
At iterate    41  f =      -559.21  |proj g|=         2.614
At iterate    42  f =      -559.23  |proj g|=         2.611
At iterate    43  f =      -559.25  |proj g|=        2.5456
At iterate    44  f =      -559.29  |proj g|=        2.6609
At iterate    45  f =      -559.41  |proj g|=        2.4773
At iterate    46  f =      -559.89  |proj g|=        1.7678
At iterate    47  f =      -560.62  |proj g|=        1.0923
At iterate    48  f =      -562.22  |proj g|=       0.68333
At iterate    49  f =         -563  |proj g|=       0.65412
At iterate    50  f =      -563.28  |proj g|=        0.3615
At iterate    51  f =      -563.29  |proj g|=       0.36478
At iterate    52  f =      -563.29  |proj g|=      0.093716
At iterate    53  f =      -563.29  |proj g|=        0.1189
At iterate    54  f =      -563.29  |proj g|=      0.055378
At iterate    55  f =      -563.29  |proj g|=     0.0064926
At iterate    56  f =      -563.29  |proj g|=       0.01058

iterations 56
function evaluations 63
segments explored during Cauchy searches 58
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0105798
final function value -563.289

F = -563.289
final  value -563.288721 
converged
 
INFO  [05:10:29.514] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:10:29.604] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:10:29.611] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:10:39.315] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:10:48.006] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:10:57.937] [mlr3]  Finished benchmark 
INFO  [05:10:58.041] [bbotk] Result of batch 97: 
INFO  [05:10:58.043] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:10:58.043] [bbotk]              9.528542                 6.859609                       0.2479522 
INFO  [05:10:58.043] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:10:58.043] [bbotk]                     4063        0.943 -0.9535007         <NA>   0.9760986 
INFO  [05:10:58.043] [bbotk]                                 uhash 
INFO  [05:10:58.043] [bbotk]  3bf34a6e-0dc4-4bb1-8e2f-fe5ddc21a411 
DEBUG [05:10:59.190] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.164167e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.164167e-05 0.001463489 
  - best initial criterion value(s) :  533.3152 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -533.32  |proj g|=       5.2414
At iterate     1  f =      -554.78  |proj g|=         2.545
At iterate     2  f =      -555.02  |proj g|=        2.5227
At iterate     3  f =      -555.54  |proj g|=        2.4425
At iterate     4  f =       -556.6  |proj g|=        2.4496
At iterate     5  f =      -559.84  |proj g|=         2.586
At iterate     6  f =      -561.44  |proj g|=        2.8155
At iterate     7  f =      -561.85  |proj g|=        2.9088
At iterate     8  f =      -561.95  |proj g|=        2.9785
At iterate     9  f =      -561.96  |proj g|=        3.0249
At iterate    10  f =      -561.96  |proj g|=        3.0154
At iterate    11  f =      -561.96  |proj g|=         3.015
At iterate    12  f =      -561.96  |proj g|=        3.0147
At iterate    13  f =      -561.96  |proj g|=        3.0141
At iterate    14  f =      -561.96  |proj g|=        3.0132
At iterate    15  f =      -561.96  |proj g|=        3.0115
At iterate    16  f =      -561.96  |proj g|=        3.0088
At iterate    17  f =      -561.96  |proj g|=        3.0042
At iterate    18  f =      -561.96  |proj g|=        2.9971
At iterate    19  f =      -561.97  |proj g|=        2.9889
At iterate    20  f =      -561.97  |proj g|=        2.9924
At iterate    21  f =      -561.97  |proj g|=         2.995
At iterate    22  f =      -561.97  |proj g|=        2.9958
At iterate    23  f =      -561.97  |proj g|=        2.9997
At iterate    24  f =      -561.97  |proj g|=        3.0038
At iterate    25  f =      -561.98  |proj g|=        3.0094
At iterate    26  f =         -562  |proj g|=        3.0129
At iterate    27  f =      -562.04  |proj g|=        3.0038
At iterate    28  f =      -562.11  |proj g|=        2.9596
At iterate    29  f =      -562.14  |proj g|=        2.8529
At iterate    30  f =      -562.16  |proj g|=        2.8846
At iterate    31  f =      -562.18  |proj g|=        2.9064
At iterate    32  f =      -562.27  |proj g|=        2.9542
At iterate    33  f =      -562.43  |proj g|=        2.9934
At iterate    34  f =       -562.6  |proj g|=        3.0223
At iterate    35  f =      -562.87  |proj g|=        2.9714
At iterate    36  f =      -563.02  |proj g|=        2.8829
At iterate    37  f =       -563.1  |proj g|=        2.7654
At iterate    38  f =       -563.1  |proj g|=        2.7655
At iterate    39  f =       -563.1  |proj g|=        2.7663
At iterate    40  f =       -563.1  |proj g|=        2.7664

iterations 40
function evaluations 45
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.76636
final function value -563.103

F = -563.103
final  value -563.102670 
converged
 
INFO  [05:10:59.195] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:10:59.296] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:10:59.303] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:11:06.030] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:11:12.919] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:11:18.762] [mlr3]  Finished benchmark 
INFO  [05:11:18.863] [bbotk] Result of batch 98: 
INFO  [05:11:18.865] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:11:18.865] [bbotk]              3.456439                 6.279765                       0.3099744 
INFO  [05:11:18.865] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:11:18.865] [bbotk]                     2704        0.727 -0.9544576         <NA>   0.9718301 
INFO  [05:11:18.865] [bbotk]                                 uhash 
INFO  [05:11:18.865] [bbotk]  2d742afa-a9b9-43ac-b60d-a139b9746048 
DEBUG [05:11:20.068] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.155872e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.155872e-05 0.001453449 
  - best initial criterion value(s) :  519.1601 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -519.16  |proj g|=       8.1794
At iterate     1  f =      -523.23  |proj g|=        8.3363
At iterate     2  f =      -523.93  |proj g|=        8.1926
At iterate     3  f =      -526.43  |proj g|=        7.2741
At iterate     4  f =       -528.6  |proj g|=        6.2106
At iterate     5  f =      -533.68  |proj g|=        4.7804
At iterate     6  f =      -534.03  |proj g|=         4.242
At iterate     7  f =      -535.44  |proj g|=        4.2268
At iterate     8  f =      -535.51  |proj g|=        4.0432
At iterate     9  f =      -535.54  |proj g|=        4.0882
At iterate    10  f =      -535.54  |proj g|=        4.0815
At iterate    11  f =      -535.54  |proj g|=         4.081
At iterate    12  f =      -535.54  |proj g|=        4.0805
At iterate    13  f =      -535.54  |proj g|=        4.0797
At iterate    14  f =      -535.54  |proj g|=        4.0784
At iterate    15  f =      -535.54  |proj g|=        4.0767
At iterate    16  f =      -535.54  |proj g|=        4.0745
At iterate    17  f =      -535.54  |proj g|=        4.0717
At iterate    18  f =      -535.54  |proj g|=        4.0689
At iterate    19  f =      -535.55  |proj g|=        4.0679
At iterate    20  f =      -535.57  |proj g|=         4.075
At iterate    21  f =      -535.63  |proj g|=        4.1067
At iterate    22  f =      -535.74  |proj g|=        4.1934
At iterate    23  f =      -535.81  |proj g|=        4.4537
At iterate    24  f =      -535.88  |proj g|=        4.3924
At iterate    25  f =      -535.88  |proj g|=         4.385
At iterate    26  f =      -535.89  |proj g|=         4.389
At iterate    27  f =       -535.9  |proj g|=        4.3976
At iterate    28  f =      -535.94  |proj g|=        4.4284
At iterate    29  f =      -536.01  |proj g|=        4.4806
At iterate    30  f =      -536.35  |proj g|=        4.3674
At iterate    31  f =      -537.07  |proj g|=        4.1989
At iterate    32  f =      -540.14  |proj g|=        3.4751
At iterate    33  f =      -544.76  |proj g|=        2.5967
At iterate    34  f =      -546.09  |proj g|=        1.7318
At iterate    35  f =      -551.87  |proj g|=        1.2304
At iterate    36  f =      -558.77  |proj g|=       0.94457
At iterate    37  f =       -560.8  |proj g|=        1.1961
At iterate    38  f =      -561.03  |proj g|=        1.3424
At iterate    39  f =      -561.06  |proj g|=        1.4087
At iterate    40  f =      -561.09  |proj g|=        1.6053
At iterate    41  f =      -561.09  |proj g|=         1.629
At iterate    42  f =      -561.09  |proj g|=        1.6315
At iterate    43  f =      -561.09  |proj g|=        1.6315

iterations 43
function evaluations 49
segments explored during Cauchy searches 45
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.63151
final function value -561.094

F = -561.094
final  value -561.093637 
converged
 
INFO  [05:11:20.072] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:11:20.173] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:11:20.180] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:11:26.895] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:11:34.706] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:11:41.990] [mlr3]  Finished benchmark 
INFO  [05:11:42.092] [bbotk] Result of batch 99: 
INFO  [05:11:42.093] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:11:42.093] [bbotk]              9.432335                 5.034082                       0.2343357 
INFO  [05:11:42.093] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:11:42.093] [bbotk]                     3450        0.742 -0.9589752         <NA>   0.9757155 
INFO  [05:11:42.093] [bbotk]                                 uhash 
INFO  [05:11:42.093] [bbotk]  994f8d9d-6e6d-4522-9def-82c9f092bd68 
DEBUG [05:11:43.270] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.150761e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.150761e-05 0.001452913 
  - best initial criterion value(s) :  554.3178 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -554.32  |proj g|=       1.2704
At iterate     1  f =      -558.16  |proj g|=        2.6653
At iterate     2  f =      -558.64  |proj g|=        2.3342
At iterate     3  f =      -558.82  |proj g|=        1.8666
At iterate     4  f =      -558.86  |proj g|=        1.9709
At iterate     5  f =      -558.93  |proj g|=        2.0933
At iterate     6  f =      -559.17  |proj g|=         2.398
At iterate     7  f =      -559.59  |proj g|=        2.7872
At iterate     8  f =      -560.15  |proj g|=        3.1643
At iterate     9  f =      -560.51  |proj g|=        3.3217
At iterate    10  f =      -560.65  |proj g|=        3.2166
At iterate    11  f =      -560.67  |proj g|=        3.1261
At iterate    12  f =      -560.67  |proj g|=        3.1141
At iterate    13  f =      -560.67  |proj g|=        3.1115
At iterate    14  f =      -560.67  |proj g|=        3.1103
At iterate    15  f =      -560.67  |proj g|=        3.1056
At iterate    16  f =      -560.67  |proj g|=        3.0984
At iterate    17  f =      -560.67  |proj g|=        3.0867
At iterate    18  f =      -560.67  |proj g|=        3.0684
At iterate    19  f =      -560.68  |proj g|=        3.0394
At iterate    20  f =      -560.69  |proj g|=         2.995
At iterate    21  f =      -560.73  |proj g|=        2.9283
At iterate    22  f =      -560.83  |proj g|=        2.8384
At iterate    23  f =      -561.11  |proj g|=        2.7516
At iterate    24  f =      -561.83  |proj g|=        2.8009
At iterate    25  f =      -563.26  |proj g|=        3.3426
At iterate    26  f =       -563.9  |proj g|=        4.3167
At iterate    27  f =      -563.96  |proj g|=        4.1576
At iterate    28  f =      -563.97  |proj g|=        4.0984
At iterate    29  f =      -563.97  |proj g|=        4.1034
At iterate    30  f =      -563.97  |proj g|=        4.1202
At iterate    31  f =      -563.97  |proj g|=        4.1451
At iterate    32  f =      -563.97  |proj g|=        4.1465
At iterate    33  f =      -563.97  |proj g|=        4.1448
At iterate    34  f =      -563.97  |proj g|=        4.1445

iterations 34
function evaluations 43
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 4.14448
final function value -563.969

F = -563.969
final  value -563.969309 
converged
 
INFO  [05:11:43.274] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:11:43.376] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:11:43.382] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:11:45.495] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:11:48.117] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:11:51.307] [mlr3]  Finished benchmark 
INFO  [05:11:51.409] [bbotk] Result of batch 100: 
INFO  [05:11:51.411] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:11:51.411] [bbotk]              2.162111                 3.841133                       0.4656311 
INFO  [05:11:51.411] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:11:51.411] [bbotk]                     1112        0.731 -0.9606294         <NA>   0.9556839 
INFO  [05:11:51.411] [bbotk]                                 uhash 
INFO  [05:11:51.411] [bbotk]  1cb71893-a280-4f62-8812-41ddf4e3f92f 
DEBUG [05:11:52.629] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.154834e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.154834e-05 0.00145578 
  - best initial criterion value(s) :  529.5816 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -529.58  |proj g|=       7.8102
At iterate     1  f =      -533.98  |proj g|=        8.4883
At iterate     2  f =      -537.78  |proj g|=        6.8649
At iterate     3  f =      -540.66  |proj g|=        5.1899
At iterate     4  f =         -547  |proj g|=        4.9225
At iterate     5  f =      -547.13  |proj g|=        4.9134
At iterate     6  f =      -547.13  |proj g|=        4.9162
At iterate     7  f =      -547.13  |proj g|=        4.9164
At iterate     8  f =      -547.13  |proj g|=        4.9165
At iterate     9  f =      -547.13  |proj g|=        4.9168
At iterate    10  f =      -547.13  |proj g|=        4.9173
At iterate    11  f =      -547.13  |proj g|=        4.9178
At iterate    12  f =      -547.13  |proj g|=        4.9182
At iterate    13  f =      -547.14  |proj g|=        4.9175
At iterate    14  f =      -547.14  |proj g|=        4.9124
At iterate    15  f =      -547.15  |proj g|=        4.8972
At iterate    16  f =      -547.16  |proj g|=        4.8657
At iterate    17  f =      -547.16  |proj g|=        4.8695
At iterate    18  f =      -547.16  |proj g|=        4.8818
At iterate    19  f =      -547.17  |proj g|=        4.8985
At iterate    20  f =       -547.2  |proj g|=        4.9263
At iterate    21  f =      -547.28  |proj g|=        4.9675
At iterate    22  f =      -547.46  |proj g|=        5.0206
At iterate    23  f =      -547.49  |proj g|=        5.0518
At iterate    24  f =      -547.91  |proj g|=         5.083
At iterate    25  f =      -549.94  |proj g|=        5.0251
At iterate    26  f =      -556.41  |proj g|=        4.5286
At iterate    27  f =      -564.96  |proj g|=        3.5023
At iterate    28  f =      -569.36  |proj g|=        2.7099
At iterate    29  f =      -570.16  |proj g|=        2.9613
At iterate    30  f =      -572.13  |proj g|=        2.3676
At iterate    31  f =      -573.44  |proj g|=        2.1193
At iterate    32  f =      -573.88  |proj g|=        2.3642
At iterate    33  f =      -574.59  |proj g|=        2.0882
At iterate    34  f =      -574.77  |proj g|=        1.9919
At iterate    35  f =      -574.82  |proj g|=        2.0604
At iterate    36  f =      -574.87  |proj g|=        1.9977
At iterate    37  f =      -574.87  |proj g|=        1.9833
At iterate    38  f =      -574.87  |proj g|=        1.9856
At iterate    39  f =      -574.87  |proj g|=        1.9833
At iterate    40  f =      -574.87  |proj g|=        1.9833

iterations 40
function evaluations 52
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.98329
final function value -574.873

F = -574.873
final  value -574.872901 
converged
 
INFO  [05:11:52.633] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:11:52.742] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:11:52.749] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:11:54.451] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:11:56.738] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:11:58.131] [mlr3]  Finished benchmark 
INFO  [05:11:58.233] [bbotk] Result of batch 101: 
INFO  [05:11:58.235] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:11:58.235] [bbotk]              3.262437                 2.224187                       0.1489529 
INFO  [05:11:58.235] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:11:58.235] [bbotk]                      576        0.754 -0.9524277         <NA>   0.9483832 
INFO  [05:11:58.235] [bbotk]                                 uhash 
INFO  [05:11:58.235] [bbotk]  7fe57965-f699-4c8c-b1a9-569b4b037edf 
DEBUG [05:11:59.347] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.176973e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.176973e-05 0.001495485 
  - best initial criterion value(s) :  562.066 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -562.07  |proj g|=       2.3894
At iterate     1  f =      -571.65  |proj g|=        1.9832
At iterate     2  f =      -578.37  |proj g|=        3.2967
At iterate     3  f =      -578.98  |proj g|=        3.4428
At iterate     4  f =      -579.38  |proj g|=        3.6448
At iterate     5  f =      -579.39  |proj g|=        3.7284
At iterate     6  f =      -579.42  |proj g|=        3.7812
At iterate     7  f =      -579.43  |proj g|=        3.7951
At iterate     8  f =       -579.5  |proj g|=        3.8477
At iterate     9  f =      -579.64  |proj g|=        3.8837
At iterate    10  f =      -580.01  |proj g|=        3.8847
At iterate    11  f =      -580.11  |proj g|=        3.6573
At iterate    12  f =      -580.95  |proj g|=        3.5713
At iterate    13  f =      -582.67  |proj g|=        3.1633
At iterate    14  f =      -587.97  |proj g|=        2.0084
At iterate    15  f =      -589.16  |proj g|=        1.9083
At iterate    16  f =      -592.52  |proj g|=        1.2028
At iterate    17  f =      -592.54  |proj g|=         1.082
At iterate    18  f =      -592.56  |proj g|=       0.95342
At iterate    19  f =      -592.57  |proj g|=         1.012
At iterate    20  f =      -592.57  |proj g|=        1.0083
At iterate    21  f =      -592.57  |proj g|=         1.008

iterations 21
function evaluations 30
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.00799
final function value -592.571

F = -592.571
final  value -592.571132 
converged
 
INFO  [05:11:59.351] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:11:59.485] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:11:59.492] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:12:04.485] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:12:10.945] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:12:16.275] [mlr3]  Finished benchmark 
INFO  [05:12:16.377] [bbotk] Result of batch 102: 
INFO  [05:12:16.379] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:12:16.379] [bbotk]              8.931446                 6.616932                      0.03442253 
INFO  [05:12:16.379] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:12:16.379] [bbotk]                     2107        0.757 -0.9529096         <NA>   0.9599954 
INFO  [05:12:16.379] [bbotk]                                 uhash 
INFO  [05:12:16.379] [bbotk]  0e84ab48-e00c-4de9-9e7a-77eeefea355f 
DEBUG [05:12:17.582] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.173423e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.173423e-05 0.001488609 
  - best initial criterion value(s) :  548.9467 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -548.95  |proj g|=       8.4825
At iterate     1  f =      -576.59  |proj g|=       0.91144
At iterate     2  f =      -580.74  |proj g|=       0.78721
At iterate     3  f =      -585.69  |proj g|=       0.99426
At iterate     4  f =      -586.36  |proj g|=        1.7075
At iterate     5  f =      -587.79  |proj g|=        1.4827
At iterate     6  f =      -589.59  |proj g|=        1.5268
At iterate     7  f =      -590.07  |proj g|=         1.242
At iterate     8  f =      -590.16  |proj g|=        1.2614
At iterate     9  f =      -590.17  |proj g|=        1.2525
At iterate    10  f =      -590.17  |proj g|=        1.2439
At iterate    11  f =      -590.17  |proj g|=        1.2468
At iterate    12  f =      -590.17  |proj g|=        1.2494
At iterate    13  f =      -590.17  |proj g|=        1.2477
At iterate    14  f =      -590.17  |proj g|=        1.2429
At iterate    15  f =      -590.17  |proj g|=        1.2476
At iterate    16  f =      -591.24  |proj g|=        1.0879
At iterate    17  f =      -591.61  |proj g|=        0.7023
At iterate    18  f =      -591.82  |proj g|=       0.68837
At iterate    19  f =      -591.89  |proj g|=       0.68817
At iterate    20  f =       -591.9  |proj g|=       0.69153
At iterate    21  f =      -591.91  |proj g|=       0.69108
At iterate    22  f =      -591.96  |proj g|=       0.68804
At iterate    23  f =      -592.29  |proj g|=       0.67077
At iterate    24  f =      -592.75  |proj g|=       0.64601
At iterate    25  f =      -593.24  |proj g|=       0.62122
At iterate    26  f =      -593.36  |proj g|=       0.62871
At iterate    27  f =      -593.38  |proj g|=       0.62504
At iterate    28  f =      -593.43  |proj g|=       0.55292
At iterate    29  f =      -593.43  |proj g|=       0.55266
At iterate    30  f =      -593.43  |proj g|=       0.55259
At iterate    31  f =      -593.43  |proj g|=       0.55259

iterations 31
function evaluations 44
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.552589
final function value -593.426

F = -593.426
final  value -593.426262 
converged
 
INFO  [05:12:17.586] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:12:17.676] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:12:17.684] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:12:29.768] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:12:39.696] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:12:49.890] [mlr3]  Finished benchmark 
INFO  [05:12:49.995] [bbotk] Result of batch 103: 
INFO  [05:12:49.997] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:12:49.997] [bbotk]              6.832449                 7.686994                       0.3760503 
INFO  [05:12:49.997] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:12:49.997] [bbotk]                     4603        0.755 -0.9506502         <NA>   0.9761686 
INFO  [05:12:49.997] [bbotk]                                 uhash 
INFO  [05:12:49.997] [bbotk]  dd93ef66-25c0-4da1-a247-4ddd4bc4f380 
DEBUG [05:12:51.249] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.169127e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.169127e-05 0.001489048 
  - best initial criterion value(s) :  560.321 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -560.32  |proj g|=       5.3796
At iterate     1  f =      -576.49  |proj g|=        4.5823
At iterate     2  f =      -585.12  |proj g|=        2.6851
At iterate     3  f =      -586.73  |proj g|=        1.4359
At iterate     4  f =      -586.88  |proj g|=        1.6451
At iterate     5  f =      -586.97  |proj g|=        1.5913
At iterate     6  f =      -586.98  |proj g|=        1.5812
At iterate     7  f =      -586.98  |proj g|=        1.5857
At iterate     8  f =      -586.98  |proj g|=        1.5913
At iterate     9  f =      -586.98  |proj g|=        1.5913

iterations 9
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.5913
final function value -586.982

F = -586.982
final  value -586.982262 
converged
 
INFO  [05:12:51.253] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:12:51.342] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:12:51.349] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:12:59.441] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:13:07.317] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:13:16.025] [mlr3]  Finished benchmark 
INFO  [05:13:16.128] [bbotk] Result of batch 104: 
INFO  [05:13:16.130] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:13:16.130] [bbotk]              5.771496                 2.679977                        0.422285 
INFO  [05:13:16.130] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:13:16.130] [bbotk]                     3573        0.955 -0.9572009         <NA>   0.9761541 
INFO  [05:13:16.130] [bbotk]                                 uhash 
INFO  [05:13:16.130] [bbotk]  3bb7bbae-55dd-4fc7-b9f8-1d113359a3b8 
DEBUG [05:13:17.141] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.164812e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.164812e-05 0.001488683 
  - best initial criterion value(s) :  583.2438 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -583.24  |proj g|=       2.0167
At iterate     1  f =      -584.54  |proj g|=        2.4675
At iterate     2  f =      -584.57  |proj g|=        2.4542
At iterate     3  f =      -584.71  |proj g|=        2.3814
At iterate     4  f =      -584.73  |proj g|=        2.4035
At iterate     5  f =      -584.74  |proj g|=        2.4234
At iterate     6  f =      -584.74  |proj g|=        2.4235

iterations 6
function evaluations 10
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.42354
final function value -584.737

F = -584.737
final  value -584.737054 
converged
 
INFO  [05:13:17.145] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:13:17.235] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:13:17.243] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:13:22.583] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:13:31.085] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:13:36.403] [mlr3]  Finished benchmark 
INFO  [05:13:36.506] [bbotk] Result of batch 105: 
INFO  [05:13:36.508] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:13:36.508] [bbotk]               8.71641                  8.86738                       0.1699925 
INFO  [05:13:36.508] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:13:36.508] [bbotk]                     2300        0.731 -0.958928         <NA>   0.9730442 
INFO  [05:13:36.508] [bbotk]                                 uhash 
INFO  [05:13:36.508] [bbotk]  3f8593e7-b3a6-4d33-a469-fef1e58420e0 
DEBUG [05:13:37.786] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.157705e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.157705e-05 0.001475942 
  - best initial criterion value(s) :  563.4825 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -563.48  |proj g|=       8.5919
At iterate     1  f =      -570.05  |proj g|=        8.8257
At iterate     2  f =      -573.57  |proj g|=         7.078
At iterate     3  f =      -577.17  |proj g|=        3.6289
At iterate     4  f =      -578.11  |proj g|=        3.8709
At iterate     5  f =      -578.17  |proj g|=        3.8949
At iterate     6  f =      -578.17  |proj g|=         3.899
At iterate     7  f =      -578.17  |proj g|=        3.9006
At iterate     8  f =      -578.17  |proj g|=        3.9012
At iterate     9  f =      -578.17  |proj g|=        3.9026
At iterate    10  f =      -578.17  |proj g|=        3.9046
At iterate    11  f =      -578.17  |proj g|=        3.9084
At iterate    12  f =      -578.18  |proj g|=        3.9142
At iterate    13  f =      -578.18  |proj g|=        3.9238
At iterate    14  f =       -578.2  |proj g|=        3.9393
At iterate    15  f =      -578.24  |proj g|=        3.9645
At iterate    16  f =      -578.36  |proj g|=        4.0036
At iterate    17  f =      -578.67  |proj g|=        4.0577
At iterate    18  f =      -579.39  |proj g|=        4.1072
At iterate    19  f =      -580.83  |proj g|=        4.0703
At iterate    20  f =      -581.71  |proj g|=        3.8837
At iterate    21  f =      -582.51  |proj g|=        3.7892
At iterate    22  f =       -582.7  |proj g|=        3.7527
At iterate    23  f =      -583.37  |proj g|=        3.6426
At iterate    24  f =      -584.35  |proj g|=        3.5206
At iterate    25  f =       -586.7  |proj g|=        3.2753
At iterate    26  f =       -588.3  |proj g|=        3.1842
At iterate    27  f =      -588.53  |proj g|=        3.1137
At iterate    28  f =      -588.58  |proj g|=        3.0399
At iterate    29  f =      -588.58  |proj g|=        3.0546
At iterate    30  f =      -588.58  |proj g|=        3.0516
At iterate    31  f =      -588.58  |proj g|=        3.0527
At iterate    32  f =      -588.58  |proj g|=        3.0546
At iterate    33  f =      -588.59  |proj g|=        3.0628
At iterate    34  f =       -588.6  |proj g|=        3.0729
At iterate    35  f =      -588.62  |proj g|=        3.0909
At iterate    36  f =      -588.67  |proj g|=        3.1184
At iterate    37  f =       -588.8  |proj g|=        3.1617
At iterate    38  f =      -589.14  |proj g|=        3.2277
At iterate    39  f =      -589.99  |proj g|=        3.3221
At iterate    40  f =      -591.96  |proj g|=        3.4269
At iterate    41  f =      -597.12  |proj g|=        3.3104
At iterate    42  f =       -600.2  |proj g|=        2.8695
At iterate    43  f =      -600.47  |proj g|=        2.7752
At iterate    44  f =      -600.52  |proj g|=        2.8051
At iterate    45  f =      -600.53  |proj g|=        2.7644
At iterate    46  f =      -600.53  |proj g|=        2.7677
At iterate    47  f =      -600.53  |proj g|=        2.7678

iterations 47
function evaluations 53
segments explored during Cauchy searches 49
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.76781
final function value -600.532

F = -600.532
final  value -600.532433 
converged
 
INFO  [05:13:37.790] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:13:37.894] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:13:37.901] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:13:44.371] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:13:51.257] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:13:57.742] [mlr3]  Finished benchmark 
INFO  [05:13:57.840] [bbotk] Result of batch 106: 
INFO  [05:13:57.842] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:13:57.842] [bbotk]              9.435192                 8.637517                       0.4622911 
INFO  [05:13:57.842] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:13:57.842] [bbotk]                     3116        0.765 -0.9495847         <NA>   0.9764472 
INFO  [05:13:57.842] [bbotk]                                 uhash 
INFO  [05:13:57.842] [bbotk]  8158b623-785e-41e4-bd93-6ad8c354d63d 
DEBUG [05:13:59.051] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.153769e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.153769e-05 0.001473923 
  - best initial criterion value(s) :  588.0522 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -588.05  |proj g|=       6.1339
At iterate     1  f =      -589.49  |proj g|=        6.9053
At iterate     2  f =      -591.77  |proj g|=        6.5947
At iterate     3  f =      -594.18  |proj g|=        5.3865
At iterate     4  f =      -595.48  |proj g|=        4.2815
At iterate     5  f =      -597.86  |proj g|=        2.1164
At iterate     6  f =      -597.87  |proj g|=        2.2532
At iterate     7  f =      -597.88  |proj g|=        2.1958
At iterate     8  f =      -597.88  |proj g|=        2.1949
At iterate     9  f =      -597.88  |proj g|=         2.194
At iterate    10  f =      -597.88  |proj g|=        2.1918
At iterate    11  f =      -597.88  |proj g|=        2.1871
At iterate    12  f =      -597.88  |proj g|=        2.1787
At iterate    13  f =      -597.88  |proj g|=        2.1624
At iterate    14  f =      -597.88  |proj g|=        2.1327
At iterate    15  f =      -597.88  |proj g|=         2.082
At iterate    16  f =      -597.89  |proj g|=        2.0088
At iterate    17  f =      -597.91  |proj g|=         2.009
At iterate    18  f =      -597.92  |proj g|=        2.0273
At iterate    19  f =      -597.92  |proj g|=        2.0333
At iterate    20  f =      -597.96  |proj g|=        2.0556
At iterate    21  f =      -598.03  |proj g|=        2.0842
At iterate    22  f =      -598.23  |proj g|=        2.1294
At iterate    23  f =      -598.68  |proj g|=        2.1831
At iterate    24  f =      -599.62  |proj g|=        2.2187
At iterate    25  f =      -600.84  |proj g|=        2.1994
At iterate    26  f =      -602.04  |proj g|=           2.2
At iterate    27  f =      -602.56  |proj g|=        2.0284
At iterate    28  f =      -603.32  |proj g|=        1.9809
At iterate    29  f =      -604.78  |proj g|=        1.8942
At iterate    30  f =      -604.99  |proj g|=        1.8761
At iterate    31  f =      -605.01  |proj g|=        1.8731
At iterate    32  f =      -605.01  |proj g|=        1.8721
At iterate    33  f =      -605.01  |proj g|=        1.8724

iterations 33
function evaluations 41
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.87239
final function value -605.007

F = -605.007
final  value -605.006883 
converged
 
INFO  [05:13:59.055] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:13:59.142] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:13:59.149] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:14:03.816] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:14:09.217] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:14:13.262] [mlr3]  Finished benchmark 
INFO  [05:14:13.360] [bbotk] Result of batch 107: 
INFO  [05:14:13.361] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:14:13.361] [bbotk]              9.019941                  6.41015                      0.02877636 
INFO  [05:14:13.361] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:14:13.361] [bbotk]                     2064        0.759 -0.9542911         <NA>   0.9580557 
INFO  [05:14:13.361] [bbotk]                                 uhash 
INFO  [05:14:13.361] [bbotk]  a72a783e-7c35-437c-8b9d-fb82414346cb 
DEBUG [05:14:14.530] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.153384e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.153384e-05 0.001472192 
  - best initial criterion value(s) :  601.5242 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -601.52  |proj g|=       2.3712
At iterate     1  f =      -605.31  |proj g|=        5.3037
At iterate     2  f =      -606.29  |proj g|=        4.9869
At iterate     3  f =      -607.65  |proj g|=        4.2945
At iterate     4  f =      -607.79  |proj g|=        3.8828
At iterate     5  f =      -607.92  |proj g|=        4.2919
At iterate     6  f =      -607.93  |proj g|=        4.2301
At iterate     7  f =      -607.93  |proj g|=        4.2189
At iterate     8  f =      -607.93  |proj g|=        4.2195
At iterate     9  f =      -607.93  |proj g|=        4.2199
At iterate    10  f =      -607.93  |proj g|=        4.2214
At iterate    11  f =      -607.93  |proj g|=        4.2232
At iterate    12  f =      -607.93  |proj g|=        4.2265
At iterate    13  f =      -607.93  |proj g|=        4.2311
At iterate    14  f =      -607.93  |proj g|=        4.2378
At iterate    15  f =      -607.93  |proj g|=        4.2462
At iterate    16  f =      -607.94  |proj g|=        4.2654
At iterate    17  f =      -607.95  |proj g|=        4.2669
At iterate    18  f =      -607.95  |proj g|=        4.3258
At iterate    19  f =      -607.97  |proj g|=        4.3063
At iterate    20  f =      -608.07  |proj g|=        4.2345
At iterate    21  f =       -608.3  |proj g|=        4.0748
At iterate    22  f =      -608.97  |proj g|=          3.66
At iterate    23  f =      -610.46  |proj g|=        2.8226
At iterate    24  f =      -611.89  |proj g|=        1.0033
At iterate    25  f =      -614.85  |proj g|=        1.0687
At iterate    26  f =      -619.34  |proj g|=        1.1457
At iterate    27  f =      -622.31  |proj g|=       0.56361
At iterate    28  f =      -622.32  |proj g|=       0.36678
At iterate    29  f =      -622.33  |proj g|=       0.42659
At iterate    30  f =      -622.33  |proj g|=       0.23922
At iterate    31  f =      -622.33  |proj g|=       0.23958
At iterate    32  f =      -622.33  |proj g|=       0.23954

iterations 32
function evaluations 36
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.239537
final function value -622.327

F = -622.327
final  value -622.327355 
converged
 
INFO  [05:14:14.535] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:14:14.623] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:14:14.630] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:14:19.515] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:14:23.628] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:14:27.157] [mlr3]  Finished benchmark 
INFO  [05:14:27.282] [bbotk] Result of batch 108: 
INFO  [05:14:27.284] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:14:27.284] [bbotk]              9.851433                 9.678906                       0.3607166 
INFO  [05:14:27.284] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:14:27.284] [bbotk]                     1942        0.753 -0.9497085         <NA>   0.9753276 
INFO  [05:14:27.284] [bbotk]                                 uhash 
INFO  [05:14:27.284] [bbotk]  8b842049-d61f-48c4-b841-6eeb3a13f4d7 
DEBUG [05:14:28.345] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.148369e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.148369e-05 0.001460655 
  - best initial criterion value(s) :  571.6575 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -571.66  |proj g|=        2.132
At iterate     1  f =      -581.52  |proj g|=        1.6771
At iterate     2  f =       -584.1  |proj g|=        2.2365
At iterate     3  f =      -584.34  |proj g|=        2.1444
At iterate     4  f =      -584.43  |proj g|=        2.0201
At iterate     5  f =      -584.44  |proj g|=        2.0399
At iterate     6  f =      -584.44  |proj g|=        2.0383
At iterate     7  f =      -584.44  |proj g|=        2.0383

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.0383
final function value -584.437

F = -584.437
final  value -584.436961 
converged
 
INFO  [05:14:28.349] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:14:28.437] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:14:28.444] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:14:29.844] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:14:31.115] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:14:32.322] [mlr3]  Finished benchmark 
INFO  [05:14:32.422] [bbotk] Result of batch 109: 
INFO  [05:14:32.424] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:14:32.424] [bbotk]              7.360133                 6.268618                        0.316067 
INFO  [05:14:32.424] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:14:32.424] [bbotk]                      418        0.773 -0.962973         <NA>   0.9657075 
INFO  [05:14:32.424] [bbotk]                                 uhash 
INFO  [05:14:32.424] [bbotk]  d55a3cf2-104d-4a92-9960-43a70c8f8ac0 
DEBUG [05:14:33.778] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.140689e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.140689e-05 0.001445056 
  - best initial criterion value(s) :  592.0603 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -592.06  |proj g|=      0.52296
At iterate     1  f =      -611.44  |proj g|=        5.4286
At iterate     2  f =      -612.94  |proj g|=        5.1528
At iterate     3  f =      -614.78  |proj g|=        4.4296
At iterate     4  f =      -615.24  |proj g|=        3.7285
At iterate     5  f =      -615.67  |proj g|=        3.7235
At iterate     6  f =      -616.74  |proj g|=        2.5573
At iterate     7  f =      -616.76  |proj g|=        2.8202
At iterate     8  f =      -616.96  |proj g|=        3.0815
At iterate     9  f =      -616.98  |proj g|=        3.0306
At iterate    10  f =      -616.98  |proj g|=        3.0225
At iterate    11  f =      -617.05  |proj g|=        3.0925
At iterate    12  f =      -617.73  |proj g|=        3.2691
At iterate    13  f =      -619.54  |proj g|=        3.0683
At iterate    14  f =      -623.16  |proj g|=        1.8585
At iterate    15  f =      -624.47  |proj g|=        1.5236
At iterate    16  f =      -625.41  |proj g|=        1.1176
At iterate    17  f =      -626.23  |proj g|=       0.52587
At iterate    18  f =       -626.3  |proj g|=       0.62565
At iterate    19  f =      -626.32  |proj g|=       0.36376
At iterate    20  f =      -626.32  |proj g|=       0.43588
At iterate    21  f =      -626.32  |proj g|=       0.43579
At iterate    22  f =      -626.32  |proj g|=       0.43008

iterations 22
function evaluations 31
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.430083
final function value -626.322

F = -626.322
final  value -626.322417 
converged
 
INFO  [05:14:33.782] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:14:33.870] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:14:33.877] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:14:38.056] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:14:42.391] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:14:46.820] [mlr3]  Finished benchmark 
INFO  [05:14:46.923] [bbotk] Result of batch 110: 
INFO  [05:14:46.925] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:14:46.925] [bbotk]              6.425343                 4.076202                       0.1325793 
INFO  [05:14:46.925] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:14:46.925] [bbotk]                     2165        0.954 -0.9547074         <NA>   0.9710442 
INFO  [05:14:46.925] [bbotk]                                 uhash 
INFO  [05:14:46.925] [bbotk]  49a8871d-cd1f-4dd6-af13-58f02d5dcc38 
DEBUG [05:14:47.974] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.132986e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.132986e-05 0.001432212 
  - best initial criterion value(s) :  571.683 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -571.68  |proj g|=       2.3161
At iterate     1  f =      -576.17  |proj g|=        2.7933
At iterate     2  f =      -578.84  |proj g|=        2.1778
At iterate     3  f =       -579.1  |proj g|=        2.1936
At iterate     4  f =      -579.16  |proj g|=        2.2088
At iterate     5  f =      -579.17  |proj g|=        2.2163
At iterate     6  f =      -579.17  |proj g|=          2.22
At iterate     7  f =      -579.17  |proj g|=        2.2221
At iterate     8  f =      -579.17  |proj g|=        2.2224

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.22237
final function value -579.167

F = -579.167
final  value -579.167106 
converged
 
INFO  [05:14:47.978] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:14:48.069] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:14:48.076] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:14:53.026] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:14:57.412] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:15:02.222] [mlr3]  Finished benchmark 
INFO  [05:15:02.323] [bbotk] Result of batch 111: 
INFO  [05:15:02.325] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:15:02.325] [bbotk]              4.497683                 4.603642                       0.2867375 
INFO  [05:15:02.325] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:15:02.325] [bbotk]                     2286        0.771 -0.9637998         <NA>   0.9732148 
INFO  [05:15:02.325] [bbotk]                                 uhash 
INFO  [05:15:02.325] [bbotk]  e6e0cf08-0be9-4f3c-bfb1-4f1526ec183f 
DEBUG [05:15:03.629] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.126478e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.126478e-05 0.001420552 
  - best initial criterion value(s) :  593.327 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -593.33  |proj g|=         6.45
At iterate     1  f =      -603.77  |proj g|=         5.632
At iterate     2  f =      -608.23  |proj g|=        5.4679
At iterate     3  f =      -612.78  |proj g|=        4.8333
At iterate     4  f =      -612.97  |proj g|=        4.6564
At iterate     5  f =      -612.97  |proj g|=        4.6343
At iterate     6  f =      -612.98  |proj g|=        4.6376
At iterate     7  f =      -612.98  |proj g|=        4.6709
At iterate     8  f =      -612.98  |proj g|=        4.6893
At iterate     9  f =      -612.98  |proj g|=        4.6924
At iterate    10  f =      -612.98  |proj g|=         4.693
At iterate    11  f =      -612.98  |proj g|=        4.6946
At iterate    12  f =      -612.98  |proj g|=         4.697
At iterate    13  f =      -612.98  |proj g|=        4.7012
At iterate    14  f =      -612.99  |proj g|=        4.7077
At iterate    15  f =      -612.99  |proj g|=        4.7178
At iterate    16  f =      -612.99  |proj g|=        4.7329
At iterate    17  f =      -613.01  |proj g|=        4.7532
At iterate    18  f =      -613.05  |proj g|=        4.7735
At iterate    19  f =      -613.14  |proj g|=        4.7708
At iterate    20  f =      -613.34  |proj g|=        4.6855
At iterate    21  f =      -613.67  |proj g|=        4.4147
At iterate    22  f =       -613.8  |proj g|=        4.2307
At iterate    23  f =       -613.8  |proj g|=        4.1841
At iterate    24  f =       -613.8  |proj g|=        4.1911
At iterate    25  f =       -613.8  |proj g|=        4.1934
At iterate    26  f =       -613.8  |proj g|=        4.2028
At iterate    27  f =       -613.8  |proj g|=        4.2135
At iterate    28  f =      -613.81  |proj g|=        4.2335
At iterate    29  f =      -613.82  |proj g|=        4.2641
At iterate    30  f =      -613.84  |proj g|=        4.3111
At iterate    31  f =      -613.88  |proj g|=        4.3696
At iterate    32  f =      -613.96  |proj g|=        4.4485
At iterate    33  f =      -614.11  |proj g|=         4.474
At iterate    34  f =      -614.33  |proj g|=        4.5838
At iterate    35  f =      -615.24  |proj g|=        4.6239
At iterate    36  f =      -615.56  |proj g|=        4.3135
At iterate    37  f =      -618.12  |proj g|=        4.1165
At iterate    38  f =      -620.18  |proj g|=        3.6194
At iterate    39  f =      -620.34  |proj g|=        3.3703
At iterate    40  f =      -620.54  |proj g|=        3.5318
At iterate    41  f =      -620.55  |proj g|=        3.5004
At iterate    42  f =      -620.55  |proj g|=        3.5022
At iterate    43  f =      -620.55  |proj g|=        3.5019

iterations 43
function evaluations 52
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.50187
final function value -620.548

F = -620.548
final  value -620.548357 
converged
 
INFO  [05:15:03.634] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:15:03.723] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:15:03.731] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:15:07.886] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:15:12.112] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:15:16.467] [mlr3]  Finished benchmark 
INFO  [05:15:16.572] [bbotk] Result of batch 112: 
INFO  [05:15:16.574] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:15:16.574] [bbotk]              5.766589                 3.152005                      0.02905326 
INFO  [05:15:16.574] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:15:16.574] [bbotk]                     1877        0.761 -0.9575753         <NA>   0.9538353 
INFO  [05:15:16.574] [bbotk]                                 uhash 
INFO  [05:15:16.574] [bbotk]  e5c4ab60-443c-407b-85fb-c10e26f15840 
DEBUG [05:15:17.835] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.133769e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.133769e-05 0.001424529 
  - best initial criterion value(s) :  604.0243 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -604.02  |proj g|=       5.6406
At iterate     1  f =      -606.07  |proj g|=        6.0044
At iterate     2  f =      -607.64  |proj g|=         5.571
At iterate     3  f =       -609.3  |proj g|=        4.4017
At iterate     4  f =       -609.4  |proj g|=        4.4017
At iterate     5  f =      -609.42  |proj g|=        4.3401
At iterate     6  f =      -609.43  |proj g|=         4.335
At iterate     7  f =      -609.43  |proj g|=        4.3353
At iterate     8  f =      -609.43  |proj g|=        4.3357
At iterate     9  f =      -609.43  |proj g|=        4.3363
At iterate    10  f =      -609.43  |proj g|=        4.3371
At iterate    11  f =      -609.43  |proj g|=        4.3384
At iterate    12  f =      -609.43  |proj g|=        4.3394
At iterate    13  f =      -609.43  |proj g|=        4.3382
At iterate    14  f =      -609.43  |proj g|=        4.3282
At iterate    15  f =      -609.43  |proj g|=        4.3072
At iterate    16  f =      -609.43  |proj g|=        4.3238
At iterate    17  f =      -609.44  |proj g|=         4.289
At iterate    18  f =      -609.48  |proj g|=        4.2054
At iterate    19  f =      -609.62  |proj g|=        4.0401
At iterate    20  f =      -610.08  |proj g|=        3.6913
At iterate    21  f =      -611.28  |proj g|=        3.1068
At iterate    22  f =      -611.92  |proj g|=        2.5373
At iterate    23  f =      -614.91  |proj g|=        1.9532
At iterate    24  f =      -621.83  |proj g|=         1.639
At iterate    25  f =      -627.09  |proj g|=        2.4596
At iterate    26  f =      -629.42  |proj g|=        1.1311
At iterate    27  f =      -629.46  |proj g|=        1.2289
At iterate    28  f =      -629.47  |proj g|=        1.1851
At iterate    29  f =      -629.47  |proj g|=        1.1915
At iterate    30  f =      -629.47  |proj g|=        1.1892
At iterate    31  f =      -629.47  |proj g|=        1.1891

iterations 31
function evaluations 38
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.18909
final function value -629.466

F = -629.466
final  value -629.466496 
converged
 
INFO  [05:15:17.840] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:15:17.938] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:15:17.945] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:15:25.453] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:15:31.193] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:15:37.586] [mlr3]  Finished benchmark 
INFO  [05:15:37.703] [bbotk] Result of batch 113: 
INFO  [05:15:37.704] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:15:37.704] [bbotk]              7.701533                 6.138409                       0.2554656 
INFO  [05:15:37.704] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:15:37.704] [bbotk]                     2929        0.789 -0.9591896         <NA>    0.975025 
INFO  [05:15:37.704] [bbotk]                                 uhash 
INFO  [05:15:37.704] [bbotk]  73abbfa4-33a4-4e4e-bf1d-d5feb7ce623c 
DEBUG [05:15:38.797] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.128809e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.128809e-05 0.001421183 
  - best initial criterion value(s) :  631.7857 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -631.79  |proj g|=       2.5463
At iterate     1  f =      -631.99  |proj g|=        1.5792
At iterate     2  f =      -634.65  |proj g|=        1.4239
At iterate     3  f =      -635.05  |proj g|=         1.094
At iterate     4  f =      -635.27  |proj g|=        1.2458
At iterate     5  f =      -635.29  |proj g|=         1.232
At iterate     6  f =      -635.39  |proj g|=        1.1952
At iterate     7  f =      -635.52  |proj g|=        1.1795
At iterate     8  f =      -635.72  |proj g|=        1.2132
At iterate     9  f =      -635.79  |proj g|=        1.2614
At iterate    10  f =       -635.8  |proj g|=         1.287
At iterate    11  f =       -635.8  |proj g|=        1.2927
At iterate    12  f =       -635.8  |proj g|=        1.2931
At iterate    13  f =       -635.8  |proj g|=         1.293

iterations 13
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.29305
final function value -635.801

F = -635.801
final  value -635.800609 
converged
 
INFO  [05:15:38.801] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:15:38.890] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:15:38.904] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:15:48.166] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:15:56.761] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:16:05.270] [mlr3]  Finished benchmark 
INFO  [05:16:05.372] [bbotk] Result of batch 114: 
INFO  [05:16:05.374] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:16:05.374] [bbotk]              2.486726                 2.317053                        0.377288 
INFO  [05:16:05.374] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:16:05.374] [bbotk]                     4178         0.77 -0.9576154         <NA>   0.9671345 
INFO  [05:16:05.374] [bbotk]                                 uhash 
INFO  [05:16:05.374] [bbotk]  b8882198-f0e1-4407-b04f-417853927c00 
DEBUG [05:16:06.495] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.121105e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.121105e-05 0.001412232 
  - best initial criterion value(s) :  609.8976 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -609.9  |proj g|=       1.4529
At iterate     1  f =      -615.88  |proj g|=        3.8815
At iterate     2  f =      -617.66  |proj g|=         3.619
At iterate     3  f =       -619.6  |proj g|=         3.181
At iterate     4  f =      -620.85  |proj g|=        2.5136
At iterate     5  f =      -622.73  |proj g|=        2.6811
At iterate     6  f =      -626.27  |proj g|=        2.6329
At iterate     7  f =      -626.31  |proj g|=        2.7419
At iterate     8  f =      -626.33  |proj g|=        2.7034
At iterate     9  f =      -626.33  |proj g|=        2.7032
At iterate    10  f =      -626.33  |proj g|=        2.7029

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.70291
final function value -626.326

F = -626.326
final  value -626.326285 
converged
 
INFO  [05:16:06.500] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:16:06.604] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:16:06.611] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:16:19.168] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:16:32.051] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:16:41.812] [mlr3]  Finished benchmark 
INFO  [05:16:41.915] [bbotk] Result of batch 115: 
INFO  [05:16:41.917] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:16:41.917] [bbotk]              9.503478                 4.947887                       0.2429409 
INFO  [05:16:41.917] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:16:41.917] [bbotk]                     4422        0.798 -0.9606646         <NA>   0.9761625 
INFO  [05:16:41.917] [bbotk]                                 uhash 
INFO  [05:16:41.917] [bbotk]  e4769590-2314-42ea-9558-36b967fc6cc1 
DEBUG [05:16:43.176] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.117371e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.117371e-05 0.001411817 
  - best initial criterion value(s) :  590.7669 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -590.77  |proj g|=       4.2196
At iterate     1  f =      -603.82  |proj g|=        7.4063
At iterate     2  f =       -612.5  |proj g|=        5.8762
At iterate     3  f =      -617.98  |proj g|=        5.0488
At iterate     4  f =      -626.85  |proj g|=        3.8604
At iterate     5  f =      -628.95  |proj g|=        4.0467
At iterate     6  f =      -629.63  |proj g|=        4.0278
At iterate     7  f =      -629.65  |proj g|=        3.9487
At iterate     8  f =      -629.66  |proj g|=         3.964
At iterate     9  f =      -629.66  |proj g|=         3.961
At iterate    10  f =      -629.66  |proj g|=        3.9609

iterations 10
function evaluations 16
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.96087
final function value -629.658

F = -629.658
final  value -629.657572 
converged
 
INFO  [05:16:43.180] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:16:43.289] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:16:43.296] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:16:50.836] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:17:02.374] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:17:10.510] [mlr3]  Finished benchmark 
INFO  [05:17:10.631] [bbotk] Result of batch 116: 
INFO  [05:17:10.633] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:17:10.633] [bbotk]               8.39462                 2.222158                       0.2477865 
INFO  [05:17:10.633] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:17:10.633] [bbotk]                     3375        0.766 -0.9611375         <NA>   0.9753663 
INFO  [05:17:10.633] [bbotk]                                 uhash 
INFO  [05:17:10.633] [bbotk]  da3c711c-b3cf-4a7c-b9a5-35be93531390 
DEBUG [05:17:11.848] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.112856e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.112856e-05 0.00141242 
  - best initial criterion value(s) :  590.4564 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -590.46  |proj g|=       7.0104
At iterate     1  f =      -599.22  |proj g|=        10.152
At iterate     2  f =      -613.61  |proj g|=        8.0148
At iterate     3  f =      -642.91  |proj g|=        2.8172
At iterate     4  f =       -651.9  |proj g|=        3.7607
At iterate     5  f =      -652.07  |proj g|=        4.0461
At iterate     6  f =      -652.14  |proj g|=        4.1649
At iterate     7  f =      -652.21  |proj g|=        4.0954
At iterate     8  f =      -652.21  |proj g|=        4.0947
At iterate     9  f =      -652.21  |proj g|=        4.0945
At iterate    10  f =      -652.21  |proj g|=        4.0943
At iterate    11  f =      -652.21  |proj g|=        4.1003
At iterate    12  f =      -652.21  |proj g|=        4.0905
At iterate    13  f =      -652.22  |proj g|=        4.1024
At iterate    14  f =      -652.23  |proj g|=        4.1192
At iterate    15  f =       -652.3  |proj g|=        4.1425
At iterate    16  f =      -652.44  |proj g|=        4.1394
At iterate    17  f =      -652.76  |proj g|=        4.0523
At iterate    18  f =      -653.31  |proj g|=        3.7354
At iterate    19  f =      -653.42  |proj g|=        3.7953
At iterate    20  f =      -653.99  |proj g|=        3.4045
At iterate    21  f =      -654.19  |proj g|=           3.2
At iterate    22  f =      -654.21  |proj g|=         3.233
At iterate    23  f =      -654.21  |proj g|=        3.2346
At iterate    24  f =      -654.21  |proj g|=         3.235
At iterate    25  f =      -654.21  |proj g|=        3.2349

iterations 25
function evaluations 34
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.23493
final function value -654.206

F = -654.206
final  value -654.205528 
converged
 
INFO  [05:17:11.852] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:17:11.941] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:17:11.947] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:17:18.267] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:17:24.696] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:17:30.428] [mlr3]  Finished benchmark 
INFO  [05:17:30.529] [bbotk] Result of batch 117: 
INFO  [05:17:30.531] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:17:30.531] [bbotk]              9.376717                 4.693777                       0.2865689 
INFO  [05:17:30.531] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:17:30.531] [bbotk]                     2720         0.78 -0.9556512         <NA>   0.9756572 
INFO  [05:17:30.531] [bbotk]                                 uhash 
INFO  [05:17:30.531] [bbotk]  462b20f1-0112-4367-9713-47345eeb2f12 
DEBUG [05:17:31.722] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.108631e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.108631e-05 0.001408474 
  - best initial criterion value(s) :  644.687 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -644.69  |proj g|=       7.0224
At iterate     1  f =      -657.42  |proj g|=       0.80214
At iterate     2  f =      -660.66  |proj g|=       0.90381
At iterate     3  f =      -663.07  |proj g|=        2.7109
At iterate     4  f =      -663.77  |proj g|=        2.2319
At iterate     5  f =      -665.03  |proj g|=         1.866
At iterate     6  f =      -668.43  |proj g|=        1.5014
At iterate     7  f =      -671.01  |proj g|=        1.6496
At iterate     8  f =      -671.21  |proj g|=        1.4986
At iterate     9  f =      -671.21  |proj g|=        1.5363
At iterate    10  f =      -671.21  |proj g|=        1.5443
At iterate    11  f =      -671.21  |proj g|=         1.542
At iterate    12  f =      -671.21  |proj g|=        1.5446
At iterate    13  f =      -671.21  |proj g|=         1.536
At iterate    14  f =      -671.28  |proj g|=        1.4832
At iterate    15  f =       -672.1  |proj g|=        1.0847
At iterate    16  f =      -673.26  |proj g|=       0.70741
At iterate    17  f =      -674.33  |proj g|=       0.63901
At iterate    18  f =      -674.81  |proj g|=       0.63837
At iterate    19  f =      -675.12  |proj g|=       0.68641
At iterate    20  f =      -675.13  |proj g|=       0.78564
At iterate    21  f =      -675.13  |proj g|=       0.77297
At iterate    22  f =      -675.13  |proj g|=        0.7738
At iterate    23  f =      -675.13  |proj g|=       0.77389

iterations 23
function evaluations 28
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.773888
final function value -675.13

F = -675.13
final  value -675.129802 
converged
 
INFO  [05:17:31.726] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:17:31.816] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:17:31.823] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:17:32.993] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:17:34.205] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:17:35.366] [mlr3]  Finished benchmark 
INFO  [05:17:35.499] [bbotk] Result of batch 118: 
INFO  [05:17:35.501] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:17:35.501] [bbotk]              2.232972                  9.00286                      0.05672051 
INFO  [05:17:35.501] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:17:35.501] [bbotk]                      406         0.78 -0.9478876         <NA>   0.8953956 
INFO  [05:17:35.501] [bbotk]                                 uhash 
INFO  [05:17:35.501] [bbotk]  88a96754-36b4-4884-a3ce-dc558c573d23 
DEBUG [05:17:36.606] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.461469e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.461469e-05 0.00197291 
  - best initial criterion value(s) :  630.8363 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -630.84  |proj g|=       2.6183
At iterate     1  f =      -639.56  |proj g|=        7.6541
At iterate     2  f =      -643.89  |proj g|=        7.5011
At iterate     3  f =      -653.25  |proj g|=        5.9305
At iterate     4  f =      -654.82  |proj g|=        3.7361
At iterate     5  f =      -656.62  |proj g|=        4.1902
At iterate     6  f =      -657.57  |proj g|=        3.1799
At iterate     7  f =      -657.63  |proj g|=        2.7201
At iterate     8  f =      -657.63  |proj g|=        2.8055
At iterate     9  f =      -657.63  |proj g|=        2.7997
At iterate    10  f =      -657.63  |proj g|=        2.7987

iterations 10
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.79869
final function value -657.63

F = -657.63
final  value -657.629622 
converged
 
INFO  [05:17:36.610] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:17:36.711] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:17:36.722] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:17:44.494] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:17:51.504] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:17:57.842] [mlr3]  Finished benchmark 
INFO  [05:17:57.943] [bbotk] Result of batch 119: 
INFO  [05:17:57.944] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:17:57.944] [bbotk]              4.875008                 8.951055                       0.2976488 
INFO  [05:17:57.944] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:17:57.944] [bbotk]                     3028        0.779 -0.9572091         <NA>    0.974601 
INFO  [05:17:57.944] [bbotk]                                 uhash 
INFO  [05:17:57.944] [bbotk]  7dc2c4ba-ed59-40d2-a2d2-7aaf3ceab2b3 
DEBUG [05:17:59.172] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.454412e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.454412e-05 0.001968608 
  - best initial criterion value(s) :  630.8504 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -630.85  |proj g|=       4.7102
At iterate     1  f =      -657.71  |proj g|=        1.4315
At iterate     2  f =       -669.9  |proj g|=        4.6465
At iterate     3  f =      -670.87  |proj g|=        4.4219
At iterate     4  f =      -671.52  |proj g|=        4.0601
At iterate     5  f =      -671.55  |proj g|=        4.0189
At iterate     6  f =      -671.56  |proj g|=        4.0275
At iterate     7  f =      -671.57  |proj g|=        4.1055
At iterate     8  f =      -671.57  |proj g|=        4.1171
At iterate     9  f =      -671.57  |proj g|=        4.1177
At iterate    10  f =      -671.57  |proj g|=        4.1184
At iterate    11  f =      -671.57  |proj g|=        4.1198
At iterate    12  f =      -671.57  |proj g|=        4.1218
At iterate    13  f =      -671.57  |proj g|=        4.1246
At iterate    14  f =      -671.57  |proj g|=        4.1281
At iterate    15  f =      -671.57  |proj g|=        4.1307
At iterate    16  f =      -671.57  |proj g|=        4.1302
At iterate    17  f =      -671.57  |proj g|=        4.1391
At iterate    18  f =      -671.57  |proj g|=        4.1364
At iterate    19  f =      -673.43  |proj g|=        3.3595
At iterate    20  f =      -679.03  |proj g|=        0.6575
At iterate    21  f =       -679.6  |proj g|=        0.3965
At iterate    22  f =      -679.61  |proj g|=        0.3571
At iterate    23  f =      -679.61  |proj g|=        0.3946
At iterate    24  f =      -679.61  |proj g|=       0.37717
At iterate    25  f =      -679.61  |proj g|=       0.37702

iterations 25
function evaluations 30
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.377023
final function value -679.609

F = -679.609
final  value -679.609213 
converged
 
INFO  [05:17:59.176] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:17:59.278] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:17:59.285] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:18:01.784] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:18:04.265] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:18:06.650] [mlr3]  Finished benchmark 
INFO  [05:18:06.762] [bbotk] Result of batch 120: 
INFO  [05:18:06.764] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:18:06.764] [bbotk]              6.130693                 8.780421                       0.3488155 
INFO  [05:18:06.764] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:18:06.764] [bbotk]                     1150          0.8 -0.9506462         <NA>   0.9725865 
INFO  [05:18:06.764] [bbotk]                                 uhash 
INFO  [05:18:06.764] [bbotk]  a3b51905-8f92-4908-aad2-33c9b7720f11 
DEBUG [05:18:08.137] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.445979e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.445979e-05 0.001944039 
  - best initial criterion value(s) :  652.1702 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -652.17  |proj g|=       4.6987
At iterate     1  f =      -659.82  |proj g|=        2.1722
At iterate     2  f =      -659.83  |proj g|=        2.1614
At iterate     3  f =      -659.83  |proj g|=        2.1498
At iterate     4  f =      -659.84  |proj g|=        2.1475
At iterate     5  f =      -659.85  |proj g|=         2.144
At iterate     6  f =      -659.87  |proj g|=        2.1529
At iterate     7  f =      -659.88  |proj g|=        2.1776
At iterate     8  f =      -659.88  |proj g|=        2.1856
At iterate     9  f =      -659.92  |proj g|=         2.202
At iterate    10  f =      -660.04  |proj g|=        2.2234
At iterate    11  f =      -660.46  |proj g|=        2.2504
At iterate    12  f =      -661.18  |proj g|=        2.2358
At iterate    13  f =      -661.47  |proj g|=        2.0972
At iterate    14  f =      -662.27  |proj g|=        2.0428
At iterate    15  f =      -662.91  |proj g|=        1.8887
At iterate    16  f =      -663.14  |proj g|=          1.86
At iterate    17  f =      -663.18  |proj g|=        1.8154
At iterate    18  f =      -663.19  |proj g|=        1.8136
At iterate    19  f =      -663.19  |proj g|=        1.8166
At iterate    20  f =      -663.19  |proj g|=        1.8163
At iterate    21  f =      -663.19  |proj g|=        1.8163

iterations 21
function evaluations 30
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.81625
final function value -663.187

F = -663.187
final  value -663.186721 
converged
 
INFO  [05:18:08.141] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:18:08.230] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:18:08.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:18:12.968] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:18:17.806] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:18:22.563] [mlr3]  Finished benchmark 
INFO  [05:18:22.685] [bbotk] Result of batch 121: 
INFO  [05:18:22.686] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:18:22.686] [bbotk]              4.801274                  2.25668                       0.2722411 
INFO  [05:18:22.686] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:18:22.686] [bbotk]                     1628        0.776 -0.9565311         <NA>   0.9718855 
INFO  [05:18:22.686] [bbotk]                                 uhash 
INFO  [05:18:22.686] [bbotk]  a04b4c18-fbe0-47c7-ace5-05df406b453c 
DEBUG [05:18:24.340] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.437273e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.437273e-05 0.001921186 
  - best initial criterion value(s) :  669.3913 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -669.39  |proj g|=       5.4074
At iterate     1  f =      -682.69  |proj g|=        2.0577
At iterate     2  f =      -685.05  |proj g|=        2.0792
At iterate     3  f =      -686.44  |proj g|=        2.0109
At iterate     4  f =      -686.73  |proj g|=        2.1209
At iterate     5  f =      -686.97  |proj g|=        2.1281
At iterate     6  f =      -688.06  |proj g|=        2.1867
At iterate     7  f =      -688.71  |proj g|=        2.2577
At iterate     8  f =      -688.76  |proj g|=        2.2405
At iterate     9  f =      -688.81  |proj g|=        2.2681
At iterate    10  f =      -688.81  |proj g|=        2.2789
At iterate    11  f =      -688.81  |proj g|=        2.2809
At iterate    12  f =      -688.81  |proj g|=        2.2811
At iterate    13  f =      -688.81  |proj g|=        2.2815
At iterate    14  f =      -688.81  |proj g|=         2.282
At iterate    15  f =      -688.81  |proj g|=        2.2829
At iterate    16  f =      -688.81  |proj g|=        2.2843
At iterate    17  f =      -688.81  |proj g|=        2.2864
At iterate    18  f =      -688.81  |proj g|=        2.2891
At iterate    19  f =      -688.81  |proj g|=        2.2914
At iterate    20  f =      -688.82  |proj g|=        2.2962
At iterate    21  f =      -688.82  |proj g|=        2.2952
At iterate    22  f =      -688.82  |proj g|=        2.3071
At iterate    23  f =      -688.84  |proj g|=        2.3032
At iterate    24  f =       -688.9  |proj g|=        2.2879
At iterate    25  f =      -689.09  |proj g|=        2.2407
At iterate    26  f =      -689.33  |proj g|=        2.1605
At iterate    27  f =      -689.38  |proj g|=        2.1183
At iterate    28  f =      -689.38  |proj g|=        2.1181
At iterate    29  f =      -689.38  |proj g|=        2.1206
At iterate    30  f =      -689.38  |proj g|=        2.1213
At iterate    31  f =      -689.38  |proj g|=        2.1215
At iterate    32  f =      -689.38  |proj g|=        2.1217
At iterate    33  f =      -689.38  |proj g|=        2.1219
At iterate    34  f =      -689.39  |proj g|=        2.1215
At iterate    35  f =      -689.39  |proj g|=        2.1205
At iterate    36  f =      -689.39  |proj g|=        2.1177
At iterate    37  f =      -689.39  |proj g|=        2.1103
At iterate    38  f =       -689.4  |proj g|=        2.0856
At iterate    39  f =      -689.41  |proj g|=        2.0656
At iterate    40  f =      -689.41  |proj g|=        2.0581
At iterate    41  f =      -689.41  |proj g|=        2.0593
At iterate    42  f =      -689.41  |proj g|=        2.0601
At iterate    43  f =      -689.41  |proj g|=        2.0603
At iterate    44  f =      -689.41  |proj g|=         2.061
At iterate    45  f =      -689.41  |proj g|=        2.0602
At iterate    46  f =      -689.41  |proj g|=        2.0602
At iterate    47  f =      -689.41  |proj g|=        2.0602
At iterate    48  f =      -689.41  |proj g|=        2.0604
At iterate    49  f =      -689.41  |proj g|=        2.0608
At iterate    50  f =      -689.41  |proj g|=        2.0615
At iterate    51  f =      -689.41  |proj g|=        2.0629
At iterate    52  f =      -689.41  |proj g|=        2.0655
At iterate    53  f =      -689.41  |proj g|=         2.066
At iterate    54  f =      -689.41  |proj g|=        2.0678
At iterate    55  f =      -689.41  |proj g|=        2.0757
At iterate    56  f =      -689.41  |proj g|=        2.0747
At iterate    57  f =      -689.42  |proj g|=        2.0705
At iterate    58  f =      -689.42  |proj g|=        2.0628
At iterate    59  f =      -689.43  |proj g|=        2.0457
At iterate    60  f =      -689.44  |proj g|=        2.0454
At iterate    61  f =      -689.47  |proj g|=        2.0087
At iterate    62  f =      -689.51  |proj g|=        2.0338
At iterate    63  f =      -689.61  |proj g|=        1.9353
At iterate    64  f =      -691.12  |proj g|=        1.0593
At iterate    65  f =      -692.98  |proj g|=       0.61973
At iterate    66  f =      -693.02  |proj g|=       0.58826
At iterate    67  f =      -693.51  |proj g|=       0.56644
At iterate    68  f =      -693.52  |proj g|=      0.084729
At iterate    69  f =      -693.52  |proj g|=        0.4894
At iterate    70  f =      -693.52  |proj g|=       0.56998
At iterate    71  f =      -693.52  |proj g|=       0.57026
At iterate    72  f =      -693.52  |proj g|=       0.56999
At iterate    73  f =      -693.52  |proj g|=       0.19346
At iterate    74  f =      -693.52  |proj g|=       0.14289
At iterate    75  f =      -693.52  |proj g|=      0.039246
At iterate    76  f =      -693.52  |proj g|=     0.0039221

iterations 76
function evaluations 89
segments explored during Cauchy searches 78
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00392206
final function value -693.521

F = -693.521
final  value -693.521138 
converged
 
INFO  [05:18:24.344] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:18:24.429] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:18:24.436] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:18:32.960] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:18:45.440] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:18:54.165] [mlr3]  Finished benchmark 
INFO  [05:18:54.303] [bbotk] Result of batch 122: 
INFO  [05:18:54.305] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:18:54.305] [bbotk]              4.671884                 6.402906                        0.343228 
INFO  [05:18:54.305] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:18:54.305] [bbotk]                     4074        0.835 -0.9479614         <NA>   0.9756283 
INFO  [05:18:54.305] [bbotk]                                 uhash 
INFO  [05:18:54.305] [bbotk]  fd785a57-faa0-49a2-b5b7-fd9b1e4efc7d 
DEBUG [05:18:55.566] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.431354e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.431354e-05 0.001919615 
  - best initial criterion value(s) :  656.6484 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -656.65  |proj g|=       3.7901
At iterate     1  f =      -659.56  |proj g|=        6.0981
At iterate     2  f =      -664.19  |proj g|=        5.9786
At iterate     3  f =      -668.73  |proj g|=        5.3849
At iterate     4  f =      -668.89  |proj g|=        5.0398
At iterate     5  f =      -669.18  |proj g|=        5.1312
At iterate     6  f =      -669.63  |proj g|=        5.0881
At iterate     7  f =      -670.03  |proj g|=        4.8777
At iterate     8  f =      -670.11  |proj g|=        4.7568
At iterate     9  f =      -670.11  |proj g|=          4.73
At iterate    10  f =      -670.11  |proj g|=        4.7341
At iterate    11  f =      -670.11  |proj g|=        4.7336
At iterate    12  f =      -670.11  |proj g|=        4.7319
At iterate    13  f =      -670.11  |proj g|=        4.7292
At iterate    14  f =      -670.11  |proj g|=        4.7246
At iterate    15  f =      -670.11  |proj g|=        4.7172
At iterate    16  f =      -670.12  |proj g|=        4.7049
At iterate    17  f =      -670.12  |proj g|=        4.6861
At iterate    18  f =      -670.13  |proj g|=        4.6558
At iterate    19  f =      -670.16  |proj g|=        4.6103
At iterate    20  f =      -670.17  |proj g|=        4.5851
At iterate    21  f =      -670.23  |proj g|=         4.524
At iterate    22  f =      -678.14  |proj g|=        5.2299
At iterate    23  f =      -678.23  |proj g|=        5.6776
At iterate    24  f =      -678.24  |proj g|=        5.7501
At iterate    25  f =      -678.24  |proj g|=        5.7385
At iterate    26  f =      -678.24  |proj g|=        5.7316
At iterate    27  f =      -678.24  |proj g|=        5.7319

iterations 27
function evaluations 33
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 5.73186
final function value -678.236

F = -678.236
final  value -678.236238 
converged
 
INFO  [05:18:55.568] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:18:55.645] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:18:55.653] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:18:56.497] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:18:57.687] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:18:58.525] [mlr3]  Finished benchmark 
INFO  [05:18:58.627] [bbotk] Result of batch 123: 
INFO  [05:18:58.629] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:18:58.629] [bbotk]              4.098199                 9.964278                        0.123558 
INFO  [05:18:58.629] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:18:58.629] [bbotk]                      246        0.822 -0.9561643         <NA>   0.9361893 
INFO  [05:18:58.629] [bbotk]                                 uhash 
INFO  [05:18:58.629] [bbotk]  9ec1258a-23ef-4a1f-8eb1-aa91cad57cbb 
DEBUG [05:19:00.629] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.489038e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.489038e-05 0.00201875 
  - best initial criterion value(s) :  649.7745 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -649.77  |proj g|=       4.5212
At iterate     1  f =      -676.59  |proj g|=        5.7618
At iterate     2  f =      -678.37  |proj g|=        5.6155
At iterate     3  f =      -682.78  |proj g|=        4.3997
At iterate     4  f =      -683.29  |proj g|=        3.7961
At iterate     5  f =      -683.54  |proj g|=        3.8703
At iterate     6  f =       -683.7  |proj g|=        4.1161
At iterate     7  f =      -683.71  |proj g|=        4.0698
At iterate     8  f =      -683.71  |proj g|=        4.0734
At iterate     9  f =      -683.71  |proj g|=        4.0734
At iterate    10  f =      -683.71  |proj g|=        4.0731
At iterate    11  f =      -683.71  |proj g|=        4.0714
At iterate    12  f =      -683.71  |proj g|=        4.0691
At iterate    13  f =      -683.71  |proj g|=         4.065
At iterate    14  f =      -683.71  |proj g|=        4.0588
At iterate    15  f =      -683.71  |proj g|=        4.0474
At iterate    16  f =      -683.71  |proj g|=        4.0276
At iterate    17  f =      -683.72  |proj g|=        3.9921
At iterate    18  f =      -683.74  |proj g|=        3.9363
At iterate    19  f =      -683.77  |proj g|=        3.8855
At iterate    20  f =      -683.79  |proj g|=         3.903
At iterate    21  f =      -683.79  |proj g|=        3.9179
At iterate    22  f =       -683.8  |proj g|=        3.9474
At iterate    23  f =      -683.83  |proj g|=        3.9889
At iterate    24  f =       -683.9  |proj g|=        4.0318
At iterate    25  f =      -684.05  |proj g|=         4.051
At iterate    26  f =      -684.35  |proj g|=        3.9743
At iterate    27  f =      -684.79  |proj g|=        4.0732
At iterate    28  f =      -684.86  |proj g|=        4.4937
At iterate    29  f =       -685.3  |proj g|=        4.5645
At iterate    30  f =      -685.41  |proj g|=        4.7019
At iterate    31  f =      -685.41  |proj g|=        4.7385
At iterate    32  f =      -685.41  |proj g|=        4.7177
At iterate    33  f =      -685.41  |proj g|=         4.721
At iterate    34  f =      -685.41  |proj g|=        4.7216
At iterate    35  f =      -685.41  |proj g|=        4.7224
At iterate    36  f =      -685.41  |proj g|=        4.7242
At iterate    37  f =      -685.41  |proj g|=        4.7266
At iterate    38  f =      -685.41  |proj g|=        4.7311
At iterate    39  f =      -685.41  |proj g|=        4.7235
At iterate    40  f =      -685.41  |proj g|=        4.7258
At iterate    41  f =      -685.41  |proj g|=         4.697
At iterate    42  f =      -685.41  |proj g|=        4.6826
At iterate    43  f =      -685.41  |proj g|=        4.6755
At iterate    44  f =      -685.42  |proj g|=        4.6487
At iterate    45  f =      -685.42  |proj g|=        4.5789
At iterate    46  f =      -685.43  |proj g|=        4.5964
At iterate    47  f =      -685.44  |proj g|=        4.5458
At iterate    48  f =      -685.57  |proj g|=         4.234
At iterate    49  f =      -685.79  |proj g|=        3.9342
At iterate    50  f =      -686.37  |proj g|=        3.5208
At iterate    51  f =      -687.33  |proj g|=        3.3467
At iterate    52  f =      -687.37  |proj g|=        3.2647
At iterate    53  f =      -688.73  |proj g|=        3.8063
At iterate    54  f =      -689.73  |proj g|=        5.3052
At iterate    55  f =      -689.75  |proj g|=        5.5639
At iterate    56  f =      -689.75  |proj g|=        5.5723
At iterate    57  f =      -689.75  |proj g|=        5.5872
At iterate    58  f =      -689.76  |proj g|=        5.5972
At iterate    59  f =      -689.76  |proj g|=        5.5991
At iterate    60  f =      -689.76  |proj g|=        5.5997
At iterate    61  f =      -689.76  |proj g|=        5.5833
At iterate    62  f =      -689.76  |proj g|=        5.5334
At iterate    63  f =      -689.76  |proj g|=        5.5005
At iterate    64  f =      -689.76  |proj g|=        5.4475
At iterate    65  f =      -689.77  |proj g|=        5.3707
At iterate    66  f =      -689.77  |proj g|=        5.1059
At iterate    67  f =      -689.79  |proj g|=        5.2241
At iterate    68  f =      -689.81  |proj g|=        5.3202
At iterate    69  f =      -689.84  |proj g|=        5.3822
At iterate    70  f =      -689.86  |proj g|=         5.404
At iterate    71  f =      -689.89  |proj g|=        5.6491
At iterate    72  f =       -689.9  |proj g|=         5.578
At iterate    73  f =      -689.95  |proj g|=        5.4682
At iterate    74  f =      -690.01  |proj g|=        5.3133
At iterate    75  f =      -690.14  |proj g|=        5.0938
At iterate    76  f =      -690.41  |proj g|=        4.7452
At iterate    77  f =      -691.11  |proj g|=         4.166
At iterate    78  f =      -692.83  |proj g|=        3.1875
At iterate    79  f =       -695.9  |proj g|=         2.033
At iterate    80  f =      -698.56  |proj g|=        1.2049
At iterate    81  f =      -701.73  |proj g|=        1.4887
At iterate    82  f =      -702.81  |proj g|=         1.701
At iterate    83  f =       -703.4  |proj g|=        1.8642
At iterate    84  f =      -703.58  |proj g|=        1.9145
At iterate    85  f =      -703.62  |proj g|=        1.9139
At iterate    86  f =      -703.62  |proj g|=        1.8974
At iterate    87  f =      -703.62  |proj g|=        1.8814
At iterate    88  f =      -703.62  |proj g|=        1.8883
At iterate    89  f =      -703.62  |proj g|=        1.8922
At iterate    90  f =      -703.62  |proj g|=        1.9018
At iterate    91  f =      -703.62  |proj g|=        1.9142
At iterate    92  f =      -703.62  |proj g|=        1.9336
At iterate    93  f =      -703.63  |proj g|=        1.9601
At iterate    94  f =      -703.64  |proj g|=        1.9963
At iterate    95  f =      -703.67  |proj g|=        2.0404
At iterate    96  f =      -703.76  |proj g|=        2.0794
At iterate    97  f =      -703.97  |proj g|=        2.0633
At iterate    98  f =      -704.46  |proj g|=        1.8732
At iterate    99  f =      -705.44  |proj g|=        1.3277
At iterate   100  f =      -705.68  |proj g|=       0.99025
At iterate   101  f =      -706.37  |proj g|=       0.51006
final  value -706.368795 
stopped after 101 iterations
 
INFO  [05:19:00.633] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:19:00.722] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:19:00.729] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:19:01.659] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:19:02.736] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:19:04.281] [mlr3]  Finished benchmark 
INFO  [05:19:04.383] [bbotk] Result of batch 124: 
INFO  [05:19:04.384] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:19:04.384] [bbotk]              5.050465                 3.116856                       0.4156218 
INFO  [05:19:04.384] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:19:04.384] [bbotk]                      285        0.793 -0.9444292         <NA>   0.9617629 
INFO  [05:19:04.384] [bbotk]                                 uhash 
INFO  [05:19:04.384] [bbotk]  7a356acc-b268-40ab-b679-dd935c13c733 
DEBUG [05:19:05.558] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.48197e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.48197e-05 0.002001957 
  - best initial criterion value(s) :  653.7538 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -653.75  |proj g|=       5.5722
At iterate     1  f =      -684.58  |proj g|=        4.0229
At iterate     2  f =      -689.37  |proj g|=        3.7362
At iterate     3  f =      -694.92  |proj g|=        3.0215
At iterate     4  f =      -695.62  |proj g|=        2.7537
At iterate     5  f =      -696.21  |proj g|=        2.8162
At iterate     6  f =      -696.55  |proj g|=        3.0411
At iterate     7  f =      -696.57  |proj g|=        2.9865
At iterate     8  f =      -696.57  |proj g|=        2.9932
At iterate     9  f =      -696.57  |proj g|=        2.9927
At iterate    10  f =      -696.57  |proj g|=        2.9926

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.99258
final function value -696.568

F = -696.568
final  value -696.567897 
converged
 
INFO  [05:19:05.563] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:19:05.677] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:19:05.685] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:19:07.503] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:19:10.881] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:19:13.613] [mlr3]  Finished benchmark 
INFO  [05:19:13.718] [bbotk] Result of batch 125: 
INFO  [05:19:13.720] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:19:13.720] [bbotk]              6.859384                 7.881502                       0.1107128 
INFO  [05:19:13.720] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:19:13.720] [bbotk]                      562        0.836 -0.9510535         <NA>   0.9572778 
INFO  [05:19:13.720] [bbotk]                                 uhash 
INFO  [05:19:13.720] [bbotk]  8ddbce2d-009b-4c0e-85fd-20d831f74363 
DEBUG [05:19:15.034] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.479876e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.479876e-05 0.001995711 
  - best initial criterion value(s) :  659.4751 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -659.48  |proj g|=       7.2898
At iterate     1  f =       -683.5  |proj g|=        8.5218
At iterate     2  f =      -688.61  |proj g|=        7.0769
At iterate     3  f =      -691.27  |proj g|=        5.0156
At iterate     4  f =      -693.34  |proj g|=        3.8244
At iterate     5  f =      -693.86  |proj g|=        3.3682
At iterate     6  f =       -693.9  |proj g|=         3.205
At iterate     7  f =       -693.9  |proj g|=        3.2336
At iterate     8  f =       -693.9  |proj g|=        3.2277
At iterate     9  f =       -693.9  |proj g|=        3.2194
At iterate    10  f =       -693.9  |proj g|=        3.2092
At iterate    11  f =       -693.9  |proj g|=        3.2057
At iterate    12  f =       -693.9  |proj g|=         3.201
At iterate    13  f =      -693.91  |proj g|=        3.1937
At iterate    14  f =      -693.93  |proj g|=        3.1858
At iterate    15  f =      -693.99  |proj g|=        3.1727
At iterate    16  f =      -694.13  |proj g|=         3.178
At iterate    17  f =      -694.15  |proj g|=        3.1307
At iterate    18  f =      -694.48  |proj g|=        3.1395
At iterate    19  f =      -699.17  |proj g|=        3.1478
At iterate    20  f =      -703.17  |proj g|=        3.0204
At iterate    21  f =      -704.08  |proj g|=        3.0012
At iterate    22  f =      -704.45  |proj g|=        3.0419
At iterate    23  f =      -704.59  |proj g|=        3.2078
At iterate    24  f =       -704.7  |proj g|=        3.2121
At iterate    25  f =      -704.71  |proj g|=        3.2281
At iterate    26  f =      -704.71  |proj g|=        3.2353
At iterate    27  f =      -704.71  |proj g|=        3.2366
At iterate    28  f =      -704.71  |proj g|=        3.2367

iterations 28
function evaluations 36
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.23671
final function value -704.713

F = -704.713
final  value -704.712595 
converged
 
INFO  [05:19:15.039] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:19:15.140] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:19:15.147] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:19:24.747] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:19:33.262] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:19:40.527] [mlr3]  Finished benchmark 
INFO  [05:19:40.643] [bbotk] Result of batch 126: 
INFO  [05:19:40.645] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:19:40.645] [bbotk]              7.338275                 8.309175                       0.1817605 
INFO  [05:19:40.645] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:19:40.645] [bbotk]                     3454        0.825 -0.9459121         <NA>    0.974471 
INFO  [05:19:40.645] [bbotk]                                 uhash 
INFO  [05:19:40.645] [bbotk]  1135aea8-4904-4802-8db7-91186986f9b5 
DEBUG [05:19:41.789] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.473055e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.473055e-05 0.001991838 
  - best initial criterion value(s) :  674.9541 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -674.95  |proj g|=       3.5995
At iterate     1  f =      -679.73  |proj g|=        2.4418
At iterate     2  f =      -683.91  |proj g|=        2.3965
At iterate     3  f =      -688.07  |proj g|=        2.1242
At iterate     4  f =      -688.77  |proj g|=         1.989
At iterate     5  f =      -689.04  |proj g|=        2.0219
At iterate     6  f =      -689.06  |proj g|=        2.0298
At iterate     7  f =      -689.06  |proj g|=        2.0324
At iterate     8  f =      -689.06  |proj g|=        2.0326
At iterate     9  f =      -689.06  |proj g|=        2.0327

iterations 9
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.03267
final function value -689.064

F = -689.064
final  value -689.063906 
converged
 
INFO  [05:19:41.793] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:19:41.879] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:19:41.886] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:19:47.660] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:19:53.613] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:19:59.204] [mlr3]  Finished benchmark 
INFO  [05:19:59.304] [bbotk] Result of batch 127: 
INFO  [05:19:59.306] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:19:59.306] [bbotk]               6.72764                 8.953738                       0.3416508 
INFO  [05:19:59.306] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:19:59.306] [bbotk]                     2833        0.817 -0.9562436         <NA>   0.9750605 
INFO  [05:19:59.306] [bbotk]                                 uhash 
INFO  [05:19:59.306] [bbotk]  f5aa2291-4647-4fdd-9999-1a32326788f7 
DEBUG [05:20:00.782] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.46679e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.46679e-05 0.001986325 
  - best initial criterion value(s) :  665.4006 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -665.4  |proj g|=       4.5984
At iterate     1  f =      -676.02  |proj g|=        2.9714
At iterate     2  f =      -676.14  |proj g|=        2.9293
At iterate     3  f =      -676.28  |proj g|=         2.841
At iterate     4  f =      -676.36  |proj g|=        2.8153
At iterate     5  f =      -677.04  |proj g|=        2.6254
At iterate     6  f =      -677.61  |proj g|=         2.595
At iterate     7  f =         -678  |proj g|=         2.666
At iterate     8  f =      -678.04  |proj g|=        2.6447
At iterate     9  f =      -678.04  |proj g|=        2.6429
At iterate    10  f =      -678.04  |proj g|=        2.6434
At iterate    11  f =      -678.04  |proj g|=        2.6446
At iterate    12  f =      -678.04  |proj g|=        2.6462
At iterate    13  f =      -678.04  |proj g|=        2.6489
At iterate    14  f =      -678.04  |proj g|=        2.6531
At iterate    15  f =      -678.04  |proj g|=        2.6595
At iterate    16  f =      -678.05  |proj g|=        2.6678
At iterate    17  f =      -678.06  |proj g|=        2.6776
At iterate    18  f =      -678.09  |proj g|=        2.6868
At iterate    19  f =      -678.16  |proj g|=        2.7025
At iterate    20  f =      -678.28  |proj g|=        2.6516
At iterate    21  f =      -678.47  |proj g|=         2.656
At iterate    22  f =      -678.97  |proj g|=        2.5819
At iterate    23  f =      -679.54  |proj g|=        2.3828
At iterate    24  f =      -679.61  |proj g|=        2.2822
At iterate    25  f =      -679.65  |proj g|=        2.3487
At iterate    26  f =      -679.66  |proj g|=        2.3391
At iterate    27  f =      -679.66  |proj g|=        2.3382
At iterate    28  f =      -679.66  |proj g|=        2.3382

iterations 28
function evaluations 31
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.33824
final function value -679.656

F = -679.656
final  value -679.656229 
converged
 
INFO  [05:20:00.786] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:20:00.878] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:20:00.885] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:20:07.262] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:20:17.426] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:20:23.824] [mlr3]  Finished benchmark 
INFO  [05:20:23.944] [bbotk] Result of batch 128: 
INFO  [05:20:23.946] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:20:23.946] [bbotk]              6.245604                 2.640288                       0.2760617 
INFO  [05:20:23.946] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:20:23.946] [bbotk]                     2699        1.008  -0.95955         <NA>   0.9747042 
INFO  [05:20:23.946] [bbotk]                                 uhash 
INFO  [05:20:23.946] [bbotk]  871e1f19-81af-4f2f-94ac-f2c8d50a0290 
DEBUG [05:20:25.194] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.46026e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.46026e-05 0.001980379 
  - best initial criterion value(s) :  692.3892 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -692.39  |proj g|=       7.5984
At iterate     1  f =      -703.59  |proj g|=        2.2699
At iterate     2  f =      -706.95  |proj g|=        2.3003
At iterate     3  f =      -708.75  |proj g|=        3.5745
At iterate     4  f =      -709.34  |proj g|=        2.8116
At iterate     5  f =      -710.22  |proj g|=         2.754
At iterate     6  f =      -711.91  |proj g|=        2.6222
At iterate     7  f =      -711.96  |proj g|=        2.4933
At iterate     8  f =      -711.96  |proj g|=        2.4932
At iterate     9  f =      -711.96  |proj g|=         2.495
At iterate    10  f =      -711.98  |proj g|=        2.4776
At iterate    11  f =      -711.98  |proj g|=        2.4867
At iterate    12  f =      -712.35  |proj g|=        2.5309
At iterate    13  f =       -715.5  |proj g|=        2.5297
At iterate    14  f =      -717.25  |proj g|=        2.5284
At iterate    15  f =      -717.83  |proj g|=        2.5275
At iterate    16  f =       -717.9  |proj g|=        2.5272
At iterate    17  f =       -717.9  |proj g|=        2.5272
At iterate    18  f =      -717.91  |proj g|=        2.5273
At iterate    19  f =      -717.91  |proj g|=        2.5273
At iterate    20  f =      -717.91  |proj g|=        2.5273

iterations 20
function evaluations 28
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.52728
final function value -717.905

F = -717.905
final  value -717.905269 
converged
 
INFO  [05:20:25.199] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:20:25.285] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:20:25.292] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:20:35.372] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:20:46.279] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:20:56.077] [mlr3]  Finished benchmark 
INFO  [05:20:56.302] [bbotk] Result of batch 129: 
INFO  [05:20:56.304] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:20:56.304] [bbotk]              8.147863                 5.484435                       0.3709716 
INFO  [05:20:56.304] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:20:56.304] [bbotk]                     4762        0.813 -0.9461096         <NA>   0.9763909 
INFO  [05:20:56.304] [bbotk]                                 uhash 
INFO  [05:20:56.304] [bbotk]  9eb067e6-279a-47a2-9895-bb72e8f47a50 
DEBUG [05:20:57.623] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.455342e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.455342e-05 0.001978239 
  - best initial criterion value(s) :  702.5004 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -702.5  |proj g|=       10.296
At iterate     1  f =      -711.27  |proj g|=       0.98215
At iterate     2  f =      -714.35  |proj g|=        3.0939
At iterate     3  f =      -718.53  |proj g|=        2.1118
At iterate     4  f =      -721.48  |proj g|=        1.4942
At iterate     5  f =      -722.89  |proj g|=         1.105
At iterate     6  f =      -725.33  |proj g|=          1.39
At iterate     7  f =      -726.19  |proj g|=         4.853
At iterate     8  f =      -727.55  |proj g|=         3.128
At iterate     9  f =      -727.57  |proj g|=        3.2651
At iterate    10  f =      -727.57  |proj g|=        3.2749
At iterate    11  f =      -727.57  |proj g|=        3.2774
At iterate    12  f =      -727.58  |proj g|=        3.2873
At iterate    13  f =      -727.63  |proj g|=        3.2987
At iterate    14  f =      -727.79  |proj g|=        3.2789
At iterate    15  f =       -728.2  |proj g|=        3.1513
At iterate    16  f =      -729.34  |proj g|=        2.6834
At iterate    17  f =      -731.72  |proj g|=        1.5032
At iterate    18  f =      -731.79  |proj g|=        1.4626
At iterate    19  f =       -734.5  |proj g|=        1.2049
At iterate    20  f =      -735.25  |proj g|=        1.0423
At iterate    21  f =      -735.49  |proj g|=        0.9345
At iterate    22  f =      -735.55  |proj g|=       0.88881
At iterate    23  f =      -735.55  |proj g|=       0.87516
At iterate    24  f =      -735.55  |proj g|=        0.8775
At iterate    25  f =      -735.55  |proj g|=       0.87526
At iterate    26  f =      -735.55  |proj g|=       0.87599
At iterate    27  f =      -735.55  |proj g|=       0.87588
At iterate    28  f =      -735.55  |proj g|=       0.87599

iterations 28
function evaluations 36
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.875992
final function value -735.555

F = -735.555
final  value -735.554526 
converged
 
INFO  [05:20:57.628] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:20:57.717] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:20:57.724] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:21:00.989] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:21:03.911] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:21:07.225] [mlr3]  Finished benchmark 
INFO  [05:21:07.327] [bbotk] Result of batch 130: 
INFO  [05:21:07.329] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:21:07.329] [bbotk]              9.437971                 3.559229                       0.1769388 
INFO  [05:21:07.329] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:21:07.329] [bbotk]                     1425         0.82 -0.9465231         <NA>    0.971378 
INFO  [05:21:07.329] [bbotk]                                 uhash 
INFO  [05:21:07.329] [bbotk]  dbd2917e-ed0a-419f-aef2-401360804808 
DEBUG [05:21:08.615] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.446882e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.446881e-05 0.001955771 
  - best initial criterion value(s) :  685.487 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -685.49  |proj g|=       6.2795
At iterate     1  f =      -696.82  |proj g|=        7.2856
At iterate     2  f =      -701.54  |proj g|=        7.2865
At iterate     3  f =      -707.75  |proj g|=        6.5879
At iterate     4  f =      -707.95  |proj g|=        6.3857
At iterate     5  f =      -708.12  |proj g|=        6.2594
At iterate     6  f =      -708.54  |proj g|=        5.8026
At iterate     7  f =      -708.55  |proj g|=        5.8433
At iterate     8  f =      -708.55  |proj g|=        5.8632
At iterate     9  f =      -708.56  |proj g|=        5.8761
At iterate    10  f =      -708.65  |proj g|=        5.9199
At iterate    11  f =      -709.38  |proj g|=        6.0163
At iterate    12  f =      -711.12  |proj g|=         5.922
At iterate    13  f =      -713.61  |proj g|=        5.0962
At iterate    14  f =      -714.74  |proj g|=        4.7652
At iterate    15  f =       -716.3  |proj g|=        4.5429
At iterate    16  f =      -717.08  |proj g|=         4.178
At iterate    17  f =      -717.48  |proj g|=        4.0695
At iterate    18  f =      -717.75  |proj g|=        3.8789
At iterate    19  f =      -717.77  |proj g|=        3.9584
At iterate    20  f =      -717.77  |proj g|=        3.9174
At iterate    21  f =      -717.78  |proj g|=        3.9365
At iterate    22  f =      -717.78  |proj g|=        3.9347
At iterate    23  f =      -717.78  |proj g|=        3.9343

iterations 23
function evaluations 30
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.93433
final function value -717.776

F = -717.776
final  value -717.776356 
converged
 
INFO  [05:21:08.619] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:21:08.711] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:21:08.718] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:21:15.201] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:21:21.051] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:21:27.866] [mlr3]  Finished benchmark 
INFO  [05:21:27.969] [bbotk] Result of batch 131: 
INFO  [05:21:27.971] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:21:27.971] [bbotk]              3.399326                  7.85167                       0.1200172 
INFO  [05:21:27.971] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:21:27.971] [bbotk]                     2670        0.826 -0.9537556         <NA>   0.9659224 
INFO  [05:21:27.971] [bbotk]                                 uhash 
INFO  [05:21:27.971] [bbotk]  cb38e2a5-ee03-4f4b-9e1e-7cca58eadd85 
DEBUG [05:21:29.785] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.438215e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.438215e-05 0.001945356 
  - best initial criterion value(s) :  702.4822 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -702.48  |proj g|=       4.1633
At iterate     1  f =      -714.76  |proj g|=        5.6947
At iterate     2  f =      -714.96  |proj g|=        5.6431
At iterate     3  f =      -715.08  |proj g|=        5.5475
At iterate     4  f =      -715.09  |proj g|=        5.5658
At iterate     5  f =       -715.1  |proj g|=        5.5826
At iterate     6  f =      -715.12  |proj g|=        5.6488
At iterate     7  f =      -715.15  |proj g|=        5.7303
At iterate     8  f =      -715.18  |proj g|=        5.7946
At iterate     9  f =      -715.18  |proj g|=        5.7998
At iterate    10  f =      -715.18  |proj g|=        5.7927
At iterate    11  f =      -715.18  |proj g|=        5.7904
At iterate    12  f =      -715.18  |proj g|=        5.7896
At iterate    13  f =      -715.18  |proj g|=        5.7839
At iterate    14  f =      -715.18  |proj g|=        5.7775
At iterate    15  f =      -715.18  |proj g|=        5.7652
At iterate    16  f =      -715.18  |proj g|=        5.7457
At iterate    17  f =      -715.19  |proj g|=        5.7121
At iterate    18  f =       -715.2  |proj g|=        5.6607
At iterate    19  f =      -715.24  |proj g|=         5.571
At iterate    20  f =      -715.25  |proj g|=        5.5345
At iterate    21  f =      -715.34  |proj g|=        5.4174
At iterate    22  f =      -716.08  |proj g|=        5.0818
At iterate    23  f =      -722.47  |proj g|=        4.7975
At iterate    24  f =      -722.62  |proj g|=         4.504
At iterate    25  f =      -722.65  |proj g|=        4.4431
At iterate    26  f =      -722.65  |proj g|=         4.452
At iterate    27  f =      -722.65  |proj g|=        4.4632
At iterate    28  f =      -722.65  |proj g|=        4.4645
At iterate    29  f =      -722.65  |proj g|=        4.4655
At iterate    30  f =      -722.65  |proj g|=        4.4686
At iterate    31  f =      -722.65  |proj g|=        4.4669
At iterate    32  f =      -722.65  |proj g|=        4.4687
At iterate    33  f =      -722.65  |proj g|=        4.4825
At iterate    34  f =      -722.67  |proj g|=        4.5365
At iterate    35  f =      -722.72  |proj g|=        4.6328
At iterate    36  f =      -722.85  |proj g|=        4.8207
At iterate    37  f =      -723.17  |proj g|=        5.1428
At iterate    38  f =      -723.54  |proj g|=        5.1955
At iterate    39  f =      -724.67  |proj g|=        6.2086
At iterate    40  f =      -726.38  |proj g|=         6.879
At iterate    41  f =      -728.86  |proj g|=        7.3508
At iterate    42  f =      -729.23  |proj g|=        7.9424
At iterate    43  f =      -729.31  |proj g|=        7.4741
At iterate    44  f =      -729.32  |proj g|=        7.5176
At iterate    45  f =      -729.33  |proj g|=        7.5038
At iterate    46  f =      -729.34  |proj g|=        7.5736
At iterate    47  f =      -729.39  |proj g|=        7.6637
At iterate    48  f =      -729.54  |proj g|=        7.8402
At iterate    49  f =      -729.56  |proj g|=         7.621
At iterate    50  f =      -734.76  |proj g|=         5.984
At iterate    51  f =      -738.93  |proj g|=       0.69863
At iterate    52  f =      -745.69  |proj g|=       0.58399
At iterate    53  f =       -745.7  |proj g|=       0.31149
At iterate    54  f =       -745.7  |proj g|=       0.39735
At iterate    55  f =       -745.7  |proj g|=       0.39505
At iterate    56  f =       -745.7  |proj g|=      0.090644
At iterate    57  f =       -745.7  |proj g|=      0.026354
At iterate    58  f =       -745.7  |proj g|=      0.040517

iterations 58
function evaluations 73
segments explored during Cauchy searches 60
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0405169
final function value -745.704

F = -745.704
final  value -745.704182 
converged
 
INFO  [05:21:29.789] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:21:29.878] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:21:29.886] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:21:33.789] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:21:38.054] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:21:42.673] [mlr3]  Finished benchmark 
INFO  [05:21:42.776] [bbotk] Result of batch 132: 
INFO  [05:21:42.778] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:21:42.778] [bbotk]              6.600389                 2.590169                       0.3918588 
INFO  [05:21:42.778] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:21:42.778] [bbotk]                     2040        0.982 -0.9478478         <NA>   0.9747822 
INFO  [05:21:42.778] [bbotk]                                 uhash 
INFO  [05:21:42.778] [bbotk]  3046cd87-402a-4060-9753-b8a6e36ea6ff 
DEBUG [05:21:43.977] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.432006e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.432006e-05 0.001934284 
  - best initial criterion value(s) :  705.5934 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -705.59  |proj g|=       4.5595
At iterate     1  f =      -710.01  |proj g|=        3.7404
At iterate     2  f =      -718.85  |proj g|=        3.3151
At iterate     3  f =      -726.13  |proj g|=        2.7271
At iterate     4  f =      -726.82  |proj g|=        2.5433
At iterate     5  f =      -727.48  |proj g|=        2.5969
At iterate     6  f =      -727.71  |proj g|=        2.7395
At iterate     7  f =      -727.73  |proj g|=        2.7042
At iterate     8  f =      -727.73  |proj g|=        2.7071
At iterate     9  f =      -727.73  |proj g|=        2.7069
At iterate    10  f =      -727.73  |proj g|=        2.7068

iterations 10
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.70684
final function value -727.726

F = -727.726
final  value -727.725630 
converged
 
INFO  [05:21:43.981] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:21:44.099] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:21:44.107] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:21:51.737] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:21:54.805] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:21:57.726] [mlr3]  Finished benchmark 
INFO  [05:21:57.823] [bbotk] Result of batch 133: 
INFO  [05:21:57.825] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:21:57.825] [bbotk]              3.010522                 5.572867                        0.284763 
INFO  [05:21:57.825] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:21:57.825] [bbotk]                     1413        0.854 -0.9537654         <NA>   0.9642909 
INFO  [05:21:57.825] [bbotk]                                 uhash 
INFO  [05:21:57.825] [bbotk]  b59066ba-419f-4a6a-bf52-c1bbff3ad44f 
DEBUG [05:21:59.011] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.424165e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.424165e-05 0.001916743 
  - best initial criterion value(s) :  702.0464 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -702.05  |proj g|=        10.51
At iterate     1  f =      -734.88  |proj g|=        5.0635
At iterate     2  f =      -737.62  |proj g|=        4.4103
At iterate     3  f =      -746.97  |proj g|=        2.1805
At iterate     4  f =      -748.68  |proj g|=       0.75739
At iterate     5  f =      -748.98  |proj g|=       0.77207
At iterate     6  f =      -749.03  |proj g|=       0.76825
At iterate     7  f =      -749.03  |proj g|=       0.76839
At iterate     8  f =      -749.03  |proj g|=       0.76839

iterations 8
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.768388
final function value -749.03

F = -749.03
final  value -749.029608 
converged
 
INFO  [05:21:59.015] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:21:59.104] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:21:59.111] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:22:08.665] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:22:18.727] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:22:25.546] [mlr3]  Finished benchmark 
INFO  [05:22:25.664] [bbotk] Result of batch 134: 
INFO  [05:22:25.666] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:22:25.666] [bbotk]              8.372325                 3.093544                     0.008304733 
INFO  [05:22:25.666] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:22:25.666] [bbotk]                     4123        0.829 -0.9510534         <NA>   0.9486379 
INFO  [05:22:25.666] [bbotk]                                 uhash 
INFO  [05:22:25.666] [bbotk]  c46da47c-445c-4321-986f-ea43783bfde4 
DEBUG [05:22:27.126] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.43868e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.43868e-05 0.00192076 
  - best initial criterion value(s) :  700.6958 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -700.7  |proj g|=       7.5718
At iterate     1  f =      -727.15  |proj g|=        8.5485
At iterate     2  f =      -730.87  |proj g|=        7.6428
At iterate     3  f =      -732.99  |proj g|=        5.4882
At iterate     4  f =      -734.96  |proj g|=        4.4359
At iterate     5  f =      -734.97  |proj g|=        4.2587
At iterate     6  f =      -735.07  |proj g|=         4.461
At iterate     7  f =      -735.42  |proj g|=        4.7258
At iterate     8  f =      -736.64  |proj g|=        5.0325
At iterate     9  f =       -739.2  |proj g|=        4.8812
At iterate    10  f =      -739.26  |proj g|=        4.5426
At iterate    11  f =      -743.38  |proj g|=        3.6961
At iterate    12  f =      -746.32  |proj g|=        2.4125
At iterate    13  f =      -748.27  |proj g|=        1.6776
At iterate    14  f =      -748.76  |proj g|=        1.7714
At iterate    15  f =      -748.97  |proj g|=        1.8669
At iterate    16  f =      -748.97  |proj g|=         1.832
At iterate    17  f =         -749  |proj g|=        1.8273
At iterate    18  f =         -749  |proj g|=         1.829
At iterate    19  f =         -749  |proj g|=        1.8255
At iterate    20  f =         -749  |proj g|=        1.8257
At iterate    21  f =      -749.03  |proj g|=        1.8157
At iterate    22  f =      -749.03  |proj g|=        1.8096
At iterate    23  f =      -749.38  |proj g|=         1.617
At iterate    24  f =      -749.39  |proj g|=        1.5927
At iterate    25  f =      -750.14  |proj g|=        1.0303
At iterate    26  f =      -751.28  |proj g|=       0.41782
At iterate    27  f =      -751.67  |proj g|=       0.40675
At iterate    28  f =      -752.24  |proj g|=       0.36349
At iterate    29  f =      -752.35  |proj g|=       0.63852
At iterate    30  f =      -752.38  |proj g|=       0.34973
At iterate    31  f =      -752.38  |proj g|=      0.088555
At iterate    32  f =      -752.38  |proj g|=      0.019948
At iterate    33  f =      -752.38  |proj g|=     0.0062891
At iterate    34  f =      -752.38  |proj g|=     0.0062891

iterations 34
function evaluations 50
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00628908
final function value -752.382

F = -752.382
final  value -752.382008 
converged
 
INFO  [05:22:27.131] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:22:27.253] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:22:27.261] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:22:33.809] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:22:40.249] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:22:46.715] [mlr3]  Finished benchmark 
INFO  [05:22:46.829] [bbotk] Result of batch 135: 
INFO  [05:22:46.832] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:22:46.832] [bbotk]               6.64686                 6.918543                        0.223186 
INFO  [05:22:46.832] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:22:46.832] [bbotk]                     4203        0.836 -0.9427991         <NA>   0.9749819 
INFO  [05:22:46.832] [bbotk]                                 uhash 
INFO  [05:22:46.832] [bbotk]  c9bc45b4-3284-4eb0-8eb5-077042ff7509 
DEBUG [05:22:48.603] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.432827e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.432827e-05 0.001917897 
  - best initial criterion value(s) :  673.4712 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -673.47  |proj g|=       8.4137
At iterate     1  f =      -698.38  |proj g|=        8.8372
At iterate     2  f =      -702.56  |proj g|=        9.1873
At iterate     3  f =      -712.85  |proj g|=        8.2875
At iterate     4  f =       -714.4  |proj g|=        7.1877
At iterate     5  f =      -714.69  |proj g|=        7.3167
At iterate     6  f =      -714.77  |proj g|=        7.0715
At iterate     7  f =      -714.79  |proj g|=        6.8933
At iterate     8  f =      -714.79  |proj g|=         6.895
At iterate     9  f =      -714.79  |proj g|=        6.8955
At iterate    10  f =      -714.79  |proj g|=        6.8957
At iterate    11  f =      -714.79  |proj g|=        6.8958
At iterate    12  f =       -714.8  |proj g|=        6.8964
At iterate    13  f =      -714.81  |proj g|=        6.8937
At iterate    14  f =      -714.83  |proj g|=        6.8765
At iterate    15  f =      -714.89  |proj g|=        6.8103
At iterate    16  f =      -715.02  |proj g|=        6.6274
At iterate    17  f =      -715.22  |proj g|=        6.2622
At iterate    18  f =      -715.23  |proj g|=        6.2289
At iterate    19  f =      -715.37  |proj g|=        5.9725
At iterate    20  f =      -727.44  |proj g|=        4.6103
At iterate    21  f =      -728.51  |proj g|=         4.316
At iterate    22  f =      -728.97  |proj g|=        4.2239
At iterate    23  f =      -729.03  |proj g|=         4.297
At iterate    24  f =      -729.03  |proj g|=        4.3299
At iterate    25  f =      -729.03  |proj g|=        4.3523
At iterate    26  f =      -729.03  |proj g|=        4.3544
At iterate    27  f =      -729.03  |proj g|=        4.3565
At iterate    28  f =      -729.03  |proj g|=        4.3694
At iterate    29  f =      -729.07  |proj g|=        4.4334
At iterate    30  f =       -729.1  |proj g|=        4.2915
At iterate    31  f =      -729.22  |proj g|=        4.4399
At iterate    32  f =      -729.58  |proj g|=         4.693
At iterate    33  f =      -730.49  |proj g|=        4.9425
At iterate    34  f =       -732.4  |proj g|=        4.9998
At iterate    35  f =      -735.75  |proj g|=        4.1856
At iterate    36  f =      -736.28  |proj g|=        4.4715
At iterate    37  f =      -741.25  |proj g|=        2.9224
At iterate    38  f =      -744.91  |proj g|=        1.8367
At iterate    39  f =      -749.98  |proj g|=        1.1286
At iterate    40  f =      -750.66  |proj g|=        1.0242
At iterate    41  f =      -756.04  |proj g|=       0.63348
At iterate    42  f =      -758.23  |proj g|=       0.37214
At iterate    43  f =      -758.59  |proj g|=        0.6388
At iterate    44  f =      -758.59  |proj g|=       0.35301
At iterate    45  f =       -758.6  |proj g|=       0.10403
At iterate    46  f =       -758.6  |proj g|=      0.017975
At iterate    47  f =       -758.6  |proj g|=      0.018041

iterations 47
function evaluations 64
segments explored during Cauchy searches 50
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0180409
final function value -758.597

F = -758.597
final  value -758.597121 
converged
 
INFO  [05:22:48.607] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:22:48.716] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:22:48.723] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:22:49.871] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:22:51.167] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:22:52.627] [mlr3]  Finished benchmark 
INFO  [05:22:52.732] [bbotk] Result of batch 136: 
INFO  [05:22:52.734] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:22:52.734] [bbotk]              2.004576                 4.890838                       0.1036614 
INFO  [05:22:52.734] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:22:52.734] [bbotk]                      661        1.005 -0.9426383         <NA>   0.9247298 
INFO  [05:22:52.734] [bbotk]                                 uhash 
INFO  [05:22:52.734] [bbotk]  1fa328c4-58ab-4eeb-a69d-2725426e3d2c 
DEBUG [05:22:54.067] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.536962e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.536962e-05 0.002080512 
  - best initial criterion value(s) :  652.8074 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -652.81  |proj g|=       6.5617
At iterate     1  f =      -671.44  |proj g|=        8.8434
At iterate     2  f =      -722.49  |proj g|=        2.3406
At iterate     3  f =      -722.88  |proj g|=        2.6493
At iterate     4  f =      -723.26  |proj g|=        3.2139
At iterate     5  f =      -723.31  |proj g|=        3.2565
At iterate     6  f =      -723.38  |proj g|=        3.2254
At iterate     7  f =      -723.39  |proj g|=        3.1879
At iterate     8  f =      -723.39  |proj g|=        3.1741
At iterate     9  f =      -723.39  |proj g|=        3.1692
At iterate    10  f =      -723.39  |proj g|=        3.1652
At iterate    11  f =      -723.39  |proj g|=        3.1424
At iterate    12  f =      -723.41  |proj g|=        3.1088
At iterate    13  f =      -723.45  |proj g|=        3.0474
At iterate    14  f =      -723.54  |proj g|=         3.019
At iterate    15  f =      -723.74  |proj g|=        2.6007
At iterate    16  f =      -724.12  |proj g|=        2.6374
At iterate    17  f =      -724.79  |proj g|=         2.516
At iterate    18  f =      -729.79  |proj g|=        1.9573
At iterate    19  f =       -733.7  |proj g|=        2.2643
At iterate    20  f =      -737.73  |proj g|=        1.1273
At iterate    21  f =      -737.99  |proj g|=        1.0043
At iterate    22  f =      -738.01  |proj g|=       0.73498
At iterate    23  f =      -738.02  |proj g|=       0.87168
At iterate    24  f =      -738.02  |proj g|=       0.85899
At iterate    25  f =      -738.02  |proj g|=       0.85776
At iterate    26  f =      -738.02  |proj g|=        0.8576

iterations 26
function evaluations 31
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.857596
final function value -738.023

F = -738.023
final  value -738.022923 
converged
 
INFO  [05:22:54.071] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:22:54.181] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:22:54.188] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:22:56.269] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:22:58.405] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:23:00.627] [mlr3]  Finished benchmark 
INFO  [05:23:00.729] [bbotk] Result of batch 137: 
INFO  [05:23:00.731] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:23:00.731] [bbotk]              4.371935                 8.214792                      0.02681829 
INFO  [05:23:00.731] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:23:00.731] [bbotk]                     1305        0.838 -0.9538447         <NA>   0.9410986 
INFO  [05:23:00.731] [bbotk]                                 uhash 
INFO  [05:23:00.731] [bbotk]  df51c55e-8d72-4797-9ff4-76d21ee6a3b0 
DEBUG [05:23:01.909] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.570407e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.570407e-05 0.002117727 
  - best initial criterion value(s) :  725.8759 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -725.88  |proj g|=       4.6975
At iterate     1  f =      -732.35  |proj g|=        2.4272
At iterate     2  f =       -734.9  |proj g|=        2.0775
At iterate     3  f =      -738.61  |proj g|=        1.0134
At iterate     4  f =       -739.3  |proj g|=        1.2707
At iterate     5  f =      -739.33  |proj g|=        1.3691
At iterate     6  f =      -739.34  |proj g|=        1.3824
At iterate     7  f =      -739.34  |proj g|=        1.3775
At iterate     8  f =      -739.34  |proj g|=        1.3775

iterations 8
function evaluations 13
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.37747
final function value -739.338

F = -739.338
final  value -739.338203 
converged
 
INFO  [05:23:01.914] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:23:02.014] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:23:02.023] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:23:04.078] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:23:06.194] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:23:08.223] [mlr3]  Finished benchmark 
INFO  [05:23:08.328] [bbotk] Result of batch 138: 
INFO  [05:23:08.330] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:23:08.330] [bbotk]              8.406068                 4.935471                       0.3620393 
INFO  [05:23:08.330] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:23:08.330] [bbotk]                     1223        0.833 -0.9529773         <NA>   0.9734753 
INFO  [05:23:08.330] [bbotk]                                 uhash 
INFO  [05:23:08.330] [bbotk]  90c15e85-0105-4447-accd-8c7a04bad51b 
DEBUG [05:23:09.666] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.563028e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.563028e-05 0.002095808 
  - best initial criterion value(s) :  698.7928 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -698.79  |proj g|=       4.7923
At iterate     1  f =      -701.65  |proj g|=        7.1898
At iterate     2  f =      -704.92  |proj g|=        6.7951
At iterate     3  f =      -708.67  |proj g|=        5.4726
At iterate     4  f =      -710.74  |proj g|=        3.8269
At iterate     5  f =      -715.14  |proj g|=        2.3114
At iterate     6  f =      -716.31  |proj g|=        1.9741
At iterate     7  f =      -716.99  |proj g|=        1.5362
At iterate     8  f =      -716.99  |proj g|=        1.5023
At iterate     9  f =      -716.99  |proj g|=        1.5057
At iterate    10  f =      -716.99  |proj g|=        1.5043
At iterate    11  f =      -716.99  |proj g|=        1.5044

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.50443
final function value -716.99

F = -716.99
final  value -716.990372 
converged
 
INFO  [05:23:09.671] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:23:09.785] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:23:09.793] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:23:15.988] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:23:22.186] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:23:28.805] [mlr3]  Finished benchmark 
INFO  [05:23:28.902] [bbotk] Result of batch 139: 
INFO  [05:23:28.904] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:23:28.904] [bbotk]              6.857297                 9.624859                       0.1525188 
INFO  [05:23:28.904] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:23:28.904] [bbotk]                     3967        0.937 -0.9601605         <NA>   0.9743258 
INFO  [05:23:28.904] [bbotk]                                 uhash 
INFO  [05:23:28.904] [bbotk]  53e0b47e-4cf2-421c-a83a-729502e2bf2a 
DEBUG [05:23:30.317] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.55633e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.55633e-05 0.002092264 
  - best initial criterion value(s) :  723.9026 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -723.9  |proj g|=       3.6401
At iterate     1  f =      -729.47  |proj g|=        7.6347
At iterate     2  f =      -733.26  |proj g|=        7.1824
At iterate     3  f =      -738.99  |proj g|=        5.8321
At iterate     4  f =      -740.31  |proj g|=        4.9904
At iterate     5  f =      -741.92  |proj g|=        4.3355
At iterate     6  f =      -743.28  |proj g|=        4.1501
At iterate     7  f =      -743.52  |proj g|=        4.7053
At iterate     8  f =      -743.58  |proj g|=        4.4897
At iterate     9  f =      -743.58  |proj g|=        4.4751
At iterate    10  f =      -743.58  |proj g|=        4.4752
At iterate    11  f =      -743.58  |proj g|=        4.4761

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.47615
final function value -743.583

F = -743.583
final  value -743.582739 
converged
 
INFO  [05:23:30.321] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:23:30.408] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:23:30.415] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:23:38.599] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:23:48.605] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:23:58.214] [mlr3]  Finished benchmark 
INFO  [05:23:58.313] [bbotk] Result of batch 140: 
INFO  [05:23:58.315] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:23:58.315] [bbotk]              6.864422                  8.26773                       0.2298306 
INFO  [05:23:58.315] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:23:58.315] [bbotk]                     4348        1.031 -0.9563513         <NA>    0.975179 
INFO  [05:23:58.315] [bbotk]                                 uhash 
INFO  [05:23:58.315] [bbotk]  886c4505-c2ff-45cd-9180-f501c48edd80 
DEBUG [05:23:59.683] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.550377e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.550377e-05 0.002089658 
  - best initial criterion value(s) :  697.0124 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -697.01  |proj g|=       10.747
At iterate     1  f =       -732.7  |proj g|=        3.6426
At iterate     2  f =      -755.69  |proj g|=        4.2105
At iterate     3  f =      -757.35  |proj g|=        3.0374
At iterate     4  f =      -757.43  |proj g|=        2.7716
At iterate     5  f =      -757.45  |proj g|=        2.7541
At iterate     6  f =      -757.47  |proj g|=        2.7912
At iterate     7  f =      -757.47  |proj g|=        2.8454
At iterate     8  f =      -757.48  |proj g|=        2.8672
At iterate     9  f =      -757.48  |proj g|=        2.8762
At iterate    10  f =      -757.48  |proj g|=        2.9102
At iterate    11  f =      -757.48  |proj g|=        2.9524
At iterate    12  f =       -757.5  |proj g|=        3.0298
At iterate    13  f =      -757.54  |proj g|=         3.148
At iterate    14  f =      -757.65  |proj g|=        3.3267
At iterate    15  f =      -757.87  |proj g|=        3.5204
At iterate    16  f =      -757.91  |proj g|=        3.7322
At iterate    17  f =      -758.39  |proj g|=        3.8727
At iterate    18  f =      -760.56  |proj g|=         3.648
At iterate    19  f =      -766.05  |proj g|=        4.9749
At iterate    20  f =      -775.26  |proj g|=        3.7484
At iterate    21  f =      -782.97  |proj g|=        2.9271
At iterate    22  f =      -783.25  |proj g|=        3.1765
At iterate    23  f =      -783.34  |proj g|=        3.0459
At iterate    24  f =      -783.36  |proj g|=        2.9998
At iterate    25  f =      -783.36  |proj g|=        2.9894
At iterate    26  f =      -783.36  |proj g|=        2.9902
At iterate    27  f =      -783.36  |proj g|=        2.9904

iterations 27
function evaluations 30
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.99043
final function value -783.359

F = -783.359
final  value -783.358823 
converged
 
INFO  [05:23:59.688] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:23:59.789] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:23:59.796] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:24:02.751] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:24:04.838] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:24:07.043] [mlr3]  Finished benchmark 
INFO  [05:24:07.283] [bbotk] Result of batch 141: 
INFO  [05:24:07.285] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:24:07.285] [bbotk]              3.816304                 5.272159                       0.1810504 
INFO  [05:24:07.285] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:24:07.285] [bbotk]                      885        0.855 -0.9401037         <NA>   0.9613025 
INFO  [05:24:07.285] [bbotk]                                 uhash 
INFO  [05:24:07.285] [bbotk]  cd89cc83-f616-4aae-9324-09e27d7a7b53 
DEBUG [05:24:08.787] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.543783e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.543783e-05 0.002075623 
  - best initial criterion value(s) :  722.2399 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -722.24  |proj g|=       5.1133
At iterate     1  f =      -740.21  |proj g|=        1.6023
At iterate     2  f =      -754.37  |proj g|=        5.7218
At iterate     3  f =      -755.06  |proj g|=        5.2402
At iterate     4  f =      -755.93  |proj g|=        4.9813
At iterate     5  f =      -757.23  |proj g|=         4.644
At iterate     6  f =      -757.98  |proj g|=        4.5903
At iterate     7  f =      -759.46  |proj g|=        5.1483
At iterate     8  f =      -759.51  |proj g|=        6.3081
At iterate     9  f =      -759.89  |proj g|=        5.7836
At iterate    10  f =       -759.9  |proj g|=        5.7519
At iterate    11  f =      -759.91  |proj g|=         5.775
At iterate    12  f =      -759.91  |proj g|=        5.7752
At iterate    13  f =      -759.91  |proj g|=        5.7755
At iterate    14  f =      -759.91  |proj g|=        5.7766
At iterate    15  f =      -759.91  |proj g|=        5.7755
At iterate    16  f =      -759.91  |proj g|=        5.7733
At iterate    17  f =      -759.92  |proj g|=        5.7772
At iterate    18  f =      -759.95  |proj g|=         5.754
At iterate    19  f =      -760.01  |proj g|=        5.7639
At iterate    20  f =      -760.17  |proj g|=         5.553
At iterate    21  f =      -760.56  |proj g|=          5.45
At iterate    22  f =      -763.97  |proj g|=        4.2304
At iterate    23  f =      -769.63  |proj g|=        3.2127
At iterate    24  f =      -784.04  |proj g|=        1.4881
At iterate    25  f =      -790.39  |proj g|=         2.413
At iterate    26  f =      -791.25  |proj g|=        2.6815
At iterate    27  f =      -791.51  |proj g|=        2.8117
At iterate    28  f =      -791.53  |proj g|=        2.8117
At iterate    29  f =      -791.53  |proj g|=        2.8117
At iterate    30  f =      -791.53  |proj g|=        2.8117
At iterate    31  f =      -791.53  |proj g|=        2.8117
At iterate    32  f =      -791.53  |proj g|=        2.8117
At iterate    33  f =      -791.53  |proj g|=        2.8117
At iterate    34  f =      -791.54  |proj g|=        2.8116
At iterate    35  f =      -791.54  |proj g|=        2.8116
At iterate    36  f =      -791.57  |proj g|=        2.8113
At iterate    37  f =      -791.62  |proj g|=        2.8108
At iterate    38  f =      -791.73  |proj g|=        2.8096
At iterate    39  f =      -791.91  |proj g|=        2.8077
At iterate    40  f =      -791.96  |proj g|=        2.7983
At iterate    41  f =      -791.96  |proj g|=        2.7833
At iterate    42  f =      -791.96  |proj g|=        2.7832
At iterate    43  f =      -791.96  |proj g|=        2.7834

iterations 43
function evaluations 47
segments explored during Cauchy searches 45
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.78337
final function value -791.961

F = -791.961
final  value -791.960800 
converged
 
INFO  [05:24:08.791] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:24:08.880] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:24:08.887] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:24:19.683] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:24:32.167] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:24:43.126] [mlr3]  Finished benchmark 
INFO  [05:24:43.227] [bbotk] Result of batch 142: 
INFO  [05:24:43.228] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:24:43.228] [bbotk]              7.065097                 3.200033                      0.09909087 
INFO  [05:24:43.228] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:24:43.228] [bbotk]                     4536        0.856 -0.9390827         <NA>   0.9732424 
INFO  [05:24:43.228] [bbotk]                                 uhash 
INFO  [05:24:43.228] [bbotk]  44fb8458-bb21-45ba-9361-0027d5dfc305 
DEBUG [05:24:45.352] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.536529e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.536529e-05 0.002067763 
  - best initial criterion value(s) :  700.4066 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -700.41  |proj g|=       7.0868
At iterate     1  f =      -724.73  |proj g|=        6.2806
At iterate     2  f =      -732.07  |proj g|=        6.2264
At iterate     3  f =      -739.88  |proj g|=        4.9079
At iterate     4  f =      -744.93  |proj g|=        6.0999
At iterate     5  f =      -746.34  |proj g|=        6.1333
At iterate     6  f =      -752.48  |proj g|=        6.6034
At iterate     7  f =      -756.79  |proj g|=        7.5228
At iterate     8  f =      -758.35  |proj g|=        8.1793
At iterate     9  f =      -758.85  |proj g|=        8.6415
At iterate    10  f =      -758.99  |proj g|=        8.9009
At iterate    11  f =         -759  |proj g|=        8.9911
At iterate    12  f =         -759  |proj g|=         9.006
At iterate    13  f =      -759.01  |proj g|=        9.0129
At iterate    14  f =      -759.01  |proj g|=        9.0279
At iterate    15  f =      -759.01  |proj g|=        9.0577
At iterate    16  f =      -759.02  |proj g|=        9.0811
At iterate    17  f =      -759.04  |proj g|=        9.1009
At iterate    18  f =      -759.09  |proj g|=        9.1307
At iterate    19  f =      -759.21  |proj g|=        9.1793
At iterate    20  f =      -759.36  |proj g|=        9.1849
At iterate    21  f =      -759.75  |proj g|=        9.2417
At iterate    22  f =      -760.97  |proj g|=        9.3023
At iterate    23  f =         -763  |proj g|=        8.9584
At iterate    24  f =      -765.82  |proj g|=        7.7759
At iterate    25  f =      -767.44  |proj g|=         6.866
At iterate    26  f =      -767.53  |proj g|=        6.5014
At iterate    27  f =      -767.57  |proj g|=         6.623
At iterate    28  f =      -767.57  |proj g|=        6.6615
At iterate    29  f =      -767.57  |proj g|=        6.6624
At iterate    30  f =      -767.57  |proj g|=        6.6602
At iterate    31  f =      -767.57  |proj g|=        6.6573
At iterate    32  f =      -767.58  |proj g|=        6.6567
At iterate    33  f =      -767.58  |proj g|=        6.6649
At iterate    34  f =      -767.58  |proj g|=        6.6908
At iterate    35  f =      -767.58  |proj g|=        6.7252
At iterate    36  f =      -767.58  |proj g|=        6.7433
At iterate    37  f =      -767.58  |proj g|=        6.7604
At iterate    38  f =      -767.58  |proj g|=        6.7633
At iterate    39  f =      -767.58  |proj g|=        6.7553
At iterate    40  f =      -767.58  |proj g|=        6.7447
At iterate    41  f =      -767.58  |proj g|=        6.7349
At iterate    42  f =      -767.59  |proj g|=        6.7162
At iterate    43  f =      -767.59  |proj g|=        6.6897
At iterate    44  f =       -767.6  |proj g|=        6.6497
At iterate    45  f =      -767.63  |proj g|=        6.5591
At iterate    46  f =      -767.68  |proj g|=        6.4993
At iterate    47  f =      -767.91  |proj g|=        6.3151
At iterate    48  f =      -768.36  |proj g|=        6.3015
At iterate    49  f =      -768.46  |proj g|=        6.1312
At iterate    50  f =      -769.44  |proj g|=        6.3622
At iterate    51  f =      -770.78  |proj g|=        6.8794
At iterate    52  f =      -771.07  |proj g|=        7.1213
At iterate    53  f =      -771.11  |proj g|=        7.2379
At iterate    54  f =      -771.11  |proj g|=        7.2548
At iterate    55  f =      -771.11  |proj g|=        7.2732
At iterate    56  f =      -771.11  |proj g|=        7.2626
At iterate    57  f =      -771.11  |proj g|=         7.268
At iterate    58  f =      -771.11  |proj g|=        7.2743
At iterate    59  f =      -771.59  |proj g|=        7.2019
At iterate    60  f =      -772.43  |proj g|=        6.8606
At iterate    61  f =      -772.47  |proj g|=        6.9775
At iterate    62  f =      -772.78  |proj g|=        6.8325
At iterate    63  f =       -772.8  |proj g|=        6.8033
At iterate    64  f =       -772.8  |proj g|=        6.8028
At iterate    65  f =       -772.8  |proj g|=        6.8038
At iterate    66  f =       -772.8  |proj g|=        6.8056
At iterate    67  f =       -772.8  |proj g|=        6.8044
At iterate    68  f =       -772.8  |proj g|=        6.8157
At iterate    69  f =      -772.81  |proj g|=        6.8125
At iterate    70  f =      -772.81  |proj g|=         6.803
At iterate    71  f =      -772.83  |proj g|=        6.7818
At iterate    72  f =      -773.04  |proj g|=        6.6705
At iterate    73  f =      -773.92  |proj g|=        6.2996
At iterate    74  f =      -774.04  |proj g|=         6.577
At iterate    75  f =      -776.04  |proj g|=        5.7676
At iterate    76  f =       -777.3  |proj g|=        5.2961
At iterate    77  f =      -781.84  |proj g|=        3.7822
At iterate    78  f =      -792.03  |proj g|=         1.984
At iterate    79  f =      -802.95  |proj g|=       0.45981
At iterate    80  f =      -803.21  |proj g|=       0.44341
At iterate    81  f =      -803.48  |proj g|=       0.56292
At iterate    82  f =      -803.55  |proj g|=       0.41194
At iterate    83  f =      -803.56  |proj g|=       0.14113
At iterate    84  f =      -803.56  |proj g|=      0.016545
At iterate    85  f =      -803.56  |proj g|=     0.0030044

iterations 85
function evaluations 99
segments explored during Cauchy searches 87
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00300444
final function value -803.559

F = -803.559
final  value -803.559137 
converged
 
INFO  [05:24:45.356] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:24:45.444] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:24:45.451] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:24:48.732] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:24:52.843] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:24:56.384] [mlr3]  Finished benchmark 
INFO  [05:24:56.506] [bbotk] Result of batch 143: 
INFO  [05:24:56.508] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:24:56.508] [bbotk]              7.314553                 5.341948                      0.09259792 
INFO  [05:24:56.508] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:24:56.508] [bbotk]                     1550        0.845 -0.9347327         <NA>   0.9663153 
INFO  [05:24:56.508] [bbotk]                                 uhash 
INFO  [05:24:56.508] [bbotk]  f600b550-64bc-429d-840a-d61f552f3956 
DEBUG [05:24:58.053] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.527777e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.527777e-05 0.002049671 
  - best initial criterion value(s) :  747.2849 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -747.28  |proj g|=       6.0723
At iterate     1  f =      -778.57  |proj g|=        2.6964
At iterate     2  f =      -782.69  |proj g|=        2.6275
At iterate     3  f =      -785.37  |proj g|=        1.3562
At iterate     4  f =      -786.62  |proj g|=        2.0633
At iterate     5  f =      -786.77  |proj g|=         1.947
At iterate     6  f =      -786.89  |proj g|=        1.8553
At iterate     7  f =      -787.21  |proj g|=        1.7262
At iterate     8  f =      -787.76  |proj g|=        1.6097
At iterate     9  f =      -788.11  |proj g|=        1.7773
At iterate    10  f =      -788.15  |proj g|=         1.717
At iterate    11  f =      -788.16  |proj g|=        1.7038
At iterate    12  f =      -788.16  |proj g|=        1.7141
At iterate    13  f =      -788.16  |proj g|=        1.7095
At iterate    14  f =      -788.16  |proj g|=        1.7072
At iterate    15  f =      -788.16  |proj g|=         1.701
At iterate    16  f =      -788.16  |proj g|=        1.6918
At iterate    17  f =      -788.16  |proj g|=        1.6763
At iterate    18  f =      -788.17  |proj g|=        1.6535
At iterate    19  f =      -788.19  |proj g|=        1.6198
At iterate    20  f =      -788.24  |proj g|=        1.5822
At iterate    21  f =      -788.31  |proj g|=        1.5579
At iterate    22  f =      -788.31  |proj g|=         1.524
At iterate    23  f =      -788.45  |proj g|=         1.511
At iterate    24  f =       -789.7  |proj g|=        1.4263
At iterate    25  f =       -789.9  |proj g|=        1.1046
At iterate    26  f =      -789.92  |proj g|=       0.97774
At iterate    27  f =      -789.92  |proj g|=       0.95322
At iterate    28  f =      -789.92  |proj g|=       0.95418
At iterate    29  f =      -789.92  |proj g|=       0.95105
At iterate    30  f =      -789.92  |proj g|=       0.95086
At iterate    31  f =      -789.92  |proj g|=       0.94876
At iterate    32  f =      -789.93  |proj g|=       0.94302
At iterate    33  f =      -789.93  |proj g|=       0.93124
At iterate    34  f =      -789.93  |proj g|=       0.93124
At iterate    35  f =      -789.93  |proj g|=       0.93124
At iterate    36  f =      -789.93  |proj g|=       0.93124
At iterate    37  f =      -789.93  |proj g|=       0.93124
At iterate    38  f =      -789.93  |proj g|=       0.93124

iterations 38
function evaluations 47
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.931237
final function value -789.93

F = -789.93
final  value -789.930016 
converged
 
INFO  [05:24:58.057] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:24:58.144] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:24:58.151] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:25:06.299] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:25:14.358] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:25:23.050] [mlr3]  Finished benchmark 
INFO  [05:25:23.156] [bbotk] Result of batch 144: 
INFO  [05:25:23.158] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:25:23.158] [bbotk]              2.356394                 4.316954                       0.1068807 
INFO  [05:25:23.158] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:25:23.158] [bbotk]                     3737        0.876 -0.9437654         <NA>    0.955675 
INFO  [05:25:23.158] [bbotk]                                 uhash 
INFO  [05:25:23.158] [bbotk]  c0ff096e-f8ab-4a0f-b6c1-dee645eb220c 
DEBUG [05:25:24.648] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.527408e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.527408e-05 0.002041739 
  - best initial criterion value(s) :  734.0029 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -734  |proj g|=       9.6314
At iterate     1  f =       -756.5  |proj g|=        1.6476
At iterate     2  f =       -757.2  |proj g|=        2.0247
At iterate     3  f =      -757.89  |proj g|=        3.1584
At iterate     4  f =      -758.01  |proj g|=        2.9177
At iterate     5  f =      -758.21  |proj g|=        2.7325
At iterate     6  f =      -759.01  |proj g|=        2.3563
At iterate     7  f =      -760.32  |proj g|=        2.1612
At iterate     8  f =      -761.71  |proj g|=        2.4398
At iterate     9  f =      -761.88  |proj g|=         2.582
At iterate    10  f =      -761.88  |proj g|=        2.6145
At iterate    11  f =      -761.89  |proj g|=        2.6266
At iterate    12  f =      -761.89  |proj g|=         2.634
At iterate    13  f =      -761.89  |proj g|=        2.6394
At iterate    14  f =      -761.89  |proj g|=         2.654
At iterate    15  f =      -761.89  |proj g|=        2.6737
At iterate    16  f =       -761.9  |proj g|=        2.7078
At iterate    17  f =      -761.91  |proj g|=        2.7597
At iterate    18  f =      -761.96  |proj g|=         2.837
At iterate    19  f =      -762.06  |proj g|=        2.9271
At iterate    20  f =      -762.27  |proj g|=        2.9503
At iterate    21  f =      -762.56  |proj g|=        2.7288
At iterate    22  f =      -762.76  |proj g|=        2.4492
At iterate    23  f =      -762.95  |proj g|=        2.1559
At iterate    24  f =      -763.26  |proj g|=        1.8252
At iterate    25  f =      -764.17  |proj g|=        1.1405
At iterate    26  f =      -765.89  |proj g|=       0.79079
At iterate    27  f =      -768.45  |proj g|=       0.77185
At iterate    28  f =      -768.75  |proj g|=       0.81047
At iterate    29  f =      -770.92  |proj g|=       0.96985
At iterate    30  f =      -772.17  |proj g|=       0.71261
At iterate    31  f =      -772.26  |proj g|=       0.71474
At iterate    32  f =      -772.29  |proj g|=       0.71055
At iterate    33  f =      -772.29  |proj g|=       0.33104
At iterate    34  f =      -772.29  |proj g|=       0.13752
At iterate    35  f =      -772.29  |proj g|=       0.13752

iterations 35
function evaluations 40
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.13752
final function value -772.293

F = -772.293
final  value -772.292513 
converged
 
INFO  [05:25:24.653] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:25:24.740] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:25:24.747] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:25:27.692] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:25:32.025] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:25:34.229] [mlr3]  Finished benchmark 
INFO  [05:25:34.332] [bbotk] Result of batch 145: 
INFO  [05:25:34.334] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:25:34.334] [bbotk]              9.159112                 7.105257                       0.4195016 
INFO  [05:25:34.334] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:25:34.334] [bbotk]                     1140        0.868 -0.9534616         <NA>   0.9740974 
INFO  [05:25:34.334] [bbotk]                                 uhash 
INFO  [05:25:34.334] [bbotk]  d7a69611-0b32-4972-9f81-2764768a6fe2 
DEBUG [05:25:35.845] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.520977e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.520977e-05 0.00201992 
  - best initial criterion value(s) :  721.3274 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -721.33  |proj g|=       9.0942
At iterate     1  f =      -743.36  |proj g|=        5.1257
At iterate     2  f =      -778.92  |proj g|=        5.2174
At iterate     3  f =      -781.61  |proj g|=        4.1894
At iterate     4  f =      -782.02  |proj g|=        3.7485
At iterate     5  f =      -782.07  |proj g|=        3.5546
At iterate     6  f =      -782.08  |proj g|=        3.5196
At iterate     7  f =      -782.18  |proj g|=        3.3555
At iterate     8  f =      -782.43  |proj g|=        3.0987
At iterate     9  f =       -783.1  |proj g|=        2.6479
At iterate    10  f =      -784.77  |proj g|=        1.9112
At iterate    11  f =      -788.92  |proj g|=       0.94291
At iterate    12  f =      -797.93  |proj g|=       0.74536
At iterate    13  f =      -802.03  |proj g|=        1.4568
At iterate    14  f =      -808.03  |proj g|=        3.1597
At iterate    15  f =      -808.38  |proj g|=        3.5032
At iterate    16  f =       -808.5  |proj g|=        3.3719
At iterate    17  f =       -808.5  |proj g|=        3.3396
At iterate    18  f =       -808.5  |proj g|=        3.3437
At iterate    19  f =       -808.5  |proj g|=        3.3439

iterations 19
function evaluations 23
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 3.34387
final function value -808.502

F = -808.502
final  value -808.501985 
converged
 
INFO  [05:25:35.850] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:25:36.007] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:25:36.014] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:25:40.335] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:25:44.597] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:25:48.286] [mlr3]  Finished benchmark 
INFO  [05:25:48.387] [bbotk] Result of batch 146: 
INFO  [05:25:48.389] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:25:48.389] [bbotk]              5.130798                 2.385824                       0.4351631 
INFO  [05:25:48.389] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:25:48.389] [bbotk]                     1924        0.871 -0.9360074         <NA>   0.9745704 
INFO  [05:25:48.389] [bbotk]                                 uhash 
INFO  [05:25:48.389] [bbotk]  4e0ac895-c40b-415e-9537-677674cb98da 
DEBUG [05:25:49.936] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.514945e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.514945e-05 0.002007293 
  - best initial criterion value(s) :  701.222 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -701.22  |proj g|=       7.6305
At iterate     1  f =      -761.18  |proj g|=        9.5655
At iterate     2  f =      -772.01  |proj g|=        8.5909
At iterate     3  f =      -787.91  |proj g|=        5.8568
At iterate     4  f =       -791.9  |proj g|=        3.6563
At iterate     5  f =      -794.02  |proj g|=        3.5622
At iterate     6  f =      -802.01  |proj g|=        2.3446
At iterate     7  f =      -804.83  |proj g|=        2.0908
At iterate     8  f =      -807.22  |proj g|=        1.9922
At iterate     9  f =      -808.73  |proj g|=        1.9907
At iterate    10  f =      -809.27  |proj g|=        2.7122
At iterate    11  f =       -810.3  |proj g|=        2.0737
At iterate    12  f =       -810.3  |proj g|=        2.1112
At iterate    13  f =       -810.3  |proj g|=        2.1284
At iterate    14  f =       -810.3  |proj g|=        2.1328
At iterate    15  f =       -810.3  |proj g|=        2.1543
At iterate    16  f =      -810.31  |proj g|=        2.1798
At iterate    17  f =      -810.33  |proj g|=        2.2261
At iterate    18  f =      -810.37  |proj g|=        2.2949
At iterate    19  f =      -813.35  |proj g|=        2.2769
At iterate    20  f =       -819.8  |proj g|=        2.0241
At iterate    21  f =      -821.51  |proj g|=        0.8014
At iterate    22  f =      -821.71  |proj g|=        1.1131
At iterate    23  f =      -821.72  |proj g|=        1.1551
At iterate    24  f =      -821.72  |proj g|=        1.1425
At iterate    25  f =      -821.72  |proj g|=        1.1425

iterations 25
function evaluations 33
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.14252
final function value -821.716

F = -821.716
final  value -821.716390 
converged
 
INFO  [05:25:49.940] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:25:50.032] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:25:50.039] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:25:55.608] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:26:00.929] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:26:06.429] [mlr3]  Finished benchmark 
INFO  [05:26:06.527] [bbotk] Result of batch 147: 
INFO  [05:26:06.529] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:26:06.529] [bbotk]              2.954794                 6.534856                     0.005047981 
INFO  [05:26:06.529] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:26:06.529] [bbotk]                     2470        0.958 -0.9398708         <NA>   0.8705713 
INFO  [05:26:06.529] [bbotk]                                 uhash 
INFO  [05:26:06.529] [bbotk]  e5738eb1-4874-40ac-a9b0-e88edbb943f4 
DEBUG [05:26:07.782] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.037617e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9897408 9500 
  - variance bounds :  2.037617e-05 0.002406583 
  - best initial criterion value(s) :  602.9434 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -602.94  |proj g|=       1.3076
At iterate     1  f =      -620.72  |proj g|=        3.9296
At iterate     2  f =      -634.12  |proj g|=        1.5908
At iterate     3  f =      -634.57  |proj g|=        1.4551
At iterate     4  f =      -635.16  |proj g|=        1.1467
At iterate     5  f =      -635.23  |proj g|=         1.028
At iterate     6  f =      -635.24  |proj g|=       0.97167
At iterate     7  f =      -635.24  |proj g|=       0.95604
At iterate     8  f =      -635.24  |proj g|=       0.95349
At iterate     9  f =      -635.24  |proj g|=       0.95343

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.953428
final function value -635.237

F = -635.237
final  value -635.236989 
converged
 
INFO  [05:26:07.786] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:26:07.876] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:26:07.883] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:26:12.891] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:26:16.902] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:26:20.903] [mlr3]  Finished benchmark 
INFO  [05:26:21.002] [bbotk] Result of batch 148: 
INFO  [05:26:21.004] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:26:21.004] [bbotk]              5.067281                 2.158984                      0.01070499 
INFO  [05:26:21.004] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:26:21.004] [bbotk]                     2049        0.886 -0.9701651         <NA>   0.9342019 
INFO  [05:26:21.004] [bbotk]                                 uhash 
INFO  [05:26:21.004] [bbotk]  e9c244da-1752-4600-b6a6-47f7124bc0d9 
DEBUG [05:26:22.625] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.087246e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9897408 9500 
  - variance bounds :  2.087246e-05 0.002454853 
  - best initial criterion value(s) :  647.0935 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -647.09  |proj g|=       13.973
At iterate     1  f =      -649.88  |proj g|=        9.2535
At iterate     2  f =      -674.48  |proj g|=        4.5257
At iterate     3  f =      -676.82  |proj g|=        1.6921
At iterate     4  f =       -677.1  |proj g|=        2.9345
At iterate     5  f =      -677.23  |proj g|=         2.584
At iterate     6  f =      -677.25  |proj g|=        2.5629
At iterate     7  f =      -677.25  |proj g|=        2.6222
At iterate     8  f =      -677.26  |proj g|=        2.7632
At iterate     9  f =      -677.27  |proj g|=        2.9295
At iterate    10  f =      -677.28  |proj g|=        3.0672
At iterate    11  f =      -677.33  |proj g|=        3.3434
At iterate    12  f =      -677.43  |proj g|=        3.7814
At iterate    13  f =      -677.58  |proj g|=        4.5152
At iterate    14  f =      -677.95  |proj g|=        4.7277
At iterate    15  f =      -679.74  |proj g|=        4.9767
At iterate    16  f =       -682.3  |proj g|=        4.5697
At iterate    17  f =      -686.44  |proj g|=        2.7111
At iterate    18  f =      -688.78  |proj g|=        1.6727
At iterate    19  f =      -689.03  |proj g|=        1.8199
At iterate    20  f =      -689.54  |proj g|=        1.4444
At iterate    21  f =       -689.6  |proj g|=        1.4294
At iterate    22  f =       -689.6  |proj g|=        1.4388
At iterate    23  f =       -689.6  |proj g|=        1.4356
At iterate    24  f =       -689.6  |proj g|=        1.4323
At iterate    25  f =       -689.6  |proj g|=        1.4316
At iterate    26  f =       -689.6  |proj g|=        1.4318

iterations 26
function evaluations 32
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.43179
final function value -689.602

F = -689.602
final  value -689.601893 
converged
 
INFO  [05:26:22.629] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:26:22.717] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:26:22.724] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:26:28.540] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:26:35.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:26:42.115] [mlr3]  Finished benchmark 
INFO  [05:26:42.218] [bbotk] Result of batch 149: 
INFO  [05:26:42.220] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:26:42.220] [bbotk]              3.721298                 7.940751                      0.06495689 
INFO  [05:26:42.220] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:26:42.220] [bbotk]                     2762        1.057 -0.9613455         <NA>   0.9620629 
INFO  [05:26:42.220] [bbotk]                                 uhash 
INFO  [05:26:42.220] [bbotk]  6fa8cdd6-1ac1-439b-9d2a-84f57a1ae106 
DEBUG [05:26:43.773] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.076985e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9897408 9500 
  - variance bounds :  2.076985e-05 0.002440759 
  - best initial criterion value(s) :  579.235 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -579.23  |proj g|=        14.96
At iterate     1  f =      -632.77  |proj g|=        6.7014
At iterate     2  f =      -632.81  |proj g|=         7.006
At iterate     3  f =      -637.02  |proj g|=        6.5318
At iterate     4  f =       -639.2  |proj g|=        6.9201
At iterate     5  f =      -640.27  |proj g|=        11.969
At iterate     6  f =      -640.74  |proj g|=        9.8945
At iterate     7  f =      -640.75  |proj g|=        9.9724
At iterate     8  f =      -640.75  |proj g|=        10.078
At iterate     9  f =      -640.75  |proj g|=        10.052
At iterate    10  f =      -640.76  |proj g|=        9.9786
At iterate    11  f =      -640.77  |proj g|=        9.8509
At iterate    12  f =      -640.79  |proj g|=        9.6466
At iterate    13  f =      -640.86  |proj g|=        9.3101
At iterate    14  f =      -641.04  |proj g|=        8.7375
At iterate    15  f =      -641.46  |proj g|=        7.8326
At iterate    16  f =      -642.43  |proj g|=         6.535
At iterate    17  f =      -644.71  |proj g|=        5.2673
At iterate    18  f =      -645.03  |proj g|=        4.6631
At iterate    19  f =      -649.92  |proj g|=        3.8226
At iterate    20  f =      -670.94  |proj g|=         4.185
At iterate    21  f =      -677.97  |proj g|=        2.9748
At iterate    22  f =      -681.56  |proj g|=        2.1809
At iterate    23  f =      -688.62  |proj g|=        1.7388
At iterate    24  f =      -688.82  |proj g|=        1.0513
At iterate    25  f =      -688.85  |proj g|=       0.98488
At iterate    26  f =      -688.87  |proj g|=       0.87826
At iterate    27  f =      -688.87  |proj g|=       0.86596
At iterate    28  f =      -688.87  |proj g|=       0.86479

iterations 28
function evaluations 41
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.86479
final function value -688.866

F = -688.866
final  value -688.866145 
converged
 
INFO  [05:26:43.777] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:26:43.882] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:26:43.889] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:26:47.188] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:26:50.953] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:26:55.534] [mlr3]  Finished benchmark 
INFO  [05:26:55.657] [bbotk] Result of batch 150: 
INFO  [05:26:55.660] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:26:55.660] [bbotk]              6.861025                 3.156523                       0.4012772 
INFO  [05:26:55.660] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:26:55.660] [bbotk]                     1606        0.889 -0.9635132         <NA>   0.9745584 
INFO  [05:26:55.660] [bbotk]                                 uhash 
INFO  [05:26:55.660] [bbotk]  1b4f4045-8c01-4a21-9c35-1c7ced4ff95c 
DEBUG [05:26:56.937] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.068557e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9897408 9500 
  - variance bounds :  2.068557e-05 0.002419617 
  - best initial criterion value(s) :  598.3782 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -598.38  |proj g|=       0.9658
At iterate     1  f =      -615.49  |proj g|=        2.7337
At iterate     2  f =      -618.19  |proj g|=        1.7526
At iterate     3  f =       -626.4  |proj g|=       0.66193
At iterate     4  f =      -636.96  |proj g|=        0.5101
At iterate     5  f =       -641.1  |proj g|=         1.143
At iterate     6  f =      -641.16  |proj g|=         1.105
At iterate     7  f =      -641.16  |proj g|=        1.1021
At iterate     8  f =      -641.16  |proj g|=        1.1024

iterations 8
function evaluations 13
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.10236
final function value -641.16

F = -641.16
final  value -641.160358 
converged
 
INFO  [05:26:56.942] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:26:57.029] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:26:57.037] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:27:04.700] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:27:11.316] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:27:18.049] [mlr3]  Finished benchmark 
INFO  [05:27:18.153] [bbotk] Result of batch 151: 
INFO  [05:27:18.155] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:27:18.155] [bbotk]              4.486824                 2.574275                       0.2187373 
INFO  [05:27:18.155] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:27:18.155] [bbotk]                     3359        0.875 -0.9702773         <NA>   0.9735966 
INFO  [05:27:18.155] [bbotk]                                 uhash 
INFO  [05:27:18.155] [bbotk]  2a136535-2cbe-41cd-a8b0-5ccae6d8310f 
DEBUG [05:27:19.605] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.059451e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9897408 9500 
  - variance bounds :  2.059451e-05 0.002428735 
  - best initial criterion value(s) :  666.6367 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -666.64  |proj g|=       4.2577
At iterate     1  f =       -678.1  |proj g|=         3.994
At iterate     2  f =      -678.23  |proj g|=        2.7271
At iterate     3  f =      -683.59  |proj g|=        1.8046
At iterate     4  f =      -684.45  |proj g|=        1.3675
At iterate     5  f =      -684.46  |proj g|=        1.3648
At iterate     6  f =      -684.47  |proj g|=        1.3984
At iterate     7  f =      -684.47  |proj g|=        1.4132
At iterate     8  f =      -684.47  |proj g|=        1.4145
At iterate     9  f =      -684.47  |proj g|=        1.4146

iterations 9
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.41461
final function value -684.466

F = -684.466
final  value -684.466201 
converged
 
INFO  [05:27:19.609] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:27:19.725] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:27:19.732] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:27:26.628] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:27:33.077] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:27:39.486] [mlr3]  Finished benchmark 
INFO  [05:27:39.967] [bbotk] Result of batch 152: 
INFO  [05:27:39.969] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:27:39.969] [bbotk]              6.715217                  9.04771                     0.002000142 
INFO  [05:27:39.969] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:27:39.969] [bbotk]                     2832        1.065 -0.9632018         <NA>    0.903311 
INFO  [05:27:39.969] [bbotk]                                 uhash 
INFO  [05:27:39.969] [bbotk]  58184a2d-e486-4537-892b-98133243036e 
DEBUG [05:27:41.344] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.270704e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9958364 9500 
  - variance bounds :  2.270704e-05 0.002585762 
  - best initial criterion value(s) :  623.0328 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -623.03  |proj g|=       6.0938
At iterate     1  f =       -630.5  |proj g|=        6.1326
At iterate     2  f =      -630.51  |proj g|=        6.0457
At iterate     3  f =      -630.52  |proj g|=        6.0686
At iterate     4  f =      -630.53  |proj g|=        6.1141
At iterate     5  f =       -631.1  |proj g|=        5.9122
At iterate     6  f =      -635.35  |proj g|=        4.5652
At iterate     7  f =      -641.94  |proj g|=        3.1322
At iterate     8  f =      -643.07  |proj g|=        2.3057
At iterate     9  f =      -650.74  |proj g|=        1.3207
At iterate    10  f =      -653.89  |proj g|=       0.88704
At iterate    11  f =      -654.28  |proj g|=        0.8843
At iterate    12  f =      -654.29  |proj g|=       0.88342
At iterate    13  f =      -654.29  |proj g|=       0.21491
At iterate    14  f =      -654.29  |proj g|=        0.2137
At iterate    15  f =      -654.29  |proj g|=       0.21368

iterations 15
function evaluations 25
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.213675
final function value -654.291

F = -654.291
final  value -654.291347 
converged
 
INFO  [05:27:41.348] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:27:41.440] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:27:41.447] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:27:51.658] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:28:01.051] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:28:11.794] [mlr3]  Finished benchmark 
INFO  [05:28:11.897] [bbotk] Result of batch 153: 
INFO  [05:28:11.899] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:28:11.899] [bbotk]               7.14272                 9.883688                       0.3750578 
INFO  [05:28:11.899] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:28:11.899] [bbotk]                     4660         0.87 -0.9695279         <NA>   0.9762315 
INFO  [05:28:11.899] [bbotk]                                 uhash 
INFO  [05:28:11.899] [bbotk]  e2efbb71-298f-44cb-bcb9-4b807d29a879 
DEBUG [05:28:13.302] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.263149e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9958364 9500 
  - variance bounds :  2.263149e-05 0.002581555 
  - best initial criterion value(s) :  654.9668 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -654.97  |proj g|=       4.1139
At iterate     1  f =      -675.75  |proj g|=        12.317
At iterate     2  f =      -679.13  |proj g|=        12.426
At iterate     3  f =      -687.23  |proj g|=        10.879
At iterate     4  f =      -687.54  |proj g|=        9.7242
At iterate     5  f =      -687.58  |proj g|=        9.4065
At iterate     6  f =       -687.6  |proj g|=        9.2405
At iterate     7  f =       -687.6  |proj g|=        9.1651
At iterate     8  f =      -695.04  |proj g|=        6.1622
At iterate     9  f =      -705.87  |proj g|=        2.4065
At iterate    10  f =      -706.44  |proj g|=        3.6084
At iterate    11  f =      -710.74  |proj g|=        2.0826
At iterate    12  f =      -714.32  |proj g|=         1.544
At iterate    13  f =      -717.29  |proj g|=        1.8202
At iterate    14  f =      -717.53  |proj g|=        1.7758
At iterate    15  f =      -717.65  |proj g|=        1.6672
At iterate    16  f =      -717.67  |proj g|=        1.7182
At iterate    17  f =      -717.67  |proj g|=        1.6971
At iterate    18  f =      -717.67  |proj g|=        1.6948
At iterate    19  f =      -717.67  |proj g|=        1.6949
At iterate    20  f =      -717.67  |proj g|=         1.695

iterations 20
function evaluations 26
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.69502
final function value -717.672

F = -717.672
final  value -717.672098 
converged
 
INFO  [05:28:13.306] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:28:13.412] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:28:13.419] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:28:14.265] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:28:15.523] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:28:16.640] [mlr3]  Finished benchmark 
INFO  [05:28:16.751] [bbotk] Result of batch 154: 
INFO  [05:28:16.752] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:28:16.752] [bbotk]               5.54458                 4.949931                       0.3762201 
INFO  [05:28:16.752] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:28:16.752] [bbotk]                      208        0.881 -0.9488436         <NA>   0.9584149 
INFO  [05:28:16.752] [bbotk]                                 uhash 
INFO  [05:28:16.752] [bbotk]  d9ecd111-3e3f-4628-bac1-9405a8708ca8 
DEBUG [05:28:18.794] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.25468e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9958364 9576 
  - variance bounds :  2.25468e-05 0.002552017 
  - best initial criterion value(s) :  638.197 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -638.2  |proj g|=       12.262
At iterate     1  f =      -641.05  |proj g|=          10.4
At iterate     2  f =      -658.37  |proj g|=        9.9275
At iterate     3  f =      -663.02  |proj g|=        7.1708
At iterate     4  f =      -669.68  |proj g|=        6.4304
At iterate     5  f =      -670.55  |proj g|=        6.4598
At iterate     6  f =      -670.56  |proj g|=         6.342
At iterate     7  f =      -670.56  |proj g|=        6.3551
At iterate     8  f =      -670.57  |proj g|=        6.4474
At iterate     9  f =      -670.59  |proj g|=        6.5568
At iterate    10  f =      -670.64  |proj g|=         6.762
At iterate    11  f =      -670.78  |proj g|=        7.0817
At iterate    12  f =      -671.12  |proj g|=        7.6259
At iterate    13  f =      -671.91  |proj g|=        8.5098
At iterate    14  f =       -673.4  |proj g|=        9.8792
At iterate    15  f =      -675.29  |proj g|=        11.371
At iterate    16  f =      -676.55  |proj g|=        12.392
At iterate    17  f =      -677.56  |proj g|=        11.826
At iterate    18  f =      -678.16  |proj g|=        11.653
At iterate    19  f =       -680.4  |proj g|=        11.223
At iterate    20  f =      -680.41  |proj g|=        10.695
At iterate    21  f =      -680.84  |proj g|=         10.65
At iterate    22  f =      -680.91  |proj g|=        10.702
At iterate    23  f =      -680.92  |proj g|=        10.796
At iterate    24  f =      -680.92  |proj g|=        10.817
At iterate    25  f =      -680.92  |proj g|=        10.817
At iterate    26  f =      -680.92  |proj g|=        10.829
At iterate    27  f =      -680.92  |proj g|=        10.829
At iterate    28  f =      -680.92  |proj g|=         10.83
At iterate    29  f =      -680.92  |proj g|=         10.83
At iterate    30  f =      -680.92  |proj g|=        10.831
At iterate    31  f =      -680.93  |proj g|=         10.83
At iterate    32  f =      -680.93  |proj g|=        10.709
At iterate    33  f =      -680.94  |proj g|=        10.912
At iterate    34  f =      -680.95  |proj g|=        10.826
At iterate    35  f =      -681.12  |proj g|=        10.122
At iterate    36  f =      -681.42  |proj g|=        9.3114
At iterate    37  f =      -681.57  |proj g|=        8.5634
At iterate    38  f =      -682.27  |proj g|=        7.6488
At iterate    39  f =      -684.54  |proj g|=        5.8235
At iterate    40  f =      -688.89  |proj g|=         3.581
At iterate    41  f =      -689.83  |proj g|=        3.7694
At iterate    42  f =      -702.99  |proj g|=        2.0301
At iterate    43  f =      -704.04  |proj g|=       0.69196
At iterate    44  f =      -707.84  |proj g|=      0.099599
At iterate    45  f =      -708.25  |proj g|=       0.89946
At iterate    46  f =      -708.34  |proj g|=       0.89537
At iterate    47  f =      -708.57  |proj g|=       0.89373
At iterate    48  f =      -708.76  |proj g|=       0.38878
At iterate    49  f =      -708.77  |proj g|=       0.10591
At iterate    50  f =      -708.77  |proj g|=       0.10614
At iterate    51  f =      -708.77  |proj g|=       0.16794
At iterate    52  f =      -708.77  |proj g|=      0.095056
At iterate    53  f =      -708.77  |proj g|=      0.039746

iterations 53
function evaluations 69
segments explored during Cauchy searches 56
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0397463
final function value -708.77

F = -708.77
final  value -708.770031 
converged
 
INFO  [05:28:18.799] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:28:18.884] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:28:18.890] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:28:28.734] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:28:38.728] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:28:48.168] [mlr3]  Finished benchmark 
INFO  [05:28:48.267] [bbotk] Result of batch 155: 
INFO  [05:28:48.269] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:28:48.269] [bbotk]              8.957797                 9.997072                       0.3686278 
INFO  [05:28:48.269] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:28:48.269] [bbotk]                     3953        1.076 -0.9591335         <NA>   0.9761343 
INFO  [05:28:48.269] [bbotk]                                 uhash 
INFO  [05:28:48.269] [bbotk]  63311b68-9f02-45c0-aed8-4ea5820dde4f 
DEBUG [05:28:49.946] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.247189e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.247189e-05 0.00255139 
  - best initial criterion value(s) :  657.0569 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -657.06  |proj g|=       5.9346
At iterate     1  f =      -689.16  |proj g|=        5.0211
At iterate     2  f =      -700.34  |proj g|=        3.5164
At iterate     3  f =       -713.9  |proj g|=        3.0996
At iterate     4  f =      -718.22  |proj g|=        2.3648
At iterate     5  f =      -718.28  |proj g|=        2.2498
At iterate     6  f =      -718.29  |proj g|=        2.2487
At iterate     7  f =      -718.29  |proj g|=        2.3242
At iterate     8  f =       -718.3  |proj g|=        2.2785
At iterate     9  f =       -718.3  |proj g|=        2.2756
At iterate    10  f =       -718.3  |proj g|=        2.2755
At iterate    11  f =       -718.3  |proj g|=        2.2654
At iterate    12  f =       -718.3  |proj g|=        2.2685
At iterate    13  f =       -718.3  |proj g|=        2.2783
At iterate    14  f =      -718.31  |proj g|=        2.2911
At iterate    15  f =      -718.32  |proj g|=        2.3125
At iterate    16  f =      -718.35  |proj g|=        2.3398
At iterate    17  f =      -718.41  |proj g|=        2.3709
At iterate    18  f =      -718.56  |proj g|=        2.3858
At iterate    19  f =      -718.83  |proj g|=        2.3501
At iterate    20  f =      -718.84  |proj g|=        2.4191
At iterate    21  f =      -719.24  |proj g|=        2.2947
At iterate    22  f =      -720.24  |proj g|=        2.1077
At iterate    23  f =      -721.59  |proj g|=        2.0114
At iterate    24  f =      -721.65  |proj g|=        1.8659
At iterate    25  f =      -721.66  |proj g|=         1.821
At iterate    26  f =      -721.66  |proj g|=        1.8061
At iterate    27  f =      -721.66  |proj g|=        1.8082
At iterate    28  f =      -721.66  |proj g|=        1.8067
At iterate    29  f =      -721.66  |proj g|=        1.8168
At iterate    30  f =      -721.67  |proj g|=        1.8286
At iterate    31  f =      -721.69  |proj g|=        1.8275
At iterate    32  f =      -721.69  |proj g|=        1.8243
At iterate    33  f =      -721.69  |proj g|=        1.8253
At iterate    34  f =      -721.69  |proj g|=        1.8245
At iterate    35  f =      -721.69  |proj g|=        1.8258
At iterate    36  f =      -721.69  |proj g|=         1.825
At iterate    37  f =      -721.69  |proj g|=        1.8226
At iterate    38  f =       -721.7  |proj g|=         1.816
At iterate    39  f =       -721.7  |proj g|=        1.8227
At iterate    40  f =       -721.7  |proj g|=        1.8316
At iterate    41  f =       -721.7  |proj g|=        1.8335
At iterate    42  f =       -721.7  |proj g|=        1.8336

iterations 42
function evaluations 49
segments explored during Cauchy searches 45
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.8336
final function value -721.698

F = -721.698
final  value -721.698449 
converged
 
INFO  [05:28:49.948] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:28:50.048] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:28:50.055] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:28:56.611] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:29:02.257] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:29:07.740] [mlr3]  Finished benchmark 
INFO  [05:29:07.838] [bbotk] Result of batch 156: 
INFO  [05:29:07.840] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:29:07.840] [bbotk]              6.568608                 4.315952                       0.3140401 
INFO  [05:29:07.840] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:29:07.840] [bbotk]                     2762        0.915 -0.9502767         <NA>   0.9748534 
INFO  [05:29:07.840] [bbotk]                                 uhash 
INFO  [05:29:07.840] [bbotk]  8e626e7d-6251-4cf6-b223-f3476fec8427 
DEBUG [05:29:09.281] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.238542e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.238542e-05 0.002543818 
  - best initial criterion value(s) :  673.2082 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -673.21  |proj g|=       8.5532
At iterate     1  f =      -702.65  |proj g|=        2.1948
At iterate     2  f =      -709.09  |proj g|=        1.9568
At iterate     3  f =       -715.4  |proj g|=        2.6251
At iterate     4  f =      -717.37  |proj g|=        1.5824
At iterate     5  f =      -718.54  |proj g|=        1.4385
At iterate     6  f =      -724.68  |proj g|=        1.3522
At iterate     7  f =      -726.74  |proj g|=        1.3566
At iterate     8  f =      -726.91  |proj g|=        1.2528
At iterate     9  f =      -726.95  |proj g|=        1.2493
At iterate    10  f =      -726.97  |proj g|=        1.2493
At iterate    11  f =      -726.97  |proj g|=        1.2493
At iterate    12  f =      -726.98  |proj g|=        1.2493
At iterate    13  f =      -726.98  |proj g|=        1.2493
At iterate    14  f =      -726.98  |proj g|=        1.2493
At iterate    15  f =      -727.28  |proj g|=        1.2493
At iterate    16  f =       -729.2  |proj g|=        1.0945
At iterate    17  f =      -729.48  |proj g|=        1.0991
At iterate    18  f =      -729.55  |proj g|=         1.137
At iterate    19  f =      -729.56  |proj g|=        1.1641
At iterate    20  f =      -729.56  |proj g|=        1.1755
At iterate    21  f =      -729.56  |proj g|=        1.1761

iterations 21
function evaluations 25
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.17611
final function value -729.562

F = -729.562
final  value -729.561996 
converged
 
INFO  [05:29:09.285] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:29:09.377] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:29:09.384] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:29:14.751] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:29:20.216] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:29:26.802] [mlr3]  Finished benchmark 
INFO  [05:29:26.918] [bbotk] Result of batch 157: 
INFO  [05:29:26.921] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:29:26.921] [bbotk]              4.769266                 6.568542                       0.2306292 
INFO  [05:29:26.921] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:29:26.921] [bbotk]                     2464        0.916 -0.9506408         <NA>   0.9729269 
INFO  [05:29:26.921] [bbotk]                                 uhash 
INFO  [05:29:26.921] [bbotk]  10b2965c-a037-49f9-85ac-db1e95b92dc9 
DEBUG [05:29:28.434] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.228516e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.228516e-05 0.002545962 
  - best initial criterion value(s) :  668.1092 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -668.11  |proj g|=       12.388
At iterate     1  f =      -681.03  |proj g|=        10.137
At iterate     2  f =      -692.65  |proj g|=        7.7018
At iterate     3  f =       -695.3  |proj g|=        6.1044
At iterate     4  f =      -697.39  |proj g|=        4.9397
At iterate     5  f =       -697.8  |proj g|=        4.3711
At iterate     6  f =      -697.81  |proj g|=        4.3201
At iterate     7  f =      -697.81  |proj g|=        4.2934
At iterate     8  f =      -697.84  |proj g|=        4.2048
At iterate     9  f =       -697.9  |proj g|=        4.0844
At iterate    10  f =      -698.06  |proj g|=        3.8605
At iterate    11  f =      -698.49  |proj g|=        3.4834
At iterate    12  f =      -699.63  |proj g|=        2.8343
At iterate    13  f =      -702.23  |proj g|=        1.9756
At iterate    14  f =      -702.78  |proj g|=        1.6409
At iterate    15  f =      -708.43  |proj g|=        0.9542
At iterate    16  f =      -716.06  |proj g|=       0.92882
At iterate    17  f =      -720.16  |proj g|=       0.91916
At iterate    18  f =      -723.44  |proj g|=       0.90511
At iterate    19  f =      -724.33  |proj g|=        1.0067
At iterate    20  f =      -724.69  |proj g|=        1.4148
At iterate    21  f =      -724.73  |proj g|=        1.4941
At iterate    22  f =      -724.74  |proj g|=        1.5391
At iterate    23  f =      -724.74  |proj g|=        1.5194
At iterate    24  f =      -724.74  |proj g|=        1.5274
At iterate    25  f =      -724.74  |proj g|=        1.5275

iterations 25
function evaluations 33
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.52752
final function value -724.736

F = -724.736
final  value -724.735650 
converged
 
INFO  [05:29:28.439] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:29:28.528] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:29:28.535] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:29:36.750] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:29:44.261] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:29:50.952] [mlr3]  Finished benchmark 
INFO  [05:29:51.052] [bbotk] Result of batch 158: 
INFO  [05:29:51.054] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:29:51.054] [bbotk]              2.753331                  8.49745                       0.2231619 
INFO  [05:29:51.054] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:29:51.054] [bbotk]                     3361        0.902 -0.9592965         <NA>    0.965801 
INFO  [05:29:51.054] [bbotk]                                 uhash 
INFO  [05:29:51.054] [bbotk]  3668e2cd-74ce-4bc3-8d09-0df305145539 
DEBUG [05:29:52.889] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.216727e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.216727e-05 0.002539489 
  - best initial criterion value(s) :  660.3971 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -660.4  |proj g|=       2.1723
At iterate     1  f =      -665.15  |proj g|=        2.0268
At iterate     2  f =      -665.16  |proj g|=        2.0031
At iterate     3  f =      -665.17  |proj g|=         1.981
At iterate     4  f =      -665.18  |proj g|=         1.971
At iterate     5  f =      -665.22  |proj g|=        1.9683
At iterate     6  f =      -665.27  |proj g|=        2.0053
At iterate     7  f =      -665.36  |proj g|=        2.1553
At iterate     8  f =      -665.36  |proj g|=        2.1832
At iterate     9  f =      -665.36  |proj g|=        2.1875
At iterate    10  f =      -665.36  |proj g|=        2.1879
At iterate    11  f =      -665.36  |proj g|=        2.1903
At iterate    12  f =      -665.36  |proj g|=         2.193
At iterate    13  f =      -665.36  |proj g|=        2.1978
At iterate    14  f =      -665.36  |proj g|=        2.2049
At iterate    15  f =      -665.36  |proj g|=        2.2164
At iterate    16  f =      -665.37  |proj g|=        2.2351
At iterate    17  f =      -665.38  |proj g|=        2.2662
At iterate    18  f =      -665.42  |proj g|=        2.3163
At iterate    19  f =       -665.5  |proj g|=        2.3867
At iterate    20  f =      -665.64  |proj g|=        2.4431
At iterate    21  f =      -665.68  |proj g|=        2.3493
At iterate    22  f =      -665.74  |proj g|=        2.3872
At iterate    23  f =      -672.81  |proj g|=        1.3689
At iterate    24  f =      -673.29  |proj g|=        1.1729
At iterate    25  f =      -673.32  |proj g|=        1.1967
At iterate    26  f =      -673.32  |proj g|=        1.1682
At iterate    27  f =      -673.32  |proj g|=        1.1765
At iterate    28  f =      -673.32  |proj g|=        1.1769
At iterate    29  f =      -673.32  |proj g|=        1.1766

iterations 29
function evaluations 37
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.17655
final function value -673.324

F = -673.324
final  value -673.324494 
converged
 
INFO  [05:29:52.893] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:29:52.980] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:29:52.986] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:30:00.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:30:07.900] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:30:16.040] [mlr3]  Finished benchmark 
INFO  [05:30:16.142] [bbotk] Result of batch 159: 
INFO  [05:30:16.144] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:30:16.144] [bbotk]              6.040589                 5.679103                       0.2003869 
INFO  [05:30:16.144] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:30:16.144] [bbotk]                     3612        1.003 -0.9697576         <NA>   0.9746359 
INFO  [05:30:16.144] [bbotk]                                 uhash 
INFO  [05:30:16.144] [bbotk]  21ebec43-f836-44e8-b636-6a58a73888e3 
DEBUG [05:30:17.626] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.208142e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.208142e-05 0.002536156 
  - best initial criterion value(s) :  674.6008 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -674.6  |proj g|=       4.6593
At iterate     1  f =      -697.51  |proj g|=        5.2733
At iterate     2  f =      -707.93  |proj g|=        2.3323
At iterate     3  f =      -715.08  |proj g|=        1.9848
At iterate     4  f =      -718.17  |proj g|=         1.357
At iterate     5  f =      -718.19  |proj g|=        1.2972
At iterate     6  f =      -718.21  |proj g|=        1.2711
At iterate     7  f =      -718.23  |proj g|=        1.2444
At iterate     8  f =      -718.24  |proj g|=         1.262
At iterate     9  f =      -718.24  |proj g|=        1.2651
At iterate    10  f =      -718.24  |proj g|=        1.2651

iterations 10
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.2651
final function value -718.235

F = -718.235
final  value -718.235080 
converged
 
INFO  [05:30:17.632] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:30:17.748] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:30:17.756] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:30:20.500] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:30:23.093] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:30:26.351] [mlr3]  Finished benchmark 
INFO  [05:30:26.789] [bbotk] Result of batch 160: 
INFO  [05:30:26.791] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:30:26.791] [bbotk]              4.046832                 2.774134                       0.3957694 
INFO  [05:30:26.791] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:30:26.791] [bbotk]                     1187         1.02 -0.9609605         <NA>   0.9710386 
INFO  [05:30:26.791] [bbotk]                                 uhash 
INFO  [05:30:26.791] [bbotk]  29575026-23d9-4674-a1f3-ab5d2a5c9c95 
DEBUG [05:30:28.770] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.197396e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.197396e-05 0.002514146 
  - best initial criterion value(s) :  656.3588 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -656.36  |proj g|=       9.0107
At iterate     1  f =      -703.24  |proj g|=         8.486
At iterate     2  f =      -714.38  |proj g|=        7.5097
At iterate     3  f =      -722.42  |proj g|=        2.3903
At iterate     4  f =      -726.87  |proj g|=        5.0011
At iterate     5  f =      -727.57  |proj g|=        4.6098
At iterate     6  f =      -729.23  |proj g|=         3.733
At iterate     7  f =       -731.7  |proj g|=        2.9433
At iterate     8  f =      -734.26  |proj g|=        4.4821
At iterate     9  f =      -737.72  |proj g|=        2.6558
At iterate    10  f =      -738.03  |proj g|=        2.2674
At iterate    11  f =      -738.28  |proj g|=        2.0773
At iterate    12  f =      -738.55  |proj g|=         2.038
At iterate    13  f =      -738.72  |proj g|=        2.1036
At iterate    14  f =      -738.73  |proj g|=        2.1475
At iterate    15  f =      -738.76  |proj g|=        2.1987
At iterate    16  f =      -739.21  |proj g|=        2.5251
At iterate    17  f =      -744.73  |proj g|=        2.3356
At iterate    18  f =      -745.46  |proj g|=        1.9517
At iterate    19  f =       -746.6  |proj g|=         1.541
At iterate    20  f =      -747.09  |proj g|=        2.4357
At iterate    21  f =      -747.31  |proj g|=        2.1491
At iterate    22  f =      -747.32  |proj g|=        2.0854
At iterate    23  f =      -747.34  |proj g|=        2.1077
At iterate    24  f =      -747.34  |proj g|=        2.1044
At iterate    25  f =      -747.34  |proj g|=        2.1076
At iterate    26  f =      -747.34  |proj g|=        2.1101
At iterate    27  f =      -747.34  |proj g|=        2.1075
At iterate    28  f =      -747.34  |proj g|=        2.1089
At iterate    29  f =      -747.34  |proj g|=        2.1102
At iterate    30  f =      -747.35  |proj g|=        2.1125
At iterate    31  f =      -747.35  |proj g|=        2.1161
At iterate    32  f =      -747.37  |proj g|=        2.1193
At iterate    33  f =      -747.42  |proj g|=         2.117
At iterate    34  f =      -747.55  |proj g|=         2.095
At iterate    35  f =      -747.55  |proj g|=        2.0857
At iterate    36  f =      -747.86  |proj g|=        2.0088
At iterate    37  f =         -751  |proj g|=        1.4891
At iterate    38  f =      -753.44  |proj g|=        0.8613
At iterate    39  f =      -753.62  |proj g|=       0.33973
At iterate    40  f =      -753.63  |proj g|=       0.28193
At iterate    41  f =      -753.63  |proj g|=       0.85261
At iterate    42  f =      -753.63  |proj g|=       0.25349
At iterate    43  f =      -753.63  |proj g|=       0.25342

iterations 43
function evaluations 56
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.253425
final function value -753.635

F = -753.635
final  value -753.634738 
converged
 
INFO  [05:30:28.774] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:30:28.860] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:30:28.866] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:30:41.280] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:30:51.637] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:31:02.892] [mlr3]  Finished benchmark 
INFO  [05:31:02.990] [bbotk] Result of batch 161: 
INFO  [05:31:02.992] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:31:02.992] [bbotk]              5.536903                 4.267346                       0.0175633 
INFO  [05:31:02.992] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:31:02.992] [bbotk]                     4776        1.105 -0.9483268         <NA>   0.9592182 
INFO  [05:31:02.992] [bbotk]                                 uhash 
INFO  [05:31:02.992] [bbotk]  b968f2ed-b0b3-4aa5-957f-816097262247 
DEBUG [05:31:04.563] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.189021e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.189021e-05 0.002496191 
  - best initial criterion value(s) :  727.3636 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -727.36  |proj g|=       3.0715
At iterate     1  f =      -732.66  |proj g|=        3.2675
At iterate     2  f =       -737.6  |proj g|=        2.1705
At iterate     3  f =      -741.14  |proj g|=       0.91772
At iterate     4  f =      -742.89  |proj g|=         0.916
At iterate     5  f =       -751.1  |proj g|=       0.89719
At iterate     6  f =      -753.93  |proj g|=       0.80962
At iterate     7  f =      -755.53  |proj g|=       0.98096
At iterate     8  f =      -755.96  |proj g|=       0.95032
At iterate     9  f =      -756.01  |proj g|=        1.1406
At iterate    10  f =       -756.1  |proj g|=        1.0232
At iterate    11  f =      -756.11  |proj g|=        1.0207
At iterate    12  f =      -756.12  |proj g|=        1.0372
At iterate    13  f =      -756.18  |proj g|=        1.0632
At iterate    14  f =      -756.35  |proj g|=        1.0696
At iterate    15  f =      -756.68  |proj g|=       0.82549
At iterate    16  f =      -756.89  |proj g|=       0.98617
At iterate    17  f =      -757.25  |proj g|=       0.67643
At iterate    18  f =      -757.69  |proj g|=       0.33548
At iterate    19  f =      -758.29  |proj g|=       0.24733
At iterate    20  f =      -758.35  |proj g|=       0.80947
At iterate    21  f =      -758.36  |proj g|=       0.29626
At iterate    22  f =      -758.36  |proj g|=       0.29391
At iterate    23  f =      -758.36  |proj g|=       0.29411
At iterate    24  f =      -758.36  |proj g|=       0.29413

iterations 24
function evaluations 30
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.294131
final function value -758.356

F = -758.356
final  value -758.356457 
converged
 
INFO  [05:31:04.567] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:31:04.656] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:31:04.676] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:31:07.234] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:31:09.864] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:31:12.582] [mlr3]  Finished benchmark 
INFO  [05:31:12.697] [bbotk] Result of batch 162: 
INFO  [05:31:12.699] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:31:12.699] [bbotk]               9.55122                 3.489301                       0.3985697 
INFO  [05:31:12.699] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:31:12.699] [bbotk]                     1191        0.983 -0.9493053         <NA>   0.9740973 
INFO  [05:31:12.699] [bbotk]                                 uhash 
INFO  [05:31:12.699] [bbotk]  bc3595c1-e0ab-4010-bb5a-4549be7fe482 
DEBUG [05:31:14.308] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.180282e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.180282e-05 0.002472974 
  - best initial criterion value(s) :  728.2819 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -728.28  |proj g|=        2.729
At iterate     1  f =      -743.65  |proj g|=        1.1003
At iterate     2  f =      -745.94  |proj g|=        3.7337
At iterate     3  f =      -746.53  |proj g|=        3.1167
At iterate     4  f =      -746.73  |proj g|=        2.2353
At iterate     5  f =      -746.75  |proj g|=        2.4791
At iterate     6  f =      -746.75  |proj g|=        2.4554
At iterate     7  f =      -746.75  |proj g|=        2.4491
At iterate     8  f =      -746.75  |proj g|=        2.4529
At iterate     9  f =      -746.75  |proj g|=        2.4583
At iterate    10  f =      -746.75  |proj g|=        2.4619
At iterate    11  f =      -746.75  |proj g|=        2.4636
At iterate    12  f =      -746.75  |proj g|=         2.468
At iterate    13  f =      -746.75  |proj g|=        2.4743
At iterate    14  f =      -746.75  |proj g|=        2.4852
At iterate    15  f =      -746.75  |proj g|=        2.5021
At iterate    16  f =      -746.76  |proj g|=         2.528
At iterate    17  f =      -746.76  |proj g|=        2.5608
At iterate    18  f =      -746.77  |proj g|=        2.5792
At iterate    19  f =      -746.77  |proj g|=        2.5197
At iterate    20  f =      -746.77  |proj g|=        2.5366
At iterate    21  f =      -746.77  |proj g|=         2.548
At iterate    22  f =      -746.85  |proj g|=        2.6217
At iterate    23  f =      -747.01  |proj g|=        2.6809
At iterate    24  f =      -747.48  |proj g|=        2.6964
At iterate    25  f =       -748.4  |proj g|=        2.1029
At iterate    26  f =      -748.95  |proj g|=        2.5311
At iterate    27  f =      -751.15  |proj g|=        1.7696
At iterate    28  f =       -755.4  |proj g|=       0.88629
At iterate    29  f =      -755.52  |proj g|=       0.18966
At iterate    30  f =      -755.54  |proj g|=       0.88033
At iterate    31  f =      -755.56  |proj g|=        0.8799
At iterate    32  f =      -755.56  |proj g|=       0.36456
At iterate    33  f =      -755.56  |proj g|=       0.36502

iterations 33
function evaluations 39
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.365019
final function value -755.562

F = -755.562
final  value -755.561994 
converged
 
INFO  [05:31:14.312] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:31:14.398] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:31:14.404] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:31:24.515] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:31:35.361] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:31:44.675] [mlr3]  Finished benchmark 
INFO  [05:31:44.775] [bbotk] Result of batch 163: 
INFO  [05:31:44.777] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:31:44.777] [bbotk]              3.830586                 2.967388                       0.0832692 
INFO  [05:31:44.777] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:31:44.777] [bbotk]                     4629        0.913 -0.9552729         <NA>   0.9694088 
INFO  [05:31:44.777] [bbotk]                                 uhash 
INFO  [05:31:44.777] [bbotk]  ce275bf6-7d2c-4326-8c3e-697c9bdbd414 
DEBUG [05:31:46.310] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.169293e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.169293e-05 0.002451447 
  - best initial criterion value(s) :  691.4431 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -691.44  |proj g|=       1.5574
At iterate     1  f =      -730.21  |proj g|=        2.7632
At iterate     2  f =       -731.6  |proj g|=        8.4952
At iterate     3  f =      -741.16  |proj g|=         5.241
At iterate     4  f =      -741.35  |proj g|=        4.6543
At iterate     5  f =      -741.38  |proj g|=        4.6052
At iterate     6  f =      -741.45  |proj g|=        4.6661
At iterate     7  f =      -741.46  |proj g|=        5.0307
At iterate     8  f =      -741.46  |proj g|=        4.8944
At iterate     9  f =      -741.46  |proj g|=        4.8887
At iterate    10  f =      -741.46  |proj g|=        4.8888

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.88877
final function value -741.464

F = -741.464
final  value -741.464193 
converged
 
INFO  [05:31:46.315] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:31:46.402] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:31:46.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:31:52.089] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:31:57.389] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:32:03.178] [mlr3]  Finished benchmark 
INFO  [05:32:03.279] [bbotk] Result of batch 164: 
INFO  [05:32:03.281] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:32:03.281] [bbotk]              6.785722                 6.052135                       0.1737377 
INFO  [05:32:03.281] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:32:03.281] [bbotk]                     2802        1.105 -0.9599597         <NA>   0.9735116 
INFO  [05:32:03.281] [bbotk]                                 uhash 
INFO  [05:32:03.281] [bbotk]  aa743244-df27-4e8b-ad79-7c1f06bff5a4 
DEBUG [05:32:05.104] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.160299e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.160299e-05 0.002449796 
  - best initial criterion value(s) :  717.8326 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -717.83  |proj g|=       6.0117
At iterate     1  f =       -726.6  |proj g|=        4.0994
At iterate     2  f =      -726.87  |proj g|=        5.6854
At iterate     3  f =       -726.9  |proj g|=        5.4749
At iterate     4  f =       -726.9  |proj g|=        5.4153
At iterate     5  f =       -726.9  |proj g|=        5.4505
At iterate     6  f =       -726.9  |proj g|=        5.4711
At iterate     7  f =       -726.9  |proj g|=        5.4745
At iterate     8  f =       -726.9  |proj g|=        5.4784
At iterate     9  f =       -726.9  |proj g|=        5.4851
At iterate    10  f =       -726.9  |proj g|=        5.4956
At iterate    11  f =       -726.9  |proj g|=        5.5126
At iterate    12  f =      -726.91  |proj g|=        5.5387
At iterate    13  f =      -726.91  |proj g|=        5.5746
At iterate    14  f =      -726.91  |proj g|=        5.6054
At iterate    15  f =      -726.91  |proj g|=        5.6244
At iterate    16  f =      -726.91  |proj g|=        5.6077
At iterate    17  f =      -726.92  |proj g|=         5.631
At iterate    18  f =      -728.77  |proj g|=        4.1387
At iterate    19  f =      -729.92  |proj g|=        1.7897
At iterate    20  f =      -732.06  |proj g|=        1.7822
At iterate    21  f =      -733.57  |proj g|=        1.5982
At iterate    22  f =      -733.96  |proj g|=       0.91033
At iterate    23  f =      -734.76  |proj g|=       0.90416
At iterate    24  f =      -734.92  |proj g|=       0.90283
At iterate    25  f =      -734.94  |proj g|=       0.24669
At iterate    26  f =      -734.95  |proj g|=       0.29416
At iterate    27  f =      -734.95  |proj g|=       0.30765
At iterate    28  f =      -734.95  |proj g|=       0.30953
At iterate    29  f =      -734.95  |proj g|=       0.31017
At iterate    30  f =      -734.95  |proj g|=       0.31242
At iterate    31  f =      -734.95  |proj g|=       0.31572
At iterate    32  f =      -734.95  |proj g|=       0.32097
At iterate    33  f =      -734.95  |proj g|=       0.32889
At iterate    34  f =      -734.95  |proj g|=       0.33667
At iterate    35  f =      -734.95  |proj g|=       0.89887
At iterate    36  f =      -734.96  |proj g|=       0.36882
At iterate    37  f =      -734.98  |proj g|=       0.29508
At iterate    38  f =      -735.01  |proj g|=       0.20033
At iterate    39  f =      -735.06  |proj g|=       0.10056
At iterate    40  f =      -735.08  |proj g|=      0.099582
At iterate    41  f =      -735.09  |proj g|=      0.099137
At iterate    42  f =      -735.09  |proj g|=      0.098735
At iterate    43  f =      -735.09  |proj g|=      0.014645
At iterate    44  f =      -735.09  |proj g|=      0.014645

iterations 44
function evaluations 54
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0146451
final function value -735.087

F = -735.087
final  value -735.087287 
converged
 
INFO  [05:32:05.108] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:32:05.211] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:32:05.218] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:32:07.948] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:32:10.712] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:32:13.053] [mlr3]  Finished benchmark 
INFO  [05:32:13.154] [bbotk] Result of batch 165: 
INFO  [05:32:13.156] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:32:13.156] [bbotk]              7.838318                 6.793585                       0.1521989 
INFO  [05:32:13.156] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:32:13.156] [bbotk]                      939         0.94 -0.9642901         <NA>   0.9665178 
INFO  [05:32:13.156] [bbotk]                                 uhash 
INFO  [05:32:13.156] [bbotk]  8cb1ceda-f089-42d7-8138-847c4609aa6a 
DEBUG [05:32:14.834] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.149233e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.149233e-05 0.002423415 
  - best initial criterion value(s) :  663.0606 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -663.06  |proj g|=       6.2714
At iterate     1  f =      -709.86  |proj g|=        11.734
At iterate     2  f =      -722.16  |proj g|=        9.6741
At iterate     3  f =      -734.24  |proj g|=        4.2815
At iterate     4  f =      -734.67  |proj g|=        3.8836
At iterate     5  f =      -735.55  |proj g|=        3.4261
At iterate     6  f =      -736.89  |proj g|=        2.8981
At iterate     7  f =      -737.38  |proj g|=        3.6435
At iterate     8  f =      -737.89  |proj g|=        2.9885
At iterate     9  f =      -737.92  |proj g|=        2.8486
At iterate    10  f =      -737.94  |proj g|=        2.8292
At iterate    11  f =      -737.94  |proj g|=        2.8382
At iterate    12  f =      -737.95  |proj g|=        2.8482
At iterate    13  f =      -737.95  |proj g|=        2.8513
At iterate    14  f =      -737.97  |proj g|=        2.8359
At iterate    15  f =      -738.01  |proj g|=        2.8446
At iterate    16  f =      -738.12  |proj g|=        2.7695
At iterate    17  f =      -738.34  |proj g|=        2.6036
At iterate    18  f =      -738.36  |proj g|=        2.7302
At iterate    19  f =       -738.8  |proj g|=        2.3785
At iterate    20  f =      -740.12  |proj g|=        1.9059
At iterate    21  f =      -742.01  |proj g|=        1.7658
At iterate    22  f =      -753.57  |proj g|=        2.5143
At iterate    23  f =      -760.37  |proj g|=        2.2223
At iterate    24  f =      -763.42  |proj g|=        1.6882
At iterate    25  f =      -764.32  |proj g|=        1.9319
At iterate    26  f =      -768.41  |proj g|=       0.73991
At iterate    27  f =      -769.24  |proj g|=       0.12456
At iterate    28  f =       -769.3  |proj g|=       0.13628
At iterate    29  f =       -769.3  |proj g|=       0.87585
At iterate    30  f =       -769.3  |proj g|=       0.18093
At iterate    31  f =       -769.3  |proj g|=       0.16696
At iterate    32  f =       -769.3  |proj g|=       0.16707

iterations 32
function evaluations 42
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.167068
final function value -769.305

F = -769.305
final  value -769.304869 
converged
 
INFO  [05:32:14.838] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:32:14.940] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:32:14.946] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:32:16.577] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:32:18.446] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:32:20.087] [mlr3]  Finished benchmark 
INFO  [05:32:20.187] [bbotk] Result of batch 166: 
INFO  [05:32:20.189] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:32:20.189] [bbotk]              7.647655                 6.619307                       0.1022407 
INFO  [05:32:20.189] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:32:20.189] [bbotk]                      707         0.93 -0.9546773         <NA>    0.959801 
INFO  [05:32:20.189] [bbotk]                                 uhash 
INFO  [05:32:20.189] [bbotk]  3be008fc-b1e3-4093-b6ed-53bc156d3b4d 
DEBUG [05:32:22.105] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.140906e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.140906e-05 0.002414432 
  - best initial criterion value(s) :  704.1855 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -704.19  |proj g|=       9.8695
At iterate     1  f =      -728.92  |proj g|=          5.35
At iterate     2  f =      -733.65  |proj g|=         6.065
At iterate     3  f =      -734.39  |proj g|=        5.6914
At iterate     4  f =      -734.73  |proj g|=        5.3241
At iterate     5  f =      -734.77  |proj g|=        5.3062
At iterate     6  f =      -734.79  |proj g|=        5.3495
At iterate     7  f =      -734.79  |proj g|=        5.3828
At iterate     8  f =      -734.79  |proj g|=        5.3911
At iterate     9  f =      -734.79  |proj g|=        5.3941
At iterate    10  f =      -734.79  |proj g|=        5.4056
At iterate    11  f =      -734.79  |proj g|=        5.4188
At iterate    12  f =       -734.8  |proj g|=        5.4418
At iterate    13  f =       -734.8  |proj g|=        5.4745
At iterate    14  f =      -734.82  |proj g|=        5.5229
At iterate    15  f =      -734.87  |proj g|=        5.5879
At iterate    16  f =      -734.99  |proj g|=         5.657
At iterate    17  f =      -735.31  |proj g|=        5.6615
At iterate    18  f =      -736.09  |proj g|=        5.3285
At iterate    19  f =      -736.69  |proj g|=        4.4682
At iterate    20  f =      -736.79  |proj g|=        4.3296
At iterate    21  f =      -746.98  |proj g|=        5.1759
At iterate    22  f =      -754.44  |proj g|=        4.7396
At iterate    23  f =      -766.54  |proj g|=        2.7766
At iterate    24  f =      -772.28  |proj g|=       0.84077
At iterate    25  f =      -772.37  |proj g|=       0.84077
At iterate    26  f =      -772.43  |proj g|=       0.84077
At iterate    27  f =      -772.44  |proj g|=       0.84077
At iterate    28  f =      -772.44  |proj g|=       0.84077
At iterate    29  f =      -772.44  |proj g|=       0.84077
At iterate    30  f =      -772.44  |proj g|=       0.84077
At iterate    31  f =      -772.44  |proj g|=       0.84076
At iterate    32  f =      -772.46  |proj g|=       0.84075
At iterate    33  f =       -772.5  |proj g|=       0.84071
At iterate    34  f =      -772.57  |proj g|=       0.85487
At iterate    35  f =      -772.68  |proj g|=       0.85949
At iterate    36  f =      -772.78  |proj g|=       0.84047
At iterate    37  f =      -772.79  |proj g|=       0.84042
At iterate    38  f =      -772.79  |proj g|=       0.84042
At iterate    39  f =      -772.79  |proj g|=       0.84042

iterations 39
function evaluations 49
segments explored during Cauchy searches 41
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.840421
final function value -772.789

F = -772.789
final  value -772.788592 
converged
 
INFO  [05:32:22.109] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:32:22.200] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:32:22.207] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:32:29.224] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:32:37.883] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:32:44.835] [mlr3]  Finished benchmark 
INFO  [05:32:44.967] [bbotk] Result of batch 167: 
INFO  [05:32:44.969] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:32:44.969] [bbotk]              4.793679                 3.716984                       0.2895053 
INFO  [05:32:44.969] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:32:44.969] [bbotk]                     3106        0.928 -0.9531774         <NA>   0.9745297 
INFO  [05:32:44.969] [bbotk]                                 uhash 
INFO  [05:32:44.969] [bbotk]  05d5d116-2b37-498e-846a-76e283ce9a5d 
DEBUG [05:32:46.373] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.132922e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.132922e-05 0.002405546 
  - best initial criterion value(s) :  701.437 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -701.44  |proj g|=       4.8783
At iterate     1  f =      -739.29  |proj g|=        5.9652
At iterate     2  f =      -757.95  |proj g|=        3.7629
At iterate     3  f =      -764.48  |proj g|=        3.3592
At iterate     4  f =      -767.28  |proj g|=        2.6813
At iterate     5  f =      -767.31  |proj g|=        2.5999
At iterate     6  f =      -767.32  |proj g|=        2.5953
At iterate     7  f =      -767.33  |proj g|=        2.6053
At iterate     8  f =      -767.33  |proj g|=        2.6561
At iterate     9  f =      -767.33  |proj g|=        2.6317
At iterate    10  f =      -767.33  |proj g|=        2.6314

iterations 10
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.63139
final function value -767.33

F = -767.33
final  value -767.329760 
converged
 
INFO  [05:32:46.377] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:32:46.467] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:32:46.474] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:32:56.201] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:33:04.972] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:33:13.044] [mlr3]  Finished benchmark 
INFO  [05:33:13.175] [bbotk] Result of batch 168: 
INFO  [05:33:13.177] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:33:13.177] [bbotk]              9.602398                 7.502625                        0.483401 
INFO  [05:33:13.177] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:33:13.177] [bbotk]                     3803        0.934 -0.9556279         <NA>   0.9762049 
INFO  [05:33:13.177] [bbotk]                                 uhash 
INFO  [05:33:13.177] [bbotk]  21321381-cfef-45e2-a9c1-0c94bd43ec0c 
DEBUG [05:33:14.725] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.126397e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.126397e-05 0.002402502 
  - best initial criterion value(s) :  711.4507 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -711.45  |proj g|=       8.3711
At iterate     1  f =       -734.9  |proj g|=        2.2324
At iterate     2  f =      -742.46  |proj g|=        1.9556
At iterate     3  f =       -750.2  |proj g|=        1.8994
At iterate     4  f =      -750.45  |proj g|=        2.2708
At iterate     5  f =       -751.4  |proj g|=        2.1864
At iterate     6  f =      -752.78  |proj g|=        2.0239
At iterate     7  f =      -753.06  |proj g|=        1.8774
At iterate     8  f =      -753.09  |proj g|=        1.7897
At iterate     9  f =       -753.1  |proj g|=        1.7416
At iterate    10  f =       -753.1  |proj g|=        1.7377
At iterate    11  f =       -753.1  |proj g|=        1.7434
At iterate    12  f =       -753.1  |proj g|=        1.7318
At iterate    13  f =      -753.46  |proj g|=        1.5783
At iterate    14  f =         -755  |proj g|=         1.192
At iterate    15  f =      -755.49  |proj g|=        1.1343
At iterate    16  f =      -755.54  |proj g|=         1.085
At iterate    17  f =      -755.55  |proj g|=        1.0649
At iterate    18  f =      -755.55  |proj g|=        1.0513
At iterate    19  f =      -755.55  |proj g|=        1.0497
At iterate    20  f =      -755.55  |proj g|=        1.0499

iterations 20
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.04986
final function value -755.551

F = -755.551
final  value -755.550653 
converged
 
INFO  [05:33:14.727] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:33:14.804] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:33:14.810] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:33:21.610] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:33:29.273] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:33:37.395] [mlr3]  Finished benchmark 
INFO  [05:33:37.521] [bbotk] Result of batch 169: 
INFO  [05:33:37.523] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:33:37.523] [bbotk]              5.468046                 3.023136                      0.06507692 
INFO  [05:33:37.523] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:33:37.523] [bbotk]                     3209        0.972 -0.9614971         <NA>   0.9681084 
INFO  [05:33:37.523] [bbotk]                                 uhash 
INFO  [05:33:37.523] [bbotk]  c290a954-e4af-4fcc-95d2-6594e15342ed 
DEBUG [05:33:37.595] [bbotk]  
INFO  [05:33:37.611] [bbotk] Finished optimizing after 200 evaluation(s) 
INFO  [05:33:37.612] [bbotk] Result: 
INFO  [05:33:37.615] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:33:37.615] [bbotk]              7.654452                 8.495489                       0.4972141 
INFO  [05:33:37.615] [bbotk]  ps_cboost_anneal2.mstop learner_param_vals  x_domain classif.auc 
INFO  [05:33:37.615] [bbotk]                     4962         <list[19]> <list[4]>   0.9766631 
INFO  [05:33:49.022] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2.tuned' on task 'spam' (iter 1/5) 
INFO  [05:33:49.215] [bbotk] Starting to optimize 4 parameter(s) with '<OptimizerInterMBO>' and '<TerminatorEvals> [n_evals=200]' 
DEBUG [05:33:49.284] [bbotk]  
INFO  [05:33:49.291] [bbotk] Evaluating 32 configuration(s) 
INFO  [05:33:51.794] [mlr3]  Running benchmark with 96 resampling iterations 
INFO  [05:33:51.801] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:33:53.682] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:34:02.871] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:34:11.448] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:34:21.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:34:29.024] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:34:29.860] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:34:33.231] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:34:34.474] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:34:45.116] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:34:47.639] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:34:59.124] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:35:03.050] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:35:09.080] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:35:10.544] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:35:14.550] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:35:21.539] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:35:22.623] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:35:23.837] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:35:29.429] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:35:32.745] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:35:45.145] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:35:50.631] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:35:59.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:36:07.437] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:36:08.901] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:36:13.178] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:36:18.521] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:36:23.222] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:36:25.804] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:36:29.336] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:36:31.745] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:36:39.356] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:36:47.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:36:54.933] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:36:59.538] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:37:00.559] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:37:02.987] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:37:04.220] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:37:09.537] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:37:14.482] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:37:20.647] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:37:22.333] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:37:26.113] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:37:27.925] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:37:31.771] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:37:35.621] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:37:42.839] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:37:48.413] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:37:51.554] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:37:55.889] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:38:05.487] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:38:11.735] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:38:19.438] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:38:29.642] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:38:34.086] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:38:35.943] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:38:42.490] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:38:48.722] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:38:54.091] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:39:02.499] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:39:04.032] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:39:15.176] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:39:20.084] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:39:21.962] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:39:29.962] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:39:35.927] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:39:48.497] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:39:52.389] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:39:58.984] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:40:04.190] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:40:14.968] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:40:17.736] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:40:30.856] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:40:41.029] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:40:54.472] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:41:03.530] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:41:11.112] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:41:17.466] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:41:20.408] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:41:22.860] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:41:26.220] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:41:29.238] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:41:36.512] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:41:44.871] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:41:49.952] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:41:52.403] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:42:03.901] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:42:09.565] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:42:12.168] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:42:21.716] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:42:26.926] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:42:33.378] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:42:34.259] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:42:42.025] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:42:51.325] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:42:58.659] [mlr3]  Finished benchmark 
INFO  [05:43:01.577] [bbotk] Result of batch 1: 
INFO  [05:43:01.580] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:43:01.580] [bbotk]              6.465655                 6.015830                      0.27437258 
INFO  [05:43:01.580] [bbotk]              7.274568                 6.866384                      0.19441177 
INFO  [05:43:01.580] [bbotk]              5.553751                 8.283651                      0.07470661 
INFO  [05:43:01.580] [bbotk]              8.936164                 4.372708                      0.42236146 
INFO  [05:43:01.580] [bbotk]              4.313169                 8.517967                      0.22006641 
INFO  [05:43:01.580] [bbotk]              3.816244                 8.038559                      0.24687340 
INFO  [05:43:01.580] [bbotk]              7.749313                 3.697903                      0.11711022 
INFO  [05:43:01.580] [bbotk]              5.375964                 5.128769                      0.41528201 
INFO  [05:43:01.580] [bbotk]              6.835418                 8.758966                      0.48097890 
INFO  [05:43:01.580] [bbotk]              4.803215                 2.758832                      0.33198546 
INFO  [05:43:01.580] [bbotk]              8.728190                 7.347052                      0.10640340 
INFO  [05:43:01.580] [bbotk]              7.220392                 5.294330                      0.29562477 
INFO  [05:43:01.580] [bbotk]              7.773623                 7.074984                      0.39521919 
INFO  [05:43:01.580] [bbotk]              3.507812                 4.186036                      0.06260783 
INFO  [05:43:01.580] [bbotk]              9.533375                 7.971203                      0.21399019 
INFO  [05:43:01.580] [bbotk]              3.267651                 5.896713                      0.16665469 
INFO  [05:43:01.580] [bbotk]              4.239082                 6.629240                      0.32385432 
INFO  [05:43:01.580] [bbotk]              3.193578                 3.479247                      0.25332737 
INFO  [05:43:01.580] [bbotk]              5.865962                 9.077312                      0.29825278 
INFO  [05:43:01.580] [bbotk]              8.484400                 3.189597                      0.08760682 
INFO  [05:43:01.580] [bbotk]              6.590564                 2.692558                      0.02623131 
INFO  [05:43:01.580] [bbotk]              8.110766                 9.539163                      0.15161240 
INFO  [05:43:01.580] [bbotk]              2.135188                 5.686190                      0.44368341 
INFO  [05:43:01.580] [bbotk]              6.050053                 4.941442                      0.36251096 
INFO  [05:43:01.580] [bbotk]              9.312095                 6.280867                      0.35549568 
INFO  [05:43:01.580] [bbotk]              2.953956                 3.890139                      0.18128777 
INFO  [05:43:01.580] [bbotk]              2.307258                 2.199089                      0.01614831 
INFO  [05:43:01.580] [bbotk]              9.902219                 4.611624                      0.13553854 
INFO  [05:43:01.580] [bbotk]              9.117838                 9.356462                      0.46332448 
INFO  [05:43:01.580] [bbotk]              2.571790                 9.998654                      0.38699038 
INFO  [05:43:01.580] [bbotk]              5.074862                 2.364182                      0.48952878 
INFO  [05:43:01.580] [bbotk]              4.621883                 7.687701                      0.03585721 
INFO  [05:43:01.580] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:43:01.580] [bbotk]  ps_cboost_anneal2.mstop classif.auc                                uhash 
INFO  [05:43:01.580] [bbotk]                     2808   0.9745907 c873100b-8e71-456d-98a7-edc15efcc175 
INFO  [05:43:01.580] [bbotk]                     2952   0.9740092 5e10927b-e9b0-401d-a00e-4ff56a391290 
INFO  [05:43:01.580] [bbotk]                     3860   0.9702970 d84f77ab-c65c-485c-9b4e-f648fa5c8e60 
INFO  [05:43:01.580] [bbotk]                      650   0.9710154 8631e689-9192-4827-bbbc-d00d99dcfa2f 
INFO  [05:43:01.580] [bbotk]                     4042   0.9736176 ae613d65-4140-4c55-b4aa-ebf885157fa0 
INFO  [05:43:01.580] [bbotk]                     1592   0.9687609 68d2eacc-8f10-4920-b2e3-7c1b4c9d5131 
INFO  [05:43:01.580] [bbotk]                     2607   0.9712140 2d68c540-2894-448a-8e8d-23a312c897b7 
INFO  [05:43:01.580] [bbotk]                     3436   0.9762768 6c50f4eb-64cb-4f82-8725-9bce80c73995 
INFO  [05:43:01.580] [bbotk]                     1539   0.9745157 ee7aa68c-bf34-4800-8641-4d5e6b1e52ec 
INFO  [05:43:01.580] [bbotk]                     4438   0.9759971 aed0568d-829c-4cd7-9c7f-04b76edebd89 
INFO  [05:43:01.580] [bbotk]                     2016   0.9695505 156a25ae-fda3-4b00-bb21-206480277eb0 
INFO  [05:43:01.580] [bbotk]                     3621   0.9755291 00cc1ccc-4985-4fe6-9370-fc48c42c91a8 
INFO  [05:43:01.580] [bbotk]                     2586   0.9756266 ab3c04ba-66f6-4a44-b193-c6ea7311912e 
INFO  [05:43:01.580] [bbotk]                     3167   0.9619485 499664a9-9ae8-43be-81cf-482c728a5afc 
INFO  [05:43:01.580] [bbotk]                      522   0.9643146 057e32e5-1f6d-4f16-a59e-266cb1314c02 
INFO  [05:43:01.580] [bbotk]                      423   0.9469060 0c07b05b-f159-442f-b415-2eeda52c834d 
INFO  [05:43:01.580] [bbotk]                     3657   0.9744649 90e629a6-2cba-47b8-82ef-753a73c3063e 
INFO  [05:43:01.580] [bbotk]                     1854   0.9670746 d07ce882-02cb-4970-aab0-0e5702b0f475 
INFO  [05:43:01.580] [bbotk]                     1117   0.9714389 59be3a46-6e6a-4b31-afdc-847b53c5e490 
INFO  [05:43:01.580] [bbotk]                     4747   0.9730087 c7fd8fb7-9f7a-4cfd-99cc-482e034b524f 
INFO  [05:43:01.580] [bbotk]                     1302   0.9478952 03f73545-0981-4e04-9fc4-dc33bf4033dc 
INFO  [05:43:01.580] [bbotk]                     4248   0.9745031 f1dc51e1-ffdd-41f7-92ed-33b35e824b7c 
INFO  [05:43:01.580] [bbotk]                     2448   0.9621998 04af3e4b-f0bc-49b5-8a05-35d623525256 
INFO  [05:43:01.580] [bbotk]                      982   0.9719159 cabfb8ed-75d7-443e-b1a4-7bab3d16b5af 
INFO  [05:43:01.580] [bbotk]                     4972   0.9754126 a6a6c781-0815-4208-b426-f0026bb1b6e3 
INFO  [05:43:01.580] [bbotk]                     4625   0.9687402 3ebcab24-52e7-4f00-a194-54182764a3c6 
INFO  [05:43:01.580] [bbotk]                      870   0.8842733 682d3b32-8ef6-4945-90ff-c5803f3c0fff 
INFO  [05:43:01.580] [bbotk]                     1847   0.9699718 d1880813-38e3-4644-84ab-ab00de8e13d7 
INFO  [05:43:01.580] [bbotk]                      245   0.9645075 32c05760-2095-4729-b84a-a90370cb8469 
INFO  [05:43:01.580] [bbotk]                     4353   0.9696135 08cb6e36-8189-4ad0-8979-734e87968097 
INFO  [05:43:01.580] [bbotk]                     3234   0.9764242 9494e21c-9db3-4478-a054-5b95942d347e 
INFO  [05:43:01.580] [bbotk]                     2259   0.9566856 8eb6def1-104c-418a-bf11-3d69ecbe8b35 
INFO  [05:43:01.580] [bbotk]  ps_cboost_anneal2.mstop classif.auc                                uhash 
DEBUG [05:43:02.313] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.813674e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.53406 15.59913 0.9467609 9454 
  - variance bounds :  2.813674e-05 0.003465785 
  - best initial criterion value(s) :  96.02952 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -96.03  |proj g|=      0.79559
At iterate     1  f =       -98.93  |proj g|=       0.82756
At iterate     2  f =      -101.46  |proj g|=       0.55542
At iterate     3  f =      -102.48  |proj g|=       0.34037
At iterate     4  f =      -102.53  |proj g|=       0.30998
At iterate     5  f =      -102.58  |proj g|=       0.27937
At iterate     6  f =      -102.62  |proj g|=       0.18561
At iterate     7  f =      -102.62  |proj g|=       0.18676
At iterate     8  f =      -102.62  |proj g|=       0.18684
At iterate     9  f =      -102.62  |proj g|=       0.18681

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.186813
final function value -102.62

F = -102.62
final  value -102.620446 
converged
 
INFO  [05:43:02.318] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:43:02.410] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:43:02.417] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:43:11.662] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:43:21.830] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:43:30.609] [mlr3]  Finished benchmark 
INFO  [05:43:30.713] [bbotk] Result of batch 2: 
INFO  [05:43:30.715] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:43:30.715] [bbotk]              7.623801                 3.293886                       0.1520259 
INFO  [05:43:30.715] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:43:30.715] [bbotk]                     4266        0.479 -0.9660434         <NA>   0.9744149 
INFO  [05:43:30.715] [bbotk]                                 uhash 
INFO  [05:43:30.715] [bbotk]  df79e296-c571-4ebf-a508-5594d9b31c29 
DEBUG [05:43:31.383] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.744091e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.53406 15.59913 0.9467609 9454 
  - variance bounds :  2.744091e-05 0.003451239 
  - best initial criterion value(s) :  101.6442 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -101.64  |proj g|=      0.63566
At iterate     1  f =       -103.6  |proj g|=        1.5266
At iterate     2  f =      -103.66  |proj g|=        1.4603
At iterate     3  f =      -103.71  |proj g|=        1.3133
At iterate     4  f =      -103.72  |proj g|=        1.3293
At iterate     5  f =      -103.81  |proj g|=        1.3856
At iterate     6  f =      -103.94  |proj g|=        1.3951
At iterate     7  f =      -104.07  |proj g|=        1.3151
At iterate     8  f =      -104.17  |proj g|=         1.122
At iterate     9  f =      -104.17  |proj g|=        1.1251
At iterate    10  f =      -104.17  |proj g|=        1.1259
At iterate    11  f =      -104.17  |proj g|=        1.1253
At iterate    12  f =      -104.17  |proj g|=        1.1254

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.12541
final function value -104.17

F = -104.17
final  value -104.170097 
converged
 
INFO  [05:43:31.387] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:43:31.519] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:43:31.527] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:43:32.809] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:43:34.066] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:43:37.193] [mlr3]  Finished benchmark 
INFO  [05:43:37.295] [bbotk] Result of batch 3: 
INFO  [05:43:37.297] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:43:37.297] [bbotk]              2.503039                 2.201781                       0.2737256 
INFO  [05:43:37.297] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:43:37.297] [bbotk]                      446        0.475 -0.9714412         <NA>   0.9424768 
INFO  [05:43:37.297] [bbotk]                                 uhash 
INFO  [05:43:37.297] [bbotk]  5597eba5-9d0c-43ad-a250-659b3a6ee6ea 
DEBUG [05:43:37.946] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.835946e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.53406 15.59913 0.9467609 9454 
  - variance bounds :  2.835946e-05 0.003569354 
  - best initial criterion value(s) :  104.1245 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -104.12  |proj g|=      0.66418
At iterate     1  f =      -105.04  |proj g|=       0.30363
At iterate     2  f =      -105.04  |proj g|=       0.30423
At iterate     3  f =      -105.04  |proj g|=       0.30511
At iterate     4  f =      -105.04  |proj g|=       0.30496
At iterate     5  f =      -105.04  |proj g|=       0.30496

iterations 5
function evaluations 8
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.304962
final function value -105.037

F = -105.037
final  value -105.037295 
converged
 
INFO  [05:43:37.950] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:43:38.051] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:43:38.058] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:43:42.165] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:43:46.568] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:43:51.831] [mlr3]  Finished benchmark 
INFO  [05:43:51.948] [bbotk] Result of batch 4: 
INFO  [05:43:51.950] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:43:51.950] [bbotk]              9.938922                 6.300721                       0.3622629 
INFO  [05:43:51.950] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:43:51.950] [bbotk]                     1977        0.472 -0.9754992         <NA>   0.9742214 
INFO  [05:43:51.950] [bbotk]                                 uhash 
INFO  [05:43:51.950] [bbotk]  bf62d7b5-cdb6-44ac-a688-cdc33d4a8484 
DEBUG [05:43:52.610] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.771137e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.771137e-05 0.003409885 
  - best initial criterion value(s) :  110.8651 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -110.87  |proj g|=      0.45879
At iterate     1  f =      -111.02  |proj g|=       0.45141
At iterate     2  f =      -111.02  |proj g|=       0.45181
At iterate     3  f =      -111.02  |proj g|=       0.45152
At iterate     4  f =      -111.03  |proj g|=       0.44999
At iterate     5  f =      -111.04  |proj g|=       0.44442
At iterate     6  f =      -111.06  |proj g|=       0.43179
At iterate     7  f =      -111.08  |proj g|=        0.4125
At iterate     8  f =      -111.09  |proj g|=        0.2608
At iterate     9  f =      -111.09  |proj g|=       0.25751
At iterate    10  f =      -111.09  |proj g|=       0.25756
At iterate    11  f =      -111.09  |proj g|=       0.25755

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.257554
final function value -111.091

F = -111.091
final  value -111.091362 
converged
 
INFO  [05:43:52.614] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:43:52.700] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:43:52.707] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:43:56.269] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:43:59.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:44:03.359] [mlr3]  Finished benchmark 
INFO  [05:44:03.455] [bbotk] Result of batch 5: 
INFO  [05:44:03.457] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:44:03.457] [bbotk]              9.273273                 4.316683                       0.4816807 
INFO  [05:44:03.457] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:44:03.457] [bbotk]                     1581        0.476 -0.9739659         <NA>   0.9746653 
INFO  [05:44:03.457] [bbotk]                                 uhash 
INFO  [05:44:03.457] [bbotk]  73005735-1ae3-4e5d-94e4-50d3b6fbe8c9 
DEBUG [05:44:04.117] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.711015e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.711015e-05 0.003220975 
  - best initial criterion value(s) :  116.6619 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -116.66  |proj g|=       0.6286
At iterate     1  f =       -117.2  |proj g|=        1.2242
At iterate     2  f =      -117.91  |proj g|=       0.98683
At iterate     3  f =       -118.3  |proj g|=       0.62482
At iterate     4  f =      -118.36  |proj g|=       0.56638
At iterate     5  f =      -118.65  |proj g|=       0.48713
At iterate     6  f =       -118.8  |proj g|=       0.43877
At iterate     7  f =      -118.81  |proj g|=       0.46791
At iterate     8  f =      -118.81  |proj g|=       0.45769
At iterate     9  f =      -118.81  |proj g|=       0.45762
At iterate    10  f =      -118.81  |proj g|=       0.45776

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.457757
final function value -118.812

F = -118.812
final  value -118.811712 
converged
 
INFO  [05:44:04.122] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:44:04.207] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:44:04.213] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:44:05.013] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:44:06.359] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:44:07.341] [mlr3]  Finished benchmark 
INFO  [05:44:07.439] [bbotk] Result of batch 6: 
INFO  [05:44:07.441] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:44:07.441] [bbotk]              5.741114                 9.565733                        0.193568 
INFO  [05:44:07.441] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:44:07.441] [bbotk]                      250        0.478 -0.9704105         <NA>    0.952059 
INFO  [05:44:07.441] [bbotk]                                 uhash 
INFO  [05:44:07.441] [bbotk]  511a47de-fd63-4007-b275-ad14efc759e5 
DEBUG [05:44:08.166] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.69296e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.69296e-05 0.003189623 
  - best initial criterion value(s) :  117.1723 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -117.17  |proj g|=       1.4102
At iterate     1  f =      -117.73  |proj g|=       0.63494
At iterate     2  f =      -118.73  |proj g|=       0.61553
At iterate     3  f =      -119.22  |proj g|=       0.59508
At iterate     4  f =       -119.3  |proj g|=       0.63443
At iterate     5  f =       -119.4  |proj g|=       0.65236
At iterate     6  f =      -119.72  |proj g|=       0.59399
At iterate     7  f =       -119.8  |proj g|=       0.49305
At iterate     8  f =      -119.81  |proj g|=        0.4823
At iterate     9  f =      -119.81  |proj g|=       0.47838
At iterate    10  f =      -119.81  |proj g|=       0.47816
At iterate    11  f =      -119.81  |proj g|=       0.47788
At iterate    12  f =      -119.81  |proj g|=       0.47763
At iterate    13  f =      -119.81  |proj g|=       0.47717
At iterate    14  f =      -119.81  |proj g|=       0.47611
At iterate    15  f =      -119.81  |proj g|=        0.4745
At iterate    16  f =      -119.81  |proj g|=       0.47193
At iterate    17  f =      -119.82  |proj g|=       0.46682
At iterate    18  f =      -119.82  |proj g|=       0.45674
At iterate    19  f =      -119.83  |proj g|=       0.45901
At iterate    20  f =      -119.84  |proj g|=       0.46821
At iterate    21  f =      -119.88  |proj g|=       0.50737
At iterate    22  f =      -119.97  |proj g|=       0.55702
At iterate    23  f =      -120.18  |proj g|=       0.55862
At iterate    24  f =       -120.5  |proj g|=       0.47686
At iterate    25  f =      -120.52  |proj g|=       0.46998
At iterate    26  f =      -120.66  |proj g|=       0.36698
At iterate    27  f =      -120.66  |proj g|=       0.36257
At iterate    28  f =      -120.66  |proj g|=       0.36479
At iterate    29  f =      -120.66  |proj g|=       0.36369
At iterate    30  f =      -120.66  |proj g|=       0.36334
At iterate    31  f =      -120.66  |proj g|=       0.36368
At iterate    32  f =      -120.66  |proj g|=       0.36429
At iterate    33  f =      -120.66  |proj g|=       0.36692
At iterate    34  f =      -120.66  |proj g|=       0.37053
At iterate    35  f =      -120.66  |proj g|=       0.38573
At iterate    36  f =      -120.67  |proj g|=       0.49864
At iterate    37  f =      -120.69  |proj g|=       0.49982
At iterate    38  f =      -120.73  |proj g|=       0.50052
At iterate    39  f =      -120.81  |proj g|=       0.49806
At iterate    40  f =      -120.94  |proj g|=       0.47888
At iterate    41  f =       -121.2  |proj g|=       0.49994
At iterate    42  f =      -121.36  |proj g|=       0.54199
At iterate    43  f =      -121.43  |proj g|=       0.58578
At iterate    44  f =      -121.46  |proj g|=       0.61464
At iterate    45  f =      -121.46  |proj g|=       0.62239
At iterate    46  f =      -121.46  |proj g|=       0.62113
At iterate    47  f =      -121.47  |proj g|=       0.61881
At iterate    48  f =      -121.47  |proj g|=       0.61705
At iterate    49  f =      -121.47  |proj g|=        0.6168
At iterate    50  f =      -121.47  |proj g|=       0.61685
At iterate    51  f =      -121.47  |proj g|=       0.61697
At iterate    52  f =      -121.47  |proj g|=       0.61718
At iterate    53  f =      -121.47  |proj g|=       0.61746
At iterate    54  f =      -121.47  |proj g|=       0.61786
At iterate    55  f =      -121.47  |proj g|=       0.61842
At iterate    56  f =      -121.47  |proj g|=       0.61899
At iterate    57  f =      -121.48  |proj g|=       0.61852
At iterate    58  f =       -121.5  |proj g|=       0.61484
At iterate    59  f =      -121.53  |proj g|=       0.59837
At iterate    60  f =       -121.6  |proj g|=       0.58057
At iterate    61  f =      -121.69  |proj g|=       0.53495
At iterate    62  f =      -121.76  |proj g|=       0.32895
At iterate    63  f =      -121.82  |proj g|=       0.47072
At iterate    64  f =      -121.82  |proj g|=       0.46931
At iterate    65  f =      -121.83  |proj g|=      0.075659
At iterate    66  f =      -121.83  |proj g|=     0.0046265
At iterate    67  f =      -121.83  |proj g|=     0.0024721

iterations 67
function evaluations 76
segments explored during Cauchy searches 69
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00247214
final function value -121.826

F = -121.826
final  value -121.826022 
converged
 
INFO  [05:44:08.171] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:44:08.273] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:44:08.280] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:44:09.629] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:44:11.191] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:44:13.008] [mlr3]  Finished benchmark 
INFO  [05:44:13.109] [bbotk] Result of batch 7: 
INFO  [05:44:13.110] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:44:13.110] [bbotk]              9.526175                 2.322711                       0.3341257 
INFO  [05:44:13.110] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:44:13.110] [bbotk]                      638        0.481 -0.9670516         <NA>   0.9692132 
INFO  [05:44:13.110] [bbotk]                                 uhash 
INFO  [05:44:13.110] [bbotk]  3754032e-18d2-42f5-987f-2fe7af0ae781 
DEBUG [05:44:13.756] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.622535e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.622535e-05 0.003025708 
  - best initial criterion value(s) :  123.6788 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -123.68  |proj g|=      0.68178
At iterate     1  f =      -124.85  |proj g|=       0.61634
At iterate     2  f =      -125.16  |proj g|=       0.60115
At iterate     3  f =      -125.85  |proj g|=       0.52797
At iterate     4  f =      -125.92  |proj g|=       0.50843
At iterate     5  f =      -125.96  |proj g|=       0.27926
At iterate     6  f =      -125.96  |proj g|=       0.15234
At iterate     7  f =      -125.96  |proj g|=       0.15292
At iterate     8  f =      -125.96  |proj g|=       0.15295

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.152953
final function value -125.959

F = -125.959
final  value -125.959068 
converged
 
INFO  [05:44:13.760] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:44:13.864] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:44:13.871] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:44:18.508] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:44:23.212] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:44:27.729] [mlr3]  Finished benchmark 
INFO  [05:44:27.827] [bbotk] Result of batch 8: 
INFO  [05:44:27.829] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:44:27.829] [bbotk]              6.263215                 7.469312                       0.1507618 
INFO  [05:44:27.829] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:44:27.829] [bbotk]                     2132        0.484 -0.9668534         <NA>   0.9713917 
INFO  [05:44:27.829] [bbotk]                                 uhash 
INFO  [05:44:27.829] [bbotk]  75e88e26-fd9b-49e8-8fbb-87d3576d92f1 
DEBUG [05:44:28.713] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.560172e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.560172e-05 0.002907468 
  - best initial criterion value(s) :  124.0616 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -124.06  |proj g|=       1.2922
At iterate     1  f =      -124.56  |proj g|=        2.3131
At iterate     2  f =      -126.39  |proj g|=        2.0717
At iterate     3  f =      -128.85  |proj g|=        1.2657
At iterate     4  f =      -128.98  |proj g|=        1.0067
At iterate     5  f =      -128.99  |proj g|=       0.98015
At iterate     6  f =      -129.03  |proj g|=        0.9177
At iterate     7  f =      -129.06  |proj g|=        0.9092
At iterate     8  f =      -129.08  |proj g|=       0.98657
At iterate     9  f =      -129.08  |proj g|=       0.97659
At iterate    10  f =      -129.08  |proj g|=       0.97403
At iterate    11  f =      -129.08  |proj g|=       0.97402
At iterate    12  f =      -129.08  |proj g|=       0.97404
At iterate    13  f =      -129.08  |proj g|=        0.9741
At iterate    14  f =      -129.08  |proj g|=       0.96896
At iterate    15  f =      -129.08  |proj g|=       0.97002
At iterate    16  f =      -129.08  |proj g|=       0.97212
At iterate    17  f =      -129.08  |proj g|=       0.97408
At iterate    18  f =      -129.09  |proj g|=       0.97479
At iterate    19  f =       -129.1  |proj g|=       0.96991
At iterate    20  f =      -129.13  |proj g|=       0.93041
At iterate    21  f =      -129.13  |proj g|=       0.96715
At iterate    22  f =       -129.2  |proj g|=        0.8817
At iterate    23  f =      -130.12  |proj g|=       0.51669
At iterate    24  f =      -130.23  |proj g|=       0.51352
At iterate    25  f =      -130.26  |proj g|=       0.32714
At iterate    26  f =      -130.26  |proj g|=       0.15368
At iterate    27  f =      -130.26  |proj g|=       0.15347
At iterate    28  f =      -130.26  |proj g|=       0.15291
At iterate    29  f =      -130.26  |proj g|=       0.15277
At iterate    30  f =      -130.26  |proj g|=       0.15276

iterations 30
function evaluations 42
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.152757
final function value -130.258

F = -130.258
final  value -130.257964 
converged
 
INFO  [05:44:28.717] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:44:28.805] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:44:28.813] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:44:36.109] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:44:42.985] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:44:50.283] [mlr3]  Finished benchmark 
INFO  [05:44:50.383] [bbotk] Result of batch 9: 
INFO  [05:44:50.385] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:44:50.385] [bbotk]              5.069836                 6.457112                       0.3172421 
INFO  [05:44:50.385] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:44:50.385] [bbotk]                     3135        0.461 -0.9660202         <NA>   0.9750626 
INFO  [05:44:50.385] [bbotk]                                 uhash 
INFO  [05:44:50.385] [bbotk]  57c53f42-dfdc-4b89-a1e7-7525e3c1d8c2 
DEBUG [05:44:51.056] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.51316e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.51316e-05 0.002909274 
  - best initial criterion value(s) :  133.9428 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -133.94  |proj g|=      0.62932
At iterate     1  f =      -135.06  |proj g|=       0.60303
At iterate     2  f =      -135.15  |proj g|=       0.56723
At iterate     3  f =      -135.42  |proj g|=       0.52834
At iterate     4  f =      -135.47  |proj g|=       0.51322
At iterate     5  f =      -135.52  |proj g|=       0.44755
At iterate     6  f =      -135.52  |proj g|=       0.40643
At iterate     7  f =      -135.52  |proj g|=       0.40917
At iterate     8  f =      -135.52  |proj g|=       0.40933

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.409326
final function value -135.517

F = -135.517
final  value -135.517229 
converged
 
INFO  [05:44:51.060] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:44:51.179] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:44:51.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:45:00.373] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:45:09.753] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:45:20.500] [mlr3]  Finished benchmark 
INFO  [05:45:20.631] [bbotk] Result of batch 10: 
INFO  [05:45:20.633] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:45:20.633] [bbotk]              7.714875                 5.812871                      0.05011135 
INFO  [05:45:20.633] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:45:20.633] [bbotk]                     4459        0.488 -0.9655491         <NA>   0.9695429 
INFO  [05:45:20.633] [bbotk]                                 uhash 
INFO  [05:45:20.633] [bbotk]  82cd81a1-8832-475a-b31e-a086d4d9473b 
DEBUG [05:45:21.312] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.452379e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.452379e-05 0.002885084 
  - best initial criterion value(s) :  136.0429 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -136.04  |proj g|=       1.7143
At iterate     1  f =      -138.71  |proj g|=       0.87939
At iterate     2  f =      -139.46  |proj g|=       0.61132
At iterate     3  f =       -139.9  |proj g|=       0.48404
At iterate     4  f =      -139.91  |proj g|=        0.1359
At iterate     5  f =      -139.91  |proj g|=       0.47822
At iterate     6  f =      -139.92  |proj g|=       0.47744
At iterate     7  f =      -139.92  |proj g|=       0.47012
At iterate     8  f =      -139.93  |proj g|=       0.21745
At iterate     9  f =      -139.93  |proj g|=       0.49533
At iterate    10  f =      -139.93  |proj g|=       0.49546
At iterate    11  f =      -139.93  |proj g|=       0.49555
At iterate    12  f =      -139.93  |proj g|=       0.49556

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.49556
final function value -139.933

F = -139.933
final  value -139.932535 
converged
 
INFO  [05:45:21.316] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:45:21.403] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:45:21.410] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:45:24.430] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:45:27.469] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:45:30.440] [mlr3]  Finished benchmark 
INFO  [05:45:30.572] [bbotk] Result of batch 11: 
INFO  [05:45:30.574] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:45:30.574] [bbotk]              5.942772                 7.879223                       0.4677686 
INFO  [05:45:30.574] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:45:30.574] [bbotk]                     1483        0.493 -0.9653083         <NA>   0.9743789 
INFO  [05:45:30.574] [bbotk]                                 uhash 
INFO  [05:45:30.574] [bbotk]  e7e363d9-236d-4c11-969b-c5a1793f826c 
DEBUG [05:45:31.258] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.406547e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.406547e-05 0.002754957 
  - best initial criterion value(s) :  137.1991 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -137.2  |proj g|=       1.7931
At iterate     1  f =      -138.15  |proj g|=        2.3191
At iterate     2  f =      -138.28  |proj g|=        2.2564
At iterate     3  f =      -138.32  |proj g|=         2.158
At iterate     4  f =      -138.34  |proj g|=         2.169
At iterate     5  f =      -138.37  |proj g|=         2.163
At iterate     6  f =      -138.43  |proj g|=        2.0967
At iterate     7  f =      -138.51  |proj g|=        1.9628
At iterate     8  f =      -138.56  |proj g|=        1.7432
At iterate     9  f =      -138.56  |proj g|=        1.7975
At iterate    10  f =      -138.56  |proj g|=         1.791
At iterate    11  f =      -138.56  |proj g|=        1.7906
At iterate    12  f =      -138.56  |proj g|=        1.7904
At iterate    13  f =      -138.56  |proj g|=        1.7897
At iterate    14  f =      -138.56  |proj g|=        1.7887
At iterate    15  f =      -138.56  |proj g|=        1.7869
At iterate    16  f =      -138.56  |proj g|=        1.7837
At iterate    17  f =      -138.56  |proj g|=        1.7794
At iterate    18  f =      -138.56  |proj g|=        1.7759
At iterate    19  f =      -138.56  |proj g|=        1.7694
At iterate    20  f =      -138.56  |proj g|=        1.7718
At iterate    21  f =      -138.56  |proj g|=        1.7638
At iterate    22  f =      -138.78  |proj g|=        1.6018
At iterate    23  f =      -140.63  |proj g|=       0.63945
At iterate    24  f =      -141.57  |proj g|=       0.59592
At iterate    25  f =      -141.95  |proj g|=       0.55415
At iterate    26  f =      -141.97  |proj g|=       0.55586
At iterate    27  f =      -142.06  |proj g|=       0.52916
At iterate    28  f =      -142.07  |proj g|=       0.50594
At iterate    29  f =      -142.08  |proj g|=       0.50983
At iterate    30  f =      -142.08  |proj g|=       0.51294
At iterate    31  f =      -142.08  |proj g|=       0.51475
At iterate    32  f =      -142.08  |proj g|=       0.51634
At iterate    33  f =      -142.08  |proj g|=       0.51781
At iterate    34  f =      -142.08  |proj g|=       0.51768
At iterate    35  f =      -142.08  |proj g|=       0.51672
At iterate    36  f =      -142.08  |proj g|=       0.51645
At iterate    37  f =      -142.08  |proj g|=       0.51642

iterations 37
function evaluations 45
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.51642
final function value -142.077

F = -142.077
final  value -142.076734 
converged
 
INFO  [05:45:31.263] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:45:31.352] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:45:31.359] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:45:42.781] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:45:50.405] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:45:58.006] [mlr3]  Finished benchmark 
INFO  [05:45:58.105] [bbotk] Result of batch 12: 
INFO  [05:45:58.107] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:45:58.107] [bbotk]              3.523815                 4.051103                        0.343824 
INFO  [05:45:58.107] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:45:58.107] [bbotk]                     4896        0.479 -0.9685238         <NA>   0.9739189 
INFO  [05:45:58.107] [bbotk]                                 uhash 
INFO  [05:45:58.107] [bbotk]  1a725a1f-b4fa-483b-b696-3481dd9f6e5c 
DEBUG [05:45:58.822] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.360711e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.360711e-05 0.002748731 
  - best initial criterion value(s) :  137.5438 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -137.54  |proj g|=       2.0717
At iterate     1  f =      -140.88  |proj g|=        1.9882
At iterate     2  f =       -142.3  |proj g|=         1.719
At iterate     3  f =      -143.55  |proj g|=        1.2291
At iterate     4  f =      -143.83  |proj g|=       0.84935
At iterate     5  f =      -143.98  |proj g|=       0.91513
At iterate     6  f =      -144.81  |proj g|=        1.1062
At iterate     7  f =      -144.98  |proj g|=        1.1633
At iterate     8  f =      -145.04  |proj g|=        1.2223
At iterate     9  f =      -145.05  |proj g|=         1.257
At iterate    10  f =      -145.05  |proj g|=        1.2763
At iterate    11  f =      -145.05  |proj g|=        1.2769
At iterate    12  f =      -145.05  |proj g|=        1.2781
At iterate    13  f =      -145.05  |proj g|=        1.2787
At iterate    14  f =      -145.05  |proj g|=        1.2799
At iterate    15  f =      -145.05  |proj g|=         1.282
At iterate    16  f =      -145.05  |proj g|=        1.2841
At iterate    17  f =      -145.05  |proj g|=        1.2857
At iterate    18  f =      -145.06  |proj g|=        1.2793
At iterate    19  f =      -145.06  |proj g|=         1.299
At iterate    20  f =      -145.08  |proj g|=        1.2752
At iterate    21  f =      -145.69  |proj g|=       0.64815
At iterate    22  f =      -145.74  |proj g|=       0.68384
At iterate    23  f =      -145.74  |proj g|=       0.68054
At iterate    24  f =      -145.74  |proj g|=       0.67664
At iterate    25  f =      -145.74  |proj g|=       0.68382
At iterate    26  f =      -145.74  |proj g|=        0.6817
At iterate    27  f =      -145.74  |proj g|=       0.68018
At iterate    28  f =      -145.74  |proj g|=        0.6846
At iterate    29  f =      -145.74  |proj g|=       0.68032
At iterate    30  f =      -145.75  |proj g|=       0.66625
At iterate    31  f =      -145.76  |proj g|=       0.64405
At iterate    32  f =      -145.81  |proj g|=       0.64423
At iterate    33  f =       -145.9  |proj g|=       0.66397
At iterate    34  f =      -146.14  |proj g|=       0.70099
At iterate    35  f =      -146.59  |proj g|=       0.76326
At iterate    36  f =      -146.68  |proj g|=        0.8288
At iterate    37  f =       -147.4  |proj g|=        0.7807
At iterate    38  f =      -148.74  |proj g|=       0.75049
At iterate    39  f =      -148.83  |proj g|=       0.74896
At iterate    40  f =      -149.03  |proj g|=       0.67886
At iterate    41  f =      -149.04  |proj g|=       0.38776
At iterate    42  f =      -149.04  |proj g|=       0.39314
At iterate    43  f =      -149.04  |proj g|=       0.39553
At iterate    44  f =      -149.04  |proj g|=       0.39705
At iterate    45  f =      -149.05  |proj g|=        0.4001
At iterate    46  f =      -149.05  |proj g|=        0.4048
At iterate    47  f =      -149.05  |proj g|=       0.54582
At iterate    48  f =      -149.05  |proj g|=       0.65573
At iterate    49  f =      -149.05  |proj g|=       0.65894
At iterate    50  f =      -149.07  |proj g|=       0.66685
At iterate    51  f =       -149.1  |proj g|=       0.68463
At iterate    52  f =      -149.16  |proj g|=       0.71353
At iterate    53  f =      -149.17  |proj g|=       0.72605
At iterate    54  f =      -149.17  |proj g|=       0.72625
At iterate    55  f =      -149.17  |proj g|=       0.72558
At iterate    56  f =      -149.17  |proj g|=       0.72486
At iterate    57  f =      -149.18  |proj g|=       0.72335
At iterate    58  f =      -149.18  |proj g|=       0.72098
At iterate    59  f =      -149.18  |proj g|=       0.71727
At iterate    60  f =      -149.18  |proj g|=       0.71643
At iterate    61  f =      -149.18  |proj g|=       0.70921
At iterate    62  f =      -149.24  |proj g|=       0.68805
At iterate    63  f =      -149.59  |proj g|=       0.40526
At iterate    64  f =      -149.91  |proj g|=        0.4032
At iterate    65  f =      -149.98  |proj g|=       0.38253
At iterate    66  f =      -150.02  |proj g|=       0.56897
At iterate    67  f =      -150.04  |proj g|=      0.036525
At iterate    68  f =      -150.04  |proj g|=      0.028399
At iterate    69  f =      -150.04  |proj g|=     0.0014095
At iterate    70  f =      -150.04  |proj g|=     0.0013165
At iterate    71  f =      -150.04  |proj g|=     0.0013165

iterations 71
function evaluations 81
segments explored during Cauchy searches 73
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00131648
final function value -150.043

F = -150.043
final  value -150.042859 
converged
 
INFO  [05:45:58.826] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:45:58.914] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:45:58.921] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:46:01.659] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:46:04.241] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:46:06.915] [mlr3]  Finished benchmark 
INFO  [05:46:07.030] [bbotk] Result of batch 13: 
INFO  [05:46:07.033] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:46:07.033] [bbotk]              7.054611                 9.622374                       0.3935787 
INFO  [05:46:07.033] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:46:07.033] [bbotk]                     1574        0.471 -0.9591438         <NA>   0.9742031 
INFO  [05:46:07.033] [bbotk]                                 uhash 
INFO  [05:46:07.033] [bbotk]  d6a93ddc-8396-4229-870d-e489bb441148 
DEBUG [05:46:07.727] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.317402e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.317402e-05 0.002631802 
  - best initial criterion value(s) :  148.0133 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -148.01  |proj g|=      0.39595
At iterate     1  f =         -150  |proj g|=        0.9232
At iterate     2  f =      -150.02  |proj g|=       0.89126
At iterate     3  f =      -150.05  |proj g|=       0.83883
At iterate     4  f =      -150.08  |proj g|=       0.82617
At iterate     5  f =      -150.18  |proj g|=        0.8426
At iterate     6  f =      -150.29  |proj g|=       0.94488
At iterate     7  f =      -150.32  |proj g|=        1.0341
At iterate     8  f =      -150.32  |proj g|=        1.0627
At iterate     9  f =      -150.32  |proj g|=        1.0676
At iterate    10  f =      -150.32  |proj g|=        1.0677
At iterate    11  f =      -150.32  |proj g|=        1.0676

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.06759
final function value -150.323

F = -150.323
final  value -150.322845 
converged
 
INFO  [05:46:07.731] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:46:07.881] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:46:07.897] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:46:09.016] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:46:10.141] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:46:11.199] [mlr3]  Finished benchmark 
INFO  [05:46:11.323] [bbotk] Result of batch 14: 
INFO  [05:46:11.326] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:46:11.326] [bbotk]              4.118971                 7.887113                       0.1927945 
INFO  [05:46:11.326] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:46:11.326] [bbotk]                      467        0.518 -0.9655452         <NA>   0.9561548 
INFO  [05:46:11.326] [bbotk]                                 uhash 
INFO  [05:46:11.326] [bbotk]  a29650f1-899b-41d5-9e5c-ee791c3a9be8 
DEBUG [05:46:12.018] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.291961e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.291961e-05 0.002577966 
  - best initial criterion value(s) :  149.7374 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -149.74  |proj g|=      0.59592
At iterate     1  f =      -150.39  |proj g|=        0.5567
At iterate     2  f =      -150.39  |proj g|=       0.55664
At iterate     3  f =       -150.4  |proj g|=       0.55506
At iterate     4  f =       -150.4  |proj g|=       0.55144
At iterate     5  f =      -150.41  |proj g|=       0.53966
At iterate     6  f =      -150.42  |proj g|=         0.388
At iterate     7  f =      -150.43  |proj g|=       0.29887
At iterate     8  f =      -150.43  |proj g|=       0.30223
At iterate     9  f =      -150.43  |proj g|=       0.29695
At iterate    10  f =      -150.43  |proj g|=       0.29588

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.295883
final function value -150.428

F = -150.428
final  value -150.428291 
converged
 
INFO  [05:46:12.022] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:46:12.281] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:46:12.289] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:46:13.875] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:46:15.389] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:46:16.954] [mlr3]  Finished benchmark 
INFO  [05:46:17.118] [bbotk] Result of batch 15: 
INFO  [05:46:17.122] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:46:17.122] [bbotk]              5.538724                 4.202581                        0.331623 
INFO  [05:46:17.122] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:46:17.122] [bbotk]                      801        0.508 -0.9725647         <NA>   0.9698028 
INFO  [05:46:17.122] [bbotk]                                 uhash 
INFO  [05:46:17.122] [bbotk]  1c7544e7-fa16-4a1a-b6d3-8dd4ff4a0dac 
DEBUG [05:46:17.881] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.242764e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.242764e-05 0.002473299 
  - best initial criterion value(s) :  156.8042 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -156.8  |proj g|=       1.0074
At iterate     1  f =      -157.92  |proj g|=        1.4951
At iterate     2  f =      -158.28  |proj g|=        1.4538
At iterate     3  f =      -159.03  |proj g|=        1.2348
At iterate     4  f =      -159.11  |proj g|=        1.3084
At iterate     5  f =      -159.13  |proj g|=         1.342
At iterate     6  f =      -159.13  |proj g|=         1.349
At iterate     7  f =      -159.13  |proj g|=        1.3497
At iterate     8  f =      -159.13  |proj g|=        1.3498
At iterate     9  f =      -159.13  |proj g|=        1.3503
At iterate    10  f =      -159.13  |proj g|=        1.3506
At iterate    11  f =      -159.13  |proj g|=        1.3518
At iterate    12  f =      -159.13  |proj g|=        1.3521
At iterate    13  f =      -159.13  |proj g|=        1.3529
At iterate    14  f =      -159.14  |proj g|=        1.3545
At iterate    15  f =      -159.15  |proj g|=        1.3552
At iterate    16  f =      -159.24  |proj g|=        1.3393
At iterate    17  f =      -159.24  |proj g|=        1.3083
At iterate    18  f =      -159.46  |proj g|=        1.2524
At iterate    19  f =      -159.82  |proj g|=        1.1275
At iterate    20  f =      -160.37  |proj g|=       0.93687
At iterate    21  f =         -161  |proj g|=       0.74812
At iterate    22  f =      -161.72  |proj g|=       0.71667
At iterate    23  f =      -161.72  |proj g|=       0.66696
At iterate    24  f =      -162.04  |proj g|=       0.63011
At iterate    25  f =      -162.05  |proj g|=       0.60575
At iterate    26  f =      -162.05  |proj g|=       0.54587
At iterate    27  f =      -162.05  |proj g|=       0.54179
At iterate    28  f =      -162.05  |proj g|=       0.54171
At iterate    29  f =      -162.05  |proj g|=       0.54178

iterations 29
function evaluations 37
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.54178
final function value -162.055

F = -162.055
final  value -162.054594 
converged
 
INFO  [05:46:17.887] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:46:18.012] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:46:18.020] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:46:19.091] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:46:20.150] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:46:21.294] [mlr3]  Finished benchmark 
INFO  [05:46:21.413] [bbotk] Result of batch 16: 
INFO  [05:46:21.416] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:46:21.416] [bbotk]              9.753716                 4.193709                       0.4284394 
INFO  [05:46:21.416] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:46:21.416] [bbotk]                      412         0.54 -0.965751         <NA>   0.9679635 
INFO  [05:46:21.416] [bbotk]                                 uhash 
INFO  [05:46:21.416] [bbotk]  304db4e7-d59e-4638-bbe4-51476fc1ec28 
DEBUG [05:46:22.142] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.19419e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.19419e-05 0.002373986 
  - best initial criterion value(s) :  164.653 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -164.65  |proj g|=      0.37982
At iterate     1  f =      -165.09  |proj g|=       0.78155
At iterate     2  f =       -165.1  |proj g|=       0.75464
At iterate     3  f =       -165.1  |proj g|=       0.73924
At iterate     4  f =       -165.1  |proj g|=       0.72935
At iterate     5  f =      -165.11  |proj g|=       0.71527
At iterate     6  f =      -165.12  |proj g|=       0.71833
At iterate     7  f =      -165.13  |proj g|=       0.76698
At iterate     8  f =      -165.14  |proj g|=       0.80458
At iterate     9  f =      -165.14  |proj g|=       0.81287
At iterate    10  f =      -165.14  |proj g|=        0.8135
At iterate    11  f =      -165.14  |proj g|=       0.81343

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.813434
final function value -165.137

F = -165.137
final  value -165.136641 
converged
 
INFO  [05:46:22.146] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:46:22.455] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:46:22.464] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:46:25.087] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:46:27.655] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:46:30.117] [mlr3]  Finished benchmark 
INFO  [05:46:30.267] [bbotk] Result of batch 17: 
INFO  [05:46:30.270] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:46:30.270] [bbotk]              6.330225                 8.483508                       0.4476678 
INFO  [05:46:30.270] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:46:30.270] [bbotk]                     1568         0.53 -0.9682568         <NA>   0.9744013 
INFO  [05:46:30.270] [bbotk]                                 uhash 
INFO  [05:46:30.270] [bbotk]  2652c147-03c9-47a7-b8eb-6eddb61d245e 
DEBUG [05:46:31.067] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.158736e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.158736e-05 0.002285186 
  - best initial criterion value(s) :  165.4631 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -165.46  |proj g|=       1.4346
At iterate     1  f =      -166.12  |proj g|=        3.9096
At iterate     2  f =      -167.92  |proj g|=        3.6521
At iterate     3  f =      -171.14  |proj g|=        2.6671
At iterate     4  f =      -171.42  |proj g|=        2.2574
At iterate     5  f =      -171.42  |proj g|=        2.1812
At iterate     6  f =      -171.42  |proj g|=        2.2022
At iterate     7  f =      -171.42  |proj g|=        2.2027
At iterate     8  f =      -171.42  |proj g|=        2.2023
At iterate     9  f =      -171.43  |proj g|=        2.1771
At iterate    10  f =      -171.46  |proj g|=        2.0628
At iterate    11  f =      -171.55  |proj g|=        1.8885
At iterate    12  f =      -171.77  |proj g|=        1.5568
At iterate    13  f =      -172.22  |proj g|=        1.0565
At iterate    14  f =      -172.91  |proj g|=       0.59505
At iterate    15  f =      -173.95  |proj g|=       0.62302
At iterate    16  f =      -174.48  |proj g|=       0.57555
At iterate    17  f =      -174.71  |proj g|=       0.43391
At iterate    18  f =      -174.71  |proj g|=       0.25503
At iterate    19  f =      -174.71  |proj g|=       0.25422
At iterate    20  f =      -174.71  |proj g|=        0.2559
At iterate    21  f =      -174.71  |proj g|=       0.25532
At iterate    22  f =      -174.71  |proj g|=       0.25528
At iterate    23  f =      -174.71  |proj g|=       0.25528

iterations 23
function evaluations 31
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.255278
final function value -174.711

F = -174.711
final  value -174.710863 
converged
 
INFO  [05:46:31.072] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:46:31.165] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:46:31.172] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:46:36.614] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:46:42.122] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:46:48.347] [mlr3]  Finished benchmark 
INFO  [05:46:48.468] [bbotk] Result of batch 18: 
INFO  [05:46:48.470] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:46:48.470] [bbotk]              8.467143                 8.984793                       0.2272606 
INFO  [05:46:48.470] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:46:48.470] [bbotk]                     3467        0.556 -0.9626171         <NA>   0.9751138 
INFO  [05:46:48.470] [bbotk]                                 uhash 
INFO  [05:46:48.470] [bbotk]  48d5be66-9499-4e4f-969b-e2dc95bea067 
DEBUG [05:46:49.194] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.126505e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.126505e-05 0.002296185 
  - best initial criterion value(s) :  166.4524 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -166.45  |proj g|=       2.2828
At iterate     1  f =      -175.65  |proj g|=        1.0207
At iterate     2  f =      -176.05  |proj g|=       0.86961
At iterate     3  f =      -176.56  |proj g|=       0.61965
At iterate     4  f =      -176.76  |proj g|=       0.59998
At iterate     5  f =      -177.21  |proj g|=       0.53058
At iterate     6  f =      -177.34  |proj g|=       0.43923
At iterate     7  f =      -177.37  |proj g|=       0.46501
At iterate     8  f =      -177.38  |proj g|=       0.46418
At iterate     9  f =      -177.38  |proj g|=       0.46139
At iterate    10  f =      -177.38  |proj g|=       0.46178
At iterate    11  f =      -177.38  |proj g|=       0.46198
At iterate    12  f =      -177.38  |proj g|=       0.46265
At iterate    13  f =      -177.38  |proj g|=       0.46377
At iterate    14  f =      -177.38  |proj g|=       0.46596
At iterate    15  f =      -177.38  |proj g|=       0.46698
At iterate    16  f =      -177.39  |proj g|=       0.46932
At iterate    17  f =       -177.4  |proj g|=       0.47979
At iterate    18  f =      -177.43  |proj g|=       0.48941
At iterate    19  f =      -177.49  |proj g|=       0.49852
At iterate    20  f =      -177.57  |proj g|=       0.49555
At iterate    21  f =      -177.58  |proj g|=       0.49007
At iterate    22  f =      -177.62  |proj g|=       0.47592
At iterate    23  f =      -177.62  |proj g|=       0.34781
At iterate    24  f =      -177.62  |proj g|=       0.34937
At iterate    25  f =      -177.62  |proj g|=        0.3495
At iterate    26  f =      -177.62  |proj g|=       0.34942

iterations 26
function evaluations 35
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.349416
final function value -177.62

F = -177.62
final  value -177.620002 
converged
 
INFO  [05:46:49.198] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:46:49.283] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:46:49.290] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:46:55.899] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:47:04.001] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:47:09.550] [mlr3]  Finished benchmark 
INFO  [05:47:09.678] [bbotk] Result of batch 19: 
INFO  [05:47:09.680] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:47:09.680] [bbotk]              3.674446                 3.191869                       0.3886921 
INFO  [05:47:09.680] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:47:09.680] [bbotk]                     2709        0.514 -0.9658919         <NA>   0.9727237 
INFO  [05:47:09.680] [bbotk]                                 uhash 
INFO  [05:47:09.680] [bbotk]  dd03a6ae-e19e-44b6-b41e-e888e470c084 
DEBUG [05:47:10.373] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.088833e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.088833e-05 0.002291068 
  - best initial criterion value(s) :  171.2308 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -171.23  |proj g|=      0.60113
At iterate     1  f =      -171.99  |proj g|=       0.57302
At iterate     2  f =      -172.04  |proj g|=       0.57084
At iterate     3  f =      -172.05  |proj g|=       0.56887
At iterate     4  f =      -172.09  |proj g|=        0.5597
At iterate     5  f =      -172.17  |proj g|=       0.52579
At iterate     6  f =      -172.17  |proj g|=         0.279
At iterate     7  f =      -172.17  |proj g|=       0.27956
At iterate     8  f =      -172.17  |proj g|=       0.27961

iterations 8
function evaluations 13
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.279608
final function value -172.172

F = -172.172
final  value -172.171764 
converged
 
INFO  [05:47:10.377] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:47:10.463] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:47:10.469] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:47:13.937] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:47:17.564] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:47:21.283] [mlr3]  Finished benchmark 
INFO  [05:47:21.381] [bbotk] Result of batch 20: 
INFO  [05:47:21.383] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:47:21.383] [bbotk]              4.294665                 5.930554                       0.1200751 
INFO  [05:47:21.383] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:47:21.383] [bbotk]                     1409        0.509  -0.97199         <NA>   0.9637126 
INFO  [05:47:21.383] [bbotk]                                 uhash 
INFO  [05:47:21.383] [bbotk]  be57d5e6-778b-4182-91c9-3e197fbc828f 
DEBUG [05:47:22.080] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.04984e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.04984e-05 0.002217014 
  - best initial criterion value(s) :  180.007 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -180.01  |proj g|=       1.4985
At iterate     1  f =      -183.42  |proj g|=        1.2916
At iterate     2  f =      -184.64  |proj g|=        1.0403
At iterate     3  f =      -185.59  |proj g|=       0.65451
At iterate     4  f =       -185.6  |proj g|=       0.63276
At iterate     5  f =       -185.6  |proj g|=       0.63758
At iterate     6  f =      -185.61  |proj g|=       0.65424
At iterate     7  f =      -185.62  |proj g|=       0.66272
At iterate     8  f =      -185.63  |proj g|=       0.66053
At iterate     9  f =      -185.63  |proj g|=       0.65876
At iterate    10  f =      -185.63  |proj g|=       0.65847
At iterate    11  f =      -185.63  |proj g|=       0.65842

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.658415
final function value -185.628

F = -185.628
final  value -185.627785 
converged
 
INFO  [05:47:22.084] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:47:22.193] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:47:22.200] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:47:27.736] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:47:34.370] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:47:40.638] [mlr3]  Finished benchmark 
INFO  [05:47:40.759] [bbotk] Result of batch 21: 
INFO  [05:47:40.761] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:47:40.761] [bbotk]              5.799556                 4.409485                       0.1847113 
INFO  [05:47:40.761] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:47:40.761] [bbotk]                     2745          0.5 -0.9637644         <NA>   0.9733844 
INFO  [05:47:40.761] [bbotk]                                 uhash 
INFO  [05:47:40.761] [bbotk]  0256ee6d-db81-4eae-b35e-62c8274c1870 
DEBUG [05:47:41.485] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.016519e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.016519e-05 0.002211725 
  - best initial criterion value(s) :  185.5373 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -185.54  |proj g|=       1.8156
At iterate     1  f =      -188.92  |proj g|=        1.7305
At iterate     2  f =      -191.13  |proj g|=       0.54854
At iterate     3  f =      -191.17  |proj g|=       0.54271
At iterate     4  f =      -191.17  |proj g|=       0.53814
At iterate     5  f =      -191.17  |proj g|=        0.5403
At iterate     6  f =      -191.17  |proj g|=       0.53948
At iterate     7  f =      -191.17  |proj g|=       0.53942
At iterate     8  f =      -191.17  |proj g|=       0.53916
At iterate     9  f =      -191.17  |proj g|=        0.5388
At iterate    10  f =      -191.17  |proj g|=       0.53831
At iterate    11  f =      -191.17  |proj g|=       0.53765
At iterate    12  f =      -191.17  |proj g|=         0.537
At iterate    13  f =      -191.17  |proj g|=       0.53587
At iterate    14  f =      -191.19  |proj g|=       0.53552
At iterate    15  f =      -191.26  |proj g|=       0.54106
At iterate    16  f =      -191.66  |proj g|=       0.50331
At iterate    17  f =      -191.67  |proj g|=       0.50832
At iterate    18  f =      -191.76  |proj g|=       0.49172
At iterate    19  f =      -191.77  |proj g|=       0.48984
At iterate    20  f =      -191.77  |proj g|=       0.49064
At iterate    21  f =      -191.77  |proj g|=       0.49111
At iterate    22  f =      -191.77  |proj g|=       0.49125
At iterate    23  f =      -191.77  |proj g|=       0.49135
At iterate    24  f =      -191.77  |proj g|=       0.49143

iterations 24
function evaluations 32
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.491426
final function value -191.772

F = -191.772
final  value -191.772088 
converged
 
INFO  [05:47:41.490] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:47:41.577] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:47:41.584] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:47:53.666] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:48:03.081] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:48:12.259] [mlr3]  Finished benchmark 
INFO  [05:48:12.357] [bbotk] Result of batch 22: 
INFO  [05:48:12.359] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:48:12.359] [bbotk]              7.296963                 9.765666                         0.37564 
INFO  [05:48:12.359] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:48:12.359] [bbotk]                     4181        0.512   -0.9612         <NA>   0.9763823 
INFO  [05:48:12.359] [bbotk]                                 uhash 
INFO  [05:48:12.359] [bbotk]  8bc1a1aa-845c-41d8-8637-8df833a0fe18 
DEBUG [05:48:13.248] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.992555e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  1.992555e-05 0.002227214 
  - best initial criterion value(s) :  183.2133 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -183.21  |proj g|=       0.7351
At iterate     1  f =      -184.51  |proj g|=        1.8844
At iterate     2  f =      -185.15  |proj g|=        1.7387
At iterate     3  f =      -186.12  |proj g|=        1.3511
At iterate     4  f =      -186.38  |proj g|=        1.2142
At iterate     5  f =      -186.77  |proj g|=        1.3096
At iterate     6  f =       -186.8  |proj g|=        1.4012
At iterate     7  f =      -187.03  |proj g|=        1.4873
At iterate     8  f =      -187.05  |proj g|=        1.5226
At iterate     9  f =      -187.05  |proj g|=        1.5331
At iterate    10  f =      -187.05  |proj g|=        1.5344
At iterate    11  f =      -187.05  |proj g|=        1.5345

iterations 11
function evaluations 17
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.5345
final function value -187.047

F = -187.047
final  value -187.046726 
converged
 
INFO  [05:48:13.252] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:48:13.360] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:48:13.367] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:48:18.819] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:48:24.894] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:48:29.705] [mlr3]  Finished benchmark 
INFO  [05:48:29.804] [bbotk] Result of batch 23: 
INFO  [05:48:29.806] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:48:29.806] [bbotk]              5.450225                 7.454505                       0.4014732 
INFO  [05:48:29.806] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:48:29.806] [bbotk]                     2627        0.657 -0.9691485         <NA>     0.97555 
INFO  [05:48:29.806] [bbotk]                                 uhash 
INFO  [05:48:29.806] [bbotk]  ef97f246-2b97-4de3-ab70-d8878bcb9ac6 
DEBUG [05:48:30.599] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.966405e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  1.966405e-05 0.002229005 
  - best initial criterion value(s) :  190.4881 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -190.49  |proj g|=       4.1282
At iterate     1  f =      -192.99  |proj g|=        5.5552
At iterate     2  f =      -193.73  |proj g|=        4.8558
At iterate     3  f =      -194.55  |proj g|=        3.4739
At iterate     4  f =      -195.29  |proj g|=        3.0497
At iterate     5  f =      -195.57  |proj g|=        2.6789
At iterate     6  f =      -195.58  |proj g|=        2.7841
At iterate     7  f =      -195.58  |proj g|=        2.7834
At iterate     8  f =      -195.58  |proj g|=        2.7834
At iterate     9  f =      -195.58  |proj g|=        2.7834
At iterate    10  f =      -195.58  |proj g|=        2.7833
At iterate    11  f =      -195.58  |proj g|=        2.7832
At iterate    12  f =      -195.58  |proj g|=        2.7823
At iterate    13  f =      -195.58  |proj g|=        2.7762
At iterate    14  f =      -195.58  |proj g|=        2.7575
At iterate    15  f =      -195.59  |proj g|=        2.7202
At iterate    16  f =      -195.61  |proj g|=        2.6532
At iterate    17  f =      -195.64  |proj g|=        2.5089
At iterate    18  f =      -195.65  |proj g|=         2.553
At iterate    19  f =      -195.73  |proj g|=        2.3513
At iterate    20  f =      -196.72  |proj g|=        1.7668
At iterate    21  f =      -200.04  |proj g|=       0.64291
At iterate    22  f =       -201.1  |proj g|=       0.59363
At iterate    23  f =      -201.53  |proj g|=       0.54946
At iterate    24  f =       -201.6  |proj g|=       0.55208
At iterate    25  f =      -201.72  |proj g|=       0.52203
At iterate    26  f =      -201.74  |proj g|=       0.36469
At iterate    27  f =      -201.75  |proj g|=       0.37017
At iterate    28  f =      -201.75  |proj g|=       0.37206
At iterate    29  f =      -201.75  |proj g|=       0.37258
At iterate    30  f =      -201.75  |proj g|=       0.37272
At iterate    31  f =      -201.75  |proj g|=       0.37291
At iterate    32  f =      -201.75  |proj g|=       0.37266
At iterate    33  f =      -201.75  |proj g|=       0.37249
At iterate    34  f =      -201.75  |proj g|=       0.37251
At iterate    35  f =      -201.75  |proj g|=       0.37254
At iterate    36  f =      -201.75  |proj g|=       0.37257
At iterate    37  f =      -201.75  |proj g|=       0.37247
At iterate    38  f =      -201.75  |proj g|=       0.37259
At iterate    39  f =      -201.75  |proj g|=       0.37205
At iterate    40  f =      -201.75  |proj g|=       0.37165
At iterate    41  f =      -201.75  |proj g|=       0.36902
At iterate    42  f =      -201.75  |proj g|=       0.36894
At iterate    43  f =      -201.75  |proj g|=        0.3637
At iterate    44  f =      -201.77  |proj g|=       0.45481
At iterate    45  f =      -201.82  |proj g|=         0.341
At iterate    46  f =      -201.89  |proj g|=       0.48608
At iterate    47  f =      -201.97  |proj g|=       0.49316
At iterate    48  f =      -202.05  |proj g|=       0.48684
At iterate    49  f =      -202.17  |proj g|=        0.3123
At iterate    50  f =      -202.19  |proj g|=       0.51764
At iterate    51  f =       -202.2  |proj g|=       0.50318
At iterate    52  f =      -202.21  |proj g|=      0.075894
At iterate    53  f =      -202.21  |proj g|=     0.0016058
At iterate    54  f =      -202.21  |proj g|=     0.0016058

iterations 54
function evaluations 68
segments explored during Cauchy searches 56
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00160575
final function value -202.206

F = -202.206
final  value -202.205987 
converged
 
INFO  [05:48:30.603] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:48:30.712] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:48:30.719] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:48:42.279] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:48:53.628] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:49:05.520] [mlr3]  Finished benchmark 
INFO  [05:49:05.643] [bbotk] Result of batch 24: 
INFO  [05:49:05.645] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:49:05.645] [bbotk]              7.693669                 3.940974                       0.4563975 
INFO  [05:49:05.645] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:49:05.645] [bbotk]                     4997        0.529 -0.9605198         <NA>   0.9772556 
INFO  [05:49:05.645] [bbotk]                                 uhash 
INFO  [05:49:05.645] [bbotk]  5a2538f7-2335-45a7-8005-ef95bb1d0981 
DEBUG [05:49:06.439] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.946129e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.946129e-05 0.002246799 
  - best initial criterion value(s) :  197.5651 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -197.57  |proj g|=      0.81054
At iterate     1  f =      -201.12  |proj g|=        3.2865
At iterate     2  f =       -202.4  |proj g|=        2.9241
At iterate     3  f =      -203.49  |proj g|=        2.1328
At iterate     4  f =      -203.52  |proj g|=        1.9157
At iterate     5  f =      -203.54  |proj g|=        1.9689
At iterate     6  f =       -203.6  |proj g|=        2.0575
At iterate     7  f =      -203.64  |proj g|=        2.0532
At iterate     8  f =      -203.66  |proj g|=         1.953
At iterate     9  f =      -203.66  |proj g|=        1.9483
At iterate    10  f =      -203.66  |proj g|=        1.9493
At iterate    11  f =      -203.66  |proj g|=        1.9496
At iterate    12  f =      -203.66  |proj g|=        1.9502
At iterate    13  f =      -203.66  |proj g|=        1.9511
At iterate    14  f =      -203.66  |proj g|=        1.9512
At iterate    15  f =      -203.66  |proj g|=        1.9555
At iterate    16  f =      -203.66  |proj g|=        1.9546
At iterate    17  f =      -203.66  |proj g|=        1.9525
At iterate    18  f =      -203.66  |proj g|=         1.948
At iterate    19  f =      -203.66  |proj g|=        1.9375
At iterate    20  f =      -203.68  |proj g|=        1.9147
At iterate    21  f =      -203.69  |proj g|=        1.8153
At iterate    22  f =      -203.73  |proj g|=        1.7962
At iterate    23  f =      -203.85  |proj g|=        1.6978
At iterate    24  f =      -204.11  |proj g|=        1.4854
At iterate    25  f =       -204.6  |proj g|=        1.1238
At iterate    26  f =      -205.44  |proj g|=       0.64653
At iterate    27  f =      -205.49  |proj g|=       0.50486
At iterate    28  f =      -205.94  |proj g|=       0.46405
At iterate    29  f =      -205.97  |proj g|=       0.40439
At iterate    30  f =      -205.98  |proj g|=       0.40337
At iterate    31  f =      -205.98  |proj g|=       0.40071
At iterate    32  f =      -205.98  |proj g|=       0.40052
At iterate    33  f =      -205.98  |proj g|=       0.40052

iterations 33
function evaluations 42
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.400519
final function value -205.975

F = -205.975
final  value -205.975326 
converged
 
INFO  [05:49:06.444] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:49:06.533] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:49:06.540] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:49:08.370] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:49:09.695] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:49:10.997] [mlr3]  Finished benchmark 
INFO  [05:49:11.097] [bbotk] Result of batch 25: 
INFO  [05:49:11.099] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:49:11.099] [bbotk]              3.231087                 4.844751                       0.1537896 
INFO  [05:49:11.099] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:49:11.099] [bbotk]                      500        0.533 -0.9605737         <NA>   0.9477592 
INFO  [05:49:11.099] [bbotk]                                 uhash 
INFO  [05:49:11.099] [bbotk]  5d110e89-f73e-4711-bc7c-4f4428db394c 
DEBUG [05:49:11.864] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.983943e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.983943e-05 0.002291629 
  - best initial criterion value(s) :  186.1294 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -186.13  |proj g|=         3.15
At iterate     1  f =      -196.97  |proj g|=        2.4285
At iterate     2  f =      -197.24  |proj g|=        2.3318
At iterate     3  f =      -197.66  |proj g|=        1.6984
At iterate     4  f =       -197.8  |proj g|=         1.966
At iterate     5  f =      -198.02  |proj g|=        1.8815
At iterate     6  f =      -198.94  |proj g|=        1.6411
At iterate     7  f =      -199.47  |proj g|=        1.6374
At iterate     8  f =      -199.73  |proj g|=        1.7112
At iterate     9  f =       -199.8  |proj g|=          1.78
At iterate    10  f =      -199.82  |proj g|=        1.8408
At iterate    11  f =      -199.82  |proj g|=        1.8519
At iterate    12  f =      -199.82  |proj g|=        1.8556
At iterate    13  f =      -199.82  |proj g|=        1.8543
At iterate    14  f =      -199.82  |proj g|=        1.8541
At iterate    15  f =      -199.82  |proj g|=        1.8532
At iterate    16  f =      -199.82  |proj g|=        1.8513
At iterate    17  f =      -199.82  |proj g|=        1.8482
At iterate    18  f =      -199.82  |proj g|=        1.8432
At iterate    19  f =      -199.82  |proj g|=        1.8355
At iterate    20  f =      -199.82  |proj g|=        1.8224
At iterate    21  f =      -199.83  |proj g|=        1.8053
At iterate    22  f =      -199.83  |proj g|=        1.7796
At iterate    23  f =      -199.84  |proj g|=        1.7541
At iterate    24  f =      -200.05  |proj g|=        1.4559
At iterate    25  f =       -200.1  |proj g|=        1.4321
At iterate    26  f =       -200.1  |proj g|=        1.4482
At iterate    27  f =       -200.1  |proj g|=        1.4502
At iterate    28  f =       -200.1  |proj g|=        1.4496
At iterate    29  f =       -200.1  |proj g|=        1.4498

iterations 29
function evaluations 38
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.44983
final function value -200.104

F = -200.104
final  value -200.103867 
converged
 
INFO  [05:49:11.868] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:49:11.957] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:49:11.964] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:49:24.024] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:49:33.348] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:49:42.594] [mlr3]  Finished benchmark 
INFO  [05:49:42.733] [bbotk] Result of batch 26: 
INFO  [05:49:42.735] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:49:42.735] [bbotk]               8.24933                 8.280751                       0.1763121 
INFO  [05:49:42.735] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:49:42.735] [bbotk]                     4461        0.534 -0.9651132         <NA>   0.9750776 
INFO  [05:49:42.735] [bbotk]                                 uhash 
INFO  [05:49:42.735] [bbotk]  128d6ab2-b14b-496e-afe4-492218568200 
DEBUG [05:49:43.524] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.95821e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.95821e-05 0.002287198 
  - best initial criterion value(s) :  201.724 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -201.72  |proj g|=       1.8354
At iterate     1  f =      -203.24  |proj g|=        4.7597
At iterate     2  f =      -206.25  |proj g|=        4.3057
At iterate     3  f =      -210.54  |proj g|=        2.8383
At iterate     4  f =      -210.79  |proj g|=        2.3286
At iterate     5  f =      -211.11  |proj g|=        2.1053
At iterate     6  f =      -211.74  |proj g|=        1.8828
At iterate     7  f =      -211.87  |proj g|=        1.8806
At iterate     8  f =       -211.9  |proj g|=        1.8708
At iterate     9  f =       -211.9  |proj g|=        1.8778
At iterate    10  f =       -211.9  |proj g|=         1.893
At iterate    11  f =       -211.9  |proj g|=        1.8874
At iterate    12  f =       -211.9  |proj g|=        1.8869
At iterate    13  f =       -211.9  |proj g|=        1.8863
At iterate    14  f =       -211.9  |proj g|=        1.8841
At iterate    15  f =       -211.9  |proj g|=        1.8797
At iterate    16  f =      -211.91  |proj g|=        1.8717
At iterate    17  f =      -211.92  |proj g|=        1.8637
At iterate    18  f =      -211.95  |proj g|=        1.8315
At iterate    19  f =      -212.02  |proj g|=         1.811
At iterate    20  f =      -212.04  |proj g|=        1.6333
At iterate    21  f =      -212.23  |proj g|=        1.5406
At iterate    22  f =      -213.13  |proj g|=       0.86576
At iterate    23  f =      -213.38  |proj g|=       0.78502
At iterate    24  f =      -214.05  |proj g|=       0.52616
At iterate    25  f =       -214.4  |proj g|=       0.48616
At iterate    26  f =      -214.42  |proj g|=       0.47417
At iterate    27  f =      -214.44  |proj g|=       0.34218
At iterate    28  f =      -214.44  |proj g|=       0.33473
At iterate    29  f =      -214.44  |proj g|=       0.33478
At iterate    30  f =      -214.44  |proj g|=       0.33468
At iterate    31  f =      -214.44  |proj g|=       0.33474

iterations 31
function evaluations 45
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.334738
final function value -214.445

F = -214.445
final  value -214.444735 
converged
 
INFO  [05:49:43.527] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:49:43.611] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:49:43.618] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:49:50.566] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:49:59.306] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:50:06.903] [mlr3]  Finished benchmark 
INFO  [05:50:07.007] [bbotk] Result of batch 27: 
INFO  [05:50:07.028] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:50:07.028] [bbotk]              3.889711                 4.213122                       0.3291948 
INFO  [05:50:07.028] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:50:07.028] [bbotk]                     3349        0.551 -0.9593289         <NA>    0.973422 
INFO  [05:50:07.028] [bbotk]                                 uhash 
INFO  [05:50:07.028] [bbotk]  c79a1042-76f3-4d4b-ba11-93bc33bf0410 
DEBUG [05:50:07.867] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.929355e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.929355e-05 0.002285548 
  - best initial criterion value(s) :  205.757 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -205.76  |proj g|=       1.5868
At iterate     1  f =      -207.64  |proj g|=        2.2425
At iterate     2  f =      -209.95  |proj g|=        2.0617
At iterate     3  f =       -212.5  |proj g|=        1.3994
At iterate     4  f =      -212.52  |proj g|=         1.319
At iterate     5  f =      -212.54  |proj g|=        1.3388
At iterate     6  f =      -212.66  |proj g|=         1.402
At iterate     7  f =      -212.66  |proj g|=        1.4048
At iterate     8  f =      -212.66  |proj g|=        1.4023
At iterate     9  f =      -212.66  |proj g|=        1.4033
At iterate    10  f =      -212.66  |proj g|=        1.4041
At iterate    11  f =      -212.66  |proj g|=        1.4049
At iterate    12  f =      -212.66  |proj g|=        1.4064
At iterate    13  f =      -212.66  |proj g|=        1.4087
At iterate    14  f =      -212.66  |proj g|=        1.4122
At iterate    15  f =      -212.66  |proj g|=        1.4177
At iterate    16  f =      -212.67  |proj g|=        1.4254
At iterate    17  f =      -212.67  |proj g|=        1.4338
At iterate    18  f =      -212.68  |proj g|=        1.4388
At iterate    19  f =      -212.69  |proj g|=        1.4632
At iterate    20  f =      -212.72  |proj g|=        1.4596
At iterate    21  f =      -212.72  |proj g|=        1.4793
At iterate    22  f =      -212.81  |proj g|=        1.4522
At iterate    23  f =      -213.25  |proj g|=          1.32
At iterate    24  f =      -213.85  |proj g|=        1.0692
At iterate    25  f =       -213.9  |proj g|=       0.99044
At iterate    26  f =      -213.91  |proj g|=       0.94841
At iterate    27  f =      -213.91  |proj g|=        0.9607
At iterate    28  f =      -213.91  |proj g|=       0.96697
At iterate    29  f =      -213.91  |proj g|=       0.96582
At iterate    30  f =      -213.91  |proj g|=       0.96628
At iterate    31  f =      -213.91  |proj g|=       0.96755
At iterate    32  f =      -213.91  |proj g|=       0.96931
At iterate    33  f =      -213.91  |proj g|=       0.96959
At iterate    34  f =      -213.91  |proj g|=       0.98882
At iterate    35  f =      -213.91  |proj g|=       0.97884
At iterate    36  f =      -213.91  |proj g|=       0.96645
At iterate    37  f =      -213.92  |proj g|=       0.94352
At iterate    38  f =      -213.92  |proj g|=       0.91027
At iterate    39  f =      -213.94  |proj g|=       0.86982
At iterate    40  f =      -213.96  |proj g|=       0.84236
At iterate    41  f =      -213.97  |proj g|=       0.84776
At iterate    42  f =      -213.98  |proj g|=       0.85219
At iterate    43  f =      -213.98  |proj g|=       0.90919
At iterate    44  f =      -213.98  |proj g|=       0.88276
At iterate    45  f =      -213.98  |proj g|=       0.88095
At iterate    46  f =      -213.99  |proj g|=       0.86657
At iterate    47  f =      -213.99  |proj g|=        0.8533
At iterate    48  f =      -214.01  |proj g|=       0.83935
At iterate    49  f =      -214.05  |proj g|=       0.81161
At iterate    50  f =      -214.16  |proj g|=       0.78274
At iterate    51  f =      -214.38  |proj g|=       0.80995
At iterate    52  f =      -214.42  |proj g|=       0.67368
At iterate    53  f =      -214.88  |proj g|=       0.66539
At iterate    54  f =      -217.19  |proj g|=       0.55023
At iterate    55  f =      -218.83  |proj g|=       0.50547
At iterate    56  f =      -218.96  |proj g|=       0.47929
At iterate    57  f =      -218.99  |proj g|=       0.48628
At iterate    58  f =      -218.99  |proj g|=        0.4873
At iterate    59  f =      -218.99  |proj g|=       0.48806
At iterate    60  f =         -219  |proj g|=       0.48827
At iterate    61  f =      -219.01  |proj g|=       0.48638
At iterate    62  f =      -219.05  |proj g|=       0.47802
At iterate    63  f =       -219.1  |proj g|=       0.45788
At iterate    64  f =       -219.1  |proj g|=       0.45747
At iterate    65  f =      -219.13  |proj g|=       0.24943
At iterate    66  f =      -219.13  |proj g|=      0.082468
At iterate    67  f =      -219.13  |proj g|=     0.0081439
At iterate    68  f =      -219.13  |proj g|=     0.0016005

iterations 68
function evaluations 83
segments explored during Cauchy searches 70
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00160053
final function value -219.135

F = -219.135
final  value -219.134778 
converged
 
INFO  [05:50:07.872] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:50:07.976] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:50:07.983] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:50:13.534] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:50:18.010] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:50:24.278] [mlr3]  Finished benchmark 
INFO  [05:50:24.428] [bbotk] Result of batch 28: 
INFO  [05:50:24.430] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:50:24.430] [bbotk]              2.493728                 8.807273                       0.1425775 
INFO  [05:50:24.430] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:50:24.430] [bbotk]                     2360        0.547 -0.9596499         <NA>   0.9558774 
INFO  [05:50:24.430] [bbotk]                                 uhash 
INFO  [05:50:24.430] [bbotk]  7f3a655c-5f10-4054-890b-59890f1ef6c9 
DEBUG [05:50:25.230] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.920474e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.920474e-05 0.002246085 
  - best initial criterion value(s) :  204.1795 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -204.18  |proj g|=       4.2491
At iterate     1  f =      -205.56  |proj g|=        4.9575
At iterate     2  f =      -206.63  |proj g|=        4.7294
At iterate     3  f =      -208.87  |proj g|=        3.7334
At iterate     4  f =      -209.57  |proj g|=        3.2887
At iterate     5  f =       -210.4  |proj g|=        2.8641
At iterate     6  f =      -210.46  |proj g|=        2.6857
At iterate     7  f =      -210.47  |proj g|=        2.6472
At iterate     8  f =      -210.47  |proj g|=         2.645
At iterate     9  f =      -210.47  |proj g|=        2.6463
At iterate    10  f =      -210.47  |proj g|=        2.6465
At iterate    11  f =      -210.47  |proj g|=        2.6473
At iterate    12  f =      -210.47  |proj g|=        2.6483
At iterate    13  f =      -210.47  |proj g|=        2.6499
At iterate    14  f =      -210.47  |proj g|=        2.6517
At iterate    15  f =      -210.47  |proj g|=        2.6525
At iterate    16  f =      -210.47  |proj g|=        2.6476
At iterate    17  f =      -210.47  |proj g|=        2.6277
At iterate    18  f =      -210.48  |proj g|=        2.5935
At iterate    19  f =      -210.48  |proj g|=        2.5762
At iterate    20  f =      -210.48  |proj g|=        2.5624
At iterate    21  f =      -210.48  |proj g|=        2.5532
At iterate    22  f =      -210.48  |proj g|=        2.5346
At iterate    23  f =      -210.49  |proj g|=        2.5048
At iterate    24  f =       -210.5  |proj g|=        2.4522
At iterate    25  f =      -210.54  |proj g|=        2.3562
At iterate    26  f =      -210.65  |proj g|=        2.1757
At iterate    27  f =      -210.95  |proj g|=        1.8358
At iterate    28  f =      -211.77  |proj g|=        1.2709
At iterate    29  f =      -213.95  |proj g|=        0.6642
At iterate    30  f =         -218  |proj g|=       0.98233
At iterate    31  f =      -218.69  |proj g|=        1.3181
At iterate    32  f =       -219.1  |proj g|=        1.4682
At iterate    33  f =      -219.54  |proj g|=       0.71388
At iterate    34  f =      -219.72  |proj g|=        1.2816
At iterate    35  f =      -219.75  |proj g|=        1.1666
At iterate    36  f =      -219.75  |proj g|=        1.1311
At iterate    37  f =      -219.75  |proj g|=        1.1255
At iterate    38  f =      -219.76  |proj g|=        1.0894
At iterate    39  f =      -219.77  |proj g|=        1.0655
At iterate    40  f =       -219.8  |proj g|=         1.063
At iterate    41  f =      -219.85  |proj g|=        1.1297
At iterate    42  f =      -219.85  |proj g|=        1.4565
At iterate    43  f =      -219.88  |proj g|=        1.3357
At iterate    44  f =      -219.88  |proj g|=          1.32
At iterate    45  f =      -219.88  |proj g|=        1.3213
At iterate    46  f =      -219.88  |proj g|=        1.3214

iterations 46
function evaluations 50
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.32139
final function value -219.883

F = -219.883
final  value -219.882656 
converged
 
INFO  [05:50:25.235] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:50:25.323] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:50:25.330] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:50:27.698] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:50:31.497] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:50:34.047] [mlr3]  Finished benchmark 
INFO  [05:50:34.194] [bbotk] Result of batch 29: 
INFO  [05:50:34.196] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:50:34.196] [bbotk]              7.250383                 4.947886                       0.3629673 
INFO  [05:50:34.196] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:50:34.196] [bbotk]                     1075        0.548 -0.9635331         <NA>   0.9724781 
INFO  [05:50:34.196] [bbotk]                                 uhash 
INFO  [05:50:34.196] [bbotk]  af7f8299-c6a5-495a-b67a-0fb107517217 
DEBUG [05:50:34.952] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.891779e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.891779e-05 0.002171699 
  - best initial criterion value(s) :  203.7622 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -203.76  |proj g|=       1.4222
At iterate     1  f =      -205.93  |proj g|=        1.1276
At iterate     2  f =      -212.92  |proj g|=       0.94676
At iterate     3  f =       -213.2  |proj g|=       0.91706
At iterate     4  f =      -215.98  |proj g|=       0.46728
At iterate     5  f =      -216.33  |proj g|=       0.54129
At iterate     6  f =       -216.4  |proj g|=       0.49063
At iterate     7  f =       -216.4  |proj g|=       0.50222
At iterate     8  f =       -216.4  |proj g|=       0.49744
At iterate     9  f =       -216.4  |proj g|=       0.49749

iterations 9
function evaluations 16
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.497491
final function value -216.398

F = -216.398
final  value -216.398001 
converged
 
INFO  [05:50:34.957] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:50:35.049] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:50:35.056] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:50:39.804] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:50:44.864] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:50:50.644] [mlr3]  Finished benchmark 
INFO  [05:50:50.794] [bbotk] Result of batch 30: 
INFO  [05:50:50.796] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:50:50.796] [bbotk]              5.829983                 8.814078                       0.2610202 
INFO  [05:50:50.796] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:50:50.796] [bbotk]                     2108        0.551 -0.966875         <NA>   0.9736516 
INFO  [05:50:50.796] [bbotk]                                 uhash 
INFO  [05:50:50.796] [bbotk]  e49b9379-3ad6-4881-aa8a-837ea4cdfaaf 
DEBUG [05:50:51.634] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.865962e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.865962e-05 0.002120891 
  - best initial criterion value(s) :  221.3643 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -221.36  |proj g|=       1.0982
At iterate     1  f =      -223.43  |proj g|=        3.2919
At iterate     2  f =      -224.19  |proj g|=        3.0421
At iterate     3  f =      -224.41  |proj g|=        2.4703
At iterate     4  f =      -224.49  |proj g|=         2.735
At iterate     5  f =       -224.5  |proj g|=        2.6983
At iterate     6  f =       -224.5  |proj g|=        2.6935
At iterate     7  f =       -224.5  |proj g|=        2.6965
At iterate     8  f =       -224.5  |proj g|=        2.7238
At iterate     9  f =       -224.5  |proj g|=         2.747
At iterate    10  f =       -224.5  |proj g|=        2.7496
At iterate    11  f =       -224.5  |proj g|=        2.7498
At iterate    12  f =       -224.5  |proj g|=        2.7499
At iterate    13  f =       -224.5  |proj g|=        2.7504
At iterate    14  f =       -224.5  |proj g|=        2.7509
At iterate    15  f =       -224.5  |proj g|=        2.7516
At iterate    16  f =       -224.5  |proj g|=         2.752
At iterate    17  f =       -224.5  |proj g|=        2.7511
At iterate    18  f =       -224.5  |proj g|=        2.7481
At iterate    19  f =      -224.51  |proj g|=        2.7434
At iterate    20  f =      -224.51  |proj g|=        2.7176
At iterate    21  f =      -224.51  |proj g|=        2.7385
At iterate    22  f =      -224.52  |proj g|=        2.7141
At iterate    23  f =      -224.57  |proj g|=        2.5762
At iterate    24  f =      -224.67  |proj g|=        2.4065
At iterate    25  f =      -224.98  |proj g|=        2.0655
At iterate    26  f =      -225.69  |proj g|=        1.6005
At iterate    27  f =      -226.79  |proj g|=       0.87772
At iterate    28  f =       -228.1  |proj g|=        1.6491
At iterate    29  f =      -228.32  |proj g|=         1.524
At iterate    30  f =      -228.47  |proj g|=        1.5302
At iterate    31  f =      -228.48  |proj g|=        1.5049
At iterate    32  f =       -228.5  |proj g|=         1.587
At iterate    33  f =      -228.51  |proj g|=        1.6217
At iterate    34  f =      -228.51  |proj g|=        1.6255
At iterate    35  f =      -228.51  |proj g|=        1.6255

iterations 35
function evaluations 40
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.62553
final function value -228.506

F = -228.506
final  value -228.505527 
converged
 
INFO  [05:50:51.639] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:50:51.732] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:50:51.739] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:51:02.805] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:51:11.427] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:51:19.376] [mlr3]  Finished benchmark 
INFO  [05:51:19.474] [bbotk] Result of batch 31: 
INFO  [05:51:19.476] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:51:19.476] [bbotk]               2.85152                 9.084825                       0.2486683 
INFO  [05:51:19.476] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:51:19.476] [bbotk]                     3857        0.577 -0.9615235         <NA>   0.9687032 
INFO  [05:51:19.476] [bbotk]                                 uhash 
INFO  [05:51:19.476] [bbotk]  6facd3ec-433c-4c75-b9e8-52d7500d45a9 
DEBUG [05:51:20.220] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.835491e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.835491e-05 0.002107591 
  - best initial criterion value(s) :  226.8569 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -226.86  |proj g|=       3.4069
At iterate     1  f =      -234.31  |proj g|=        2.7644
At iterate     2  f =      -236.99  |proj g|=        1.2214
At iterate     3  f =       -237.2  |proj g|=       0.38818
At iterate     4  f =      -237.36  |proj g|=        1.0237
At iterate     5  f =      -237.39  |proj g|=       0.82364
At iterate     6  f =      -237.39  |proj g|=       0.80136
At iterate     7  f =      -237.39  |proj g|=       0.80809
At iterate     8  f =      -237.39  |proj g|=       0.80768

iterations 8
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.807684
final function value -237.392

F = -237.392
final  value -237.392275 
converged
 
INFO  [05:51:20.225] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:51:20.326] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:51:20.333] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:51:23.284] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:51:25.372] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:51:27.669] [mlr3]  Finished benchmark 
INFO  [05:51:27.785] [bbotk] Result of batch 32: 
INFO  [05:51:27.787] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:51:27.787] [bbotk]              5.539778                 5.077414                       0.1466637 
INFO  [05:51:27.787] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:51:27.787] [bbotk]                     1080        0.571 -0.9607006         <NA>    0.965774 
INFO  [05:51:27.787] [bbotk]                                 uhash 
INFO  [05:51:27.787] [bbotk]  46b2f96b-4fd6-445c-ab25-9cf2abfa8521 
DEBUG [05:51:28.598] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.806577e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.806577e-05 0.002051246 
  - best initial criterion value(s) :  234.0395 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -234.04  |proj g|=      0.74003
At iterate     1  f =      -234.67  |proj g|=        1.4095
At iterate     2  f =      -234.68  |proj g|=        1.3818
At iterate     3  f =      -234.69  |proj g|=        1.3517
At iterate     4  f =      -234.71  |proj g|=        1.3376
At iterate     5  f =      -234.75  |proj g|=        1.3588
At iterate     6  f =       -234.8  |proj g|=         1.464
At iterate     7  f =      -234.82  |proj g|=        1.6181
At iterate     8  f =      -234.83  |proj g|=        1.6319
At iterate     9  f =      -234.83  |proj g|=        1.6334
At iterate    10  f =      -234.83  |proj g|=        1.6335
At iterate    11  f =      -234.83  |proj g|=        1.6389
At iterate    12  f =      -234.83  |proj g|=        1.6389
At iterate    13  f =      -234.83  |proj g|=        1.6391
At iterate    14  f =      -234.83  |proj g|=        1.6396
At iterate    15  f =      -234.83  |proj g|=        1.6398
At iterate    16  f =      -234.84  |proj g|=        1.6383
At iterate    17  f =      -234.87  |proj g|=        1.6334
At iterate    18  f =      -234.93  |proj g|=        1.6079
At iterate    19  f =      -235.08  |proj g|=        1.5882
At iterate    20  f =       -235.1  |proj g|=        1.4509
At iterate    21  f =      -235.38  |proj g|=        1.3185
At iterate    22  f =      -237.67  |proj g|=       0.60281
At iterate    23  f =      -238.27  |proj g|=        0.4764
At iterate    24  f =      -238.38  |proj g|=       0.45564
At iterate    25  f =      -238.49  |proj g|=       0.46179
At iterate    26  f =       -238.5  |proj g|=       0.47521
At iterate    27  f =       -238.5  |proj g|=       0.47395
At iterate    28  f =       -238.5  |proj g|=       0.47692
At iterate    29  f =       -238.5  |proj g|=       0.47632
At iterate    30  f =       -238.5  |proj g|=       0.47638

iterations 30
function evaluations 39
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.476379
final function value -238.504

F = -238.504
final  value -238.504460 
converged
 
INFO  [05:51:28.603] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:51:28.690] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:51:28.697] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:51:32.662] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:51:37.294] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:51:41.995] [mlr3]  Finished benchmark 
INFO  [05:51:42.092] [bbotk] Result of batch 33: 
INFO  [05:51:42.094] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:51:42.094] [bbotk]              6.093153                 8.121677                       0.2580556 
INFO  [05:51:42.094] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:51:42.094] [bbotk]                     2014        0.569 -0.9615714         <NA>   0.9734922 
INFO  [05:51:42.094] [bbotk]                                 uhash 
INFO  [05:51:42.094] [bbotk]  d52fda80-382a-4bc5-9a50-fa25f4cf7260 
DEBUG [05:51:42.974] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.782917e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.782917e-05 0.002028808 
  - best initial criterion value(s) :  237.5862 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -237.59  |proj g|=      0.53216
At iterate     1  f =      -237.86  |proj g|=        2.0686
At iterate     2  f =      -239.03  |proj g|=        1.7234
At iterate     3  f =      -239.43  |proj g|=        1.4054
At iterate     4  f =      -239.49  |proj g|=         1.225
At iterate     5  f =      -239.66  |proj g|=        1.1383
At iterate     6  f =      -239.85  |proj g|=        1.0807
At iterate     7  f =      -239.87  |proj g|=        1.0896
At iterate     8  f =      -239.87  |proj g|=         1.083
At iterate     9  f =      -239.87  |proj g|=        1.0856
At iterate    10  f =      -239.87  |proj g|=        1.0856
At iterate    11  f =      -239.87  |proj g|=        1.0995
At iterate    12  f =      -239.89  |proj g|=        1.0926
At iterate    13  f =      -240.02  |proj g|=        1.1791
At iterate    14  f =      -241.06  |proj g|=        1.0272
At iterate    15  f =      -242.97  |proj g|=       0.66219
At iterate    16  f =      -243.49  |proj g|=       0.49675
At iterate    17  f =      -243.55  |proj g|=       0.60529
At iterate    18  f =      -243.57  |proj g|=        0.6241
At iterate    19  f =      -243.58  |proj g|=         0.544
At iterate    20  f =      -243.59  |proj g|=       0.57004
At iterate    21  f =      -243.59  |proj g|=       0.57846
At iterate    22  f =      -243.59  |proj g|=       0.57761
At iterate    23  f =      -243.59  |proj g|=       0.57701
At iterate    24  f =      -243.59  |proj g|=       0.57693

iterations 24
function evaluations 33
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.576931
final function value -243.593

F = -243.593
final  value -243.592757 
converged
 
INFO  [05:51:42.977] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:51:43.057] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:51:43.064] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:51:52.896] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:52:01.568] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:52:09.817] [mlr3]  Finished benchmark 
INFO  [05:52:09.919] [bbotk] Result of batch 34: 
INFO  [05:52:09.921] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:52:09.921] [bbotk]              2.765781                 9.325996                         0.36189 
INFO  [05:52:09.921] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:52:09.921] [bbotk]                     3356        0.631 -0.9610753         <NA>   0.9693128 
INFO  [05:52:09.921] [bbotk]                                 uhash 
INFO  [05:52:09.921] [bbotk]  11e6a97f-cc6d-4eff-b619-9c30f3621953 
DEBUG [05:52:10.885] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.75536e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.75536e-05 0.002019066 
  - best initial criterion value(s) :  237.6261 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -237.63  |proj g|=      0.80373
At iterate     1  f =      -240.23  |proj g|=        4.1968
At iterate     2  f =      -247.74  |proj g|=        2.7475
At iterate     3  f =      -248.81  |proj g|=        1.8126
At iterate     4  f =      -251.32  |proj g|=        1.8836
At iterate     5  f =      -251.64  |proj g|=         2.495
At iterate     6  f =      -251.91  |proj g|=        2.3511
At iterate     7  f =      -251.93  |proj g|=        2.2209
At iterate     8  f =      -251.93  |proj g|=         2.228
At iterate     9  f =      -251.93  |proj g|=        2.2278

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.22784
final function value -251.93

F = -251.93
final  value -251.929952 
converged
 
INFO  [05:52:10.889] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:52:10.992] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:52:10.999] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:52:18.221] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:52:25.395] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:52:33.767] [mlr3]  Finished benchmark 
INFO  [05:52:33.867] [bbotk] Result of batch 35: 
INFO  [05:52:33.869] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:52:33.869] [bbotk]              6.192041                   3.4295                       0.2465971 
INFO  [05:52:33.869] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:52:33.869] [bbotk]                     3391        0.717 -0.9598522         <NA>   0.9748848 
INFO  [05:52:33.869] [bbotk]                                 uhash 
INFO  [05:52:33.869] [bbotk]  5bd3e83f-d7b5-41fe-aaed-d83e4dfd93a2 
DEBUG [05:52:34.951] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.735671e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.735671e-05 0.002020348 
  - best initial criterion value(s) :  237.8078 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -237.81  |proj g|=       6.8547
At iterate     1  f =      -238.02  |proj g|=        6.5732
At iterate     2  f =      -240.88  |proj g|=        5.8273
At iterate     3  f =      -244.59  |proj g|=        3.6911
At iterate     4  f =      -246.72  |proj g|=        1.6714
At iterate     5  f =      -246.82  |proj g|=         1.419
At iterate     6  f =      -247.06  |proj g|=        1.1368
At iterate     7  f =      -247.06  |proj g|=        1.1232
At iterate     8  f =      -247.06  |proj g|=        1.1311
At iterate     9  f =      -247.06  |proj g|=        1.1305
At iterate    10  f =      -247.06  |proj g|=        1.1293
At iterate    11  f =      -247.06  |proj g|=        1.1262
At iterate    12  f =      -247.06  |proj g|=        1.1223
At iterate    13  f =      -247.06  |proj g|=        1.1151
At iterate    14  f =      -247.06  |proj g|=         1.104
At iterate    15  f =      -247.06  |proj g|=        1.0855
At iterate    16  f =      -247.06  |proj g|=        1.0664
At iterate    17  f =      -247.06  |proj g|=        1.0466
At iterate    18  f =      -247.08  |proj g|=       0.98651
At iterate    19  f =      -247.16  |proj g|=       0.79612
At iterate    20  f =      -247.42  |proj g|=       0.71774
At iterate    21  f =      -248.21  |proj g|=       0.69175
At iterate    22  f =      -248.23  |proj g|=       0.69056
At iterate    23  f =       -248.8  |proj g|=        0.6514
At iterate    24  f =      -249.04  |proj g|=       0.61564
At iterate    25  f =      -249.12  |proj g|=       0.58946
At iterate    26  f =      -249.14  |proj g|=       0.58924
At iterate    27  f =      -249.15  |proj g|=       0.15574
At iterate    28  f =      -249.15  |proj g|=        0.3823
At iterate    29  f =      -249.15  |proj g|=       0.10639
At iterate    30  f =      -249.15  |proj g|=       0.10626
At iterate    31  f =      -249.15  |proj g|=       0.10626

iterations 31
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.10626
final function value -249.154

F = -249.154
final  value -249.153828 
converged
 
INFO  [05:52:34.953] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:52:35.047] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:52:35.054] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:52:44.790] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:52:52.782] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:53:03.510] [mlr3]  Finished benchmark 
INFO  [05:53:03.610] [bbotk] Result of batch 36: 
INFO  [05:53:03.612] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:53:03.612] [bbotk]              6.151486                 6.762174                       0.3361601 
INFO  [05:53:03.612] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:53:03.612] [bbotk]                     4007        0.659 -0.9650835         <NA>   0.9760486 
INFO  [05:53:03.612] [bbotk]                                 uhash 
INFO  [05:53:03.612] [bbotk]  094747c8-9205-4ed5-a26e-326e0f342df4 
DEBUG [05:53:04.625] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.718942e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.718942e-05 0.00202726 
  - best initial criterion value(s) :  239.9534 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -239.95  |proj g|=       4.7187
At iterate     1  f =      -242.51  |proj g|=        5.9843
At iterate     2  f =      -249.15  |proj g|=        6.0701
At iterate     3  f =      -250.67  |proj g|=        4.4297
At iterate     4  f =      -251.68  |proj g|=        3.5776
At iterate     5  f =      -251.72  |proj g|=        3.2908
At iterate     6  f =      -251.72  |proj g|=        3.3181
At iterate     7  f =      -251.72  |proj g|=        3.3557
At iterate     8  f =      -251.75  |proj g|=        3.4771
At iterate     9  f =      -251.84  |proj g|=        3.6663
At iterate    10  f =      -252.06  |proj g|=         3.909
At iterate    11  f =       -252.6  |proj g|=        4.0958
At iterate    12  f =      -253.05  |proj g|=        4.4251
At iterate    13  f =      -254.18  |proj g|=        4.1413
At iterate    14  f =      -256.75  |proj g|=        2.6611
At iterate    15  f =      -258.22  |proj g|=         1.841
At iterate    16  f =      -259.38  |proj g|=        1.5763
At iterate    17  f =      -260.63  |proj g|=        1.4077
At iterate    18  f =       -260.9  |proj g|=        1.3272
At iterate    19  f =      -260.92  |proj g|=        1.3786
At iterate    20  f =      -260.94  |proj g|=        1.3285
At iterate    21  f =      -260.94  |proj g|=        1.3304
At iterate    22  f =      -260.94  |proj g|=        1.3312
At iterate    23  f =      -260.94  |proj g|=        1.3319
At iterate    24  f =      -260.94  |proj g|=        1.3318
At iterate    25  f =      -260.94  |proj g|=        1.3314
At iterate    26  f =      -260.94  |proj g|=        1.3307
At iterate    27  f =      -260.94  |proj g|=        1.3295
At iterate    28  f =      -260.94  |proj g|=        1.3288
At iterate    29  f =      -260.94  |proj g|=        1.3261
At iterate    30  f =      -260.94  |proj g|=        1.3254
At iterate    31  f =      -260.95  |proj g|=        1.3238
At iterate    32  f =      -260.97  |proj g|=        1.3122
At iterate    33  f =      -260.99  |proj g|=        1.3024
At iterate    34  f =      -261.06  |proj g|=        1.2773
At iterate    35  f =      -261.07  |proj g|=        1.2184
At iterate    36  f =      -261.19  |proj g|=        1.1961
At iterate    37  f =      -261.36  |proj g|=         1.168
At iterate    38  f =      -261.49  |proj g|=        1.1435
At iterate    39  f =      -261.74  |proj g|=        1.0647
At iterate    40  f =      -262.34  |proj g|=        1.0458
At iterate    41  f =      -262.34  |proj g|=        1.0789
At iterate    42  f =      -265.44  |proj g|=       0.56208
At iterate    43  f =      -266.47  |proj g|=       0.51474
At iterate    44  f =      -266.49  |proj g|=       0.54025
At iterate    45  f =      -266.64  |proj g|=       0.45852
At iterate    46  f =      -266.68  |proj g|=      0.031272
At iterate    47  f =      -266.68  |proj g|=     0.0074143
At iterate    48  f =      -266.68  |proj g|=       0.01279
At iterate    49  f =      -266.68  |proj g|=     0.0012316
At iterate    50  f =      -266.68  |proj g|=     0.0011726

iterations 50
function evaluations 70
segments explored during Cauchy searches 52
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00117264
final function value -266.683

F = -266.683
final  value -266.682991 
converged
 
INFO  [05:53:04.629] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:53:04.751] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:53:04.759] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:53:10.742] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:53:16.618] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:53:23.004] [mlr3]  Finished benchmark 
INFO  [05:53:23.140] [bbotk] Result of batch 37: 
INFO  [05:53:23.142] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:53:23.142] [bbotk]              2.922993                 3.804525                       0.2472936 
INFO  [05:53:23.142] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:53:23.142] [bbotk]                     2858        0.672 -0.9550771         <NA>   0.9676511 
INFO  [05:53:23.142] [bbotk]                                 uhash 
INFO  [05:53:23.142] [bbotk]  f772407b-d917-445b-871c-7e39cad53c6f 
DEBUG [05:53:23.958] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.693325e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.693325e-05 0.002010482 
  - best initial criterion value(s) :  247.482 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -247.48  |proj g|=       6.7012
At iterate     1  f =      -255.06  |proj g|=         3.408
At iterate     2  f =       -263.2  |proj g|=        3.2313
At iterate     3  f =      -264.88  |proj g|=        2.6412
At iterate     4  f =      -266.23  |proj g|=        2.0026
At iterate     5  f =      -266.72  |proj g|=        1.7506
At iterate     6  f =      -267.05  |proj g|=        1.6696
At iterate     7  f =      -267.24  |proj g|=        2.3726
At iterate     8  f =      -267.38  |proj g|=        1.9789
At iterate     9  f =      -267.38  |proj g|=        1.9506
At iterate    10  f =      -267.38  |proj g|=         1.951
At iterate    11  f =      -267.38  |proj g|=        1.9519
At iterate    12  f =      -267.38  |proj g|=        1.9529
At iterate    13  f =      -267.38  |proj g|=        1.9544
At iterate    14  f =      -267.38  |proj g|=        1.9565
At iterate    15  f =      -267.38  |proj g|=        1.9594
At iterate    16  f =      -267.39  |proj g|=        1.9612
At iterate    17  f =      -267.39  |proj g|=        1.9553
At iterate    18  f =      -267.39  |proj g|=        1.9264
At iterate    19  f =       -267.4  |proj g|=        1.8793
At iterate    20  f =       -267.4  |proj g|=        1.8923
At iterate    21  f =      -267.42  |proj g|=         1.826
At iterate    22  f =      -269.39  |proj g|=        1.0123
At iterate    23  f =       -270.6  |proj g|=       0.69786
At iterate    24  f =      -271.08  |proj g|=       0.62779
At iterate    25  f =      -271.09  |proj g|=       0.61971
At iterate    26  f =      -271.09  |proj g|=       0.61465
At iterate    27  f =      -271.09  |proj g|=       0.61914
At iterate    28  f =      -271.09  |proj g|=       0.61963
At iterate    29  f =      -271.09  |proj g|=       0.61999
At iterate    30  f =      -271.09  |proj g|=       0.62335
At iterate    31  f =      -271.09  |proj g|=       0.62344
At iterate    32  f =      -271.09  |proj g|=       0.62868
At iterate    33  f =       -271.1  |proj g|=       0.62553
At iterate    34  f =      -271.12  |proj g|=       0.61941
At iterate    35  f =      -271.16  |proj g|=       0.60558
At iterate    36  f =      -271.25  |proj g|=       0.58025
At iterate    37  f =      -271.51  |proj g|=       0.52955
At iterate    38  f =      -271.52  |proj g|=       0.49647
At iterate    39  f =       -272.1  |proj g|=       0.58899
At iterate    40  f =      -272.66  |proj g|=       0.70286
At iterate    41  f =      -273.05  |proj g|=       0.49921
At iterate    42  f =      -273.16  |proj g|=       0.51816
At iterate    43  f =      -273.17  |proj g|=       0.52315
At iterate    44  f =      -273.17  |proj g|=       0.52302
At iterate    45  f =      -273.17  |proj g|=       0.52437
At iterate    46  f =      -273.18  |proj g|=       0.52267
At iterate    47  f =      -273.18  |proj g|=      0.010486
At iterate    48  f =      -273.18  |proj g|=     0.0010657
At iterate    49  f =      -273.18  |proj g|=    0.00092795

iterations 49
function evaluations 65
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.000927949
final function value -273.181

F = -273.181
final  value -273.180629 
converged
 
INFO  [05:53:23.962] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:53:24.050] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:53:24.057] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:53:36.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:53:47.260] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:53:57.786] [mlr3]  Finished benchmark 
INFO  [05:53:57.887] [bbotk] Result of batch 38: 
INFO  [05:53:57.889] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:53:57.889] [bbotk]                6.6808                 4.563979                        0.162819 
INFO  [05:53:57.889] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:53:57.889] [bbotk]                     4899        0.548 -0.9524348         <NA>   0.9746251 
INFO  [05:53:57.889] [bbotk]                                 uhash 
INFO  [05:53:57.889] [bbotk]  b95d7b23-862e-49a6-8166-890709a245a2 
DEBUG [05:53:58.653] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.674493e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.674493e-05 0.002007394 
  - best initial criterion value(s) :  253.1604 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -253.16  |proj g|=      0.53626
At iterate     1  f =      -262.16  |proj g|=        4.3574
At iterate     2  f =      -262.49  |proj g|=        4.2182
At iterate     3  f =      -262.78  |proj g|=        3.4342
At iterate     4  f =      -262.92  |proj g|=        3.8319
At iterate     5  f =      -262.93  |proj g|=        3.7593
At iterate     6  f =      -262.93  |proj g|=        3.7455
At iterate     7  f =      -262.93  |proj g|=        3.7405
At iterate     8  f =      -262.94  |proj g|=        3.7469
At iterate     9  f =      -262.94  |proj g|=        3.7811
At iterate    10  f =      -262.94  |proj g|=        3.8113
At iterate    11  f =      -262.94  |proj g|=        3.8145
At iterate    12  f =      -262.94  |proj g|=        3.8146

iterations 12
function evaluations 16
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.81457
final function value -262.94

F = -262.94
final  value -262.940479 
converged
 
INFO  [05:53:58.657] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:53:58.780] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:53:58.788] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:54:09.045] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:54:18.918] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:54:30.478] [mlr3]  Finished benchmark 
INFO  [05:54:30.580] [bbotk] Result of batch 39: 
INFO  [05:54:30.582] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:54:30.582] [bbotk]              7.308873                 8.419607                      0.09550453 
INFO  [05:54:30.582] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:54:30.582] [bbotk]                     4468        0.556 -0.9654177         <NA>   0.9729421 
INFO  [05:54:30.582] [bbotk]                                 uhash 
INFO  [05:54:30.582] [bbotk]  406fd400-271f-4030-904f-a46db03e8ec8 
DEBUG [05:54:31.392] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.653374e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.653374e-05 0.00198106 
  - best initial criterion value(s) :  248.0619 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -248.06  |proj g|=       13.851
At iterate     1  f =      -251.53  |proj g|=        3.2651
At iterate     2  f =      -270.11  |proj g|=       0.92302
At iterate     3  f =      -270.45  |proj g|=        1.0094
At iterate     4  f =      -271.37  |proj g|=        0.9929
At iterate     5  f =      -271.65  |proj g|=        1.0174
At iterate     6  f =       -271.7  |proj g|=        1.1762
At iterate     7  f =      -271.74  |proj g|=         1.118
At iterate     8  f =      -271.75  |proj g|=        1.0957
At iterate     9  f =      -271.75  |proj g|=        1.0978
At iterate    10  f =      -271.75  |proj g|=         1.098
At iterate    11  f =      -271.75  |proj g|=        1.0988
At iterate    12  f =      -271.75  |proj g|=        1.0997
At iterate    13  f =      -271.75  |proj g|=        1.1016
At iterate    14  f =      -271.75  |proj g|=        1.1023
At iterate    15  f =      -271.75  |proj g|=        1.1348
At iterate    16  f =      -271.76  |proj g|=        1.1189
At iterate    17  f =      -271.78  |proj g|=        1.0833
At iterate    18  f =      -271.83  |proj g|=        1.0348
At iterate    19  f =      -271.96  |proj g|=       0.95468
At iterate    20  f =      -272.25  |proj g|=       0.85082
At iterate    21  f =      -272.53  |proj g|=       0.69434
At iterate    22  f =      -273.16  |proj g|=       0.64454
At iterate    23  f =      -273.75  |proj g|=       0.78207
At iterate    24  f =         -274  |proj g|=       0.92845
At iterate    25  f =       -274.1  |proj g|=       0.95405
At iterate    26  f =       -274.1  |proj g|=       0.91943
At iterate    27  f =      -274.11  |proj g|=       0.91289
At iterate    28  f =      -274.11  |proj g|=       0.91321
At iterate    29  f =      -274.11  |proj g|=       0.91309
At iterate    30  f =      -274.11  |proj g|=       0.91312

iterations 30
function evaluations 34
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.913118
final function value -274.107

F = -274.107
final  value -274.107401 
converged
 
INFO  [05:54:31.396] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:54:31.517] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:54:31.524] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:54:38.173] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:54:42.796] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:54:47.791] [mlr3]  Finished benchmark 
INFO  [05:54:47.892] [bbotk] Result of batch 40: 
INFO  [05:54:47.894] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:54:47.894] [bbotk]               9.15954                 5.211562                      0.01703478 
INFO  [05:54:47.894] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:54:47.894] [bbotk]                     3100        0.571 -0.9605971         <NA>   0.9549032 
INFO  [05:54:47.894] [bbotk]                                 uhash 
INFO  [05:54:47.894] [bbotk]  2cdd16eb-3964-4b48-aa0e-640715832947 
DEBUG [05:54:48.716] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.655086e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.655086e-05 0.001993631 
  - best initial criterion value(s) :  255.9547 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -255.95  |proj g|=       1.1318
At iterate     1  f =      -256.86  |proj g|=        1.4166
At iterate     2  f =      -258.97  |proj g|=        1.2426
At iterate     3  f =      -260.99  |proj g|=        0.7584
At iterate     4  f =      -262.62  |proj g|=       0.73507
At iterate     5  f =      -262.92  |proj g|=       0.67895
At iterate     6  f =      -263.05  |proj g|=       0.63489
At iterate     7  f =      -263.06  |proj g|=       0.63287
At iterate     8  f =      -263.06  |proj g|=       0.63925
At iterate     9  f =      -263.06  |proj g|=        0.6387
At iterate    10  f =      -263.06  |proj g|=       0.63873
At iterate    11  f =      -263.06  |proj g|=       0.63876
At iterate    12  f =      -263.06  |proj g|=       0.63882
At iterate    13  f =      -263.06  |proj g|=       0.63883
At iterate    14  f =      -263.06  |proj g|=       0.63565
At iterate    15  f =      -263.06  |proj g|=       0.63664
At iterate    16  f =      -263.06  |proj g|=        0.6378
At iterate    17  f =      -263.07  |proj g|=       0.63852
At iterate    18  f =      -263.08  |proj g|=       0.63696
At iterate    19  f =      -263.11  |proj g|=       0.62805
At iterate    20  f =      -263.17  |proj g|=       0.57274
At iterate    21  f =       -263.2  |proj g|=       0.69351
At iterate    22  f =      -263.32  |proj g|=       0.71536
At iterate    23  f =      -263.65  |proj g|=       0.75365
At iterate    24  f =      -264.21  |proj g|=       0.83696
At iterate    25  f =      -265.47  |proj g|=        1.1707
At iterate    26  f =      -265.83  |proj g|=       0.76456
At iterate    27  f =      -265.85  |proj g|=       0.60588
At iterate    28  f =      -265.85  |proj g|=       0.66159
At iterate    29  f =      -265.85  |proj g|=       0.65627
At iterate    30  f =      -265.85  |proj g|=       0.65597

iterations 30
function evaluations 37
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.655974
final function value -265.851

F = -265.851
final  value -265.851140 
converged
 
INFO  [05:54:48.720] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:54:48.810] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:54:48.817] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:54:49.616] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:54:50.508] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:54:51.414] [mlr3]  Finished benchmark 
INFO  [05:54:51.517] [bbotk] Result of batch 41: 
INFO  [05:54:51.519] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:54:51.519] [bbotk]              9.068038                 9.515422                       0.4535842 
INFO  [05:54:51.519] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:54:51.519] [bbotk]                      300        0.571 -0.9665033         <NA>   0.9658915 
INFO  [05:54:51.519] [bbotk]                                 uhash 
INFO  [05:54:51.519] [bbotk]  4161b27b-3a02-4fc9-9e33-179aa26dbf1a 
DEBUG [05:54:52.455] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.632468e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.632468e-05 0.001926424 
  - best initial criterion value(s) :  261.7201 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -261.72  |proj g|=       6.6079
At iterate     1  f =      -262.62  |proj g|=        6.5238
At iterate     2  f =      -267.52  |proj g|=        5.6382
At iterate     3  f =      -268.38  |proj g|=        4.7298
At iterate     4  f =      -269.84  |proj g|=         3.783
At iterate     5  f =      -270.18  |proj g|=        3.2323
At iterate     6  f =      -270.18  |proj g|=        3.2224
At iterate     7  f =      -270.77  |proj g|=        2.9265
At iterate     8  f =      -274.76  |proj g|=        1.8469
At iterate     9  f =      -274.78  |proj g|=        1.7854
At iterate    10  f =      -280.84  |proj g|=       0.95969
At iterate    11  f =         -281  |proj g|=       0.97734
At iterate    12  f =      -285.77  |proj g|=       0.81378
At iterate    13  f =      -287.99  |proj g|=       0.84256
At iterate    14  f =       -288.2  |proj g|=       0.88863
At iterate    15  f =      -288.27  |proj g|=        1.3357
At iterate    16  f =      -288.43  |proj g|=        1.2752
At iterate    17  f =      -288.43  |proj g|=        1.2774
At iterate    18  f =      -288.43  |proj g|=        1.2836
At iterate    19  f =      -288.43  |proj g|=        1.2852
At iterate    20  f =      -288.43  |proj g|=        1.2872
At iterate    21  f =      -288.43  |proj g|=        1.2888
At iterate    22  f =      -288.43  |proj g|=        1.2925
At iterate    23  f =      -288.43  |proj g|=        1.2977
At iterate    24  f =      -288.43  |proj g|=         1.306
At iterate    25  f =      -288.44  |proj g|=         1.316
At iterate    26  f =      -288.44  |proj g|=        1.3291
At iterate    27  f =      -288.44  |proj g|=        1.3406
At iterate    28  f =      -288.44  |proj g|=        1.3557
At iterate    29  f =      -288.45  |proj g|=        1.3641
At iterate    30  f =      -289.43  |proj g|=       0.46642
At iterate    31  f =      -289.62  |proj g|=       0.47041
At iterate    32  f =      -289.65  |proj g|=        0.3818
At iterate    33  f =      -289.65  |proj g|=        0.1271
At iterate    34  f =      -289.65  |proj g|=      0.055489
At iterate    35  f =      -289.65  |proj g|=      0.086817
At iterate    36  f =      -289.65  |proj g|=      0.077875
At iterate    37  f =      -289.65  |proj g|=     0.0037389
At iterate    38  f =      -289.65  |proj g|=     0.0010427

iterations 38
function evaluations 51
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00104266
final function value -289.65

F = -289.65
final  value -289.649740 
converged
 
INFO  [05:54:52.459] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:54:52.591] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:54:52.598] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:54:59.697] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:55:06.610] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:55:14.210] [mlr3]  Finished benchmark 
INFO  [05:55:14.314] [bbotk] Result of batch 42: 
INFO  [05:55:14.315] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:55:14.315] [bbotk]              6.675885                 8.279409                       0.2875017 
INFO  [05:55:14.315] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:55:14.315] [bbotk]                     4502        0.635 -0.952839         <NA>   0.9759466 
INFO  [05:55:14.315] [bbotk]                                 uhash 
INFO  [05:55:14.315] [bbotk]  0422cf34-b5e6-4edf-a1a9-a977da58c669 
DEBUG [05:55:15.131] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.618241e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.618241e-05 0.001927823 
  - best initial criterion value(s) :  276.1237 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -276.12  |proj g|=       2.3459
At iterate     1  f =      -280.14  |proj g|=        1.4699
At iterate     2  f =      -283.02  |proj g|=        2.4542
At iterate     3  f =      -283.33  |proj g|=        2.4324
At iterate     4  f =      -283.47  |proj g|=        2.4103
At iterate     5  f =      -283.49  |proj g|=         2.421
At iterate     6  f =       -283.5  |proj g|=        2.4445
At iterate     7  f =       -283.5  |proj g|=        2.4708
At iterate     8  f =       -283.5  |proj g|=        2.4766
At iterate     9  f =       -283.5  |proj g|=        2.4832
At iterate    10  f =       -283.5  |proj g|=        2.4953
At iterate    11  f =       -283.5  |proj g|=        2.5115
At iterate    12  f =      -283.51  |proj g|=        2.5376
At iterate    13  f =      -283.52  |proj g|=         2.575
At iterate    14  f =      -283.57  |proj g|=        2.6257
At iterate    15  f =      -283.68  |proj g|=        2.6791
At iterate    16  f =      -283.98  |proj g|=        2.6854
At iterate    17  f =      -284.82  |proj g|=        2.4804
At iterate    18  f =       -287.3  |proj g|=        1.8108
At iterate    19  f =      -290.51  |proj g|=        1.0862
At iterate    20  f =      -290.85  |proj g|=       0.84137
At iterate    21  f =      -290.87  |proj g|=       0.79018
At iterate    22  f =      -290.88  |proj g|=       0.77864
At iterate    23  f =      -290.88  |proj g|=       0.78788
At iterate    24  f =      -290.88  |proj g|=       0.80629
At iterate    25  f =      -290.91  |proj g|=       0.81152
At iterate    26  f =      -291.08  |proj g|=       0.78067
At iterate    27  f =      -291.22  |proj g|=       0.78431
At iterate    28  f =       -291.3  |proj g|=       0.71486
At iterate    29  f =      -291.31  |proj g|=       0.68935
At iterate    30  f =      -291.31  |proj g|=       0.68657
At iterate    31  f =      -291.31  |proj g|=       0.68094
At iterate    32  f =      -291.31  |proj g|=       0.68242
At iterate    33  f =      -291.31  |proj g|=       0.68243

iterations 33
function evaluations 40
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.682425
final function value -291.313

F = -291.313
final  value -291.313448 
converged
 
INFO  [05:55:15.135] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:55:15.227] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:55:15.234] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:55:19.059] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:55:23.020] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:55:27.038] [mlr3]  Finished benchmark 
INFO  [05:55:27.143] [bbotk] Result of batch 43: 
INFO  [05:55:27.145] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:55:27.145] [bbotk]              9.415893                 9.891677                       0.4447677 
INFO  [05:55:27.145] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:55:27.145] [bbotk]                     2491        0.561 -0.9531009         <NA>   0.9745886 
INFO  [05:55:27.145] [bbotk]                                 uhash 
INFO  [05:55:27.145] [bbotk]  4e4daa21-2ae1-4b79-a4d7-5775775c95cb 
DEBUG [05:55:28.082] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.601586e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.601585e-05 0.00192404 
  - best initial criterion value(s) :  284.6916 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -284.69  |proj g|=       3.5852
At iterate     1  f =      -284.99  |proj g|=        4.2281
At iterate     2  f =       -285.9  |proj g|=        3.8942
At iterate     3  f =      -287.26  |proj g|=        2.7967
At iterate     4  f =      -287.63  |proj g|=        2.7509
At iterate     5  f =      -287.79  |proj g|=        2.5936
At iterate     6  f =      -287.81  |proj g|=        2.5621
At iterate     7  f =      -287.81  |proj g|=        2.5641
At iterate     8  f =      -287.81  |proj g|=        2.5683
At iterate     9  f =      -287.81  |proj g|=        2.5698
At iterate    10  f =      -287.81  |proj g|=        2.5702
At iterate    11  f =      -287.81  |proj g|=        2.5722
At iterate    12  f =      -287.81  |proj g|=        2.5746
At iterate    13  f =      -287.81  |proj g|=         2.579
At iterate    14  f =      -287.81  |proj g|=        2.5858
At iterate    15  f =      -287.81  |proj g|=        2.5971
At iterate    16  f =      -287.81  |proj g|=        2.6158
At iterate    17  f =      -287.82  |proj g|=        2.6466
At iterate    18  f =      -287.82  |proj g|=        2.6917
At iterate    19  f =      -287.84  |proj g|=        2.7318
At iterate    20  f =      -287.84  |proj g|=        2.6956
At iterate    21  f =      -287.85  |proj g|=        2.7246
At iterate    22  f =      -288.92  |proj g|=          2.28
At iterate    23  f =      -291.79  |proj g|=       0.97132
At iterate    24  f =      -292.31  |proj g|=       0.87789
At iterate    25  f =      -292.46  |proj g|=       0.84764
At iterate    26  f =      -292.46  |proj g|=       0.88896
At iterate    27  f =      -292.48  |proj g|=       0.86711
At iterate    28  f =      -292.48  |proj g|=       0.86472
At iterate    29  f =      -292.48  |proj g|=       0.86502
At iterate    30  f =      -292.48  |proj g|=       0.86498
At iterate    31  f =      -292.48  |proj g|=       0.86497

iterations 31
function evaluations 37
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.864973
final function value -292.483

F = -292.483
final  value -292.482815 
converged
 
INFO  [05:55:28.086] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:55:28.224] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:55:28.232] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:55:34.407] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:55:40.660] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:55:47.043] [mlr3]  Finished benchmark 
INFO  [05:55:47.147] [bbotk] Result of batch 44: 
INFO  [05:55:47.149] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:55:47.149] [bbotk]              9.794227                 7.326729                       0.3670792 
INFO  [05:55:47.149] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:55:47.149] [bbotk]                     3994        0.652 -0.957901         <NA>   0.9747748 
INFO  [05:55:47.149] [bbotk]                                 uhash 
INFO  [05:55:47.149] [bbotk]  1b2fc8e4-4c9d-45c1-b39b-f822c56722b8 
DEBUG [05:55:48.079] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.585553e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.585553e-05 0.001923068 
  - best initial criterion value(s) :  279.3027 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -279.3  |proj g|=      0.54455
At iterate     1  f =      -285.28  |proj g|=        4.7241
At iterate     2  f =      -287.24  |proj g|=        4.4244
At iterate     3  f =      -290.07  |proj g|=        3.3512
At iterate     4  f =       -290.2  |proj g|=        3.0798
At iterate     5  f =       -290.3  |proj g|=         2.989
At iterate     6  f =      -290.77  |proj g|=        2.4642
At iterate     7  f =      -290.92  |proj g|=        2.7487
At iterate     8  f =      -290.92  |proj g|=        2.7561
At iterate     9  f =      -290.92  |proj g|=        2.7653
At iterate    10  f =      -290.92  |proj g|=        2.7652
At iterate    11  f =      -290.92  |proj g|=        2.7646
At iterate    12  f =      -290.92  |proj g|=        2.7639
At iterate    13  f =      -290.92  |proj g|=         2.757
At iterate    14  f =      -290.92  |proj g|=        2.7585
At iterate    15  f =      -290.92  |proj g|=         2.759
At iterate    16  f =      -290.92  |proj g|=        2.7596
At iterate    17  f =      -290.93  |proj g|=        2.7583
At iterate    18  f =      -290.94  |proj g|=        2.7517
At iterate    19  f =      -290.97  |proj g|=        2.7223
At iterate    20  f =      -291.06  |proj g|=        2.6265
At iterate    21  f =      -291.26  |proj g|=        2.4878
At iterate    22  f =      -291.76  |proj g|=         1.864
At iterate    23  f =      -291.83  |proj g|=        2.1706
At iterate    24  f =      -292.95  |proj g|=        1.4062
At iterate    25  f =       -294.6  |proj g|=       0.61673
At iterate    26  f =      -295.16  |proj g|=        0.5493
At iterate    27  f =      -295.18  |proj g|=       0.55553
At iterate    28  f =      -295.32  |proj g|=       0.50069
At iterate    29  f =      -295.33  |proj g|=       0.52281
At iterate    30  f =      -295.34  |proj g|=       0.50725
At iterate    31  f =      -295.34  |proj g|=       0.50617
At iterate    32  f =      -295.34  |proj g|=       0.50629
At iterate    33  f =      -295.34  |proj g|=       0.50642
At iterate    34  f =      -295.34  |proj g|=       0.50647

iterations 34
function evaluations 42
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.506471
final function value -295.341

F = -295.341
final  value -295.340677 
converged
 
INFO  [05:55:48.083] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:55:48.220] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:55:48.228] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:55:52.965] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:55:59.315] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:56:07.360] [mlr3]  Finished benchmark 
INFO  [05:56:07.465] [bbotk] Result of batch 45: 
INFO  [05:56:07.467] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:56:07.467] [bbotk]              5.169822                 7.322134                       0.1702007 
INFO  [05:56:07.467] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:56:07.467] [bbotk]                     3047        0.647 -0.9592248         <NA>   0.9730306 
INFO  [05:56:07.467] [bbotk]                                 uhash 
INFO  [05:56:07.467] [bbotk]  ee580db3-8323-45d2-8ce6-e42a6dfee385 
DEBUG [05:56:08.407] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.567264e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.567264e-05 0.001933586 
  - best initial criterion value(s) :  292.9999 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -293  |proj g|=       6.8602
At iterate     1  f =      -297.26  |proj g|=        6.3548
At iterate     2  f =      -298.55  |proj g|=        5.7557
At iterate     3  f =         -301  |proj g|=        3.7843
At iterate     4  f =      -301.47  |proj g|=        2.5863
At iterate     5  f =      -301.58  |proj g|=        2.4544
At iterate     6  f =      -301.59  |proj g|=        2.4382
At iterate     7  f =      -301.59  |proj g|=         2.427
At iterate     8  f =      -301.59  |proj g|=         2.425
At iterate     9  f =      -301.59  |proj g|=        2.4215
At iterate    10  f =       -301.6  |proj g|=        2.4125
At iterate    11  f =       -301.6  |proj g|=        2.3948
At iterate    12  f =      -301.61  |proj g|=        2.3511
At iterate    13  f =      -301.64  |proj g|=        2.3054
At iterate    14  f =      -301.71  |proj g|=        2.1443
At iterate    15  f =      -301.86  |proj g|=        2.0978
At iterate    16  f =       -302.2  |proj g|=        1.7537
At iterate    17  f =      -303.05  |proj g|=        1.8454
At iterate    18  f =      -304.45  |proj g|=       0.99975
At iterate    19  f =      -306.29  |proj g|=       0.76909
At iterate    20  f =      -307.41  |proj g|=       0.66125
At iterate    21  f =      -308.19  |proj g|=       0.55583
At iterate    22  f =      -308.64  |proj g|=       0.52009
At iterate    23  f =      -308.83  |proj g|=       0.55835
At iterate    24  f =      -308.87  |proj g|=       0.57906
At iterate    25  f =      -308.89  |proj g|=       0.61321
At iterate    26  f =      -308.89  |proj g|=       0.61081
At iterate    27  f =      -308.89  |proj g|=       0.61105
At iterate    28  f =      -308.89  |proj g|=       0.61114

iterations 28
function evaluations 33
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.611145
final function value -308.889

F = -308.889
final  value -308.889015 
converged
 
INFO  [05:56:08.411] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:56:08.500] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:56:08.508] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:56:13.375] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:56:17.497] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:56:21.469] [mlr3]  Finished benchmark 
INFO  [05:56:21.582] [bbotk] Result of batch 46: 
INFO  [05:56:21.584] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:56:21.584] [bbotk]              3.170686                 5.995881                       0.3529919 
INFO  [05:56:21.584] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:56:21.584] [bbotk]                     1764        0.676 -0.9527664         <NA>   0.9686623 
INFO  [05:56:21.584] [bbotk]                                 uhash 
INFO  [05:56:21.584] [bbotk]  2f871fff-5951-4680-9a9e-b92cafb5872b 
DEBUG [05:56:22.446] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.546649e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.546649e-05 0.001889958 
  - best initial criterion value(s) :  284.0975 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -284.1  |proj g|=       6.8386
At iterate     1  f =       -293.6  |proj g|=        2.2579
At iterate     2  f =      -297.78  |proj g|=        1.7157
At iterate     3  f =      -304.64  |proj g|=       0.86864
At iterate     4  f =      -305.13  |proj g|=       0.70833
At iterate     5  f =      -305.77  |proj g|=       0.98017
At iterate     6  f =      -306.76  |proj g|=        1.0769
At iterate     7  f =      -307.06  |proj g|=       0.99284
At iterate     8  f =      -307.15  |proj g|=       0.94537
At iterate     9  f =      -307.17  |proj g|=        0.9047
At iterate    10  f =      -307.17  |proj g|=       0.85582
At iterate    11  f =      -307.17  |proj g|=       0.86918
At iterate    12  f =      -307.17  |proj g|=       0.86875
At iterate    13  f =      -307.17  |proj g|=       0.85429
At iterate    14  f =      -307.19  |proj g|=       0.82419
At iterate    15  f =      -307.26  |proj g|=       0.72802
At iterate    16  f =      -307.43  |proj g|=       0.70891
At iterate    17  f =      -307.76  |proj g|=       0.76759
At iterate    18  f =      -308.16  |proj g|=       0.76426
At iterate    19  f =      -308.24  |proj g|=       0.87064
At iterate    20  f =      -308.73  |proj g|=       0.76616
At iterate    21  f =      -308.88  |proj g|=       0.67983
At iterate    22  f =      -308.88  |proj g|=       0.68447
At iterate    23  f =      -308.88  |proj g|=       0.68535
At iterate    24  f =      -308.88  |proj g|=       0.68596
At iterate    25  f =      -308.88  |proj g|=       0.68586

iterations 25
function evaluations 33
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.685858
final function value -308.883

F = -308.883
final  value -308.883406 
converged
 
INFO  [05:56:22.450] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:56:22.536] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:56:22.543] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:56:27.051] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:56:31.326] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:56:36.703] [mlr3]  Finished benchmark 
INFO  [05:56:36.800] [bbotk] Result of batch 47: 
INFO  [05:56:36.802] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:56:36.802] [bbotk]              9.569554                 9.443247                        0.379177 
INFO  [05:56:36.802] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:56:36.802] [bbotk]                     1947        0.601 -0.9571004         <NA>   0.9745492 
INFO  [05:56:36.802] [bbotk]                                 uhash 
INFO  [05:56:36.802] [bbotk]  e340d17f-82c9-49e5-bb43-a208ff5faac8 
DEBUG [05:56:37.642] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.53135e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.53135e-05 0.001852845 
  - best initial criterion value(s) :  286.9327 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -286.93  |proj g|=       7.0391
At iterate     1  f =      -311.42  |proj g|=        1.3782
At iterate     2  f =      -312.99  |proj g|=        1.2058
At iterate     3  f =      -314.64  |proj g|=        1.1902
At iterate     4  f =      -314.91  |proj g|=       0.77354
At iterate     5  f =      -315.36  |proj g|=       0.77686
At iterate     6  f =      -315.91  |proj g|=       0.73948
At iterate     7  f =      -315.92  |proj g|=       0.78099
At iterate     8  f =      -316.04  |proj g|=       0.73065
At iterate     9  f =      -316.05  |proj g|=       0.73031
At iterate    10  f =      -316.05  |proj g|=       0.72984
At iterate    11  f =      -316.05  |proj g|=       0.73904
At iterate    12  f =      -316.05  |proj g|=        0.7465
At iterate    13  f =      -316.06  |proj g|=       0.75772
At iterate    14  f =      -316.08  |proj g|=       0.78307
At iterate    15  f =      -316.13  |proj g|=       0.80685
At iterate    16  f =      -316.15  |proj g|=       0.96185
At iterate    17  f =      -316.27  |proj g|=        0.8998
At iterate    18  f =      -316.43  |proj g|=       0.84214
At iterate    19  f =      -316.54  |proj g|=       0.81975
At iterate    20  f =      -316.57  |proj g|=       0.87648
At iterate    21  f =      -316.58  |proj g|=       0.88505
At iterate    22  f =      -316.58  |proj g|=       0.86735
At iterate    23  f =      -316.58  |proj g|=       0.87388
At iterate    24  f =      -316.58  |proj g|=       0.87323
At iterate    25  f =      -316.58  |proj g|=       0.87314

iterations 25
function evaluations 29
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.87314
final function value -316.58

F = -316.58
final  value -316.580024 
converged
 
INFO  [05:56:37.646] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:56:37.732] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:56:37.740] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:56:46.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:56:58.139] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:57:08.780] [mlr3]  Finished benchmark 
INFO  [05:57:08.881] [bbotk] Result of batch 48: 
INFO  [05:57:08.883] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:57:08.883] [bbotk]               3.88956                 4.556634                      0.04325312 
INFO  [05:57:08.883] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:57:08.883] [bbotk]                     4417        0.592 -0.9532887         <NA>   0.9635059 
INFO  [05:57:08.883] [bbotk]                                 uhash 
INFO  [05:57:08.883] [bbotk]  8ec9b454-0cb5-41e2-86cb-be6feb7209fc 
DEBUG [05:57:09.690] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.514896e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.514896e-05 0.001838429 
  - best initial criterion value(s) :  296.9284 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -296.93  |proj g|=       2.5611
At iterate     1  f =       -308.1  |proj g|=        5.5804
At iterate     2  f =      -315.75  |proj g|=        2.9687
At iterate     3  f =      -315.79  |proj g|=        2.7378
At iterate     4  f =      -315.79  |proj g|=        2.6958
At iterate     5  f =       -315.8  |proj g|=        2.6786
At iterate     6  f =       -315.8  |proj g|=        2.6706
At iterate     7  f =       -315.8  |proj g|=        2.6708

iterations 7
function evaluations 13
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.67076
final function value -315.797

F = -315.797
final  value -315.797185 
converged
 
INFO  [05:57:09.694] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:57:09.805] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:57:09.811] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:57:15.338] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:57:20.444] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:57:25.730] [mlr3]  Finished benchmark 
INFO  [05:57:25.838] [bbotk] Result of batch 49: 
INFO  [05:57:25.840] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:57:25.840] [bbotk]              3.992889                 4.346374                       0.2146004 
INFO  [05:57:25.840] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:57:25.840] [bbotk]                     2580        0.594 -0.9598124         <NA>   0.9712946 
INFO  [05:57:25.840] [bbotk]                                 uhash 
INFO  [05:57:25.840] [bbotk]  ba93d95c-1e36-4899-b2de-ae39dceaea68 
DEBUG [05:57:26.789] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.496729e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.496729e-05 0.001826289 
  - best initial criterion value(s) :  294.2286 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -294.23  |proj g|=       2.8392
At iterate     1  f =      -311.12  |proj g|=        8.9063
At iterate     2  f =      -313.67  |proj g|=         8.258
At iterate     3  f =       -315.1  |proj g|=        7.2634
At iterate     4  f =       -317.6  |proj g|=        3.3263
At iterate     5  f =         -318  |proj g|=        4.3052
At iterate     6  f =      -318.44  |proj g|=        4.6418
At iterate     7  f =      -318.52  |proj g|=        4.1783
At iterate     8  f =      -318.52  |proj g|=        4.1744
At iterate     9  f =      -318.52  |proj g|=        4.1722
At iterate    10  f =      -318.52  |proj g|=        4.1718
At iterate    11  f =      -318.52  |proj g|=        4.1704
At iterate    12  f =      -318.52  |proj g|=        4.1686
At iterate    13  f =      -318.52  |proj g|=        4.1652
At iterate    14  f =      -318.52  |proj g|=        4.1605
At iterate    15  f =      -318.52  |proj g|=         4.154
At iterate    16  f =      -318.52  |proj g|=        4.1477
At iterate    17  f =      -318.52  |proj g|=        4.1497
At iterate    18  f =      -318.53  |proj g|=        4.1831
At iterate    19  f =      -318.53  |proj g|=         4.284
At iterate    20  f =      -318.53  |proj g|=         4.322
At iterate    21  f =      -318.53  |proj g|=        4.3302
At iterate    22  f =      -318.53  |proj g|=        4.3354
At iterate    23  f =      -318.54  |proj g|=        4.3419
At iterate    24  f =      -318.54  |proj g|=        4.3466
At iterate    25  f =      -318.54  |proj g|=        4.3381
At iterate    26  f =      -318.55  |proj g|=        4.2939
At iterate    27  f =      -318.57  |proj g|=        4.2071
At iterate    28  f =      -318.61  |proj g|=        4.1296
At iterate    29  f =       -318.7  |proj g|=         3.858
At iterate    30  f =      -318.73  |proj g|=         3.981
At iterate    31  f =      -318.99  |proj g|=        3.5083
At iterate    32  f =      -319.81  |proj g|=        2.5007
At iterate    33  f =      -321.42  |proj g|=        1.2641
At iterate    34  f =      -323.74  |proj g|=        0.6343
At iterate    35  f =      -325.13  |proj g|=       0.57272
At iterate    36  f =      -325.15  |proj g|=       0.57496
At iterate    37  f =      -325.65  |proj g|=       0.52704
At iterate    38  f =       -325.7  |proj g|=       0.56601
At iterate    39  f =      -325.81  |proj g|=       0.57415
At iterate    40  f =      -325.83  |proj g|=       0.58743
At iterate    41  f =      -325.83  |proj g|=       0.59505
At iterate    42  f =      -325.83  |proj g|=       0.59855
At iterate    43  f =      -325.83  |proj g|=       0.59837
At iterate    44  f =      -325.83  |proj g|=       0.59836

iterations 44
function evaluations 53
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.598362
final function value -325.829

F = -325.829
final  value -325.828602 
converged
 
INFO  [05:57:26.793] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:57:26.881] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:57:26.888] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:57:32.599] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:57:38.086] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:57:44.010] [mlr3]  Finished benchmark 
INFO  [05:57:44.130] [bbotk] Result of batch 50: 
INFO  [05:57:44.132] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:57:44.132] [bbotk]              8.562471                  2.05746                        0.155721 
INFO  [05:57:44.132] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:57:44.132] [bbotk]                     2592        0.634 -0.9535075         <NA>   0.9728881 
INFO  [05:57:44.132] [bbotk]                                 uhash 
INFO  [05:57:44.132] [bbotk]  c84862c2-bce4-4131-a979-3692194e001b 
DEBUG [05:57:45.054] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.480408e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9467609 9504 
  - variance bounds :  1.480408e-05 0.001816658 
  - best initial criterion value(s) :  315.9825 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -315.98  |proj g|=       1.2976
At iterate     1  f =      -318.38  |proj g|=        2.7051
At iterate     2  f =      -320.44  |proj g|=        2.1996
At iterate     3  f =      -321.65  |proj g|=        1.3482
At iterate     4  f =      -321.66  |proj g|=        1.2447
At iterate     5  f =      -321.66  |proj g|=        1.2691
At iterate     6  f =      -321.67  |proj g|=        1.3057
At iterate     7  f =      -321.68  |proj g|=        1.3558
At iterate     8  f =      -321.69  |proj g|=        1.3899
At iterate     9  f =       -321.7  |proj g|=        1.3628
At iterate    10  f =       -321.7  |proj g|=        1.3462
At iterate    11  f =       -321.7  |proj g|=        1.3425
At iterate    12  f =       -321.7  |proj g|=        1.3419
At iterate    13  f =       -321.7  |proj g|=        1.3418
At iterate    14  f =       -321.7  |proj g|=        1.3401
At iterate    15  f =       -321.7  |proj g|=          1.34
At iterate    16  f =       -321.7  |proj g|=        1.3396
At iterate    17  f =       -321.7  |proj g|=        1.3389
At iterate    18  f =       -321.7  |proj g|=        1.3375
At iterate    19  f =      -321.71  |proj g|=        1.3332
At iterate    20  f =      -321.71  |proj g|=        1.3541
At iterate    21  f =      -321.71  |proj g|=        1.3363
At iterate    22  f =      -321.73  |proj g|=        1.2973
At iterate    23  f =      -321.77  |proj g|=        1.2213
At iterate    24  f =      -321.86  |proj g|=        1.0665
At iterate    25  f =      -322.09  |proj g|=       0.94652
At iterate    26  f =      -322.11  |proj g|=       0.88896
At iterate    27  f =      -322.55  |proj g|=       0.86177
At iterate    28  f =      -323.08  |proj g|=       0.81341
At iterate    29  f =      -323.34  |proj g|=       0.80063
At iterate    30  f =      -323.36  |proj g|=       0.78953
At iterate    31  f =      -323.39  |proj g|=       0.82046
At iterate    32  f =       -323.4  |proj g|=       0.87184
At iterate    33  f =       -323.4  |proj g|=       0.86374
At iterate    34  f =       -323.4  |proj g|=       0.86385
At iterate    35  f =       -323.4  |proj g|=       0.86387

iterations 35
function evaluations 43
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.863875
final function value -323.4

F = -323.4
final  value -323.399587 
converged
 
INFO  [05:57:45.058] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:57:45.143] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:57:45.150] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:57:49.264] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:57:53.834] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:57:58.938] [mlr3]  Finished benchmark 
INFO  [05:57:59.045] [bbotk] Result of batch 51: 
INFO  [05:57:59.047] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:57:59.047] [bbotk]              6.570982                   8.9301                      0.09527209 
INFO  [05:57:59.047] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:57:59.047] [bbotk]                     1910        0.627 -0.9590527         <NA>   0.9678117 
INFO  [05:57:59.047] [bbotk]                                 uhash 
INFO  [05:57:59.047] [bbotk]  30fe4735-d0a9-4d37-988e-223b22c2eb97 
DEBUG [05:57:59.919] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.462197e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9467609 9504 
  - variance bounds :  1.462197e-05 0.001780847 
  - best initial criterion value(s) :  304.1906 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -304.19  |proj g|=       1.1289
At iterate     1  f =      -311.99  |proj g|=        1.9344
At iterate     2  f =      -319.83  |proj g|=        1.1259
At iterate     3  f =      -321.06  |proj g|=       0.45354
At iterate     4  f =      -321.09  |proj g|=        0.4546
At iterate     5  f =       -321.1  |proj g|=       0.44442
At iterate     6  f =      -321.13  |proj g|=       0.42835
At iterate     7  f =      -321.14  |proj g|=       0.41995
At iterate     8  f =      -321.14  |proj g|=       0.28969
At iterate     9  f =      -321.14  |proj g|=       0.29227
At iterate    10  f =      -321.14  |proj g|=       0.29243

iterations 10
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.292426
final function value -321.139

F = -321.139
final  value -321.138927 
converged
 
INFO  [05:57:59.923] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:58:00.013] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:58:00.020] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:58:07.863] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:58:15.950] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:58:23.298] [mlr3]  Finished benchmark 
INFO  [05:58:23.401] [bbotk] Result of batch 52: 
INFO  [05:58:23.421] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:58:23.421] [bbotk]              5.947069                 2.611943                       0.3595534 
INFO  [05:58:23.421] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:58:23.421] [bbotk]                     3158        0.623 -0.9632876         <NA>   0.9756486 
INFO  [05:58:23.421] [bbotk]                                 uhash 
INFO  [05:58:23.421] [bbotk]  8b15cac9-2244-4c36-8dd6-815fcf7020a7 
DEBUG [05:58:24.491] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.450463e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9467609 9504 
  - variance bounds :  1.450463e-05 0.001782675 
  - best initial criterion value(s) :  324.4302 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -324.43  |proj g|=       4.4623
At iterate     1  f =      -331.57  |proj g|=        6.2975
At iterate     2  f =      -333.95  |proj g|=         4.725
At iterate     3  f =      -335.06  |proj g|=        2.9229
At iterate     4  f =      -336.11  |proj g|=        2.2615
At iterate     5  f =      -336.11  |proj g|=        2.2238
At iterate     6  f =      -336.11  |proj g|=        2.2227
At iterate     7  f =      -336.11  |proj g|=        2.2217
At iterate     8  f =      -336.11  |proj g|=        2.2182
At iterate     9  f =      -336.11  |proj g|=        2.2126
At iterate    10  f =      -336.11  |proj g|=        2.2025
At iterate    11  f =      -336.11  |proj g|=        2.1844
At iterate    12  f =      -336.12  |proj g|=        2.1521
At iterate    13  f =      -336.12  |proj g|=        2.0942
At iterate    14  f =      -336.13  |proj g|=        2.0001
At iterate    15  f =      -336.15  |proj g|=        1.8832
At iterate    16  f =      -336.18  |proj g|=        2.0218
At iterate    17  f =      -336.19  |proj g|=        1.9455
At iterate    18  f =      -336.31  |proj g|=        1.6879
At iterate    19  f =      -336.88  |proj g|=       0.98956
At iterate    20  f =      -337.97  |proj g|=       0.64563
At iterate    21  f =      -338.99  |proj g|=         0.605
At iterate    22  f =      -339.02  |proj g|=        0.6073
At iterate    23  f =      -339.59  |proj g|=       0.56267
At iterate    24  f =      -339.82  |proj g|=       0.64741
At iterate    25  f =      -340.09  |proj g|=       0.46315
At iterate    26  f =       -340.1  |proj g|=       0.46867
At iterate    27  f =      -340.11  |proj g|=       0.31605
At iterate    28  f =      -340.11  |proj g|=       0.19223
At iterate    29  f =      -340.11  |proj g|=       0.19214
At iterate    30  f =      -340.11  |proj g|=       0.19214

iterations 30
function evaluations 38
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.192138
final function value -340.109

F = -340.109
final  value -340.108801 
converged
 
INFO  [05:58:24.496] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:58:24.591] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:58:24.598] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:58:31.222] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:58:37.558] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:58:45.206] [mlr3]  Finished benchmark 
INFO  [05:58:45.320] [bbotk] Result of batch 53: 
INFO  [05:58:45.322] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:58:45.322] [bbotk]              3.959925                 9.046719                       0.3133631 
INFO  [05:58:45.322] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:58:45.322] [bbotk]                     2896        0.588 -0.9546427         <NA>   0.9729043 
INFO  [05:58:45.322] [bbotk]                                 uhash 
INFO  [05:58:45.322] [bbotk]  41e20f67-a101-4826-80e0-49afb5f7e4ad 
DEBUG [05:58:46.142] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.435172e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9467609 9504 
  - variance bounds :  1.435172e-05 0.001777239 
  - best initial criterion value(s) :  316.1831 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -316.18  |proj g|=       1.4382
At iterate     1  f =      -316.66  |proj g|=        2.5572
At iterate     2  f =      -317.77  |proj g|=         2.305
At iterate     3  f =      -318.29  |proj g|=        1.5513
At iterate     4  f =      -318.87  |proj g|=          1.88
At iterate     5  f =      -319.43  |proj g|=        1.8339
At iterate     6  f =      -321.45  |proj g|=        1.5684
At iterate     7  f =      -321.79  |proj g|=        1.2444
At iterate     8  f =      -321.92  |proj g|=        1.2435
At iterate     9  f =      -321.92  |proj g|=         1.219
At iterate    10  f =      -321.92  |proj g|=        1.2237
At iterate    11  f =      -321.92  |proj g|=        1.2234

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.22337
final function value -321.923

F = -321.923
final  value -321.923219 
converged
 
INFO  [05:58:46.147] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:58:46.236] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:58:46.243] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:58:49.012] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:58:55.846] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:58:59.800] [mlr3]  Finished benchmark 
INFO  [05:58:59.938] [bbotk] Result of batch 54: 
INFO  [05:58:59.940] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:58:59.940] [bbotk]              3.158078                 7.419739                        0.492094 
INFO  [05:58:59.940] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:58:59.940] [bbotk]                     1367        0.597 -0.967644         <NA>   0.9689536 
INFO  [05:58:59.940] [bbotk]                                 uhash 
INFO  [05:58:59.940] [bbotk]  ba9cbf1e-f6e7-4db9-b542-0ccd41b599eb 
DEBUG [05:59:00.826] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.418096e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.418096e-05 0.001739192 
  - best initial criterion value(s) :  311.1579 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -311.16  |proj g|=         2.48
At iterate     1  f =      -328.59  |proj g|=        6.6218
At iterate     2  f =      -330.27  |proj g|=        6.1099
At iterate     3  f =      -332.57  |proj g|=        4.6492
At iterate     4  f =      -332.62  |proj g|=        4.3452
At iterate     5  f =      -332.65  |proj g|=        4.4438
At iterate     6  f =       -332.8  |proj g|=        4.7863
At iterate     7  f =      -332.94  |proj g|=         5.078
At iterate     8  f =      -332.99  |proj g|=        5.0587
At iterate     9  f =      -332.99  |proj g|=        4.9993
At iterate    10  f =      -332.99  |proj g|=        4.9865
At iterate    11  f =      -332.99  |proj g|=        4.9936
At iterate    12  f =         -333  |proj g|=        5.0325
At iterate    13  f =      -333.04  |proj g|=        5.1021
At iterate    14  f =      -333.16  |proj g|=         5.181
At iterate    15  f =       -333.5  |proj g|=        5.2354
At iterate    16  f =      -333.52  |proj g|=        5.1151
At iterate    17  f =      -334.26  |proj g|=        4.8261
At iterate    18  f =      -336.22  |proj g|=        3.5878
At iterate    19  f =      -339.55  |proj g|=         1.729
At iterate    20  f =      -341.76  |proj g|=       0.52892
At iterate    21  f =      -342.57  |proj g|=       0.43546
At iterate    22  f =      -342.66  |proj g|=       0.50511
At iterate    23  f =         -343  |proj g|=       0.48315
At iterate    24  f =      -343.09  |proj g|=       0.49867
At iterate    25  f =       -343.1  |proj g|=        0.4917
At iterate    26  f =      -343.11  |proj g|=        0.4122
At iterate    27  f =      -343.11  |proj g|=        0.4145
At iterate    28  f =      -343.11  |proj g|=       0.42036
At iterate    29  f =      -343.11  |proj g|=       0.41818
At iterate    30  f =      -343.11  |proj g|=        0.4182

iterations 30
function evaluations 41
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.418197
final function value -343.111

F = -343.111
final  value -343.111279 
converged
 
INFO  [05:59:00.830] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:59:00.918] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:59:00.925] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:59:06.242] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:59:15.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:59:20.903] [mlr3]  Finished benchmark 
INFO  [05:59:21.047] [bbotk] Result of batch 55: 
INFO  [05:59:21.049] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:59:21.049] [bbotk]              7.506008                 9.263605                        0.461558 
INFO  [05:59:21.049] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [05:59:21.049] [bbotk]                     2658          0.6 -0.958589         <NA>   0.9759596 
INFO  [05:59:21.049] [bbotk]                                 uhash 
INFO  [05:59:21.049] [bbotk]  7f7c9bc1-fc2e-4d6c-8945-4c4a60c48daf 
DEBUG [05:59:21.958] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.407584e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.407584e-05 0.001735666 
  - best initial criterion value(s) :  337.7386 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -337.74  |proj g|=       3.0059
At iterate     1  f =      -341.48  |proj g|=        2.2272
At iterate     2  f =      -344.35  |proj g|=        1.6563
At iterate     3  f =      -346.56  |proj g|=       0.74359
At iterate     4  f =      -346.62  |proj g|=        0.6592
At iterate     5  f =      -346.79  |proj g|=       0.69179
At iterate     6  f =      -347.24  |proj g|=       0.68765
At iterate     7  f =      -347.46  |proj g|=       0.64436
At iterate     8  f =      -347.49  |proj g|=       0.62359
At iterate     9  f =      -347.49  |proj g|=       0.62093
At iterate    10  f =      -347.49  |proj g|=       0.62169
At iterate    11  f =      -347.49  |proj g|=       0.62153
At iterate    12  f =      -347.49  |proj g|=       0.62128
At iterate    13  f =      -347.49  |proj g|=       0.62055
At iterate    14  f =      -347.49  |proj g|=       0.61924
At iterate    15  f =      -347.49  |proj g|=       0.61719
At iterate    16  f =      -347.49  |proj g|=       0.61351
At iterate    17  f =      -347.49  |proj g|=       0.61492
At iterate    18  f =       -347.5  |proj g|=       0.59672
At iterate    19  f =       -347.5  |proj g|=       0.59828
At iterate    20  f =      -347.57  |proj g|=       0.60317
At iterate    21  f =      -347.66  |proj g|=       0.60815
At iterate    22  f =      -347.78  |proj g|=       0.61429
At iterate    23  f =      -347.83  |proj g|=       0.61083
At iterate    24  f =      -347.83  |proj g|=       0.59808
At iterate    25  f =      -347.84  |proj g|=       0.59456
At iterate    26  f =      -347.84  |proj g|=       0.59065
At iterate    27  f =      -347.84  |proj g|=       0.59171
At iterate    28  f =      -347.84  |proj g|=       0.59166

iterations 28
function evaluations 37
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.591663
final function value -347.838

F = -347.838
final  value -347.838461 
converged
 
INFO  [05:59:21.963] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:59:22.051] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:59:22.059] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:59:27.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:59:33.940] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [05:59:44.095] [mlr3]  Finished benchmark 
INFO  [05:59:44.227] [bbotk] Result of batch 56: 
INFO  [05:59:44.229] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [05:59:44.229] [bbotk]              9.786043                 7.628978                       0.2556023 
INFO  [05:59:44.229] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [05:59:44.229] [bbotk]                     2658        0.628 -0.9590617         <NA>    0.974164 
INFO  [05:59:44.229] [bbotk]                                 uhash 
INFO  [05:59:44.229] [bbotk]  654921f5-a8c2-48ac-ad1d-cd969b4dbb15 
DEBUG [05:59:45.069] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.394574e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.394574e-05 0.001732588 
  - best initial criterion value(s) :  327.6916 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -327.69  |proj g|=       2.1948
At iterate     1  f =      -327.95  |proj g|=         2.512
At iterate     2  f =      -327.95  |proj g|=        2.4836
At iterate     3  f =      -327.96  |proj g|=        2.4526
At iterate     4  f =      -327.98  |proj g|=         2.401
At iterate     5  f =      -328.02  |proj g|=        2.2952
At iterate     6  f =      -328.11  |proj g|=        2.1253
At iterate     7  f =      -328.21  |proj g|=        1.9486
At iterate     8  f =      -328.25  |proj g|=        2.0644
At iterate     9  f =      -328.26  |proj g|=        2.0158
At iterate    10  f =      -328.26  |proj g|=        2.0086
At iterate    11  f =      -328.26  |proj g|=        2.0093

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.00929
final function value -328.259

F = -328.259
final  value -328.259200 
converged
 
INFO  [05:59:45.074] [bbotk] Evaluating 1 configuration(s) 
INFO  [05:59:45.176] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [05:59:45.184] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [05:59:52.138] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [05:59:59.563] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:00:07.243] [mlr3]  Finished benchmark 
INFO  [06:00:07.356] [bbotk] Result of batch 57: 
INFO  [06:00:07.358] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:00:07.358] [bbotk]              8.828797                 4.226639                      0.02467172 
INFO  [06:00:07.358] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:00:07.358] [bbotk]                     2832         0.61 -0.968958         <NA>   0.9585744 
INFO  [06:00:07.358] [bbotk]                                 uhash 
INFO  [06:00:07.358] [bbotk]  fab01726-b5be-4e44-b785-64c3d7f0ea6a 
DEBUG [06:00:08.271] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.390476e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.390476e-05 0.001725551 
  - best initial criterion value(s) :  341.1774 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -341.18  |proj g|=       3.0012
At iterate     1  f =      -348.44  |proj g|=        6.2972
At iterate     2  f =      -350.75  |proj g|=        4.9349
At iterate     3  f =      -352.34  |proj g|=        3.4979
At iterate     4  f =      -354.95  |proj g|=        2.1708
At iterate     5  f =         -355  |proj g|=        2.6251
At iterate     6  f =      -355.01  |proj g|=        2.5111
At iterate     7  f =      -355.01  |proj g|=        2.4996
At iterate     8  f =      -355.01  |proj g|=        2.4998
At iterate     9  f =      -355.01  |proj g|=        2.5007
At iterate    10  f =      -355.01  |proj g|=         2.503
At iterate    11  f =      -355.01  |proj g|=        2.5068
At iterate    12  f =      -355.01  |proj g|=        2.5129
At iterate    13  f =      -355.01  |proj g|=        2.5224
At iterate    14  f =      -355.01  |proj g|=        2.5378
At iterate    15  f =      -355.01  |proj g|=        2.5598
At iterate    16  f =      -355.02  |proj g|=        2.5918
At iterate    17  f =      -355.02  |proj g|=        2.6445
At iterate    18  f =      -355.04  |proj g|=        2.6931
At iterate    19  f =      -355.05  |proj g|=        2.7979
At iterate    20  f =      -355.09  |proj g|=        2.8097
At iterate    21  f =      -355.31  |proj g|=        2.7746
At iterate    22  f =      -355.78  |proj g|=         2.556
At iterate    23  f =      -356.83  |proj g|=        1.8997
At iterate    24  f =      -358.11  |proj g|=        1.0594
At iterate    25  f =      -358.51  |proj g|=       0.57051
At iterate    26  f =      -359.77  |proj g|=       0.80081
At iterate    27  f =      -360.16  |proj g|=       0.87075
At iterate    28  f =      -360.29  |proj g|=       0.93539
At iterate    29  f =       -360.3  |proj g|=       0.94633
At iterate    30  f =       -360.3  |proj g|=       0.95528
At iterate    31  f =       -360.3  |proj g|=       0.95007
At iterate    32  f =       -360.3  |proj g|=       0.95337
At iterate    33  f =       -360.3  |proj g|=       0.95397
At iterate    34  f =       -360.3  |proj g|=       0.95394

iterations 34
function evaluations 40
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.953944
final function value -360.301

F = -360.301
final  value -360.301370 
converged
 
INFO  [06:00:08.275] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:00:08.360] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:00:08.366] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:00:15.517] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:00:21.762] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:00:26.996] [mlr3]  Finished benchmark 
INFO  [06:00:27.093] [bbotk] Result of batch 58: 
INFO  [06:00:27.095] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:00:27.095] [bbotk]              6.713127                 8.071502                      0.02349929 
INFO  [06:00:27.095] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:00:27.095] [bbotk]                     2703        0.624 -0.9563977         <NA>   0.9564449 
INFO  [06:00:27.095] [bbotk]                                 uhash 
INFO  [06:00:27.095] [bbotk]  7296ef81-439e-4256-9e13-39ab9e1611ac 
DEBUG [06:00:28.022] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.391564e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.391564e-05 0.001731721 
  - best initial criterion value(s) :  343.0988 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -343.1  |proj g|=       4.5674
At iterate     1  f =      -353.52  |proj g|=        7.2298
At iterate     2  f =      -357.27  |proj g|=        5.6039
At iterate     3  f =      -359.66  |proj g|=        3.4024
At iterate     4  f =      -360.69  |proj g|=        2.5745
At iterate     5  f =      -360.76  |proj g|=         2.635
At iterate     6  f =      -360.77  |proj g|=        2.4709
At iterate     7  f =      -360.77  |proj g|=        2.4916
At iterate     8  f =      -360.77  |proj g|=        2.4899
At iterate     9  f =      -360.77  |proj g|=        2.4868
At iterate    10  f =      -360.77  |proj g|=        2.4776
At iterate    11  f =      -360.77  |proj g|=        2.4666
At iterate    12  f =      -360.77  |proj g|=        2.4489
At iterate    13  f =      -360.77  |proj g|=         2.438
At iterate    14  f =      -360.78  |proj g|=        2.4143
At iterate    15  f =      -360.96  |proj g|=        2.1359
At iterate    16  f =      -361.79  |proj g|=        1.5651
At iterate    17  f =      -364.38  |proj g|=       0.92415
At iterate    18  f =      -365.95  |proj g|=        0.7852
At iterate    19  f =      -366.11  |proj g|=       0.96952
At iterate    20  f =      -366.67  |proj g|=       0.88262
At iterate    21  f =      -366.76  |proj g|=       0.88157
At iterate    22  f =      -366.79  |proj g|=       0.91132
At iterate    23  f =       -366.8  |proj g|=       0.94788
At iterate    24  f =      -366.81  |proj g|=        0.9575
At iterate    25  f =      -366.81  |proj g|=       0.95192
At iterate    26  f =      -366.81  |proj g|=       0.95697
At iterate    27  f =      -366.81  |proj g|=        0.9529
At iterate    28  f =      -366.81  |proj g|=       0.95204
At iterate    29  f =      -366.81  |proj g|=       0.95195

iterations 29
function evaluations 38
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.951955
final function value -366.808

F = -366.808
final  value -366.807520 
converged
 
INFO  [06:00:28.026] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:00:28.110] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:00:28.117] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:00:30.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:00:33.328] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:00:35.756] [mlr3]  Finished benchmark 
INFO  [06:00:35.857] [bbotk] Result of batch 59: 
INFO  [06:00:35.859] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:00:35.859] [bbotk]              8.246011                 2.173778                       0.0403868 
INFO  [06:00:35.859] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:00:35.859] [bbotk]                     1082        0.638 -0.9534018         <NA>   0.9520929 
INFO  [06:00:35.859] [bbotk]                                 uhash 
INFO  [06:00:35.859] [bbotk]  c9664eb5-26b0-40d6-bbee-71168a2b32a8 
DEBUG [06:00:36.772] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.406085e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.406085e-05 0.001747026 
  - best initial criterion value(s) :  356.0843 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -356.08  |proj g|=       2.6008
At iterate     1  f =      -356.55  |proj g|=        3.3775
At iterate     2  f =      -357.15  |proj g|=        3.1951
At iterate     3  f =      -358.13  |proj g|=        2.5514
At iterate     4  f =      -358.63  |proj g|=        2.6591
At iterate     5  f =      -359.14  |proj g|=        2.6156
At iterate     6  f =      -359.23  |proj g|=        2.6392
At iterate     7  f =      -359.24  |proj g|=        2.6485
At iterate     8  f =      -359.24  |proj g|=         2.654
At iterate     9  f =      -359.24  |proj g|=        2.6578
At iterate    10  f =      -359.24  |proj g|=        2.6568
At iterate    11  f =      -359.24  |proj g|=         2.656
At iterate    12  f =      -359.24  |proj g|=        2.6549
At iterate    13  f =      -359.24  |proj g|=        2.6517
At iterate    14  f =      -359.24  |proj g|=        2.6475
At iterate    15  f =      -359.24  |proj g|=        2.6396
At iterate    16  f =      -359.24  |proj g|=        2.6289
At iterate    17  f =      -359.25  |proj g|=        2.6098
At iterate    18  f =      -359.26  |proj g|=        2.5884
At iterate    19  f =      -359.27  |proj g|=        2.5469
At iterate    20  f =       -359.3  |proj g|=        2.5192
At iterate    21  f =      -359.78  |proj g|=        2.4123
At iterate    22  f =      -364.07  |proj g|=        1.5957
At iterate    23  f =       -368.9  |proj g|=        1.1192
At iterate    24  f =      -370.22  |proj g|=       0.73402
At iterate    25  f =         -371  |proj g|=       0.60145
At iterate    26  f =      -371.06  |proj g|=       0.71207
At iterate    27  f =       -371.1  |proj g|=       0.66343
At iterate    28  f =      -371.11  |proj g|=       0.66091
At iterate    29  f =      -371.11  |proj g|=       0.66273
At iterate    30  f =      -371.11  |proj g|=       0.66192
At iterate    31  f =      -371.11  |proj g|=       0.66208

iterations 31
function evaluations 37
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.662082
final function value -371.11

F = -371.11
final  value -371.110022 
converged
 
INFO  [06:00:36.777] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:00:36.886] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:00:36.893] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:00:43.632] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:00:49.090] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:00:55.126] [mlr3]  Finished benchmark 
INFO  [06:00:55.256] [bbotk] Result of batch 60: 
INFO  [06:00:55.258] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:00:55.258] [bbotk]               3.24216                 2.552887                       0.0796633 
INFO  [06:00:55.258] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:00:55.258] [bbotk]                     2738         0.62 -0.9507995         <NA>   0.9610636 
INFO  [06:00:55.258] [bbotk]                                 uhash 
INFO  [06:00:55.258] [bbotk]  67ec8d7a-585e-4a15-8feb-da706cc81f4a 
DEBUG [06:00:56.106] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.396351e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.396351e-05 0.001734774 
  - best initial criterion value(s) :  363.1642 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -363.16  |proj g|=       1.2317
At iterate     1  f =      -365.69  |proj g|=        1.9312
At iterate     2  f =      -366.26  |proj g|=        1.8078
At iterate     3  f =      -367.17  |proj g|=         1.379
At iterate     4  f =      -367.21  |proj g|=        1.3957
At iterate     5  f =      -367.24  |proj g|=        1.5136
At iterate     6  f =      -367.24  |proj g|=        1.5225
At iterate     7  f =      -367.24  |proj g|=        1.5231
At iterate     8  f =      -367.24  |proj g|=        1.5232

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.52323
final function value -367.237

F = -367.237
final  value -367.236862 
converged
 
INFO  [06:00:56.111] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:00:56.200] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:00:56.206] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:00:59.912] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:01:02.780] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:01:05.726] [mlr3]  Finished benchmark 
INFO  [06:01:05.826] [bbotk] Result of batch 61: 
INFO  [06:01:05.828] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:01:05.828] [bbotk]              5.770205                  3.74731                       0.1004597 
INFO  [06:01:05.828] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:01:05.828] [bbotk]                     1130        0.637 -0.9595333         <NA>   0.9625459 
INFO  [06:01:05.828] [bbotk]                                 uhash 
INFO  [06:01:05.828] [bbotk]  066719a9-d040-41ea-87b2-80c7a790c655 
DEBUG [06:01:06.867] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.38461e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.38461e-05 0.001709888 
  - best initial criterion value(s) :  357.6274 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -357.63  |proj g|=      0.86641
At iterate     1  f =      -361.69  |proj g|=        4.0776
At iterate     2  f =      -363.47  |proj g|=        3.8199
At iterate     3  f =      -366.51  |proj g|=        2.5202
At iterate     4  f =      -366.77  |proj g|=        2.4455
At iterate     5  f =       -367.2  |proj g|=        2.7262
At iterate     6  f =      -367.23  |proj g|=        2.7478
At iterate     7  f =      -367.23  |proj g|=        2.8026
At iterate     8  f =      -367.23  |proj g|=        2.7729
At iterate     9  f =      -367.23  |proj g|=        2.7705
At iterate    10  f =      -367.23  |proj g|=        2.7706

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.77059
final function value -367.232

F = -367.232
final  value -367.231688 
converged
 
INFO  [06:01:06.869] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:01:06.967] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:01:06.974] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:01:08.880] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:01:12.934] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:01:15.321] [mlr3]  Finished benchmark 
INFO  [06:01:15.421] [bbotk] Result of batch 62: 
INFO  [06:01:15.423] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:01:15.423] [bbotk]              7.286502                 4.428549                       0.3376056 
INFO  [06:01:15.423] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:01:15.423] [bbotk]                      798        0.792 -0.9628605         <NA>   0.9705736 
INFO  [06:01:15.423] [bbotk]                                 uhash 
INFO  [06:01:15.423] [bbotk]  33789275-c277-438c-bf36-fcdf0c97218f 
DEBUG [06:01:16.554] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.370145e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.370145e-05 0.001664918 
  - best initial criterion value(s) :  353.8605 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -353.86  |proj g|=       2.0844
At iterate     1  f =      -361.72  |proj g|=         3.999
At iterate     2  f =      -361.84  |proj g|=        3.9331
At iterate     3  f =      -362.04  |proj g|=        3.7067
At iterate     4  f =       -362.4  |proj g|=        3.6236
At iterate     5  f =      -363.17  |proj g|=        3.1206
At iterate     6  f =      -363.24  |proj g|=        3.2646
At iterate     7  f =      -363.24  |proj g|=        3.2315
At iterate     8  f =      -363.24  |proj g|=         3.233
At iterate     9  f =      -363.24  |proj g|=        3.2324
At iterate    10  f =      -363.24  |proj g|=        3.2323
At iterate    11  f =      -363.24  |proj g|=        3.2319
At iterate    12  f =      -363.24  |proj g|=        3.2312
At iterate    13  f =      -363.24  |proj g|=        3.2301
At iterate    14  f =      -363.24  |proj g|=        3.2282
At iterate    15  f =      -363.24  |proj g|=        3.2263
At iterate    16  f =      -363.25  |proj g|=        3.2262
At iterate    17  f =      -363.25  |proj g|=        3.2307
At iterate    18  f =      -363.27  |proj g|=        3.2317
At iterate    19  f =       -363.3  |proj g|=        3.2637
At iterate    20  f =      -363.31  |proj g|=        3.2138
At iterate    21  f =      -363.38  |proj g|=        3.2351
At iterate    22  f =      -363.73  |proj g|=        3.2455
At iterate    23  f =       -364.6  |proj g|=        3.1243
At iterate    24  f =      -367.25  |proj g|=        2.5693
At iterate    25  f =      -373.31  |proj g|=        1.6093
At iterate    26  f =      -373.43  |proj g|=         1.465
At iterate    27  f =      -378.64  |proj g|=       0.91633
At iterate    28  f =      -382.01  |proj g|=       0.45655
At iterate    29  f =      -382.06  |proj g|=       0.53959
At iterate    30  f =      -382.09  |proj g|=         0.527
At iterate    31  f =       -382.1  |proj g|=      0.085129
At iterate    32  f =       -382.1  |proj g|=       0.06363
At iterate    33  f =       -382.1  |proj g|=      0.064545
At iterate    34  f =       -382.1  |proj g|=      0.064522

iterations 34
function evaluations 42
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0645218
final function value -382.096

F = -382.096
final  value -382.095775 
converged
 
INFO  [06:01:16.558] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:01:16.666] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:01:16.673] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:01:24.162] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:01:31.539] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:01:41.648] [mlr3]  Finished benchmark 
INFO  [06:01:41.748] [bbotk] Result of batch 63: 
INFO  [06:01:41.750] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:01:41.750] [bbotk]              8.092561                 8.823531                      0.06785361 
INFO  [06:01:41.750] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:01:41.750] [bbotk]                     3516        0.795 -0.9573152         <NA>   0.9699464 
INFO  [06:01:41.750] [bbotk]                                 uhash 
INFO  [06:01:41.750] [bbotk]  2cd6cb42-57c4-40a8-9fee-d506b3e9fd4c 
DEBUG [06:01:42.878] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.355713e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.355713e-05 0.001667357 
  - best initial criterion value(s) :  370.3875 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -370.39  |proj g|=       6.2483
At iterate     1  f =      -375.23  |proj g|=        7.3897
At iterate     2  f =      -376.25  |proj g|=        6.9466
At iterate     3  f =       -378.4  |proj g|=        4.8877
At iterate     4  f =      -379.01  |proj g|=        3.7686
At iterate     5  f =       -379.4  |proj g|=        3.3036
At iterate     6  f =      -379.42  |proj g|=        3.1898
At iterate     7  f =      -379.42  |proj g|=        3.1741
At iterate     8  f =      -379.42  |proj g|=        3.1727
At iterate     9  f =      -379.42  |proj g|=        3.1621
At iterate    10  f =      -379.42  |proj g|=        3.1403
At iterate    11  f =      -379.43  |proj g|=        3.0956
At iterate    12  f =      -379.45  |proj g|=        3.0325
At iterate    13  f =      -379.52  |proj g|=        2.8864
At iterate    14  f =      -379.53  |proj g|=        3.0314
At iterate    15  f =      -379.69  |proj g|=         2.758
At iterate    16  f =      -385.03  |proj g|=        1.6234
At iterate    17  f =      -389.65  |proj g|=        1.3064
At iterate    18  f =      -390.86  |proj g|=        1.1901
At iterate    19  f =      -391.33  |proj g|=        1.1264
At iterate    20  f =      -391.67  |proj g|=        1.4068
At iterate    21  f =      -392.08  |proj g|=        1.2945
At iterate    22  f =      -392.13  |proj g|=        1.2808
At iterate    23  f =      -392.14  |proj g|=        1.2903
At iterate    24  f =      -392.15  |proj g|=        1.3036
At iterate    25  f =      -392.15  |proj g|=        1.3088
At iterate    26  f =      -392.15  |proj g|=        1.3095
At iterate    27  f =      -392.15  |proj g|=        1.3098
At iterate    28  f =      -392.15  |proj g|=        1.3103
At iterate    29  f =      -392.15  |proj g|=        1.3105
At iterate    30  f =      -392.15  |proj g|=        1.3101
At iterate    31  f =      -392.15  |proj g|=        1.3149
At iterate    32  f =      -392.15  |proj g|=        1.3135
At iterate    33  f =      -392.15  |proj g|=        1.3069
At iterate    34  f =      -392.16  |proj g|=        1.2988
At iterate    35  f =      -392.17  |proj g|=        1.2857
At iterate    36  f =      -392.19  |proj g|=        1.2755
At iterate    37  f =      -392.19  |proj g|=        1.2736
At iterate    38  f =      -392.19  |proj g|=        1.2728
At iterate    39  f =       -392.2  |proj g|=        1.2772
At iterate    40  f =       -392.2  |proj g|=        1.2787
At iterate    41  f =       -392.2  |proj g|=        1.2788

iterations 41
function evaluations 49
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.2788
final function value -392.195

F = -392.195
final  value -392.195103 
converged
 
INFO  [06:01:42.882] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:01:42.975] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:01:43.000] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:01:55.268] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:02:05.622] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:02:16.963] [mlr3]  Finished benchmark 
INFO  [06:02:17.097] [bbotk] Result of batch 64: 
INFO  [06:02:17.099] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:02:17.099] [bbotk]              9.202268                 7.299002                       0.3845422 
INFO  [06:02:17.099] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:02:17.099] [bbotk]                     4162        0.618 -0.946471         <NA>   0.9753439 
INFO  [06:02:17.099] [bbotk]                                 uhash 
INFO  [06:02:17.099] [bbotk]  6fc88265-ed19-409c-adf3-5d74005a777a 
DEBUG [06:02:18.003] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.346537e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.346537e-05 0.001655521 
  - best initial criterion value(s) :  384.7972 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -384.8  |proj g|=       2.5361
At iterate     1  f =      -393.67  |proj g|=        2.1124
At iterate     2  f =      -394.16  |proj g|=        1.8845
At iterate     3  f =      -395.16  |proj g|=        1.0215
At iterate     4  f =      -395.17  |proj g|=       0.95755
At iterate     5  f =       -395.2  |proj g|=       0.99067
At iterate     6  f =       -395.2  |proj g|=       0.98875
At iterate     7  f =       -395.2  |proj g|=       0.98845
At iterate     8  f =       -395.2  |proj g|=       0.98923
At iterate     9  f =       -395.2  |proj g|=       0.98915
At iterate    10  f =       -395.2  |proj g|=       0.98904
At iterate    11  f =       -395.2  |proj g|=       0.98847
At iterate    12  f =       -395.2  |proj g|=       0.98766
At iterate    13  f =       -395.2  |proj g|=       0.98627
At iterate    14  f =       -395.2  |proj g|=       0.98489
At iterate    15  f =       -395.2  |proj g|=        0.9784
At iterate    16  f =      -395.21  |proj g|=         0.978
At iterate    17  f =      -395.52  |proj g|=       0.98503
At iterate    18  f =      -395.95  |proj g|=       0.94703
At iterate    19  f =         -396  |proj g|=       0.93439
At iterate    20  f =      -396.01  |proj g|=       0.93786
At iterate    21  f =      -396.01  |proj g|=       0.94405
At iterate    22  f =      -396.01  |proj g|=       0.94398
At iterate    23  f =      -396.01  |proj g|=        0.9436
At iterate    24  f =      -396.01  |proj g|=       0.94365

iterations 24
function evaluations 33
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.943648
final function value -396.008

F = -396.008
final  value -396.008427 
converged
 
INFO  [06:02:18.007] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:02:18.095] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:02:18.102] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:02:24.082] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:02:30.847] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:02:36.326] [mlr3]  Finished benchmark 
INFO  [06:02:36.428] [bbotk] Result of batch 65: 
INFO  [06:02:36.430] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:02:36.430] [bbotk]              9.897508                 9.348143                       0.2470574 
INFO  [06:02:36.430] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:02:36.430] [bbotk]                     2762        0.625 -0.9527469         <NA>   0.9741371 
INFO  [06:02:36.430] [bbotk]                                 uhash 
INFO  [06:02:36.430] [bbotk]  fe5cadff-ca8a-4a2b-8054-342a269b1884 
DEBUG [06:02:37.290] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.335841e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.335841e-05 0.00166203 
  - best initial criterion value(s) :  388.1487 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -388.15  |proj g|=      0.91667
At iterate     1  f =      -390.39  |proj g|=        3.1421
At iterate     2  f =      -394.66  |proj g|=        1.0385
At iterate     3  f =      -395.08  |proj g|=        1.6957
At iterate     4  f =      -395.42  |proj g|=        1.4221
At iterate     5  f =      -395.55  |proj g|=        0.8603
At iterate     6  f =      -395.59  |proj g|=        1.1457
At iterate     7  f =       -395.6  |proj g|=          1.09
At iterate     8  f =       -395.6  |proj g|=         1.083
At iterate     9  f =       -395.6  |proj g|=        1.0831

iterations 9
function evaluations 11
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.08314
final function value -395.598

F = -395.598
final  value -395.597533 
converged
 
INFO  [06:02:37.294] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:02:37.420] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:02:37.427] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:02:47.037] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:02:56.771] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:03:07.164] [mlr3]  Finished benchmark 
INFO  [06:03:07.267] [bbotk] Result of batch 66: 
INFO  [06:03:07.269] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:03:07.269] [bbotk]              7.570037                 9.391636                       0.4142608 
INFO  [06:03:07.269] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:03:07.269] [bbotk]                     4314        0.634 -0.9587825         <NA>   0.9767703 
INFO  [06:03:07.269] [bbotk]                                 uhash 
INFO  [06:03:07.269] [bbotk]  c47d44f3-a034-4232-bf3d-df0712467041 
DEBUG [06:03:08.209] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.329117e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.329117e-05 0.001654493 
  - best initial criterion value(s) :  379.636 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -379.64  |proj g|=       2.0054
At iterate     1  f =      -386.26  |proj g|=        5.4666
At iterate     2  f =      -386.35  |proj g|=        5.3475
At iterate     3  f =      -386.57  |proj g|=        4.8712
At iterate     4  f =      -386.71  |proj g|=        4.7172
At iterate     5  f =      -387.81  |proj g|=        3.4833
At iterate     6  f =      -388.04  |proj g|=        3.5728
At iterate     7  f =      -388.04  |proj g|=        3.6547
At iterate     8  f =      -388.04  |proj g|=        3.6578
At iterate     9  f =      -388.04  |proj g|=        3.6581
At iterate    10  f =      -388.04  |proj g|=          3.66
At iterate    11  f =      -388.04  |proj g|=        3.6649
At iterate    12  f =      -388.04  |proj g|=        3.6722
At iterate    13  f =      -388.04  |proj g|=        3.6837
At iterate    14  f =      -388.04  |proj g|=        3.6989
At iterate    15  f =      -388.04  |proj g|=        3.7126
At iterate    16  f =      -388.05  |proj g|=        3.7365
At iterate    17  f =      -388.08  |proj g|=        3.7861
At iterate    18  f =      -388.22  |proj g|=        3.8582
At iterate    19  f =      -388.69  |proj g|=        3.8955
At iterate    20  f =      -389.79  |proj g|=        3.9274
At iterate    21  f =      -390.04  |proj g|=        3.3458
At iterate    22  f =       -391.9  |proj g|=        2.9791
At iterate    23  f =      -394.65  |proj g|=        1.9805
At iterate    24  f =      -399.03  |proj g|=         1.255
At iterate    25  f =      -403.09  |proj g|=        1.0231
At iterate    26  f =      -404.64  |proj g|=       0.86943
At iterate    27  f =      -404.65  |proj g|=       0.95164
At iterate    28  f =       -405.4  |proj g|=       0.49953
At iterate    29  f =      -405.44  |proj g|=       0.48886
At iterate    30  f =      -405.49  |proj g|=       0.40609
At iterate    31  f =      -405.49  |proj g|=       0.39238
At iterate    32  f =      -405.49  |proj g|=       0.38706
At iterate    33  f =      -405.49  |proj g|=       0.38606
At iterate    34  f =      -405.49  |proj g|=       0.38606

iterations 34
function evaluations 41
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.386058
final function value -405.486

F = -405.486
final  value -405.486327 
converged
 
INFO  [06:03:08.213] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:03:08.339] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:03:08.346] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:03:17.513] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:03:25.299] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:03:33.302] [mlr3]  Finished benchmark 
INFO  [06:03:33.405] [bbotk] Result of batch 67: 
INFO  [06:03:33.407] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:03:33.407] [bbotk]              5.347519                 9.895479                       0.2711931 
INFO  [06:03:33.407] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:03:33.407] [bbotk]                     3547        0.628 -0.952826         <NA>   0.9752121 
INFO  [06:03:33.407] [bbotk]                                 uhash 
INFO  [06:03:33.407] [bbotk]  33e5bf1c-bd25-414a-9e15-42cafe875ccb 
DEBUG [06:03:34.282] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.320005e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.320005e-05 0.001662581 
  - best initial criterion value(s) :  393.8193 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -393.82  |proj g|=       1.6429
At iterate     1  f =      -397.97  |proj g|=        2.1365
At iterate     2  f =         -398  |proj g|=         2.116
At iterate     3  f =      -398.18  |proj g|=        2.0133
At iterate     4  f =      -398.37  |proj g|=        1.9622
At iterate     5  f =      -399.03  |proj g|=        1.8988
At iterate     6  f =      -399.74  |proj g|=        2.0053
At iterate     7  f =      -400.08  |proj g|=         2.198
At iterate     8  f =      -400.15  |proj g|=        2.3077
At iterate     9  f =      -400.16  |proj g|=        2.3501
At iterate    10  f =      -400.16  |proj g|=        2.3569
At iterate    11  f =      -400.16  |proj g|=        2.3573

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.35727
final function value -400.158

F = -400.158
final  value -400.158212 
converged
 
INFO  [06:03:34.286] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:03:34.377] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:03:34.385] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:03:37.992] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:03:42.164] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:03:47.550] [mlr3]  Finished benchmark 
INFO  [06:03:47.653] [bbotk] Result of batch 68: 
INFO  [06:03:47.655] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:03:47.655] [bbotk]              2.092205                 5.460877                       0.2935752 
INFO  [06:03:47.655] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:03:47.655] [bbotk]                     1767         0.64 -0.9598928         <NA>   0.9581121 
INFO  [06:03:47.655] [bbotk]                                 uhash 
INFO  [06:03:47.655] [bbotk]  76f95caa-5a29-4f17-9ef7-6977d51ef631 
DEBUG [06:03:48.697] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.31759e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.31759e-05 0.001647729 
  - best initial criterion value(s) :  388.022 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -388.02  |proj g|=       4.6733
At iterate     1  f =       -401.6  |proj g|=        2.0203
At iterate     2  f =      -402.93  |proj g|=        2.7041
At iterate     3  f =       -404.8  |proj g|=        2.4553
At iterate     4  f =      -405.06  |proj g|=        2.3943
At iterate     5  f =      -405.53  |proj g|=        2.4211
At iterate     6  f =      -405.59  |proj g|=        2.9738
At iterate     7  f =      -405.68  |proj g|=        2.6714
At iterate     8  f =      -405.69  |proj g|=        2.6389
At iterate     9  f =      -405.69  |proj g|=         2.652
At iterate    10  f =      -405.69  |proj g|=        2.6521
At iterate    11  f =      -405.69  |proj g|=        2.6525
At iterate    12  f =      -405.69  |proj g|=        2.6536
At iterate    13  f =      -405.69  |proj g|=        2.6353
At iterate    14  f =      -405.69  |proj g|=        2.6332
At iterate    15  f =      -405.71  |proj g|=        2.6088
At iterate    16  f =      -405.74  |proj g|=        2.5875
At iterate    17  f =      -405.83  |proj g|=        2.5161
At iterate    18  f =      -406.08  |proj g|=         2.465
At iterate    19  f =      -406.75  |proj g|=        2.2927
At iterate    20  f =      -408.79  |proj g|=        2.1058
At iterate    21  f =      -409.39  |proj g|=        1.6858
At iterate    22  f =      -413.97  |proj g|=        1.4969
At iterate    23  f =      -416.77  |proj g|=          1.21
At iterate    24  f =      -418.17  |proj g|=        1.0125
At iterate    25  f =      -418.28  |proj g|=        1.0372
At iterate    26  f =      -419.03  |proj g|=        1.0402
At iterate    27  f =      -419.34  |proj g|=        1.2702
At iterate    28  f =       -420.1  |proj g|=        1.0534
At iterate    29  f =      -420.28  |proj g|=         1.078
At iterate    30  f =       -420.3  |proj g|=        1.0931
At iterate    31  f =       -420.3  |proj g|=        1.0996
At iterate    32  f =      -420.31  |proj g|=        1.0941
At iterate    33  f =      -420.78  |proj g|=       0.98483
At iterate    34  f =      -421.78  |proj g|=       0.58738
At iterate    35  f =      -421.84  |proj g|=       0.63829
At iterate    36  f =      -421.86  |proj g|=       0.65129
At iterate    37  f =       -421.9  |proj g|=       0.65832
At iterate    38  f =      -421.99  |proj g|=       0.63959
At iterate    39  f =      -422.14  |proj g|=       0.55284
At iterate    40  f =      -422.36  |proj g|=       0.55587
At iterate    41  f =      -422.52  |proj g|=       0.55331
At iterate    42  f =      -422.59  |proj g|=       0.53949
At iterate    43  f =      -422.64  |proj g|=       0.45692
At iterate    44  f =      -422.77  |proj g|=       0.46203
At iterate    45  f =      -422.78  |proj g|=       0.46763
At iterate    46  f =      -422.79  |proj g|=       0.39376
At iterate    47  f =      -422.79  |proj g|=      0.022004
At iterate    48  f =      -422.79  |proj g|=     0.0013057
At iterate    49  f =      -422.79  |proj g|=     0.0006529

iterations 49
function evaluations 68
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0006529
final function value -422.786

F = -422.786
final  value -422.785968 
converged
 
INFO  [06:03:48.701] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:03:48.835] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:03:48.843] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:03:56.552] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:04:03.931] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:04:11.889] [mlr3]  Finished benchmark 
INFO  [06:04:11.991] [bbotk] Result of batch 69: 
INFO  [06:04:11.993] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:04:11.993] [bbotk]              2.973568                 7.143977                      0.03840735 
INFO  [06:04:11.993] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:04:11.993] [bbotk]                     4681        0.643  -0.94485         <NA>   0.9557062 
INFO  [06:04:11.993] [bbotk]                                 uhash 
INFO  [06:04:11.993] [bbotk]  ebb10a30-532a-4abb-a3b3-6727adb56d23 
DEBUG [06:04:12.923] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.320566e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.320566e-05 0.00164026 
  - best initial criterion value(s) :  408.1968 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -408.2  |proj g|=        1.125
At iterate     1  f =         -409  |proj g|=        2.8394
At iterate     2  f =      -410.84  |proj g|=        2.4549
At iterate     3  f =      -413.02  |proj g|=        1.1222
At iterate     4  f =      -413.06  |proj g|=        1.3168
At iterate     5  f =      -413.11  |proj g|=        1.2127
At iterate     6  f =      -413.12  |proj g|=        1.2007
At iterate     7  f =      -413.12  |proj g|=        1.2067
At iterate     8  f =      -413.12  |proj g|=        1.2112
At iterate     9  f =      -413.12  |proj g|=        1.2113

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.2113
final function value -413.122

F = -413.122
final  value -413.121728 
converged
 
INFO  [06:04:12.928] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:04:13.017] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:04:13.025] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:04:14.631] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:04:16.417] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:04:17.874] [mlr3]  Finished benchmark 
INFO  [06:04:17.972] [bbotk] Result of batch 70: 
INFO  [06:04:17.974] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:04:17.974] [bbotk]              9.650645                 6.351554                      0.08344479 
INFO  [06:04:17.974] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:04:17.974] [bbotk]                      734        0.688 -0.9591055         <NA>   0.9571451 
INFO  [06:04:17.974] [bbotk]                                 uhash 
INFO  [06:04:17.974] [bbotk]  a0db2030-eb7c-48d9-8e84-cbb6f4af52c2 
DEBUG [06:04:19.096] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.319769e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.319769e-05 0.001634169 
  - best initial criterion value(s) :  379.6614 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -379.66  |proj g|=        8.891
At iterate     1  f =      -392.79  |proj g|=        8.4068
At iterate     2  f =      -407.72  |proj g|=        6.1019
At iterate     3  f =      -409.04  |proj g|=        4.7031
At iterate     4  f =      -411.68  |proj g|=        2.3524
At iterate     5  f =       -411.7  |proj g|=        2.0146
At iterate     6  f =      -411.71  |proj g|=        2.0816
At iterate     7  f =      -411.71  |proj g|=        2.0796
At iterate     8  f =      -411.71  |proj g|=         2.078
At iterate     9  f =      -411.71  |proj g|=        2.0761
At iterate    10  f =      -411.71  |proj g|=        2.0697
At iterate    11  f =      -411.71  |proj g|=        2.0602
At iterate    12  f =      -411.71  |proj g|=         2.041
At iterate    13  f =      -411.71  |proj g|=        2.0069
At iterate    14  f =      -411.72  |proj g|=        1.9436
At iterate    15  f =      -411.73  |proj g|=        1.8295
At iterate    16  f =      -411.77  |proj g|=        1.6433
At iterate    17  f =      -411.84  |proj g|=         1.422
At iterate    18  f =      -411.88  |proj g|=        1.8688
At iterate    19  f =      -411.93  |proj g|=        1.5009
At iterate    20  f =      -411.97  |proj g|=        1.3585
At iterate    21  f =      -412.07  |proj g|=        1.3392
At iterate    22  f =      -412.55  |proj g|=        1.2743
At iterate    23  f =      -413.48  |proj g|=        1.1833
At iterate    24  f =      -415.31  |proj g|=        1.0348
At iterate    25  f =      -417.16  |proj g|=       0.95829
At iterate    26  f =      -418.07  |proj g|=        1.0056
At iterate    27  f =       -418.7  |proj g|=        1.0215
At iterate    28  f =      -419.01  |proj g|=        1.1093
At iterate    29  f =      -419.18  |proj g|=        1.1626
At iterate    30  f =       -419.3  |proj g|=        1.2258
At iterate    31  f =      -419.36  |proj g|=        1.2276
At iterate    32  f =      -419.49  |proj g|=        1.3284
At iterate    33  f =      -419.86  |proj g|=        1.2783
At iterate    34  f =      -420.24  |proj g|=        1.1602
At iterate    35  f =      -420.24  |proj g|=        1.1465
At iterate    36  f =      -420.24  |proj g|=        1.1495
At iterate    37  f =      -420.24  |proj g|=        1.1494

iterations 37
function evaluations 50
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.14942
final function value -420.241

F = -420.241
final  value -420.240825 
converged
 
INFO  [06:04:19.101] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:04:19.191] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:04:19.212] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:04:20.843] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:04:22.539] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:04:24.234] [mlr3]  Finished benchmark 
INFO  [06:04:24.335] [bbotk] Result of batch 71: 
INFO  [06:04:24.336] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:04:24.336] [bbotk]              7.099802                  8.33108                       0.1549637 
INFO  [06:04:24.336] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:04:24.336] [bbotk]                      952        0.764 -0.9560578         <NA>   0.9660631 
INFO  [06:04:24.336] [bbotk]                                 uhash 
INFO  [06:04:24.336] [bbotk]  e2a2c2bf-b09e-4f72-b2aa-a1306c7215b1 
DEBUG [06:04:25.404] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.307162e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.307162e-05 0.001604819 
  - best initial criterion value(s) :  386.8752 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -386.88  |proj g|=       6.0679
At iterate     1  f =      -407.24  |proj g|=        3.6052
At iterate     2  f =      -409.48  |proj g|=        3.3654
At iterate     3  f =       -412.1  |proj g|=        2.1629
At iterate     4  f =      -412.82  |proj g|=        2.5785
At iterate     5  f =       -413.3  |proj g|=        2.6311
At iterate     6  f =      -416.48  |proj g|=        2.6346
At iterate     7  f =      -417.39  |proj g|=        2.5305
At iterate     8  f =      -417.41  |proj g|=        2.6306
At iterate     9  f =      -417.41  |proj g|=        2.6279
At iterate    10  f =      -417.41  |proj g|=        2.6293
At iterate    11  f =      -417.41  |proj g|=        2.6319
At iterate    12  f =      -417.41  |proj g|=        2.6294
At iterate    13  f =      -417.86  |proj g|=        2.6145
At iterate    14  f =      -419.09  |proj g|=        2.6506
At iterate    15  f =      -419.18  |proj g|=        2.6805
At iterate    16  f =      -419.19  |proj g|=        2.7001
At iterate    17  f =      -419.19  |proj g|=        2.7062
At iterate    18  f =      -419.19  |proj g|=        2.7092
At iterate    19  f =      -419.19  |proj g|=        2.7092
At iterate    20  f =      -419.19  |proj g|=        2.7065
At iterate    21  f =      -419.19  |proj g|=        2.7055
At iterate    22  f =      -419.19  |proj g|=        2.7029
At iterate    23  f =      -419.19  |proj g|=        2.6994
At iterate    24  f =       -419.2  |proj g|=        2.6876
At iterate    25  f =      -419.21  |proj g|=         2.681
At iterate    26  f =      -419.21  |proj g|=        2.6379
At iterate    27  f =      -419.24  |proj g|=        2.6329
At iterate    28  f =      -424.78  |proj g|=        2.1111
At iterate    29  f =      -427.83  |proj g|=        1.5972
At iterate    30  f =      -430.16  |proj g|=       0.87111
At iterate    31  f =      -431.84  |proj g|=        0.6233
At iterate    32  f =      -432.45  |proj g|=       0.59613
At iterate    33  f =      -432.73  |proj g|=       0.51108
At iterate    34  f =      -432.74  |proj g|=       0.45928
At iterate    35  f =      -432.75  |proj g|=       0.36815
At iterate    36  f =      -432.75  |proj g|=       0.36878
At iterate    37  f =      -432.75  |proj g|=        0.3693
At iterate    38  f =      -432.75  |proj g|=       0.36979
At iterate    39  f =      -432.75  |proj g|=       0.36892
At iterate    40  f =      -432.75  |proj g|=       0.37223
At iterate    41  f =      -432.75  |proj g|=       0.37855
At iterate    42  f =      -432.75  |proj g|=       0.38691
At iterate    43  f =      -432.75  |proj g|=       0.40904
At iterate    44  f =      -432.76  |proj g|=       0.48848
At iterate    45  f =      -432.79  |proj g|=       0.48157
At iterate    46  f =      -432.85  |proj g|=       0.50903
At iterate    47  f =      -432.97  |proj g|=       0.48293
At iterate    48  f =      -433.15  |proj g|=       0.51853
At iterate    49  f =      -433.24  |proj g|=       0.51297
At iterate    50  f =      -433.25  |proj g|=       0.50396
At iterate    51  f =      -433.26  |proj g|=       0.50066
At iterate    52  f =      -433.26  |proj g|=      0.021433
At iterate    53  f =      -433.26  |proj g|=     0.0023482
At iterate    54  f =      -433.26  |proj g|=     0.0023481

iterations 54
function evaluations 65
segments explored during Cauchy searches 56
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0023481
final function value -433.256

F = -433.256
final  value -433.256483 
converged
 
INFO  [06:04:25.408] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:04:25.509] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:04:25.515] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:04:28.453] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:04:31.425] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:04:34.231] [mlr3]  Finished benchmark 
INFO  [06:04:34.328] [bbotk] Result of batch 72: 
INFO  [06:04:34.330] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:04:34.330] [bbotk]               8.86748                 6.962385                       0.4660234 
INFO  [06:04:34.330] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:04:34.330] [bbotk]                     1907         0.66 -0.9505018         <NA>   0.9754997 
INFO  [06:04:34.330] [bbotk]                                 uhash 
INFO  [06:04:34.330] [bbotk]  2290bf46-e8f7-4ed8-adae-38868d8c0b04 
DEBUG [06:04:35.506] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.299508e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.299508e-05 0.001587525 
  - best initial criterion value(s) :  406.2027 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -406.2  |proj g|=       3.2763
At iterate     1  f =      -415.74  |proj g|=        1.4181
At iterate     2  f =      -419.05  |proj g|=          2.56
At iterate     3  f =      -419.93  |proj g|=        2.5663
At iterate     4  f =      -420.46  |proj g|=        2.5347
At iterate     5  f =      -420.51  |proj g|=        2.5381
At iterate     6  f =      -420.53  |proj g|=        2.5919
At iterate     7  f =      -420.53  |proj g|=        2.6297
At iterate     8  f =      -420.53  |proj g|=        2.6373
At iterate     9  f =      -420.53  |proj g|=        2.6406
At iterate    10  f =      -420.53  |proj g|=        2.6501
At iterate    11  f =      -420.53  |proj g|=        2.6627
At iterate    12  f =      -420.53  |proj g|=        2.6826
At iterate    13  f =      -420.54  |proj g|=        2.7108
At iterate    14  f =      -420.55  |proj g|=        2.7439
At iterate    15  f =      -420.58  |proj g|=        2.7601
At iterate    16  f =      -420.64  |proj g|=        2.6862
At iterate    17  f =      -420.66  |proj g|=         2.574
At iterate    18  f =      -420.66  |proj g|=        2.5533
At iterate    19  f =      -420.66  |proj g|=        2.5503
At iterate    20  f =      -420.66  |proj g|=        2.5295
At iterate    21  f =      -420.66  |proj g|=        2.5062
At iterate    22  f =      -420.67  |proj g|=        2.4582
At iterate    23  f =       -420.7  |proj g|=        2.3821
At iterate    24  f =      -420.77  |proj g|=        2.2472
At iterate    25  f =      -420.94  |proj g|=          2.02
At iterate    26  f =      -421.35  |proj g|=        1.6908
At iterate    27  f =      -421.95  |proj g|=        1.5099
At iterate    28  f =      -422.19  |proj g|=        1.7269
At iterate    29  f =      -422.23  |proj g|=        1.8778
At iterate    30  f =      -422.26  |proj g|=        1.9475
At iterate    31  f =      -422.32  |proj g|=        2.0401
At iterate    32  f =      -422.45  |proj g|=        2.1405
At iterate    33  f =      -422.82  |proj g|=         2.209
At iterate    34  f =      -423.82  |proj g|=        2.0764
At iterate    35  f =      -424.81  |proj g|=        1.1765
At iterate    36  f =      -425.45  |proj g|=        1.2805
At iterate    37  f =      -426.56  |proj g|=        1.3331
At iterate    38  f =      -428.61  |proj g|=        1.1021
At iterate    39  f =      -429.26  |proj g|=        0.9089
At iterate    40  f =      -429.44  |proj g|=       0.81389
At iterate    41  f =      -429.48  |proj g|=       0.86494
At iterate    42  f =      -429.48  |proj g|=       0.85689
At iterate    43  f =      -429.48  |proj g|=       0.85446
At iterate    44  f =      -429.48  |proj g|=       0.85512
At iterate    45  f =      -429.48  |proj g|=       0.85512

iterations 45
function evaluations 48
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.855119
final function value -429.483

F = -429.483
final  value -429.482525 
converged
 
INFO  [06:04:35.510] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:04:35.597] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:04:35.604] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:04:40.474] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:04:45.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:04:49.937] [mlr3]  Finished benchmark 
INFO  [06:04:50.054] [bbotk] Result of batch 73: 
INFO  [06:04:50.056] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:04:50.056] [bbotk]              3.548645                 8.263418                        0.261099 
INFO  [06:04:50.056] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:04:50.056] [bbotk]                     3233        0.656 -0.9549398         <NA>   0.9714721 
INFO  [06:04:50.056] [bbotk]                                 uhash 
INFO  [06:04:50.056] [bbotk]  a194d6ed-181b-4d64-b5ac-8b222cf1c113 
DEBUG [06:04:51.020] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.287872e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.287872e-05 0.001581716 
  - best initial criterion value(s) :  419.4176 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -419.42  |proj g|=       3.7846
At iterate     1  f =      -432.74  |proj g|=        2.5701
At iterate     2  f =      -432.94  |proj g|=        2.3302
At iterate     3  f =      -433.25  |proj g|=        1.6547
At iterate     4  f =      -433.85  |proj g|=        1.2929
At iterate     5  f =      -436.18  |proj g|=       0.95801
At iterate     6  f =      -436.93  |proj g|=        1.7482
At iterate     7  f =      -438.19  |proj g|=        1.0625
At iterate     8  f =      -438.53  |proj g|=       0.99413
At iterate     9  f =       -438.6  |proj g|=       0.98718
At iterate    10  f =      -438.63  |proj g|=        1.0084
At iterate    11  f =      -438.63  |proj g|=          1.03
At iterate    12  f =      -438.64  |proj g|=        1.0369
At iterate    13  f =      -438.64  |proj g|=        1.0373
At iterate    14  f =      -438.64  |proj g|=        1.0375
At iterate    15  f =      -438.64  |proj g|=         1.038
At iterate    16  f =      -438.64  |proj g|=        1.0384
At iterate    17  f =      -438.64  |proj g|=        1.0388
At iterate    18  f =      -438.64  |proj g|=        1.0387
At iterate    19  f =      -438.64  |proj g|=        1.0401
At iterate    20  f =      -438.64  |proj g|=        1.0398
At iterate    21  f =      -438.64  |proj g|=        1.0393
At iterate    22  f =      -438.65  |proj g|=        1.0371
At iterate    23  f =      -438.69  |proj g|=        1.0343
At iterate    24  f =      -438.79  |proj g|=        1.0326
At iterate    25  f =      -438.82  |proj g|=       0.98059
At iterate    26  f =         -439  |proj g|=        1.0087
At iterate    27  f =      -439.21  |proj g|=        1.0481
At iterate    28  f =      -439.27  |proj g|=        1.0721
At iterate    29  f =      -439.29  |proj g|=        1.0701
At iterate    30  f =      -439.29  |proj g|=        1.0659
At iterate    31  f =      -439.29  |proj g|=        1.0639
At iterate    32  f =      -439.29  |proj g|=         1.066
At iterate    33  f =      -439.29  |proj g|=        1.0661

iterations 33
function evaluations 42
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.06613
final function value -439.288

F = -439.288
final  value -439.288091 
converged
 
INFO  [06:04:51.024] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:04:51.109] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:04:51.116] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:04:53.353] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:04:55.570] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:04:58.260] [mlr3]  Finished benchmark 
INFO  [06:04:58.367] [bbotk] Result of batch 74: 
INFO  [06:04:58.369] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:04:58.369] [bbotk]              8.771112                 2.337592                      0.06323759 
INFO  [06:04:58.369] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:04:58.369] [bbotk]                     1434        0.639 -0.953849         <NA>   0.9618076 
INFO  [06:04:58.369] [bbotk]                                 uhash 
INFO  [06:04:58.369] [bbotk]  48d311bc-103d-4f84-b092-e421772c189f 
DEBUG [06:04:59.259] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.279515e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.279515e-05 0.001572561 
  - best initial criterion value(s) :  419.2497 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -419.25  |proj g|=       3.9868
At iterate     1  f =      -427.84  |proj g|=        2.9266
At iterate     2  f =      -432.45  |proj g|=          2.03
At iterate     3  f =      -432.54  |proj g|=         1.879
At iterate     4  f =      -432.56  |proj g|=          1.88
At iterate     5  f =      -432.58  |proj g|=        1.8849
At iterate     6  f =      -432.58  |proj g|=        1.8832
At iterate     7  f =      -432.58  |proj g|=        1.8835

iterations 7
function evaluations 11
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.88349
final function value -432.578

F = -432.578
final  value -432.577501 
converged
 
INFO  [06:04:59.263] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:04:59.351] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:04:59.358] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:05:08.743] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:05:17.830] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:05:26.286] [mlr3]  Finished benchmark 
INFO  [06:05:26.386] [bbotk] Result of batch 75: 
INFO  [06:05:26.388] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:05:26.388] [bbotk]              3.512788                 3.263406                       0.3122358 
INFO  [06:05:26.388] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:05:26.388] [bbotk]                     3538        0.656 -0.9603193         <NA>   0.9724361 
INFO  [06:05:26.388] [bbotk]                                 uhash 
INFO  [06:05:26.388] [bbotk]  9881fb07-7e12-48a0-9841-283cc2ded468 
DEBUG [06:05:27.442] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.268984e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.268984e-05 0.001566626 
  - best initial criterion value(s) :  431.9928 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -431.99  |proj g|=       2.5441
At iterate     1  f =      -441.92  |proj g|=        2.8194
At iterate     2  f =      -442.18  |proj g|=        2.5488
At iterate     3  f =      -442.45  |proj g|=        1.8948
At iterate     4  f =      -442.82  |proj g|=        2.0252
At iterate     5  f =      -445.08  |proj g|=        1.9242
At iterate     6  f =      -446.32  |proj g|=        1.5351
At iterate     7  f =      -446.74  |proj g|=        1.2795
At iterate     8  f =      -446.83  |proj g|=        1.2606
At iterate     9  f =      -446.84  |proj g|=        1.2825
At iterate    10  f =      -446.84  |proj g|=        1.2571
At iterate    11  f =      -446.84  |proj g|=        1.2733
At iterate    12  f =      -446.84  |proj g|=        1.2721
At iterate    13  f =      -446.84  |proj g|=        1.2717
At iterate    14  f =      -446.84  |proj g|=        1.2712
At iterate    15  f =      -446.84  |proj g|=        1.2694
At iterate    16  f =      -446.84  |proj g|=        1.2672
At iterate    17  f =      -446.84  |proj g|=        1.2633
At iterate    18  f =      -446.84  |proj g|=        1.2582
At iterate    19  f =      -446.84  |proj g|=        1.2537
At iterate    20  f =      -446.85  |proj g|=        1.2496
At iterate    21  f =      -446.86  |proj g|=        1.2424
At iterate    22  f =      -446.88  |proj g|=        1.2485
At iterate    23  f =      -446.88  |proj g|=        1.1982
At iterate    24  f =      -446.92  |proj g|=        1.1815
At iterate    25  f =       -447.4  |proj g|=       0.96221
At iterate    26  f =      -447.74  |proj g|=       0.97722
At iterate    27  f =      -447.75  |proj g|=       0.96837
At iterate    28  f =      -447.76  |proj g|=       0.98139
At iterate    29  f =      -447.76  |proj g|=       0.98449
At iterate    30  f =      -447.76  |proj g|=       0.98564
At iterate    31  f =      -447.76  |proj g|=       0.98567
At iterate    32  f =      -447.76  |proj g|=       0.98572
At iterate    33  f =      -447.76  |proj g|=       0.98579
At iterate    34  f =      -447.76  |proj g|=       0.98592
At iterate    35  f =      -447.76  |proj g|=       0.98514
At iterate    36  f =      -447.76  |proj g|=       0.98621
At iterate    37  f =      -447.76  |proj g|=       0.98677
At iterate    38  f =      -447.76  |proj g|=       0.98952
At iterate    39  f =      -447.77  |proj g|=       0.99205
At iterate    40  f =      -447.77  |proj g|=       0.99454
At iterate    41  f =      -447.78  |proj g|=       0.99296
At iterate    42  f =      -447.79  |proj g|=       0.96294
At iterate    43  f =       -447.8  |proj g|=       0.97377
At iterate    44  f =      -447.81  |proj g|=       0.97149
At iterate    45  f =      -447.81  |proj g|=       0.97068
At iterate    46  f =      -447.81  |proj g|=       0.96311
At iterate    47  f =      -447.81  |proj g|=       0.96179
At iterate    48  f =      -447.81  |proj g|=       0.96162
At iterate    49  f =      -447.81  |proj g|=       0.96151

iterations 49
function evaluations 59
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.96151
final function value -447.812

F = -447.812
final  value -447.812369 
converged
 
INFO  [06:05:27.447] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:05:27.563] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:05:27.570] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:05:35.057] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:05:42.747] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:05:49.483] [mlr3]  Finished benchmark 
INFO  [06:05:49.584] [bbotk] Result of batch 76: 
INFO  [06:05:49.586] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:05:49.586] [bbotk]              3.790473                 6.997862                       0.4715727 
INFO  [06:05:49.586] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:05:49.586] [bbotk]                     2865        0.658 -0.9562492         <NA>   0.9739659 
INFO  [06:05:49.586] [bbotk]                                 uhash 
INFO  [06:05:49.586] [bbotk]  d376e58e-a394-487b-81f3-27de866b91ff 
DEBUG [06:05:50.614] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.260027e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.260027e-05 0.001563006 
  - best initial criterion value(s) :  424.4342 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -424.43  |proj g|=       4.1922
At iterate     1  f =       -441.2  |proj g|=        9.2549
At iterate     2  f =      -444.88  |proj g|=        7.8414
At iterate     3  f =      -447.16  |proj g|=        3.4127
At iterate     4  f =      -448.02  |proj g|=        5.2542
At iterate     5  f =      -448.15  |proj g|=        4.9823
At iterate     6  f =      -448.57  |proj g|=        4.2537
At iterate     7  f =      -449.17  |proj g|=        3.6519
At iterate     8  f =      -450.23  |proj g|=        3.7899
At iterate     9  f =      -450.38  |proj g|=        3.4781
At iterate    10  f =       -450.4  |proj g|=        3.6318
At iterate    11  f =      -450.43  |proj g|=        3.4315
At iterate    12  f =      -450.43  |proj g|=        3.4157
At iterate    13  f =      -450.43  |proj g|=        3.4177
At iterate    14  f =      -450.43  |proj g|=        3.4242
At iterate    15  f =      -450.43  |proj g|=        3.4329
At iterate    16  f =      -450.43  |proj g|=        3.4484
At iterate    17  f =      -450.43  |proj g|=        3.4706
At iterate    18  f =      -450.43  |proj g|=        3.5077
At iterate    19  f =      -450.44  |proj g|=        3.5504
At iterate    20  f =      -450.44  |proj g|=        3.6405
At iterate    21  f =      -450.46  |proj g|=        3.6713
At iterate    22  f =      -450.48  |proj g|=        3.8365
At iterate    23  f =      -450.61  |proj g|=        3.9307
At iterate    24  f =      -450.93  |proj g|=        3.9292
At iterate    25  f =      -451.61  |proj g|=        3.8606
At iterate    26  f =      -458.27  |proj g|=        1.4583
At iterate    27  f =      -459.42  |proj g|=        1.2215
At iterate    28  f =      -459.71  |proj g|=         1.277
At iterate    29  f =      -459.75  |proj g|=        1.3127
At iterate    30  f =      -459.75  |proj g|=        1.3083
At iterate    31  f =      -459.75  |proj g|=        1.3085
At iterate    32  f =      -459.75  |proj g|=        1.3086
At iterate    33  f =      -459.75  |proj g|=        1.3085
At iterate    34  f =      -459.75  |proj g|=        1.3087

iterations 34
function evaluations 38
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.30867
final function value -459.75

F = -459.75
final  value -459.750154 
converged
 
INFO  [06:05:50.618] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:05:50.707] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:05:50.714] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:05:54.980] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:06:00.892] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:06:07.010] [mlr3]  Finished benchmark 
INFO  [06:06:07.108] [bbotk] Result of batch 77: 
INFO  [06:06:07.110] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:06:07.110] [bbotk]              4.325831                 5.679778                       0.4977645 
INFO  [06:06:07.110] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:06:07.110] [bbotk]                     2014        0.699 -0.9492737         <NA>   0.9740983 
INFO  [06:06:07.110] [bbotk]                                 uhash 
INFO  [06:06:07.110] [bbotk]  b119c310-a9dc-45e8-aaa9-7def0d27f6a0 
DEBUG [06:06:08.130] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.251321e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9632324 9504 
  - variance bounds :  1.251321e-05 0.001542283 
  - best initial criterion value(s) :  427.2816 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -427.28  |proj g|=       4.7089
At iterate     1  f =      -447.52  |proj g|=        2.6851
At iterate     2  f =      -452.57  |proj g|=        1.7628
At iterate     3  f =       -453.4  |proj g|=        1.3672
At iterate     4  f =      -453.49  |proj g|=        1.3017
At iterate     5  f =      -453.54  |proj g|=        1.3348
At iterate     6  f =      -453.54  |proj g|=        1.3492
At iterate     7  f =      -453.54  |proj g|=        1.3487
At iterate     8  f =      -453.54  |proj g|=        1.3485
At iterate     9  f =      -453.54  |proj g|=        1.3481
At iterate    10  f =      -453.54  |proj g|=        1.3472
At iterate    11  f =      -453.54  |proj g|=        1.3458
At iterate    12  f =      -453.54  |proj g|=        1.3435
At iterate    13  f =      -453.54  |proj g|=        1.3399
At iterate    14  f =      -453.54  |proj g|=         1.334
At iterate    15  f =      -453.55  |proj g|=        1.3247
At iterate    16  f =      -453.56  |proj g|=        1.3117
At iterate    17  f =      -453.57  |proj g|=        1.2998
At iterate    18  f =      -453.59  |proj g|=        1.3091
At iterate    19  f =       -453.6  |proj g|=         1.328
At iterate    20  f =       -453.6  |proj g|=         1.338
At iterate    21  f =       -453.6  |proj g|=        1.3428
At iterate    22  f =       -453.6  |proj g|=        1.3491
At iterate    23  f =      -453.61  |proj g|=        1.3588
At iterate    24  f =      -453.61  |proj g|=        1.3701
At iterate    25  f =      -453.62  |proj g|=        1.3825
At iterate    26  f =      -453.65  |proj g|=         1.387
At iterate    27  f =      -453.65  |proj g|=        1.4062
At iterate    28  f =      -453.68  |proj g|=        1.4045
At iterate    29  f =      -453.86  |proj g|=        1.3828
At iterate    30  f =       -453.9  |proj g|=        1.3679
At iterate    31  f =       -453.9  |proj g|=        1.3681
At iterate    32  f =       -453.9  |proj g|=        1.3681
At iterate    33  f =       -453.9  |proj g|=        1.3686
At iterate    34  f =       -453.9  |proj g|=        1.3685

iterations 34
function evaluations 44
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.36854
final function value -453.899

F = -453.899
final  value -453.899387 
converged
 
INFO  [06:06:08.134] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:06:08.225] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:06:08.232] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:06:16.777] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:06:25.441] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:06:38.521] [mlr3]  Finished benchmark 
INFO  [06:06:38.659] [bbotk] Result of batch 78: 
INFO  [06:06:38.661] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:06:38.661] [bbotk]              4.759129                 5.992226                       0.1617532 
INFO  [06:06:38.661] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:06:38.661] [bbotk]                     3413        0.671 -0.9574923         <NA>   0.9727492 
INFO  [06:06:38.661] [bbotk]                                 uhash 
INFO  [06:06:38.661] [bbotk]  28cc4fc6-ad40-4126-ae09-a134033fcb12 
DEBUG [06:06:39.682] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.241475e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9632324 9504 
  - variance bounds :  1.241475e-05 0.001537015 
  - best initial criterion value(s) :  434.2479 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -434.25  |proj g|=       4.9406
At iterate     1  f =       -439.1  |proj g|=        6.8024
At iterate     2  f =      -439.38  |proj g|=        6.6476
At iterate     3  f =       -440.8  |proj g|=          4.59
At iterate     4  f =      -441.82  |proj g|=        4.7813
At iterate     5  f =      -443.91  |proj g|=        3.7301
At iterate     6  f =      -444.39  |proj g|=        2.7913
At iterate     7  f =      -444.43  |proj g|=        2.5871
At iterate     8  f =      -444.43  |proj g|=        2.5496
At iterate     9  f =      -444.43  |proj g|=        2.5517
At iterate    10  f =      -444.43  |proj g|=        2.5563
At iterate    11  f =      -444.43  |proj g|=        2.5621
At iterate    12  f =      -444.43  |proj g|=        2.5728
At iterate    13  f =      -444.43  |proj g|=        2.5891
At iterate    14  f =      -444.44  |proj g|=        2.6154
At iterate    15  f =      -444.44  |proj g|=        2.6581
At iterate    16  f =      -444.44  |proj g|=        2.7204
At iterate    17  f =      -444.45  |proj g|=        2.8068
At iterate    18  f =      -444.47  |proj g|=        2.8662
At iterate    19  f =      -444.59  |proj g|=        3.0384
At iterate    20  f =      -444.88  |proj g|=        3.1805
At iterate    21  f =      -446.14  |proj g|=        3.1226
At iterate    22  f =      -448.92  |proj g|=        2.2077
At iterate    23  f =       -449.2  |proj g|=        2.7049
At iterate    24  f =      -451.49  |proj g|=        1.4929
At iterate    25  f =      -452.31  |proj g|=        1.3439
At iterate    26  f =      -452.88  |proj g|=        1.2776
At iterate    27  f =      -453.18  |proj g|=        1.4059
At iterate    28  f =      -453.34  |proj g|=        1.3637
At iterate    29  f =      -453.35  |proj g|=        1.4295
At iterate    30  f =      -453.36  |proj g|=        1.4155
At iterate    31  f =      -453.36  |proj g|=        1.4127
At iterate    32  f =      -453.36  |proj g|=        1.4132
At iterate    33  f =      -453.36  |proj g|=        1.4132

iterations 33
function evaluations 40
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.41316
final function value -453.358

F = -453.358
final  value -453.357793 
converged
 
INFO  [06:06:39.686] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:06:39.776] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:06:39.784] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:06:49.085] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:06:57.312] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:07:05.061] [mlr3]  Finished benchmark 
INFO  [06:07:05.163] [bbotk] Result of batch 79: 
INFO  [06:07:05.165] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:07:05.165] [bbotk]              6.729115                 7.705763                       0.3843796 
INFO  [06:07:05.165] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:07:05.165] [bbotk]                     3783        0.676 -0.959691         <NA>   0.9762195 
INFO  [06:07:05.165] [bbotk]                                 uhash 
INFO  [06:07:05.165] [bbotk]  9a7b3df8-180b-4e96-bdf4-fdbb21449f62 
DEBUG [06:07:06.103] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.235597e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9632324 9504 
  - variance bounds :  1.235597e-05 0.001538429 
  - best initial criterion value(s) :  440.5112 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -440.51  |proj g|=       3.3264
At iterate     1  f =      -450.18  |proj g|=        5.8496
At iterate     2  f =      -454.79  |proj g|=        5.3289
At iterate     3  f =      -463.52  |proj g|=        3.4969
At iterate     4  f =      -467.71  |proj g|=         1.526
At iterate     5  f =      -472.43  |proj g|=        1.3441
At iterate     6  f =      -472.56  |proj g|=        1.4526
At iterate     7  f =      -472.57  |proj g|=        1.4362
At iterate     8  f =      -472.57  |proj g|=        1.4345
At iterate     9  f =      -472.57  |proj g|=        1.4346

iterations 9
function evaluations 15
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.4346
final function value -472.574

F = -472.574
final  value -472.573862 
converged
 
INFO  [06:07:06.107] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:07:06.196] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:07:06.203] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:07:16.642] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:07:28.568] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:07:40.104] [mlr3]  Finished benchmark 
INFO  [06:07:40.238] [bbotk] Result of batch 80: 
INFO  [06:07:40.241] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:07:40.241] [bbotk]              2.799509                 6.698283                       0.4088881 
INFO  [06:07:40.241] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:07:40.241] [bbotk]                     4599        0.697 -0.9530052         <NA>   0.9717633 
INFO  [06:07:40.241] [bbotk]                                 uhash 
INFO  [06:07:40.241] [bbotk]  c96e01e9-6019-41c1-98bd-7b19650ca455 
DEBUG [06:07:41.474] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.225321e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9632324 9504 
  - variance bounds :  1.225321e-05 0.001531914 
  - best initial criterion value(s) :  444.5116 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -444.51  |proj g|=       5.5886
At iterate     1  f =      -445.37  |proj g|=        6.2417
At iterate     2  f =      -446.48  |proj g|=        5.4715
At iterate     3  f =      -448.95  |proj g|=        2.7939
At iterate     4  f =      -450.02  |proj g|=        2.2041
At iterate     5  f =      -450.07  |proj g|=        2.1669
At iterate     6  f =      -450.07  |proj g|=        2.2041
At iterate     7  f =      -450.07  |proj g|=        2.2049
At iterate     8  f =      -450.07  |proj g|=        2.2055
At iterate     9  f =      -450.07  |proj g|=        2.2062
At iterate    10  f =      -450.07  |proj g|=        2.2086
At iterate    11  f =      -450.08  |proj g|=        2.2117
At iterate    12  f =      -450.08  |proj g|=        2.2176
At iterate    13  f =      -450.08  |proj g|=        2.2268
At iterate    14  f =      -450.08  |proj g|=          2.24
At iterate    15  f =      -450.08  |proj g|=        2.2554
At iterate    16  f =       -450.1  |proj g|=        2.2607
At iterate    17  f =      -450.14  |proj g|=        2.2164
At iterate    18  f =      -450.21  |proj g|=        2.0376
At iterate    19  f =      -450.32  |proj g|=        1.6196
At iterate    20  f =      -450.34  |proj g|=        1.4147
At iterate    21  f =      -450.34  |proj g|=        1.4124
At iterate    22  f =      -450.35  |proj g|=         1.407
At iterate    23  f =      -450.37  |proj g|=        1.4205
At iterate    24  f =      -450.42  |proj g|=        1.4514
At iterate    25  f =      -450.53  |proj g|=        1.5296
At iterate    26  f =      -450.81  |proj g|=        1.6364
At iterate    27  f =      -451.48  |proj g|=        1.7608
At iterate    28  f =      -452.76  |proj g|=        1.7461
At iterate    29  f =      -454.45  |proj g|=        1.3484
At iterate    30  f =      -454.49  |proj g|=         1.572
At iterate    31  f =      -455.88  |proj g|=       0.98104
At iterate    32  f =      -456.11  |proj g|=       0.88494
At iterate    33  f =      -457.54  |proj g|=       0.97728
At iterate    34  f =      -457.78  |proj g|=       0.97684
At iterate    35  f =      -457.85  |proj g|=         1.007
At iterate    36  f =      -457.87  |proj g|=        1.0461
At iterate    37  f =      -457.87  |proj g|=        1.0499
At iterate    38  f =      -457.87  |proj g|=        1.0509
At iterate    39  f =      -457.87  |proj g|=        1.0506
At iterate    40  f =      -457.87  |proj g|=        1.0506

iterations 40
function evaluations 49
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.05065
final function value -457.874

F = -457.874
final  value -457.874309 
converged
 
INFO  [06:07:41.479] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:07:41.573] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:07:41.580] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:07:52.661] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:08:01.535] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:08:09.588] [mlr3]  Finished benchmark 
INFO  [06:08:09.705] [bbotk] Result of batch 81: 
INFO  [06:08:09.708] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:08:09.708] [bbotk]              9.115354                  4.17744                      0.01263552 
INFO  [06:08:09.708] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:08:09.708] [bbotk]                     4657        0.854 -0.9612024         <NA>   0.9564548 
INFO  [06:08:09.708] [bbotk]                                 uhash 
INFO  [06:08:09.708] [bbotk]  91e4d8cd-7867-47e8-98dd-dec9a41e10f8 
DEBUG [06:08:10.785] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.227309e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.227309e-05 0.001533236 
  - best initial criterion value(s) :  462.4891 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -462.49  |proj g|=       2.3875
At iterate     1  f =      -472.04  |proj g|=        2.3398
At iterate     2  f =      -474.63  |proj g|=        3.3857
At iterate     3  f =      -478.92  |proj g|=         4.018
At iterate     4  f =      -481.67  |proj g|=        3.4241
At iterate     5  f =      -482.29  |proj g|=        2.8774
At iterate     6  f =      -482.43  |proj g|=        2.6384
At iterate     7  f =      -482.44  |proj g|=        2.7099
At iterate     8  f =      -482.44  |proj g|=        2.6856
At iterate     9  f =      -482.44  |proj g|=        2.6875
At iterate    10  f =      -482.44  |proj g|=        2.6876
At iterate    11  f =      -482.44  |proj g|=        2.6877
At iterate    12  f =      -482.44  |proj g|=         2.677
At iterate    13  f =      -482.44  |proj g|=        2.6765
At iterate    14  f =      -482.44  |proj g|=         2.652
At iterate    15  f =      -482.44  |proj g|=        2.6487
At iterate    16  f =      -483.05  |proj g|=        2.4342
At iterate    17  f =      -485.39  |proj g|=        1.5814
At iterate    18  f =      -488.35  |proj g|=        0.5965
At iterate    19  f =      -488.81  |proj g|=       0.58509
At iterate    20  f =      -488.82  |proj g|=        0.5833
At iterate    21  f =      -489.04  |proj g|=       0.55244
At iterate    22  f =      -489.07  |proj g|=       0.46429
At iterate    23  f =      -489.07  |proj g|=       0.47511
At iterate    24  f =      -489.07  |proj g|=       0.47684
At iterate    25  f =      -489.07  |proj g|=       0.47728

iterations 25
function evaluations 35
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.477281
final function value -489.066

F = -489.066
final  value -489.066461 
converged
 
INFO  [06:08:10.790] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:08:10.905] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:08:10.913] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:08:14.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:08:17.395] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:08:20.735] [mlr3]  Finished benchmark 
INFO  [06:08:20.870] [bbotk] Result of batch 82: 
INFO  [06:08:20.872] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:08:20.872] [bbotk]              4.642434                 2.568314                       0.2743102 
INFO  [06:08:20.872] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:08:20.872] [bbotk]                     2062        0.744 -0.9457239         <NA>   0.9726331 
INFO  [06:08:20.872] [bbotk]                                 uhash 
INFO  [06:08:20.872] [bbotk]  7c983e04-63e5-47b4-9c69-214f49698ab2 
DEBUG [06:08:21.842] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.217917e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.217917e-05 0.001512937 
  - best initial criterion value(s) :  416.978 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -416.98  |proj g|=       14.062
At iterate     1  f =      -441.61  |proj g|=         7.658
At iterate     2  f =      -449.59  |proj g|=        6.1345
At iterate     3  f =      -461.19  |proj g|=        4.6618
At iterate     4  f =       -464.2  |proj g|=        3.6125
At iterate     5  f =      -465.74  |proj g|=        3.3817
At iterate     6  f =      -466.86  |proj g|=        2.6481
At iterate     7  f =      -466.96  |proj g|=        2.5651
At iterate     8  f =      -469.46  |proj g|=        2.6324
At iterate     9  f =      -478.48  |proj g|=        1.9805
At iterate    10  f =      -488.68  |proj g|=       0.63363
At iterate    11  f =       -489.3  |proj g|=       0.62795
At iterate    12  f =      -489.42  |proj g|=       0.61404
At iterate    13  f =      -489.58  |proj g|=       0.37799
At iterate    14  f =      -489.62  |proj g|=       0.73255
At iterate    15  f =      -489.64  |proj g|=       0.62548
At iterate    16  f =      -489.64  |proj g|=       0.61416
At iterate    17  f =      -489.64  |proj g|=       0.61495
At iterate    18  f =      -489.64  |proj g|=       0.61512

iterations 18
function evaluations 24
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.615117
final function value -489.645

F = -489.645
final  value -489.644895 
converged
 
INFO  [06:08:21.847] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:08:21.945] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:08:21.953] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:08:28.311] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:08:34.605] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:08:40.585] [mlr3]  Finished benchmark 
INFO  [06:08:40.686] [bbotk] Result of batch 83: 
INFO  [06:08:40.688] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:08:40.688] [bbotk]              3.864311                 2.366984                       0.4094146 
INFO  [06:08:40.688] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:08:40.688] [bbotk]                     3989        0.679 -0.9502825         <NA>   0.9746766 
INFO  [06:08:40.688] [bbotk]                                 uhash 
INFO  [06:08:40.688] [bbotk]  01065e85-273f-462a-af49-59bf6b1d3e5d 
DEBUG [06:08:41.733] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.210526e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.210526e-05 0.001510857 
  - best initial criterion value(s) :  444.4788 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -444.48  |proj g|=       3.2105
At iterate     1  f =      -454.76  |proj g|=         11.77
At iterate     2  f =      -461.37  |proj g|=        9.7397
At iterate     3  f =      -463.04  |proj g|=        8.8587
At iterate     4  f =      -463.55  |proj g|=           7.6
At iterate     5  f =      -465.07  |proj g|=        6.3441
At iterate     6  f =      -465.22  |proj g|=        6.5065
At iterate     7  f =      -465.22  |proj g|=        6.4742
At iterate     8  f =      -465.22  |proj g|=        6.4681
At iterate     9  f =      -465.24  |proj g|=        6.4236
At iterate    10  f =      -465.26  |proj g|=        6.2371
At iterate    11  f =      -465.32  |proj g|=        6.3083
At iterate    12  f =      -465.81  |proj g|=        5.8043
At iterate    13  f =       -467.8  |proj g|=        4.4093
At iterate    14  f =      -473.06  |proj g|=        2.1221
At iterate    15  f =      -482.63  |proj g|=        1.2086
At iterate    16  f =      -484.34  |proj g|=        1.5018
At iterate    17  f =      -488.92  |proj g|=        1.5607
At iterate    18  f =      -493.78  |proj g|=         1.428
At iterate    19  f =      -496.88  |proj g|=        1.1068
At iterate    20  f =      -498.96  |proj g|=        1.5606
At iterate    21  f =      -499.84  |proj g|=        1.2651
At iterate    22  f =      -501.26  |proj g|=        0.9101
At iterate    23  f =      -501.53  |proj g|=       0.75038
At iterate    24  f =      -501.67  |proj g|=        0.5585
At iterate    25  f =      -501.69  |proj g|=       0.50074
At iterate    26  f =       -501.7  |proj g|=       0.50111
At iterate    27  f =       -501.7  |proj g|=       0.40311
At iterate    28  f =       -501.7  |proj g|=       0.40379
At iterate    29  f =       -501.7  |proj g|=       0.40346

iterations 29
function evaluations 39
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.403457
final function value -501.698

F = -501.698
final  value -501.697599 
converged
 
INFO  [06:08:41.737] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:08:41.826] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:08:41.834] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:08:47.846] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:08:53.781] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:08:59.864] [mlr3]  Finished benchmark 
INFO  [06:08:59.965] [bbotk] Result of batch 84: 
INFO  [06:08:59.967] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:08:59.967] [bbotk]              4.913991                   4.1072                       0.1173638 
INFO  [06:08:59.967] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:08:59.967] [bbotk]                     3964         0.68 -0.9392468         <NA>   0.9722287 
INFO  [06:08:59.967] [bbotk]                                 uhash 
INFO  [06:08:59.967] [bbotk]  0822b324-ca6b-44b3-8b93-449e6174aa8f 
DEBUG [06:09:01.090] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.201105e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.201105e-05 0.001505701 
  - best initial criterion value(s) :  447.3736 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -447.37  |proj g|=       9.4838
At iterate     1  f =      -474.42  |proj g|=        2.3115
At iterate     2  f =      -478.62  |proj g|=        2.2203
At iterate     3  f =      -484.35  |proj g|=        1.8093
At iterate     4  f =      -484.54  |proj g|=        1.8064
At iterate     5  f =      -484.68  |proj g|=        1.7147
At iterate     6  f =      -485.44  |proj g|=        1.7612
At iterate     7  f =      -485.89  |proj g|=        1.7416
At iterate     8  f =      -485.92  |proj g|=        1.7869
At iterate     9  f =      -485.99  |proj g|=         1.746
At iterate    10  f =      -485.99  |proj g|=        1.7365
At iterate    11  f =         -486  |proj g|=         1.734
At iterate    12  f =      -486.12  |proj g|=        1.7242
At iterate    13  f =      -487.08  |proj g|=        1.7153
At iterate    14  f =      -487.39  |proj g|=        1.9079
At iterate    15  f =      -491.17  |proj g|=        1.5578
At iterate    16  f =      -492.77  |proj g|=        1.6309
At iterate    17  f =       -492.8  |proj g|=        1.6112
At iterate    18  f =      -492.81  |proj g|=        1.6039
At iterate    19  f =      -492.81  |proj g|=        1.6143
At iterate    20  f =      -492.81  |proj g|=        1.6181
At iterate    21  f =      -492.81  |proj g|=        1.6182

iterations 21
function evaluations 28
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.61816
final function value -492.813

F = -492.813
final  value -492.812560 
converged
 
INFO  [06:09:01.094] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:09:01.181] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:09:01.188] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:09:03.142] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:09:05.169] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:09:07.595] [mlr3]  Finished benchmark 
INFO  [06:09:07.719] [bbotk] Result of batch 85: 
INFO  [06:09:07.721] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:09:07.721] [bbotk]                 8.169                 6.136886                       0.3215271 
INFO  [06:09:07.721] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:09:07.721] [bbotk]                     1251        0.784 -0.9514594         <NA>    0.972798 
INFO  [06:09:07.721] [bbotk]                                 uhash 
INFO  [06:09:07.721] [bbotk]  3c4f6e18-950c-4bdf-917c-c47d4adf7f76 
DEBUG [06:09:08.690] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.192217e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.192217e-05 0.001482353 
  - best initial criterion value(s) :  458.1674 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -458.17  |proj g|=      0.50242
At iterate     1  f =      -472.34  |proj g|=        12.524
At iterate     2  f =      -475.17  |proj g|=        12.528
At iterate     3  f =      -481.17  |proj g|=        10.247
At iterate     4  f =      -481.76  |proj g|=         9.184
At iterate     5  f =      -482.33  |proj g|=        8.8036
At iterate     6  f =      -483.69  |proj g|=        8.3126
At iterate     7  f =      -483.84  |proj g|=        8.6195
At iterate     8  f =       -483.9  |proj g|=        8.5671
At iterate     9  f =       -483.9  |proj g|=        8.5358
At iterate    10  f =       -483.9  |proj g|=        8.5519
At iterate    11  f =       -483.9  |proj g|=        8.5453
At iterate    12  f =       -483.9  |proj g|=        8.5451

iterations 12
function evaluations 18
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 8.54511
final function value -483.898

F = -483.898
final  value -483.897979 
converged
 
INFO  [06:09:08.695] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:09:08.791] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:09:08.799] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:09:14.478] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:09:23.885] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:09:30.909] [mlr3]  Finished benchmark 
INFO  [06:09:31.012] [bbotk] Result of batch 86: 
INFO  [06:09:31.014] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:09:31.014] [bbotk]              8.321613                 5.183828                       0.2251743 
INFO  [06:09:31.014] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:09:31.014] [bbotk]                     3449        0.687 -0.9615638         <NA>   0.9750525 
INFO  [06:09:31.014] [bbotk]                                 uhash 
INFO  [06:09:31.014] [bbotk]  836d890c-1094-4dc8-b341-b7ee29b2f57e 
DEBUG [06:09:32.065] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.185513e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.185513e-05 0.001479506 
  - best initial criterion value(s) :  466.4587 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -466.46  |proj g|=       2.8557
At iterate     1  f =      -466.96  |proj g|=         3.553
At iterate     2  f =      -467.98  |proj g|=        3.4596
At iterate     3  f =       -470.8  |proj g|=         2.944
At iterate     4  f =      -471.33  |proj g|=        2.8889
At iterate     5  f =      -471.55  |proj g|=        2.8866
At iterate     6  f =      -471.58  |proj g|=        2.9024
At iterate     7  f =      -471.58  |proj g|=        2.9326
At iterate     8  f =      -471.59  |proj g|=        2.9281
At iterate     9  f =      -471.59  |proj g|=        2.9245
At iterate    10  f =      -471.66  |proj g|=        2.8788
At iterate    11  f =      -471.81  |proj g|=        2.7705
At iterate    12  f =      -472.16  |proj g|=        2.5016
At iterate    13  f =      -472.16  |proj g|=        2.5561
At iterate    14  f =      -472.77  |proj g|=        2.0548
At iterate    15  f =      -473.75  |proj g|=        1.3929
At iterate    16  f =      -475.58  |proj g|=       0.85456
At iterate    17  f =      -476.57  |proj g|=       0.64985
At iterate    18  f =      -476.88  |proj g|=       0.47744
At iterate    19  f =       -476.9  |proj g|=       0.46001
At iterate    20  f =      -476.92  |proj g|=       0.42659
At iterate    21  f =      -476.92  |proj g|=       0.39697
At iterate    22  f =      -476.92  |proj g|=       0.40212
At iterate    23  f =      -476.92  |proj g|=       0.40659
At iterate    24  f =      -476.92  |proj g|=       0.40781
At iterate    25  f =      -476.92  |proj g|=       0.40778

iterations 25
function evaluations 34
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.407777
final function value -476.918

F = -476.918
final  value -476.918402 
converged
 
INFO  [06:09:32.070] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:09:32.185] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:09:32.193] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:09:42.007] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:09:51.010] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:10:00.833] [mlr3]  Finished benchmark 
INFO  [06:10:00.937] [bbotk] Result of batch 87: 
INFO  [06:10:00.939] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:10:00.939] [bbotk]              9.670508                 3.411804                       0.3598603 
INFO  [06:10:00.939] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:10:00.939] [bbotk]                     4051        0.707 -0.9609424         <NA>   0.9748435 
INFO  [06:10:00.939] [bbotk]                                 uhash 
INFO  [06:10:00.939] [bbotk]  4aba9744-15d8-4446-9c45-e5cde905b059 
DEBUG [06:10:02.063] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.17864e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.17864e-05 0.001477409 
  - best initial criterion value(s) :  470.9169 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -470.92  |proj g|=       3.8006
At iterate     1  f =      -503.61  |proj g|=       0.97026
At iterate     2  f =      -510.15  |proj g|=        2.6285
At iterate     3  f =      -511.03  |proj g|=        3.8383
At iterate     4  f =      -513.49  |proj g|=        3.2319
At iterate     5  f =      -513.78  |proj g|=        2.8533
At iterate     6  f =      -513.91  |proj g|=        3.7126
At iterate     7  f =      -513.96  |proj g|=        3.4117
At iterate     8  f =      -513.96  |proj g|=        3.4158
At iterate     9  f =      -513.96  |proj g|=        3.4209
At iterate    10  f =      -513.97  |proj g|=        3.4451
At iterate    11  f =      -513.97  |proj g|=        3.4757
At iterate    12  f =      -513.99  |proj g|=        3.5237
At iterate    13  f =      -514.03  |proj g|=        3.5697
At iterate    14  f =      -514.12  |proj g|=        3.5784
At iterate    15  f =       -514.3  |proj g|=        3.5627
At iterate    16  f =      -514.66  |proj g|=         3.109
At iterate    17  f =      -515.08  |proj g|=        3.0264
At iterate    18  f =      -515.56  |proj g|=        2.6079
At iterate    19  f =      -517.25  |proj g|=        1.8986
At iterate    20  f =      -518.72  |proj g|=        1.1119
At iterate    21  f =      -520.18  |proj g|=        1.2229
At iterate    22  f =      -520.21  |proj g|=        1.8482
At iterate    23  f =      -520.27  |proj g|=         1.611
At iterate    24  f =      -520.28  |proj g|=        1.5546
At iterate    25  f =      -520.28  |proj g|=        1.5631
At iterate    26  f =      -520.28  |proj g|=        1.5641
At iterate    27  f =      -520.28  |proj g|=        1.5636

iterations 27
function evaluations 32
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.56363
final function value -520.276

F = -520.276
final  value -520.275672 
converged
 
INFO  [06:10:02.067] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:10:02.182] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:10:02.190] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:10:03.744] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:10:05.219] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:10:06.986] [mlr3]  Finished benchmark 
INFO  [06:10:07.089] [bbotk] Result of batch 88: 
INFO  [06:10:07.091] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:10:07.091] [bbotk]              2.642099                 7.952767                       0.3196548 
INFO  [06:10:07.091] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:10:07.091] [bbotk]                      482        0.776 -0.9447677         <NA>   0.9483836 
INFO  [06:10:07.091] [bbotk]                                 uhash 
INFO  [06:10:07.091] [bbotk]  4819b80e-4645-4e15-b9ec-6da4f2a45938 
DEBUG [06:10:08.161] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.203317e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.203317e-05 0.001516928 
  - best initial criterion value(s) :  483.3561 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -483.36  |proj g|=       4.6187
At iterate     1  f =      -500.23  |proj g|=        10.494
At iterate     2  f =      -504.78  |proj g|=        8.5616
At iterate     3  f =      -507.54  |proj g|=        3.2481
At iterate     4  f =       -508.4  |proj g|=        5.2148
At iterate     5  f =      -508.56  |proj g|=        4.9896
At iterate     6  f =      -509.92  |proj g|=        3.4379
At iterate     7  f =      -510.77  |proj g|=        2.9505
At iterate     8  f =      -511.37  |proj g|=        2.9073
At iterate     9  f =      -511.61  |proj g|=        2.9068
At iterate    10  f =       -511.7  |proj g|=        3.0352
At iterate    11  f =      -511.71  |proj g|=        2.9751
At iterate    12  f =      -511.71  |proj g|=        3.0222
At iterate    13  f =      -511.71  |proj g|=        3.0148
At iterate    14  f =      -511.71  |proj g|=        3.0111
At iterate    15  f =      -511.72  |proj g|=        2.9914
At iterate    16  f =      -511.73  |proj g|=        2.9626
At iterate    17  f =      -511.76  |proj g|=        2.9104
At iterate    18  f =      -511.84  |proj g|=        2.7847
At iterate    19  f =      -511.85  |proj g|=         2.922
At iterate    20  f =      -512.04  |proj g|=        2.6661
At iterate    21  f =      -513.58  |proj g|=        2.2588
At iterate    22  f =      -519.04  |proj g|=        1.9326
At iterate    23  f =      -519.61  |proj g|=         1.677
At iterate    24  f =      -519.64  |proj g|=        1.7171
At iterate    25  f =      -519.65  |proj g|=        1.7139
At iterate    26  f =      -519.65  |proj g|=        1.7092
At iterate    27  f =      -519.65  |proj g|=         1.711
At iterate    28  f =      -519.65  |proj g|=        1.7106
At iterate    29  f =      -519.65  |proj g|=        1.7106

iterations 29
function evaluations 35
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.71063
final function value -519.647

F = -519.647
final  value -519.647277 
converged
 
INFO  [06:10:08.165] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:10:08.284] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:10:08.291] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:10:19.086] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:10:30.542] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:10:42.329] [mlr3]  Finished benchmark 
INFO  [06:10:42.431] [bbotk] Result of batch 89: 
INFO  [06:10:42.433] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:10:42.433] [bbotk]              9.300492                 6.032525                         0.45646 
INFO  [06:10:42.433] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:10:42.433] [bbotk]                     4537        0.717 -0.9454035         <NA>   0.9756853 
INFO  [06:10:42.433] [bbotk]                                 uhash 
INFO  [06:10:42.433] [bbotk]  cac54c2f-cd95-4c12-82d5-0f8dae164a7a 
DEBUG [06:10:43.821] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.197479e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.197479e-05 0.001516902 
  - best initial criterion value(s) :  508.1702 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -508.17  |proj g|=       1.7848
At iterate     1  f =      -515.57  |proj g|=        2.6567
At iterate     2  f =      -515.62  |proj g|=        2.5716
At iterate     3  f =      -515.85  |proj g|=        2.1209
At iterate     4  f =      -516.09  |proj g|=        1.8968
At iterate     5  f =      -516.92  |proj g|=        1.6142
At iterate     6  f =      -517.87  |proj g|=        1.6415
At iterate     7  f =      -518.43  |proj g|=        1.8522
At iterate     8  f =      -518.62  |proj g|=        2.0438
At iterate     9  f =      -518.67  |proj g|=        2.1692
At iterate    10  f =      -518.67  |proj g|=        2.1993
At iterate    11  f =      -518.67  |proj g|=        2.2104
At iterate    12  f =      -518.67  |proj g|=        2.2107
At iterate    13  f =      -518.67  |proj g|=        2.2108
At iterate    14  f =      -518.67  |proj g|=        2.2112
At iterate    15  f =      -518.67  |proj g|=        2.2118
At iterate    16  f =      -518.67  |proj g|=        2.2124
At iterate    17  f =      -518.67  |proj g|=        2.2099
At iterate    18  f =      -518.67  |proj g|=        2.2248
At iterate    19  f =      -518.67  |proj g|=        2.2159
At iterate    20  f =      -518.78  |proj g|=        2.1149
At iterate    21  f =         -519  |proj g|=        1.8175
At iterate    22  f =      -519.37  |proj g|=        1.8777
At iterate    23  f =      -519.37  |proj g|=        1.8795
At iterate    24  f =      -519.37  |proj g|=        1.8777
At iterate    25  f =      -519.37  |proj g|=        1.8789
At iterate    26  f =      -519.37  |proj g|=        1.8789
At iterate    27  f =      -519.37  |proj g|=         1.879
At iterate    28  f =      -519.37  |proj g|=         1.879
At iterate    29  f =      -519.37  |proj g|=         1.879
At iterate    30  f =      -519.37  |proj g|=        1.8795
At iterate    31  f =      -519.37  |proj g|=        1.8766
At iterate    32  f =      -519.38  |proj g|=        1.8779
At iterate    33  f =      -519.38  |proj g|=        1.8804
At iterate    34  f =      -519.38  |proj g|=        1.8836
At iterate    35  f =       -519.4  |proj g|=        1.8878
At iterate    36  f =      -519.44  |proj g|=        1.8915
At iterate    37  f =      -519.54  |proj g|=        1.8768
At iterate    38  f =      -519.55  |proj g|=        1.9056
At iterate    39  f =      -519.77  |proj g|=        1.8657
At iterate    40  f =      -524.61  |proj g|=        1.3319
At iterate    41  f =      -524.74  |proj g|=        1.1482
At iterate    42  f =      -524.74  |proj g|=        1.1281
At iterate    43  f =      -524.74  |proj g|=        1.1261
At iterate    44  f =      -524.75  |proj g|=        1.1129
At iterate    45  f =      -524.75  |proj g|=         1.093
At iterate    46  f =      -524.76  |proj g|=         1.053
At iterate    47  f =      -524.78  |proj g|=       0.98466
At iterate    48  f =      -524.84  |proj g|=       0.89431
At iterate    49  f =      -524.85  |proj g|=       0.76217
At iterate    50  f =      -524.98  |proj g|=       0.63035
At iterate    51  f =      -525.63  |proj g|=       0.57206
At iterate    52  f =      -525.77  |proj g|=       0.41999
At iterate    53  f =      -525.78  |proj g|=       0.22732
At iterate    54  f =      -525.78  |proj g|=       0.09349
At iterate    55  f =      -525.78  |proj g|=      0.047645
At iterate    56  f =      -525.78  |proj g|=     0.0030471
At iterate    57  f =      -525.78  |proj g|=     0.0030471

iterations 57
function evaluations 72
segments explored during Cauchy searches 59
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00304709
final function value -525.779

F = -525.779
final  value -525.779474 
converged
 
INFO  [06:10:43.825] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:10:43.914] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:10:43.921] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:10:49.974] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:10:56.548] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:11:02.222] [mlr3]  Finished benchmark 
INFO  [06:11:02.326] [bbotk] Result of batch 90: 
INFO  [06:11:02.328] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:11:02.328] [bbotk]              5.202196                 4.490409                       0.4041492 
INFO  [06:11:02.328] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:11:02.328] [bbotk]                     2792        0.715 -0.9471903         <NA>   0.9755638 
INFO  [06:11:02.328] [bbotk]                                 uhash 
INFO  [06:11:02.328] [bbotk]  ff5f77f0-6d21-4ba1-acff-ea54ffa29e5c 
DEBUG [06:11:03.425] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.191527e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.191527e-05 0.001515092 
  - best initial criterion value(s) :  489.3439 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -489.34  |proj g|=       2.2288
At iterate     1  f =      -497.11  |proj g|=        5.3334
At iterate     2  f =      -497.81  |proj g|=        4.9803
At iterate     3  f =      -498.18  |proj g|=        3.7961
At iterate     4  f =      -498.33  |proj g|=        4.3481
At iterate     5  f =      -498.35  |proj g|=        4.2538
At iterate     6  f =      -498.35  |proj g|=        4.2397
At iterate     7  f =      -498.35  |proj g|=        4.2346
At iterate     8  f =      -498.35  |proj g|=        4.2318
At iterate     9  f =      -498.35  |proj g|=        4.2443
At iterate    10  f =      -498.35  |proj g|=        4.2842
At iterate    11  f =      -498.35  |proj g|=        4.2821
At iterate    12  f =      -498.35  |proj g|=        4.2817
At iterate    13  f =      -498.35  |proj g|=        4.2807
At iterate    14  f =      -498.35  |proj g|=        4.2794
At iterate    15  f =      -498.35  |proj g|=        4.2777
At iterate    16  f =      -498.35  |proj g|=         4.277
At iterate    17  f =      -498.35  |proj g|=        4.2779
At iterate    18  f =      -498.35  |proj g|=        4.2803
At iterate    19  f =      -498.35  |proj g|=        4.2933
At iterate    20  f =      -498.35  |proj g|=        4.2792
At iterate    21  f =      -498.35  |proj g|=        4.2941
At iterate    22  f =      -498.37  |proj g|=        4.3269
At iterate    23  f =      -498.48  |proj g|=        4.4342
At iterate    24  f =      -498.81  |proj g|=        4.5818
At iterate    25  f =      -499.72  |proj g|=        4.7755
At iterate    26  f =      -499.74  |proj g|=        5.1858
At iterate    27  f =      -501.67  |proj g|=        5.0678
At iterate    28  f =      -504.76  |proj g|=        4.6727
At iterate    29  f =      -508.81  |proj g|=        3.9295
At iterate    30  f =      -514.24  |proj g|=        2.9931
At iterate    31  f =      -518.85  |proj g|=         3.095
At iterate    32  f =      -519.52  |proj g|=        2.0044
At iterate    33  f =      -519.53  |proj g|=        2.3805
At iterate    34  f =      -519.54  |proj g|=        2.2426
At iterate    35  f =      -519.54  |proj g|=         2.214
At iterate    36  f =      -519.54  |proj g|=        2.2251
At iterate    37  f =      -519.54  |proj g|=         2.225

iterations 37
function evaluations 45
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.22498
final function value -519.544

F = -519.544
final  value -519.543666 
converged
 
INFO  [06:11:03.429] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:11:03.638] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:11:03.645] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:11:14.582] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:11:26.458] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:11:36.404] [mlr3]  Finished benchmark 
INFO  [06:11:36.546] [bbotk] Result of batch 91: 
INFO  [06:11:36.548] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:11:36.548] [bbotk]              6.747742                 6.334249                      0.07145808 
INFO  [06:11:36.548] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:11:36.548] [bbotk]                     4427        0.697 -0.9568566         <NA>   0.9713403 
INFO  [06:11:36.548] [bbotk]                                 uhash 
INFO  [06:11:36.548] [bbotk]  5f7bf4eb-e16c-459a-9958-375d5f84e9e8 
DEBUG [06:11:37.631] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.182277e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.182277e-05 0.001508412 
  - best initial criterion value(s) :  508.8128 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -508.81  |proj g|=       4.3722
At iterate     1  f =      -516.65  |proj g|=       0.73456
At iterate     2  f =      -516.78  |proj g|=       0.73309
At iterate     3  f =      -516.89  |proj g|=       0.73006
At iterate     4  f =      -517.09  |proj g|=       0.83884
At iterate     5  f =      -517.76  |proj g|=        1.1202
At iterate     6  f =      -518.41  |proj g|=        1.1229
At iterate     7  f =      -518.69  |proj g|=       0.99594
At iterate     8  f =      -518.79  |proj g|=       0.93908
At iterate     9  f =      -518.81  |proj g|=       0.95138
At iterate    10  f =      -518.81  |proj g|=       0.95608
At iterate    11  f =      -518.81  |proj g|=       0.95623
At iterate    12  f =      -518.81  |proj g|=       0.95643
At iterate    13  f =      -518.81  |proj g|=       0.95673
At iterate    14  f =      -518.81  |proj g|=       0.95727
At iterate    15  f =      -518.81  |proj g|=       0.95845
At iterate    16  f =      -518.81  |proj g|=       0.96013
At iterate    17  f =      -518.81  |proj g|=       0.96298
At iterate    18  f =      -518.82  |proj g|=       0.96783
At iterate    19  f =      -518.82  |proj g|=       0.97439
At iterate    20  f =      -518.84  |proj g|=       0.98689
At iterate    21  f =      -518.84  |proj g|=       0.98489
At iterate    22  f =      -518.87  |proj g|=       0.99601
At iterate    23  f =      -519.28  |proj g|=       0.94178
At iterate    24  f =      -519.74  |proj g|=       0.68187
At iterate    25  f =      -519.78  |proj g|=       0.74936
At iterate    26  f =      -519.78  |proj g|=       0.73743
At iterate    27  f =      -519.78  |proj g|=       0.73729
At iterate    28  f =      -519.78  |proj g|=       0.73679
At iterate    29  f =      -519.78  |proj g|=       0.73668
At iterate    30  f =      -519.78  |proj g|=       0.73671
At iterate    31  f =      -519.78  |proj g|=       0.73684

iterations 31
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.736843
final function value -519.778

F = -519.778
final  value -519.777577 
converged
 
INFO  [06:11:37.635] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:11:37.725] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:11:37.733] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:11:40.199] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:11:42.940] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:11:45.805] [mlr3]  Finished benchmark 
INFO  [06:11:45.908] [bbotk] Result of batch 92: 
INFO  [06:11:45.910] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:11:45.910] [bbotk]              4.986861                 2.834726                       0.4457851 
INFO  [06:11:45.910] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:11:45.910] [bbotk]                     1020        0.708 -0.9565202         <NA>      0.9722 
INFO  [06:11:45.910] [bbotk]                                 uhash 
INFO  [06:11:45.910] [bbotk]  79cfaf77-ac33-45e3-862b-6b578903b252 
DEBUG [06:11:47.003] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.173604e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.173604e-05 0.001486349 
  - best initial criterion value(s) :  482.8411 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -482.84  |proj g|=       13.239
At iterate     1  f =      -499.16  |proj g|=        3.5663
At iterate     2  f =      -502.95  |proj g|=        3.4033
At iterate     3  f =      -504.64  |proj g|=        2.2223
At iterate     4  f =      -505.34  |proj g|=        1.3784
At iterate     5  f =      -505.45  |proj g|=        1.1519
At iterate     6  f =      -505.48  |proj g|=        1.1034
At iterate     7  f =       -505.5  |proj g|=        1.2046
At iterate     8  f =       -505.5  |proj g|=        1.2198
At iterate     9  f =       -505.5  |proj g|=        1.2199
At iterate    10  f =       -505.5  |proj g|=        1.2197
At iterate    11  f =       -505.5  |proj g|=        1.2191
At iterate    12  f =       -505.5  |proj g|=        1.2164
At iterate    13  f =       -505.5  |proj g|=        1.2099
At iterate    14  f =       -505.5  |proj g|=        1.2174
At iterate    15  f =       -505.5  |proj g|=         1.208
At iterate    16  f =      -505.71  |proj g|=        1.0818
At iterate    17  f =      -508.17  |proj g|=        1.1978
At iterate    18  f =      -509.63  |proj g|=         1.354
At iterate    19  f =      -509.89  |proj g|=        1.2993
At iterate    20  f =      -509.97  |proj g|=        1.3366
At iterate    21  f =      -510.03  |proj g|=        1.3087
At iterate    22  f =      -510.05  |proj g|=        1.3272
At iterate    23  f =      -510.05  |proj g|=        1.3249
At iterate    24  f =      -510.05  |proj g|=        1.3242
At iterate    25  f =      -510.05  |proj g|=        1.3239
At iterate    26  f =      -510.05  |proj g|=        1.3234
At iterate    27  f =      -510.05  |proj g|=        1.3234

iterations 27
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.3234
final function value -510.053

F = -510.053
final  value -510.053112 
converged
 
INFO  [06:11:47.007] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:11:47.465] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:11:47.472] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:11:57.947] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:12:08.641] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:12:18.701] [mlr3]  Finished benchmark 
INFO  [06:12:18.814] [bbotk] Result of batch 93: 
INFO  [06:12:18.816] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:12:18.816] [bbotk]              3.892558                 2.638432                       0.3898746 
INFO  [06:12:18.816] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:12:18.816] [bbotk]                     4812        0.723 -0.9598651         <NA>   0.9750376 
INFO  [06:12:18.816] [bbotk]                                 uhash 
INFO  [06:12:18.816] [bbotk]  05d0454e-1c0c-4f1b-b902-e9dcccc3daf8 
DEBUG [06:12:20.312] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.16731e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.16731e-05 0.001477653 
  - best initial criterion value(s) :  474.0403 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -474.04  |proj g|=       4.3017
At iterate     1  f =      -514.54  |proj g|=        12.531
At iterate     2  f =      -520.86  |proj g|=        12.307
At iterate     3  f =      -527.54  |proj g|=        1.3086
At iterate     4  f =      -531.61  |proj g|=        6.6514
At iterate     5  f =      -532.38  |proj g|=        5.7018
At iterate     6  f =      -533.98  |proj g|=        3.9233
At iterate     7  f =       -536.6  |proj g|=        2.6831
At iterate     8  f =      -537.75  |proj g|=        5.9322
At iterate     9  f =      -542.03  |proj g|=         3.202
At iterate    10  f =       -543.1  |proj g|=        2.1948
At iterate    11  f =      -543.63  |proj g|=        1.7495
At iterate    12  f =      -548.47  |proj g|=        1.5059
At iterate    13  f =       -550.6  |proj g|=        1.2839
At iterate    14  f =      -551.03  |proj g|=        1.1302
At iterate    15  f =      -551.29  |proj g|=         1.139
At iterate    16  f =       -551.3  |proj g|=        1.1334
At iterate    17  f =       -551.3  |proj g|=        1.1258
At iterate    18  f =       -551.3  |proj g|=        1.1235
At iterate    19  f =       -551.3  |proj g|=        1.1163
At iterate    20  f =      -551.31  |proj g|=        1.1072
At iterate    21  f =      -551.32  |proj g|=        1.0888
At iterate    22  f =      -551.33  |proj g|=        1.0632
At iterate    23  f =      -551.35  |proj g|=        1.0362
At iterate    24  f =      -551.37  |proj g|=        1.0244
At iterate    25  f =      -551.37  |proj g|=        1.0307
At iterate    26  f =      -551.37  |proj g|=        1.0366
At iterate    27  f =      -551.37  |proj g|=        1.0419
At iterate    28  f =      -551.37  |proj g|=        1.0447
At iterate    29  f =      -551.38  |proj g|=        1.0513
At iterate    30  f =      -551.38  |proj g|=        1.0578
At iterate    31  f =      -551.38  |proj g|=        1.0622
At iterate    32  f =      -551.39  |proj g|=        1.0578
At iterate    33  f =       -551.4  |proj g|=        1.0444
At iterate    34  f =       -551.4  |proj g|=        1.0338
At iterate    35  f =       -551.4  |proj g|=        1.0312
At iterate    36  f =       -551.4  |proj g|=        1.0311
At iterate    37  f =       -551.4  |proj g|=        1.0311
At iterate    38  f =       -551.4  |proj g|=        1.0313
At iterate    39  f =       -551.4  |proj g|=        1.0319
At iterate    40  f =       -551.4  |proj g|=        1.0329
At iterate    41  f =       -551.4  |proj g|=         1.035
At iterate    42  f =       -551.4  |proj g|=        1.0411
At iterate    43  f =       -551.4  |proj g|=        1.0479
At iterate    44  f =      -551.41  |proj g|=        1.0558
At iterate    45  f =      -551.41  |proj g|=         1.058
At iterate    46  f =      -551.41  |proj g|=        1.0554
At iterate    47  f =      -551.41  |proj g|=        1.0536
At iterate    48  f =      -551.41  |proj g|=        1.0532
At iterate    49  f =      -551.41  |proj g|=        1.0531
At iterate    50  f =      -551.41  |proj g|=         1.053
At iterate    51  f =      -551.41  |proj g|=        1.0527
At iterate    52  f =      -551.41  |proj g|=        1.0524
At iterate    53  f =      -551.41  |proj g|=        1.0522
At iterate    54  f =      -551.41  |proj g|=        1.0524
At iterate    55  f =      -551.41  |proj g|=        1.0532
At iterate    56  f =      -551.41  |proj g|=        1.0543
At iterate    57  f =      -551.41  |proj g|=        1.0549
At iterate    58  f =      -551.41  |proj g|=         1.055
At iterate    59  f =      -551.41  |proj g|=        1.0551
At iterate    60  f =      -551.41  |proj g|=         1.055
At iterate    61  f =      -551.41  |proj g|=        1.0549
At iterate    62  f =      -551.41  |proj g|=        1.0547
At iterate    63  f =      -551.41  |proj g|=        1.0542
At iterate    64  f =      -551.41  |proj g|=        1.0532
At iterate    65  f =      -551.41  |proj g|=        1.0524
At iterate    66  f =      -551.41  |proj g|=        1.0521
At iterate    67  f =      -551.41  |proj g|=        1.0522
At iterate    68  f =      -551.41  |proj g|=        1.0524
At iterate    69  f =      -551.41  |proj g|=        1.0526
At iterate    70  f =      -551.41  |proj g|=        1.0546
At iterate    71  f =      -551.41  |proj g|=        1.0565
At iterate    72  f =      -551.41  |proj g|=        1.0597
At iterate    73  f =      -551.42  |proj g|=        1.0631
At iterate    74  f =      -551.43  |proj g|=        1.0649
At iterate    75  f =      -551.45  |proj g|=        1.0593
At iterate    76  f =      -551.48  |proj g|=        1.0394
At iterate    77  f =      -551.54  |proj g|=       0.99519
At iterate    78  f =      -551.63  |proj g|=       0.91114
At iterate    79  f =      -551.63  |proj g|=       0.90057
At iterate    80  f =      -551.69  |proj g|=       0.83164
At iterate    81  f =       -551.7  |proj g|=       0.83711
At iterate    82  f =       -551.7  |proj g|=       0.84218
At iterate    83  f =       -551.7  |proj g|=       0.84157
At iterate    84  f =       -551.7  |proj g|=       0.84075
At iterate    85  f =       -551.7  |proj g|=       0.83946
At iterate    86  f =       -551.7  |proj g|=       0.83721
At iterate    87  f =       -551.7  |proj g|=       0.83261
At iterate    88  f =       -551.7  |proj g|=       0.82433
At iterate    89  f =       -551.7  |proj g|=       0.80903
At iterate    90  f =      -551.71  |proj g|=       0.78352
At iterate    91  f =      -551.71  |proj g|=        0.7839
At iterate    92  f =      -551.72  |proj g|=         0.757
At iterate    93  f =      -551.73  |proj g|=       0.75552
At iterate    94  f =      -551.73  |proj g|=       0.75786
At iterate    95  f =      -551.74  |proj g|=       0.76703
At iterate    96  f =      -551.74  |proj g|=       0.77481
At iterate    97  f =      -551.75  |proj g|=       0.78667
At iterate    98  f =      -551.75  |proj g|=       0.78576
At iterate    99  f =      -551.78  |proj g|=       0.78747
At iterate   100  f =      -551.79  |proj g|=        0.8143
At iterate   101  f =      -551.89  |proj g|=       0.77166
final  value -551.891802 
stopped after 101 iterations
 
INFO  [06:12:20.315] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:12:20.400] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:12:20.408] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:12:24.339] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:12:28.189] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:12:31.933] [mlr3]  Finished benchmark 
INFO  [06:12:32.031] [bbotk] Result of batch 94: 
INFO  [06:12:32.033] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:12:32.033] [bbotk]              2.710699                 2.348497                       0.4094176 
INFO  [06:12:32.033] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:12:32.033] [bbotk]                     2498        0.795 -0.9374726         <NA>   0.9679824 
INFO  [06:12:32.033] [bbotk]                                 uhash 
INFO  [06:12:32.033] [bbotk]  bb69ae7d-26d8-40ac-9d58-f5eee6f62432 
DEBUG [06:12:33.375] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.157942e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.157942e-05 0.001469268 
  - best initial criterion value(s) :  514.706 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -514.71  |proj g|=       13.519
At iterate     1  f =      -532.05  |proj g|=         4.167
At iterate     2  f =      -542.62  |proj g|=        4.0512
At iterate     3  f =      -546.25  |proj g|=        2.4684
At iterate     4  f =      -548.99  |proj g|=        1.1397
At iterate     5  f =       -550.1  |proj g|=        1.0569
At iterate     6  f =      -550.89  |proj g|=        0.9902
At iterate     7  f =      -551.33  |proj g|=        2.6341
At iterate     8  f =      -552.42  |proj g|=        1.2571
At iterate     9  f =      -552.51  |proj g|=        1.0657
At iterate    10  f =      -552.55  |proj g|=        1.2124
At iterate    11  f =      -552.56  |proj g|=        1.0839
At iterate    12  f =      -552.56  |proj g|=         1.073
At iterate    13  f =      -552.56  |proj g|=        1.0708
At iterate    14  f =      -552.56  |proj g|=        1.0485
At iterate    15  f =      -552.57  |proj g|=        1.0192
At iterate    16  f =      -552.59  |proj g|=       0.96411
At iterate    17  f =      -552.63  |proj g|=       0.86981
At iterate    18  f =      -552.73  |proj g|=       0.85612
At iterate    19  f =      -553.01  |proj g|=       0.85299
At iterate    20  f =       -553.7  |proj g|=       0.83279
At iterate    21  f =      -554.89  |proj g|=       0.77854
At iterate    22  f =      -555.31  |proj g|=       0.73092
At iterate    23  f =      -555.39  |proj g|=       0.72237
At iterate    24  f =      -555.42  |proj g|=         0.705
At iterate    25  f =      -555.46  |proj g|=       0.67397
At iterate    26  f =      -555.47  |proj g|=       0.61963
At iterate    27  f =       -555.5  |proj g|=        0.6292
At iterate    28  f =       -555.5  |proj g|=       0.62848
At iterate    29  f =       -555.5  |proj g|=       0.63236
At iterate    30  f =       -555.5  |proj g|=       0.63281
At iterate    31  f =       -555.5  |proj g|=       0.63291
At iterate    32  f =       -555.5  |proj g|=       0.63297
At iterate    33  f =       -555.5  |proj g|=       0.63301
At iterate    34  f =       -555.5  |proj g|=         0.633
At iterate    35  f =       -555.5  |proj g|=       0.63277
At iterate    36  f =       -555.5  |proj g|=       0.63199
At iterate    37  f =       -555.5  |proj g|=       0.63034
At iterate    38  f =      -555.52  |proj g|=       0.62066
At iterate    39  f =      -555.56  |proj g|=       0.59221
At iterate    40  f =      -555.72  |proj g|=       0.47654
At iterate    41  f =      -555.93  |proj g|=       0.47317
At iterate    42  f =      -556.16  |proj g|=       0.46267
At iterate    43  f =      -556.17  |proj g|=       0.61004
At iterate    44  f =      -556.18  |proj g|=       0.61607
At iterate    45  f =      -556.29  |proj g|=       0.54605
At iterate    46  f =       -556.3  |proj g|=       0.55251
At iterate    47  f =       -556.3  |proj g|=       0.55196
At iterate    48  f =       -556.3  |proj g|=       0.55194

iterations 48
function evaluations 56
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.551943
final function value -556.3

F = -556.3
final  value -556.300427 
converged
 
INFO  [06:12:33.380] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:12:33.466] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:12:33.473] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:12:39.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:12:45.457] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:12:51.335] [mlr3]  Finished benchmark 
INFO  [06:12:51.453] [bbotk] Result of batch 95: 
INFO  [06:12:51.455] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:12:51.455] [bbotk]               9.87537                 2.699046                      0.01394463 
INFO  [06:12:51.455] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:12:51.455] [bbotk]                     4040        0.878 -0.9447186         <NA>   0.9558918 
INFO  [06:12:51.455] [bbotk]                                 uhash 
INFO  [06:12:51.455] [bbotk]  ec3f934f-43c6-473f-85db-8abef18d9d8e 
DEBUG [06:12:52.719] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.161773e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.161773e-05 0.001466444 
  - best initial criterion value(s) :  500.5771 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -500.58  |proj g|=       5.2502
At iterate     1  f =      -507.66  |proj g|=        8.8869
At iterate     2  f =      -510.95  |proj g|=        8.3622
At iterate     3  f =      -517.29  |proj g|=        6.3265
At iterate     4  f =       -517.9  |proj g|=        5.6029
At iterate     5  f =      -518.24  |proj g|=         5.359
At iterate     6  f =      -518.51  |proj g|=        5.5676
At iterate     7  f =      -518.51  |proj g|=        5.4938
At iterate     8  f =      -518.51  |proj g|=        5.5007
At iterate     9  f =      -518.51  |proj g|=        5.5013
At iterate    10  f =      -518.51  |proj g|=        5.5067
At iterate    11  f =      -518.51  |proj g|=         5.511
At iterate    12  f =      -518.52  |proj g|=        5.5241
At iterate    13  f =      -518.52  |proj g|=        5.5401
At iterate    14  f =      -518.52  |proj g|=        5.5657
At iterate    15  f =      -518.53  |proj g|=        5.5958
At iterate    16  f =      -518.56  |proj g|=         5.657
At iterate    17  f =      -518.63  |proj g|=          5.71
At iterate    18  f =       -518.8  |proj g|=        5.8585
At iterate    19  f =      -519.23  |proj g|=        5.8612
At iterate    20  f =      -519.33  |proj g|=        6.3511
At iterate    21  f =      -520.34  |proj g|=        6.3015
At iterate    22  f =      -529.24  |proj g|=         6.223
At iterate    23  f =       -544.7  |proj g|=        6.2767
At iterate    24  f =      -546.67  |proj g|=        6.1769
At iterate    25  f =      -547.52  |proj g|=        6.2281
At iterate    26  f =      -547.55  |proj g|=        6.5869
At iterate    27  f =      -547.66  |proj g|=        6.4979
At iterate    28  f =      -547.66  |proj g|=        6.4926
At iterate    29  f =      -547.66  |proj g|=        6.4955
At iterate    30  f =      -547.66  |proj g|=        6.4986
At iterate    31  f =      -547.66  |proj g|=        6.5143
At iterate    32  f =      -547.66  |proj g|=         6.529
At iterate    33  f =      -547.66  |proj g|=        6.5681
At iterate    34  f =      -547.67  |proj g|=        6.6038
At iterate    35  f =      -547.69  |proj g|=        6.6897
At iterate    36  f =      -547.73  |proj g|=        6.7561
At iterate    37  f =      -547.85  |proj g|=        6.8893
At iterate    38  f =      -548.13  |proj g|=        6.8189
At iterate    39  f =      -548.17  |proj g|=        7.0736
At iterate    40  f =      -548.75  |proj g|=        6.7374
At iterate    41  f =       -552.5  |proj g|=         4.886
At iterate    42  f =      -558.61  |proj g|=        2.3247
At iterate    43  f =       -560.6  |proj g|=        1.2941
At iterate    44  f =       -561.8  |proj g|=       0.47479
At iterate    45  f =      -561.88  |proj g|=       0.45047
At iterate    46  f =      -561.89  |proj g|=       0.51872
At iterate    47  f =      -561.89  |proj g|=      0.081518
At iterate    48  f =      -561.89  |proj g|=     0.0032002
At iterate    49  f =      -561.89  |proj g|=     0.0012685

iterations 49
function evaluations 60
segments explored during Cauchy searches 52
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00126847
final function value -561.893

F = -561.893
final  value -561.892784 
converged
 
INFO  [06:12:52.723] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:12:52.808] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:12:52.815] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:13:01.224] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:13:08.980] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:13:16.951] [mlr3]  Finished benchmark 
INFO  [06:13:17.050] [bbotk] Result of batch 96: 
INFO  [06:13:17.051] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:13:17.051] [bbotk]              5.529112                 6.271226                       0.2541603 
INFO  [06:13:17.051] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:13:17.051] [bbotk]                     4905         0.76 -0.942401         <NA>   0.9760011 
INFO  [06:13:17.051] [bbotk]                                 uhash 
INFO  [06:13:17.051] [bbotk]  43bb513a-db54-4809-8bb6-aba7b5952b39 
DEBUG [06:13:18.235] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.156826e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.156826e-05 0.001465265 
  - best initial criterion value(s) :  525.8002 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -525.8  |proj g|=       4.7074
At iterate     1  f =      -527.86  |proj g|=        5.7897
At iterate     2  f =       -529.1  |proj g|=        5.2681
At iterate     3  f =       -529.7  |proj g|=        4.8088
At iterate     4  f =      -530.11  |proj g|=        4.9221
At iterate     5  f =      -530.38  |proj g|=        4.8461
At iterate     6  f =      -531.33  |proj g|=        4.1801
At iterate     7  f =      -531.36  |proj g|=        4.2404
At iterate     8  f =      -531.36  |proj g|=         4.233
At iterate     9  f =      -531.36  |proj g|=        4.2296
At iterate    10  f =      -531.36  |proj g|=        4.2341
At iterate    11  f =      -531.36  |proj g|=        4.2288
At iterate    12  f =      -531.37  |proj g|=        4.2056
At iterate    13  f =       -531.4  |proj g|=        4.1622
At iterate    14  f =      -531.48  |proj g|=         4.092
At iterate    15  f =      -531.92  |proj g|=        3.9004
At iterate    16  f =      -531.98  |proj g|=        3.8054
At iterate    17  f =      -533.23  |proj g|=        3.4523
At iterate    18  f =       -536.1  |proj g|=        2.9471
At iterate    19  f =      -543.99  |proj g|=        2.1379
At iterate    20  f =      -557.22  |proj g|=        1.1122
At iterate    21  f =      -560.62  |proj g|=       0.98491
At iterate    22  f =      -561.17  |proj g|=        0.7153
At iterate    23  f =      -565.38  |proj g|=        0.6415
At iterate    24  f =       -566.6  |proj g|=       0.58958
At iterate    25  f =      -566.94  |proj g|=       0.55252
At iterate    26  f =      -566.98  |proj g|=       0.43334
At iterate    27  f =      -566.99  |proj g|=       0.43768
At iterate    28  f =      -566.99  |proj g|=       0.53513
At iterate    29  f =      -566.99  |proj g|=       0.33608
At iterate    30  f =      -566.99  |proj g|=       0.33598

iterations 30
function evaluations 38
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.335978
final function value -566.992

F = -566.992
final  value -566.992342 
converged
 
INFO  [06:13:18.239] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:13:18.343] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:13:18.350] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:13:25.172] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:13:31.242] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:13:37.151] [mlr3]  Finished benchmark 
INFO  [06:13:37.249] [bbotk] Result of batch 97: 
INFO  [06:13:37.251] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:13:37.251] [bbotk]               7.07906                  6.69617                       0.0523601 
INFO  [06:13:37.251] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:13:37.251] [bbotk]                     2883        0.777 -0.9438023         <NA>   0.9663239 
INFO  [06:13:37.251] [bbotk]                                 uhash 
INFO  [06:13:37.251] [bbotk]  4286d969-4590-4010-b366-24cf9e885fc1 
DEBUG [06:13:38.386] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.148155e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.148155e-05 0.001457492 
  - best initial criterion value(s) :  518.7836 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -518.78  |proj g|=       3.7875
At iterate     1  f =      -536.82  |proj g|=        3.0971
At iterate     2  f =       -549.2  |proj g|=         3.795
At iterate     3  f =      -550.45  |proj g|=        3.6742
At iterate     4  f =      -551.98  |proj g|=        3.3914
At iterate     5  f =      -552.18  |proj g|=        3.2902
At iterate     6  f =      -552.22  |proj g|=        3.2604
At iterate     7  f =      -552.26  |proj g|=        3.3893
At iterate     8  f =      -552.28  |proj g|=        3.3367
At iterate     9  f =      -552.28  |proj g|=        3.3347
At iterate    10  f =      -552.28  |proj g|=        3.3346
At iterate    11  f =      -552.28  |proj g|=        3.3345
At iterate    12  f =      -552.28  |proj g|=        3.3353
At iterate    13  f =      -552.28  |proj g|=        3.3324
At iterate    14  f =      -552.28  |proj g|=        3.3626
At iterate    15  f =      -552.29  |proj g|=        3.3386
At iterate    16  f =      -552.31  |proj g|=        3.3111
At iterate    17  f =      -552.34  |proj g|=        3.2575
At iterate    18  f =      -552.44  |proj g|=        3.1673
At iterate    19  f =      -552.69  |proj g|=        3.0049
At iterate    20  f =      -553.26  |proj g|=        2.7417
At iterate    21  f =       -554.6  |proj g|=        2.2983
At iterate    22  f =      -557.02  |proj g|=        1.7592
At iterate    23  f =      -561.36  |proj g|=       0.66943
At iterate    24  f =      -564.05  |proj g|=        1.9656
At iterate    25  f =      -566.09  |proj g|=        1.8944
At iterate    26  f =      -570.25  |proj g|=        1.2032
At iterate    27  f =      -570.53  |proj g|=       0.89854
At iterate    28  f =      -570.53  |proj g|=        1.0272
At iterate    29  f =      -570.54  |proj g|=       0.97367
At iterate    30  f =      -570.54  |proj g|=       0.97334

iterations 30
function evaluations 37
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.973337
final function value -570.537

F = -570.537
final  value -570.537275 
converged
 
INFO  [06:13:38.390] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:13:38.475] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:13:38.482] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:13:49.625] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:14:00.043] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:14:11.472] [mlr3]  Finished benchmark 
INFO  [06:14:11.572] [bbotk] Result of batch 98: 
INFO  [06:14:11.574] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:14:11.574] [bbotk]              7.918328                 3.934351                       0.1721373 
INFO  [06:14:11.574] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:14:11.574] [bbotk]                     4996         0.74 -0.9476126         <NA>   0.9752296 
INFO  [06:14:11.574] [bbotk]                                 uhash 
INFO  [06:14:11.574] [bbotk]  7c46aa83-e265-4a56-919e-5912b513655b 
DEBUG [06:14:12.593] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.142516e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.142516e-05 0.001453082 
  - best initial criterion value(s) :  545.3613 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -545.36  |proj g|=       2.4539
At iterate     1  f =       -562.6  |proj g|=        3.8327
At iterate     2  f =      -563.68  |proj g|=        3.3354
At iterate     3  f =      -564.37  |proj g|=        2.5328
At iterate     4  f =      -564.64  |proj g|=        2.6594
At iterate     5  f =      -564.85  |proj g|=        2.7061
At iterate     6  f =      -564.86  |proj g|=        2.6763
At iterate     7  f =      -564.86  |proj g|=        2.6828
At iterate     8  f =      -564.86  |proj g|=        2.6824
At iterate     9  f =      -564.86  |proj g|=        2.6824

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.68238
final function value -564.86

F = -564.86
final  value -564.859728 
converged
 
INFO  [06:14:12.598] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:14:12.864] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:14:12.871] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:14:22.469] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:14:30.224] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:14:38.433] [mlr3]  Finished benchmark 
INFO  [06:14:38.532] [bbotk] Result of batch 99: 
INFO  [06:14:38.534] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:14:38.534] [bbotk]              7.894463                 6.147737                       0.4568734 
INFO  [06:14:38.534] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:14:38.534] [bbotk]                     3267        0.735 -0.9506528         <NA>   0.9764659 
INFO  [06:14:38.534] [bbotk]                                 uhash 
INFO  [06:14:38.534] [bbotk]  419ab1a3-0124-440b-8c41-ce58f2c497e3 
DEBUG [06:14:39.704] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.138269e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.138269e-05 0.001455778 
  - best initial criterion value(s) :  522.7133 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -522.71  |proj g|=       5.4419
At iterate     1  f =       -530.5  |proj g|=        6.1793
At iterate     2  f =      -533.51  |proj g|=        5.8984
At iterate     3  f =      -536.08  |proj g|=        5.1027
At iterate     4  f =      -536.14  |proj g|=        4.8415
At iterate     5  f =      -536.17  |proj g|=        4.9068
At iterate     6  f =      -536.23  |proj g|=        4.9309
At iterate     7  f =      -536.33  |proj g|=        4.8765
At iterate     8  f =      -536.39  |proj g|=        4.7525
At iterate     9  f =       -536.4  |proj g|=        4.6765
At iterate    10  f =       -536.4  |proj g|=        4.6743
At iterate    11  f =       -536.4  |proj g|=        4.6747
At iterate    12  f =       -536.4  |proj g|=        4.6745
At iterate    13  f =       -536.4  |proj g|=        4.6744
At iterate    14  f =       -536.4  |proj g|=        4.6738
At iterate    15  f =       -536.4  |proj g|=        4.6747
At iterate    16  f =      -536.41  |proj g|=        4.6649
At iterate    17  f =      -536.43  |proj g|=        4.6761
At iterate    18  f =      -536.45  |proj g|=        4.5869
At iterate    19  f =      -536.51  |proj g|=        4.6171
At iterate    20  f =      -536.79  |proj g|=        4.6804
At iterate    21  f =      -538.31  |proj g|=        4.6103
At iterate    22  f =      -543.36  |proj g|=         3.855
At iterate    23  f =      -544.25  |proj g|=        3.4547
At iterate    24  f =      -544.26  |proj g|=        3.3947
At iterate    25  f =      -544.52  |proj g|=        3.3221
At iterate    26  f =       -544.6  |proj g|=        3.3158
At iterate    27  f =      -544.61  |proj g|=        3.3201
At iterate    28  f =      -544.61  |proj g|=        3.3175
At iterate    29  f =      -544.61  |proj g|=        3.3181

iterations 29
function evaluations 36
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.31814
final function value -544.608

F = -544.608
final  value -544.608290 
converged
 
INFO  [06:14:39.709] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:14:39.820] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:14:39.827] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:14:42.521] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:14:45.451] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:14:48.691] [mlr3]  Finished benchmark 
INFO  [06:14:48.792] [bbotk] Result of batch 100: 
INFO  [06:14:48.794] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:14:48.794] [bbotk]               2.53997                 3.025179                       0.3726612 
INFO  [06:14:48.794] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:14:48.794] [bbotk]                     1362        0.762 -0.9599563         <NA>   0.9610994 
INFO  [06:14:48.794] [bbotk]                                 uhash 
INFO  [06:14:48.794] [bbotk]  56a15ed9-fcb0-4ef9-adcb-4f72d65ced59 
DEBUG [06:14:49.944] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.134022e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.134022e-05 0.001444918 
  - best initial criterion value(s) :  524.9352 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -524.94  |proj g|=        14.06
At iterate     1  f =      -560.51  |proj g|=        5.5056
At iterate     2  f =      -569.07  |proj g|=        5.7619
At iterate     3  f =      -571.88  |proj g|=        3.9969
At iterate     4  f =      -574.07  |proj g|=        1.9565
At iterate     5  f =      -574.44  |proj g|=        1.3836
At iterate     6  f =      -574.65  |proj g|=        1.1329
At iterate     7  f =       -574.9  |proj g|=         2.207
At iterate     8  f =      -575.14  |proj g|=        1.5129
At iterate     9  f =      -575.15  |proj g|=        1.4441
At iterate    10  f =      -575.15  |proj g|=        1.4379
At iterate    11  f =      -575.15  |proj g|=        1.4384
At iterate    12  f =      -575.15  |proj g|=        1.4491
At iterate    13  f =      -575.15  |proj g|=        1.4551
At iterate    14  f =      -575.17  |proj g|=        1.4591
At iterate    15  f =       -575.2  |proj g|=        1.4369
At iterate    16  f =      -575.29  |proj g|=        1.3499
At iterate    17  f =      -575.44  |proj g|=        1.1708
At iterate    18  f =       -575.7  |proj g|=        1.0067
At iterate    19  f =      -576.04  |proj g|=       0.62121
At iterate    20  f =      -576.46  |proj g|=        0.5981
At iterate    21  f =      -577.53  |proj g|=       0.45956
At iterate    22  f =      -578.61  |proj g|=       0.58083
At iterate    23  f =      -578.65  |proj g|=        0.5739
At iterate    24  f =      -578.66  |proj g|=       0.54347
At iterate    25  f =      -578.66  |proj g|=       0.54202
At iterate    26  f =      -578.66  |proj g|=       0.54038
At iterate    27  f =      -578.66  |proj g|=       0.54015
At iterate    28  f =      -578.66  |proj g|=       0.54013

iterations 28
function evaluations 33
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.540132
final function value -578.663

F = -578.663
final  value -578.663019 
converged
 
INFO  [06:14:49.948] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:14:50.065] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:14:50.072] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:14:56.806] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:15:03.571] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:15:10.470] [mlr3]  Finished benchmark 
INFO  [06:15:10.572] [bbotk] Result of batch 101: 
INFO  [06:15:10.574] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:15:10.574] [bbotk]              9.715047                 5.077988                       0.1448428 
INFO  [06:15:10.574] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:15:10.574] [bbotk]                     3211        0.755 -0.9504096         <NA>   0.9731055 
INFO  [06:15:10.574] [bbotk]                                 uhash 
INFO  [06:15:10.574] [bbotk]  9d98c363-9b86-44e8-8980-10b27429f264 
DEBUG [06:15:11.861] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.126818e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.126818e-05 0.001440878 
  - best initial criterion value(s) :  521.8527 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -521.85  |proj g|=       5.3769
At iterate     1  f =      -544.92  |proj g|=        3.0864
At iterate     2  f =      -548.09  |proj g|=          3.25
At iterate     3  f =       -554.9  |proj g|=        2.6018
At iterate     4  f =       -558.3  |proj g|=          2.08
At iterate     5  f =       -560.4  |proj g|=        2.5482
At iterate     6  f =      -560.41  |proj g|=        2.6027
At iterate     7  f =      -560.41  |proj g|=        2.5921
At iterate     8  f =      -560.41  |proj g|=        2.5914
At iterate     9  f =      -560.74  |proj g|=        2.6272
At iterate    10  f =      -562.94  |proj g|=         2.579
At iterate    11  f =      -566.24  |proj g|=        2.3523
At iterate    12  f =      -569.53  |proj g|=        1.9608
At iterate    13  f =      -569.98  |proj g|=        1.8942
At iterate    14  f =      -570.13  |proj g|=        1.8101
At iterate    15  f =      -570.17  |proj g|=        1.7928
At iterate    16  f =      -570.17  |proj g|=         1.788
At iterate    17  f =      -570.17  |proj g|=        1.7887
At iterate    18  f =      -570.17  |proj g|=        1.7887

iterations 18
function evaluations 28
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.78866
final function value -570.173

F = -570.173
final  value -570.173269 
converged
 
INFO  [06:15:11.865] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:15:11.955] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:15:11.962] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:15:16.701] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:15:19.264] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:15:22.281] [mlr3]  Finished benchmark 
INFO  [06:15:22.380] [bbotk] Result of batch 102: 
INFO  [06:15:22.382] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:15:22.382] [bbotk]              2.674352                   5.7495                       0.4251656 
INFO  [06:15:22.382] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:15:22.382] [bbotk]                     1271        0.733 -0.9561775         <NA>   0.9633104 
INFO  [06:15:22.382] [bbotk]                                 uhash 
INFO  [06:15:22.382] [bbotk]  95393b88-17ff-4e19-9448-4de67cd21d68 
DEBUG [06:15:23.546] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.120514e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.120514e-05 0.001427096 
  - best initial criterion value(s) :  542.8015 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -542.8  |proj g|=       1.1903
At iterate     1  f =      -569.01  |proj g|=         12.12
At iterate     2  f =      -574.27  |proj g|=        11.429
At iterate     3  f =      -575.93  |proj g|=        7.8046
At iterate     4  f =      -576.66  |proj g|=        9.1543
At iterate     5  f =      -576.76  |proj g|=        8.4872
At iterate     6  f =      -576.77  |proj g|=        8.5513
At iterate     7  f =      -576.77  |proj g|=        8.5651
At iterate     8  f =      -576.77  |proj g|=        8.5492
At iterate     9  f =      -576.77  |proj g|=        8.5395
At iterate    10  f =      -576.81  |proj g|=        8.4399
At iterate    11  f =       -576.9  |proj g|=        8.2904
At iterate    12  f =      -577.21  |proj g|=         7.916
At iterate    13  f =      -577.21  |proj g|=         7.866
At iterate    14  f =      -577.93  |proj g|=        7.1549
At iterate    15  f =      -584.88  |proj g|=        4.2531
At iterate    16  f =      -589.52  |proj g|=        2.2808
At iterate    17  f =      -590.91  |proj g|=        2.3326
At iterate    18  f =      -591.22  |proj g|=        2.3931
At iterate    19  f =      -591.31  |proj g|=        2.5215
At iterate    20  f =      -591.37  |proj g|=        2.5314
At iterate    21  f =      -591.38  |proj g|=        2.5414
At iterate    22  f =      -591.38  |proj g|=        2.5459
At iterate    23  f =      -591.38  |proj g|=        2.5558
At iterate    24  f =      -591.38  |proj g|=        2.5638
At iterate    25  f =      -591.39  |proj g|=        2.5626
At iterate    26  f =      -591.39  |proj g|=        2.5738
At iterate    27  f =       -591.4  |proj g|=        2.5622
At iterate    28  f =       -591.4  |proj g|=        2.5432
At iterate    29  f =       -591.4  |proj g|=        2.5433
At iterate    30  f =       -591.4  |proj g|=        2.5433

iterations 30
function evaluations 43
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.54332
final function value -591.402

F = -591.402
final  value -591.402320 
converged
 
INFO  [06:15:23.550] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:15:23.670] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:15:23.677] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:15:27.714] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:15:31.331] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:15:34.760] [mlr3]  Finished benchmark 
INFO  [06:15:34.860] [bbotk] Result of batch 103: 
INFO  [06:15:34.862] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:15:34.862] [bbotk]              9.106597                 5.830963                      0.09052983 
INFO  [06:15:34.862] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:15:34.862] [bbotk]                     1622        0.734 -0.9450242         <NA>   0.9665791 
INFO  [06:15:34.862] [bbotk]                                 uhash 
INFO  [06:15:34.862] [bbotk]  e301b147-bbc1-41d0-94ad-786c2ac149a0 
DEBUG [06:15:35.896] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.11243e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.11243e-05 0.001410404 
  - best initial criterion value(s) :  534.7407 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -534.74  |proj g|=       4.6581
At iterate     1  f =      -535.87  |proj g|=        6.7545
At iterate     2  f =      -537.49  |proj g|=        6.2135
At iterate     3  f =      -539.92  |proj g|=        5.1134
At iterate     4  f =      -543.28  |proj g|=         2.281
At iterate     5  f =      -549.04  |proj g|=        1.6946
At iterate     6  f =      -550.61  |proj g|=        1.8137
At iterate     7  f =      -550.72  |proj g|=        1.8702
At iterate     8  f =      -550.72  |proj g|=        1.8653
At iterate     9  f =      -550.72  |proj g|=        1.8644
At iterate    10  f =      -550.72  |proj g|=        1.8644

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.86443
final function value -550.718

F = -550.718
final  value -550.718457 
converged
 
INFO  [06:15:35.901] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:15:36.026] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:15:36.034] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:15:41.257] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:15:47.669] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:15:52.616] [mlr3]  Finished benchmark 
INFO  [06:15:52.736] [bbotk] Result of batch 104: 
INFO  [06:15:52.738] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:15:52.738] [bbotk]              3.178865                 7.720675                       0.2439346 
INFO  [06:15:52.738] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:15:52.738] [bbotk]                     2311         0.74 -0.9630669         <NA>   0.9681352 
INFO  [06:15:52.738] [bbotk]                                 uhash 
INFO  [06:15:52.738] [bbotk]  bcda24f3-dc2a-48c2-bece-e83f17e02e15 
DEBUG [06:15:54.199] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.104152e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.104152e-05 0.001409195 
  - best initial criterion value(s) :  541.0579 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -541.06  |proj g|=       13.298
At iterate     1  f =      -568.47  |proj g|=        2.2659
At iterate     2  f =      -589.47  |proj g|=        2.9074
At iterate     3  f =      -593.53  |proj g|=        2.3323
At iterate     4  f =      -597.78  |proj g|=        2.2503
At iterate     5  f =       -599.6  |proj g|=        2.2206
At iterate     6  f =      -600.84  |proj g|=        2.2472
At iterate     7  f =         -602  |proj g|=        2.6445
At iterate     8  f =      -602.85  |proj g|=        2.6112
At iterate     9  f =      -603.21  |proj g|=        2.6305
At iterate    10  f =      -603.33  |proj g|=        2.6742
At iterate    11  f =      -603.37  |proj g|=        2.7172
At iterate    12  f =      -603.38  |proj g|=        2.7354
At iterate    13  f =      -603.38  |proj g|=        2.7383
At iterate    14  f =      -603.38  |proj g|=        2.7389
At iterate    15  f =      -603.38  |proj g|=        2.7411
At iterate    16  f =      -603.38  |proj g|=        2.7439
At iterate    17  f =      -603.38  |proj g|=        2.7486
At iterate    18  f =      -603.38  |proj g|=        2.7557
At iterate    19  f =      -603.38  |proj g|=        2.7675
At iterate    20  f =      -603.39  |proj g|=        2.7849
At iterate    21  f =      -603.42  |proj g|=        2.8093
At iterate    22  f =      -603.49  |proj g|=        2.8319
At iterate    23  f =      -603.61  |proj g|=        2.8138
At iterate    24  f =      -603.63  |proj g|=        2.7547
At iterate    25  f =      -603.65  |proj g|=        2.7396
At iterate    26  f =      -603.95  |proj g|=        2.7632
At iterate    27  f =      -606.05  |proj g|=        2.7144
At iterate    28  f =      -606.55  |proj g|=        2.6079
At iterate    29  f =      -606.61  |proj g|=        2.5437
At iterate    30  f =      -606.62  |proj g|=        2.5168
At iterate    31  f =      -606.62  |proj g|=        2.5117
At iterate    32  f =      -606.62  |proj g|=        2.5105
At iterate    33  f =      -606.62  |proj g|=         2.513
At iterate    34  f =      -606.62  |proj g|=        2.5146
At iterate    35  f =      -606.62  |proj g|=        2.5155
At iterate    36  f =      -606.62  |proj g|=         2.515
At iterate    37  f =      -606.62  |proj g|=        2.5074
At iterate    38  f =      -606.62  |proj g|=          2.51
At iterate    39  f =      -606.62  |proj g|=         2.517
At iterate    40  f =      -606.63  |proj g|=        2.5257
At iterate    41  f =      -606.65  |proj g|=        2.5391
At iterate    42  f =       -606.7  |proj g|=        2.5537
At iterate    43  f =      -606.82  |proj g|=        2.5579
At iterate    44  f =      -607.12  |proj g|=        2.5202
At iterate    45  f =      -607.79  |proj g|=         2.201
At iterate    46  f =      -608.97  |proj g|=        1.1442
At iterate    47  f =       -609.5  |proj g|=       0.94273
At iterate    48  f =      -609.98  |proj g|=        1.1782
At iterate    49  f =      -610.01  |proj g|=        1.2292
At iterate    50  f =      -610.13  |proj g|=        1.5196
At iterate    51  f =      -610.13  |proj g|=        1.5543
At iterate    52  f =      -610.14  |proj g|=        1.5802
At iterate    53  f =      -610.14  |proj g|=        1.5613
At iterate    54  f =      -610.14  |proj g|=          1.53
At iterate    55  f =      -610.14  |proj g|=        1.5281
At iterate    56  f =      -610.14  |proj g|=        1.5122
At iterate    57  f =      -610.15  |proj g|=        1.4923
At iterate    58  f =      -610.16  |proj g|=        1.4547
At iterate    59  f =      -610.19  |proj g|=        1.3929
At iterate    60  f =      -610.25  |proj g|=        1.2827
At iterate    61  f =      -611.85  |proj g|=        1.1031
At iterate    62  f =      -613.18  |proj g|=       0.44835
At iterate    63  f =      -613.55  |proj g|=       0.50122
At iterate    64  f =      -613.68  |proj g|=       0.48079
At iterate    65  f =      -613.71  |proj g|=       0.46503
At iterate    66  f =      -613.71  |proj g|=      0.063571
At iterate    67  f =      -613.72  |proj g|=      0.009817
At iterate    68  f =      -613.72  |proj g|=     0.0010621
At iterate    69  f =      -613.72  |proj g|=    0.00064051

iterations 69
function evaluations 89
segments explored during Cauchy searches 72
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.000640512
final function value -613.715

F = -613.715
final  value -613.715153 
converged
 
INFO  [06:15:54.203] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:15:54.293] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:15:54.300] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:16:08.398] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:16:22.619] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:16:30.603] [mlr3]  Finished benchmark 
INFO  [06:16:31.183] [bbotk] Result of batch 105: 
INFO  [06:16:31.184] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:16:31.184] [bbotk]              4.071746                 9.718978                      0.01085691 
INFO  [06:16:31.184] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:16:31.184] [bbotk]                     4947        0.768 -0.9366196         <NA>   0.9489934 
INFO  [06:16:31.184] [bbotk]                                 uhash 
INFO  [06:16:31.184] [bbotk]  f05bb1dd-507e-49be-ac42-641ee4db2f42 
DEBUG [06:16:32.322] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.124523e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9738152 9504 
  - variance bounds :  1.124523e-05 0.001429805 
  - best initial criterion value(s) :  548.8132 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -548.81  |proj g|=       7.2047
At iterate     1  f =      -579.16  |proj g|=        6.5818
At iterate     2  f =      -583.91  |proj g|=        5.3251
At iterate     3  f =      -587.73  |proj g|=        4.0634
At iterate     4  f =      -588.84  |proj g|=        4.6283
At iterate     5  f =      -589.04  |proj g|=        4.5901
At iterate     6  f =      -590.21  |proj g|=        4.4729
At iterate     7  f =      -591.02  |proj g|=        4.5824
At iterate     8  f =      -591.43  |proj g|=        4.7528
At iterate     9  f =      -591.55  |proj g|=        4.8757
At iterate    10  f =      -591.57  |proj g|=        4.9467
At iterate    11  f =      -591.57  |proj g|=        4.9642
At iterate    12  f =      -591.57  |proj g|=        4.9674
At iterate    13  f =      -591.57  |proj g|=        4.9667
At iterate    14  f =      -591.57  |proj g|=        4.9664
At iterate    15  f =      -591.57  |proj g|=        4.9658
At iterate    16  f =      -591.57  |proj g|=        4.9643
At iterate    17  f =      -591.58  |proj g|=        4.9624
At iterate    18  f =      -591.58  |proj g|=        4.9573
At iterate    19  f =      -591.58  |proj g|=        4.9584
At iterate    20  f =      -591.59  |proj g|=        4.9267
At iterate    21  f =       -591.6  |proj g|=        4.9336
At iterate    22  f =      -592.24  |proj g|=        4.9964
At iterate    23  f =      -592.95  |proj g|=        4.9649
At iterate    24  f =      -592.97  |proj g|=        4.9241
At iterate    25  f =      -592.97  |proj g|=        4.9246
At iterate    26  f =      -592.97  |proj g|=        4.9251

iterations 26
function evaluations 31
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.92513
final function value -592.968

F = -592.968
final  value -592.967899 
converged
 
INFO  [06:16:32.327] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:16:32.421] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:16:32.429] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:16:38.145] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:16:43.983] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:16:49.582] [mlr3]  Finished benchmark 
INFO  [06:16:49.679] [bbotk] Result of batch 106: 
INFO  [06:16:49.681] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:16:49.681] [bbotk]              7.307257                 7.800454                       0.2668451 
INFO  [06:16:49.681] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:16:49.681] [bbotk]                     3617        0.763 -0.9448872         <NA>   0.9753027 
INFO  [06:16:49.681] [bbotk]                                 uhash 
INFO  [06:16:49.681] [bbotk]  748deae3-8b97-4ae8-8808-fce0c6628707 
DEBUG [06:16:51.239] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.11958e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9738152 9504 
  - variance bounds :  1.11958e-05 0.001427734 
  - best initial criterion value(s) :  541.3351 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -541.34  |proj g|=       6.4862
At iterate     1  f =      -548.79  |proj g|=        3.2716
At iterate     2  f =      -549.24  |proj g|=        3.1298
At iterate     3  f =      -549.73  |proj g|=        2.5789
At iterate     4  f =      -549.77  |proj g|=        2.7303
At iterate     5  f =      -549.81  |proj g|=        2.5294
At iterate     6  f =      -549.81  |proj g|=        2.4824
At iterate     7  f =      -549.81  |proj g|=        2.4812
At iterate     8  f =      -549.81  |proj g|=        2.4801
At iterate     9  f =      -549.81  |proj g|=        2.4794
At iterate    10  f =      -549.82  |proj g|=        2.4673
At iterate    11  f =      -549.82  |proj g|=        2.4724
At iterate    12  f =      -549.83  |proj g|=        2.4527
At iterate    13  f =      -549.87  |proj g|=        2.3904
At iterate    14  f =      -549.96  |proj g|=        2.2706
At iterate    15  f =      -550.14  |proj g|=        2.3372
At iterate    16  f =      -550.52  |proj g|=        2.3221
At iterate    17  f =      -550.55  |proj g|=        2.4394
At iterate    18  f =       -551.5  |proj g|=        2.3487
At iterate    19  f =      -553.77  |proj g|=        2.3304
At iterate    20  f =      -556.96  |proj g|=        2.4721
At iterate    21  f =      -557.93  |proj g|=        2.2692
At iterate    22  f =      -558.47  |proj g|=        2.2633
At iterate    23  f =      -558.63  |proj g|=        2.2068
At iterate    24  f =      -558.67  |proj g|=        2.2974
At iterate    25  f =       -558.7  |proj g|=        2.2696
At iterate    26  f =       -558.7  |proj g|=        2.2671
At iterate    27  f =       -558.7  |proj g|=        2.2668
At iterate    28  f =       -558.7  |proj g|=        2.2668

iterations 28
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.26676
final function value -558.705

F = -558.705
final  value -558.704568 
converged
 
INFO  [06:16:51.244] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:16:51.338] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:16:51.346] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:16:57.853] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:17:04.204] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:17:10.574] [mlr3]  Finished benchmark 
INFO  [06:17:10.673] [bbotk] Result of batch 107: 
INFO  [06:17:10.674] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:17:10.674] [bbotk]              7.559464                 5.033261                       0.3887044 
INFO  [06:17:10.674] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:17:10.674] [bbotk]                     4207        1.097 -0.9612276         <NA>   0.9765578 
INFO  [06:17:10.674] [bbotk]                                 uhash 
INFO  [06:17:10.674] [bbotk]  2a116bb4-999b-49e7-86a0-d488902b2cd2 
DEBUG [06:17:11.933] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.115994e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9738152 9504 
  - variance bounds :  1.115994e-05 0.00142786 
  - best initial criterion value(s) :  582.1858 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -582.19  |proj g|=       3.9004
At iterate     1  f =      -614.77  |proj g|=        3.4286
At iterate     2  f =      -615.56  |proj g|=        2.8496
At iterate     3  f =      -615.97  |proj g|=        2.4909
At iterate     4  f =      -616.27  |proj g|=        2.4638
At iterate     5  f =      -616.41  |proj g|=        2.5383
At iterate     6  f =      -616.42  |proj g|=         2.528
At iterate     7  f =      -616.42  |proj g|=        2.5284
At iterate     8  f =      -616.42  |proj g|=        2.5289
At iterate     9  f =      -616.42  |proj g|=         2.531
At iterate    10  f =      -616.42  |proj g|=         2.534
At iterate    11  f =      -616.42  |proj g|=         2.539
At iterate    12  f =      -616.42  |proj g|=        2.5472
At iterate    13  f =      -616.43  |proj g|=        2.5606
At iterate    14  f =      -616.45  |proj g|=        2.5821
At iterate    15  f =      -616.49  |proj g|=        2.6159
At iterate    16  f =      -616.58  |proj g|=        2.6608
At iterate    17  f =      -616.74  |proj g|=          2.69
At iterate    18  f =      -616.81  |proj g|=        2.6077
At iterate    19  f =      -616.87  |proj g|=        2.6263
At iterate    20  f =      -617.48  |proj g|=        2.6192
At iterate    21  f =      -617.49  |proj g|=        2.6425
At iterate    22  f =      -617.49  |proj g|=        2.6478
At iterate    23  f =      -617.49  |proj g|=        2.6484
At iterate    24  f =      -617.49  |proj g|=        2.6487

iterations 24
function evaluations 30
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.64874
final function value -617.494

F = -617.494
final  value -617.493882 
converged
 
INFO  [06:17:11.937] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:17:12.037] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:17:12.044] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:17:18.401] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:17:25.000] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:17:31.540] [mlr3]  Finished benchmark 
INFO  [06:17:31.638] [bbotk] Result of batch 108: 
INFO  [06:17:31.640] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:17:31.640] [bbotk]              7.781282                 5.250948                     0.005642083 
INFO  [06:17:31.640] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:17:31.640] [bbotk]                     4284        0.846 -0.9422821         <NA>   0.9423694 
INFO  [06:17:31.640] [bbotk]                                 uhash 
INFO  [06:17:31.640] [bbotk]  d1933d56-9f62-4beb-a06a-54434e129cfd 
DEBUG [06:17:32.977] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.157633e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.157633e-05 0.001462951 
  - best initial criterion value(s) :  546.506 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -546.51  |proj g|=       7.4723
At iterate     1  f =      -556.93  |proj g|=         7.953
At iterate     2  f =      -558.36  |proj g|=        7.9757
At iterate     3  f =      -560.71  |proj g|=        7.1619
At iterate     4  f =      -561.28  |proj g|=          6.53
At iterate     5  f =      -561.89  |proj g|=        5.7109
At iterate     6  f =      -561.89  |proj g|=        5.6765
At iterate     7  f =      -561.89  |proj g|=        5.6893
At iterate     8  f =      -561.91  |proj g|=        5.7249
At iterate     9  f =      -561.94  |proj g|=        5.7885
At iterate    10  f =      -562.03  |proj g|=        5.8805
At iterate    11  f =      -562.25  |proj g|=        6.0188
At iterate    12  f =      -562.79  |proj g|=        6.2204
At iterate    13  f =      -564.08  |proj g|=        6.5208
At iterate    14  f =       -566.7  |proj g|=        6.9715
At iterate    15  f =      -567.61  |proj g|=        7.1774
At iterate    16  f =      -569.67  |proj g|=        7.4583
At iterate    17  f =      -585.86  |proj g|=        4.8514
At iterate    18  f =      -588.88  |proj g|=        5.9312
At iterate    19  f =      -589.78  |proj g|=        6.9811
At iterate    20  f =      -589.79  |proj g|=        7.1387
At iterate    21  f =      -589.79  |proj g|=        7.1447
At iterate    22  f =      -589.79  |proj g|=        7.1415
At iterate    23  f =      -589.79  |proj g|=        7.1389
At iterate    24  f =      -589.79  |proj g|=        7.1365
At iterate    25  f =      -589.79  |proj g|=        7.1248
At iterate    26  f =      -589.79  |proj g|=        7.1079
At iterate    27  f =      -589.79  |proj g|=        7.0961
At iterate    28  f =       -589.8  |proj g|=         7.092
At iterate    29  f =      -589.81  |proj g|=        7.0984
At iterate    30  f =      -589.83  |proj g|=        7.1245
At iterate    31  f =      -589.89  |proj g|=        7.1826
At iterate    32  f =      -590.05  |proj g|=        7.2993
At iterate    33  f =      -590.13  |proj g|=        6.7532
At iterate    34  f =      -590.71  |proj g|=         7.556
At iterate    35  f =      -591.57  |proj g|=        8.2826
At iterate    36  f =      -592.62  |proj g|=        8.8953
At iterate    37  f =      -592.82  |proj g|=        8.7374
At iterate    38  f =      -593.09  |proj g|=        8.7336
At iterate    39  f =      -593.12  |proj g|=        8.6743
At iterate    40  f =      -593.13  |proj g|=         8.549
At iterate    41  f =      -593.14  |proj g|=        8.5229
At iterate    42  f =      -594.56  |proj g|=        7.0768
At iterate    43  f =      -598.62  |proj g|=        5.0439
At iterate    44  f =      -607.63  |proj g|=        1.6482
At iterate    45  f =      -610.62  |proj g|=       0.40174
At iterate    46  f =      -610.69  |proj g|=       0.46642
At iterate    47  f =      -612.21  |proj g|=       0.32411
At iterate    48  f =      -612.91  |proj g|=       0.31129
At iterate    49  f =      -613.07  |proj g|=       0.40163
At iterate    50  f =      -613.19  |proj g|=       0.32403
At iterate    51  f =      -613.19  |proj g|=       0.18896
At iterate    52  f =      -613.19  |proj g|=      0.019226
At iterate    53  f =      -613.19  |proj g|=     0.0020838
At iterate    54  f =      -613.19  |proj g|=     0.0011008

iterations 54
function evaluations 67
segments explored during Cauchy searches 56
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00110084
final function value -613.19

F = -613.19
final  value -613.189509 
converged
 
INFO  [06:17:32.981] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:17:33.086] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:17:33.092] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:17:41.226] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:17:50.148] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:17:59.456] [mlr3]  Finished benchmark 
INFO  [06:17:59.555] [bbotk] Result of batch 109: 
INFO  [06:17:59.557] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:17:59.557] [bbotk]              7.224038                 4.892657                       0.3013798 
INFO  [06:17:59.557] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:17:59.557] [bbotk]                     4319        0.749 -0.9397199         <NA>   0.9760431 
INFO  [06:17:59.557] [bbotk]                                 uhash 
INFO  [06:17:59.557] [bbotk]  1a0f3902-c187-4c91-b959-511aa011dfd3 
DEBUG [06:18:00.617] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.153401e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.153401e-05 0.00146168 
  - best initial criterion value(s) :  571.5969 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -571.6  |proj g|=       3.4373
At iterate     1  f =      -598.54  |proj g|=        2.4962
At iterate     2  f =      -601.34  |proj g|=        3.8692
At iterate     3  f =      -602.34  |proj g|=        3.5069
At iterate     4  f =      -604.38  |proj g|=        2.9198
At iterate     5  f =      -604.57  |proj g|=        2.8968
At iterate     6  f =      -604.63  |proj g|=        2.9713
At iterate     7  f =      -604.64  |proj g|=        2.9394
At iterate     8  f =      -604.65  |proj g|=        2.9413
At iterate     9  f =      -604.65  |proj g|=        2.9414

iterations 9
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.94141
final function value -604.646

F = -604.646
final  value -604.645500 
converged
 
INFO  [06:18:00.621] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:18:00.708] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:18:00.716] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:18:08.060] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:18:16.191] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:18:25.303] [mlr3]  Finished benchmark 
INFO  [06:18:25.434] [bbotk] Result of batch 110: 
INFO  [06:18:25.436] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:18:25.436] [bbotk]              5.882961                 5.850011                       0.1019168 
INFO  [06:18:25.436] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:18:25.436] [bbotk]                     3445        0.766   -0.9505         <NA>   0.9717674 
INFO  [06:18:25.436] [bbotk]                                 uhash 
INFO  [06:18:25.436] [bbotk]  8726b822-df90-44ea-9d1b-181fc103739f 
DEBUG [06:18:26.682] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.145908e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.145908e-05 0.001455576 
  - best initial criterion value(s) :  550.6704 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -550.67  |proj g|=       5.7706
At iterate     1  f =      -552.77  |proj g|=        8.2409
At iterate     2  f =      -560.73  |proj g|=        7.4441
At iterate     3  f =      -569.48  |proj g|=        5.9297
At iterate     4  f =      -575.88  |proj g|=         5.308
At iterate     5  f =       -576.2  |proj g|=        5.0381
At iterate     6  f =      -576.27  |proj g|=        5.0356
At iterate     7  f =      -576.29  |proj g|=        5.1487
At iterate     8  f =      -576.31  |proj g|=        5.0911
At iterate     9  f =      -576.31  |proj g|=        5.0916
At iterate    10  f =      -576.31  |proj g|=        5.0918
At iterate    11  f =      -576.31  |proj g|=        5.0918
At iterate    12  f =      -576.31  |proj g|=         5.092
At iterate    13  f =      -576.31  |proj g|=        5.0922
At iterate    14  f =      -576.31  |proj g|=        5.0927
At iterate    15  f =      -576.31  |proj g|=        5.0935
At iterate    16  f =      -576.31  |proj g|=        5.0939
At iterate    17  f =      -576.32  |proj g|=        5.0914
At iterate    18  f =      -576.33  |proj g|=        5.0796
At iterate    19  f =      -576.36  |proj g|=        5.0477
At iterate    20  f =      -576.39  |proj g|=        5.0161
At iterate    21  f =      -576.48  |proj g|=        4.9087
At iterate    22  f =      -576.58  |proj g|=         4.855
At iterate    23  f =      -576.62  |proj g|=        4.8093
At iterate    24  f =      -577.38  |proj g|=        4.5437
At iterate    25  f =      -592.06  |proj g|=        2.5568
At iterate    26  f =      -593.68  |proj g|=        2.5603
At iterate    27  f =      -596.04  |proj g|=        2.3802
At iterate    28  f =       -597.1  |proj g|=        2.1734
At iterate    29  f =      -598.01  |proj g|=        1.9317
At iterate    30  f =      -598.31  |proj g|=        1.6856
At iterate    31  f =      -598.41  |proj g|=          1.45
At iterate    32  f =      -598.41  |proj g|=        1.4513
At iterate    33  f =      -598.41  |proj g|=        1.4515

iterations 33
function evaluations 43
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.45146
final function value -598.41

F = -598.41
final  value -598.409656 
converged
 
INFO  [06:18:26.686] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:18:26.773] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:18:26.780] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:18:38.325] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:18:49.519] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:19:00.652] [mlr3]  Finished benchmark 
INFO  [06:19:00.773] [bbotk] Result of batch 111: 
INFO  [06:19:00.776] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:19:00.776] [bbotk]              2.498209                 4.314545                       0.1261244 
INFO  [06:19:00.776] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:19:00.776] [bbotk]                     4952        0.769 -0.9537084         <NA>   0.9623604 
INFO  [06:19:00.776] [bbotk]                                 uhash 
INFO  [06:19:00.776] [bbotk]  2732414b-a465-4212-96a6-23f48a8bc254 
DEBUG [06:19:02.456] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.140477e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.140477e-05 0.001447021 
  - best initial criterion value(s) :  564.8602 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -564.86  |proj g|=       10.307
At iterate     1  f =      -587.18  |proj g|=        9.5986
At iterate     2  f =      -596.69  |proj g|=        5.6565
At iterate     3  f =      -598.46  |proj g|=        3.8044
At iterate     4  f =      -598.71  |proj g|=        3.1419
At iterate     5  f =      -598.82  |proj g|=        3.1496
At iterate     6  f =      -598.83  |proj g|=        3.1452
At iterate     7  f =      -598.83  |proj g|=        3.1448
At iterate     8  f =      -598.83  |proj g|=        3.1436
At iterate     9  f =      -598.83  |proj g|=         3.142
At iterate    10  f =      -598.83  |proj g|=        3.1392
At iterate    11  f =      -598.83  |proj g|=        3.1349
At iterate    12  f =      -598.84  |proj g|=        3.1287
At iterate    13  f =      -598.86  |proj g|=        3.1221
At iterate    14  f =       -598.9  |proj g|=        3.1212
At iterate    15  f =      -598.97  |proj g|=        3.1364
At iterate    16  f =      -598.98  |proj g|=        3.1211
At iterate    17  f =       -599.1  |proj g|=        3.1877
At iterate    18  f =      -610.76  |proj g|=         2.809
At iterate    19  f =      -612.74  |proj g|=        2.6971
At iterate    20  f =      -614.09  |proj g|=        2.6333
At iterate    21  f =      -614.77  |proj g|=        2.6522
At iterate    22  f =      -615.14  |proj g|=        2.8907
At iterate    23  f =      -615.49  |proj g|=        2.8545
At iterate    24  f =      -615.51  |proj g|=        2.8577
At iterate    25  f =       -615.6  |proj g|=        2.8461
At iterate    26  f =       -615.7  |proj g|=        2.9053
At iterate    27  f =       -615.7  |proj g|=        2.9114
At iterate    28  f =       -615.7  |proj g|=        2.9121
At iterate    29  f =       -615.7  |proj g|=         2.912
At iterate    30  f =       -615.7  |proj g|=        2.9118
At iterate    31  f =       -615.7  |proj g|=        2.9115
At iterate    32  f =       -615.7  |proj g|=        2.9113
At iterate    33  f =       -615.7  |proj g|=        2.9115
At iterate    34  f =       -615.7  |proj g|=        2.9122
At iterate    35  f =       -615.7  |proj g|=        2.9124
At iterate    36  f =       -615.7  |proj g|=        2.9122
At iterate    37  f =       -615.7  |proj g|=        2.9123
At iterate    38  f =       -615.7  |proj g|=        2.9149
At iterate    39  f =       -615.7  |proj g|=        2.9137
At iterate    40  f =       -615.7  |proj g|=        2.9117
At iterate    41  f =       -615.7  |proj g|=        2.9066
At iterate    42  f =      -615.71  |proj g|=        2.9007
At iterate    43  f =      -615.72  |proj g|=        2.8865
At iterate    44  f =      -615.76  |proj g|=        2.8716
At iterate    45  f =      -615.84  |proj g|=        2.8299
At iterate    46  f =      -616.03  |proj g|=        2.7966
At iterate    47  f =      -616.13  |proj g|=        2.5754
At iterate    48  f =      -616.56  |proj g|=        2.7347
At iterate    49  f =      -616.69  |proj g|=        2.7604
At iterate    50  f =       -616.7  |proj g|=        2.7628
At iterate    51  f =      -616.73  |proj g|=        2.7712
At iterate    52  f =      -616.76  |proj g|=        2.7754
At iterate    53  f =      -616.93  |proj g|=        2.7363
At iterate    54  f =      -617.05  |proj g|=        2.8962
At iterate    55  f =      -617.82  |proj g|=        2.7184
At iterate    56  f =      -618.74  |proj g|=        2.0804
At iterate    57  f =       -621.2  |proj g|=        1.3002
At iterate    58  f =      -622.58  |proj g|=        1.1068
At iterate    59  f =      -624.12  |proj g|=        0.7073
At iterate    60  f =      -625.52  |proj g|=       0.71269
At iterate    61  f =      -625.76  |proj g|=       0.72065
At iterate    62  f =      -625.98  |proj g|=       0.71159
At iterate    63  f =      -626.17  |proj g|=        0.6937
At iterate    64  f =      -626.19  |proj g|=       0.53505
At iterate    65  f =      -626.19  |proj g|=       0.03454
At iterate    66  f =      -626.19  |proj g|=     0.0014009
At iterate    67  f =      -626.19  |proj g|=       0.01409

iterations 67
function evaluations 80
segments explored during Cauchy searches 69
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.01409
final function value -626.194

F = -626.194
final  value -626.193992 
converged
 
INFO  [06:19:02.461] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:19:02.553] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:19:02.560] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:19:10.328] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:19:18.070] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:19:27.423] [mlr3]  Finished benchmark 
INFO  [06:19:27.564] [bbotk] Result of batch 112: 
INFO  [06:19:27.566] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:19:27.566] [bbotk]              2.319842                 2.474369                       0.1676758 
INFO  [06:19:27.566] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:19:27.566] [bbotk]                     4044        0.983 -0.9436938         <NA>   0.9606543 
INFO  [06:19:27.566] [bbotk]                                 uhash 
INFO  [06:19:27.566] [bbotk]  7c08f997-0930-4c8b-a966-ef615bb88787 
DEBUG [06:19:28.649] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.136755e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.136755e-05 0.001440813 
  - best initial criterion value(s) :  573.1064 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -573.11  |proj g|=       4.0936
At iterate     1  f =      -597.21  |proj g|=        6.3686
At iterate     2  f =      -597.74  |proj g|=        5.9569
At iterate     3  f =      -599.17  |proj g|=        4.1213
At iterate     4  f =      -602.77  |proj g|=        2.6494
At iterate     5  f =      -610.96  |proj g|=        2.5032
At iterate     6  f =      -614.03  |proj g|=        2.6273
At iterate     7  f =      -615.99  |proj g|=         2.773
At iterate     8  f =         -617  |proj g|=        2.9341
At iterate     9  f =      -617.45  |proj g|=        3.1765
At iterate    10  f =      -617.61  |proj g|=        3.2385
At iterate    11  f =      -617.65  |proj g|=        3.2794
At iterate    12  f =      -617.65  |proj g|=        3.2835
At iterate    13  f =      -617.65  |proj g|=        3.2846
At iterate    14  f =      -617.65  |proj g|=        3.2848

iterations 14
function evaluations 18
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.28476
final function value -617.651

F = -617.651
final  value -617.650561 
converged
 
INFO  [06:19:28.653] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:19:28.742] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:19:28.749] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:19:34.127] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:19:38.590] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:19:44.846] [mlr3]  Finished benchmark 
INFO  [06:19:44.979] [bbotk] Result of batch 113: 
INFO  [06:19:44.981] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:19:44.981] [bbotk]              4.886416                 9.185166                       0.4865165 
INFO  [06:19:44.981] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:19:44.981] [bbotk]                     2181        0.762 -0.946842         <NA>   0.9750422 
INFO  [06:19:44.981] [bbotk]                                 uhash 
INFO  [06:19:44.981] [bbotk]  a528a7f6-6079-4e57-814f-854168803c66 
DEBUG [06:19:46.170] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.131824e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.131824e-05 0.00143031 
  - best initial criterion value(s) :  598.8809 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -598.88  |proj g|=       3.7255
At iterate     1  f =      -600.87  |proj g|=        5.3047
At iterate     2  f =      -603.21  |proj g|=        5.9191
At iterate     3  f =      -605.48  |proj g|=        5.1314
At iterate     4  f =      -606.81  |proj g|=        3.7925
At iterate     5  f =      -606.89  |proj g|=        3.9905
At iterate     6  f =      -606.97  |proj g|=        3.9299
At iterate     7  f =      -606.97  |proj g|=        3.9194
At iterate     8  f =      -606.97  |proj g|=        3.9204
At iterate     9  f =      -606.97  |proj g|=        3.9203
At iterate    10  f =      -606.97  |proj g|=        3.9184
At iterate    11  f =      -606.97  |proj g|=        3.9088
At iterate    12  f =      -606.99  |proj g|=        3.8941
At iterate    13  f =      -607.02  |proj g|=        3.8656
At iterate    14  f =      -607.08  |proj g|=        3.9362
At iterate    15  f =      -607.22  |proj g|=        3.8092
At iterate    16  f =      -607.48  |proj g|=        3.7971
At iterate    17  f =       -610.8  |proj g|=        3.6058
At iterate    18  f =      -615.92  |proj g|=        3.2654
At iterate    19  f =      -622.12  |proj g|=        3.3335
At iterate    20  f =      -626.23  |proj g|=        1.6983
At iterate    21  f =      -627.97  |proj g|=        2.6023
At iterate    22  f =      -627.97  |proj g|=        2.6733
At iterate    23  f =      -627.97  |proj g|=         2.658
At iterate    24  f =      -627.97  |proj g|=        2.6565
At iterate    25  f =      -627.97  |proj g|=        2.6566

iterations 25
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.65661
final function value -627.975

F = -627.975
final  value -627.974520 
converged
 
INFO  [06:19:46.175] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:19:46.265] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:19:46.272] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:19:51.016] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:19:56.277] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:20:01.252] [mlr3]  Finished benchmark 
INFO  [06:20:01.397] [bbotk] Result of batch 114: 
INFO  [06:20:01.399] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:20:01.399] [bbotk]              3.816916                 8.374514                       0.2327339 
INFO  [06:20:01.399] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:20:01.399] [bbotk]                     2391        0.782 -0.9539185         <NA>   0.9708336 
INFO  [06:20:01.399] [bbotk]                                 uhash 
INFO  [06:20:01.399] [bbotk]  830b035d-ac7f-4967-bfbd-31c76ba2adf1 
DEBUG [06:20:02.656] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.124341e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.124341e-05 0.001424054 
  - best initial criterion value(s) :  588.8165 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -588.82  |proj g|=       4.4907
At iterate     1  f =      -602.29  |proj g|=        3.6032
At iterate     2  f =       -614.1  |proj g|=        4.4109
At iterate     3  f =      -615.05  |proj g|=        4.3521
At iterate     4  f =      -615.85  |proj g|=        4.2953
At iterate     5  f =      -615.98  |proj g|=        4.2859
At iterate     6  f =      -616.01  |proj g|=        4.3031
At iterate     7  f =      -616.03  |proj g|=        4.3603
At iterate     8  f =      -616.03  |proj g|=        4.3635
At iterate     9  f =      -616.03  |proj g|=        4.3638
At iterate    10  f =      -616.03  |proj g|=        4.3644
At iterate    11  f =      -616.03  |proj g|=        4.3652
At iterate    12  f =      -616.03  |proj g|=        4.3667
At iterate    13  f =      -616.03  |proj g|=        4.3692
At iterate    14  f =      -616.03  |proj g|=        4.3729
At iterate    15  f =      -616.03  |proj g|=        4.3783
At iterate    16  f =      -616.04  |proj g|=        4.3844
At iterate    17  f =      -616.04  |proj g|=        4.3858
At iterate    18  f =      -616.06  |proj g|=        4.3683
At iterate    19  f =      -616.06  |proj g|=        4.3458
At iterate    20  f =      -616.07  |proj g|=        4.3388
At iterate    21  f =      -616.11  |proj g|=         4.324
At iterate    22  f =      -616.55  |proj g|=        4.1951
At iterate    23  f =      -617.99  |proj g|=         3.921
At iterate    24  f =      -624.77  |proj g|=        3.7531
At iterate    25  f =      -625.64  |proj g|=        4.6914
At iterate    26  f =      -635.32  |proj g|=         3.598
At iterate    27  f =      -638.14  |proj g|=        3.0492
At iterate    28  f =      -640.71  |proj g|=        1.5632
At iterate    29  f =      -641.15  |proj g|=        1.6779
At iterate    30  f =      -641.24  |proj g|=        1.8559
At iterate    31  f =      -641.25  |proj g|=        1.6342
At iterate    32  f =      -641.25  |proj g|=        1.7343
At iterate    33  f =      -641.25  |proj g|=        1.7291
At iterate    34  f =      -641.25  |proj g|=        1.7288

iterations 34
function evaluations 40
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.72877
final function value -641.252

F = -641.252
final  value -641.252289 
converged
 
INFO  [06:20:02.660] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:20:02.749] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:20:02.756] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:20:08.103] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:20:14.107] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:20:20.548] [mlr3]  Finished benchmark 
INFO  [06:20:20.649] [bbotk] Result of batch 115: 
INFO  [06:20:20.651] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:20:20.651] [bbotk]               3.80509                 8.148266                       0.3813202 
INFO  [06:20:20.651] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:20:20.651] [bbotk]                     2549        0.782 -0.9468691         <NA>   0.9727773 
INFO  [06:20:20.651] [bbotk]                                 uhash 
INFO  [06:20:20.651] [bbotk]  cb876d29-6ace-4822-9adb-e15dee80fd60 
DEBUG [06:20:22.218] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.117833e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.117833e-05 0.001425709 
  - best initial criterion value(s) :  576.2898 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -576.29  |proj g|=       5.3694
At iterate     1  f =       -584.3  |proj g|=        8.0538
At iterate     2  f =      -592.93  |proj g|=        6.8121
At iterate     3  f =      -603.84  |proj g|=        5.4758
At iterate     4  f =      -604.46  |proj g|=        5.1914
At iterate     5  f =      -605.44  |proj g|=        5.4527
At iterate     6  f =      -608.35  |proj g|=        6.3232
At iterate     7  f =       -609.4  |proj g|=        7.0294
At iterate     8  f =      -609.43  |proj g|=         7.206
At iterate     9  f =      -609.46  |proj g|=        7.2966
At iterate    10  f =      -609.46  |proj g|=        7.3142
At iterate    11  f =      -609.46  |proj g|=        7.3174
At iterate    12  f =      -609.47  |proj g|=        7.3404
At iterate    13  f =      -609.48  |proj g|=        7.3683
At iterate    14  f =       -609.5  |proj g|=        7.3853
At iterate    15  f =      -609.56  |proj g|=        7.4774
At iterate    16  f =      -609.58  |proj g|=        7.3898
At iterate    17  f =      -609.71  |proj g|=        7.4669
At iterate    18  f =      -611.32  |proj g|=        6.6414
At iterate    19  f =      -611.42  |proj g|=        6.6363
At iterate    20  f =      -611.43  |proj g|=        6.6801
At iterate    21  f =      -611.43  |proj g|=        6.6773
At iterate    22  f =      -611.43  |proj g|=          6.68
At iterate    23  f =      -611.43  |proj g|=        6.6794
At iterate    24  f =      -611.43  |proj g|=        6.6582
At iterate    25  f =      -611.43  |proj g|=        6.6538
At iterate    26  f =      -611.44  |proj g|=        6.6207
At iterate    27  f =      -611.47  |proj g|=        6.5839
At iterate    28  f =      -611.56  |proj g|=        6.5004
At iterate    29  f =      -611.59  |proj g|=        6.4933
At iterate    30  f =      -611.77  |proj g|=        6.4281
At iterate    31  f =      -612.32  |proj g|=        5.8785
At iterate    32  f =      -612.95  |proj g|=        6.1963
At iterate    33  f =      -614.02  |proj g|=        5.7562
At iterate    34  f =      -618.73  |proj g|=        4.9868
At iterate    35  f =      -619.63  |proj g|=        4.1074
At iterate    36  f =      -628.05  |proj g|=        4.8025
At iterate    37  f =      -642.05  |proj g|=        4.6231
At iterate    38  f =       -645.1  |proj g|=        2.8994
At iterate    39  f =      -648.33  |proj g|=        1.3096
At iterate    40  f =      -649.64  |proj g|=          1.05
At iterate    41  f =      -650.52  |proj g|=       0.66384
At iterate    42  f =      -650.64  |proj g|=       0.32156
At iterate    43  f =      -650.77  |proj g|=        0.3279
At iterate    44  f =      -650.77  |proj g|=        0.1953
At iterate    45  f =      -650.77  |proj g|=      0.038569
At iterate    46  f =      -650.77  |proj g|=      0.023624

iterations 46
function evaluations 60
segments explored during Cauchy searches 49
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0236242
final function value -650.77

F = -650.77
final  value -650.770177 
converged
 
INFO  [06:20:22.222] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:20:22.355] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:20:22.363] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:20:30.079] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:20:40.286] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:20:47.539] [mlr3]  Finished benchmark 
INFO  [06:20:47.653] [bbotk] Result of batch 116: 
INFO  [06:20:47.655] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:20:47.655] [bbotk]              2.221962                 2.968268                       0.1253542 
INFO  [06:20:47.655] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:20:47.655] [bbotk]                     3485        0.954 -0.9381953         <NA>   0.9557162 
INFO  [06:20:47.655] [bbotk]                                 uhash 
INFO  [06:20:47.655] [bbotk]  e9c7ee67-f85a-4fbb-88ea-6b8a34c0563b 
DEBUG [06:20:49.175] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.121365e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.121365e-05 0.001422025 
  - best initial criterion value(s) :  588.6843 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -588.68  |proj g|=       6.1178
At iterate     1  f =      -589.67  |proj g|=        9.8941
At iterate     2  f =      -602.08  |proj g|=        8.2829
At iterate     3  f =      -621.54  |proj g|=        3.9367
At iterate     4  f =      -624.16  |proj g|=        2.3464
At iterate     5  f =      -629.94  |proj g|=        2.4092
At iterate     6  f =      -638.69  |proj g|=        3.1889
At iterate     7  f =      -642.31  |proj g|=        3.0998
At iterate     8  f =      -642.81  |proj g|=        3.0584
At iterate     9  f =      -642.86  |proj g|=        3.0711
At iterate    10  f =      -642.93  |proj g|=        3.1939
At iterate    11  f =      -642.93  |proj g|=         3.186
At iterate    12  f =      -642.93  |proj g|=        3.1848
At iterate    13  f =      -642.93  |proj g|=        3.1839
At iterate    14  f =      -642.93  |proj g|=        3.1819
At iterate    15  f =      -642.93  |proj g|=        3.1789
At iterate    16  f =      -642.93  |proj g|=        3.1737
At iterate    17  f =      -642.94  |proj g|=        3.1654
At iterate    18  f =      -642.94  |proj g|=        3.1523
At iterate    19  f =      -642.96  |proj g|=         3.133
At iterate    20  f =      -643.01  |proj g|=        3.1096
At iterate    21  f =       -643.1  |proj g|=        3.0987
At iterate    22  f =      -643.23  |proj g|=        3.1461
At iterate    23  f =       -643.3  |proj g|=         3.234
At iterate    24  f =       -643.3  |proj g|=        3.2533
At iterate    25  f =      -643.31  |proj g|=        3.2687
At iterate    26  f =      -643.32  |proj g|=        3.2953
At iterate    27  f =      -643.36  |proj g|=        3.3334
At iterate    28  f =      -643.45  |proj g|=         3.379
At iterate    29  f =       -643.6  |proj g|=        3.4127
At iterate    30  f =      -643.88  |proj g|=        3.4089
At iterate    31  f =      -644.35  |proj g|=        3.3075
At iterate    32  f =      -644.52  |proj g|=        3.2587
At iterate    33  f =      -644.64  |proj g|=        3.1554
At iterate    34  f =      -644.65  |proj g|=        3.0665
At iterate    35  f =      -644.66  |proj g|=        3.1153
At iterate    36  f =      -644.66  |proj g|=        3.1103
At iterate    37  f =      -644.66  |proj g|=        3.1101
At iterate    38  f =      -644.66  |proj g|=        3.1102
At iterate    39  f =      -644.66  |proj g|=        3.1103
At iterate    40  f =      -644.66  |proj g|=        3.1105
At iterate    41  f =      -644.66  |proj g|=        3.1107
At iterate    42  f =      -644.66  |proj g|=        3.1141
At iterate    43  f =      -644.66  |proj g|=        3.1124
At iterate    44  f =      -644.67  |proj g|=        3.1247
At iterate    45  f =      -644.67  |proj g|=        3.1159
At iterate    46  f =       -644.7  |proj g|=        3.0974
At iterate    47  f =       -644.8  |proj g|=        3.0382
At iterate    48  f =      -644.97  |proj g|=        2.9482
At iterate    49  f =       -645.2  |proj g|=        2.8835
At iterate    50  f =      -645.22  |proj g|=        2.8321
At iterate    51  f =      -645.64  |proj g|=        2.7863
At iterate    52  f =      -645.92  |proj g|=        2.8002
At iterate    53  f =      -646.14  |proj g|=        2.8341
At iterate    54  f =      -646.35  |proj g|=        2.7869
At iterate    55  f =      -646.71  |proj g|=        2.7672
At iterate    56  f =      -647.35  |proj g|=        2.6159
At iterate    57  f =      -649.26  |proj g|=        1.7513
At iterate    58  f =       -649.5  |proj g|=        1.7513
At iterate    59  f =      -649.55  |proj g|=        1.7513
At iterate    60  f =      -649.56  |proj g|=        1.7513
At iterate    61  f =      -649.56  |proj g|=        1.7513
At iterate    62  f =      -649.56  |proj g|=        1.7513
At iterate    63  f =      -649.56  |proj g|=        1.7513
At iterate    64  f =      -649.57  |proj g|=        1.7512
At iterate    65  f =      -649.59  |proj g|=         1.751
At iterate    66  f =      -649.64  |proj g|=        1.7505
At iterate    67  f =      -649.74  |proj g|=        1.7494
At iterate    68  f =       -649.9  |proj g|=        1.7475
At iterate    69  f =      -649.96  |proj g|=        1.7482
At iterate    70  f =      -649.98  |proj g|=        1.7478
At iterate    71  f =      -649.99  |proj g|=        1.7473
At iterate    72  f =      -649.99  |proj g|=        1.7473
At iterate    73  f =      -649.99  |proj g|=        1.7473

iterations 73
function evaluations 87
segments explored during Cauchy searches 78
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.7473
final function value -649.992

F = -649.992
final  value -649.991821 
converged
 
INFO  [06:20:49.179] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:20:49.264] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:20:49.271] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:20:54.378] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:20:59.690] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:21:05.504] [mlr3]  Finished benchmark 
INFO  [06:21:05.602] [bbotk] Result of batch 117: 
INFO  [06:21:05.604] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:21:05.604] [bbotk]              6.669077                 2.754208                       0.1663774 
INFO  [06:21:05.604] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:21:05.604] [bbotk]                     2720        0.772 -0.9362622         <NA>   0.9730441 
INFO  [06:21:05.604] [bbotk]                                 uhash 
INFO  [06:21:05.604] [bbotk]  67d1d0eb-52f8-470e-8ac3-e266ad200b16 
DEBUG [06:21:06.772] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.115161e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.115161e-05 0.001418593 
  - best initial criterion value(s) :  561.5282 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -561.53  |proj g|=       11.123
At iterate     1  f =      -574.12  |proj g|=        5.9853
At iterate     2  f =      -574.27  |proj g|=        5.9328
At iterate     3  f =      -574.38  |proj g|=        5.5757
At iterate     4  f =       -574.4  |proj g|=        5.3571
At iterate     5  f =       -574.4  |proj g|=        5.3238
At iterate     6  f =       -574.4  |proj g|=        5.3163
At iterate     7  f =       -574.4  |proj g|=        5.3106
At iterate     8  f =       -574.4  |proj g|=        5.2772
At iterate     9  f =      -582.08  |proj g|=          2.67
At iterate    10  f =       -585.6  |proj g|=        1.8443
At iterate    11  f =      -586.24  |proj g|=        1.8444
At iterate    12  f =      -586.31  |proj g|=        1.8267
At iterate    13  f =      -586.31  |proj g|=        1.8316
At iterate    14  f =      -586.31  |proj g|=        1.8311
At iterate    15  f =      -586.31  |proj g|=        1.8309
At iterate    16  f =      -586.31  |proj g|=        1.8311
At iterate    17  f =      -586.31  |proj g|=        1.8312
At iterate    18  f =      -586.31  |proj g|=        1.8313
At iterate    19  f =      -586.31  |proj g|=        1.8313

iterations 19
function evaluations 25
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.83132
final function value -586.314

F = -586.314
final  value -586.313562 
converged
 
INFO  [06:21:06.776] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:21:06.860] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:21:06.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:21:13.353] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:21:20.804] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:21:27.751] [mlr3]  Finished benchmark 
INFO  [06:21:27.867] [bbotk] Result of batch 118: 
INFO  [06:21:27.869] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:21:27.869] [bbotk]              5.784703                 5.003667                       0.2733031 
INFO  [06:21:27.869] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:21:27.869] [bbotk]                     3233         0.78 -0.9659511         <NA>   0.9750907 
INFO  [06:21:27.869] [bbotk]                                 uhash 
INFO  [06:21:27.869] [bbotk]  7ef3e228-e02d-4c04-aecf-8a61b024e920 
DEBUG [06:21:29.218] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.110555e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.110555e-05 0.001416261 
  - best initial criterion value(s) :  619.312 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -619.31  |proj g|=       6.3622
At iterate     1  f =      -637.09  |proj g|=        6.6049
At iterate     2  f =      -638.38  |proj g|=        7.7036
At iterate     3  f =      -639.38  |proj g|=        8.4811
At iterate     4  f =       -641.7  |proj g|=        9.1971
At iterate     5  f =       -642.1  |proj g|=        8.4873
At iterate     6  f =      -642.42  |proj g|=        8.0671
At iterate     7  f =      -642.44  |proj g|=        8.0479
At iterate     8  f =      -642.44  |proj g|=         8.069
At iterate     9  f =      -642.44  |proj g|=        8.0665
At iterate    10  f =      -642.44  |proj g|=        8.0594
At iterate    11  f =      -642.44  |proj g|=        8.0513
At iterate    12  f =      -642.44  |proj g|=        8.0359
At iterate    13  f =      -642.44  |proj g|=         8.012
At iterate    14  f =      -642.44  |proj g|=        7.9747
At iterate    15  f =      -642.45  |proj g|=        7.9206
At iterate    16  f =      -642.47  |proj g|=        7.8331
At iterate    17  f =      -642.52  |proj g|=        7.7139
At iterate    18  f =      -642.53  |proj g|=        7.6023
At iterate    19  f =      -642.65  |proj g|=        7.4119
At iterate    20  f =       -646.7  |proj g|=        5.7753
At iterate    21  f =      -655.43  |proj g|=        1.9167
At iterate    22  f =      -657.48  |proj g|=       0.41974
At iterate    23  f =      -658.17  |proj g|=       0.30152
At iterate    24  f =      -658.18  |proj g|=       0.73244
At iterate    25  f =      -658.32  |proj g|=       0.72916
At iterate    26  f =      -658.33  |proj g|=       0.32097
At iterate    27  f =      -658.33  |proj g|=       0.27054
At iterate    28  f =      -658.33  |proj g|=       0.27007

iterations 28
function evaluations 33
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.270067
final function value -658.325

F = -658.325
final  value -658.325336 
converged
 
INFO  [06:21:29.222] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:21:29.309] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:21:29.316] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:21:34.451] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:21:41.525] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:21:46.068] [mlr3]  Finished benchmark 
INFO  [06:21:46.169] [bbotk] Result of batch 119: 
INFO  [06:21:46.171] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:21:46.171] [bbotk]              4.895682                 7.334515                       0.3941678 
INFO  [06:21:46.171] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:21:46.171] [bbotk]                     2150        0.895 -0.9512407         <NA>   0.9743387 
INFO  [06:21:46.171] [bbotk]                                 uhash 
INFO  [06:21:46.171] [bbotk]  4b46cd74-be29-4cdb-a85f-18cd4e61b0c8 
DEBUG [06:21:47.747] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.105352e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.105352e-05 0.001405974 
  - best initial criterion value(s) :  628.4986 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -628.5  |proj g|=       5.3766
At iterate     1  f =      -640.97  |proj g|=         2.157
At iterate     2  f =      -651.75  |proj g|=        4.4827
At iterate     3  f =       -652.6  |proj g|=        4.4618
At iterate     4  f =      -653.32  |proj g|=        4.5939
At iterate     5  f =      -653.47  |proj g|=        4.7276
At iterate     6  f =      -653.53  |proj g|=        4.8787
At iterate     7  f =      -653.55  |proj g|=        5.0607
At iterate     8  f =      -653.55  |proj g|=        5.0693
At iterate     9  f =      -653.55  |proj g|=        5.0706
At iterate    10  f =      -653.55  |proj g|=        5.0798
At iterate    11  f =      -653.55  |proj g|=        5.0892
At iterate    12  f =      -653.55  |proj g|=        5.1073
At iterate    13  f =      -653.55  |proj g|=        5.1338
At iterate    14  f =      -653.56  |proj g|=        5.1765
At iterate    15  f =      -653.57  |proj g|=        5.2409
At iterate    16  f =      -653.61  |proj g|=        5.3362
At iterate    17  f =       -653.7  |proj g|=         5.462
At iterate    18  f =      -653.95  |proj g|=        5.5847
At iterate    19  f =       -654.6  |proj g|=        5.5702
At iterate    20  f =      -656.09  |proj g|=        5.1037
At iterate    21  f =       -659.2  |proj g|=        3.7508
At iterate    22  f =      -662.76  |proj g|=        1.7665
At iterate    23  f =      -664.79  |proj g|=        1.2352
At iterate    24  f =      -665.03  |proj g|=          1.15
At iterate    25  f =      -665.06  |proj g|=        1.1259
At iterate    26  f =      -665.07  |proj g|=        1.1288
At iterate    27  f =      -665.07  |proj g|=        1.1295
At iterate    28  f =      -665.07  |proj g|=        1.1359
At iterate    29  f =      -665.08  |proj g|=        1.1414
At iterate    30  f =       -665.1  |proj g|=        1.1496
At iterate    31  f =      -665.15  |proj g|=        1.1558
At iterate    32  f =      -665.27  |proj g|=        1.1545
At iterate    33  f =      -665.57  |proj g|=        1.1302
At iterate    34  f =      -666.16  |proj g|=        1.0635
At iterate    35  f =      -666.87  |proj g|=       0.73748
At iterate    36  f =      -667.18  |proj g|=       0.87419
At iterate    37  f =      -667.82  |proj g|=       0.31856
At iterate    38  f =      -668.38  |proj g|=       0.53624
At iterate    39  f =      -668.47  |proj g|=       0.75224
At iterate    40  f =      -668.48  |proj g|=        0.7054
At iterate    41  f =      -668.48  |proj g|=       0.71113
At iterate    42  f =      -668.48  |proj g|=        0.7114

iterations 42
function evaluations 48
segments explored during Cauchy searches 45
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.711402
final function value -668.475

F = -668.475
final  value -668.475052 
converged
 
INFO  [06:21:47.749] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:21:47.824] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:21:47.831] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:21:55.071] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:22:03.380] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:22:11.177] [mlr3]  Finished benchmark 
INFO  [06:22:11.278] [bbotk] Result of batch 120: 
INFO  [06:22:11.280] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:22:11.280] [bbotk]              8.382483                 7.680072                        0.134704 
INFO  [06:22:11.280] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:22:11.280] [bbotk]                     3626        0.966 -0.945421         <NA>   0.9736931 
INFO  [06:22:11.280] [bbotk]                                 uhash 
INFO  [06:22:11.280] [bbotk]  3a3a647a-4881-4281-9775-0c8a51208ca2 
DEBUG [06:22:12.756] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.099723e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.099723e-05 0.00140161 
  - best initial criterion value(s) :  564.7078 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -564.71  |proj g|=       3.2252
At iterate     1  f =      -573.33  |proj g|=        3.3371
At iterate     2  f =      -573.37  |proj g|=        3.3126
At iterate     3  f =      -573.47  |proj g|=        3.2461
At iterate     4  f =      -573.56  |proj g|=        3.2108
At iterate     5  f =      -573.96  |proj g|=        3.0975
At iterate     6  f =      -574.43  |proj g|=        3.0325
At iterate     7  f =       -574.8  |proj g|=        3.0228
At iterate     8  f =      -574.83  |proj g|=        3.0654
At iterate     9  f =      -574.83  |proj g|=        3.0673
At iterate    10  f =      -574.83  |proj g|=        3.0674
At iterate    11  f =      -574.84  |proj g|=        3.0739
At iterate    12  f =      -574.86  |proj g|=        3.0814
At iterate    13  f =      -574.98  |proj g|=        3.0949
At iterate    14  f =      -575.03  |proj g|=        3.0466
At iterate    15  f =      -575.32  |proj g|=        3.0549
At iterate    16  f =      -576.23  |proj g|=        3.0037
At iterate    17  f =      -578.13  |proj g|=         2.819
At iterate    18  f =      -581.09  |proj g|=        2.4406
At iterate    19  f =      -583.19  |proj g|=        2.0485
At iterate    20  f =      -583.47  |proj g|=        1.8838
At iterate    21  f =      -585.12  |proj g|=        1.7554
At iterate    22  f =      -589.44  |proj g|=        1.5883
At iterate    23  f =      -591.06  |proj g|=        1.5564
At iterate    24  f =      -591.09  |proj g|=        1.5497
At iterate    25  f =       -591.1  |proj g|=        1.5374
At iterate    26  f =      -591.11  |proj g|=        1.5546
At iterate    27  f =      -591.11  |proj g|=        1.5513
At iterate    28  f =      -591.11  |proj g|=        1.5508
At iterate    29  f =      -591.11  |proj g|=        1.5507

iterations 29
function evaluations 40
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.55073
final function value -591.111

F = -591.111
final  value -591.110745 
converged
 
INFO  [06:22:12.761] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:22:12.847] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:22:12.854] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:22:21.222] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:22:30.185] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:22:39.411] [mlr3]  Finished benchmark 
INFO  [06:22:39.543] [bbotk] Result of batch 121: 
INFO  [06:22:39.545] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:22:39.545] [bbotk]              2.581133                 3.403891                       0.4198351 
INFO  [06:22:39.545] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:22:39.545] [bbotk]                     3787        0.986 -0.9675326         <NA>   0.9693908 
INFO  [06:22:39.545] [bbotk]                                 uhash 
INFO  [06:22:39.545] [bbotk]  8db3a742-592f-4cd9-a931-5d251448707f 
DEBUG [06:22:40.657] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.092481e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.092481e-05 0.001394456 
  - best initial criterion value(s) :  626.0615 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -626.06  |proj g|=       8.3971
At iterate     1  f =      -648.88  |proj g|=        5.1004
At iterate     2  f =      -651.74  |proj g|=        4.4372
At iterate     3  f =      -656.92  |proj g|=        1.8087
At iterate     4  f =      -658.73  |proj g|=       0.45239
At iterate     5  f =      -658.87  |proj g|=       0.77544
At iterate     6  f =      -658.87  |proj g|=       0.77735
At iterate     7  f =      -658.87  |proj g|=        0.7769
At iterate     8  f =      -658.87  |proj g|=        0.7769

iterations 8
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.776902
final function value -658.874

F = -658.874
final  value -658.874361 
converged
 
INFO  [06:22:40.661] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:22:40.749] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:22:40.756] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:22:41.946] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:22:43.182] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:22:44.701] [mlr3]  Finished benchmark 
INFO  [06:22:44.802] [bbotk] Result of batch 122: 
INFO  [06:22:44.804] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:22:44.804] [bbotk]              7.660165                 8.577745                       0.3352987 
INFO  [06:22:44.804] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:22:44.804] [bbotk]                      497        0.798 -0.9583697         <NA>   0.9673658 
INFO  [06:22:44.804] [bbotk]                                 uhash 
INFO  [06:22:44.804] [bbotk]  24380acd-8a64-49fd-bc19-3cf04075fcc6 
DEBUG [06:22:46.123] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.085394e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.085394e-05 0.001379576 
  - best initial criterion value(s) :  656.9953 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -657  |proj g|=       8.5441
At iterate     1  f =      -658.46  |proj g|=        6.7978
At iterate     2  f =      -659.63  |proj g|=        6.8849
At iterate     3  f =      -660.19  |proj g|=        6.7094
At iterate     4  f =      -660.33  |proj g|=         6.676
At iterate     5  f =      -660.35  |proj g|=        6.6988
At iterate     6  f =      -660.36  |proj g|=        6.7203
At iterate     7  f =      -660.36  |proj g|=        6.7296
At iterate     8  f =      -660.36  |proj g|=        6.7286
At iterate     9  f =      -660.36  |proj g|=        6.7192
At iterate    10  f =      -660.36  |proj g|=         6.703
At iterate    11  f =      -660.36  |proj g|=        6.6607
At iterate    12  f =      -660.37  |proj g|=         6.599
At iterate    13  f =      -660.39  |proj g|=        6.4852
At iterate    14  f =      -660.44  |proj g|=        6.2843
At iterate    15  f =      -660.58  |proj g|=        5.9097
At iterate    16  f =      -660.92  |proj g|=        5.2375
At iterate    17  f =      -661.56  |proj g|=        4.3087
At iterate    18  f =      -662.25  |proj g|=        3.9897
At iterate    19  f =      -662.36  |proj g|=        3.8764
At iterate    20  f =      -662.57  |proj g|=        3.8831
At iterate    21  f =      -662.86  |proj g|=        3.8655
At iterate    22  f =      -663.48  |proj g|=        3.7653
At iterate    23  f =      -664.39  |proj g|=        3.3139
At iterate    24  f =       -665.4  |proj g|=        2.3691
At iterate    25  f =      -665.43  |proj g|=        2.4107
At iterate    26  f =      -666.52  |proj g|=        1.9137
At iterate    27  f =      -671.11  |proj g|=       0.58868
At iterate    28  f =      -671.29  |proj g|=       0.76738
At iterate    29  f =       -671.3  |proj g|=       0.76547
At iterate    30  f =      -671.46  |proj g|=       0.75123
At iterate    31  f =      -671.46  |proj g|=       0.47454
At iterate    32  f =      -671.46  |proj g|=       0.47712
At iterate    33  f =      -671.46  |proj g|=       0.47712

iterations 33
function evaluations 41
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.477123
final function value -671.461

F = -671.461
final  value -671.461353 
converged
 
INFO  [06:22:46.127] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:22:46.215] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:22:46.222] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:22:58.926] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:23:08.981] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:23:17.816] [mlr3]  Finished benchmark 
INFO  [06:23:17.917] [bbotk] Result of batch 123: 
INFO  [06:23:17.919] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:23:17.919] [bbotk]              7.880138                 5.879164                       0.1027367 
INFO  [06:23:17.919] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:23:17.919] [bbotk]                     4240        0.809 -0.9550057         <NA>   0.9730536 
INFO  [06:23:17.919] [bbotk]                                 uhash 
INFO  [06:23:17.919] [bbotk]  56a3e595-1462-48e6-9033-c43b2cd67885 
DEBUG [06:23:19.229] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.079589e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.079589e-05 0.001374981 
  - best initial criterion value(s) :  655.7244 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -655.72  |proj g|=        2.678
At iterate     1  f =      -668.24  |proj g|=        4.5874
At iterate     2  f =      -671.12  |proj g|=        6.4553
At iterate     3  f =      -673.29  |proj g|=        5.2067
At iterate     4  f =      -673.33  |proj g|=        4.9836
At iterate     5  f =      -673.33  |proj g|=        4.9954
At iterate     6  f =      -673.33  |proj g|=        4.9902
At iterate     7  f =      -673.33  |proj g|=        4.9909
At iterate     8  f =      -673.33  |proj g|=        4.9944
At iterate     9  f =      -673.33  |proj g|=             5
At iterate    10  f =      -673.33  |proj g|=        5.0003
At iterate    11  f =      -673.33  |proj g|=        5.0192
At iterate    12  f =      -673.33  |proj g|=        5.0178
At iterate    13  f =      -673.34  |proj g|=        5.1109
At iterate    14  f =      -673.35  |proj g|=        5.1071
At iterate    15  f =      -673.54  |proj g|=        5.0816
At iterate    16  f =      -673.92  |proj g|=        5.0564
At iterate    17  f =      -674.99  |proj g|=         4.942
At iterate    18  f =         -675  |proj g|=        5.0348
At iterate    19  f =      -677.16  |proj g|=        4.4506
At iterate    20  f =      -682.77  |proj g|=        2.8822
At iterate    21  f =      -684.74  |proj g|=        2.6612
At iterate    22  f =      -688.23  |proj g|=        3.3177
At iterate    23  f =      -689.96  |proj g|=        3.4218
At iterate    24  f =      -691.38  |proj g|=        2.6113
At iterate    25  f =      -691.87  |proj g|=        1.8144
At iterate    26  f =      -691.88  |proj g|=        1.6294
At iterate    27  f =      -691.88  |proj g|=        1.6878
At iterate    28  f =      -691.88  |proj g|=         1.683
At iterate    29  f =      -691.88  |proj g|=        1.6829
At iterate    30  f =      -691.88  |proj g|=        1.6833

iterations 30
function evaluations 40
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.68334
final function value -691.883

F = -691.883
final  value -691.882993 
converged
 
INFO  [06:23:19.233] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:23:19.355] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:23:19.363] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:23:29.302] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:23:38.413] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:23:46.430] [mlr3]  Finished benchmark 
INFO  [06:23:46.533] [bbotk] Result of batch 124: 
INFO  [06:23:46.535] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:23:46.535] [bbotk]              2.515219                 8.439027                       0.1722655 
INFO  [06:23:46.535] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:23:46.535] [bbotk]                     3783        0.806 -0.9470976         <NA>   0.9629598 
INFO  [06:23:46.535] [bbotk]                                 uhash 
INFO  [06:23:46.535] [bbotk]  e1f29c21-b916-4888-8666-3281c5bb366e 
DEBUG [06:23:47.921] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.074651e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.074651e-05 0.001367272 
  - best initial criterion value(s) :  646.6243 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -646.62  |proj g|=       5.4445
At iterate     1  f =      -680.64  |proj g|=         5.003
At iterate     2  f =      -682.28  |proj g|=        9.2157
At iterate     3  f =      -683.83  |proj g|=        7.6437
At iterate     4  f =      -683.98  |proj g|=        7.4792
At iterate     5  f =      -684.42  |proj g|=        6.3921
At iterate     6  f =      -684.69  |proj g|=        7.1958
At iterate     7  f =      -684.78  |proj g|=         7.283
At iterate     8  f =      -684.79  |proj g|=        7.2709
At iterate     9  f =      -684.79  |proj g|=        7.2754
At iterate    10  f =      -684.79  |proj g|=        7.2764
At iterate    11  f =      -684.79  |proj g|=        7.2799
At iterate    12  f =      -684.79  |proj g|=        7.2872
At iterate    13  f =       -684.8  |proj g|=        7.2799
At iterate    14  f =       -684.8  |proj g|=         7.316
At iterate    15  f =       -684.8  |proj g|=        7.3063
At iterate    16  f =       -687.4  |proj g|=        6.0255
At iterate    17  f =      -695.24  |proj g|=        2.5475
At iterate    18  f =      -698.26  |proj g|=        1.0611
At iterate    19  f =      -698.46  |proj g|=       0.89337
At iterate    20  f =      -698.47  |proj g|=       0.87449
At iterate    21  f =      -698.47  |proj g|=       0.85058
At iterate    22  f =      -698.47  |proj g|=       0.84774
At iterate    23  f =      -698.47  |proj g|=       0.84854
At iterate    24  f =      -698.47  |proj g|=       0.85102
At iterate    25  f =      -698.48  |proj g|=       0.85581
At iterate    26  f =      -698.48  |proj g|=       0.86015
At iterate    27  f =      -698.48  |proj g|=       0.83481
At iterate    28  f =      -698.49  |proj g|=       0.84562
At iterate    29  f =      -698.51  |proj g|=       0.84661
At iterate    30  f =      -698.58  |proj g|=       0.80413
At iterate    31  f =      -698.72  |proj g|=       0.64146
At iterate    32  f =         -699  |proj g|=       0.30173
At iterate    33  f =         -699  |proj g|=       0.30181
At iterate    34  f =      -699.08  |proj g|=        0.2962
At iterate    35  f =      -699.08  |proj g|=      0.041839
At iterate    36  f =      -699.08  |proj g|=     0.0014328
At iterate    37  f =      -699.08  |proj g|=     0.0014332

iterations 37
function evaluations 47
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00143319
final function value -699.082

F = -699.082
final  value -699.082209 
converged
 
INFO  [06:23:47.925] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:23:48.015] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:23:48.022] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:23:55.053] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:24:02.291] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:24:09.943] [mlr3]  Finished benchmark 
INFO  [06:24:10.048] [bbotk] Result of batch 125: 
INFO  [06:24:10.050] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:24:10.050] [bbotk]              8.868606                 8.974263                      0.03310615 
INFO  [06:24:10.050] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:24:10.050] [bbotk]                     3347        0.829 -0.9436707         <NA>   0.9639315 
INFO  [06:24:10.050] [bbotk]                                 uhash 
INFO  [06:24:10.050] [bbotk]  1ea3988e-ff02-4237-9e8b-8788d2f7a052 
DEBUG [06:24:11.622] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.069109e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.069109e-05 0.001359984 
  - best initial criterion value(s) :  640.3055 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -640.31  |proj g|=        5.825
At iterate     1  f =      -643.09  |proj g|=        4.8542
At iterate     2  f =       -645.2  |proj g|=        4.8333
At iterate     3  f =       -645.6  |proj g|=         4.664
At iterate     4  f =      -645.71  |proj g|=        4.5571
At iterate     5  f =      -645.72  |proj g|=        4.5378
At iterate     6  f =      -645.72  |proj g|=        4.5406
At iterate     7  f =      -645.72  |proj g|=        4.5448
At iterate     8  f =      -645.72  |proj g|=        4.5462
At iterate     9  f =      -645.72  |proj g|=         4.547
At iterate    10  f =      -645.72  |proj g|=        4.5488
At iterate    11  f =      -645.72  |proj g|=        4.5522
At iterate    12  f =      -645.72  |proj g|=        4.5565
At iterate    13  f =      -645.72  |proj g|=        4.5637
At iterate    14  f =      -645.72  |proj g|=         4.575
At iterate    15  f =      -645.73  |proj g|=         4.592
At iterate    16  f =      -645.75  |proj g|=        4.6171
At iterate    17  f =      -645.81  |proj g|=         4.649
At iterate    18  f =      -645.97  |proj g|=        4.6762
At iterate    19  f =      -646.39  |proj g|=        4.6519
At iterate    20  f =      -647.45  |proj g|=        4.4504
At iterate    21  f =      -649.86  |proj g|=        3.8737
At iterate    22  f =      -655.96  |proj g|=          3.37
At iterate    23  f =       -659.5  |proj g|=        1.1254
At iterate    24  f =      -662.38  |proj g|=        3.5025
At iterate    25  f =      -662.49  |proj g|=        3.2914
At iterate    26  f =      -662.52  |proj g|=         3.114
At iterate    27  f =      -662.52  |proj g|=        3.1352
At iterate    28  f =      -662.52  |proj g|=        3.1375
At iterate    29  f =      -662.52  |proj g|=        3.1505
At iterate    30  f =      -662.52  |proj g|=        3.1652
At iterate    31  f =      -662.52  |proj g|=        3.1927
At iterate    32  f =      -662.53  |proj g|=        3.2338
At iterate    33  f =      -662.55  |proj g|=        3.2983
At iterate    34  f =      -662.61  |proj g|=        3.3944
At iterate    35  f =      -662.75  |proj g|=        3.5326
At iterate    36  f =      -663.12  |proj g|=        3.7062
At iterate    37  f =      -664.02  |proj g|=        3.8459
At iterate    38  f =      -665.92  |proj g|=        3.6867
At iterate    39  f =      -669.14  |proj g|=        2.2178
At iterate    40  f =      -670.52  |proj g|=       0.80426
At iterate    41  f =      -670.76  |proj g|=        1.1968
At iterate    42  f =      -670.89  |proj g|=       0.97628
At iterate    43  f =       -670.9  |proj g|=       0.93949
At iterate    44  f =       -670.9  |proj g|=       0.94546
At iterate    45  f =       -670.9  |proj g|=       0.94381
At iterate    46  f =       -670.9  |proj g|=       0.94404

iterations 46
function evaluations 51
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.944042
final function value -670.896

F = -670.896
final  value -670.895557 
converged
 
INFO  [06:24:11.626] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:24:11.756] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:24:11.763] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:24:22.492] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:24:33.879] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:24:45.436] [mlr3]  Finished benchmark 
INFO  [06:24:45.538] [bbotk] Result of batch 126: 
INFO  [06:24:45.540] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:24:45.540] [bbotk]              4.084297                 2.694303                       0.4339114 
INFO  [06:24:45.540] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:24:45.540] [bbotk]                     4885        0.806 -0.960257         <NA>   0.9757593 
INFO  [06:24:45.540] [bbotk]                                 uhash 
INFO  [06:24:45.540] [bbotk]  05a5e2ce-45b8-41a2-9c53-8f2e07d5d085 
DEBUG [06:24:46.813] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.065556e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.065556e-05 0.00135776 
  - best initial criterion value(s) :  661.2345 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -661.23  |proj g|=       6.6767
At iterate     1  f =      -668.36  |proj g|=         5.641
At iterate     2  f =      -668.81  |proj g|=        6.1312
At iterate     3  f =      -670.21  |proj g|=        6.1069
At iterate     4  f =      -670.22  |proj g|=        6.1529
At iterate     5  f =      -670.23  |proj g|=        6.0904
At iterate     6  f =      -670.23  |proj g|=        6.1026
At iterate     7  f =      -670.23  |proj g|=        6.1052
At iterate     8  f =      -670.23  |proj g|=        6.1142
At iterate     9  f =      -670.23  |proj g|=        6.1283
At iterate    10  f =      -670.23  |proj g|=        6.1506
At iterate    11  f =      -670.23  |proj g|=        6.1851
At iterate    12  f =      -670.25  |proj g|=        6.2305
At iterate    13  f =      -670.28  |proj g|=        6.2893
At iterate    14  f =      -670.36  |proj g|=        6.3296
At iterate    15  f =       -670.4  |proj g|=        6.7875
At iterate    16  f =       -670.7  |proj g|=        6.5016
At iterate    17  f =      -671.49  |proj g|=        5.4232
At iterate    18  f =      -677.81  |proj g|=        4.0033
At iterate    19  f =      -689.24  |proj g|=         3.307
At iterate    20  f =      -693.78  |proj g|=        2.8045
At iterate    21  f =      -694.83  |proj g|=        2.1796
At iterate    22  f =      -696.65  |proj g|=        2.5361
At iterate    23  f =      -697.53  |proj g|=        1.0983
At iterate    24  f =      -697.96  |proj g|=        1.5404
At iterate    25  f =      -698.06  |proj g|=        1.5606
At iterate    26  f =      -698.08  |proj g|=          1.49
At iterate    27  f =      -698.08  |proj g|=        1.4741
At iterate    28  f =      -698.08  |proj g|=        1.4642
At iterate    29  f =      -698.08  |proj g|=        1.4641
At iterate    30  f =      -698.08  |proj g|=        1.4642

iterations 30
function evaluations 35
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.46421
final function value -698.077

F = -698.077
final  value -698.077495 
converged
 
INFO  [06:24:46.817] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:24:46.947] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:24:46.955] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:24:54.228] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:25:02.003] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:25:08.518] [mlr3]  Finished benchmark 
INFO  [06:25:08.634] [bbotk] Result of batch 127: 
INFO  [06:25:08.636] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:25:08.636] [bbotk]              7.799967                 5.041104                       0.2300517 
INFO  [06:25:08.636] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:25:08.636] [bbotk]                     3159        0.807 -0.9464006         <NA>   0.9747443 
INFO  [06:25:08.636] [bbotk]                                 uhash 
INFO  [06:25:08.636] [bbotk]  a30a0014-7de1-447e-8bba-ea7b9c1f1442 
DEBUG [06:25:09.920] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.061153e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.061153e-05 0.001355986 
  - best initial criterion value(s) :  658.9476 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -658.95  |proj g|=        12.68
At iterate     1  f =      -688.95  |proj g|=        3.8606
At iterate     2  f =      -689.25  |proj g|=        4.7126
At iterate     3  f =      -691.14  |proj g|=        4.8673
At iterate     4  f =      -691.99  |proj g|=        4.5753
At iterate     5  f =      -692.33  |proj g|=        5.6145
At iterate     6  f =      -692.37  |proj g|=        5.6831
At iterate     7  f =      -692.38  |proj g|=        5.5885
At iterate     8  f =      -692.38  |proj g|=        5.5939
At iterate     9  f =      -692.38  |proj g|=        5.6053
At iterate    10  f =      -692.38  |proj g|=        5.6147
At iterate    11  f =      -692.39  |proj g|=        5.6557
At iterate    12  f =      -692.39  |proj g|=        5.6204
At iterate    13  f =       -692.4  |proj g|=        5.6632
At iterate    14  f =      -692.48  |proj g|=        5.7308
At iterate    15  f =      -693.09  |proj g|=        5.7115
At iterate    16  f =      -700.81  |proj g|=       0.59153
At iterate    17  f =       -700.9  |proj g|=       0.23792
At iterate    18  f =      -700.91  |proj g|=       0.68173
At iterate    19  f =      -700.91  |proj g|=       0.23912
At iterate    20  f =      -700.91  |proj g|=       0.20515
At iterate    21  f =      -700.91  |proj g|=       0.20516

iterations 21
function evaluations 29
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.205161
final function value -700.911

F = -700.911
final  value -700.910692 
converged
 
INFO  [06:25:09.924] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:25:10.011] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:25:10.018] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:25:13.763] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:25:17.233] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:25:23.030] [mlr3]  Finished benchmark 
INFO  [06:25:23.127] [bbotk] Result of batch 128: 
INFO  [06:25:23.129] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:25:23.129] [bbotk]              2.496205                 3.903767                       0.3146285 
INFO  [06:25:23.129] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:25:23.129] [bbotk]                     1899        0.839 -0.9542749         <NA>   0.9619809 
INFO  [06:25:23.129] [bbotk]                                 uhash 
INFO  [06:25:23.129] [bbotk]  e1cea771-3262-4d8c-ade4-5019da629fe2 
DEBUG [06:25:24.274] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.057231e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.057231e-05 0.001346736 
  - best initial criterion value(s) :  628.1202 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -628.12  |proj g|=       3.4466
At iterate     1  f =      -631.24  |proj g|=        2.9873
At iterate     2  f =      -632.29  |proj g|=         3.041
At iterate     3  f =      -632.49  |proj g|=        2.9946
At iterate     4  f =      -632.52  |proj g|=        2.9695
At iterate     5  f =      -632.52  |proj g|=        2.9671
At iterate     6  f =      -632.52  |proj g|=        2.9674
At iterate     7  f =      -632.52  |proj g|=        2.9676

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.96761
final function value -632.519

F = -632.519
final  value -632.519107 
converged
 
INFO  [06:25:24.278] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:25:24.365] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:25:24.372] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:25:35.496] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:25:46.767] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:25:56.059] [mlr3]  Finished benchmark 
INFO  [06:25:56.158] [bbotk] Result of batch 129: 
INFO  [06:25:56.160] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:25:56.160] [bbotk]              8.625207                 7.446723                       0.1327837 
INFO  [06:25:56.160] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:25:56.160] [bbotk]                     4840        0.831 -0.9647918         <NA>   0.9745552 
INFO  [06:25:56.160] [bbotk]                                 uhash 
INFO  [06:25:56.160] [bbotk]  61ea2984-498a-49e4-8738-77e1283e197f 
DEBUG [06:25:57.486] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.052795e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.052795e-05 0.001342903 
  - best initial criterion value(s) :  634.0771 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -634.08  |proj g|=       3.2987
At iterate     1  f =       -713.5  |proj g|=       0.99985
At iterate     2  f =      -714.89  |proj g|=        1.1748
At iterate     3  f =      -715.65  |proj g|=         1.026
At iterate     4  f =      -717.22  |proj g|=        1.0951
At iterate     5  f =      -717.87  |proj g|=        1.1439
At iterate     6  f =      -717.98  |proj g|=        1.1589
At iterate     7  f =      -718.01  |proj g|=        1.1579
At iterate     8  f =      -718.01  |proj g|=        1.1579
At iterate     9  f =      -718.01  |proj g|=        1.1579

iterations 9
function evaluations 13
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.1579
final function value -718.008

F = -718.008
final  value -718.008099 
converged
 
INFO  [06:25:57.490] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:25:57.574] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:25:57.581] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:25:59.175] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:26:00.872] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:26:02.583] [mlr3]  Finished benchmark 
INFO  [06:26:02.901] [bbotk] Result of batch 130: 
INFO  [06:26:02.903] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:26:02.903] [bbotk]              9.235292                 4.600921                       0.1892603 
INFO  [06:26:02.903] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:26:02.903] [bbotk]                      679        0.811 -0.9490534         <NA>   0.9655231 
INFO  [06:26:02.903] [bbotk]                                 uhash 
INFO  [06:26:02.903] [bbotk]  19d83357-f83c-4a8d-ad6b-63354e35d55f 
DEBUG [06:26:04.251] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.046819e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.046819e-05 0.001330737 
  - best initial criterion value(s) :  668.2239 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -668.22  |proj g|=       12.656
At iterate     1  f =      -675.27  |proj g|=        10.225
At iterate     2  f =      -677.54  |proj g|=         9.305
At iterate     3  f =      -679.17  |proj g|=        7.5916
At iterate     4  f =      -679.84  |proj g|=        6.6563
At iterate     5  f =      -680.14  |proj g|=        6.1363
At iterate     6  f =      -680.26  |proj g|=         5.902
At iterate     7  f =      -680.29  |proj g|=         6.138
At iterate     8  f =      -680.31  |proj g|=        5.8365
At iterate     9  f =      -680.31  |proj g|=        5.8456
At iterate    10  f =      -680.31  |proj g|=        5.8506
At iterate    11  f =      -680.31  |proj g|=        5.8566
At iterate    12  f =      -680.31  |proj g|=        5.8665
At iterate    13  f =      -680.31  |proj g|=        5.8822
At iterate    14  f =      -680.31  |proj g|=        5.9077
At iterate    15  f =      -680.32  |proj g|=        5.9477
At iterate    16  f =      -680.34  |proj g|=        6.0116
At iterate    17  f =      -680.39  |proj g|=        6.1107
At iterate    18  f =      -680.53  |proj g|=        6.2583
At iterate    19  f =       -680.9  |proj g|=        6.4574
At iterate    20  f =      -681.83  |proj g|=        6.6628
At iterate    21  f =      -683.92  |proj g|=        6.6737
At iterate    22  f =      -687.94  |proj g|=        5.8283
At iterate    23  f =      -692.01  |proj g|=        3.9141
At iterate    24  f =       -693.3  |proj g|=        2.9782
At iterate    25  f =      -693.77  |proj g|=        3.4367
At iterate    26  f =      -694.18  |proj g|=        3.1089
At iterate    27  f =      -694.23  |proj g|=        3.0721
At iterate    28  f =      -694.24  |proj g|=        3.0834
At iterate    29  f =      -694.24  |proj g|=        3.0823
At iterate    30  f =      -694.24  |proj g|=        3.0823

iterations 30
function evaluations 35
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.08227
final function value -694.237

F = -694.237
final  value -694.236755 
converged
 
INFO  [06:26:04.255] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:26:04.340] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:26:04.347] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:26:13.833] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:26:24.188] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:26:34.452] [mlr3]  Finished benchmark 
INFO  [06:26:34.584] [bbotk] Result of batch 131: 
INFO  [06:26:34.586] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:26:34.586] [bbotk]              2.167157                 3.654661                      0.03308133 
INFO  [06:26:34.586] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:26:34.586] [bbotk]                     4466        0.843  -0.96005         <NA>   0.9424503 
INFO  [06:26:34.586] [bbotk]                                 uhash 
INFO  [06:26:34.586] [bbotk]  ccebc64b-e5ef-4e1f-b03c-708cc7d83088 
DEBUG [06:26:35.813] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.082597e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.082597e-05 0.001362345 
  - best initial criterion value(s) :  597.0881 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -597.09  |proj g|=       2.2184
At iterate     1  f =      -598.04  |proj g|=        3.0058
At iterate     2  f =      -598.48  |proj g|=        2.6338
At iterate     3  f =      -598.57  |proj g|=        2.5039
At iterate     4  f =      -598.58  |proj g|=        2.4682
At iterate     5  f =      -598.58  |proj g|=        2.4646
At iterate     6  f =      -598.58  |proj g|=        2.4645

iterations 6
function evaluations 9
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.46448
final function value -598.579

F = -598.579
final  value -598.579265 
converged
 
INFO  [06:26:35.817] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:26:35.904] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:26:35.911] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:26:44.306] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:26:51.688] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:26:58.434] [mlr3]  Finished benchmark 
INFO  [06:26:58.534] [bbotk] Result of batch 132: 
INFO  [06:26:58.536] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:26:58.536] [bbotk]              6.066307                 3.593566                       0.2632624 
INFO  [06:26:58.536] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:26:58.536] [bbotk]                     3322        0.914 -0.9694293         <NA>   0.9750499 
INFO  [06:26:58.536] [bbotk]                                 uhash 
INFO  [06:26:58.536] [bbotk]  d0ba7cf3-58c3-4f25-b1f2-362824512b63 
DEBUG [06:26:59.908] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.078579e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.078579e-05 0.00135991 
  - best initial criterion value(s) :  693.9241 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -693.92  |proj g|=       2.2984
At iterate     1  f =      -729.02  |proj g|=        2.3311
At iterate     2  f =      -730.46  |proj g|=        4.6291
At iterate     3  f =      -731.52  |proj g|=        4.1296
At iterate     4  f =      -733.01  |proj g|=         2.949
At iterate     5  f =      -733.57  |proj g|=        2.4275
At iterate     6  f =      -733.67  |proj g|=        3.2046
At iterate     7  f =      -733.71  |proj g|=        2.9857
At iterate     8  f =      -733.71  |proj g|=        2.9436
At iterate     9  f =      -733.71  |proj g|=        2.9486
At iterate    10  f =      -733.71  |proj g|=        2.9393
At iterate    11  f =      -733.72  |proj g|=        2.9104
At iterate    12  f =      -733.72  |proj g|=        2.8726
At iterate    13  f =      -733.74  |proj g|=        2.8071
At iterate    14  f =      -733.79  |proj g|=        2.7046
At iterate    15  f =      -733.91  |proj g|=         2.551
At iterate    16  f =       -734.2  |proj g|=        2.3805
At iterate    17  f =      -734.77  |proj g|=        2.2833
At iterate    18  f =      -735.37  |proj g|=         1.054
At iterate    19  f =      -736.79  |proj g|=        1.2206
At iterate    20  f =      -738.25  |proj g|=        2.2227
At iterate    21  f =      -739.31  |proj g|=        2.5996
At iterate    22  f =      -740.33  |proj g|=        2.7278
At iterate    23  f =      -740.55  |proj g|=        2.3753
At iterate    24  f =      -740.61  |proj g|=        1.8336
At iterate    25  f =      -740.63  |proj g|=         2.007
At iterate    26  f =      -740.63  |proj g|=        1.9864
At iterate    27  f =      -740.63  |proj g|=        1.9851

iterations 27
function evaluations 36
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.98514
final function value -740.626

F = -740.626
final  value -740.625848 
converged
 
INFO  [06:26:59.912] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:27:00.031] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:27:00.038] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:27:10.843] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:27:20.764] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:27:33.710] [mlr3]  Finished benchmark 
INFO  [06:27:33.812] [bbotk] Result of batch 133: 
INFO  [06:27:33.814] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:27:33.814] [bbotk]              3.764493                 2.399684                      0.08175344 
INFO  [06:27:33.814] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:27:33.814] [bbotk]                     4592        0.845 -0.9484202         <NA>   0.9683517 
INFO  [06:27:33.814] [bbotk]                                 uhash 
INFO  [06:27:33.814] [bbotk]  447ed16f-b3d4-4a2c-951e-a82c2ffa4f27 
DEBUG [06:27:35.461] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.071963e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.071963e-05 0.001351978 
  - best initial criterion value(s) :  678.1779 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -678.18  |proj g|=       4.8793
At iterate     1  f =      -706.32  |proj g|=        11.958
At iterate     2  f =      -716.19  |proj g|=        11.692
At iterate     3  f =      -726.54  |proj g|=        9.3866
At iterate     4  f =      -728.71  |proj g|=        6.3146
At iterate     5  f =      -730.11  |proj g|=        5.7805
At iterate     6  f =      -734.95  |proj g|=        4.3411
At iterate     7  f =      -736.51  |proj g|=        3.7444
At iterate     8  f =      -737.52  |proj g|=        3.4397
At iterate     9  f =      -737.94  |proj g|=         3.351
At iterate    10  f =         -738  |proj g|=          3.95
At iterate    11  f =      -738.14  |proj g|=        3.2516
At iterate    12  f =      -738.14  |proj g|=        3.3288
At iterate    13  f =      -738.14  |proj g|=        3.3336
At iterate    14  f =      -738.14  |proj g|=        3.3491
At iterate    15  f =      -738.14  |proj g|=        3.3629
At iterate    16  f =      -738.14  |proj g|=        3.3877
At iterate    17  f =      -738.15  |proj g|=        3.4236
At iterate    18  f =      -738.16  |proj g|=        3.4748
At iterate    19  f =      -738.19  |proj g|=        3.5408
At iterate    20  f =      -738.27  |proj g|=        3.5993
At iterate    21  f =      -738.49  |proj g|=        3.5669
At iterate    22  f =      -738.97  |proj g|=        3.2312
At iterate    23  f =      -739.97  |proj g|=        2.1659
At iterate    24  f =       -740.3  |proj g|=        1.4508
At iterate    25  f =      -740.32  |proj g|=        1.4464
At iterate    26  f =      -740.32  |proj g|=        1.4432
At iterate    27  f =      -740.32  |proj g|=         1.441
At iterate    28  f =      -740.32  |proj g|=        1.4402
At iterate    29  f =      -740.33  |proj g|=        1.4357
At iterate    30  f =      -740.34  |proj g|=        1.4309
At iterate    31  f =      -740.36  |proj g|=        1.4234
At iterate    32  f =      -740.42  |proj g|=        1.4118
At iterate    33  f =      -740.58  |proj g|=        1.3913
At iterate    34  f =      -740.97  |proj g|=        1.3594
At iterate    35  f =      -741.91  |proj g|=        1.3145
At iterate    36  f =      -743.52  |proj g|=        1.2773
At iterate    37  f =      -743.85  |proj g|=        1.3124
At iterate    38  f =      -743.88  |proj g|=        1.3145
At iterate    39  f =      -743.93  |proj g|=        1.3265
At iterate    40  f =         -744  |proj g|=        1.3566
At iterate    41  f =      -744.06  |proj g|=        1.4025
At iterate    42  f =      -744.06  |proj g|=        1.3996
At iterate    43  f =      -744.08  |proj g|=        1.4238
At iterate    44  f =      -744.08  |proj g|=        1.4295
At iterate    45  f =      -744.08  |proj g|=        1.4296
At iterate    46  f =      -744.08  |proj g|=        1.4295

iterations 46
function evaluations 52
segments explored during Cauchy searches 50
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.42947
final function value -744.081

F = -744.081
final  value -744.080895 
converged
 
INFO  [06:27:35.465] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:27:35.553] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:27:35.560] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:27:46.164] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:27:57.796] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:28:09.866] [mlr3]  Finished benchmark 
INFO  [06:28:09.971] [bbotk] Result of batch 134: 
INFO  [06:28:09.973] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:28:09.973] [bbotk]              5.342745                  2.44123                      0.07264912 
INFO  [06:28:09.973] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:28:09.973] [bbotk]                     4829        0.841 -0.9424106         <NA>   0.9712752 
INFO  [06:28:09.973] [bbotk]                                 uhash 
INFO  [06:28:09.973] [bbotk]  a7b9d6d6-e4ca-49e8-a0c2-f511ddc8c301 
DEBUG [06:28:11.542] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.065894e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.065894e-05 0.001345628 
  - best initial criterion value(s) :  690.2834 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -690.28  |proj g|=       8.0532
At iterate     1  f =      -705.06  |proj g|=         6.891
At iterate     2  f =      -714.75  |proj g|=        5.3216
At iterate     3  f =      -724.93  |proj g|=        4.5488
At iterate     4  f =      -725.26  |proj g|=        4.4004
At iterate     5  f =      -725.81  |proj g|=        4.4866
At iterate     6  f =      -727.13  |proj g|=        4.7127
At iterate     7  f =      -727.31  |proj g|=        4.8178
At iterate     8  f =      -727.34  |proj g|=        4.8777
At iterate     9  f =      -727.34  |proj g|=        4.8986
At iterate    10  f =      -727.34  |proj g|=        4.9034
At iterate    11  f =      -727.34  |proj g|=        4.9036
At iterate    12  f =      -727.34  |proj g|=        4.9039
At iterate    13  f =      -727.34  |proj g|=        4.9044
At iterate    14  f =      -727.34  |proj g|=        4.9052
At iterate    15  f =      -727.35  |proj g|=        4.9062
At iterate    16  f =      -727.35  |proj g|=        4.9073
At iterate    17  f =      -727.35  |proj g|=        4.9071
At iterate    18  f =      -727.35  |proj g|=        4.9025
At iterate    19  f =      -727.35  |proj g|=        4.8941
At iterate    20  f =      -727.35  |proj g|=        4.8966
At iterate    21  f =      -727.36  |proj g|=        4.8852
At iterate    22  f =      -727.61  |proj g|=        4.8683
At iterate    23  f =      -728.05  |proj g|=        4.7904
At iterate    24  f =      -728.06  |proj g|=        4.8056
At iterate    25  f =      -728.06  |proj g|=        4.8079
At iterate    26  f =      -728.06  |proj g|=        4.8082

iterations 26
function evaluations 33
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.80821
final function value -728.062

F = -728.062
final  value -728.061683 
converged
 
INFO  [06:28:11.547] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:28:11.671] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:28:11.678] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:28:19.464] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:28:27.466] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:28:34.202] [mlr3]  Finished benchmark 
INFO  [06:28:34.304] [bbotk] Result of batch 135: 
INFO  [06:28:34.306] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:28:34.306] [bbotk]              4.986092                 5.942932                       0.1547806 
INFO  [06:28:34.306] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:28:34.306] [bbotk]                     3335        1.006 -0.9513599         <NA>   0.9727874 
INFO  [06:28:34.306] [bbotk]                                 uhash 
INFO  [06:28:34.306] [bbotk]  e030fc5f-def4-4704-bd14-5034015b6fe2 
DEBUG [06:28:35.545] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.060533e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.060533e-05 0.001340931 
  - best initial criterion value(s) :  712.5075 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -712.51  |proj g|=       8.0248
At iterate     1  f =      -740.38  |proj g|=        1.1895
At iterate     2  f =      -746.62  |proj g|=        1.3758
At iterate     3  f =       -747.1  |proj g|=        1.3655
At iterate     4  f =      -747.71  |proj g|=        1.3838
At iterate     5  f =       -747.9  |proj g|=        1.4106
At iterate     6  f =      -747.94  |proj g|=        1.4272
At iterate     7  f =      -747.94  |proj g|=        1.4257
At iterate     8  f =      -747.94  |proj g|=        1.4254
At iterate     9  f =      -747.94  |proj g|=        1.4255

iterations 9
function evaluations 11
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.42548
final function value -747.939

F = -747.939
final  value -747.939407 
converged
 
INFO  [06:28:35.550] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:28:35.640] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:28:35.647] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:28:47.870] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:28:58.285] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:29:14.020] [mlr3]  Finished benchmark 
INFO  [06:29:14.232] [bbotk] Result of batch 136: 
INFO  [06:29:14.234] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:29:14.234] [bbotk]                  7.61                 6.700214                       0.4386299 
INFO  [06:29:14.234] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:29:14.234] [bbotk]                     4726        0.861 -0.9496695         <NA>   0.9770366 
INFO  [06:29:14.234] [bbotk]                                 uhash 
INFO  [06:29:14.234] [bbotk]  35787861-5ae1-4819-9846-3758e6d4b0b4 
DEBUG [06:29:15.480] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.058465e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.058465e-05 0.001340937 
  - best initial criterion value(s) :  698.5067 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -698.51  |proj g|=       6.3237
At iterate     1  f =      -732.13  |proj g|=        4.6851
At iterate     2  f =         -733  |proj g|=        4.1982
At iterate     3  f =      -734.08  |proj g|=        3.6901
At iterate     4  f =      -734.28  |proj g|=        3.7599
At iterate     5  f =      -734.55  |proj g|=        3.7741
At iterate     6  f =      -735.68  |proj g|=          3.92
At iterate     7  f =      -735.98  |proj g|=        4.0377
At iterate     8  f =      -736.02  |proj g|=        4.0933
At iterate     9  f =      -736.03  |proj g|=        4.1116
At iterate    10  f =      -736.03  |proj g|=        4.1141
At iterate    11  f =      -736.03  |proj g|=        4.1143

iterations 11
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.11428
final function value -736.027

F = -736.027
final  value -736.026683 
converged
 
INFO  [06:29:15.484] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:29:15.574] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:29:15.581] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:29:22.192] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:29:29.059] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:29:35.727] [mlr3]  Finished benchmark 
INFO  [06:29:35.831] [bbotk] Result of batch 137: 
INFO  [06:29:35.833] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:29:35.833] [bbotk]              9.965316                 3.561995                       0.4746101 
INFO  [06:29:35.833] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:29:35.833] [bbotk]                     2680        0.869 -0.955726         <NA>   0.9743581 
INFO  [06:29:35.833] [bbotk]                                 uhash 
INFO  [06:29:35.833] [bbotk]  0eed0dc8-9eea-4706-8c82-503bde05cfd2 
DEBUG [06:29:37.800] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.054105e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.054105e-05 0.001338258 
  - best initial criterion value(s) :  682.4644 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -682.46  |proj g|=       9.7966
At iterate     1  f =      -712.47  |proj g|=        1.0608
At iterate     2  f =      -713.21  |proj g|=        1.4774
At iterate     3  f =      -713.96  |proj g|=        3.1354
At iterate     4  f =      -714.07  |proj g|=        2.5794
At iterate     5  f =      -714.08  |proj g|=        2.6682
At iterate     6  f =      -714.08  |proj g|=        2.6853
At iterate     7  f =      -714.08  |proj g|=         2.741
At iterate     8  f =      -714.09  |proj g|=        2.7915
At iterate     9  f =      -714.11  |proj g|=        2.8021
At iterate    10  f =      -714.11  |proj g|=        2.7463
At iterate    11  f =      -714.11  |proj g|=        2.7259
At iterate    12  f =      -714.11  |proj g|=        2.7232
At iterate    13  f =      -714.11  |proj g|=        2.7185
At iterate    14  f =      -714.11  |proj g|=        2.7107
At iterate    15  f =      -714.11  |proj g|=        2.6981
At iterate    16  f =      -714.12  |proj g|=        2.6775
At iterate    17  f =      -714.12  |proj g|=        2.6443
At iterate    18  f =      -714.12  |proj g|=         2.592
At iterate    19  f =      -714.14  |proj g|=        2.5226
At iterate    20  f =      -714.16  |proj g|=        2.4801
At iterate    21  f =      -714.16  |proj g|=         2.533
At iterate    22  f =      -714.17  |proj g|=        2.4977
At iterate    23  f =      -717.14  |proj g|=        1.7102
At iterate    24  f =      -720.44  |proj g|=       0.96743
At iterate    25  f =      -721.15  |proj g|=       0.78142
At iterate    26  f =      -721.22  |proj g|=       0.77649
At iterate    27  f =      -721.22  |proj g|=       0.77639
At iterate    28  f =      -721.22  |proj g|=       0.28739
At iterate    29  f =      -721.22  |proj g|=       0.28758
At iterate    30  f =      -721.22  |proj g|=       0.28764
At iterate    31  f =      -721.22  |proj g|=       0.28767
At iterate    32  f =      -721.22  |proj g|=        0.2877
At iterate    33  f =      -721.22  |proj g|=       0.28772
At iterate    34  f =      -721.22  |proj g|=       0.28758
At iterate    35  f =      -721.23  |proj g|=       0.28679
At iterate    36  f =      -721.23  |proj g|=       0.28419
At iterate    37  f =      -721.24  |proj g|=       0.27716
At iterate    38  f =      -721.25  |proj g|=       0.27859
At iterate    39  f =      -721.27  |proj g|=       0.41413
At iterate    40  f =      -721.27  |proj g|=       0.44842
At iterate    41  f =       -721.3  |proj g|=       0.57337
At iterate    42  f =      -721.31  |proj g|=       0.58746
At iterate    43  f =      -721.31  |proj g|=       0.56734
At iterate    44  f =      -721.31  |proj g|=       0.56413
At iterate    45  f =      -721.31  |proj g|=       0.55427
At iterate    46  f =      -721.31  |proj g|=       0.56762
At iterate    47  f =      -721.31  |proj g|=       0.55185
At iterate    48  f =      -721.32  |proj g|=        0.5221
At iterate    49  f =      -721.32  |proj g|=       0.48176
At iterate    50  f =      -721.32  |proj g|=        0.4119
At iterate    51  f =      -721.34  |proj g|=       0.29596
At iterate    52  f =      -721.36  |proj g|=       0.21223
At iterate    53  f =      -721.42  |proj g|=       0.21066
At iterate    54  f =      -721.55  |proj g|=       0.77905
At iterate    55  f =      -721.57  |proj g|=       0.78328
At iterate    56  f =      -721.64  |proj g|=       0.78786
At iterate    57  f =      -721.65  |proj g|=       0.78807
At iterate    58  f =      -721.65  |proj g|=       0.78814
At iterate    59  f =      -721.65  |proj g|=       0.78812
At iterate    60  f =      -721.65  |proj g|=       0.78801
At iterate    61  f =      -721.66  |proj g|=       0.78762
At iterate    62  f =      -721.68  |proj g|=       0.78645
At iterate    63  f =      -721.71  |proj g|=       0.78374
At iterate    64  f =      -721.71  |proj g|=       0.78248
At iterate    65  f =      -721.76  |proj g|=       0.77863
At iterate    66  f =      -721.81  |proj g|=       0.18951
At iterate    67  f =      -721.82  |proj g|=       0.21209
At iterate    68  f =      -721.82  |proj g|=       0.48337
At iterate    69  f =      -721.82  |proj g|=      0.035291
At iterate    70  f =      -721.82  |proj g|=      0.035291

iterations 70
function evaluations 81
segments explored during Cauchy searches 74
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0352914
final function value -721.819

F = -721.819
final  value -721.818548 
converged
 
INFO  [06:29:37.805] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:29:38.266] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:29:38.273] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:29:40.483] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:29:43.548] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:29:45.572] [mlr3]  Finished benchmark 
INFO  [06:29:45.687] [bbotk] Result of batch 138: 
INFO  [06:29:45.689] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:29:45.689] [bbotk]              6.378931                  4.32782                      0.04813211 
INFO  [06:29:45.689] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:29:45.689] [bbotk]                      894        0.843 -0.9599024         <NA>   0.9509959 
INFO  [06:29:45.689] [bbotk]                                 uhash 
INFO  [06:29:45.689] [bbotk]  40bb8f36-2fb2-4fe2-99f3-b3039a9c4ce5 
DEBUG [06:29:47.089] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.066225e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.066225e-05 0.001355323 
  - best initial criterion value(s) :  685.1818 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -685.18  |proj g|=       5.8745
At iterate     1  f =      -759.51  |proj g|=        1.9388
At iterate     2  f =      -763.41  |proj g|=        1.7013
At iterate     3  f =      -763.85  |proj g|=        1.7175
At iterate     4  f =      -764.43  |proj g|=        1.8281
At iterate     5  f =      -764.91  |proj g|=        1.8017
At iterate     6  f =         -765  |proj g|=        1.8241
At iterate     7  f =      -765.01  |proj g|=        1.8376
At iterate     8  f =      -765.01  |proj g|=        1.8375
At iterate     9  f =      -765.01  |proj g|=        1.8367
At iterate    10  f =      -765.02  |proj g|=        1.8319
At iterate    11  f =      -765.18  |proj g|=        1.7729
At iterate    12  f =      -765.55  |proj g|=        1.6355
At iterate    13  f =      -766.34  |proj g|=        1.3319
At iterate    14  f =      -766.34  |proj g|=        1.3312
At iterate    15  f =      -767.52  |proj g|=       0.85324
At iterate    16  f =      -769.08  |proj g|=       0.86657
At iterate    17  f =      -769.36  |proj g|=        1.6496
At iterate    18  f =      -769.66  |proj g|=       0.78942
At iterate    19  f =      -769.66  |proj g|=       0.94743
At iterate    20  f =      -769.66  |proj g|=        0.9322
At iterate    21  f =      -769.66  |proj g|=       0.92396
At iterate    22  f =      -769.66  |proj g|=        0.9254

iterations 22
function evaluations 31
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.925397
final function value -769.661

F = -769.661
final  value -769.660966 
converged
 
INFO  [06:29:47.093] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:29:47.181] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:29:47.188] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:29:49.704] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:29:52.490] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:29:55.324] [mlr3]  Finished benchmark 
INFO  [06:29:55.423] [bbotk] Result of batch 139: 
INFO  [06:29:55.425] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:29:55.425] [bbotk]              7.846153                 9.605024                       0.1928653 
INFO  [06:29:55.425] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:29:55.425] [bbotk]                     1220        0.884 -0.9506053         <NA>   0.9698313 
INFO  [06:29:55.425] [bbotk]                                 uhash 
INFO  [06:29:55.425] [bbotk]  85156754-14e7-40db-8a6f-70f29461179f 
DEBUG [06:29:56.660] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.060016e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.060016e-05 0.001342322 
  - best initial criterion value(s) :  742.0636 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -742.06  |proj g|=       3.2808
At iterate     1  f =      -757.81  |proj g|=        4.1134
At iterate     2  f =      -759.19  |proj g|=        5.7495
At iterate     3  f =      -762.59  |proj g|=        4.7896
At iterate     4  f =      -763.87  |proj g|=        3.7242
At iterate     5  f =      -764.74  |proj g|=        3.4367
At iterate     6  f =      -765.19  |proj g|=        3.6396
At iterate     7  f =      -765.21  |proj g|=        3.6155
At iterate     8  f =      -765.21  |proj g|=        3.6108
At iterate     9  f =      -765.21  |proj g|=        3.6113
At iterate    10  f =      -765.21  |proj g|=        3.6113

iterations 10
function evaluations 12
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.61128
final function value -765.207

F = -765.207
final  value -765.207478 
converged
 
INFO  [06:29:56.665] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:29:56.769] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:29:56.776] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:30:06.117] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:30:14.897] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:30:22.858] [mlr3]  Finished benchmark 
INFO  [06:30:22.958] [bbotk] Result of batch 140: 
INFO  [06:30:22.960] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:30:22.960] [bbotk]              9.689823                 9.812155                        0.132025 
INFO  [06:30:22.960] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:30:22.960] [bbotk]                     3744        0.868 -0.950888         <NA>   0.9732873 
INFO  [06:30:22.960] [bbotk]                                 uhash 
INFO  [06:30:22.960] [bbotk]  6e17f295-8aaf-42d9-a2c7-9b7933bab55f 
DEBUG [06:30:24.449] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.055104e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.055104e-05 0.001338694 
  - best initial criterion value(s) :  719.4678 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -719.47  |proj g|=       5.7698
At iterate     1  f =      -762.16  |proj g|=        6.6952
At iterate     2  f =       -762.8  |proj g|=        6.2454
At iterate     3  f =      -763.84  |proj g|=        4.2136
At iterate     4  f =      -764.02  |proj g|=        4.5391
At iterate     5  f =      -764.45  |proj g|=         4.747
At iterate     6  f =      -765.62  |proj g|=        4.6114
At iterate     7  f =      -767.04  |proj g|=        3.7105
At iterate     8  f =      -767.21  |proj g|=        3.1567
At iterate     9  f =      -767.62  |proj g|=        3.0278
At iterate    10  f =      -767.64  |proj g|=        3.0682
At iterate    11  f =      -767.75  |proj g|=        3.0845
At iterate    12  f =      -767.87  |proj g|=        3.1106
At iterate    13  f =      -768.73  |proj g|=        3.2961
At iterate    14  f =       -768.8  |proj g|=        3.2939
At iterate    15  f =      -768.81  |proj g|=        3.3001
At iterate    16  f =      -768.81  |proj g|=        3.2997
At iterate    17  f =      -768.81  |proj g|=        3.2998

iterations 17
function evaluations 23
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.29977
final function value -768.806

F = -768.806
final  value -768.806128 
converged
 
INFO  [06:30:24.453] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:30:24.556] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:30:24.562] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:30:31.120] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:30:37.584] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:30:45.382] [mlr3]  Finished benchmark 
INFO  [06:30:45.482] [bbotk] Result of batch 141: 
INFO  [06:30:45.484] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:30:45.484] [bbotk]              5.774458                 5.130565                       0.1382091 
INFO  [06:30:45.484] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:30:45.484] [bbotk]                     2847        1.032 -0.9527292         <NA>   0.9722636 
INFO  [06:30:45.484] [bbotk]                                 uhash 
INFO  [06:30:45.484] [bbotk]  8ce75a7a-f3a1-493d-9fdb-0be3a9885a32 
DEBUG [06:30:47.162] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.049732e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.049732e-05 0.00133531 
  - best initial criterion value(s) :  702.3488 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -702.35  |proj g|=       8.6133
At iterate     1  f =      -737.37  |proj g|=        6.7112
At iterate     2  f =      -744.67  |proj g|=        6.5361
At iterate     3  f =      -751.48  |proj g|=        5.1024
At iterate     4  f =      -753.45  |proj g|=        5.8325
At iterate     5  f =      -756.07  |proj g|=        5.9485
At iterate     6  f =      -758.73  |proj g|=        6.1088
At iterate     7  f =      -759.46  |proj g|=        6.4087
At iterate     8  f =      -759.63  |proj g|=         6.539
At iterate     9  f =      -759.66  |proj g|=         6.607
At iterate    10  f =      -759.66  |proj g|=         6.628
At iterate    11  f =      -759.66  |proj g|=        6.6393
At iterate    12  f =      -759.66  |proj g|=        6.6445
At iterate    13  f =      -759.66  |proj g|=        6.6606
At iterate    14  f =      -759.67  |proj g|=        6.6855
At iterate    15  f =       -759.7  |proj g|=         6.724
At iterate    16  f =      -759.76  |proj g|=        6.7531
At iterate    17  f =      -759.77  |proj g|=         6.843
At iterate    18  f =       -759.9  |proj g|=        6.8406
At iterate    19  f =       -760.2  |proj g|=        6.7949
At iterate    20  f =      -760.67  |proj g|=        6.6433
At iterate    21  f =      -760.75  |proj g|=        6.4878
At iterate    22  f =      -760.77  |proj g|=        6.5396
At iterate    23  f =      -760.77  |proj g|=        6.5351
At iterate    24  f =      -760.77  |proj g|=        6.5311
At iterate    25  f =      -760.77  |proj g|=        6.5314
At iterate    26  f =      -760.77  |proj g|=        6.5323
At iterate    27  f =      -760.77  |proj g|=        6.5327
At iterate    28  f =      -760.78  |proj g|=         6.532
At iterate    29  f =      -760.79  |proj g|=        6.4532
At iterate    30  f =      -760.81  |proj g|=        6.5059
At iterate    31  f =      -760.88  |proj g|=        6.5613
At iterate    32  f =      -761.11  |proj g|=        6.6698
At iterate    33  f =      -761.64  |proj g|=        6.7656
At iterate    34  f =      -763.03  |proj g|=        6.7334
At iterate    35  f =      -765.55  |proj g|=        6.2752
At iterate    36  f =       -767.2  |proj g|=        5.7121
At iterate    37  f =      -767.91  |proj g|=        5.2468
At iterate    38  f =      -768.01  |proj g|=        5.1886
At iterate    39  f =      -768.03  |proj g|=         5.207
At iterate    40  f =      -768.11  |proj g|=        5.2661
At iterate    41  f =      -768.11  |proj g|=         5.237
At iterate    42  f =      -768.12  |proj g|=        5.2177
At iterate    43  f =      -768.12  |proj g|=        5.2185

iterations 43
function evaluations 53
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 5.21846
final function value -768.116

F = -768.116
final  value -768.115597 
converged
 
INFO  [06:30:47.167] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:30:47.252] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:30:47.259] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:31:03.601] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:31:15.336] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:31:26.305] [mlr3]  Finished benchmark 
INFO  [06:31:26.405] [bbotk] Result of batch 142: 
INFO  [06:31:26.407] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:31:26.407] [bbotk]              7.487295                 5.082052                       0.3700654 
INFO  [06:31:26.407] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:31:26.407] [bbotk]                     4815        0.962 -0.9370009         <NA>   0.9767601 
INFO  [06:31:26.407] [bbotk]                                 uhash 
INFO  [06:31:26.407] [bbotk]  2a37c793-9462-4597-8575-271359067192 
DEBUG [06:31:27.754] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.047497e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.047497e-05 0.001334241 
  - best initial criterion value(s) :  736.4891 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -736.49  |proj g|=       9.5624
At iterate     1  f =      -754.19  |proj g|=        9.9526
At iterate     2  f =      -755.84  |proj g|=        9.8184
At iterate     3  f =      -760.06  |proj g|=        7.3756
At iterate     4  f =      -760.34  |proj g|=        5.6944
At iterate     5  f =      -760.51  |proj g|=        5.8366
At iterate     6  f =      -760.51  |proj g|=         5.725
At iterate     7  f =      -767.43  |proj g|=        4.9977
At iterate     8  f =      -788.98  |proj g|=        1.3922
At iterate     9  f =      -793.46  |proj g|=        1.1057
At iterate    10  f =      -796.31  |proj g|=       0.91955
At iterate    11  f =      -796.97  |proj g|=       0.85332
At iterate    12  f =       -798.4  |proj g|=       0.67729
At iterate    13  f =      -798.95  |proj g|=       0.76714
At iterate    14  f =      -799.13  |proj g|=       0.75725
At iterate    15  f =      -799.24  |proj g|=       0.65481
At iterate    16  f =      -799.27  |proj g|=       0.56869
At iterate    17  f =      -799.27  |proj g|=       0.54054
At iterate    18  f =      -799.27  |proj g|=       0.53797
At iterate    19  f =      -799.27  |proj g|=       0.53678

iterations 19
function evaluations 25
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.536778
final function value -799.275

F = -799.275
final  value -799.274923 
converged
 
INFO  [06:31:27.758] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:31:27.846] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:31:27.853] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:31:39.683] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:31:53.636] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:32:03.307] [mlr3]  Finished benchmark 
INFO  [06:32:03.437] [bbotk] Result of batch 143: 
INFO  [06:32:03.439] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:32:03.439] [bbotk]              8.727386                 4.645766                       0.1211982 
INFO  [06:32:03.439] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:32:03.439] [bbotk]                     4670         0.87 -0.9355026         <NA>   0.9742239 
INFO  [06:32:03.439] [bbotk]                                 uhash 
INFO  [06:32:03.439] [bbotk]  f89d78f5-be1f-45d5-9992-2ab2fc2e67d4 
DEBUG [06:32:05.071] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.043242e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.043242e-05 0.001330713 
  - best initial criterion value(s) :  693.8552 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -693.86  |proj g|=       6.9048
At iterate     1  f =      -707.57  |proj g|=        11.718
At iterate     2  f =      -721.29  |proj g|=        10.298
At iterate     3  f =      -731.82  |proj g|=        8.2685
At iterate     4  f =      -740.55  |proj g|=        7.2546
At iterate     5  f =      -744.91  |proj g|=        6.7374
At iterate     6  f =      -744.94  |proj g|=        6.4943
At iterate     7  f =      -744.98  |proj g|=        6.6058
At iterate     8  f =      -744.98  |proj g|=        6.5997
At iterate     9  f =      -744.98  |proj g|=        6.5991
At iterate    10  f =      -744.98  |proj g|=        6.5986
At iterate    11  f =      -744.98  |proj g|=        6.5977
At iterate    12  f =      -744.98  |proj g|=        6.5954
At iterate    13  f =      -744.98  |proj g|=         6.592
At iterate    14  f =      -744.98  |proj g|=        6.5859
At iterate    15  f =      -744.99  |proj g|=        6.5721
At iterate    16  f =      -745.01  |proj g|=        6.5435
At iterate    17  f =      -745.05  |proj g|=        6.4964
At iterate    18  f =      -745.16  |proj g|=        6.3839
At iterate    19  f =      -745.18  |proj g|=        6.4049
At iterate    20  f =      -745.45  |proj g|=        6.2304
At iterate    21  f =         -754  |proj g|=        4.9785
At iterate    22  f =      -778.39  |proj g|=        1.3428
At iterate    23  f =      -781.98  |proj g|=       0.81438
At iterate    24  f =      -782.35  |proj g|=       0.76891
At iterate    25  f =      -782.38  |proj g|=        0.7672
At iterate    26  f =       -782.6  |proj g|=       0.75483
At iterate    27  f =      -782.61  |proj g|=       0.18179
At iterate    28  f =      -782.61  |proj g|=      0.061895
At iterate    29  f =      -782.61  |proj g|=      0.060935

iterations 29
function evaluations 38
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0609355
final function value -782.606

F = -782.606
final  value -782.606472 
converged
 
INFO  [06:32:05.075] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:32:05.165] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:32:05.172] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:32:10.018] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:32:15.356] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:32:20.148] [mlr3]  Finished benchmark 
INFO  [06:32:20.336] [bbotk] Result of batch 144: 
INFO  [06:32:20.338] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:32:20.338] [bbotk]              2.499971                 6.758763                       0.1808832 
INFO  [06:32:20.338] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:32:20.338] [bbotk]                     2385         1.03 -0.9546986         <NA>    0.958802 
INFO  [06:32:20.338] [bbotk]                                 uhash 
INFO  [06:32:20.338] [bbotk]  99f2eb9f-dc8f-4747-8c38-bd30cb1d69c5 
DEBUG [06:32:21.551] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.042799e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.042799e-05 0.00132795 
  - best initial criterion value(s) :  709.784 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -709.78  |proj g|=       6.0644
At iterate     1  f =      -743.74  |proj g|=         0.651
At iterate     2  f =         -745  |proj g|=       0.71643
At iterate     3  f =      -747.23  |proj g|=        2.0468
At iterate     4  f =      -747.26  |proj g|=        1.9769
At iterate     5  f =      -747.27  |proj g|=        2.2013
At iterate     6  f =      -747.27  |proj g|=        2.1159
At iterate     7  f =      -747.27  |proj g|=        2.1195
At iterate     8  f =      -747.27  |proj g|=        2.1198

iterations 8
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.11984
final function value -747.273

F = -747.273
final  value -747.272573 
converged
 
INFO  [06:32:21.556] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:32:21.657] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:32:21.665] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:32:29.751] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:32:38.130] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:32:46.053] [mlr3]  Finished benchmark 
INFO  [06:32:46.229] [bbotk] Result of batch 145: 
INFO  [06:32:46.232] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:32:46.232] [bbotk]              3.448629                 8.054795                       0.2095843 
INFO  [06:32:46.232] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:32:46.232] [bbotk]                     4961         0.86 -0.9559681         <NA>   0.9719899 
INFO  [06:32:46.232] [bbotk]                                 uhash 
INFO  [06:32:46.232] [bbotk]  0afec998-f232-4133-a1cc-d9dedb453835 
DEBUG [06:32:47.816] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.037492e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.037492e-05 0.001322087 
  - best initial criterion value(s) :  738.2065 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -738.21  |proj g|=       9.2024
At iterate     1  f =      -770.23  |proj g|=        4.9948
At iterate     2  f =      -772.19  |proj g|=        8.1377
At iterate     3  f =      -773.71  |proj g|=        6.9062
At iterate     4  f =      -773.72  |proj g|=        6.8991
At iterate     5  f =      -773.72  |proj g|=        6.9086
At iterate     6  f =      -773.72  |proj g|=        6.9253
At iterate     7  f =      -773.72  |proj g|=        6.9326
At iterate     8  f =      -773.72  |proj g|=        6.9438
At iterate     9  f =      -773.72  |proj g|=        6.9562
At iterate    10  f =      -773.73  |proj g|=        6.9789
At iterate    11  f =      -773.73  |proj g|=        7.0139
At iterate    12  f =      -773.74  |proj g|=        7.0698
At iterate    13  f =      -773.77  |proj g|=        7.1512
At iterate    14  f =      -773.85  |proj g|=        7.2646
At iterate    15  f =      -774.02  |proj g|=        7.4363
At iterate    16  f =      -774.46  |proj g|=        7.5479
At iterate    17  f =      -774.48  |proj g|=        7.7629
At iterate    18  f =      -775.64  |proj g|=        7.5487
At iterate    19  f =      -777.78  |proj g|=        6.3524
At iterate    20  f =      -782.48  |proj g|=        5.8518
At iterate    21  f =      -791.85  |proj g|=        7.1802
At iterate    22  f =      -792.36  |proj g|=        8.0695
At iterate    23  f =      -792.38  |proj g|=        7.9899
At iterate    24  f =       -792.4  |proj g|=        7.9509
At iterate    25  f =       -792.4  |proj g|=        7.9494
At iterate    26  f =       -792.4  |proj g|=        7.9495

iterations 26
function evaluations 30
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 7.94946
final function value -792.399

F = -792.399
final  value -792.398978 
converged
 
INFO  [06:32:47.821] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:32:47.911] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:32:47.919] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:32:55.887] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:33:03.601] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:33:11.244] [mlr3]  Finished benchmark 
INFO  [06:33:11.348] [bbotk] Result of batch 146: 
INFO  [06:33:11.350] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:33:11.350] [bbotk]               4.70151                 6.742236                       0.2650055 
INFO  [06:33:11.350] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:33:11.350] [bbotk]                     4815        0.995 -0.9523627         <NA>   0.9754625 
INFO  [06:33:11.350] [bbotk]                                 uhash 
INFO  [06:33:11.350] [bbotk]  4cdd462e-b1cd-4659-aae1-7873968cc32a 
DEBUG [06:33:12.693] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.03424e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.03424e-05 0.001315606 
  - best initial criterion value(s) :  713.3135 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -713.31  |proj g|=       7.8455
At iterate     1  f =      -737.82  |proj g|=        9.6012
At iterate     2  f =      -745.69  |proj g|=        9.7662
At iterate     3  f =      -759.77  |proj g|=        9.4368
At iterate     4  f =      -762.02  |proj g|=        8.3803
At iterate     5  f =       -762.5  |proj g|=        8.8399
At iterate     6  f =      -762.78  |proj g|=        8.6557
At iterate     7  f =      -763.06  |proj g|=        8.3097
At iterate     8  f =      -763.18  |proj g|=        8.2387
At iterate     9  f =      -763.28  |proj g|=         8.157
At iterate    10  f =      -763.28  |proj g|=         8.157
At iterate    11  f =      -763.28  |proj g|=        8.1574

iterations 11
function evaluations 15
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 8.15739
final function value -763.283

F = -763.283
final  value -763.283344 
converged
 
INFO  [06:33:12.695] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:33:12.829] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:33:12.844] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:33:17.884] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:33:23.277] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:33:28.722] [mlr3]  Finished benchmark 
INFO  [06:33:28.841] [bbotk] Result of batch 147: 
INFO  [06:33:28.844] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:33:28.844] [bbotk]              6.190509                 8.603913                       0.2693623 
INFO  [06:33:28.844] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:33:28.844] [bbotk]                     3220        0.875 -0.9584899         <NA>   0.9750166 
INFO  [06:33:28.844] [bbotk]                                 uhash 
INFO  [06:33:28.844] [bbotk]  44424bf5-7a7c-4cae-ac07-b6d150f2e41b 
DEBUG [06:33:30.718] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.030666e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.030666e-05 0.001317592 
  - best initial criterion value(s) :  755.2612 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -755.26  |proj g|=       6.5946
At iterate     1  f =       -769.3  |proj g|=        8.8961
At iterate     2  f =      -771.39  |proj g|=        8.3358
At iterate     3  f =      -773.25  |proj g|=        6.9811
At iterate     4  f =       -774.5  |proj g|=        7.2377
At iterate     5  f =      -775.28  |proj g|=        7.4993
At iterate     6  f =      -775.35  |proj g|=        7.7901
At iterate     7  f =      -775.36  |proj g|=        7.4486
At iterate     8  f =       -775.4  |proj g|=        7.6152
At iterate     9  f =       -775.4  |proj g|=        7.6162
At iterate    10  f =       -775.4  |proj g|=        7.6139
At iterate    11  f =      -775.41  |proj g|=        7.5991
At iterate    12  f =      -775.41  |proj g|=        7.6018
At iterate    13  f =      -775.42  |proj g|=        7.4947
At iterate    14  f =      -775.43  |proj g|=        7.5268
At iterate    15  f =      -775.58  |proj g|=        7.6898
At iterate    16  f =      -775.86  |proj g|=        7.8471
At iterate    17  f =      -776.67  |proj g|=        8.0329
At iterate    18  f =      -778.61  |proj g|=        8.0675
At iterate    19  f =      -783.59  |proj g|=        7.5297
At iterate    20  f =      -801.36  |proj g|=         4.812
At iterate    21  f =      -809.53  |proj g|=        3.0262
At iterate    22  f =      -813.78  |proj g|=        2.5401
At iterate    23  f =      -816.21  |proj g|=        1.6031
At iterate    24  f =      -818.28  |proj g|=       0.79415
At iterate    25  f =      -818.71  |proj g|=       0.71956
At iterate    26  f =      -818.79  |proj g|=       0.26087
At iterate    27  f =      -818.79  |proj g|=       0.24715
At iterate    28  f =      -818.79  |proj g|=       0.24294
At iterate    29  f =      -818.79  |proj g|=       0.24341

iterations 29
function evaluations 37
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.243406
final function value -818.795

F = -818.795
final  value -818.794763 
converged
 
INFO  [06:33:30.723] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:33:31.367] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:33:31.375] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:33:32.189] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:33:32.968] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:33:33.754] [mlr3]  Finished benchmark 
INFO  [06:33:33.883] [bbotk] Result of batch 148: 
INFO  [06:33:33.885] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:33:33.885] [bbotk]              7.192242                 2.432852                       0.4004142 
INFO  [06:33:33.885] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:33:33.885] [bbotk]                      244        0.976 -0.9505129         <NA>    0.962005 
INFO  [06:33:33.885] [bbotk]                                 uhash 
INFO  [06:33:33.885] [bbotk]  3e339c9a-3c9a-41db-9e2c-d4be58cb0706 
DEBUG [06:33:35.465] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.027378e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.027378e-05 0.001307718 
  - best initial criterion value(s) :  717.4602 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -717.46  |proj g|=       12.895
At iterate     1  f =       -775.4  |proj g|=        4.3207
At iterate     2  f =      -779.63  |proj g|=        7.8598
At iterate     3  f =      -786.33  |proj g|=        6.5835
At iterate     4  f =      -790.22  |proj g|=        5.2246
At iterate     5  f =      -790.79  |proj g|=        4.4872
At iterate     6  f =      -790.79  |proj g|=        4.4941
At iterate     7  f =      -790.79  |proj g|=        4.5115
At iterate     8  f =      -790.79  |proj g|=        4.5354
At iterate     9  f =       -790.8  |proj g|=        4.5766
At iterate    10  f =      -790.82  |proj g|=        4.6412
At iterate    11  f =      -790.87  |proj g|=        4.7456
At iterate    12  f =         -791  |proj g|=        4.9076
At iterate    13  f =      -791.33  |proj g|=        5.1566
At iterate    14  f =      -792.16  |proj g|=        5.5134
At iterate    15  f =      -811.79  |proj g|=        4.6597
At iterate    16  f =      -822.25  |proj g|=        3.5872
At iterate    17  f =      -827.19  |proj g|=        2.0013
At iterate    18  f =      -833.74  |proj g|=       0.89259
At iterate    19  f =      -834.03  |proj g|=       0.62044
At iterate    20  f =      -834.05  |proj g|=       0.67744
At iterate    21  f =      -834.05  |proj g|=       0.68742
At iterate    22  f =      -834.05  |proj g|=       0.68673

iterations 22
function evaluations 28
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.686727
final function value -834.047

F = -834.047
final  value -834.046995 
converged
 
INFO  [06:33:35.469] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:33:35.554] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:33:35.561] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:33:39.040] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:33:41.500] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:33:43.842] [mlr3]  Finished benchmark 
INFO  [06:33:43.941] [bbotk] Result of batch 149: 
INFO  [06:33:43.942] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:33:43.942] [bbotk]              9.691818                  4.26269                        0.285473 
INFO  [06:33:43.942] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:33:43.942] [bbotk]                      967        0.957 -0.9355437         <NA>   0.9706036 
INFO  [06:33:43.942] [bbotk]                                 uhash 
INFO  [06:33:43.942] [bbotk]  f8196bff-a4a8-4627-86ca-ce472748beb0 
DEBUG [06:33:45.386] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.021848e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.021848e-05 0.001294506 
  - best initial criterion value(s) :  731.9677 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -731.97  |proj g|=       11.468
At iterate     1  f =      -809.75  |proj g|=        2.7295
At iterate     2  f =       -818.7  |proj g|=        3.6972
At iterate     3  f =       -819.5  |proj g|=        4.0173
At iterate     4  f =      -819.53  |proj g|=        4.0035
At iterate     5  f =      -819.62  |proj g|=        4.0278
At iterate     6  f =      -819.63  |proj g|=         4.058
At iterate     7  f =      -819.64  |proj g|=        4.0707
At iterate     8  f =      -819.64  |proj g|=        4.0721
At iterate     9  f =      -819.64  |proj g|=        4.0725
At iterate    10  f =      -819.64  |proj g|=        4.0734
At iterate    11  f =      -819.64  |proj g|=        4.0758
At iterate    12  f =      -819.64  |proj g|=        4.0792
At iterate    13  f =      -819.64  |proj g|=        4.0851
At iterate    14  f =      -819.64  |proj g|=        4.0936
At iterate    15  f =      -819.65  |proj g|=        4.1052
At iterate    16  f =      -819.67  |proj g|=        4.1167
At iterate    17  f =      -819.71  |proj g|=        4.1245
At iterate    18  f =      -819.79  |proj g|=        4.1326
At iterate    19  f =      -819.93  |proj g|=        4.0291
At iterate    20  f =      -820.15  |proj g|=        4.0595
At iterate    21  f =      -821.54  |proj g|=        3.9446
At iterate    22  f =       -823.2  |proj g|=        3.5891
At iterate    23  f =      -823.63  |proj g|=        3.4043
At iterate    24  f =      -823.74  |proj g|=        3.5259
At iterate    25  f =      -823.78  |proj g|=        3.5074
At iterate    26  f =      -823.78  |proj g|=        3.5018
At iterate    27  f =      -823.78  |proj g|=        3.5032
At iterate    28  f =      -823.78  |proj g|=        3.5031

iterations 28
function evaluations 31
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.50305
final function value -823.777

F = -823.777
final  value -823.777039 
converged
 
INFO  [06:33:45.390] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:33:45.491] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:33:45.498] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:33:52.215] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:33:58.541] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:34:04.779] [mlr3]  Finished benchmark 
INFO  [06:34:04.878] [bbotk] Result of batch 150: 
INFO  [06:34:04.880] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:34:04.880] [bbotk]              7.592142                 7.470371                       0.1852948 
INFO  [06:34:04.880] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:34:04.880] [bbotk]                     2220         0.89 -0.9491992         <NA>   0.9727659 
INFO  [06:34:04.880] [bbotk]                                 uhash 
INFO  [06:34:04.880] [bbotk]  1bd62d21-8585-4a91-88a2-17098f743f17 
DEBUG [06:34:06.594] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.017098e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.017098e-05 0.001286555 
  - best initial criterion value(s) :  751.5611 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -751.56  |proj g|=       12.702
At iterate     1  f =      -785.49  |proj g|=        10.312
At iterate     2  f =      -792.93  |proj g|=        7.9566
At iterate     3  f =      -804.07  |proj g|=        5.8496
At iterate     4  f =      -807.02  |proj g|=        5.2666
At iterate     5  f =      -807.17  |proj g|=        5.5052
At iterate     6  f =      -808.04  |proj g|=        5.4924
At iterate     7  f =      -808.07  |proj g|=        5.4405
At iterate     8  f =      -808.07  |proj g|=        5.4437
At iterate     9  f =      -808.07  |proj g|=        5.4431
At iterate    10  f =      -808.07  |proj g|=        5.4426
At iterate    11  f =      -808.07  |proj g|=        5.4411
At iterate    12  f =      -808.07  |proj g|=        5.4391
At iterate    13  f =      -808.07  |proj g|=        5.4356
At iterate    14  f =      -808.07  |proj g|=        5.4303
At iterate    15  f =      -808.08  |proj g|=         5.422
At iterate    16  f =      -808.08  |proj g|=        5.4097
At iterate    17  f =       -808.1  |proj g|=        5.3788
At iterate    18  f =      -808.14  |proj g|=        5.3576
At iterate    19  f =      -808.27  |proj g|=        5.2105
At iterate    20  f =      -808.56  |proj g|=        5.1934
At iterate    21  f =      -809.63  |proj g|=        5.1095
At iterate    22  f =      -811.49  |proj g|=        4.9341
At iterate    23  f =      -813.71  |proj g|=        4.6696
At iterate    24  f =      -813.94  |proj g|=        4.2348
At iterate    25  f =      -815.57  |proj g|=        4.6808
At iterate    26  f =      -815.69  |proj g|=        4.5977
At iterate    27  f =       -815.7  |proj g|=        4.6129
At iterate    28  f =      -815.75  |proj g|=        4.5413
At iterate    29  f =      -815.76  |proj g|=        4.5341
At iterate    30  f =      -815.76  |proj g|=        4.5413
At iterate    31  f =      -815.76  |proj g|=        4.5454
At iterate    32  f =      -815.76  |proj g|=        4.5452

iterations 32
function evaluations 36
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.54522
final function value -815.762

F = -815.762
final  value -815.762023 
converged
 
INFO  [06:34:06.598] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:34:06.709] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:34:06.716] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:34:13.822] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:34:22.703] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:34:31.863] [mlr3]  Finished benchmark 
INFO  [06:34:31.964] [bbotk] Result of batch 151: 
INFO  [06:34:31.966] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:34:31.966] [bbotk]              9.435951                 4.528798                       0.2831148 
INFO  [06:34:31.966] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:34:31.966] [bbotk]                     3338         0.89 -0.9482745         <NA>   0.9751183 
INFO  [06:34:31.966] [bbotk]                                 uhash 
INFO  [06:34:31.966] [bbotk]  5b93cf50-a80e-4806-b931-a46345809753 
DEBUG [06:34:33.269] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.013747e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.013747e-05 0.001284541 
  - best initial criterion value(s) :  738.8916 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -738.89  |proj g|=       8.3786
At iterate     1  f =      -745.75  |proj g|=        10.124
At iterate     2  f =      -746.91  |proj g|=        9.7077
At iterate     3  f =      -750.64  |proj g|=        7.5445
At iterate     4  f =      -753.81  |proj g|=        3.9354
At iterate     5  f =      -757.73  |proj g|=        3.5949
At iterate     6  f =       -759.3  |proj g|=        3.7409
At iterate     7  f =      -759.32  |proj g|=        3.7603
At iterate     8  f =      -759.32  |proj g|=         3.764
At iterate     9  f =      -759.32  |proj g|=        3.7641

iterations 9
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.7641
final function value -759.32

F = -759.32
final  value -759.320486 
converged
 
INFO  [06:34:33.273] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:34:33.360] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:34:33.367] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:34:45.424] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:34:56.470] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:35:07.666] [mlr3]  Finished benchmark 
INFO  [06:35:07.787] [bbotk] Result of batch 152: 
INFO  [06:35:07.789] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:35:07.789] [bbotk]               7.19351                 9.103273                       0.3501757 
INFO  [06:35:07.789] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:35:07.789] [bbotk]                     4614        0.922 -0.9638326         <NA>    0.976451 
INFO  [06:35:07.789] [bbotk]                                 uhash 
INFO  [06:35:07.789] [bbotk]  3195aaf0-1ccd-4d1b-8173-312c5a1c6d73 
DEBUG [06:35:09.299] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.011436e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.011436e-05 0.001283913 
  - best initial criterion value(s) :  758.3425 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -758.34  |proj g|=       6.6887
At iterate     1  f =      -759.04  |proj g|=        8.7625
At iterate     2  f =      -764.06  |proj g|=        8.1727
At iterate     3  f =      -772.02  |proj g|=        5.0725
At iterate     4  f =      -776.61  |proj g|=        4.2329
At iterate     5  f =      -778.33  |proj g|=        4.4794
At iterate     6  f =      -780.13  |proj g|=         4.514
At iterate     7  f =      -780.17  |proj g|=         4.474
At iterate     8  f =      -780.17  |proj g|=        4.4737
At iterate     9  f =      -780.17  |proj g|=        4.4734
At iterate    10  f =      -780.17  |proj g|=        4.4731
At iterate    11  f =      -780.17  |proj g|=        4.4723
At iterate    12  f =      -780.18  |proj g|=        4.4711
At iterate    13  f =      -780.18  |proj g|=        4.4695
At iterate    14  f =      -780.19  |proj g|=        4.4658
At iterate    15  f =       -780.2  |proj g|=        4.4649
At iterate    16  f =      -780.21  |proj g|=        4.4493
At iterate    17  f =      -780.25  |proj g|=        4.4452
At iterate    18  f =      -780.64  |proj g|=        4.4087
At iterate    19  f =      -783.88  |proj g|=        3.7284
At iterate    20  f =      -784.72  |proj g|=        3.5479
At iterate    21  f =      -784.82  |proj g|=        3.6383
At iterate    22  f =      -784.86  |proj g|=        3.6709
At iterate    23  f =      -784.86  |proj g|=        3.6611
At iterate    24  f =      -784.86  |proj g|=        3.6506
At iterate    25  f =      -784.86  |proj g|=        3.6511
At iterate    26  f =      -784.86  |proj g|=        3.6505
At iterate    27  f =      -784.86  |proj g|=        3.6502

iterations 27
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.65024
final function value -784.865

F = -784.865
final  value -784.864677 
converged
 
INFO  [06:35:09.303] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:35:09.419] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:35:09.426] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:35:10.483] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:35:11.549] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:35:12.675] [mlr3]  Finished benchmark 
INFO  [06:35:12.778] [bbotk] Result of batch 153: 
INFO  [06:35:12.780] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:35:12.780] [bbotk]              9.874783                 9.206334                      0.09111891 
INFO  [06:35:12.780] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:35:12.780] [bbotk]                      314        0.894 -0.9583325         <NA>     0.94596 
INFO  [06:35:12.780] [bbotk]                                 uhash 
INFO  [06:35:12.780] [bbotk]  a0143464-603c-49bc-807f-e2f95583b58a 
DEBUG [06:35:14.280] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.034187e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.034187e-05 0.001321504 
  - best initial criterion value(s) :  799.6985 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -799.7  |proj g|=        4.141
At iterate     1  f =       -842.5  |proj g|=        2.9074
At iterate     2  f =       -842.9  |proj g|=        3.5724
At iterate     3  f =      -844.97  |proj g|=        3.0253
At iterate     4  f =      -848.53  |proj g|=        1.2236
At iterate     5  f =      -848.81  |proj g|=        1.0628
At iterate     6  f =      -848.98  |proj g|=        1.0384
At iterate     7  f =      -848.98  |proj g|=        1.0412
At iterate     8  f =      -848.98  |proj g|=        1.0414
At iterate     9  f =      -848.98  |proj g|=        1.0412
At iterate    10  f =      -848.98  |proj g|=        1.0413

iterations 10
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.04125
final function value -848.985

F = -848.985
final  value -848.984711 
converged
 
INFO  [06:35:14.285] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:35:14.383] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:35:14.390] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:35:23.997] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:35:33.240] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:35:43.977] [mlr3]  Finished benchmark 
INFO  [06:35:44.114] [bbotk] Result of batch 154: 
INFO  [06:35:44.116] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:35:44.116] [bbotk]               8.43956                 3.744912                       0.1310406 
INFO  [06:35:44.116] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:35:44.116] [bbotk]                     3626        0.884 -0.9484745         <NA>   0.9735826 
INFO  [06:35:44.116] [bbotk]                                 uhash 
INFO  [06:35:44.116] [bbotk]  0a2e868a-e8e9-4c82-8423-e10954569788 
DEBUG [06:35:45.658] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.029884e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.029884e-05 0.001318438 
  - best initial criterion value(s) :  795.4206 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -795.42  |proj g|=       7.2444
At iterate     1  f =      -799.35  |proj g|=        3.3544
At iterate     2  f =      -799.45  |proj g|=        3.8993
At iterate     3  f =      -803.26  |proj g|=        3.9499
At iterate     4  f =      -803.89  |proj g|=        3.8301
At iterate     5  f =      -803.89  |proj g|=        3.8204
At iterate     6  f =      -803.89  |proj g|=        3.8216
At iterate     7  f =      -803.89  |proj g|=        3.8216
At iterate     8  f =      -803.89  |proj g|=        3.8214
At iterate     9  f =      -803.89  |proj g|=         3.821
At iterate    10  f =      -803.89  |proj g|=        3.8207
At iterate    11  f =      -803.89  |proj g|=        3.8197
At iterate    12  f =       -803.9  |proj g|=        3.8172
At iterate    13  f =      -803.91  |proj g|=        3.8178
At iterate    14  f =      -803.92  |proj g|=        3.8089
At iterate    15  f =      -803.93  |proj g|=        3.8237
At iterate    16  f =         -804  |proj g|=        3.8051
At iterate    17  f =      -804.69  |proj g|=        3.7432
At iterate    18  f =      -808.44  |proj g|=        3.4555
At iterate    19  f =      -811.19  |proj g|=        3.1866
At iterate    20  f =      -812.38  |proj g|=        2.8479
At iterate    21  f =      -812.55  |proj g|=        2.7376
At iterate    22  f =      -813.01  |proj g|=        2.4971
At iterate    23  f =      -813.14  |proj g|=        2.4107
At iterate    24  f =      -813.18  |proj g|=        2.7488
At iterate    25  f =      -813.21  |proj g|=        2.5741
At iterate    26  f =      -813.21  |proj g|=        2.5689
At iterate    27  f =      -813.21  |proj g|=        2.5641
At iterate    28  f =      -813.21  |proj g|=        2.5648
At iterate    29  f =      -813.21  |proj g|=        2.5649

iterations 29
function evaluations 36
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.56489
final function value -813.206

F = -813.206
final  value -813.205546 
converged
 
INFO  [06:35:45.663] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:35:45.750] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:35:45.757] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:35:53.915] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:36:01.155] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:36:07.451] [mlr3]  Finished benchmark 
INFO  [06:36:07.553] [bbotk] Result of batch 155: 
INFO  [06:36:07.555] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:36:07.555] [bbotk]              5.647395                 4.585264                       0.0101815 
INFO  [06:36:07.555] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:36:07.555] [bbotk]                     3091        0.916 -0.9550776         <NA>   0.9453245 
INFO  [06:36:07.555] [bbotk]                                 uhash 
INFO  [06:36:07.555] [bbotk]  0ef8e109-b6e2-42dc-9290-86dbb9d1ad28 
DEBUG [06:36:09.223] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.053626e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.053626e-05 0.001329923 
  - best initial criterion value(s) :  769.4702 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -769.47  |proj g|=        8.334
At iterate     1  f =      -812.51  |proj g|=        9.6856
At iterate     2  f =      -816.19  |proj g|=        9.7927
At iterate     3  f =      -819.58  |proj g|=        8.1197
At iterate     4  f =       -823.5  |proj g|=           6.9
At iterate     5  f =      -823.52  |proj g|=        6.6888
At iterate     6  f =      -823.53  |proj g|=        6.7538
At iterate     7  f =      -823.53  |proj g|=        6.7527
At iterate     8  f =      -823.53  |proj g|=        6.7511
At iterate     9  f =      -823.53  |proj g|=        6.7496
At iterate    10  f =      -823.53  |proj g|=        6.7421
At iterate    11  f =      -823.53  |proj g|=        6.7339
At iterate    12  f =      -823.53  |proj g|=        6.7177
At iterate    13  f =      -823.54  |proj g|=        6.6865
At iterate    14  f =      -823.57  |proj g|=        6.6461
At iterate    15  f =      -823.64  |proj g|=        6.5249
At iterate    16  f =      -823.65  |proj g|=        6.5812
At iterate    17  f =      -823.82  |proj g|=        6.4174
At iterate    18  f =      -826.03  |proj g|=        5.9202
At iterate    19  f =      -828.92  |proj g|=        6.8191
At iterate    20  f =      -832.11  |proj g|=        5.6269
At iterate    21  f =       -832.2  |proj g|=        5.4023
At iterate    22  f =       -832.2  |proj g|=        5.3364
At iterate    23  f =      -832.21  |proj g|=        5.3525
At iterate    24  f =      -832.21  |proj g|=        5.3516
At iterate    25  f =      -832.21  |proj g|=        5.3515

iterations 25
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 5.35151
final function value -832.206

F = -832.206
final  value -832.205500 
converged
 
INFO  [06:36:09.227] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:36:09.349] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:36:09.357] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:36:14.317] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:36:19.611] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:36:24.953] [mlr3]  Finished benchmark 
INFO  [06:36:25.056] [bbotk] Result of batch 156: 
INFO  [06:36:25.058] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:36:25.058] [bbotk]              5.384744                 9.416008                      0.05299793 
INFO  [06:36:25.058] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:36:25.058] [bbotk]                     2497        1.103 -0.9521996         <NA>     0.96359 
INFO  [06:36:25.058] [bbotk]                                 uhash 
INFO  [06:36:25.058] [bbotk]  ed409b6c-fb3f-4a86-b1f4-5d812936648b 
DEBUG [06:36:26.569] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.049276e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.049276e-05 0.001324767 
  - best initial criterion value(s) :  753.351 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -753.35  |proj g|=       13.772
At iterate     1  f =      -821.74  |proj g|=         11.62
At iterate     2  f =      -846.28  |proj g|=        10.935
At iterate     3  f =      -848.85  |proj g|=        9.1714
At iterate     4  f =       -850.5  |proj g|=        7.1491
At iterate     5  f =      -850.88  |proj g|=         6.669
At iterate     6  f =      -851.54  |proj g|=        6.3083
At iterate     7  f =      -852.18  |proj g|=        6.6154
At iterate     8  f =      -852.36  |proj g|=        6.5967
At iterate     9  f =       -852.4  |proj g|=        6.5041
At iterate    10  f =      -852.41  |proj g|=        6.5297
At iterate    11  f =      -852.41  |proj g|=        6.4572
At iterate    12  f =      -852.42  |proj g|=        6.2915
At iterate    13  f =      -852.45  |proj g|=        6.3216
At iterate    14  f =      -852.69  |proj g|=         6.459
At iterate    15  f =      -853.21  |proj g|=        6.4728
At iterate    16  f =      -854.45  |proj g|=        6.0657
At iterate    17  f =      -856.63  |proj g|=         4.987
At iterate    18  f =      -857.76  |proj g|=         2.116
At iterate    19  f =       -858.8  |proj g|=        2.6949
At iterate    20  f =      -860.71  |proj g|=        3.1991
At iterate    21  f =      -865.43  |proj g|=        3.1085
At iterate    22  f =      -867.24  |proj g|=        1.8055
At iterate    23  f =      -868.28  |proj g|=        1.0133
At iterate    24  f =      -869.18  |proj g|=       0.59192
At iterate    25  f =      -869.36  |proj g|=       0.69088
At iterate    26  f =      -869.37  |proj g|=       0.51489
At iterate    27  f =      -869.37  |proj g|=       0.51283
At iterate    28  f =      -869.37  |proj g|=       0.51245
At iterate    29  f =      -869.37  |proj g|=       0.51244

iterations 29
function evaluations 33
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.512438
final function value -869.37

F = -869.37
final  value -869.369615 
converged
 
INFO  [06:36:26.573] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:36:26.700] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:36:26.708] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:36:30.283] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:36:32.820] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:36:36.030] [mlr3]  Finished benchmark 
INFO  [06:36:36.128] [bbotk] Result of batch 157: 
INFO  [06:36:36.130] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:36:36.130] [bbotk]              9.936099                 6.789655                       0.1161921 
INFO  [06:36:36.130] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:36:36.130] [bbotk]                     1078         0.91 -0.9445473         <NA>   0.9648668 
INFO  [06:36:36.130] [bbotk]                                 uhash 
INFO  [06:36:36.130] [bbotk]  7b878c0e-bb50-4872-b300-71bf797524ab 
DEBUG [06:36:37.613] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.044375e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.044375e-05 0.001315749 
  - best initial criterion value(s) :  800.6344 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -800.63  |proj g|=       8.8144
At iterate     1  f =      -854.68  |proj g|=         3.368
At iterate     2  f =      -863.53  |proj g|=        4.3433
At iterate     3  f =      -864.47  |proj g|=        4.0078
At iterate     4  f =      -865.07  |proj g|=        3.7847
At iterate     5  f =      -865.56  |proj g|=        3.8161
At iterate     6  f =      -865.71  |proj g|=        3.8605
At iterate     7  f =      -865.72  |proj g|=        3.8669
At iterate     8  f =      -865.72  |proj g|=        3.8667
At iterate     9  f =      -865.72  |proj g|=        3.8666
At iterate    10  f =      -865.72  |proj g|=        3.8665
At iterate    11  f =      -865.72  |proj g|=        3.8662
At iterate    12  f =      -865.72  |proj g|=        3.8657
At iterate    13  f =      -865.72  |proj g|=         3.865
At iterate    14  f =      -865.72  |proj g|=        3.8638
At iterate    15  f =      -865.72  |proj g|=        3.8621
At iterate    16  f =      -865.73  |proj g|=        3.8603
At iterate    17  f =      -865.75  |proj g|=        3.8582
At iterate    18  f =      -865.75  |proj g|=        3.8597
At iterate    19  f =      -865.78  |proj g|=        3.8616
At iterate    20  f =      -866.81  |proj g|=        4.1581
At iterate    21  f =      -866.86  |proj g|=        4.1401
At iterate    22  f =      -866.87  |proj g|=        4.1491
At iterate    23  f =      -866.87  |proj g|=        4.1559
At iterate    24  f =      -866.87  |proj g|=        4.1586
At iterate    25  f =      -866.87  |proj g|=        4.1586

iterations 25
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.1586
final function value -866.869

F = -866.869
final  value -866.869445 
converged
 
INFO  [06:36:37.617] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:36:37.718] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:36:37.725] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:36:49.414] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:37:00.932] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:37:11.014] [mlr3]  Finished benchmark 
INFO  [06:37:11.129] [bbotk] Result of batch 158: 
INFO  [06:37:11.131] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:37:11.131] [bbotk]              6.332201                 7.902009                      0.09403952 
INFO  [06:37:11.131] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:37:11.131] [bbotk]                     4837         0.92 -0.9404516         <NA>   0.9730088 
INFO  [06:37:11.131] [bbotk]                                 uhash 
INFO  [06:37:11.131] [bbotk]  a8275ec4-c268-4d7a-8fb4-04268abb2f6b 
DEBUG [06:37:12.602] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.039895e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.039895e-05 0.001310514 
  - best initial criterion value(s) :  848.5543 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -848.55  |proj g|=       2.3762
At iterate     1  f =      -854.71  |proj g|=        2.2759
At iterate     2  f =      -860.11  |proj g|=        2.1445
At iterate     3  f =      -860.22  |proj g|=        2.1258
At iterate     4  f =      -860.25  |proj g|=        2.1103
At iterate     5  f =      -860.25  |proj g|=          2.11
At iterate     6  f =      -860.25  |proj g|=        2.1091
At iterate     7  f =      -860.25  |proj g|=         2.109

iterations 7
function evaluations 10
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.10901
final function value -860.253

F = -860.253
final  value -860.253115 
converged
 
INFO  [06:37:12.606] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:37:12.691] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:37:12.698] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:37:21.681] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:37:31.058] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:37:41.197] [mlr3]  Finished benchmark 
INFO  [06:37:41.295] [bbotk] Result of batch 159: 
INFO  [06:37:41.297] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:37:41.297] [bbotk]              4.448932                 8.664527                       0.1111573 
INFO  [06:37:41.297] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:37:41.297] [bbotk]                     4198        1.103 -0.9532184         <NA>   0.9714911 
INFO  [06:37:41.297] [bbotk]                                 uhash 
INFO  [06:37:41.297] [bbotk]  22d0b9cd-a272-4d07-9ea7-4b01c7580621 
DEBUG [06:37:42.809] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.034855e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.034855e-05 0.001305936 
  - best initial criterion value(s) :  768.711 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -768.71  |proj g|=       9.7433
At iterate     1  f =      -822.24  |proj g|=        11.024
At iterate     2  f =      -823.82  |proj g|=        10.866
At iterate     3  f =      -824.96  |proj g|=        10.699
At iterate     4  f =      -825.35  |proj g|=        10.431
At iterate     5  f =      -825.44  |proj g|=        9.7266
At iterate     6  f =      -825.45  |proj g|=        9.9609
At iterate     7  f =      -825.45  |proj g|=        9.9369
At iterate     8  f =      -825.45  |proj g|=        9.9352
At iterate     9  f =      -825.45  |proj g|=        9.9338
At iterate    10  f =      -825.45  |proj g|=        9.9281
At iterate    11  f =      -825.46  |proj g|=        9.9201
At iterate    12  f =      -825.46  |proj g|=        9.9073
At iterate    13  f =      -825.47  |proj g|=        9.8811
At iterate    14  f =       -825.5  |proj g|=         9.827
At iterate    15  f =      -825.57  |proj g|=        9.7712
At iterate    16  f =      -825.75  |proj g|=        9.4974
At iterate    17  f =      -825.79  |proj g|=        9.7628
At iterate    18  f =      -826.16  |proj g|=        9.5541
At iterate    19  f =      -831.25  |proj g|=        10.994
At iterate    20  f =      -832.49  |proj g|=        11.491
At iterate    21  f =      -832.53  |proj g|=        11.536
At iterate    22  f =      -832.54  |proj g|=        11.528
At iterate    23  f =      -832.54  |proj g|=        11.528
At iterate    24  f =      -832.54  |proj g|=        11.528

iterations 24
function evaluations 31
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 11.5282
final function value -832.54

F = -832.54
final  value -832.540393 
converged
 
INFO  [06:37:42.814] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:37:42.901] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:37:42.908] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:37:52.156] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:38:01.413] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:38:09.948] [mlr3]  Finished benchmark 
INFO  [06:38:10.073] [bbotk] Result of batch 160: 
INFO  [06:38:10.075] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:38:10.075] [bbotk]              8.321442                 3.077161                       0.1497246 
INFO  [06:38:10.075] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:38:10.075] [bbotk]                     4350        0.913 -0.9531448         <NA>   0.9745876 
INFO  [06:38:10.075] [bbotk]                                 uhash 
INFO  [06:38:10.075] [bbotk]  fd0d84ba-3472-4419-a9f6-49eeb5dcf40b 
DEBUG [06:38:11.648] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.031323e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.031323e-05 0.00130319 
  - best initial criterion value(s) :  827.7565 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -827.76  |proj g|=        6.237
At iterate     1  f =      -868.18  |proj g|=        10.818
At iterate     2  f =      -875.52  |proj g|=        10.531
At iterate     3  f =      -881.31  |proj g|=         5.686
At iterate     4  f =      -882.61  |proj g|=        7.4201
At iterate     5  f =      -884.54  |proj g|=        6.8299
At iterate     6  f =      -886.93  |proj g|=        5.0218
At iterate     7  f =      -887.21  |proj g|=        5.5248
At iterate     8  f =      -887.63  |proj g|=        4.6134
At iterate     9  f =      -887.67  |proj g|=         4.347
At iterate    10  f =      -887.68  |proj g|=        4.3221
At iterate    11  f =      -887.68  |proj g|=        4.3283
At iterate    12  f =      -887.68  |proj g|=        4.3358
At iterate    13  f =      -887.69  |proj g|=        4.3448
At iterate    14  f =      -887.69  |proj g|=        4.3491
At iterate    15  f =      -887.71  |proj g|=        4.3387
At iterate    16  f =      -887.75  |proj g|=        4.2854
At iterate    17  f =      -887.83  |proj g|=          4.09
At iterate    18  f =       -887.9  |proj g|=        4.1713
At iterate    19  f =      -888.08  |proj g|=        3.8491
At iterate    20  f =      -888.62  |proj g|=        3.1211
At iterate    21  f =      -889.65  |proj g|=        2.3417
At iterate    22  f =      -892.69  |proj g|=        0.9723
At iterate    23  f =      -896.74  |proj g|=       0.77083
At iterate    24  f =      -896.94  |proj g|=       0.42347
At iterate    25  f =      -897.43  |proj g|=       0.67191
At iterate    26  f =      -897.74  |proj g|=       0.37932
At iterate    27  f =      -897.78  |proj g|=       0.67357
At iterate    28  f =      -897.81  |proj g|=        0.2339
At iterate    29  f =      -897.81  |proj g|=       0.23392
At iterate    30  f =      -897.81  |proj g|=        0.2339

iterations 30
function evaluations 35
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.233902
final function value -897.814

F = -897.814
final  value -897.813874 
converged
 
INFO  [06:38:11.652] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:38:11.737] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:38:11.744] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:38:12.672] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:38:13.496] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:38:14.420] [mlr3]  Finished benchmark 
INFO  [06:38:14.538] [bbotk] Result of batch 161: 
INFO  [06:38:14.540] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:38:14.540] [bbotk]              9.304016                 3.629654                       0.2609484 
INFO  [06:38:14.540] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:38:14.540] [bbotk]                      206        0.939 -0.9416285         <NA>   0.9554783 
INFO  [06:38:14.540] [bbotk]                                 uhash 
INFO  [06:38:14.540] [bbotk]  f67414f3-6e3a-49c6-916f-265e08aa22bc 
DEBUG [06:38:16.058] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.034854e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.034854e-05 0.001307656 
  - best initial criterion value(s) :  803.4687 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -803.47  |proj g|=       3.6715
At iterate     1  f =      -846.19  |proj g|=        10.071
At iterate     2  f =      -849.35  |proj g|=        8.3023
At iterate     3  f =      -852.84  |proj g|=        9.2872
At iterate     4  f =      -859.33  |proj g|=        8.4857
At iterate     5  f =      -863.14  |proj g|=        6.3196
At iterate     6  f =      -863.26  |proj g|=        5.8603
At iterate     7  f =      -863.27  |proj g|=        5.8932
At iterate     8  f =      -863.27  |proj g|=        5.8769
At iterate     9  f =      -863.27  |proj g|=        5.8777

iterations 9
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 5.87766
final function value -863.267

F = -863.267
final  value -863.267395 
converged
 
INFO  [06:38:16.063] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:38:16.150] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:38:16.157] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:38:26.552] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:38:37.961] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:38:48.679] [mlr3]  Finished benchmark 
INFO  [06:38:48.780] [bbotk] Result of batch 162: 
INFO  [06:38:48.782] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:38:48.782] [bbotk]              2.827625                 8.318904                      0.04232385 
INFO  [06:38:48.782] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:38:48.782] [bbotk]                     4731        1.091 -0.9545069         <NA>   0.9548082 
INFO  [06:38:48.782] [bbotk]                                 uhash 
INFO  [06:38:48.782] [bbotk]  64dcc1c0-09bf-4412-962d-14a52f023d87 
DEBUG [06:38:50.354] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.039183e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.039183e-05 0.001309243 
  - best initial criterion value(s) :  843.3587 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -843.36  |proj g|=       8.5595
At iterate     1  f =       -857.8  |proj g|=        7.7846
At iterate     2  f =      -870.25  |proj g|=        5.9302
At iterate     3  f =       -883.3  |proj g|=        3.4337
At iterate     4  f =      -884.03  |proj g|=        3.4906
At iterate     5  f =      -885.33  |proj g|=        3.5695
At iterate     6  f =      -887.64  |proj g|=         3.827
At iterate     7  f =      -888.03  |proj g|=        3.9225
At iterate     8  f =      -888.14  |proj g|=        3.9776
At iterate     9  f =      -888.15  |proj g|=        3.9936
At iterate    10  f =      -888.15  |proj g|=        3.9927
At iterate    11  f =      -888.15  |proj g|=        3.9956
At iterate    12  f =      -888.15  |proj g|=        3.9937
At iterate    13  f =      -888.15  |proj g|=         3.991
At iterate    14  f =      -888.16  |proj g|=        3.9822
At iterate    15  f =      -888.16  |proj g|=        3.9691
At iterate    16  f =      -888.18  |proj g|=        3.9381
At iterate    17  f =      -888.21  |proj g|=        3.9252
At iterate    18  f =       -888.3  |proj g|=        3.9042
At iterate    19  f =      -888.54  |proj g|=        3.8648
At iterate    20  f =      -889.02  |proj g|=        3.8091
At iterate    21  f =      -889.59  |proj g|=        3.7558
At iterate    22  f =      -889.65  |proj g|=        3.6303
At iterate    23  f =       -889.8  |proj g|=        3.7107
At iterate    24  f =      -889.86  |proj g|=        3.7535
At iterate    25  f =      -889.88  |proj g|=        3.7717
At iterate    26  f =      -889.88  |proj g|=        3.7719
At iterate    27  f =      -889.88  |proj g|=        3.7692
At iterate    28  f =      -889.88  |proj g|=        3.7701
At iterate    29  f =      -889.88  |proj g|=          3.77

iterations 29
function evaluations 33
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.76995
final function value -889.88

F = -889.88
final  value -889.879982 
converged
 
INFO  [06:38:50.359] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:38:50.445] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:38:50.452] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:38:58.322] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:39:05.303] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:39:12.344] [mlr3]  Finished benchmark 
INFO  [06:39:12.445] [bbotk] Result of batch 163: 
INFO  [06:39:12.447] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:39:12.447] [bbotk]              7.581947                 3.275276                       0.4798709 
INFO  [06:39:12.447] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:39:12.447] [bbotk]                     3264        0.948 -0.9474064         <NA>   0.9764733 
INFO  [06:39:12.447] [bbotk]                                 uhash 
INFO  [06:39:12.447] [bbotk]  9fda062b-5411-432c-ab66-20bde4fc11ad 
DEBUG [06:39:14.084] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.037131e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.037131e-05 0.001309914 
  - best initial criterion value(s) :  820.7544 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -820.75  |proj g|=       2.9669
At iterate     1  f =      -866.08  |proj g|=        10.412
At iterate     2  f =      -866.88  |proj g|=        10.427
At iterate     3  f =      -870.17  |proj g|=        9.9771
At iterate     4  f =      -872.59  |proj g|=        7.7143
At iterate     5  f =      -874.15  |proj g|=        6.6805
At iterate     6  f =      -874.59  |proj g|=        7.0219
At iterate     7  f =      -874.73  |proj g|=        6.2484
At iterate     8  f =      -874.74  |proj g|=        6.3702
At iterate     9  f =      -874.74  |proj g|=         6.361
At iterate    10  f =      -874.74  |proj g|=        6.3398
At iterate    11  f =      -874.74  |proj g|=        6.3174
At iterate    12  f =      -874.74  |proj g|=        6.2738
At iterate    13  f =      -874.75  |proj g|=        6.2049
At iterate    14  f =      -874.77  |proj g|=        6.0928
At iterate    15  f =      -874.81  |proj g|=        5.9089
At iterate    16  f =      -874.92  |proj g|=        5.6235
At iterate    17  f =      -874.97  |proj g|=        5.3187
At iterate    18  f =      -875.28  |proj g|=        4.9599
At iterate    19  f =      -878.13  |proj g|=        4.5402
At iterate    20  f =      -888.51  |proj g|=        3.8431
At iterate    21  f =       -892.7  |proj g|=        4.0068
At iterate    22  f =      -904.37  |proj g|=        2.1408
At iterate    23  f =      -909.72  |proj g|=       0.93644
At iterate    24  f =       -911.6  |proj g|=         1.277
At iterate    25  f =      -911.72  |proj g|=         1.202
At iterate    26  f =      -911.76  |proj g|=        1.1424
At iterate    27  f =      -911.77  |proj g|=        1.0249
At iterate    28  f =      -911.78  |proj g|=        0.9923
At iterate    29  f =      -911.78  |proj g|=       0.98748
At iterate    30  f =      -911.78  |proj g|=       0.98705

iterations 30
function evaluations 37
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.987051
final function value -911.776

F = -911.776
final  value -911.776279 
converged
 
INFO  [06:39:14.088] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:39:14.206] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:39:14.213] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:39:19.922] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:39:24.368] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:39:31.832] [mlr3]  Finished benchmark 
INFO  [06:39:31.934] [bbotk] Result of batch 164: 
INFO  [06:39:31.936] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:39:31.936] [bbotk]              3.081202                 3.817841                       0.4041338 
INFO  [06:39:31.936] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:39:31.936] [bbotk]                     2101        0.946 -0.9384069         <NA>   0.9696123 
INFO  [06:39:31.936] [bbotk]                                 uhash 
INFO  [06:39:31.936] [bbotk]  f61f5d95-9b76-479d-a6cb-665e99efbf5d 
DEBUG [06:39:33.709] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.031851e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.031851e-05 0.001301271 
  - best initial criterion value(s) :  865.1112 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -865.11  |proj g|=       5.5866
At iterate     1  f =       -874.2  |proj g|=         5.658
At iterate     2  f =      -881.33  |proj g|=        4.2344
At iterate     3  f =      -886.14  |proj g|=        1.9139
At iterate     4  f =       -886.2  |proj g|=        1.2888
At iterate     5  f =      -886.24  |proj g|=        1.5458
At iterate     6  f =      -886.27  |proj g|=         1.567
At iterate     7  f =      -886.33  |proj g|=        1.6414
At iterate     8  f =      -886.33  |proj g|=        1.6554
At iterate     9  f =      -886.33  |proj g|=        1.6528
At iterate    10  f =      -886.33  |proj g|=        1.6526
At iterate    11  f =      -886.33  |proj g|=        1.6511
At iterate    12  f =      -886.33  |proj g|=        1.6491
At iterate    13  f =      -886.33  |proj g|=        1.6454
At iterate    14  f =      -886.33  |proj g|=        1.6391
At iterate    15  f =      -886.33  |proj g|=        1.6294
At iterate    16  f =      -886.33  |proj g|=        1.6174
At iterate    17  f =      -886.34  |proj g|=        1.6019
At iterate    18  f =      -886.35  |proj g|=        1.5717
At iterate    19  f =      -886.37  |proj g|=        1.5393
At iterate    20  f =      -886.37  |proj g|=        1.4579
At iterate    21  f =      -886.41  |proj g|=        1.3716
At iterate    22  f =      -886.52  |proj g|=         1.261
At iterate    23  f =       -886.6  |proj g|=         1.325
At iterate    24  f =      -886.61  |proj g|=        1.3436
At iterate    25  f =      -886.61  |proj g|=        1.3466
At iterate    26  f =      -886.61  |proj g|=        1.3461
At iterate    27  f =      -886.61  |proj g|=        1.3452
At iterate    28  f =      -886.61  |proj g|=        1.3452

iterations 28
function evaluations 36
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.34517
final function value -886.606

F = -886.606
final  value -886.605901 
converged
 
INFO  [06:39:33.713] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:39:33.835] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:39:33.843] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:39:41.094] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:39:48.913] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:39:57.072] [mlr3]  Finished benchmark 
INFO  [06:39:57.188] [bbotk] Result of batch 165: 
INFO  [06:39:57.190] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:39:57.190] [bbotk]              3.358839                 8.576227                       0.1118234 
INFO  [06:39:57.190] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:39:57.190] [bbotk]                     3244        0.925 -0.9543683         <NA>   0.9662904 
INFO  [06:39:57.190] [bbotk]                                 uhash 
INFO  [06:39:57.190] [bbotk]  f9ab51e8-a8fc-4b39-92a3-afe3d650a9fc 
DEBUG [06:39:58.824] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.026804e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.026804e-05 0.001296262 
  - best initial criterion value(s) :  843.8229 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -843.82  |proj g|=       2.5055
At iterate     1  f =      -895.53  |proj g|=        6.3906
At iterate     2  f =      -900.65  |proj g|=        9.6952
At iterate     3  f =      -900.89  |proj g|=        9.5248
At iterate     4  f =      -901.04  |proj g|=        9.1437
At iterate     5  f =      -901.15  |proj g|=        8.9962
At iterate     6  f =      -901.28  |proj g|=        8.9475
At iterate     7  f =      -901.29  |proj g|=        9.0869
At iterate     8  f =      -901.29  |proj g|=        9.0701
At iterate     9  f =      -901.29  |proj g|=        9.0694
At iterate    10  f =      -901.29  |proj g|=        9.0645
At iterate    11  f =      -901.29  |proj g|=        9.0589
At iterate    12  f =      -901.29  |proj g|=        9.0468
At iterate    13  f =       -901.3  |proj g|=        9.0383
At iterate    14  f =       -901.3  |proj g|=        8.9491
At iterate    15  f =      -901.32  |proj g|=        8.9556
At iterate    16  f =       -901.4  |proj g|=        8.9439
At iterate    17  f =      -902.84  |proj g|=        8.9628
At iterate    18  f =      -909.69  |proj g|=        7.3346
At iterate    19  f =      -916.36  |proj g|=        5.3961
At iterate    20  f =      -918.31  |proj g|=        5.0206
At iterate    21  f =      -919.18  |proj g|=        3.9843
At iterate    22  f =      -920.59  |proj g|=        3.3005
At iterate    23  f =      -920.61  |proj g|=        3.8816
At iterate    24  f =      -920.68  |proj g|=        3.6018
At iterate    25  f =      -920.68  |proj g|=        3.5833
At iterate    26  f =      -920.68  |proj g|=        3.5861
At iterate    27  f =      -920.68  |proj g|=        3.5861

iterations 27
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 3.58607
final function value -920.682

F = -920.682
final  value -920.681576 
converged
 
INFO  [06:39:58.828] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:39:58.916] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:39:58.924] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:40:04.451] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:40:09.490] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:40:14.874] [mlr3]  Finished benchmark 
INFO  [06:40:14.976] [bbotk] Result of batch 166: 
INFO  [06:40:14.978] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:40:14.978] [bbotk]              5.038588                 7.477893                       0.1623285 
INFO  [06:40:14.978] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:40:14.978] [bbotk]                     2310        0.955 -0.9392838         <NA>    0.971288 
INFO  [06:40:14.978] [bbotk]                                 uhash 
INFO  [06:40:14.978] [bbotk]  5677523f-c660-41c6-bc74-fadb6bd04838 
DEBUG [06:40:16.761] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.021969e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.021969e-05 0.001292637 
  - best initial criterion value(s) :  795.1451 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -795.15  |proj g|=       7.9926
At iterate     1  f =      -808.22  |proj g|=        5.3225
At iterate     2  f =      -821.76  |proj g|=        4.7582
At iterate     3  f =      -821.96  |proj g|=        5.1317
At iterate     4  f =      -822.02  |proj g|=        5.0138
At iterate     5  f =      -822.02  |proj g|=        5.0129
At iterate     6  f =      -822.02  |proj g|=        5.0237
At iterate     7  f =      -822.02  |proj g|=        5.0199
At iterate     8  f =      -822.02  |proj g|=        5.0184
At iterate     9  f =      -822.02  |proj g|=        5.0158
At iterate    10  f =      -822.02  |proj g|=        5.0094
At iterate    11  f =      -822.02  |proj g|=        5.0003
At iterate    12  f =      -822.03  |proj g|=        4.9844
At iterate    13  f =      -822.04  |proj g|=        4.9588
At iterate    14  f =      -822.06  |proj g|=        4.9186
At iterate    15  f =       -822.1  |proj g|=        4.8563
At iterate    16  f =      -822.22  |proj g|=         4.765
At iterate    17  f =      -822.23  |proj g|=        4.7186
At iterate    18  f =      -822.46  |proj g|=         4.597
At iterate    19  f =      -832.86  |proj g|=        3.7051
At iterate    20  f =       -833.7  |proj g|=        3.7406
At iterate    21  f =      -833.74  |proj g|=         3.705
At iterate    22  f =      -833.75  |proj g|=        3.6822
At iterate    23  f =      -833.75  |proj g|=        3.6938
At iterate    24  f =      -833.75  |proj g|=        3.6936
At iterate    25  f =      -833.75  |proj g|=        3.6936

iterations 25
function evaluations 35
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.69362
final function value -833.746

F = -833.746
final  value -833.746276 
converged
 
INFO  [06:40:16.765] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:40:16.889] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:40:16.897] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:40:25.399] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:40:33.371] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:40:41.200] [mlr3]  Finished benchmark 
INFO  [06:40:41.329] [bbotk] Result of batch 167: 
INFO  [06:40:41.331] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:40:41.331] [bbotk]               3.67509                 6.663956                       0.2389979 
INFO  [06:40:41.331] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:40:41.331] [bbotk]                     3309        1.103 -0.9622677         <NA>   0.9716724 
INFO  [06:40:41.331] [bbotk]                                 uhash 
INFO  [06:40:41.331] [bbotk]  db4982fe-ee07-4766-9bf4-a0c33507c82a 
DEBUG [06:40:42.652] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.017295e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.017295e-05 0.001289154 
  - best initial criterion value(s) :  804.9214 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -804.92  |proj g|=       15.018
At iterate     1  f =         -904  |proj g|=        3.1807
At iterate     2  f =       -915.1  |proj g|=        3.4536
At iterate     3  f =      -919.05  |proj g|=        3.6058
At iterate     4  f =      -919.51  |proj g|=        3.5732
At iterate     5  f =      -919.54  |proj g|=        3.5782
At iterate     6  f =      -919.55  |proj g|=        3.5828
At iterate     7  f =      -919.55  |proj g|=        3.5827
At iterate     8  f =      -919.55  |proj g|=        3.5827

iterations 8
function evaluations 10
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.58268
final function value -919.551

F = -919.551
final  value -919.550932 
converged
 
INFO  [06:40:42.656] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:40:42.743] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:40:42.749] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:40:50.362] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:40:59.088] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:41:07.327] [mlr3]  Finished benchmark 
INFO  [06:41:07.426] [bbotk] Result of batch 168: 
INFO  [06:41:07.428] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:41:07.428] [bbotk]              6.104239                 2.297199                       0.3700456 
INFO  [06:41:07.428] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:41:07.428] [bbotk]                     3546        0.933 -0.9442002         <NA>   0.9760105 
INFO  [06:41:07.428] [bbotk]                                 uhash 
INFO  [06:41:07.428] [bbotk]  ff952203-85ba-4604-bd82-77bd0b93e8be 
DEBUG [06:41:09.058] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.014991e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.014991e-05 0.001288088 
  - best initial criterion value(s) :  848.8442 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -848.84  |proj g|=       5.9272
At iterate     1  f =      -897.32  |proj g|=        11.247
At iterate     2  f =      -907.33  |proj g|=         10.97
At iterate     3  f =      -917.53  |proj g|=        10.596
At iterate     4  f =      -919.63  |proj g|=        8.3319
At iterate     5  f =      -920.47  |proj g|=        9.3336
At iterate     6  f =      -921.14  |proj g|=        9.3444
At iterate     7  f =      -923.99  |proj g|=        7.9682
At iterate     8  f =      -925.33  |proj g|=        6.2062
At iterate     9  f =      -925.61  |proj g|=        5.8259
At iterate    10  f =      -925.63  |proj g|=        5.6643
At iterate    11  f =      -925.63  |proj g|=         5.653
At iterate    12  f =      -925.63  |proj g|=        5.6136
At iterate    13  f =      -925.63  |proj g|=        5.6032
At iterate    14  f =      -925.64  |proj g|=        5.5118
At iterate    15  f =      -925.65  |proj g|=        5.4081
At iterate    16  f =      -925.69  |proj g|=        5.2107
At iterate    17  f =      -925.78  |proj g|=        4.9081
At iterate    18  f =      -926.01  |proj g|=        4.4118
At iterate    19  f =      -926.09  |proj g|=         4.076
At iterate    20  f =      -926.66  |proj g|=        3.5156
At iterate    21  f =      -931.67  |proj g|=        1.9883
At iterate    22  f =      -937.06  |proj g|=       0.95208
At iterate    23  f =      -937.22  |proj g|=        1.0216
At iterate    24  f =      -937.92  |proj g|=        1.0007
At iterate    25  f =         -938  |proj g|=        0.9901
At iterate    26  f =      -938.16  |proj g|=        1.0049
At iterate    27  f =      -938.16  |proj g|=        1.0015
At iterate    28  f =      -938.16  |proj g|=        1.0014
At iterate    29  f =      -938.16  |proj g|=        1.0014

iterations 29
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.0014
final function value -938.162

F = -938.162
final  value -938.161771 
converged
 
INFO  [06:41:09.062] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:41:09.165] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:41:09.171] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:41:15.703] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:41:22.987] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:41:28.930] [mlr3]  Finished benchmark 
INFO  [06:41:29.029] [bbotk] Result of batch 169: 
INFO  [06:41:29.031] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:41:29.031] [bbotk]              5.817495                 2.582679                      0.06895159 
INFO  [06:41:29.031] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:41:29.031] [bbotk]                     3220        0.938 -0.944387         <NA>   0.9688089 
INFO  [06:41:29.031] [bbotk]                                 uhash 
INFO  [06:41:29.031] [bbotk]  ed14a87e-dcc7-4c6e-8680-a0c3e30b1de5 
DEBUG [06:41:29.100] [bbotk]  
INFO  [06:41:29.112] [bbotk] Finished optimizing after 200 evaluation(s) 
INFO  [06:41:29.114] [bbotk] Result: 
INFO  [06:41:29.116] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:41:29.116] [bbotk]              7.693669                 3.940974                       0.4563975 
INFO  [06:41:29.116] [bbotk]  ps_cboost_anneal2.mstop learner_param_vals  x_domain classif.auc 
INFO  [06:41:29.116] [bbotk]                     4997         <list[19]> <list[4]>   0.9772556 
INFO  [06:41:42.005] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2.tuned' on task 'spam' (iter 3/5) 
INFO  [06:41:42.179] [bbotk] Starting to optimize 4 parameter(s) with '<OptimizerInterMBO>' and '<TerminatorEvals> [n_evals=200]' 
DEBUG [06:41:42.249] [bbotk]  
INFO  [06:41:42.256] [bbotk] Evaluating 32 configuration(s) 
INFO  [06:41:44.521] [mlr3]  Running benchmark with 96 resampling iterations 
INFO  [06:41:44.528] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:41:53.478] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:42:00.653] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:42:05.107] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:42:12.209] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:42:14.585] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:42:21.582] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:42:29.553] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:42:40.464] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:42:41.895] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:42:42.811] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:42:47.104] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:42:49.173] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:42:55.063] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:42:57.622] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:43:02.966] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:43:11.290] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:43:19.840] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:43:29.169] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:43:33.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:43:40.767] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:43:46.285] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:43:54.911] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:43:56.744] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:44:07.825] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:44:13.058] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:44:20.932] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:44:29.104] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:44:39.853] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:44:45.122] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:44:52.566] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:44:55.294] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:44:56.618] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:45:03.957] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:45:05.547] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:45:08.439] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:45:18.672] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:45:23.885] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:45:28.958] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:45:36.163] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:45:40.449] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:45:45.012] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:45:52.702] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:45:56.022] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:46:05.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:46:15.566] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:46:16.664] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:46:24.514] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:46:30.052] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:46:34.179] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:46:45.854] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:46:47.669] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:46:53.405] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:46:58.011] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:47:12.678] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:47:19.347] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:47:26.660] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:47:28.405] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:47:30.978] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:47:41.332] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:47:48.691] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:47:49.751] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:47:54.287] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:48:01.517] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:48:07.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:48:18.218] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:48:22.308] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:48:29.309] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:48:34.042] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:48:40.856] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:48:43.228] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:48:45.430] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:48:51.632] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:48:55.047] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:48:56.091] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:49:01.094] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:49:02.903] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:49:03.849] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:49:07.920] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:49:12.826] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:49:15.011] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:49:20.410] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:49:23.305] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:49:31.698] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:49:33.746] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:49:35.587] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:49:38.694] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:49:49.728] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:49:51.364] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:50:02.146] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:50:10.890] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:50:20.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:50:24.676] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:50:32.802] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:50:39.927] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:50:49.666] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:50:52.474] [mlr3]  Finished benchmark 
INFO  [06:50:55.132] [bbotk] Result of batch 1: 
INFO  [06:50:55.135] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:50:55.135] [bbotk]              4.483621                 6.228855                      0.32915443 
INFO  [06:50:55.135] [bbotk]              3.347598                 5.902845                      0.23709822 
INFO  [06:50:55.135] [bbotk]              8.122224                 4.991188                      0.32314543 
INFO  [06:50:55.135] [bbotk]              6.543059                 7.427409                      0.46189140 
INFO  [06:50:55.135] [bbotk]              4.218013                 3.147246                      0.19473305 
INFO  [06:50:55.135] [bbotk]              7.656007                 7.681180                      0.26139734 
INFO  [06:50:55.135] [bbotk]              6.466064                 9.491400                      0.04789571 
INFO  [06:50:55.135] [bbotk]              6.833469                 2.614054                      0.09847733 
INFO  [06:50:55.135] [bbotk]              5.561947                 8.134251                      0.23433904 
INFO  [06:50:55.135] [bbotk]              5.428526                 4.344572                      0.40809636 
INFO  [06:50:55.135] [bbotk]              7.038314                 6.425783                      0.13751427 
INFO  [06:50:55.135] [bbotk]              9.116432                 9.967272                      0.29437264 
INFO  [06:50:55.135] [bbotk]              8.962114                 6.570451                      0.38215707 
INFO  [06:50:55.135] [bbotk]              2.762310                 4.638323                      0.12500188 
INFO  [06:50:55.135] [bbotk]              7.324563                 5.044534                      0.48656221 
INFO  [06:50:55.135] [bbotk]              5.129280                 6.969157                      0.01550380 
INFO  [06:50:55.135] [bbotk]              4.771280                 8.647891                      0.07606957 
INFO  [06:50:55.135] [bbotk]              9.742887                 3.297401                      0.36014778 
INFO  [06:50:55.135] [bbotk]              2.391206                 3.507509                      0.30364605 
INFO  [06:50:55.135] [bbotk]              4.574246                 3.937842                      0.35418648 
INFO  [06:50:55.135] [bbotk]              5.866590                 7.205919                      0.16316611 
INFO  [06:50:55.135] [bbotk]              6.060278                 5.542583                      0.27074703 
INFO  [06:50:55.135] [bbotk]              3.838239                 8.486918                      0.43697961 
INFO  [06:50:55.135] [bbotk]              7.884412                 9.666569                      0.14705074 
INFO  [06:50:55.135] [bbotk]              8.546692                 2.138450                      0.45098768 
INFO  [06:50:55.135] [bbotk]              2.505661                 9.086295                      0.21567859 
INFO  [06:50:55.135] [bbotk]              9.332692                 4.212189                      0.09151371 
INFO  [06:50:55.135] [bbotk]              3.042121                 2.771034                      0.03811754 
INFO  [06:50:55.135] [bbotk]              8.280532                 7.899037                      0.39541943 
INFO  [06:50:55.135] [bbotk]              3.589431                 2.307042                      0.48335745 
INFO  [06:50:55.135] [bbotk]              2.158209                 8.807409                      0.17492000 
INFO  [06:50:55.135] [bbotk]              9.768937                 5.387309                      0.02775922 
INFO  [06:50:55.135] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:50:55.135] [bbotk]  ps_cboost_anneal2.mstop classif.auc                                uhash 
INFO  [06:50:55.135] [bbotk]                     1243   0.9732714 e2909b89-b53b-43aa-bd78-3e343b36cc26 
INFO  [06:50:55.135] [bbotk]                     3481   0.9736173 62fa7359-4251-4a0b-82a8-a36ae2c4e06e 
INFO  [06:50:55.135] [bbotk]                      356   0.9671314 f9e24edb-94ce-4e35-a158-961fc56e96ac 
INFO  [06:50:55.135] [bbotk]                     3301   0.9780324 e6cb76f0-22b4-4bfb-8e94-f879c72daee5 
INFO  [06:50:55.135] [bbotk]                      536   0.9614921 0c4dd38c-6ec7-46c3-8870-dd4e4367ef26 
INFO  [06:50:55.135] [bbotk]                     1553   0.9747914 67dcfde5-c09f-4ead-a6c4-da52cd1e144a 
INFO  [06:50:55.135] [bbotk]                     1414   0.9606827 2e517d6e-2554-4cca-bf35-c5d23fe887ad 
INFO  [06:50:55.135] [bbotk]                     2678   0.9729997 c8dd5325-5bce-4617-986d-c04cc81255d4 
INFO  [06:50:55.135] [bbotk]                     3603   0.9767252 8744ff15-2323-44cf-a36d-efae8cb52de7 
INFO  [06:50:55.135] [bbotk]                     4527   0.9782678 f8e7cffb-462e-4ae3-a0eb-a4dff1097457 
INFO  [06:50:55.135] [bbotk]                     1893   0.9730117 52db83e6-f8c5-4ec4-8683-211b53f029f9 
INFO  [06:50:55.135] [bbotk]                     3992   0.9775764 fda37bad-3284-4290-a9e4-f0461d2f57c2 
INFO  [06:50:55.135] [bbotk]                     3811   0.9778352 61c0bced-6d4a-4e7e-ad3c-61872727de97 
INFO  [06:50:55.135] [bbotk]                     2354   0.9617956 9a4eed0e-b0af-4b64-8e04-2de50acfe62f 
INFO  [06:50:55.135] [bbotk]                     2256   0.9772988 332a4f16-17dd-464a-affa-4f6ff7e8fbe2 
INFO  [06:50:55.135] [bbotk]                     2450   0.9488514 ede59893-cf10-4c9a-a6d4-22026cda19cb 
INFO  [06:50:55.135] [bbotk]                     4726   0.9730508 07b79020-770c-482e-a053-529863ee80fd 
INFO  [06:50:55.135] [bbotk]                     1784   0.9760154 6ec0326a-e361-40d5-a710-bf5c99073392 
INFO  [06:50:55.135] [bbotk]                     3794   0.9675983 09ceeb52-fe00-47b8-a84b-e5b10ab0248c 
INFO  [06:50:55.135] [bbotk]                      828   0.9717284 677b9704-7db1-4c6c-a839-3326e29e35da 
INFO  [06:50:55.135] [bbotk]                      295   0.9549546 c3536650-bec3-4be9-8bf3-b514b3a6eacf 
INFO  [06:50:55.135] [bbotk]                     3186   0.9769255 6c8dd44d-6d1c-466a-be17-27d9b21839cb 
INFO  [06:50:55.135] [bbotk]                     2014   0.9751813 7913d8f2-5926-44df-a98e-dcb6a2ad3b0b 
INFO  [06:50:55.135] [bbotk]                     2788   0.9747974 55a6ef7f-b1fb-412e-a44f-fb3954006f8f 
INFO  [06:50:55.135] [bbotk]                     4288   0.9779766 943357c2-f160-4078-8ff0-a4d3fdf6143a 
INFO  [06:50:55.135] [bbotk]                     4955   0.9685309 f74731a4-dd70-46c1-b762-ab29c1c7febd 
INFO  [06:50:55.135] [bbotk]                     1100   0.9659901 bacb88ae-198f-4a23-982c-b1a8b4221c44 
INFO  [06:50:55.135] [bbotk]                     4135   0.9578342 e5eaaeb7-2564-49cf-8e7b-1f662c8e35b5 
INFO  [06:50:55.135] [bbotk]                     1321   0.9756516 31e33ab9-a910-425c-85d4-4f6bc2ca0612 
INFO  [06:50:55.135] [bbotk]                     2937   0.9760461 41c0507c-e156-4edc-a4e3-a90af24b61d2 
INFO  [06:50:55.135] [bbotk]                      768   0.9417589 4a9e672a-dc5e-4b2b-8ef3-2dfba9cbf7a2 
INFO  [06:50:55.135] [bbotk]                     4608   0.9682528 bd3f3bfe-560d-46e9-8c35-0aa9ebc3f815 
INFO  [06:50:55.135] [bbotk]  ps_cboost_anneal2.mstop classif.auc                                uhash 
DEBUG [06:50:55.913] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.302614e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9421168 9320 
  - variance bounds :  8.302614e-06 0.000915582 
  - best initial criterion value(s) :  116.2131 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -116.21  |proj g|=      0.87427
At iterate     1  f =      -117.37  |proj g|=       0.58728
At iterate     2  f =      -117.48  |proj g|=       0.36672
At iterate     3  f =      -117.51  |proj g|=       0.35372
At iterate     4  f =       -117.6  |proj g|=       0.22484
At iterate     5  f =      -117.64  |proj g|=       0.37995
At iterate     6  f =      -117.65  |proj g|=       0.43972
At iterate     7  f =      -117.65  |proj g|=       0.16207
At iterate     8  f =      -117.65  |proj g|=       0.14706
At iterate     9  f =      -117.65  |proj g|=       0.14705

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.147054
final function value -117.65

F = -117.65
final  value -117.649796 
converged
 
INFO  [06:50:55.917] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:50:56.004] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:50:56.011] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:51:00.769] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:51:04.931] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:51:10.085] [mlr3]  Finished benchmark 
INFO  [06:51:10.413] [bbotk] Result of batch 2: 
INFO  [06:51:10.415] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:51:10.415] [bbotk]              9.239725                  2.87764                       0.1689626 
INFO  [06:51:10.415] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:51:10.415] [bbotk]                     1994        0.509 -0.9730279         <NA>   0.9743805 
INFO  [06:51:10.415] [bbotk]                                 uhash 
INFO  [06:51:10.415] [bbotk]  190ed9ad-5fad-4b55-879b-498cea97f86b 
DEBUG [06:51:11.060] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.10495e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9421168 9320 
  - variance bounds :  8.104949e-06 0.0008891238 
  - best initial criterion value(s) :  122.0375 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -122.04  |proj g|=      0.19576
At iterate     1  f =      -122.62  |proj g|=       0.77211
At iterate     2  f =      -122.63  |proj g|=        0.7713
At iterate     3  f =      -122.64  |proj g|=       0.77064
At iterate     4  f =      -122.67  |proj g|=       0.75905
At iterate     5  f =       -122.7  |proj g|=       0.40585
At iterate     6  f =       -122.7  |proj g|=       0.13522
At iterate     7  f =       -122.7  |proj g|=       0.13655
At iterate     8  f =       -122.7  |proj g|=       0.13665
At iterate     9  f =       -122.7  |proj g|=       0.13665

iterations 9
function evaluations 16
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.136651
final function value -122.7

F = -122.7
final  value -122.700028 
converged
 
INFO  [06:51:11.064] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:51:11.180] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:51:11.189] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:51:23.629] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:51:36.030] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:51:47.235] [mlr3]  Finished benchmark 
INFO  [06:51:47.334] [bbotk] Result of batch 3: 
INFO  [06:51:47.336] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:51:47.336] [bbotk]              2.795457                  9.84162                       0.2698544 
INFO  [06:51:47.336] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:51:47.336] [bbotk]                     4787        0.463 -0.9727907         <NA>   0.9723949 
INFO  [06:51:47.336] [bbotk]                                 uhash 
INFO  [06:51:47.336] [bbotk]  f39cd31d-9497-4b11-9754-986336ea025c 
DEBUG [06:51:48.001] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.876191e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9421168 9320 
  - variance bounds :  7.876191e-06 0.0008685007 
  - best initial criterion value(s) :  119.959 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -119.96  |proj g|=       2.1396
At iterate     1  f =      -123.84  |proj g|=       0.45879
At iterate     2  f =      -124.43  |proj g|=       0.43934
At iterate     3  f =      -125.31  |proj g|=       0.51107
At iterate     4  f =      -125.47  |proj g|=       0.58267
At iterate     5  f =      -125.77  |proj g|=       0.46376
At iterate     6  f =       -126.2  |proj g|=       0.76003
At iterate     7  f =      -126.45  |proj g|=       0.29853
At iterate     8  f =      -126.47  |proj g|=       0.17568
At iterate     9  f =      -126.47  |proj g|=       0.57325
At iterate    10  f =      -126.47  |proj g|=       0.42053
At iterate    11  f =      -126.47  |proj g|=       0.42103

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.42103
final function value -126.473

F = -126.473
final  value -126.473363 
converged
 
INFO  [06:51:48.005] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:51:48.095] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:51:48.102] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:51:57.444] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:52:08.259] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:52:18.329] [mlr3]  Finished benchmark 
INFO  [06:52:18.430] [bbotk] Result of batch 4: 
INFO  [06:52:18.432] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:52:18.432] [bbotk]              8.190903                 4.549301                       0.2785673 
INFO  [06:52:18.432] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:52:18.432] [bbotk]                     4291         0.46 -0.972803         <NA>    0.977231 
INFO  [06:52:18.432] [bbotk]                                 uhash 
INFO  [06:52:18.432] [bbotk]  9d3e80a6-8ac7-49e8-94f3-f9a74763fd18 
DEBUG [06:52:19.084] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.79097e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9421168 9320 
  - variance bounds :  7.79097e-06 0.0008766799 
  - best initial criterion value(s) :  129.1638 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -129.16  |proj g|=      0.84494
At iterate     1  f =      -129.36  |proj g|=       0.77535
At iterate     2  f =      -129.66  |proj g|=       0.75313
At iterate     3  f =      -131.17  |proj g|=       0.46103
At iterate     4  f =      -131.18  |proj g|=       0.47386
At iterate     5  f =      -131.19  |proj g|=       0.48254
At iterate     6  f =      -131.19  |proj g|=       0.48097
At iterate     7  f =       -131.2  |proj g|=       0.27514
At iterate     8  f =       -131.2  |proj g|=       0.27483
At iterate     9  f =       -131.2  |proj g|=       0.27511
At iterate    10  f =       -131.2  |proj g|=       0.27499
At iterate    11  f =       -131.2  |proj g|=       0.27498

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.274985
final function value -131.195

F = -131.195
final  value -131.195498 
converged
 
INFO  [06:52:19.088] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:52:19.201] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:52:19.213] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:52:22.338] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:52:25.557] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:52:28.468] [mlr3]  Finished benchmark 
INFO  [06:52:28.586] [bbotk] Result of batch 5: 
INFO  [06:52:28.588] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:52:28.588] [bbotk]              9.547685                 3.910578                        0.412641 
INFO  [06:52:28.588] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:52:28.588] [bbotk]                     1298        0.472 -0.9721421         <NA>   0.9757746 
INFO  [06:52:28.588] [bbotk]                                 uhash 
INFO  [06:52:28.588] [bbotk]  75a4bc2c-a54c-465e-94a9-08925403052f 
DEBUG [06:52:29.244] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.652338e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9421168 9320 
  - variance bounds :  7.652338e-06 0.0008358231 
  - best initial criterion value(s) :  133.8972 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -133.9  |proj g|=        2.144
At iterate     1  f =      -134.79  |proj g|=        1.0286
At iterate     2  f =      -135.65  |proj g|=       0.96091
At iterate     3  f =      -136.22  |proj g|=       0.71086
At iterate     4  f =      -136.34  |proj g|=       0.68856
At iterate     5  f =      -136.38  |proj g|=       0.73588
At iterate     6  f =      -136.38  |proj g|=       0.78694
At iterate     7  f =      -136.38  |proj g|=        0.8157
At iterate     8  f =      -136.38  |proj g|=       0.81465
At iterate     9  f =      -136.38  |proj g|=        0.8148
At iterate    10  f =      -136.38  |proj g|=       0.81494
At iterate    11  f =      -136.38  |proj g|=       0.81519
At iterate    12  f =      -136.38  |proj g|=       0.81557
At iterate    13  f =      -136.38  |proj g|=       0.81647
At iterate    14  f =      -136.38  |proj g|=       0.81529
At iterate    15  f =      -136.38  |proj g|=       0.81688
At iterate    16  f =      -136.38  |proj g|=        0.8192
At iterate    17  f =      -136.39  |proj g|=        0.8295
At iterate    18  f =      -136.41  |proj g|=       0.83278
At iterate    19  f =      -136.47  |proj g|=       0.78931
At iterate    20  f =      -136.47  |proj g|=       0.77663
At iterate    21  f =      -136.58  |proj g|=       0.64649
At iterate    22  f =      -136.88  |proj g|=       0.47404
At iterate    23  f =      -137.03  |proj g|=       0.24365
At iterate    24  f =      -137.07  |proj g|=        0.2118
At iterate    25  f =      -137.08  |proj g|=       0.21518
At iterate    26  f =      -137.08  |proj g|=       0.21319
At iterate    27  f =      -137.08  |proj g|=       0.21443
At iterate    28  f =      -137.08  |proj g|=       0.21457
At iterate    29  f =      -137.08  |proj g|=       0.21434
At iterate    30  f =      -137.08  |proj g|=       0.21431

iterations 30
function evaluations 37
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.21431
final function value -137.083

F = -137.083
final  value -137.082660 
converged
 
INFO  [06:52:29.248] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:52:29.338] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:52:29.345] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:52:34.013] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:52:38.601] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:52:44.295] [mlr3]  Finished benchmark 
INFO  [06:52:44.434] [bbotk] Result of batch 6: 
INFO  [06:52:44.436] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:52:44.436] [bbotk]              5.499556                 9.266761                       0.3733318 
INFO  [06:52:44.436] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:52:44.436] [bbotk]                     2021        0.476 -0.9714052         <NA>   0.9764144 
INFO  [06:52:44.436] [bbotk]                                 uhash 
INFO  [06:52:44.436] [bbotk]  3eb407e4-0b51-4a48-b5f2-bcd5286e93e4 
DEBUG [06:52:45.223] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.536589e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9421168 9320 
  - variance bounds :  7.536589e-06 0.0008142811 
  - best initial criterion value(s) :  140.004 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -140  |proj g|=       1.0249
At iterate     1  f =      -140.19  |proj g|=       0.72868
At iterate     2  f =       -140.3  |proj g|=       0.83895
At iterate     3  f =      -140.32  |proj g|=       0.88126
At iterate     4  f =      -140.32  |proj g|=       0.89592
At iterate     5  f =      -140.32  |proj g|=       0.89847
At iterate     6  f =      -140.32  |proj g|=        0.8987

iterations 6
function evaluations 9
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.898696
final function value -140.32

F = -140.32
final  value -140.319674 
converged
 
INFO  [06:52:45.225] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:52:45.308] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:52:45.315] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:52:46.630] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:52:47.826] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:52:48.651] [mlr3]  Finished benchmark 
INFO  [06:52:48.757] [bbotk] Result of batch 7: 
INFO  [06:52:48.760] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:52:48.760] [bbotk]              9.738131                 7.044283                     0.001518807 
INFO  [06:52:48.760] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:52:48.760] [bbotk]                      206        0.569 -0.9733414         <NA>   0.8146903 
INFO  [06:52:48.760] [bbotk]                                 uhash 
INFO  [06:52:48.760] [bbotk]  c321fe4a-8790-4a8a-8cce-a2d7a9657406 
DEBUG [06:52:49.473] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.12935e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  7.12935e-05 0.009999148 
  - best initial criterion value(s) :  92.39781 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -92.398  |proj g|=      0.75171
At iterate     1  f =      -94.696  |proj g|=       0.39343
At iterate     2  f =      -94.714  |proj g|=       0.39433
At iterate     3  f =      -94.738  |proj g|=       0.39404
At iterate     4  f =      -94.754  |proj g|=       0.39144
At iterate     5  f =      -94.886  |proj g|=       0.35957
At iterate     6  f =       -95.06  |proj g|=       0.34476
At iterate     7  f =      -95.301  |proj g|=       0.38509
At iterate     8  f =      -95.369  |proj g|=       0.34156
At iterate     9  f =      -95.371  |proj g|=       0.34792
At iterate    10  f =      -95.371  |proj g|=       0.34557
At iterate    11  f =      -95.371  |proj g|=       0.34557
At iterate    12  f =      -95.371  |proj g|=       0.34552
At iterate    13  f =      -95.371  |proj g|=        0.3453
At iterate    14  f =      -95.371  |proj g|=       0.34497
At iterate    15  f =      -95.371  |proj g|=       0.34424
At iterate    16  f =      -95.372  |proj g|=       0.34272
At iterate    17  f =      -95.373  |proj g|=       0.33985
At iterate    18  f =      -95.375  |proj g|=       0.33672
At iterate    19  f =      -95.382  |proj g|=       0.33592
At iterate    20  f =      -95.402  |proj g|=       0.33515
At iterate    21  f =      -95.456  |proj g|=       0.33483
At iterate    22  f =       -95.62  |proj g|=       0.33236
At iterate    23  f =      -95.858  |proj g|=       0.31922
At iterate    24  f =      -96.036  |proj g|=       0.29917
At iterate    25  f =      -96.078  |proj g|=       0.83825
At iterate    26  f =      -96.165  |proj g|=       0.84801
At iterate    27  f =      -96.194  |proj g|=       0.84246
At iterate    28  f =       -96.45  |proj g|=       0.84237
At iterate    29  f =      -97.267  |proj g|=       0.32239
At iterate    30  f =       -97.37  |proj g|=       0.33567
At iterate    31  f =      -97.383  |proj g|=       0.34122
At iterate    32  f =      -97.384  |proj g|=       0.34301
At iterate    33  f =      -97.384  |proj g|=       0.34322
At iterate    34  f =      -97.384  |proj g|=       0.34324

iterations 34
function evaluations 44
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.343239
final function value -97.3842

F = -97.3842
final  value -97.384186 
converged
 
INFO  [06:52:49.478] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:52:49.587] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:52:49.594] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:52:53.273] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:52:56.406] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:52:59.179] [mlr3]  Finished benchmark 
INFO  [06:52:59.329] [bbotk] Result of batch 8: 
INFO  [06:52:59.330] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:52:59.330] [bbotk]              6.213062                 7.886272                      0.05004802 
INFO  [06:52:59.330] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:52:59.330] [bbotk]                     1533        0.491 -0.9790924         <NA>   0.9617703 
INFO  [06:52:59.330] [bbotk]                                 uhash 
INFO  [06:52:59.330] [bbotk]  178289ef-bf0b-4cb0-b1b7-ae3c5e4e6714 
DEBUG [06:53:00.038] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 6.947444e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  6.947444e-05 0.009543195 
  - best initial criterion value(s) :  93.29692 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -93.297  |proj g|=      0.93697
At iterate     1  f =      -96.985  |proj g|=       0.88209
At iterate     2  f =      -98.001  |proj g|=       0.81754
At iterate     3  f =      -98.032  |proj g|=       0.82675
At iterate     4  f =      -98.042  |proj g|=       0.83407
At iterate     5  f =      -98.042  |proj g|=         0.836
At iterate     6  f =      -98.042  |proj g|=       0.83646
At iterate     7  f =      -98.042  |proj g|=        0.8363
At iterate     8  f =      -98.042  |proj g|=       0.83637
At iterate     9  f =      -98.043  |proj g|=       0.83657
At iterate    10  f =      -98.043  |proj g|=       0.83689
At iterate    11  f =      -98.044  |proj g|=       0.83757
At iterate    12  f =      -98.046  |proj g|=       0.83826
At iterate    13  f =      -98.052  |proj g|=       0.83971
At iterate    14  f =      -98.061  |proj g|=         0.832
At iterate    15  f =      -98.084  |proj g|=       0.83453
At iterate    16  f =      -98.137  |proj g|=       0.83033
At iterate    17  f =      -98.376  |proj g|=       0.79423
At iterate    18  f =      -98.857  |proj g|=       0.79862
At iterate    19  f =      -99.813  |proj g|=       0.77029
At iterate    20  f =      -99.928  |proj g|=       0.49432
At iterate    21  f =      -100.43  |proj g|=       0.24528
At iterate    22  f =      -101.82  |proj g|=       0.15999
At iterate    23  f =       -101.9  |proj g|=       0.15631
At iterate    24  f =      -101.92  |proj g|=       0.17597
At iterate    25  f =      -101.92  |proj g|=       0.17519
At iterate    26  f =      -101.92  |proj g|=       0.17521
At iterate    27  f =      -101.92  |proj g|=       0.17517
At iterate    28  f =      -101.92  |proj g|=       0.17509
At iterate    29  f =      -101.92  |proj g|=       0.17494
At iterate    30  f =      -101.92  |proj g|=       0.17471
At iterate    31  f =      -101.92  |proj g|=       0.17433
At iterate    32  f =      -101.92  |proj g|=       0.17375
At iterate    33  f =      -101.92  |proj g|=         0.173
At iterate    34  f =      -101.92  |proj g|=       0.17237
At iterate    35  f =      -101.93  |proj g|=       0.17257
At iterate    36  f =      -101.93  |proj g|=       0.17149
At iterate    37  f =      -101.93  |proj g|=       0.17151
At iterate    38  f =      -102.09  |proj g|=       0.14235
At iterate    39  f =       -102.1  |proj g|=       0.35539
At iterate    40  f =       -102.1  |proj g|=       0.02078
At iterate    41  f =       -102.1  |proj g|=     0.0018155
At iterate    42  f =       -102.1  |proj g|=    0.00088529

iterations 42
function evaluations 56
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000885292
final function value -102.098

F = -102.098
final  value -102.098063 
converged
 
INFO  [06:53:00.042] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:53:00.134] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:53:00.141] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:53:01.863] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:53:03.485] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:53:04.755] [mlr3]  Finished benchmark 
INFO  [06:53:04.852] [bbotk] Result of batch 9: 
INFO  [06:53:04.854] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:53:04.854] [bbotk]              7.252082                 3.082532                       0.2654941 
INFO  [06:53:04.854] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:53:04.854] [bbotk]                      521        0.486 -0.9771912         <NA>   0.9685327 
INFO  [06:53:04.854] [bbotk]                                 uhash 
INFO  [06:53:04.854] [bbotk]  7b074d18-e530-4179-9437-e9ef33a42fcb 
DEBUG [06:53:05.524] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 6.770476e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  6.770476e-05 0.009057242 
  - best initial criterion value(s) :  102.8197 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -102.82  |proj g|=       0.3641
At iterate     1  f =      -104.31  |proj g|=       0.40225
At iterate     2  f =      -104.33  |proj g|=       0.40039
At iterate     3  f =      -104.35  |proj g|=       0.39768
At iterate     4  f =      -104.37  |proj g|=       0.39349
At iterate     5  f =      -104.45  |proj g|=       0.38463
At iterate     6  f =       -104.6  |proj g|=       0.35332
At iterate     7  f =      -104.66  |proj g|=       0.34756
At iterate     8  f =      -104.66  |proj g|=       0.35139
At iterate     9  f =      -104.66  |proj g|=       0.35046
At iterate    10  f =      -104.66  |proj g|=       0.35059
At iterate    11  f =      -104.66  |proj g|=       0.35059

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.35059
final function value -104.663

F = -104.663
final  value -104.662862 
converged
 
INFO  [06:53:05.528] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:53:05.630] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:53:05.636] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:53:15.687] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:53:29.219] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:53:39.004] [mlr3]  Finished benchmark 
INFO  [06:53:39.119] [bbotk] Result of batch 10: 
INFO  [06:53:39.121] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:53:39.121] [bbotk]               7.57592                 4.676382                       0.4312018 
INFO  [06:53:39.121] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [06:53:39.121] [bbotk]                     4202        0.488 -0.976546         <NA>   0.9779651 
INFO  [06:53:39.121] [bbotk]                                 uhash 
INFO  [06:53:39.121] [bbotk]  51e574d1-d2b6-4196-bbf5-c5e3137c2858 
DEBUG [06:53:39.803] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 6.633715e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  6.633715e-05 0.008986876 
  - best initial criterion value(s) :  107.8502 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -107.85  |proj g|=      0.87173
At iterate     1  f =      -109.18  |proj g|=       0.78941
At iterate     2  f =      -109.31  |proj g|=       0.79405
At iterate     3  f =      -109.49  |proj g|=       0.41624
At iterate     4  f =      -109.49  |proj g|=       0.40724
At iterate     5  f =       -109.5  |proj g|=       0.40911
At iterate     6  f =       -109.5  |proj g|=       0.40875
At iterate     7  f =       -109.5  |proj g|=       0.40848
At iterate     8  f =       -109.5  |proj g|=       0.40845

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.408453
final function value -109.496

F = -109.496
final  value -109.495826 
converged
 
INFO  [06:53:39.805] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:53:39.880] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:53:39.887] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:53:48.823] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:53:57.892] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:54:08.434] [mlr3]  Finished benchmark 
INFO  [06:54:08.532] [bbotk] Result of batch 11: 
INFO  [06:54:08.533] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:54:08.533] [bbotk]              7.484523                 2.792094                       0.1466859 
INFO  [06:54:08.533] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:54:08.533] [bbotk]                     4122        0.487 -0.9768862         <NA>   0.9760609 
INFO  [06:54:08.533] [bbotk]                                 uhash 
INFO  [06:54:08.533] [bbotk]  29dfffed-99bd-40f9-a6db-b97206199472 
DEBUG [06:54:09.452] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 6.492767e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  6.492767e-05 0.008911533 
  - best initial criterion value(s) :  99.40475 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -99.405  |proj g|=      0.29309
At iterate     1  f =      -99.903  |proj g|=       0.83622
At iterate     2  f =      -99.973  |proj g|=       0.81085
At iterate     3  f =         -100  |proj g|=        0.7979
At iterate     4  f =      -100.01  |proj g|=       0.78903
At iterate     5  f =      -100.02  |proj g|=       0.77202
At iterate     6  f =      -100.08  |proj g|=       0.68714
At iterate     7  f =      -100.31  |proj g|=       0.71106
At iterate     8  f =      -100.34  |proj g|=       0.97904
At iterate     9  f =      -100.61  |proj g|=          1.22
At iterate    10  f =      -100.82  |proj g|=         1.228
At iterate    11  f =      -100.83  |proj g|=        1.3748
At iterate    12  f =      -100.84  |proj g|=        1.3281
At iterate    13  f =      -100.84  |proj g|=        1.3325
At iterate    14  f =      -100.84  |proj g|=        1.3338
At iterate    15  f =      -100.84  |proj g|=         1.335
At iterate    16  f =      -100.84  |proj g|=        1.3375
At iterate    17  f =      -100.84  |proj g|=        1.3417
At iterate    18  f =      -100.84  |proj g|=        1.3486
At iterate    19  f =      -100.84  |proj g|=        1.3575
At iterate    20  f =      -100.84  |proj g|=         1.369
At iterate    21  f =      -100.85  |proj g|=        1.3943
At iterate    22  f =      -100.86  |proj g|=        1.4192
At iterate    23  f =      -100.88  |proj g|=        1.4337
At iterate    24  f =      -100.93  |proj g|=        1.4199
At iterate    25  f =      -101.68  |proj g|=       0.87574
At iterate    26  f =      -102.33  |proj g|=       0.73072
At iterate    27  f =      -102.65  |proj g|=       0.58389
At iterate    28  f =       -102.7  |proj g|=        0.2449
At iterate    29  f =       -102.7  |proj g|=       0.24321
At iterate    30  f =      -102.75  |proj g|=       0.22445
At iterate    31  f =      -102.94  |proj g|=       0.81094
At iterate    32  f =      -102.97  |proj g|=       0.82226
At iterate    33  f =      -103.39  |proj g|=       0.83152
At iterate    34  f =      -103.93  |proj g|=       0.20205
At iterate    35  f =      -103.94  |proj g|=        0.8318
At iterate    36  f =      -103.94  |proj g|=       0.20154
At iterate    37  f =      -103.94  |proj g|=       0.20152
At iterate    38  f =      -103.94  |proj g|=       0.20152

iterations 38
function evaluations 51
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.201524
final function value -103.941

F = -103.941
final  value -103.941114 
converged
 
INFO  [06:54:09.456] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:54:09.541] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:54:09.548] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:54:17.744] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:54:25.905] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:54:34.021] [mlr3]  Finished benchmark 
INFO  [06:54:34.137] [bbotk] Result of batch 12: 
INFO  [06:54:34.139] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:54:34.139] [bbotk]              2.718964                 6.026358                       0.1797256 
INFO  [06:54:34.139] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:54:34.139] [bbotk]                     3595        0.698 -0.9860124         <NA>   0.9678031 
INFO  [06:54:34.139] [bbotk]                                 uhash 
INFO  [06:54:34.139] [bbotk]  5d8095a8-e8d4-4a73-90dd-178b6629671e 
DEBUG [06:54:34.872] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 6.338356e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  6.338356e-05 0.00877348 
  - best initial criterion value(s) :  111.2118 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -111.21  |proj g|=      0.89246
At iterate     1  f =      -111.75  |proj g|=       0.36408
At iterate     2  f =      -111.86  |proj g|=       0.52299
At iterate     3  f =      -111.95  |proj g|=       0.45439
At iterate     4  f =       -112.1  |proj g|=       0.33143
At iterate     5  f =      -112.27  |proj g|=       0.27714
At iterate     6  f =       -112.4  |proj g|=       0.33508
At iterate     7  f =      -112.81  |proj g|=       0.41284
At iterate     8  f =      -112.84  |proj g|=       0.42462
At iterate     9  f =      -112.87  |proj g|=       0.82157
At iterate    10  f =      -112.88  |proj g|=       0.43552
At iterate    11  f =      -112.88  |proj g|=       0.43661
At iterate    12  f =      -112.88  |proj g|=       0.43705
At iterate    13  f =      -112.88  |proj g|=        0.4369
At iterate    14  f =      -112.88  |proj g|=        0.4368
At iterate    15  f =      -112.88  |proj g|=       0.43671
At iterate    16  f =      -112.88  |proj g|=       0.43638
At iterate    17  f =      -112.88  |proj g|=       0.43596
At iterate    18  f =      -112.88  |proj g|=       0.43521
At iterate    19  f =      -112.88  |proj g|=       0.43405
At iterate    20  f =      -112.88  |proj g|=       0.43213
At iterate    21  f =      -112.89  |proj g|=       0.42895
At iterate    22  f =       -112.9  |proj g|=       0.42355
At iterate    23  f =      -112.93  |proj g|=       0.41435
At iterate    24  f =         -113  |proj g|=       0.39883
At iterate    25  f =      -113.22  |proj g|=       0.37345
At iterate    26  f =      -113.71  |proj g|=         0.193
At iterate    27  f =      -114.03  |proj g|=       0.85435
At iterate    28  f =      -114.14  |proj g|=       0.85432
At iterate    29  f =      -114.14  |proj g|=       0.85431
At iterate    30  f =      -114.14  |proj g|=        0.8543
At iterate    31  f =      -114.14  |proj g|=        0.8543
At iterate    32  f =      -114.14  |proj g|=       0.85427
At iterate    33  f =      -114.14  |proj g|=       0.85421
At iterate    34  f =      -114.15  |proj g|=       0.85402
At iterate    35  f =      -114.15  |proj g|=       0.85354
At iterate    36  f =      -114.16  |proj g|=       0.85226
At iterate    37  f =      -114.19  |proj g|=       0.84908
At iterate    38  f =      -114.26  |proj g|=       0.84202
At iterate    39  f =      -114.38  |proj g|=       0.82919
At iterate    40  f =      -114.43  |proj g|=       0.82029
At iterate    41  f =      -114.43  |proj g|=       0.22305
At iterate    42  f =      -114.43  |proj g|=       0.22295
At iterate    43  f =      -114.43  |proj g|=       0.22328
At iterate    44  f =      -114.43  |proj g|=       0.22322
At iterate    45  f =      -114.43  |proj g|=        0.2232
At iterate    46  f =      -114.43  |proj g|=       0.22311
At iterate    47  f =      -114.43  |proj g|=       0.22296
At iterate    48  f =      -114.43  |proj g|=       0.22271
At iterate    49  f =      -114.43  |proj g|=       0.22215
At iterate    50  f =      -114.43  |proj g|=       0.22353
At iterate    51  f =      -114.43  |proj g|=       0.21891
At iterate    52  f =      -114.44  |proj g|=        0.2196
At iterate    53  f =      -114.45  |proj g|=       0.22322
At iterate    54  f =      -114.47  |proj g|=       0.22296
At iterate    55  f =      -114.53  |proj g|=        0.2115
At iterate    56  f =      -114.63  |proj g|=        0.1952
At iterate    57  f =      -114.64  |proj g|=       0.19692
At iterate    58  f =      -114.76  |proj g|=       0.21001
At iterate    59  f =      -114.99  |proj g|=       0.20386
At iterate    60  f =      -115.18  |proj g|=        0.7981
At iterate    61  f =      -115.23  |proj g|=       0.81263
At iterate    62  f =      -115.23  |proj g|=       0.15849
At iterate    63  f =      -115.23  |proj g|=      0.008595
At iterate    64  f =      -115.23  |proj g|=      0.010377
At iterate    65  f =      -115.23  |proj g|=     0.0063626

iterations 65
function evaluations 80
segments explored during Cauchy searches 68
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00636261
final function value -115.229

F = -115.229
final  value -115.229247 
converged
 
INFO  [06:54:34.877] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:54:34.964] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:54:34.971] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:54:37.918] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:54:39.561] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:54:41.732] [mlr3]  Finished benchmark 
INFO  [06:54:41.833] [bbotk] Result of batch 13: 
INFO  [06:54:41.835] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:54:41.835] [bbotk]              6.599454                 8.994685                       0.3700591 
INFO  [06:54:41.835] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:54:41.835] [bbotk]                      696        0.488 -0.9752638         <NA>   0.9728327 
INFO  [06:54:41.835] [bbotk]                                 uhash 
INFO  [06:54:41.835] [bbotk]  99295987-85df-4d5d-97da-c342950b5126 
DEBUG [06:54:42.531] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 6.198827e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  6.198827e-05 0.008378047 
  - best initial criterion value(s) :  113.5902 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -113.59  |proj g|=       0.8934
At iterate     1  f =      -114.13  |proj g|=        1.0228
At iterate     2  f =      -114.16  |proj g|=        1.0094
At iterate     3  f =      -114.16  |proj g|=        1.0017
At iterate     4  f =      -114.16  |proj g|=        1.0024
At iterate     5  f =      -114.16  |proj g|=        1.0028
At iterate     6  f =      -114.16  |proj g|=        1.0038
At iterate     7  f =      -114.16  |proj g|=         1.005
At iterate     8  f =      -114.16  |proj g|=        1.0061
At iterate     9  f =      -114.16  |proj g|=        1.0059
At iterate    10  f =      -114.17  |proj g|=        1.0007
At iterate    11  f =      -114.17  |proj g|=        1.0004
At iterate    12  f =      -114.41  |proj g|=       0.97021
At iterate    13  f =      -116.85  |proj g|=       0.80956
At iterate    14  f =      -119.02  |proj g|=       0.78248
At iterate    15  f =      -119.28  |proj g|=       0.77898
At iterate    16  f =      -119.35  |proj g|=       0.50401
At iterate    17  f =      -119.38  |proj g|=        0.4797
At iterate    18  f =      -119.42  |proj g|=       0.45365
At iterate    19  f =      -119.45  |proj g|=       0.45334
At iterate    20  f =      -119.46  |proj g|=       0.47423
At iterate    21  f =      -119.46  |proj g|=       0.47335
At iterate    22  f =      -119.46  |proj g|=       0.47325
At iterate    23  f =      -119.46  |proj g|=       0.47361
At iterate    24  f =      -119.46  |proj g|=       0.47459
At iterate    25  f =      -119.46  |proj g|=       0.47637
At iterate    26  f =      -119.46  |proj g|=       0.51274
At iterate    27  f =      -119.46  |proj g|=       0.81778
At iterate    28  f =      -119.46  |proj g|=       0.81545
At iterate    29  f =      -119.48  |proj g|=       0.81053
At iterate    30  f =       -119.5  |proj g|=       0.60069
At iterate    31  f =      -119.52  |proj g|=       0.79013
At iterate    32  f =      -119.58  |proj g|=       0.77438
At iterate    33  f =      -119.71  |proj g|=       0.38076
At iterate    34  f =      -119.79  |proj g|=       0.30308
At iterate    35  f =      -119.99  |proj g|=       0.25394
At iterate    36  f =       -120.8  |proj g|=       0.16891
At iterate    37  f =      -121.32  |proj g|=       0.14683
At iterate    38  f =      -121.35  |proj g|=       0.15768
At iterate    39  f =      -121.36  |proj g|=       0.15182
At iterate    40  f =      -121.36  |proj g|=     0.0068475
At iterate    41  f =      -121.36  |proj g|=     0.0068469
At iterate    42  f =      -121.36  |proj g|=     0.0014692

iterations 42
function evaluations 51
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00146918
final function value -121.364

F = -121.364
final  value -121.363847 
converged
 
INFO  [06:54:42.536] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:54:42.624] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:54:42.632] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:54:47.432] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:54:52.349] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:54:55.742] [mlr3]  Finished benchmark 
INFO  [06:54:55.878] [bbotk] Result of batch 14: 
INFO  [06:54:55.880] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:54:55.880] [bbotk]              9.428241                 3.229638                        0.368742 
INFO  [06:54:55.880] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:54:55.880] [bbotk]                     1697        0.482 -0.9746112         <NA>   0.9763043 
INFO  [06:54:55.880] [bbotk]                                 uhash 
INFO  [06:54:55.880] [bbotk]  0f6880ee-efdf-4230-9236-4ac841d053f8 
DEBUG [06:54:56.559] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 6.076853e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  6.076853e-05 0.008277422 
  - best initial criterion value(s) :  112.5087 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -112.51  |proj g|=      0.90359
At iterate     1  f =      -115.26  |proj g|=        1.0642
At iterate     2  f =      -115.48  |proj g|=        1.0976
At iterate     3  f =      -115.49  |proj g|=        1.0937
At iterate     4  f =      -115.49  |proj g|=        1.0918
At iterate     5  f =      -115.49  |proj g|=        1.0918
At iterate     6  f =      -115.49  |proj g|=        1.0918
At iterate     7  f =      -115.49  |proj g|=        1.0917

iterations 7
function evaluations 11
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.09173
final function value -115.486

F = -115.486
final  value -115.486285 
converged
 
INFO  [06:54:56.563] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:54:56.652] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:54:56.659] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:54:59.824] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:55:03.241] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:55:06.261] [mlr3]  Finished benchmark 
INFO  [06:55:06.361] [bbotk] Result of batch 15: 
INFO  [06:55:06.363] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:55:06.363] [bbotk]              8.367082                 5.444035                       0.2148237 
INFO  [06:55:06.363] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:55:06.363] [bbotk]                     1447        0.494 -0.9830221         <NA>   0.9739679 
INFO  [06:55:06.363] [bbotk]                                 uhash 
INFO  [06:55:06.363] [bbotk]  97444d71-5328-403d-9ce3-5eb53dae7add 
DEBUG [06:55:07.050] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.951521e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  5.951521e-05 0.007946876 
  - best initial criterion value(s) :  115.4392 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -115.44  |proj g|=       1.6675
At iterate     1  f =      -118.66  |proj g|=       0.64403
At iterate     2  f =      -119.52  |proj g|=       0.71634
At iterate     3  f =      -120.71  |proj g|=       0.73243
At iterate     4  f =       -120.9  |proj g|=       0.70673
At iterate     5  f =      -121.26  |proj g|=       0.67076
At iterate     6  f =      -122.49  |proj g|=       0.55525
At iterate     7  f =       -123.1  |proj g|=       0.57314
At iterate     8  f =      -123.46  |proj g|=       0.69529
At iterate     9  f =      -123.69  |proj g|=       0.72927
At iterate    10  f =      -123.72  |proj g|=       0.54052
At iterate    11  f =      -123.73  |proj g|=       0.53748
At iterate    12  f =      -123.73  |proj g|=       0.53638
At iterate    13  f =      -123.73  |proj g|=        0.5366
At iterate    14  f =      -123.73  |proj g|=       0.53659
At iterate    15  f =      -123.73  |proj g|=       0.53659

iterations 15
function evaluations 24
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.536588
final function value -123.734

F = -123.734
final  value -123.734330 
converged
 
INFO  [06:55:07.054] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:55:07.142] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:55:07.150] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:55:16.291] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:55:24.131] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:55:33.629] [mlr3]  Finished benchmark 
INFO  [06:55:33.729] [bbotk] Result of batch 16: 
INFO  [06:55:33.731] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:55:33.731] [bbotk]              6.268128                  2.31025                       0.2868218 
INFO  [06:55:33.731] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:55:33.731] [bbotk]                     3716        0.486 -0.9784267         <NA>   0.9774208 
INFO  [06:55:33.731] [bbotk]                                 uhash 
INFO  [06:55:33.731] [bbotk]  8e450b45-02d6-4757-a6c7-c7ab005fe8a7 
DEBUG [06:55:34.567] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.843376e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  5.843376e-05 0.007881416 
  - best initial criterion value(s) :  130.2152 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -130.22  |proj g|=      0.38457
At iterate     1  f =      -132.15  |proj g|=       0.80943
At iterate     2  f =      -132.15  |proj g|=       0.80907
At iterate     3  f =      -132.15  |proj g|=       0.80875
At iterate     4  f =      -132.15  |proj g|=       0.80875
At iterate     5  f =      -132.15  |proj g|=        0.8087
At iterate     6  f =      -132.15  |proj g|=       0.80855
At iterate     7  f =      -132.15  |proj g|=       0.80816
At iterate     8  f =      -132.15  |proj g|=       0.80751
At iterate     9  f =      -132.15  |proj g|=       0.80696
At iterate    10  f =      -132.15  |proj g|=       0.80678
At iterate    11  f =      -132.15  |proj g|=       0.80681
At iterate    12  f =      -132.15  |proj g|=       0.80684
At iterate    13  f =      -132.15  |proj g|=       0.80689
At iterate    14  f =      -132.15  |proj g|=       0.80694
At iterate    15  f =      -132.15  |proj g|=       0.80703
At iterate    16  f =      -132.15  |proj g|=       0.53002
At iterate    17  f =      -132.15  |proj g|=       0.47906
At iterate    18  f =      -132.16  |proj g|=       0.47674
At iterate    19  f =      -132.16  |proj g|=       0.47237
At iterate    20  f =      -132.18  |proj g|=       0.46438
At iterate    21  f =      -132.21  |proj g|=       0.45273
At iterate    22  f =      -132.23  |proj g|=       0.83058
At iterate    23  f =      -132.23  |proj g|=       0.82787
At iterate    24  f =      -132.24  |proj g|=       0.82563
At iterate    25  f =      -132.27  |proj g|=        0.8198
At iterate    26  f =      -132.37  |proj g|=       0.45823
At iterate    27  f =      -132.62  |proj g|=       0.39069
At iterate    28  f =      -132.77  |proj g|=       0.35771
At iterate    29  f =      -132.81  |proj g|=       0.38205
At iterate    30  f =      -132.85  |proj g|=       0.41594
At iterate    31  f =      -132.85  |proj g|=       0.41379
At iterate    32  f =      -132.85  |proj g|=       0.41127
At iterate    33  f =      -132.85  |proj g|=       0.41148
At iterate    34  f =      -132.85  |proj g|=       0.41146

iterations 34
function evaluations 39
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.411462
final function value -132.847

F = -132.847
final  value -132.846673 
converged
 
INFO  [06:55:34.571] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:55:34.661] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:55:34.668] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:55:39.417] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:55:44.886] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:55:51.559] [mlr3]  Finished benchmark 
INFO  [06:55:51.659] [bbotk] Result of batch 17: 
INFO  [06:55:51.661] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:55:51.661] [bbotk]               6.69422                 8.641125                       0.4616331 
INFO  [06:55:51.661] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:55:51.661] [bbotk]                     2350        0.615 -0.9736392         <NA>   0.9774179 
INFO  [06:55:51.661] [bbotk]                                 uhash 
INFO  [06:55:51.661] [bbotk]  57af137a-c64d-460c-96bb-38112ca7f895 
DEBUG [06:55:52.565] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.738955e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  5.738955e-05 0.007810613 
  - best initial criterion value(s) :  132.7842 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -132.78  |proj g|=      0.54676
At iterate     1  f =      -134.29  |proj g|=       0.86513
At iterate     2  f =      -134.59  |proj g|=       0.86391
At iterate     3  f =      -134.71  |proj g|=       0.86171
At iterate     4  f =      -134.74  |proj g|=       0.86227
At iterate     5  f =      -134.77  |proj g|=       0.86116
At iterate     6  f =      -134.88  |proj g|=       0.85613
At iterate     7  f =      -135.08  |proj g|=       0.84545
At iterate     8  f =      -135.32  |proj g|=       0.82983
At iterate     9  f =      -135.42  |proj g|=       0.81814
At iterate    10  f =      -135.45  |proj g|=       0.81233
At iterate    11  f =      -135.45  |proj g|=       0.81073
At iterate    12  f =      -135.45  |proj g|=       0.81061
At iterate    13  f =      -135.45  |proj g|=        0.8106
At iterate    14  f =      -135.45  |proj g|=       0.81056
At iterate    15  f =      -135.45  |proj g|=        0.8105
At iterate    16  f =      -135.45  |proj g|=        0.8104
At iterate    17  f =      -135.45  |proj g|=       0.81019
At iterate    18  f =      -135.45  |proj g|=       0.80985
At iterate    19  f =      -135.45  |proj g|=       0.80924
At iterate    20  f =      -135.45  |proj g|=       0.80842
At iterate    21  f =      -135.45  |proj g|=       0.80661
At iterate    22  f =      -135.45  |proj g|=       0.80604
At iterate    23  f =      -135.46  |proj g|=       0.80446
At iterate    24  f =      -135.48  |proj g|=       0.79868
At iterate    25  f =      -135.52  |proj g|=       0.73624
At iterate    26  f =      -135.65  |proj g|=       0.72583
At iterate    27  f =      -135.95  |proj g|=       0.68514
At iterate    28  f =       -136.4  |proj g|=       0.60824
At iterate    29  f =      -136.53  |proj g|=       0.35781
At iterate    30  f =      -137.02  |proj g|=        0.3279
At iterate    31  f =      -137.33  |proj g|=       0.28896
At iterate    32  f =      -137.69  |proj g|=       0.25022
At iterate    33  f =      -138.17  |proj g|=        0.1924
At iterate    34  f =      -138.19  |proj g|=       0.79012
At iterate    35  f =      -138.19  |proj g|=        0.2209
At iterate    36  f =      -138.19  |proj g|=       0.22158
At iterate    37  f =      -138.19  |proj g|=       0.22239
At iterate    38  f =      -138.19  |proj g|=       0.22226
At iterate    39  f =      -138.19  |proj g|=       0.22226

iterations 39
function evaluations 48
segments explored during Cauchy searches 41
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.222259
final function value -138.193

F = -138.193
final  value -138.193166 
converged
 
INFO  [06:55:52.569] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:55:52.892] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:55:52.899] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:55:54.166] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:55:55.333] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:55:56.646] [mlr3]  Finished benchmark 
INFO  [06:55:56.785] [bbotk] Result of batch 18: 
INFO  [06:55:56.788] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:55:56.788] [bbotk]              5.080232                 3.599728                       0.4371741 
INFO  [06:55:56.788] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:55:56.788] [bbotk]                      481         0.65 -0.9741223         <NA>   0.9702294 
INFO  [06:55:56.788] [bbotk]                                 uhash 
INFO  [06:55:56.788] [bbotk]  17b26228-0d2e-4bb4-9fe7-fc6dd4cecbb3 
DEBUG [06:55:57.730] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.620552e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  5.620552e-05 0.007500712 
  - best initial criterion value(s) :  126.1749 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -126.17  |proj g|=       1.2924
At iterate     1  f =      -128.39  |proj g|=       0.92296
At iterate     2  f =      -128.56  |proj g|=       0.86562
At iterate     3  f =      -128.57  |proj g|=       0.87966
At iterate     4  f =      -128.57  |proj g|=       0.86184
At iterate     5  f =      -128.57  |proj g|=       0.86912
At iterate     6  f =      -128.57  |proj g|=       0.86886
At iterate     7  f =      -128.57  |proj g|=       0.86879
At iterate     8  f =      -128.57  |proj g|=       0.86845
At iterate     9  f =      -128.57  |proj g|=       0.86796
At iterate    10  f =      -128.57  |proj g|=       0.86708
At iterate    11  f =      -128.57  |proj g|=       0.86564
At iterate    12  f =      -128.57  |proj g|=       0.86345
At iterate    13  f =      -128.57  |proj g|=       0.86047
At iterate    14  f =      -128.57  |proj g|=       0.85591
At iterate    15  f =      -128.57  |proj g|=       0.84857
At iterate    16  f =      -128.58  |proj g|=       0.82846
At iterate    17  f =      -128.61  |proj g|=       0.81086
At iterate    18  f =      -128.63  |proj g|=       0.73361
At iterate    19  f =      -128.71  |proj g|=       0.73298
At iterate    20  f =       -129.1  |proj g|=       0.72399
At iterate    21  f =      -129.42  |proj g|=       0.71345
At iterate    22  f =      -129.66  |proj g|=        0.7245
At iterate    23  f =      -129.86  |proj g|=       0.79789
At iterate    24  f =      -130.18  |proj g|=       0.80746
At iterate    25  f =      -130.95  |proj g|=       0.40683
At iterate    26  f =      -130.99  |proj g|=       0.40755
At iterate    27  f =      -130.99  |proj g|=       0.40747
At iterate    28  f =      -130.99  |proj g|=        0.4075
At iterate    29  f =      -130.99  |proj g|=       0.40752
At iterate    30  f =         -131  |proj g|=       0.40929
At iterate    31  f =       -131.1  |proj g|=       0.40568
At iterate    32  f =      -131.24  |proj g|=       0.39766
At iterate    33  f =      -131.55  |proj g|=       0.36903
At iterate    34  f =      -131.57  |proj g|=       0.81234
At iterate    35  f =      -131.57  |proj g|=        0.3666
At iterate    36  f =      -131.57  |proj g|=       0.36639
At iterate    37  f =      -131.57  |proj g|=       0.36645
At iterate    38  f =      -131.57  |proj g|=       0.36643
At iterate    39  f =      -131.57  |proj g|=       0.36637
At iterate    40  f =      -131.57  |proj g|=       0.36626
At iterate    41  f =      -131.57  |proj g|=       0.36608
At iterate    42  f =      -131.57  |proj g|=       0.36577
At iterate    43  f =      -131.57  |proj g|=       0.36516
At iterate    44  f =      -131.57  |proj g|=       0.71958
At iterate    45  f =      -131.57  |proj g|=       0.81442
At iterate    46  f =      -131.58  |proj g|=       0.81662
At iterate    47  f =      -131.58  |proj g|=       0.81675
At iterate    48  f =       -131.6  |proj g|=       0.81963
At iterate    49  f =      -131.84  |proj g|=       0.82413
At iterate    50  f =      -131.96  |proj g|=       0.82449
At iterate    51  f =      -132.02  |proj g|=       0.81677
At iterate    52  f =      -132.04  |proj g|=       0.81044
At iterate    53  f =      -132.04  |proj g|=       0.14839
At iterate    54  f =      -132.04  |proj g|=      0.043152
At iterate    55  f =      -132.04  |proj g|=      0.019766
At iterate    56  f =      -132.04  |proj g|=      0.019766

iterations 56
function evaluations 66
segments explored during Cauchy searches 58
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0197664
final function value -132.043

F = -132.043
final  value -132.043047 
converged
 
INFO  [06:55:57.734] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:55:57.824] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:55:57.832] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:56:08.715] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:56:18.738] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:56:26.882] [mlr3]  Finished benchmark 
INFO  [06:56:26.983] [bbotk] Result of batch 19: 
INFO  [06:56:26.985] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:56:26.985] [bbotk]              8.896078                 5.345376                       0.2879847 
INFO  [06:56:26.985] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:56:26.985] [bbotk]                     4135        0.647 -0.9817644         <NA>    0.977408 
INFO  [06:56:26.985] [bbotk]                                 uhash 
INFO  [06:56:26.985] [bbotk]  a0fd326f-3060-43d1-8a31-ee762b765dea 
DEBUG [06:56:27.970] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.523946e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  5.523946e-05 0.007446137 
  - best initial criterion value(s) :  131.8507 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -131.85  |proj g|=       1.3012
At iterate     1  f =      -136.59  |proj g|=       0.97009
At iterate     2  f =      -137.22  |proj g|=       0.82199
At iterate     3  f =      -137.56  |proj g|=       0.41329
At iterate     4  f =      -137.56  |proj g|=       0.35721
At iterate     5  f =      -137.57  |proj g|=       0.61823
At iterate     6  f =      -137.57  |proj g|=       0.60488
At iterate     7  f =      -137.57  |proj g|=       0.60027
At iterate     8  f =      -137.57  |proj g|=       0.59357
At iterate     9  f =      -137.57  |proj g|=       0.58452
At iterate    10  f =      -137.57  |proj g|=       0.53635
At iterate    11  f =      -137.57  |proj g|=       0.59185
At iterate    12  f =      -137.57  |proj g|=       0.54185
At iterate    13  f =      -137.57  |proj g|=       0.39936
At iterate    14  f =      -137.58  |proj g|=       0.35672
At iterate    15  f =      -137.61  |proj g|=       0.41705
At iterate    16  f =      -137.67  |proj g|=       0.45627
At iterate    17  f =      -137.69  |proj g|=       0.31691
At iterate    18  f =      -137.83  |proj g|=       0.51003
At iterate    19  f =      -138.05  |proj g|=       0.55613
At iterate    20  f =      -138.28  |proj g|=       0.66249
At iterate    21  f =       -138.5  |proj g|=       0.97395
At iterate    22  f =      -138.66  |proj g|=        1.1655
At iterate    23  f =      -139.23  |proj g|=        1.4955
At iterate    24  f =      -140.26  |proj g|=        1.0098
At iterate    25  f =      -140.29  |proj g|=        1.0696
At iterate    26  f =      -140.29  |proj g|=        1.0607
At iterate    27  f =      -140.29  |proj g|=        1.0449
At iterate    28  f =      -140.29  |proj g|=        1.0462
At iterate    29  f =      -140.29  |proj g|=         1.046
At iterate    30  f =      -140.29  |proj g|=        1.0456
At iterate    31  f =      -140.29  |proj g|=        1.0448
At iterate    32  f =      -140.29  |proj g|=        1.0436
At iterate    33  f =      -140.29  |proj g|=        1.0415
At iterate    34  f =      -140.29  |proj g|=        1.0383
At iterate    35  f =      -140.29  |proj g|=        1.0338
At iterate    36  f =       -140.3  |proj g|=        1.0282
At iterate    37  f =       -140.3  |proj g|=        1.0195
At iterate    38  f =      -140.31  |proj g|=        1.0132
At iterate    39  f =      -140.31  |proj g|=       0.99334
At iterate    40  f =      -140.32  |proj g|=       0.98312
At iterate    41  f =      -140.45  |proj g|=       0.92163
At iterate    42  f =      -140.98  |proj g|=       0.84111
At iterate    43  f =      -141.78  |proj g|=       0.83782
At iterate    44  f =       -142.7  |proj g|=       0.17676
At iterate    45  f =      -142.74  |proj g|=       0.75467
At iterate    46  f =       -143.1  |proj g|=       0.22161
At iterate    47  f =       -143.3  |proj g|=       0.21238
At iterate    48  f =      -143.38  |proj g|=       0.19103
At iterate    49  f =      -143.42  |proj g|=       0.18346
At iterate    50  f =      -143.45  |proj g|=       0.79467
At iterate    51  f =      -143.45  |proj g|=      0.041047
At iterate    52  f =      -143.45  |proj g|=     0.0048141
At iterate    53  f =      -143.45  |proj g|=      0.002578
At iterate    54  f =      -143.45  |proj g|=      0.003926

iterations 54
function evaluations 66
segments explored during Cauchy searches 57
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00392598
final function value -143.449

F = -143.449
final  value -143.448856 
converged
 
INFO  [06:56:27.974] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:56:28.217] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:56:28.224] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:56:29.528] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:56:31.038] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:56:32.896] [mlr3]  Finished benchmark 
INFO  [06:56:32.999] [bbotk] Result of batch 20: 
INFO  [06:56:33.001] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:56:33.001] [bbotk]              9.011557                 7.520786                       0.1243876 
INFO  [06:56:33.001] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:56:33.001] [bbotk]                      452        0.636 -0.9729436         <NA>   0.9595892 
INFO  [06:56:33.001] [bbotk]                                 uhash 
INFO  [06:56:33.001] [bbotk]  76184f71-fb29-4e9a-8e22-44ebc8ee45c3 
DEBUG [06:56:33.935] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.427621e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  5.427621e-05 0.006998735 
  - best initial criterion value(s) :  133.9884 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -133.99  |proj g|=      0.98464
At iterate     1  f =      -135.52  |proj g|=        1.6041
At iterate     2  f =      -137.33  |proj g|=        1.5806
At iterate     3  f =      -138.92  |proj g|=        1.4687
At iterate     4  f =      -138.98  |proj g|=        1.4379
At iterate     5  f =      -138.98  |proj g|=        1.4346
At iterate     6  f =      -138.98  |proj g|=        1.4341
At iterate     7  f =      -138.98  |proj g|=        1.4379
At iterate     8  f =      -138.99  |proj g|=        1.4456
At iterate     9  f =      -138.99  |proj g|=        1.4509
At iterate    10  f =      -138.99  |proj g|=         1.452
At iterate    11  f =      -138.99  |proj g|=        1.4522
At iterate    12  f =      -138.99  |proj g|=        1.4526
At iterate    13  f =      -138.99  |proj g|=        1.4534
At iterate    14  f =      -138.99  |proj g|=        1.4544
At iterate    15  f =      -138.99  |proj g|=        1.4559
At iterate    16  f =      -138.99  |proj g|=        1.4573
At iterate    17  f =         -139  |proj g|=        1.4566
At iterate    18  f =      -139.02  |proj g|=        1.4478
At iterate    19  f =      -139.04  |proj g|=        1.4216
At iterate    20  f =      -139.05  |proj g|=        1.4097
At iterate    21  f =      -139.06  |proj g|=        1.3969
At iterate    22  f =      -140.15  |proj g|=        1.1346
At iterate    23  f =      -142.51  |proj g|=       0.84708
At iterate    24  f =      -142.77  |proj g|=       0.85566
At iterate    25  f =      -142.79  |proj g|=       0.81522
At iterate    26  f =       -142.8  |proj g|=       0.83913
At iterate    27  f =       -142.8  |proj g|=       0.82028
At iterate    28  f =       -142.8  |proj g|=       0.82024
At iterate    29  f =      -142.81  |proj g|=       0.84141
At iterate    30  f =      -142.91  |proj g|=       0.73212
At iterate    31  f =      -143.18  |proj g|=       0.82367
At iterate    32  f =      -143.21  |proj g|=       0.74967
At iterate    33  f =      -144.37  |proj g|=       0.93018
At iterate    34  f =      -144.98  |proj g|=       0.74486
At iterate    35  f =      -146.37  |proj g|=       0.81613
At iterate    36  f =      -146.89  |proj g|=       0.81541
At iterate    37  f =      -147.42  |proj g|=       0.81167
At iterate    38  f =      -147.46  |proj g|=       0.15961
At iterate    39  f =      -147.51  |proj g|=       0.15922
At iterate    40  f =      -147.51  |proj g|=      0.074592
At iterate    41  f =      -147.51  |proj g|=       0.13482
At iterate    42  f =      -147.51  |proj g|=       0.13948
At iterate    43  f =      -147.51  |proj g|=       0.13425
At iterate    44  f =      -147.51  |proj g|=      0.091602
At iterate    45  f =      -147.51  |proj g|=      0.021862
At iterate    46  f =      -147.51  |proj g|=      0.001554
At iterate    47  f =      -147.51  |proj g|=     0.0010872

iterations 47
function evaluations 61
segments explored during Cauchy searches 49
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00108723
final function value -147.511

F = -147.511
final  value -147.511399 
converged
 
INFO  [06:56:33.939] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:56:34.073] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:56:34.080] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:56:38.617] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:56:43.136] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:56:46.408] [mlr3]  Finished benchmark 
INFO  [06:56:46.678] [bbotk] Result of batch 21: 
INFO  [06:56:46.680] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:56:46.680] [bbotk]               6.18623                 2.973499                       0.2058374 
INFO  [06:56:46.680] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:56:46.680] [bbotk]                     1594        0.639 -0.9732738         <NA>   0.9737947 
INFO  [06:56:46.680] [bbotk]                                 uhash 
INFO  [06:56:46.680] [bbotk]  84cfa810-50ba-4a2a-b87f-b22e88f66016 
DEBUG [06:56:47.616] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.327837e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  5.327837e-05 0.006929158 
  - best initial criterion value(s) :  136.1625 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -136.16  |proj g|=      0.94374
At iterate     1  f =      -143.97  |proj g|=        1.1167
At iterate     2  f =      -145.07  |proj g|=        1.4464
At iterate     3  f =      -145.85  |proj g|=        1.3848
At iterate     4  f =      -146.32  |proj g|=        1.2991
At iterate     5  f =      -146.38  |proj g|=        1.2783
At iterate     6  f =      -146.39  |proj g|=        1.2964
At iterate     7  f =      -146.39  |proj g|=        1.2916
At iterate     8  f =      -146.39  |proj g|=        1.2911
At iterate     9  f =      -146.39  |proj g|=        1.2912
At iterate    10  f =      -146.39  |proj g|=        1.2913
At iterate    11  f =      -146.39  |proj g|=        1.2915
At iterate    12  f =      -146.39  |proj g|=        1.2918
At iterate    13  f =      -146.39  |proj g|=        1.2923
At iterate    14  f =      -146.39  |proj g|=        1.2929
At iterate    15  f =      -146.39  |proj g|=        1.2944
At iterate    16  f =      -146.39  |proj g|=        1.2948
At iterate    17  f =      -146.45  |proj g|=        1.2898
At iterate    18  f =      -146.67  |proj g|=        1.2607
At iterate    19  f =      -147.74  |proj g|=        1.0977
At iterate    20  f =      -149.51  |proj g|=        0.8605
At iterate    21  f =      -149.54  |proj g|=       0.88038
At iterate    22  f =       -150.6  |proj g|=       0.25036
At iterate    23  f =      -151.01  |proj g|=       0.23524
At iterate    24  f =      -151.79  |proj g|=       0.19465
At iterate    25  f =      -152.19  |proj g|=       0.15019
At iterate    26  f =      -152.24  |proj g|=       0.80862
At iterate    27  f =      -152.28  |proj g|=       0.17596
At iterate    28  f =      -152.29  |proj g|=        0.1642
At iterate    29  f =      -152.29  |proj g|=       0.16708
At iterate    30  f =      -152.29  |proj g|=        0.1669
At iterate    31  f =      -152.29  |proj g|=        0.1669

iterations 31
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.166901
final function value -152.286

F = -152.286
final  value -152.285687 
converged
 
INFO  [06:56:47.618] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:56:47.700] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:56:47.707] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:56:53.012] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:56:56.870] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:57:02.292] [mlr3]  Finished benchmark 
INFO  [06:57:02.449] [bbotk] Result of batch 22: 
INFO  [06:57:02.451] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:57:02.451] [bbotk]              4.340732                 9.262948                        0.258415 
INFO  [06:57:02.451] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:57:02.451] [bbotk]                     2273        0.652 -0.9726625         <NA>    0.974542 
INFO  [06:57:02.451] [bbotk]                                 uhash 
INFO  [06:57:02.451] [bbotk]  1843435a-54de-4445-8506-e7d57f05cdac 
DEBUG [06:57:03.392] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.233375e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  5.233375e-05 0.006880292 
  - best initial criterion value(s) :  132.5474 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -132.55  |proj g|=      0.35934
At iterate     1  f =      -136.84  |proj g|=        0.4962
At iterate     2  f =      -137.01  |proj g|=       0.46089
At iterate     3  f =      -137.16  |proj g|=       0.34646
At iterate     4  f =       -137.2  |proj g|=       0.38452
At iterate     5  f =      -137.31  |proj g|=       0.42061
At iterate     6  f =      -138.04  |proj g|=        0.5912
At iterate     7  f =      -138.35  |proj g|=       0.77426
At iterate     8  f =      -138.95  |proj g|=       0.81764
At iterate     9  f =      -139.76  |proj g|=       0.84997
At iterate    10  f =       -140.1  |proj g|=       0.83961
At iterate    11  f =      -140.11  |proj g|=       0.54279
At iterate    12  f =      -140.12  |proj g|=       0.53807
At iterate    13  f =      -140.12  |proj g|=       0.53782
At iterate    14  f =      -140.12  |proj g|=       0.53784
At iterate    15  f =      -140.12  |proj g|=       0.53784

iterations 15
function evaluations 23
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.537837
final function value -140.119

F = -140.119
final  value -140.118562 
converged
 
INFO  [06:57:03.396] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:57:03.487] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:57:03.494] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:57:11.662] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:57:20.157] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:57:27.485] [mlr3]  Finished benchmark 
INFO  [06:57:27.583] [bbotk] Result of batch 23: 
INFO  [06:57:27.585] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:57:27.585] [bbotk]              8.122536                 8.073066                       0.3775299 
INFO  [06:57:27.585] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:57:27.585] [bbotk]                     3117        0.686 -0.9831244         <NA>   0.9772458 
INFO  [06:57:27.585] [bbotk]                                 uhash 
INFO  [06:57:27.585] [bbotk]  a7badbdf-a8a2-4045-bdee-0648fe379f8f 
DEBUG [06:57:28.359] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.149937e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  5.149937e-05 0.006842278 
  - best initial criterion value(s) :  142.3313 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -142.33  |proj g|=       1.0001
At iterate     1  f =      -153.35  |proj g|=        1.3719
At iterate     2  f =      -154.68  |proj g|=        1.2967
At iterate     3  f =      -157.51  |proj g|=       0.91004
At iterate     4  f =      -157.65  |proj g|=       0.79546
At iterate     5  f =      -157.74  |proj g|=       0.77745
At iterate     6  f =      -157.98  |proj g|=       0.72371
At iterate     7  f =      -158.03  |proj g|=       0.80607
At iterate     8  f =      -158.04  |proj g|=        0.7865
At iterate     9  f =      -158.04  |proj g|=       0.78212
At iterate    10  f =      -158.04  |proj g|=       0.78238
At iterate    11  f =      -158.04  |proj g|=       0.78255
At iterate    12  f =      -158.04  |proj g|=       0.78273
At iterate    13  f =      -158.04  |proj g|=       0.78318
At iterate    14  f =      -158.04  |proj g|=       0.78377
At iterate    15  f =      -158.04  |proj g|=       0.78481
At iterate    16  f =      -158.04  |proj g|=       0.78639
At iterate    17  f =      -158.04  |proj g|=       0.78879
At iterate    18  f =      -158.04  |proj g|=       0.79204
At iterate    19  f =      -158.05  |proj g|=       0.83212
At iterate    20  f =      -158.05  |proj g|=       0.83386
At iterate    21  f =      -158.06  |proj g|=       0.83642
At iterate    22  f =      -158.06  |proj g|=       0.83701
At iterate    23  f =      -158.06  |proj g|=       0.83684
At iterate    24  f =      -158.06  |proj g|=       0.83655
At iterate    25  f =      -158.06  |proj g|=       0.83611
At iterate    26  f =      -158.06  |proj g|=       0.83529
At iterate    27  f =      -158.07  |proj g|=       0.75685
At iterate    28  f =      -158.08  |proj g|=       0.74136
At iterate    29  f =       -158.1  |proj g|=       0.71753
At iterate    30  f =      -158.16  |proj g|=       0.69868
At iterate    31  f =      -158.27  |proj g|=       0.72666
At iterate    32  f =      -158.44  |proj g|=       0.80149
At iterate    33  f =      -158.59  |proj g|=       0.83844
At iterate    34  f =      -158.64  |proj g|=       0.88457
At iterate    35  f =      -158.76  |proj g|=       0.87548
At iterate    36  f =      -158.77  |proj g|=       0.87262
At iterate    37  f =      -158.77  |proj g|=       0.87222
At iterate    38  f =      -158.77  |proj g|=       0.87143
At iterate    39  f =      -158.77  |proj g|=        0.8708
At iterate    40  f =      -158.77  |proj g|=       0.87008
At iterate    41  f =      -158.77  |proj g|=       0.86948
At iterate    42  f =      -158.77  |proj g|=       0.86748
At iterate    43  f =      -158.77  |proj g|=       0.86546
At iterate    44  f =      -158.78  |proj g|=        0.8577
At iterate    45  f =      -158.79  |proj g|=        0.8577
At iterate    46  f =      -158.92  |proj g|=       0.85521
At iterate    47  f =      -159.16  |proj g|=        0.8489
At iterate    48  f =      -159.75  |proj g|=        0.8256
At iterate    49  f =      -160.74  |proj g|=       0.29076
At iterate    50  f =      -161.14  |proj g|=       0.21578
At iterate    51  f =      -161.39  |proj g|=       0.21474
At iterate    52  f =      -161.65  |proj g|=       0.21261
At iterate    53  f =      -161.68  |proj g|=       0.21106
At iterate    54  f =      -161.74  |proj g|=        0.2095
At iterate    55  f =      -162.25  |proj g|=       0.18369
At iterate    56  f =      -162.59  |proj g|=       0.81693
At iterate    57  f =      -162.69  |proj g|=       0.82613
At iterate    58  f =       -162.7  |proj g|=       0.15159
At iterate    59  f =       -162.7  |proj g|=      0.049904
At iterate    60  f =       -162.7  |proj g|=     0.0053973
At iterate    61  f =       -162.7  |proj g|=     0.0017584

iterations 61
function evaluations 67
segments explored during Cauchy searches 64
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00175841
final function value -162.703

F = -162.703
final  value -162.703104 
converged
 
INFO  [06:57:28.363] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:57:28.465] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:57:28.472] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:57:35.359] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:57:41.664] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:57:48.550] [mlr3]  Finished benchmark 
INFO  [06:57:48.666] [bbotk] Result of batch 24: 
INFO  [06:57:48.667] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:57:48.667] [bbotk]              5.593526                 4.873715                      0.09908703 
INFO  [06:57:48.667] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:57:48.667] [bbotk]                     3138        0.516 -0.9715702         <NA>   0.9731968 
INFO  [06:57:48.667] [bbotk]                                 uhash 
INFO  [06:57:48.667] [bbotk]  f380038a-081c-415e-a6cd-e97b11c34bca 
DEBUG [06:57:49.448] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 5.058887e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  5.058887e-05 0.006777107 
  - best initial criterion value(s) :  135.477 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -135.48  |proj g|=       1.3587
At iterate     1  f =       -138.4  |proj g|=        3.1469
At iterate     2  f =      -138.45  |proj g|=        2.8912
At iterate     3  f =      -138.51  |proj g|=        2.4175
At iterate     4  f =      -138.57  |proj g|=        2.2694
At iterate     5  f =      -138.81  |proj g|=        2.1288
At iterate     6  f =      -139.01  |proj g|=        2.8804
At iterate     7  f =      -139.12  |proj g|=        4.2584
At iterate     8  f =      -139.12  |proj g|=         4.115
At iterate     9  f =      -139.12  |proj g|=        4.1016
At iterate    10  f =      -139.14  |proj g|=        4.2116
At iterate    11  f =       -139.3  |proj g|=        4.6287
At iterate    12  f =      -139.61  |proj g|=        5.0485
At iterate    13  f =      -140.29  |proj g|=        5.2256
At iterate    14  f =      -140.38  |proj g|=        4.8913
At iterate    15  f =      -142.17  |proj g|=        4.5696
At iterate    16  f =      -148.13  |proj g|=        3.2774
At iterate    17  f =      -154.05  |proj g|=         2.395
At iterate    18  f =      -154.31  |proj g|=        2.3709
At iterate    19  f =      -154.33  |proj g|=        2.3645
At iterate    20  f =      -154.35  |proj g|=        2.3472
At iterate    21  f =      -154.36  |proj g|=        2.3508
At iterate    22  f =      -154.36  |proj g|=        2.3505
At iterate    23  f =      -154.36  |proj g|=        2.3493
At iterate    24  f =      -154.36  |proj g|=        2.3481
At iterate    25  f =      -154.36  |proj g|=        2.3455
At iterate    26  f =      -154.36  |proj g|=        2.3411
At iterate    27  f =      -154.37  |proj g|=        2.3329
At iterate    28  f =       -154.4  |proj g|=        2.3181
At iterate    29  f =      -154.46  |proj g|=        2.2893
At iterate    30  f =      -154.62  |proj g|=        2.2244
At iterate    31  f =      -155.02  |proj g|=        2.0784
At iterate    32  f =      -155.08  |proj g|=        2.0398
At iterate    33  f =      -156.18  |proj g|=        1.7484
At iterate    34  f =       -166.1  |proj g|=       0.19014
At iterate    35  f =      -166.69  |proj g|=       0.17217
At iterate    36  f =      -166.96  |proj g|=       0.82756
At iterate    37  f =         -167  |proj g|=       0.82195
At iterate    38  f =      -167.02  |proj g|=       0.14233
At iterate    39  f =      -167.02  |proj g|=      0.075697
At iterate    40  f =      -167.02  |proj g|=     0.0035137
At iterate    41  f =      -167.02  |proj g|=     0.0057462

iterations 41
function evaluations 51
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00574619
final function value -167.023

F = -167.023
final  value -167.022798 
converged
 
INFO  [06:57:49.452] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:57:49.538] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:57:49.545] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:58:00.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:58:10.153] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:58:21.799] [mlr3]  Finished benchmark 
INFO  [06:58:21.897] [bbotk] Result of batch 25: 
INFO  [06:58:21.898] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:58:21.898] [bbotk]              7.826885                 9.851822                      0.02014054 
INFO  [06:58:21.898] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:58:21.898] [bbotk]                     4563        0.534 -0.9729913         <NA>   0.9647801 
INFO  [06:58:21.898] [bbotk]                                 uhash 
INFO  [06:58:21.898] [bbotk]  ede85205-0e24-40b6-ad00-c8da92176a3f 
DEBUG [06:58:22.670] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.969262e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  4.969262e-05 0.006696431 
  - best initial criterion value(s) :  146.5376 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -146.54  |proj g|=       6.3536
At iterate     1  f =      -149.05  |proj g|=        5.8012
At iterate     2  f =      -151.83  |proj g|=        4.7735
At iterate     3  f =      -153.46  |proj g|=        2.4079
At iterate     4  f =      -155.96  |proj g|=        2.3424
At iterate     5  f =       -156.2  |proj g|=         1.954
At iterate     6  f =      -156.87  |proj g|=         1.673
At iterate     7  f =       -159.5  |proj g|=       0.98631
At iterate     8  f =      -160.86  |proj g|=        1.0603
At iterate     9  f =      -162.52  |proj g|=          1.17
At iterate    10  f =      -163.57  |proj g|=        1.2465
At iterate    11  f =      -164.34  |proj g|=        1.2976
At iterate    12  f =      -164.34  |proj g|=        1.3356
At iterate    13  f =      -164.38  |proj g|=        1.3192
At iterate    14  f =      -164.38  |proj g|=        1.3167
At iterate    15  f =      -164.38  |proj g|=         1.317
At iterate    16  f =      -164.38  |proj g|=         1.317
At iterate    17  f =      -164.38  |proj g|=        1.3171
At iterate    18  f =      -164.38  |proj g|=        1.3171
At iterate    19  f =      -164.38  |proj g|=        1.3168
At iterate    20  f =      -164.38  |proj g|=         1.316
At iterate    21  f =      -164.38  |proj g|=        1.3147
At iterate    22  f =      -164.38  |proj g|=        1.3149
At iterate    23  f =      -164.38  |proj g|=        1.3149
At iterate    24  f =      -164.38  |proj g|=         1.315
At iterate    25  f =      -164.38  |proj g|=        1.3151
At iterate    26  f =      -164.38  |proj g|=        1.3151
At iterate    27  f =      -164.39  |proj g|=        1.3148
At iterate    28  f =      -164.39  |proj g|=        1.3136
At iterate    29  f =      -164.39  |proj g|=        1.3107
At iterate    30  f =      -164.39  |proj g|=        1.3062
At iterate    31  f =       -164.4  |proj g|=        1.2992
At iterate    32  f =      -164.41  |proj g|=        1.2844
At iterate    33  f =      -164.43  |proj g|=        1.2765
At iterate    34  f =      -164.55  |proj g|=        1.2402
At iterate    35  f =      -164.84  |proj g|=        1.1653
At iterate    36  f =       -165.6  |proj g|=        1.0063
At iterate    37  f =      -167.36  |proj g|=       0.85998
At iterate    38  f =      -168.62  |proj g|=        0.8611
At iterate    39  f =      -169.34  |proj g|=        0.8439
At iterate    40  f =      -169.65  |proj g|=       0.82607
At iterate    41  f =      -169.69  |proj g|=       0.81911
At iterate    42  f =      -169.69  |proj g|=      0.092317
At iterate    43  f =      -169.69  |proj g|=     0.0042907
At iterate    44  f =      -169.69  |proj g|=     0.0051126

iterations 44
function evaluations 51
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00511257
final function value -169.689

F = -169.689
final  value -169.689355 
converged
 
INFO  [06:58:22.674] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:58:22.759] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:58:22.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:58:25.049] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:58:26.968] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:58:29.357] [mlr3]  Finished benchmark 
INFO  [06:58:29.495] [bbotk] Result of batch 26: 
INFO  [06:58:29.497] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:58:29.497] [bbotk]              9.814036                 8.668519                       0.4947869 
INFO  [06:58:29.497] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:58:29.497] [bbotk]                     1082        0.525 -0.9714119         <NA>   0.9754857 
INFO  [06:58:29.497] [bbotk]                                 uhash 
INFO  [06:58:29.497] [bbotk]  83bf74c0-729c-41ed-926a-1558c29e9db4 
DEBUG [06:58:30.306] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.889467e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.65764 0.9865363 9498 
  - variance bounds :  4.889467e-05 0.00646643 
  - best initial criterion value(s) :  151.9897 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -151.99  |proj g|=        2.084
At iterate     1  f =      -154.61  |proj g|=         2.056
At iterate     2  f =      -155.49  |proj g|=         2.354
At iterate     3  f =      -155.51  |proj g|=        2.3326
At iterate     4  f =      -155.52  |proj g|=        2.3201
At iterate     5  f =      -155.52  |proj g|=        2.3206
At iterate     6  f =      -155.52  |proj g|=        2.3228
At iterate     7  f =      -155.52  |proj g|=        2.3235
At iterate     8  f =      -155.52  |proj g|=         2.324
At iterate     9  f =      -155.52  |proj g|=        2.3249
At iterate    10  f =      -155.52  |proj g|=        2.3263
At iterate    11  f =      -155.52  |proj g|=        2.3286
At iterate    12  f =      -155.52  |proj g|=        2.3322
At iterate    13  f =      -155.52  |proj g|=        2.3381
At iterate    14  f =      -155.52  |proj g|=        2.3475
At iterate    15  f =      -155.54  |proj g|=        2.3614
At iterate    16  f =      -155.56  |proj g|=        2.3773
At iterate    17  f =      -155.62  |proj g|=        2.3797
At iterate    18  f =      -155.67  |proj g|=        2.3224
At iterate    19  f =      -155.67  |proj g|=        2.3273
At iterate    20  f =      -155.68  |proj g|=        2.3123
At iterate    21  f =      -155.85  |proj g|=          2.29
At iterate    22  f =      -157.52  |proj g|=        2.0227
At iterate    23  f =      -160.32  |proj g|=        1.5879
At iterate    24  f =      -164.24  |proj g|=        1.0715
At iterate    25  f =      -167.64  |proj g|=       0.18119
At iterate    26  f =      -168.47  |proj g|=        0.8316
At iterate    27  f =      -168.68  |proj g|=       0.82475
At iterate    28  f =      -168.71  |proj g|=       0.28784
At iterate    29  f =      -168.71  |proj g|=       0.31297
At iterate    30  f =      -168.71  |proj g|=       0.31058
At iterate    31  f =      -168.71  |proj g|=        0.3105
At iterate    32  f =      -168.71  |proj g|=       0.31061
At iterate    33  f =      -168.71  |proj g|=       0.31093
At iterate    34  f =      -168.71  |proj g|=       0.31154
At iterate    35  f =      -168.71  |proj g|=       0.40973
At iterate    36  f =      -168.71  |proj g|=       0.71499
At iterate    37  f =      -168.71  |proj g|=       0.83193
At iterate    38  f =      -168.71  |proj g|=       0.83257
At iterate    39  f =      -168.71  |proj g|=        0.8334
At iterate    40  f =      -168.72  |proj g|=       0.83514
At iterate    41  f =      -168.72  |proj g|=       0.83502
At iterate    42  f =      -168.73  |proj g|=       0.83709
At iterate    43  f =      -169.27  |proj g|=       0.16935
At iterate    44  f =      -169.31  |proj g|=       0.82615
At iterate    45  f =      -169.32  |proj g|=       0.82717
At iterate    46  f =      -169.32  |proj g|=       0.10661
At iterate    47  f =      -169.32  |proj g|=      0.038244
At iterate    48  f =      -169.32  |proj g|=     0.0039731
At iterate    49  f =      -169.32  |proj g|=     0.0010278

iterations 49
function evaluations 58
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00102776
final function value -169.316

F = -169.316
final  value -169.316488 
converged
 
INFO  [06:58:30.310] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:58:30.399] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:58:30.406] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:58:40.459] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:58:51.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:59:00.175] [mlr3]  Finished benchmark 
INFO  [06:59:00.276] [bbotk] Result of batch 27: 
INFO  [06:59:00.278] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:59:00.278] [bbotk]              8.813718                 2.039425                      0.02694397 
INFO  [06:59:00.278] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:59:00.278] [bbotk]                     4152        0.548 -0.9747689         <NA>   0.9670793 
INFO  [06:59:00.278] [bbotk]                                 uhash 
INFO  [06:59:00.278] [bbotk]  9bced671-eea1-4d6f-93af-cde8db93b888 
DEBUG [06:59:01.059] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.804021e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  4.804021e-05 0.006402156 
  - best initial criterion value(s) :  154.2927 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -154.29  |proj g|=       1.3224
At iterate     1  f =      -157.97  |proj g|=         2.714
At iterate     2  f =      -159.33  |proj g|=        2.6445
At iterate     3  f =      -161.22  |proj g|=         2.401
At iterate     4  f =      -161.57  |proj g|=        2.2984
At iterate     5  f =      -162.26  |proj g|=        2.2218
At iterate     6  f =      -163.13  |proj g|=        2.1961
At iterate     7  f =      -163.38  |proj g|=        2.1643
At iterate     8  f =      -163.56  |proj g|=        2.2429
At iterate     9  f =      -163.58  |proj g|=        2.2209
At iterate    10  f =      -163.58  |proj g|=        2.2191
At iterate    11  f =      -163.58  |proj g|=        2.2192
At iterate    12  f =      -163.58  |proj g|=        2.2196
At iterate    13  f =      -163.58  |proj g|=          2.22
At iterate    14  f =      -163.58  |proj g|=        2.2206
At iterate    15  f =      -163.58  |proj g|=        2.2214
At iterate    16  f =      -163.59  |proj g|=        2.2229
At iterate    17  f =       -163.6  |proj g|=        2.2146
At iterate    18  f =      -163.63  |proj g|=        2.2133
At iterate    19  f =      -163.66  |proj g|=        2.1759
At iterate    20  f =      -163.83  |proj g|=        2.1525
At iterate    21  f =      -165.08  |proj g|=        1.9716
At iterate    22  f =      -169.32  |proj g|=        1.2966
At iterate    23  f =      -172.15  |proj g|=       0.96396
At iterate    24  f =      -173.16  |proj g|=        1.2313
At iterate    25  f =      -173.23  |proj g|=        1.1527
At iterate    26  f =      -173.36  |proj g|=        1.1187
At iterate    27  f =      -173.51  |proj g|=       0.98941
At iterate    28  f =      -173.54  |proj g|=        1.0636
At iterate    29  f =      -173.55  |proj g|=        1.0429
At iterate    30  f =      -173.55  |proj g|=        1.0423
At iterate    31  f =      -173.55  |proj g|=        1.0422
At iterate    32  f =      -173.55  |proj g|=        1.0423

iterations 32
function evaluations 40
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.04231
final function value -173.547

F = -173.547
final  value -173.546561 
converged
 
INFO  [06:59:01.063] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:59:01.175] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:59:01.183] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:59:03.288] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:59:05.316] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:59:07.750] [mlr3]  Finished benchmark 
INFO  [06:59:07.849] [bbotk] Result of batch 28: 
INFO  [06:59:07.851] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:59:07.851] [bbotk]              3.896794                 3.346363                      0.08233709 
INFO  [06:59:07.851] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:59:07.851] [bbotk]                      971         0.53 -0.9745746         <NA>   0.9570914 
INFO  [06:59:07.851] [bbotk]                                 uhash 
INFO  [06:59:07.851] [bbotk]  9aff5b86-ec7a-4468-ad45-d6986a935abd 
DEBUG [06:59:08.690] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.743053e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  4.743053e-05 0.006232179 
  - best initial criterion value(s) :  163.8449 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -163.84  |proj g|=       1.2949
At iterate     1  f =      -167.63  |proj g|=        1.5405
At iterate     2  f =      -167.68  |proj g|=        1.5319
At iterate     3  f =      -167.86  |proj g|=        1.4926
At iterate     4  f =         -168  |proj g|=        1.4737
At iterate     5  f =      -168.82  |proj g|=        1.2903
At iterate     6  f =      -169.49  |proj g|=        1.3121
At iterate     7  f =      -169.55  |proj g|=          1.26
At iterate     8  f =      -169.58  |proj g|=        1.2888
At iterate     9  f =      -169.58  |proj g|=        1.2881
At iterate    10  f =      -169.58  |proj g|=        1.2878
At iterate    11  f =      -169.58  |proj g|=        1.2872
At iterate    12  f =      -169.58  |proj g|=        1.2863
At iterate    13  f =      -169.58  |proj g|=        1.2848
At iterate    14  f =      -169.58  |proj g|=        1.2823
At iterate    15  f =      -169.58  |proj g|=        1.2782
At iterate    16  f =      -169.59  |proj g|=        1.2709
At iterate    17  f =       -169.6  |proj g|=        1.2583
At iterate    18  f =      -169.63  |proj g|=        1.2366
At iterate    19  f =      -169.72  |proj g|=        1.1966
At iterate    20  f =      -169.73  |proj g|=        1.1738
At iterate    21  f =      -169.96  |proj g|=        1.1171
At iterate    22  f =       -170.7  |proj g|=       0.97234
At iterate    23  f =      -172.72  |proj g|=       0.90651
At iterate    24  f =      -176.11  |proj g|=       0.90024
At iterate    25  f =      -177.88  |proj g|=       0.86454
At iterate    26  f =      -177.95  |proj g|=       0.86947
At iterate    27  f =      -178.06  |proj g|=       0.85656
At iterate    28  f =      -178.07  |proj g|=       0.85318
At iterate    29  f =      -178.08  |proj g|=       0.85465
At iterate    30  f =      -178.08  |proj g|=       0.85512
At iterate    31  f =      -178.08  |proj g|=       0.85539
At iterate    32  f =      -178.08  |proj g|=       0.85557
At iterate    33  f =      -178.08  |proj g|=       0.85602
At iterate    34  f =      -178.08  |proj g|=       0.85663
At iterate    35  f =      -178.08  |proj g|=       0.85761
At iterate    36  f =      -178.08  |proj g|=       0.85887
At iterate    37  f =      -178.08  |proj g|=       0.86051
At iterate    38  f =      -178.08  |proj g|=       0.86271
At iterate    39  f =      -178.08  |proj g|=       0.86311
At iterate    40  f =      -178.08  |proj g|=       0.87105
At iterate    41  f =      -178.08  |proj g|=       0.86976
At iterate    42  f =      -178.11  |proj g|=       0.86229
At iterate    43  f =      -178.16  |proj g|=       0.84337
At iterate    44  f =       -178.3  |proj g|=       0.78905
At iterate    45  f =      -178.59  |proj g|=       0.67827
At iterate    46  f =      -179.08  |proj g|=       0.50115
At iterate    47  f =      -179.57  |proj g|=       0.36875
At iterate    48  f =      -180.26  |proj g|=       0.21517
At iterate    49  f =      -180.84  |proj g|=       0.18995
At iterate    50  f =      -181.25  |proj g|=       0.16409
At iterate    51  f =      -181.35  |proj g|=       0.84465
At iterate    52  f =      -181.43  |proj g|=       0.15168
At iterate    53  f =      -181.43  |proj g|=       0.14986
At iterate    54  f =      -181.43  |proj g|=      0.018431
At iterate    55  f =      -181.43  |proj g|=     0.0034328

iterations 55
function evaluations 63
segments explored during Cauchy searches 57
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00343278
final function value -181.434

F = -181.434
final  value -181.434278 
converged
 
INFO  [06:59:08.694] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:59:08.783] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:59:08.790] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:59:17.273] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:59:24.399] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:59:31.584] [mlr3]  Finished benchmark 
INFO  [06:59:31.710] [bbotk] Result of batch 29: 
INFO  [06:59:31.712] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [06:59:31.712] [bbotk]              6.398347                 7.722711                       0.4605759 
INFO  [06:59:31.712] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [06:59:31.712] [bbotk]                     3525        0.556 -0.9722979         <NA>   0.9781912 
INFO  [06:59:31.712] [bbotk]                                 uhash 
INFO  [06:59:31.712] [bbotk]  79550225-915a-4d4d-9f20-61fc0c1bc77f 
DEBUG [06:59:32.550] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.679115e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  4.679115e-05 0.006196017 
  - best initial criterion value(s) :  172.4764 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -172.48  |proj g|=       1.0288
At iterate     1  f =      -177.05  |proj g|=        1.0916
At iterate     2  f =      -178.67  |proj g|=        1.0764
At iterate     3  f =      -180.11  |proj g|=        1.0174
At iterate     4  f =      -180.13  |proj g|=        1.0062
At iterate     5  f =      -180.13  |proj g|=        1.0109
At iterate     6  f =      -180.15  |proj g|=        1.0212
At iterate     7  f =      -180.19  |proj g|=        1.0389
At iterate     8  f =      -180.21  |proj g|=         1.054
At iterate     9  f =      -180.21  |proj g|=        1.0491
At iterate    10  f =      -180.21  |proj g|=        1.0553
At iterate    11  f =      -180.22  |proj g|=        1.0566
At iterate    12  f =      -180.22  |proj g|=        1.0601
At iterate    13  f =      -180.24  |proj g|=        1.0636
At iterate    14  f =      -180.28  |proj g|=        1.0638
At iterate    15  f =      -180.35  |proj g|=        1.0672
At iterate    16  f =      -180.48  |proj g|=        1.0084
At iterate    17  f =      -180.65  |proj g|=       0.97514
At iterate    18  f =      -181.12  |proj g|=       0.79238
At iterate    19  f =      -181.19  |proj g|=       0.78327
At iterate    20  f =      -181.19  |proj g|=       0.78091
At iterate    21  f =      -181.19  |proj g|=       0.78125
At iterate    22  f =      -181.19  |proj g|=       0.78153
At iterate    23  f =      -181.19  |proj g|=       0.78181
At iterate    24  f =      -181.19  |proj g|=       0.78265
At iterate    25  f =      -181.19  |proj g|=       0.78339
At iterate    26  f =      -181.19  |proj g|=       0.78551
At iterate    27  f =      -181.19  |proj g|=       0.79051
At iterate    28  f =      -181.19  |proj g|=       0.78957
At iterate    29  f =      -181.19  |proj g|=       0.79423
At iterate    30  f =      -181.22  |proj g|=       0.80833
At iterate    31  f =      -181.37  |proj g|=       0.83849
At iterate    32  f =      -181.74  |proj g|=       0.82335
At iterate    33  f =      -181.92  |proj g|=       0.47041
At iterate    34  f =      -181.92  |proj g|=       0.49966
At iterate    35  f =      -181.98  |proj g|=       0.50874
At iterate    36  f =      -182.17  |proj g|=       0.37751
At iterate    37  f =      -182.49  |proj g|=       0.25914
At iterate    38  f =      -183.19  |proj g|=       0.20051
At iterate    39  f =      -183.75  |proj g|=       0.80781
At iterate    40  f =      -183.88  |proj g|=        0.1727
At iterate    41  f =      -183.93  |proj g|=       0.16224
At iterate    42  f =      -183.94  |proj g|=       0.82686
At iterate    43  f =      -183.94  |proj g|=     0.0041844
At iterate    44  f =      -183.94  |proj g|=     0.0049193
At iterate    45  f =      -183.94  |proj g|=     0.0019658

iterations 45
function evaluations 56
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00196583
final function value -183.937

F = -183.937
final  value -183.936826 
converged
 
INFO  [06:59:32.554] [bbotk] Evaluating 1 configuration(s) 
INFO  [06:59:32.644] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [06:59:32.651] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [06:59:41.572] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [06:59:51.289] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [06:59:59.901] [mlr3]  Finished benchmark 
INFO  [07:00:00.049] [bbotk] Result of batch 30: 
INFO  [07:00:00.051] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:00:00.051] [bbotk]              2.677588                 2.774228                       0.1794983 
INFO  [07:00:00.051] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:00:00.051] [bbotk]                     3872        0.568 -0.9733333         <NA>   0.9677559 
INFO  [07:00:00.051] [bbotk]                                 uhash 
INFO  [07:00:00.051] [bbotk]  25c98c0e-1ac5-4ceb-9a52-9056b4d8d71e 
DEBUG [07:00:00.869] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.601202e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  4.601202e-05 0.006132497 
  - best initial criterion value(s) :  183.1682 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -183.17  |proj g|=      0.92671
At iterate     1  f =      -184.21  |proj g|=       0.59351
At iterate     2  f =      -184.35  |proj g|=       0.83318
At iterate     3  f =      -187.23  |proj g|=       0.48743
At iterate     4  f =      -188.19  |proj g|=       0.40061
At iterate     5  f =      -189.13  |proj g|=       0.52532
At iterate     6  f =      -189.14  |proj g|=        0.5413
At iterate     7  f =      -189.14  |proj g|=       0.54182
At iterate     8  f =      -189.14  |proj g|=       0.54122
At iterate     9  f =      -189.14  |proj g|=       0.54116
At iterate    10  f =      -189.14  |proj g|=       0.54111
At iterate    11  f =      -189.14  |proj g|=       0.54068
At iterate    12  f =      -189.14  |proj g|=       0.54055
At iterate    13  f =      -189.14  |proj g|=       0.54034
At iterate    14  f =      -189.14  |proj g|=       0.84252
At iterate    15  f =      -189.15  |proj g|=        0.8444
At iterate    16  f =      -189.17  |proj g|=       0.84783
At iterate    17  f =      -189.19  |proj g|=       0.84977
At iterate    18  f =      -189.22  |proj g|=       0.84775
At iterate    19  f =      -189.24  |proj g|=       0.84217
At iterate    20  f =      -189.25  |proj g|=       0.53561
At iterate    21  f =      -189.25  |proj g|=       0.53533
At iterate    22  f =      -189.25  |proj g|=       0.53513
At iterate    23  f =      -189.25  |proj g|=       0.53502
At iterate    24  f =      -189.25  |proj g|=       0.53487
At iterate    25  f =      -189.25  |proj g|=       0.53458
At iterate    26  f =      -189.25  |proj g|=       0.53414
At iterate    27  f =      -189.25  |proj g|=       0.53343
At iterate    28  f =      -189.25  |proj g|=       0.53229
At iterate    29  f =      -189.25  |proj g|=       0.53046
At iterate    30  f =      -189.25  |proj g|=       0.52759
At iterate    31  f =      -189.25  |proj g|=       0.52354
At iterate    32  f =      -189.25  |proj g|=       0.51939
At iterate    33  f =      -189.26  |proj g|=       0.51997
At iterate    34  f =      -189.27  |proj g|=       0.53607
At iterate    35  f =      -189.27  |proj g|=       0.53534
At iterate    36  f =      -189.27  |proj g|=       0.53554
At iterate    37  f =      -189.27  |proj g|=       0.53693
At iterate    38  f =      -189.28  |proj g|=       0.53762
At iterate    39  f =      -189.29  |proj g|=        0.5368
At iterate    40  f =      -189.32  |proj g|=       0.50681
At iterate    41  f =      -189.38  |proj g|=       0.51148
At iterate    42  f =      -189.76  |proj g|=       0.42608
At iterate    43  f =      -190.35  |proj g|=       0.18791
At iterate    44  f =      -190.73  |proj g|=       0.17101
At iterate    45  f =      -190.82  |proj g|=       0.25391
At iterate    46  f =      -190.87  |proj g|=       0.84294
At iterate    47  f =      -190.89  |proj g|=       0.15101
At iterate    48  f =      -190.89  |proj g|=      0.091839
At iterate    49  f =      -190.89  |proj g|=     0.0050133
At iterate    50  f =      -190.89  |proj g|=     0.0050132

iterations 50
function evaluations 62
segments explored during Cauchy searches 54
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00501321
final function value -190.888

F = -190.888
final  value -190.887796 
converged
 
INFO  [07:00:00.873] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:00:00.962] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:00:00.969] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:00:02.761] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:00:04.709] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:00:06.638] [mlr3]  Finished benchmark 
INFO  [07:00:06.739] [bbotk] Result of batch 31: 
INFO  [07:00:06.741] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:00:06.741] [bbotk]              9.212627                 9.316012                       0.1294408 
INFO  [07:00:06.741] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:00:06.741] [bbotk]                      634        0.548 -0.9718735         <NA>   0.9640006 
INFO  [07:00:06.741] [bbotk]                                 uhash 
INFO  [07:00:06.741] [bbotk]  eb29ff10-8bba-4a71-a5a9-999d6a3c9071 
DEBUG [07:00:07.533] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.528909e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  4.528909e-05 0.005957776 
  - best initial criterion value(s) :  186.0141 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -186.01  |proj g|=       0.9164
At iterate     1  f =      -190.22  |proj g|=       0.90361
At iterate     2  f =      -190.25  |proj g|=       0.91438
At iterate     3  f =      -190.25  |proj g|=        0.9102
At iterate     4  f =      -190.26  |proj g|=       0.90422
At iterate     5  f =      -190.26  |proj g|=       0.90445
At iterate     6  f =      -190.26  |proj g|=       0.90462
At iterate     7  f =      -190.26  |proj g|=       0.90484
At iterate     8  f =      -190.26  |proj g|=       0.90517
At iterate     9  f =      -190.26  |proj g|=       0.90558
At iterate    10  f =      -190.26  |proj g|=       0.90587
At iterate    11  f =      -190.26  |proj g|=       0.90686
At iterate    12  f =      -190.26  |proj g|=       0.90814
At iterate    13  f =      -190.26  |proj g|=       0.91044
At iterate    14  f =      -190.27  |proj g|=       0.91389
At iterate    15  f =      -190.29  |proj g|=       0.91585
At iterate    16  f =      -190.33  |proj g|=       0.93379
At iterate    17  f =      -190.42  |proj g|=       0.91819
At iterate    18  f =       -191.1  |proj g|=       0.86766
At iterate    19  f =      -192.06  |proj g|=       0.44932
At iterate    20  f =      -192.54  |proj g|=       0.51708
At iterate    21  f =      -192.64  |proj g|=       0.83971
At iterate    22  f =      -192.65  |proj g|=       0.81381
At iterate    23  f =      -192.65  |proj g|=       0.48302
At iterate    24  f =      -192.65  |proj g|=       0.48181
At iterate    25  f =      -192.65  |proj g|=       0.48177

iterations 25
function evaluations 33
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.48177
final function value -192.65

F = -192.65
final  value -192.650304 
converged
 
INFO  [07:00:07.537] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:00:07.778] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:00:07.785] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:00:11.109] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:00:16.178] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:00:19.788] [mlr3]  Finished benchmark 
INFO  [07:00:19.891] [bbotk] Result of batch 32: 
INFO  [07:00:19.893] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:00:19.893] [bbotk]              5.531437                 6.060886                        0.234288 
INFO  [07:00:19.893] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:00:19.893] [bbotk]                     1664        0.562 -0.9727544         <NA>   0.9741144 
INFO  [07:00:19.893] [bbotk]                                 uhash 
INFO  [07:00:19.893] [bbotk]  732b360f-2e0c-4177-ad45-164385edd202 
DEBUG [07:00:20.734] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.461156e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  4.461156e-05 0.00577397 
  - best initial criterion value(s) :  183.0978 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -183.1  |proj g|=       2.2326
At iterate     1  f =      -184.23  |proj g|=        2.6916
At iterate     2  f =      -184.44  |proj g|=        2.5606
At iterate     3  f =      -184.91  |proj g|=        2.1786
At iterate     4  f =      -185.37  |proj g|=        2.0244
At iterate     5  f =      -185.57  |proj g|=        2.0581
At iterate     6  f =      -185.73  |proj g|=         1.984
At iterate     7  f =      -185.73  |proj g|=        1.9558
At iterate     8  f =      -185.73  |proj g|=        1.9618
At iterate     9  f =      -185.73  |proj g|=        1.9634
At iterate    10  f =      -185.74  |proj g|=         1.971
At iterate    11  f =      -185.74  |proj g|=        1.9784
At iterate    12  f =      -185.74  |proj g|=        1.9902
At iterate    13  f =      -185.75  |proj g|=        2.0035
At iterate    14  f =      -185.79  |proj g|=        2.0171
At iterate    15  f =      -185.88  |proj g|=        2.0189
At iterate    16  f =      -186.12  |proj g|=        1.9749
At iterate    17  f =      -186.76  |proj g|=        1.8057
At iterate    18  f =      -188.48  |proj g|=        1.3835
At iterate    19  f =      -192.22  |proj g|=        1.1243
At iterate    20  f =      -196.78  |proj g|=         1.037
At iterate    21  f =      -197.84  |proj g|=       0.97708
At iterate    22  f =      -197.88  |proj g|=       0.96263
At iterate    23  f =      -197.91  |proj g|=       0.94266
At iterate    24  f =      -197.92  |proj g|=       0.93869
At iterate    25  f =      -197.94  |proj g|=       0.93911
At iterate    26  f =      -197.94  |proj g|=       0.93925
At iterate    27  f =      -197.94  |proj g|=       0.93919
At iterate    28  f =      -197.94  |proj g|=       0.93912
At iterate    29  f =      -197.94  |proj g|=       0.93891
At iterate    30  f =      -197.94  |proj g|=       0.93849
At iterate    31  f =      -197.94  |proj g|=       0.93876
At iterate    32  f =      -197.94  |proj g|=       0.93808
At iterate    33  f =      -197.94  |proj g|=       0.93671
At iterate    34  f =      -197.94  |proj g|=       0.93316
At iterate    35  f =      -197.95  |proj g|=       0.92596
At iterate    36  f =         -198  |proj g|=       0.90635
At iterate    37  f =      -198.02  |proj g|=       0.88358
At iterate    38  f =      -198.14  |proj g|=       0.84402
At iterate    39  f =      -198.57  |proj g|=       0.85146
At iterate    40  f =      -198.74  |proj g|=       0.84394
At iterate    41  f =      -198.89  |proj g|=       0.82968
At iterate    42  f =       -198.9  |proj g|=       0.58324
At iterate    43  f =       -198.9  |proj g|=       0.14462
At iterate    44  f =       -198.9  |proj g|=      0.024271
At iterate    45  f =       -198.9  |proj g|=     0.0031186

iterations 45
function evaluations 55
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0031186
final function value -198.903

F = -198.903
final  value -198.903087 
converged
 
INFO  [07:00:20.738] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:00:20.853] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:00:20.865] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:00:28.487] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:00:36.553] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:00:44.189] [mlr3]  Finished benchmark 
INFO  [07:00:44.291] [bbotk] Result of batch 33: 
INFO  [07:00:44.293] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:00:44.293] [bbotk]              3.472986                 5.324932                       0.3066384 
INFO  [07:00:44.293] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:00:44.293] [bbotk]                     3483        0.565 -0.9711803         <NA>   0.9749997 
INFO  [07:00:44.293] [bbotk]                                 uhash 
INFO  [07:00:44.293] [bbotk]  41334bc1-30bf-48ad-ac55-0503bfa9ec01 
DEBUG [07:00:45.210] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.397086e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  4.397086e-05 0.005733179 
  - best initial criterion value(s) :  185.1139 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -185.11  |proj g|=        1.385
At iterate     1  f =      -190.71  |proj g|=        1.7119
At iterate     2  f =      -190.74  |proj g|=        1.7066
At iterate     3  f =      -190.77  |proj g|=        1.6986
At iterate     4  f =      -190.79  |proj g|=         1.701
At iterate     5  f =      -190.91  |proj g|=        1.7455
At iterate     6  f =         -191  |proj g|=        1.7989
At iterate     7  f =      -191.02  |proj g|=        1.8334
At iterate     8  f =      -191.02  |proj g|=        1.8419
At iterate     9  f =      -191.02  |proj g|=        1.8426
At iterate    10  f =      -191.02  |proj g|=        1.8426
At iterate    11  f =      -191.03  |proj g|=        1.8426
At iterate    12  f =      -191.03  |proj g|=        1.8425
At iterate    13  f =      -191.03  |proj g|=        1.8418
At iterate    14  f =      -191.03  |proj g|=        1.8392
At iterate    15  f =      -191.03  |proj g|=        1.8322
At iterate    16  f =      -191.04  |proj g|=        1.8164
At iterate    17  f =      -191.05  |proj g|=        1.8145
At iterate    18  f =      -191.08  |proj g|=        1.7955
At iterate    19  f =       -191.2  |proj g|=        1.7178
At iterate    20  f =      -191.41  |proj g|=        1.6285
At iterate    21  f =      -192.26  |proj g|=        1.3613
At iterate    22  f =      -193.87  |proj g|=        1.0171
At iterate    23  f =      -194.03  |proj g|=        1.0069
At iterate    24  f =      -195.25  |proj g|=        1.3828
At iterate    25  f =      -195.43  |proj g|=        1.4051
At iterate    26  f =      -195.51  |proj g|=        1.4113
At iterate    27  f =      -195.52  |proj g|=        1.4395
At iterate    28  f =      -195.52  |proj g|=        1.4389
At iterate    29  f =      -195.52  |proj g|=        1.4398
At iterate    30  f =      -195.52  |proj g|=        1.4404
At iterate    31  f =      -195.52  |proj g|=         1.441
At iterate    32  f =      -195.52  |proj g|=        1.4418
At iterate    33  f =      -195.52  |proj g|=        1.4433
At iterate    34  f =      -195.52  |proj g|=        1.4442
At iterate    35  f =      -195.52  |proj g|=        1.4445
At iterate    36  f =      -195.52  |proj g|=        1.4456
At iterate    37  f =      -195.52  |proj g|=        1.4544
At iterate    38  f =      -195.52  |proj g|=        1.4509
At iterate    39  f =      -195.52  |proj g|=        1.4461
At iterate    40  f =      -195.52  |proj g|=        1.4379
At iterate    41  f =      -195.52  |proj g|=        1.4259
At iterate    42  f =      -195.52  |proj g|=         1.408
At iterate    43  f =      -195.53  |proj g|=        1.3815
At iterate    44  f =      -195.55  |proj g|=        1.3392
At iterate    45  f =      -195.59  |proj g|=        1.2746
At iterate    46  f =      -195.69  |proj g|=        1.1934
At iterate    47  f =      -195.83  |proj g|=        1.1431
At iterate    48  f =      -195.94  |proj g|=        1.0885
At iterate    49  f =      -196.18  |proj g|=        1.2261
At iterate    50  f =       -196.4  |proj g|=        1.4773
At iterate    51  f =      -196.47  |proj g|=        1.6529
At iterate    52  f =      -196.48  |proj g|=         1.708
At iterate    53  f =      -196.49  |proj g|=        1.7511
At iterate    54  f =      -196.49  |proj g|=        1.7513
At iterate    55  f =      -196.49  |proj g|=        1.7407
At iterate    56  f =      -196.49  |proj g|=        1.7351
At iterate    57  f =       -196.5  |proj g|=        1.7072
At iterate    58  f =      -196.51  |proj g|=        1.6703
At iterate    59  f =      -196.55  |proj g|=        1.5908
At iterate    60  f =      -196.65  |proj g|=        1.4452
At iterate    61  f =      -196.91  |proj g|=        1.1644
At iterate    62  f =      -197.57  |proj g|=       0.71315
At iterate    63  f =       -198.9  |proj g|=       0.27848
At iterate    64  f =      -200.35  |proj g|=       0.80525
At iterate    65  f =      -200.93  |proj g|=       0.80275
At iterate    66  f =       -201.4  |proj g|=       0.18468
At iterate    67  f =      -201.58  |proj g|=       0.18117
At iterate    68  f =       -201.6  |proj g|=       0.81161
At iterate    69  f =      -201.61  |proj g|=       0.81351
At iterate    70  f =      -201.63  |proj g|=       0.16946
At iterate    71  f =      -201.63  |proj g|=      0.030189
At iterate    72  f =      -201.63  |proj g|=     0.0020341
At iterate    73  f =      -201.63  |proj g|=     0.0011326

iterations 73
function evaluations 81
segments explored during Cauchy searches 75
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0011326
final function value -201.627

F = -201.627
final  value -201.626831 
converged
 
INFO  [07:00:45.215] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:00:45.348] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:00:45.356] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:00:51.303] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:00:56.106] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:01:00.639] [mlr3]  Finished benchmark 
INFO  [07:01:00.797] [bbotk] Result of batch 34: 
INFO  [07:01:00.799] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:01:00.799] [bbotk]              8.727184                 3.750672                       0.3656113 
INFO  [07:01:00.799] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:01:00.799] [bbotk]                     2240        0.591 -0.9708133         <NA>   0.9768561 
INFO  [07:01:00.799] [bbotk]                                 uhash 
INFO  [07:01:00.799] [bbotk]  408f460f-961d-4ddd-8948-833e0dafa4ae 
DEBUG [07:01:01.867] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.339038e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  4.339038e-05 0.005823502 
  - best initial criterion value(s) :  189.171 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -189.17  |proj g|=       2.1291
At iterate     1  f =      -189.45  |proj g|=        2.3735
At iterate     2  f =      -190.77  |proj g|=        1.9603
At iterate     3  f =      -191.55  |proj g|=        1.5475
At iterate     4  f =      -191.85  |proj g|=        1.7822
At iterate     5  f =      -191.88  |proj g|=        1.7145
At iterate     6  f =      -191.89  |proj g|=        1.6895
At iterate     7  f =      -191.89  |proj g|=        1.6918
At iterate     8  f =      -191.89  |proj g|=        1.6934
At iterate     9  f =      -191.89  |proj g|=        1.6977
At iterate    10  f =      -191.89  |proj g|=        1.7034
At iterate    11  f =      -191.89  |proj g|=        1.7131
At iterate    12  f =      -191.89  |proj g|=        1.7275
At iterate    13  f =      -191.91  |proj g|=        1.7483
At iterate    14  f =      -191.94  |proj g|=        1.7742
At iterate    15  f =         -192  |proj g|=           1.8
At iterate    16  f =      -192.14  |proj g|=        1.8556
At iterate    17  f =      -192.44  |proj g|=        1.8245
At iterate    18  f =      -192.55  |proj g|=        1.8764
At iterate    19  f =      -193.53  |proj g|=        1.7978
At iterate    20  f =       -195.6  |proj g|=        1.7278
At iterate    21  f =      -198.59  |proj g|=        1.4969
At iterate    22  f =         -204  |proj g|=        1.1286
At iterate    23  f =      -206.99  |proj g|=       0.76426
At iterate    24  f =      -208.28  |proj g|=       0.24526
At iterate    25  f =      -208.57  |proj g|=        0.2075
At iterate    26  f =      -208.57  |proj g|=       0.82567
At iterate    27  f =      -208.57  |proj g|=       0.20722
At iterate    28  f =      -208.57  |proj g|=       0.20831
At iterate    29  f =      -208.57  |proj g|=        0.2081
At iterate    30  f =      -208.57  |proj g|=       0.20807

iterations 30
function evaluations 41
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.208067
final function value -208.575

F = -208.575
final  value -208.574745 
converged
 
INFO  [07:01:01.871] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:01:01.963] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:01:01.971] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:01:08.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:01:13.885] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:01:21.792] [mlr3]  Finished benchmark 
INFO  [07:01:21.944] [bbotk] Result of batch 35: 
INFO  [07:01:21.946] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:01:21.946] [bbotk]               3.37877                 4.384132                      0.08333839 
INFO  [07:01:21.946] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:01:21.946] [bbotk]                     2586        0.744 -0.9694832         <NA>   0.9653051 
INFO  [07:01:21.946] [bbotk]                                 uhash 
INFO  [07:01:21.946] [bbotk]  048aa25a-4273-4e70-8227-750d784f7834 
DEBUG [07:01:22.771] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.273991e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  4.273991e-05 0.0057684 
  - best initial criterion value(s) :  179.6361 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -179.64  |proj g|=       2.8932
At iterate     1  f =         -197  |proj g|=         3.691
At iterate     2  f =      -197.85  |proj g|=        4.4707
At iterate     3  f =       -198.3  |proj g|=         4.326
At iterate     4  f =      -198.57  |proj g|=        4.1262
At iterate     5  f =      -198.58  |proj g|=        4.0472
At iterate     6  f =      -198.58  |proj g|=        4.0688
At iterate     7  f =      -198.58  |proj g|=        4.0677
At iterate     8  f =      -198.58  |proj g|=        4.0654
At iterate     9  f =      -198.58  |proj g|=         4.065
At iterate    10  f =      -198.59  |proj g|=        4.0628
At iterate    11  f =       -198.6  |proj g|=        4.0561
At iterate    12  f =       -198.6  |proj g|=        4.0209
At iterate    13  f =      -198.62  |proj g|=        4.0102
At iterate    14  f =       -198.7  |proj g|=        3.9641
At iterate    15  f =      -198.87  |proj g|=        3.8436
At iterate    16  f =      -199.24  |proj g|=        3.5635
At iterate    17  f =      -199.99  |proj g|=        3.0301
At iterate    18  f =      -200.04  |proj g|=        3.1435
At iterate    19  f =      -201.23  |proj g|=        2.2625
At iterate    20  f =      -202.97  |proj g|=        1.5564
At iterate    21  f =      -205.69  |proj g|=        1.4363
At iterate    22  f =      -206.96  |proj g|=       0.91592
At iterate    23  f =      -209.12  |proj g|=        1.0417
At iterate    24  f =      -209.41  |proj g|=        1.0385
At iterate    25  f =      -210.04  |proj g|=       0.92917
At iterate    26  f =      -210.28  |proj g|=       0.75468
At iterate    27  f =      -210.28  |proj g|=       0.75465
At iterate    28  f =      -210.28  |proj g|=       0.75463
At iterate    29  f =      -210.28  |proj g|=       0.75463
At iterate    30  f =      -210.28  |proj g|=       0.75463

iterations 30
function evaluations 40
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.754633
final function value -210.28

F = -210.28
final  value -210.279890 
converged
 
INFO  [07:01:22.775] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:01:22.864] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:01:22.871] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:01:25.134] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:01:27.335] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:01:29.264] [mlr3]  Finished benchmark 
INFO  [07:01:29.422] [bbotk] Result of batch 36: 
INFO  [07:01:29.424] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:01:29.424] [bbotk]              7.977386                 2.797781                       0.4024221 
INFO  [07:01:29.424] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:01:29.424] [bbotk]                      898        0.576 -0.9707357         <NA>   0.9744478 
INFO  [07:01:29.424] [bbotk]                                 uhash 
INFO  [07:01:29.424] [bbotk]  58b28e89-5700-4181-9831-c59fdbc0fa7f 
DEBUG [07:01:30.347] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.214319e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  4.214319e-05 0.00560307 
  - best initial criterion value(s) :  194.7365 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -194.74  |proj g|=      0.64554
At iterate     1  f =       -202.2  |proj g|=        3.2868
At iterate     2  f =      -203.81  |proj g|=        3.1394
At iterate     3  f =      -206.03  |proj g|=        2.6288
At iterate     4  f =      -206.22  |proj g|=        2.4153
At iterate     5  f =       -206.5  |proj g|=        2.2959
At iterate     6  f =      -206.64  |proj g|=        2.3416
At iterate     7  f =      -206.65  |proj g|=         2.354
At iterate     8  f =      -206.66  |proj g|=        2.3367
At iterate     9  f =      -206.71  |proj g|=        2.2765
At iterate    10  f =      -206.83  |proj g|=        2.1841
At iterate    11  f =      -207.19  |proj g|=        1.9856
At iterate    12  f =      -208.22  |proj g|=        1.5986
At iterate    13  f =      -210.11  |proj g|=        1.3205
At iterate    14  f =      -210.82  |proj g|=         1.358
At iterate    15  f =      -210.86  |proj g|=         1.977
At iterate    16  f =      -211.34  |proj g|=        1.7983
At iterate    17  f =      -211.37  |proj g|=        1.7217
At iterate    18  f =      -211.37  |proj g|=        1.7267
At iterate    19  f =      -211.37  |proj g|=        1.7264
At iterate    20  f =      -211.37  |proj g|=        1.7262
At iterate    21  f =      -211.37  |proj g|=        1.7262
At iterate    22  f =      -211.37  |proj g|=        1.7257
At iterate    23  f =      -211.37  |proj g|=        1.7252
At iterate    24  f =      -211.37  |proj g|=        1.7243
At iterate    25  f =      -211.37  |proj g|=        1.7228
At iterate    26  f =      -211.37  |proj g|=        1.7217
At iterate    27  f =      -211.37  |proj g|=        1.7182
At iterate    28  f =      -211.37  |proj g|=        1.7169
At iterate    29  f =      -211.87  |proj g|=        1.5366
At iterate    30  f =      -214.57  |proj g|=        0.6117
At iterate    31  f =      -215.45  |proj g|=       0.34414
At iterate    32  f =      -216.03  |proj g|=       0.16381
At iterate    33  f =      -216.03  |proj g|=       0.82057
At iterate    34  f =      -216.26  |proj g|=       0.65583
At iterate    35  f =      -216.26  |proj g|=       0.38897
At iterate    36  f =      -216.26  |proj g|=       0.12326
At iterate    37  f =      -216.26  |proj g|=     0.0064665
At iterate    38  f =      -216.26  |proj g|=      0.092724
At iterate    39  f =      -216.26  |proj g|=      0.083438
At iterate    40  f =      -216.26  |proj g|=     0.0017575
At iterate    41  f =      -216.26  |proj g|=    0.00096546

iterations 41
function evaluations 50
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000965456
final function value -216.259

F = -216.259
final  value -216.259296 
converged
 
INFO  [07:01:30.352] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:01:30.441] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:01:30.449] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:01:32.069] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:01:33.573] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:01:35.934] [mlr3]  Finished benchmark 
INFO  [07:01:36.033] [bbotk] Result of batch 37: 
INFO  [07:01:36.035] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:01:36.035] [bbotk]              4.947648                  6.56598                       0.2668423 
INFO  [07:01:36.035] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:01:36.035] [bbotk]                      646        0.644 -0.9693504         <NA>   0.9682501 
INFO  [07:01:36.035] [bbotk]                                 uhash 
INFO  [07:01:36.035] [bbotk]  7a77b04a-cb2a-489b-84ee-e6b563404bd6 
DEBUG [07:01:36.931] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.151448e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  4.151448e-05 0.005445103 
  - best initial criterion value(s) :  200.4168 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -200.42  |proj g|=       1.2765
At iterate     1  f =      -202.17  |proj g|=         1.477
At iterate     2  f =      -203.96  |proj g|=        2.3529
At iterate     3  f =      -208.78  |proj g|=        2.0207
At iterate     4  f =         -209  |proj g|=        1.8384
At iterate     5  f =      -209.03  |proj g|=        1.8578
At iterate     6  f =      -209.03  |proj g|=        1.8544
At iterate     7  f =      -209.03  |proj g|=        1.8555
At iterate     8  f =      -209.03  |proj g|=        1.8559
At iterate     9  f =      -209.03  |proj g|=        1.8564
At iterate    10  f =      -209.03  |proj g|=         1.858
At iterate    11  f =      -209.03  |proj g|=        1.8601
At iterate    12  f =      -209.03  |proj g|=        1.8634
At iterate    13  f =      -209.03  |proj g|=        1.8679
At iterate    14  f =      -209.03  |proj g|=        1.8728
At iterate    15  f =      -209.04  |proj g|=        1.8786
At iterate    16  f =      -209.05  |proj g|=         1.876
At iterate    17  f =      -209.06  |proj g|=         1.899
At iterate    18  f =      -209.08  |proj g|=        1.8835
At iterate    19  f =      -209.27  |proj g|=        1.8218
At iterate    20  f =      -210.64  |proj g|=        1.4024
At iterate    21  f =      -213.45  |proj g|=        1.3031
At iterate    22  f =      -217.48  |proj g|=       0.97263
At iterate    23  f =       -219.4  |proj g|=       0.40263
At iterate    24  f =      -220.38  |proj g|=       0.39617
At iterate    25  f =      -220.81  |proj g|=       0.27587
At iterate    26  f =      -220.83  |proj g|=       0.82391
At iterate    27  f =      -220.83  |proj g|=       0.82078
At iterate    28  f =      -220.83  |proj g|=       0.26741
At iterate    29  f =      -220.83  |proj g|=       0.26811
At iterate    30  f =      -220.83  |proj g|=       0.26812

iterations 30
function evaluations 40
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.268117
final function value -220.833

F = -220.833
final  value -220.832625 
converged
 
INFO  [07:01:36.935] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:01:37.020] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:01:37.026] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:01:44.751] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:01:50.773] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:01:57.089] [mlr3]  Finished benchmark 
INFO  [07:01:57.188] [bbotk] Result of batch 38: 
INFO  [07:01:57.189] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:01:57.189] [bbotk]              6.127959                 6.977401                       0.2813976 
INFO  [07:01:57.189] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:01:57.189] [bbotk]                     2888        0.638 -0.9691549         <NA>   0.9767797 
INFO  [07:01:57.189] [bbotk]                                 uhash 
INFO  [07:01:57.189] [bbotk]  576b3811-cbeb-4de6-86f6-e9f2f5a216a0 
DEBUG [07:01:57.980] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.099879e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  4.099879e-05 0.005417483 
  - best initial criterion value(s) :  222.3719 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -222.37  |proj g|=      0.98803
At iterate     1  f =      -222.64  |proj g|=        1.0422
At iterate     2  f =      -222.66  |proj g|=        1.0476
At iterate     3  f =      -222.66  |proj g|=         1.045
At iterate     4  f =      -222.66  |proj g|=        1.0439
At iterate     5  f =      -222.66  |proj g|=         1.044

iterations 5
function evaluations 9
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.04397
final function value -222.662

F = -222.662
final  value -222.662166 
converged
 
INFO  [07:01:57.982] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:01:58.061] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:01:58.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:02:06.518] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:02:14.381] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:02:24.982] [mlr3]  Finished benchmark 
INFO  [07:02:25.101] [bbotk] Result of batch 39: 
INFO  [07:02:25.103] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:02:25.103] [bbotk]              2.407999                 4.486156                        0.166555 
INFO  [07:02:25.103] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:02:25.103] [bbotk]                     3864        0.596 -0.9710318         <NA>   0.9633049 
INFO  [07:02:25.103] [bbotk]                                 uhash 
INFO  [07:02:25.103] [bbotk]  f8f8f5be-4a1c-44be-a1f2-c0c450b20469 
DEBUG [07:02:26.138] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.044788e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  4.044788e-05 0.005371221 
  - best initial criterion value(s) :  199.512 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -199.51  |proj g|=        1.727
At iterate     1  f =      -208.72  |proj g|=        3.0644
At iterate     2  f =      -208.88  |proj g|=        3.0334
At iterate     3  f =      -209.07  |proj g|=        2.9097
At iterate     4  f =      -209.09  |proj g|=         2.951
At iterate     5  f =      -209.16  |proj g|=        3.0152
At iterate     6  f =      -209.38  |proj g|=        3.2467
At iterate     7  f =      -209.53  |proj g|=        3.4868
At iterate     8  f =       -209.6  |proj g|=        3.4318
At iterate     9  f =      -209.61  |proj g|=        3.5195
At iterate    10  f =      -210.78  |proj g|=        3.2991
At iterate    11  f =      -217.22  |proj g|=        1.7482
At iterate    12  f =      -221.53  |proj g|=        1.4084
At iterate    13  f =      -224.29  |proj g|=        1.2911
At iterate    14  f =      -226.42  |proj g|=        0.7987
At iterate    15  f =      -226.66  |proj g|=       0.79718
At iterate    16  f =      -226.74  |proj g|=       0.73055
At iterate    17  f =      -226.74  |proj g|=       0.73055
At iterate    18  f =      -226.74  |proj g|=       0.73055
At iterate    19  f =      -226.74  |proj g|=       0.73054
At iterate    20  f =      -226.74  |proj g|=        0.7305
At iterate    21  f =      -226.75  |proj g|=       0.73025
At iterate    22  f =      -226.76  |proj g|=       0.80384
At iterate    23  f =      -226.77  |proj g|=       0.80727
At iterate    24  f =      -226.77  |proj g|=       0.79292
At iterate    25  f =      -226.78  |proj g|=       0.72968
At iterate    26  f =      -226.78  |proj g|=       0.72968
At iterate    27  f =      -226.78  |proj g|=       0.72946
At iterate    28  f =      -226.78  |proj g|=       0.72585
At iterate    29  f =      -226.78  |proj g|=       0.72177
At iterate    30  f =      -226.81  |proj g|=       0.68312
At iterate    31  f =      -226.88  |proj g|=       0.58717
At iterate    32  f =      -227.08  |proj g|=       0.25949
At iterate    33  f =      -227.27  |proj g|=       0.21058
At iterate    34  f =      -227.39  |proj g|=       0.68201
At iterate    35  f =      -227.56  |proj g|=       0.18743
At iterate    36  f =      -227.57  |proj g|=       0.33472
At iterate    37  f =      -227.57  |proj g|=       0.55844
At iterate    38  f =      -227.57  |proj g|=       0.10285
At iterate    39  f =      -227.57  |proj g|=      0.026142
At iterate    40  f =      -227.57  |proj g|=      0.026136

iterations 40
function evaluations 49
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.026136
final function value -227.57

F = -227.57
final  value -227.570068 
converged
 
INFO  [07:02:26.142] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:02:26.228] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:02:26.235] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:02:28.579] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:02:31.163] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:02:33.924] [mlr3]  Finished benchmark 
INFO  [07:02:34.023] [bbotk] Result of batch 40: 
INFO  [07:02:34.025] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:02:34.025] [bbotk]               2.85113                  6.62978                       0.1146991 
INFO  [07:02:34.025] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:02:34.025] [bbotk]                     1109        0.571 -0.9704092         <NA>   0.9521249 
INFO  [07:02:34.025] [bbotk]                                 uhash 
INFO  [07:02:34.025] [bbotk]  b613c71e-f00a-41ab-a2bf-4b930826c77e 
DEBUG [07:02:34.864] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.025839e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  4.025839e-05 0.005281903 
  - best initial criterion value(s) :  191.6061 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -191.61  |proj g|=       5.1304
At iterate     1  f =      -203.66  |proj g|=        3.9599
At iterate     2  f =      -204.16  |proj g|=        4.6956
At iterate     3  f =      -206.49  |proj g|=        6.1938
At iterate     4  f =      -206.62  |proj g|=        5.9256
At iterate     5  f =      -206.63  |proj g|=        5.8397
At iterate     6  f =      -206.63  |proj g|=        5.8121
At iterate     7  f =      -206.63  |proj g|=        5.8043
At iterate     8  f =      -206.63  |proj g|=        5.7859
At iterate     9  f =      -206.64  |proj g|=        5.7571
At iterate    10  f =      -206.65  |proj g|=        5.7039
At iterate    11  f =      -206.68  |proj g|=        5.6047
At iterate    12  f =      -206.77  |proj g|=        5.4044
At iterate    13  f =         -207  |proj g|=         4.985
At iterate    14  f =      -207.57  |proj g|=        4.1728
At iterate    15  f =      -208.56  |proj g|=        3.0888
At iterate    16  f =      -208.84  |proj g|=        3.5621
At iterate    17  f =      -209.46  |proj g|=        2.5689
At iterate    18  f =      -210.36  |proj g|=        2.1551
At iterate    19  f =      -218.81  |proj g|=        2.2694
At iterate    20  f =      -220.41  |proj g|=        2.2423
At iterate    21  f =      -223.37  |proj g|=        2.1564
At iterate    22  f =      -224.92  |proj g|=          2.01
At iterate    23  f =      -224.93  |proj g|=        1.9861
At iterate    24  f =      -224.93  |proj g|=        1.9983
At iterate    25  f =      -224.93  |proj g|=        1.9979
At iterate    26  f =      -224.93  |proj g|=        1.9981
At iterate    27  f =      -224.93  |proj g|=        1.9979
At iterate    28  f =      -224.93  |proj g|=        1.9975
At iterate    29  f =      -224.93  |proj g|=        1.9942
At iterate    30  f =      -224.93  |proj g|=        1.9896
At iterate    31  f =      -224.94  |proj g|=        1.9824
At iterate    32  f =      -224.95  |proj g|=        1.9758
At iterate    33  f =      -224.95  |proj g|=          1.99
At iterate    34  f =      -224.95  |proj g|=        1.9807
At iterate    35  f =      -224.95  |proj g|=        1.9803
At iterate    36  f =      -224.95  |proj g|=        1.9802
At iterate    37  f =      -224.95  |proj g|=        1.9798
At iterate    38  f =      -224.95  |proj g|=        1.9789
At iterate    39  f =      -224.95  |proj g|=        1.9775
At iterate    40  f =      -224.95  |proj g|=        1.9713
At iterate    41  f =      -224.96  |proj g|=        1.9703
At iterate    42  f =      -224.99  |proj g|=        1.9479
At iterate    43  f =      -225.19  |proj g|=        1.8697
At iterate    44  f =      -225.74  |proj g|=         1.691
At iterate    45  f =      -227.32  |proj g|=        1.3524
At iterate    46  f =      -231.97  |proj g|=       0.86199
At iterate    47  f =      -232.88  |proj g|=        0.8531
At iterate    48  f =      -233.56  |proj g|=       0.83188
At iterate    49  f =      -233.65  |proj g|=       0.82089
At iterate    50  f =      -233.73  |proj g|=       0.81486
At iterate    51  f =      -233.74  |proj g|=      0.096684
At iterate    52  f =      -233.74  |proj g|=      0.024859
At iterate    53  f =      -233.74  |proj g|=      0.025114
At iterate    54  f =      -233.74  |proj g|=      0.025114

iterations 54
function evaluations 64
segments explored during Cauchy searches 57
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0251136
final function value -233.739

F = -233.739
final  value -233.739306 
converged
 
INFO  [07:02:34.869] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:02:34.973] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:02:34.980] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:02:41.220] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:02:46.918] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:02:52.243] [mlr3]  Finished benchmark 
INFO  [07:02:52.344] [bbotk] Result of batch 41: 
INFO  [07:02:52.346] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:02:52.346] [bbotk]              9.412063                 7.425663                      0.01219179 
INFO  [07:02:52.346] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:02:52.346] [bbotk]                     2783        0.549 -0.9681902         <NA>   0.9520068 
INFO  [07:02:52.346] [bbotk]                                 uhash 
INFO  [07:02:52.346] [bbotk]  d25e75b9-9503-4fe2-a5fd-2c83ff049110 
DEBUG [07:02:53.118] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.006899e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  4.006899e-05 0.005242771 
  - best initial criterion value(s) :  192.7363 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -192.74  |proj g|=       1.3766
At iterate     1  f =      -193.66  |proj g|=        1.1073
At iterate     2  f =      -193.84  |proj g|=        1.1075
At iterate     3  f =      -193.88  |proj g|=        1.1256
At iterate     4  f =      -194.71  |proj g|=        1.0802
At iterate     5  f =      -194.92  |proj g|=        1.0422
At iterate     6  f =      -194.94  |proj g|=        1.0367
At iterate     7  f =      -194.94  |proj g|=         1.036
At iterate     8  f =      -194.94  |proj g|=        1.0357
At iterate     9  f =      -194.94  |proj g|=        1.0357
At iterate    10  f =      -194.94  |proj g|=        1.0357

iterations 10
function evaluations 17
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.0357
final function value -194.941

F = -194.941
final  value -194.940809 
converged
 
INFO  [07:02:53.122] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:02:53.451] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:02:53.458] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:02:58.360] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:03:02.174] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:03:05.745] [mlr3]  Finished benchmark 
INFO  [07:03:05.846] [bbotk] Result of batch 42: 
INFO  [07:03:05.848] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:03:05.848] [bbotk]              3.851177                  2.74599                       0.1178528 
INFO  [07:03:05.848] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:03:05.848] [bbotk]                     1847        0.557 -0.9845851         <NA>    0.967836 
INFO  [07:03:05.848] [bbotk]                                 uhash 
INFO  [07:03:05.848] [bbotk]  dfb6f8af-7600-44d0-a1fd-ba6c263348c0 
DEBUG [07:03:06.646] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.951273e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  3.951273e-05 0.005199759 
  - best initial criterion value(s) :  222.7884 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -222.79  |proj g|=       2.6795
At iterate     1  f =      -222.99  |proj g|=        2.7258
At iterate     2  f =         -223  |proj g|=          2.72
At iterate     3  f =      -223.06  |proj g|=        2.6862
At iterate     4  f =      -223.14  |proj g|=        2.6436
At iterate     5  f =      -223.35  |proj g|=        2.5332
At iterate     6  f =       -223.5  |proj g|=        2.4439
At iterate     7  f =      -223.54  |proj g|=        2.4355
At iterate     8  f =      -223.54  |proj g|=        2.4435
At iterate     9  f =      -223.54  |proj g|=        2.4441
At iterate    10  f =      -223.54  |proj g|=        2.4448
At iterate    11  f =      -223.54  |proj g|=         2.446
At iterate    12  f =      -223.54  |proj g|=        2.4478
At iterate    13  f =      -223.54  |proj g|=        2.4506
At iterate    14  f =      -223.55  |proj g|=        2.4549
At iterate    15  f =      -223.56  |proj g|=        2.4624
At iterate    16  f =      -223.58  |proj g|=        2.4762
At iterate    17  f =      -223.63  |proj g|=        2.5017
At iterate    18  f =      -223.72  |proj g|=        2.5411
At iterate    19  f =      -223.78  |proj g|=        2.5543
At iterate    20  f =       -223.8  |proj g|=         2.568
At iterate    21  f =      -223.88  |proj g|=        2.5774
At iterate    22  f =      -224.46  |proj g|=          2.53
At iterate    23  f =      -226.91  |proj g|=         2.152
At iterate    24  f =      -229.74  |proj g|=         1.488
At iterate    25  f =      -236.15  |proj g|=       0.86156
At iterate    26  f =      -237.77  |proj g|=       0.46369
At iterate    27  f =      -238.15  |proj g|=       0.49849
At iterate    28  f =      -238.18  |proj g|=       0.84177
At iterate    29  f =      -238.18  |proj g|=       0.61873
At iterate    30  f =      -238.18  |proj g|=         0.475
At iterate    31  f =      -238.18  |proj g|=       0.47497

iterations 31
function evaluations 36
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.474965
final function value -238.185

F = -238.185
final  value -238.184544 
converged
 
INFO  [07:03:06.650] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:03:06.768] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:03:06.776] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:03:15.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:03:27.046] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:03:36.782] [mlr3]  Finished benchmark 
INFO  [07:03:36.915] [bbotk] Result of batch 43: 
INFO  [07:03:36.918] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:03:36.918] [bbotk]              9.246441                 3.953968                       0.2934935 
INFO  [07:03:36.918] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:03:36.918] [bbotk]                     4021        0.555 -0.9716997         <NA>   0.9775199 
INFO  [07:03:36.918] [bbotk]                                 uhash 
INFO  [07:03:36.918] [bbotk]  c3427e1a-124c-4e97-9493-69df19ac5995 
DEBUG [07:03:37.874] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.908731e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  3.908731e-05 0.005178599 
  - best initial criterion value(s) :  223.7586 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -223.76  |proj g|=       1.5413
At iterate     1  f =      -228.89  |proj g|=        2.3208
At iterate     2  f =      -228.91  |proj g|=        2.3052
At iterate     3  f =      -228.92  |proj g|=        2.2808
At iterate     4  f =      -228.92  |proj g|=        2.2779
At iterate     5  f =      -228.94  |proj g|=        2.2576
At iterate     6  f =         -229  |proj g|=        2.2477
At iterate     7  f =      -229.49  |proj g|=        2.1539
At iterate     8  f =      -230.54  |proj g|=        1.9649
At iterate     9  f =      -231.64  |proj g|=        1.5927
At iterate    10  f =      -236.07  |proj g|=        1.1462
At iterate    11  f =      -241.21  |proj g|=       0.88605
At iterate    12  f =      -242.48  |proj g|=       0.86718
At iterate    13  f =      -243.76  |proj g|=       0.85033
At iterate    14  f =      -244.19  |proj g|=       0.83503
At iterate    15  f =       -244.3  |proj g|=        0.7545
At iterate    16  f =      -244.32  |proj g|=       0.76445
At iterate    17  f =      -244.32  |proj g|=       0.76936
At iterate    18  f =      -244.32  |proj g|=       0.77143
At iterate    19  f =      -244.32  |proj g|=       0.77146

iterations 19
function evaluations 28
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.771464
final function value -244.317

F = -244.317
final  value -244.317281 
converged
 
INFO  [07:03:37.879] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:03:37.968] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:03:37.975] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:03:44.920] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:03:51.436] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:03:58.547] [mlr3]  Finished benchmark 
INFO  [07:03:58.649] [bbotk] Result of batch 44: 
INFO  [07:03:58.651] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:03:58.651] [bbotk]              4.450842                 7.184623                       0.2832525 
INFO  [07:03:58.651] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:03:58.651] [bbotk]                     2913          0.7 -0.9677264         <NA>   0.9759521 
INFO  [07:03:58.651] [bbotk]                                 uhash 
INFO  [07:03:58.651] [bbotk]  8f21bdd5-2a7e-4eba-a373-9a77152e7aa7 
DEBUG [07:03:59.471] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.863543e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  3.863543e-05 0.005152664 
  - best initial criterion value(s) :  227.9873 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -227.99  |proj g|=       2.7805
At iterate     1  f =      -228.34  |proj g|=        2.9445
At iterate     2  f =      -228.64  |proj g|=        2.8242
At iterate     3  f =      -229.27  |proj g|=        2.6119
At iterate     4  f =      -230.67  |proj g|=        2.2179
At iterate     5  f =      -231.69  |proj g|=        2.0083
At iterate     6  f =       -231.8  |proj g|=        2.1494
At iterate     7  f =      -231.81  |proj g|=        2.1231
At iterate     8  f =      -231.81  |proj g|=          2.12
At iterate     9  f =      -231.81  |proj g|=        2.1057
At iterate    10  f =      -231.82  |proj g|=        2.0907
At iterate    11  f =      -231.85  |proj g|=        2.0566
At iterate    12  f =      -231.91  |proj g|=        1.9973
At iterate    13  f =      -232.06  |proj g|=        1.8846
At iterate    14  f =      -232.47  |proj g|=         1.678
At iterate    15  f =      -233.31  |proj g|=        1.2808
At iterate    16  f =      -235.16  |proj g|=       0.95089
At iterate    17  f =      -237.76  |proj g|=       0.66523
At iterate    18  f =      -243.03  |proj g|=       0.14187
At iterate    19  f =      -243.38  |proj g|=       0.86377
At iterate    20  f =      -243.73  |proj g|=       0.85821
At iterate    21  f =      -243.82  |proj g|=       0.85167
At iterate    22  f =      -243.84  |proj g|=       0.84739
At iterate    23  f =      -243.84  |proj g|=       0.20974
At iterate    24  f =      -243.84  |proj g|=       0.14182
At iterate    25  f =      -243.84  |proj g|=       0.14182
At iterate    26  f =      -243.84  |proj g|=       0.14182

iterations 26
function evaluations 31
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.14182
final function value -243.844

F = -243.844
final  value -243.844069 
converged
 
INFO  [07:03:59.475] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:03:59.598] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:03:59.605] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:04:07.271] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:04:14.960] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:04:21.755] [mlr3]  Finished benchmark 
INFO  [07:04:21.857] [bbotk] Result of batch 45: 
INFO  [07:04:21.859] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:04:21.859] [bbotk]              8.249558                 2.414252                        0.499223 
INFO  [07:04:21.859] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:04:21.859] [bbotk]                     3778        0.579 -0.9736103         <NA>   0.9779754 
INFO  [07:04:21.859] [bbotk]                                 uhash 
INFO  [07:04:21.859] [bbotk]  d41ef907-21eb-4d74-a5fb-635b14eed846 
DEBUG [07:04:22.844] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.823876e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  3.823876e-05 0.005127848 
  - best initial criterion value(s) :  245.7878 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -245.79  |proj g|=      0.45667
At iterate     1  f =      -247.71  |proj g|=       0.92008
At iterate     2  f =       -250.8  |proj g|=       0.86497
At iterate     3  f =      -254.11  |proj g|=       0.85672
At iterate     4  f =      -254.12  |proj g|=       0.85575
At iterate     5  f =      -254.17  |proj g|=       0.85196
At iterate     6  f =      -254.23  |proj g|=        0.8446
At iterate     7  f =      -254.23  |proj g|=       0.84312
At iterate     8  f =      -254.23  |proj g|=        0.8429
At iterate     9  f =      -254.23  |proj g|=       0.84291
At iterate    10  f =      -254.23  |proj g|=       0.84292

iterations 10
function evaluations 13
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.842917
final function value -254.234

F = -254.234
final  value -254.233969 
converged
 
INFO  [07:04:22.848] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:04:23.100] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:04:23.107] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:04:26.012] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:04:28.850] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:04:31.737] [mlr3]  Finished benchmark 
INFO  [07:04:31.866] [bbotk] Result of batch 46: 
INFO  [07:04:31.869] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:04:31.869] [bbotk]              8.696005                 8.043635                      0.02428771 
INFO  [07:04:31.869] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:04:31.869] [bbotk]                     1796        0.744 -0.9692168         <NA>    0.955241 
INFO  [07:04:31.869] [bbotk]                                 uhash 
INFO  [07:04:31.869] [bbotk]  f43a7710-bb90-4093-8711-2356130bc9cd 
DEBUG [07:04:32.734] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.796779e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  3.796779e-05 0.005099139 
  - best initial criterion value(s) :  229.9658 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -229.97  |proj g|=      0.38641
At iterate     1  f =      -247.08  |proj g|=       0.91483
At iterate     2  f =      -247.59  |proj g|=       0.91409
At iterate     3  f =      -248.71  |proj g|=        0.9116
At iterate     4  f =      -248.95  |proj g|=       0.90878
At iterate     5  f =      -249.07  |proj g|=       0.90911
At iterate     6  f =      -249.24  |proj g|=       0.90835
At iterate     7  f =      -250.19  |proj g|=       0.90115
At iterate     8  f =       -251.6  |proj g|=       0.88526
At iterate     9  f =      -253.05  |proj g|=       0.89965
At iterate    10  f =      -253.59  |proj g|=       0.91757
At iterate    11  f =      -253.69  |proj g|=        0.9124
At iterate    12  f =       -253.7  |proj g|=        0.9042
At iterate    13  f =       -253.7  |proj g|=       0.90115
At iterate    14  f =       -253.7  |proj g|=       0.90094
At iterate    15  f =       -253.7  |proj g|=       0.90091
At iterate    16  f =       -253.7  |proj g|=       0.90089
At iterate    17  f =       -253.7  |proj g|=       0.90086
At iterate    18  f =       -253.7  |proj g|=       0.90082
At iterate    19  f =       -253.7  |proj g|=       0.90075
At iterate    20  f =       -253.7  |proj g|=       0.90069
At iterate    21  f =       -253.7  |proj g|=       0.90076
At iterate    22  f =       -253.7  |proj g|=       0.90117
At iterate    23  f =       -253.7  |proj g|=       0.90144
At iterate    24  f =       -253.7  |proj g|=       0.90333
At iterate    25  f =       -253.7  |proj g|=       0.90145
At iterate    26  f =      -253.71  |proj g|=       0.90295
At iterate    27  f =      -253.74  |proj g|=       0.90407
At iterate    28  f =      -253.86  |proj g|=       0.75678
At iterate    29  f =      -254.29  |proj g|=       0.71224
At iterate    30  f =      -254.41  |proj g|=       0.71089
At iterate    31  f =      -254.44  |proj g|=       0.68716
At iterate    32  f =      -254.53  |proj g|=       0.83755
At iterate    33  f =      -254.53  |proj g|=       0.69012
At iterate    34  f =      -254.53  |proj g|=       0.68918
At iterate    35  f =      -254.53  |proj g|=       0.68923

iterations 35
function evaluations 42
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.689234
final function value -254.532

F = -254.532
final  value -254.532325 
converged
 
INFO  [07:04:32.739] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:04:32.841] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:04:32.849] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:04:39.474] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:04:46.037] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:04:52.980] [mlr3]  Finished benchmark 
INFO  [07:04:53.101] [bbotk] Result of batch 47: 
INFO  [07:04:53.103] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:04:53.103] [bbotk]              6.109067                 3.388727                       0.2866609 
INFO  [07:04:53.103] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:04:53.103] [bbotk]                     4203        0.579 -0.9705478         <NA>    0.977568 
INFO  [07:04:53.103] [bbotk]                                 uhash 
INFO  [07:04:53.103] [bbotk]  2301a8c9-6538-4b9c-9bc4-14ea73ea5367 
DEBUG [07:04:54.053] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.758157e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  3.758157e-05 0.005079396 
  - best initial criterion value(s) :  240.4485 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -240.45  |proj g|=       2.3103
At iterate     1  f =      -241.75  |proj g|=        2.7286
At iterate     2  f =      -243.51  |proj g|=        2.4894
At iterate     3  f =      -243.73  |proj g|=        2.3623
At iterate     4  f =      -243.86  |proj g|=        2.4169
At iterate     5  f =      -243.87  |proj g|=         2.421
At iterate     6  f =      -243.87  |proj g|=        2.4241
At iterate     7  f =      -243.87  |proj g|=        2.4235
At iterate     8  f =      -243.87  |proj g|=        2.4234
At iterate     9  f =      -243.87  |proj g|=        2.4229
At iterate    10  f =      -243.87  |proj g|=        2.4222
At iterate    11  f =      -243.87  |proj g|=         2.421
At iterate    12  f =      -243.87  |proj g|=        2.4191
At iterate    13  f =      -243.87  |proj g|=        2.4161
At iterate    14  f =      -243.87  |proj g|=        2.4118
At iterate    15  f =      -243.88  |proj g|=         2.407
At iterate    16  f =      -243.89  |proj g|=        2.4017
At iterate    17  f =       -243.9  |proj g|=        2.3658
At iterate    18  f =      -243.94  |proj g|=        2.3647
At iterate    19  f =      -244.25  |proj g|=        2.3119
At iterate    20  f =      -244.76  |proj g|=        2.1897
At iterate    21  f =      -246.24  |proj g|=        1.8319
At iterate    22  f =      -248.95  |proj g|=        1.3064
At iterate    23  f =      -252.82  |proj g|=       0.88977
At iterate    24  f =      -253.52  |proj g|=       0.88873
At iterate    25  f =      -254.63  |proj g|=       0.86989
At iterate    26  f =      -254.91  |proj g|=       0.85594
At iterate    27  f =      -254.94  |proj g|=       0.85129
At iterate    28  f =      -254.94  |proj g|=       0.57938
At iterate    29  f =      -254.94  |proj g|=       0.57974
At iterate    30  f =      -254.94  |proj g|=       0.57982

iterations 30
function evaluations 34
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.579822
final function value -254.936

F = -254.936
final  value -254.936499 
converged
 
INFO  [07:04:54.057] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:04:54.147] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:04:54.154] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:05:02.244] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:05:10.058] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:05:18.465] [mlr3]  Finished benchmark 
INFO  [07:05:18.563] [bbotk] Result of batch 48: 
INFO  [07:05:18.564] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:05:18.564] [bbotk]               6.46536                  5.16182                      0.04023698 
INFO  [07:05:18.564] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:05:18.564] [bbotk]                     4862        0.661 -0.9729501         <NA>   0.9709007 
INFO  [07:05:18.564] [bbotk]                                 uhash 
INFO  [07:05:18.564] [bbotk]  1176138d-cfc6-4e75-b6bf-5643c42a36d9 
DEBUG [07:05:19.430] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.710672e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  3.710672e-05 0.005038659 
  - best initial criterion value(s) :  235.0965 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -235.1  |proj g|=       3.8004
At iterate     1  f =      -237.97  |proj g|=        5.1433
At iterate     2  f =      -238.06  |proj g|=        5.0695
At iterate     3  f =      -238.65  |proj g|=        4.2365
At iterate     4  f =      -239.02  |proj g|=        4.1152
At iterate     5  f =      -239.92  |proj g|=        3.5826
At iterate     6  f =      -239.92  |proj g|=        3.6005
At iterate     7  f =      -239.93  |proj g|=        3.6044
At iterate     8  f =      -239.94  |proj g|=        3.6331
At iterate     9  f =      -239.97  |proj g|=         3.606
At iterate    10  f =      -240.03  |proj g|=        3.6477
At iterate    11  f =       -240.2  |proj g|=        3.3701
At iterate    12  f =       -240.8  |proj g|=        3.3348
At iterate    13  f =      -246.74  |proj g|=        2.2334
At iterate    14  f =      -256.14  |proj g|=        1.1875
At iterate    15  f =      -262.68  |proj g|=       0.83606
At iterate    16  f =      -262.97  |proj g|=       0.83488
At iterate    17  f =      -263.08  |proj g|=       0.82484
At iterate    18  f =      -263.08  |proj g|=       0.67565
At iterate    19  f =      -263.08  |proj g|=       0.67565
At iterate    20  f =      -263.08  |proj g|=       0.67565
At iterate    21  f =      -263.08  |proj g|=       0.67564
At iterate    22  f =      -263.08  |proj g|=       0.67564
At iterate    23  f =      -263.08  |proj g|=       0.67562
At iterate    24  f =      -263.08  |proj g|=       0.67558
At iterate    25  f =      -263.08  |proj g|=       0.67557
At iterate    26  f =      -263.08  |proj g|=       0.67547
At iterate    27  f =      -263.08  |proj g|=       0.67475
At iterate    28  f =      -263.09  |proj g|=       0.66492
At iterate    29  f =      -263.11  |proj g|=       0.63443
At iterate    30  f =      -263.18  |proj g|=       0.51038
At iterate    31  f =      -263.25  |proj g|=       0.80077
At iterate    32  f =      -263.44  |proj g|=       0.20004
At iterate    33  f =      -263.58  |proj g|=       0.19214
At iterate    34  f =      -263.69  |proj g|=       0.17973
At iterate    35  f =      -263.73  |proj g|=       0.17275
At iterate    36  f =      -263.73  |proj g|=     0.0096076
At iterate    37  f =      -263.73  |proj g|=      0.002563
At iterate    38  f =      -263.73  |proj g|=     0.0037359

iterations 38
function evaluations 44
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0037359
final function value -263.731

F = -263.731
final  value -263.731016 
converged
 
INFO  [07:05:19.435] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:05:19.521] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:05:19.541] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:05:25.901] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:05:31.958] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:05:39.292] [mlr3]  Finished benchmark 
INFO  [07:05:39.413] [bbotk] Result of batch 49: 
INFO  [07:05:39.415] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:05:39.415] [bbotk]              5.347765                 6.210595                       0.3083115 
INFO  [07:05:39.415] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:05:39.415] [bbotk]                     3711        0.579 -0.9669745         <NA>   0.9772328 
INFO  [07:05:39.415] [bbotk]                                 uhash 
INFO  [07:05:39.415] [bbotk]  7500b7a7-0791-4161-8655-6b9afb6bc908 
DEBUG [07:05:40.346] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.67305e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  3.67305e-05 0.005013331 
  - best initial criterion value(s) :  234.3208 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -234.32  |proj g|=       1.1715
At iterate     1  f =       -252.6  |proj g|=        2.0466
At iterate     2  f =      -253.91  |proj g|=        1.9169
At iterate     3  f =      -255.32  |proj g|=        1.0954
At iterate     4  f =      -255.84  |proj g|=        1.4807
At iterate     5  f =      -255.93  |proj g|=        1.4247
At iterate     6  f =       -256.2  |proj g|=        1.2807
At iterate     7  f =      -256.59  |proj g|=        1.1792
At iterate     8  f =      -256.81  |proj g|=        1.3738
At iterate     9  f =      -257.04  |proj g|=        1.2573
At iterate    10  f =      -257.06  |proj g|=        1.2434
At iterate    11  f =      -257.06  |proj g|=        1.2472
At iterate    12  f =      -257.06  |proj g|=        1.2505
At iterate    13  f =      -257.06  |proj g|=        1.2514
At iterate    14  f =      -257.06  |proj g|=        1.2521
At iterate    15  f =      -257.06  |proj g|=        1.2538
At iterate    16  f =      -257.06  |proj g|=        1.2561
At iterate    17  f =      -257.06  |proj g|=        1.2599
At iterate    18  f =      -257.06  |proj g|=         1.266
At iterate    19  f =      -257.06  |proj g|=        1.2757
At iterate    20  f =      -257.07  |proj g|=        1.2907
At iterate    21  f =      -257.08  |proj g|=        1.3117
At iterate    22  f =      -257.11  |proj g|=         1.333
At iterate    23  f =      -257.16  |proj g|=        1.3305
At iterate    24  f =      -257.17  |proj g|=         1.288
At iterate    25  f =      -257.18  |proj g|=        1.2875
At iterate    26  f =      -257.56  |proj g|=        1.2172
At iterate    27  f =       -259.2  |proj g|=        1.4217
At iterate    28  f =      -259.51  |proj g|=        1.4852
At iterate    29  f =      -259.52  |proj g|=        1.4683
At iterate    30  f =      -259.52  |proj g|=        1.4662
At iterate    31  f =      -259.52  |proj g|=        1.4665
At iterate    32  f =      -259.52  |proj g|=        1.4667
At iterate    33  f =      -259.52  |proj g|=        1.4669
At iterate    34  f =      -259.52  |proj g|=        1.4672
At iterate    35  f =      -259.52  |proj g|=        1.4677
At iterate    36  f =      -259.52  |proj g|=        1.4686
At iterate    37  f =      -259.52  |proj g|=        1.4699
At iterate    38  f =      -259.52  |proj g|=        1.4718
At iterate    39  f =      -259.52  |proj g|=        1.4741
At iterate    40  f =      -259.52  |proj g|=        1.4748
At iterate    41  f =      -259.53  |proj g|=        1.4677
At iterate    42  f =      -259.53  |proj g|=        1.4675
At iterate    43  f =      -259.53  |proj g|=        1.4654
At iterate    44  f =      -259.53  |proj g|=        1.4631
At iterate    45  f =      -259.54  |proj g|=        1.4583
At iterate    46  f =      -259.56  |proj g|=        1.4496
At iterate    47  f =      -259.61  |proj g|=        1.4312
At iterate    48  f =      -259.73  |proj g|=        1.4092
At iterate    49  f =      -259.75  |proj g|=        1.3725
At iterate    50  f =      -260.01  |proj g|=        1.3281
At iterate    51  f =      -264.57  |proj g|=       0.21401
At iterate    52  f =      -264.74  |proj g|=       0.80746
At iterate    53  f =      -264.75  |proj g|=       0.80709
At iterate    54  f =      -264.75  |proj g|=     0.0095045
At iterate    55  f =      -264.75  |proj g|=     0.0049831
At iterate    56  f =      -264.75  |proj g|=      0.002515

iterations 56
function evaluations 64
segments explored during Cauchy searches 58
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00251504
final function value -264.75

F = -264.75
final  value -264.749728 
converged
 
INFO  [07:05:40.351] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:05:40.438] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:05:40.445] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:05:50.269] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:06:02.740] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:06:11.929] [mlr3]  Finished benchmark 
INFO  [07:06:12.027] [bbotk] Result of batch 50: 
INFO  [07:06:12.029] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:06:12.029] [bbotk]              9.280033                 8.181079                      0.07288311 
INFO  [07:06:12.029] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:06:12.029] [bbotk]                     4507        0.602 -0.9634207         <NA>   0.9742923 
INFO  [07:06:12.029] [bbotk]                                 uhash 
INFO  [07:06:12.029] [bbotk]  78d1088c-7e34-4f5f-92dd-c20bcdaff72b 
DEBUG [07:06:12.924] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.631007e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  3.631007e-05 0.004977667 
  - best initial criterion value(s) :  253.9663 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -253.97  |proj g|=       1.6992
At iterate     1  f =      -254.95  |proj g|=        1.7887
At iterate     2  f =      -257.08  |proj g|=        1.6631
At iterate     3  f =      -258.69  |proj g|=        1.4904
At iterate     4  f =      -258.96  |proj g|=        1.4168
At iterate     5  f =      -259.08  |proj g|=        1.4773
At iterate     6  f =      -259.09  |proj g|=        1.4585
At iterate     7  f =      -259.09  |proj g|=        1.4591
At iterate     8  f =      -259.09  |proj g|=        1.4591
At iterate     9  f =      -259.09  |proj g|=        1.4591
At iterate    10  f =      -259.09  |proj g|=        1.4591
At iterate    11  f =      -259.09  |proj g|=         1.459
At iterate    12  f =      -259.09  |proj g|=         1.459
At iterate    13  f =      -259.09  |proj g|=        1.4589
At iterate    14  f =      -259.09  |proj g|=         1.459
At iterate    15  f =       -259.1  |proj g|=        1.4598
At iterate    16  f =       -259.1  |proj g|=        1.4631
At iterate    17  f =      -259.11  |proj g|=        1.4708
At iterate    18  f =      -259.11  |proj g|=        1.4695
At iterate    19  f =      -259.13  |proj g|=        1.4757
At iterate    20  f =      -263.47  |proj g|=        1.1769
At iterate    21  f =      -269.53  |proj g|=       0.62729
At iterate    22  f =      -269.61  |proj g|=       0.63337
At iterate    23  f =      -269.62  |proj g|=       0.63149
At iterate    24  f =      -269.62  |proj g|=       0.62922
At iterate    25  f =      -269.62  |proj g|=       0.62899
At iterate    26  f =      -269.78  |proj g|=       0.60712
At iterate    27  f =      -270.37  |proj g|=       0.16637
At iterate    28  f =      -270.45  |proj g|=       0.16047
At iterate    29  f =      -270.49  |proj g|=       0.84416
At iterate    30  f =      -270.49  |proj g|=       0.15289
At iterate    31  f =      -270.49  |proj g|=       0.15302
At iterate    32  f =      -270.49  |proj g|=     0.0084287
At iterate    33  f =      -270.49  |proj g|=      0.006738

iterations 33
function evaluations 50
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00673799
final function value -270.487

F = -270.487
final  value -270.486857 
converged
 
INFO  [07:06:12.928] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:06:13.016] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:06:13.023] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:06:19.017] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:06:26.023] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:06:31.283] [mlr3]  Finished benchmark 
INFO  [07:06:31.382] [bbotk] Result of batch 51: 
INFO  [07:06:31.384] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:06:31.384] [bbotk]              4.723646                 5.496495                       0.4674188 
INFO  [07:06:31.384] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:06:31.384] [bbotk]                     2462        0.598 -0.9721835         <NA>   0.9769871 
INFO  [07:06:31.384] [bbotk]                                 uhash 
INFO  [07:06:31.384] [bbotk]  d630e985-c677-450a-accd-0a7ee0f53a58 
DEBUG [07:06:32.481] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.59443e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  3.59443e-05 0.004955327 
  - best initial criterion value(s) :  250.6742 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -250.67  |proj g|=       2.7492
At iterate     1  f =      -256.48  |proj g|=         1.754
At iterate     2  f =      -257.72  |proj g|=        2.6151
At iterate     3  f =       -260.6  |proj g|=        2.4116
At iterate     4  f =      -260.61  |proj g|=        2.4704
At iterate     5  f =      -260.61  |proj g|=        2.4678
At iterate     6  f =      -260.61  |proj g|=        2.4663
At iterate     7  f =      -260.61  |proj g|=          2.46
At iterate     8  f =      -260.61  |proj g|=        2.4507
At iterate     9  f =      -260.62  |proj g|=        2.4345
At iterate    10  f =      -260.62  |proj g|=        2.4075
At iterate    11  f =      -260.64  |proj g|=        2.3611
At iterate    12  f =      -260.69  |proj g|=         2.279
At iterate    13  f =      -260.83  |proj g|=        2.1334
At iterate    14  f =      -261.14  |proj g|=        1.9056
At iterate    15  f =      -261.65  |proj g|=        1.6834
At iterate    16  f =      -261.84  |proj g|=        1.9986
At iterate    17  f =       -262.1  |proj g|=         1.722
At iterate    18  f =      -262.27  |proj g|=        1.6225
At iterate    19  f =      -270.51  |proj g|=        1.1778
At iterate    20  f =      -274.15  |proj g|=        1.0015
At iterate    21  f =      -274.26  |proj g|=       0.98011
At iterate    22  f =      -274.29  |proj g|=       0.94993
At iterate    23  f =      -274.29  |proj g|=       0.95019
At iterate    24  f =      -274.29  |proj g|=       0.94987
At iterate    25  f =      -274.29  |proj g|=       0.94953
At iterate    26  f =      -274.29  |proj g|=       0.94916
At iterate    27  f =      -274.29  |proj g|=       0.94841
At iterate    28  f =      -274.29  |proj g|=       0.94809
At iterate    29  f =      -274.29  |proj g|=       0.94593
At iterate    30  f =      -274.29  |proj g|=       0.94532
At iterate    31  f =       -274.3  |proj g|=       0.94316
At iterate    32  f =      -274.36  |proj g|=        0.9309
At iterate    33  f =       -274.6  |proj g|=       0.88592
At iterate    34  f =      -275.36  |proj g|=       0.85121
At iterate    35  f =      -275.92  |proj g|=       0.84484
At iterate    36  f =      -276.22  |proj g|=       0.17838
At iterate    37  f =      -276.26  |proj g|=      0.091662
At iterate    38  f =      -276.26  |proj g|=      0.063789
At iterate    39  f =      -276.26  |proj g|=      0.010728
At iterate    40  f =      -276.26  |proj g|=     0.0035894

iterations 40
function evaluations 50
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00358938
final function value -276.255

F = -276.255
final  value -276.255391 
converged
 
INFO  [07:06:32.486] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:06:32.591] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:06:32.598] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:06:40.794] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:06:48.975] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:06:56.680] [mlr3]  Finished benchmark 
INFO  [07:06:56.779] [bbotk] Result of batch 52: 
INFO  [07:06:56.781] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:06:56.781] [bbotk]               5.51154                 2.808546                       0.4731164 
INFO  [07:06:56.781] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:06:56.781] [bbotk]                     3858        0.754 -0.9669684         <NA>    0.978278 
INFO  [07:06:56.781] [bbotk]                                 uhash 
INFO  [07:06:56.781] [bbotk]  ee4def92-45f7-4fcc-86c9-f5482a4a6f52 
DEBUG [07:06:57.868] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.561276e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  3.561276e-05 0.004933342 
  - best initial criterion value(s) :  219.0549 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -219.05  |proj g|=       15.655
At iterate     1  f =      -235.31  |proj g|=        2.9662
At iterate     2  f =      -250.95  |proj g|=        4.6394
At iterate     3  f =      -252.69  |proj g|=        5.1476
At iterate     4  f =      -263.39  |proj g|=        3.6539
At iterate     5  f =      -263.78  |proj g|=         3.295
At iterate     6  f =      -263.82  |proj g|=        3.3138
At iterate     7  f =      -263.83  |proj g|=        3.2484
At iterate     8  f =      -263.83  |proj g|=        3.2564
At iterate     9  f =      -263.83  |proj g|=        3.2562
At iterate    10  f =      -263.83  |proj g|=         3.256
At iterate    11  f =      -263.83  |proj g|=        3.2555
At iterate    12  f =      -263.83  |proj g|=        3.2548
At iterate    13  f =      -263.83  |proj g|=        3.2537
At iterate    14  f =      -263.83  |proj g|=         3.252
At iterate    15  f =      -263.83  |proj g|=        3.2503
At iterate    16  f =      -263.83  |proj g|=         3.244
At iterate    17  f =      -263.83  |proj g|=        3.2409
At iterate    18  f =      -263.83  |proj g|=        3.1978
At iterate    19  f =      -263.84  |proj g|=        3.2115
At iterate    20  f =      -263.87  |proj g|=        3.2485
At iterate    21  f =      -263.93  |proj g|=        3.2777
At iterate    22  f =      -264.11  |proj g|=        3.2896
At iterate    23  f =      -264.53  |proj g|=        3.2111
At iterate    24  f =      -265.53  |proj g|=        2.9983
At iterate    25  f =      -267.83  |proj g|=        2.4488
At iterate    26  f =      -272.15  |proj g|=        1.6812
At iterate    27  f =      -273.69  |proj g|=        1.4122
At iterate    28  f =      -278.51  |proj g|=       0.83575
At iterate    29  f =      -279.05  |proj g|=       0.83066
At iterate    30  f =      -279.13  |proj g|=       0.50594
At iterate    31  f =      -279.15  |proj g|=       0.20215
At iterate    32  f =      -279.15  |proj g|=      0.044619
At iterate    33  f =      -279.15  |proj g|=      0.002667
At iterate    34  f =      -279.15  |proj g|=     0.0026671

iterations 34
function evaluations 43
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0026671
final function value -279.147

F = -279.147
final  value -279.147415 
converged
 
INFO  [07:06:57.871] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:06:57.969] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:06:57.975] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:07:00.431] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:07:02.813] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:07:05.418] [mlr3]  Finished benchmark 
INFO  [07:07:05.520] [bbotk] Result of batch 53: 
INFO  [07:07:05.522] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:07:05.522] [bbotk]              4.940291                 4.497895                       0.4386198 
INFO  [07:07:05.522] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:07:05.522] [bbotk]                      911        0.746 -0.9652562         <NA>   0.9736804 
INFO  [07:07:05.522] [bbotk]                                 uhash 
INFO  [07:07:05.522] [bbotk]  fd110e6d-1487-4234-b2d3-d85143d76016 
DEBUG [07:07:06.392] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.521004e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  3.521004e-05 0.004820314 
  - best initial criterion value(s) :  235.2542 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -235.25  |proj g|=       1.0584
At iterate     1  f =      -262.97  |proj g|=        2.3829
At iterate     2  f =      -263.03  |proj g|=         2.492
At iterate     3  f =      -263.33  |proj g|=         2.451
At iterate     4  f =      -263.37  |proj g|=        2.4212
At iterate     5  f =      -263.38  |proj g|=        2.4247
At iterate     6  f =      -263.39  |proj g|=        2.4208
At iterate     7  f =      -263.39  |proj g|=         2.417
At iterate     8  f =      -263.39  |proj g|=        2.4163
At iterate     9  f =      -263.39  |proj g|=        2.4159
At iterate    10  f =      -265.85  |proj g|=        2.0206
At iterate    11  f =      -271.76  |proj g|=        1.1573
At iterate    12  f =      -275.54  |proj g|=       0.83094
At iterate    13  f =       -275.8  |proj g|=       0.83832
At iterate    14  f =      -276.04  |proj g|=       0.36558
At iterate    15  f =      -276.05  |proj g|=       0.36559
At iterate    16  f =      -276.06  |proj g|=       0.36559
At iterate    17  f =      -276.06  |proj g|=       0.36559
At iterate    18  f =      -276.06  |proj g|=       0.36559
At iterate    19  f =      -276.06  |proj g|=       0.36559

iterations 19
function evaluations 32
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.365586
final function value -276.058

F = -276.058
final  value -276.058287 
converged
 
INFO  [07:07:06.396] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:07:06.485] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:07:06.493] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:07:14.369] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:07:21.707] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:07:30.275] [mlr3]  Finished benchmark 
INFO  [07:07:30.408] [bbotk] Result of batch 54: 
INFO  [07:07:30.410] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:07:30.410] [bbotk]              8.543997                 6.519966                      0.08250231 
INFO  [07:07:30.410] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:07:30.410] [bbotk]                     3184        0.604 -0.9736819         <NA>   0.9733638 
INFO  [07:07:30.410] [bbotk]                                 uhash 
INFO  [07:07:30.410] [bbotk]  295884ea-5cfa-45a5-93ee-35877c7668bf 
DEBUG [07:07:31.302] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.481295e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  3.481295e-05 0.004789312 
  - best initial criterion value(s) :  268.2014 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -268.2  |proj g|=       2.2844
At iterate     1  f =      -272.93  |proj g|=        2.5317
At iterate     2  f =      -273.38  |proj g|=        2.3427
At iterate     3  f =      -273.47  |proj g|=        2.3115
At iterate     4  f =      -273.51  |proj g|=        2.3234
At iterate     5  f =      -273.51  |proj g|=         2.332
At iterate     6  f =      -273.51  |proj g|=        2.3309
At iterate     7  f =      -273.51  |proj g|=        2.3309
At iterate     8  f =      -273.51  |proj g|=        2.3305
At iterate     9  f =      -273.51  |proj g|=        2.3299
At iterate    10  f =      -273.51  |proj g|=        2.3289
At iterate    11  f =      -273.51  |proj g|=        2.3272
At iterate    12  f =      -273.52  |proj g|=        2.3248
At iterate    13  f =      -273.52  |proj g|=        2.3219
At iterate    14  f =      -273.52  |proj g|=        2.3196
At iterate    15  f =      -273.53  |proj g|=        2.3176
At iterate    16  f =      -273.56  |proj g|=        2.3173
At iterate    17  f =      -273.56  |proj g|=        2.2974
At iterate    18  f =      -273.63  |proj g|=        2.2945
At iterate    19  f =      -288.41  |proj g|=       0.83705
At iterate    20  f =      -289.91  |proj g|=       0.79959
At iterate    21  f =      -290.29  |proj g|=       0.80091
At iterate    22  f =      -290.85  |proj g|=       0.23127
At iterate    23  f =      -290.93  |proj g|=       0.23165
At iterate    24  f =      -290.94  |proj g|=       0.82903
At iterate    25  f =      -290.95  |proj g|=       0.23171
At iterate    26  f =      -290.95  |proj g|=       0.23171
At iterate    27  f =      -290.95  |proj g|=       0.23171

iterations 27
function evaluations 33
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.231713
final function value -290.946

F = -290.946
final  value -290.946239 
converged
 
INFO  [07:07:31.307] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:07:31.396] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:07:31.403] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:07:37.837] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:07:44.512] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:07:50.282] [mlr3]  Finished benchmark 
INFO  [07:07:50.420] [bbotk] Result of batch 55: 
INFO  [07:07:50.422] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:07:50.422] [bbotk]              6.739243                 7.254605                       0.4937173 
INFO  [07:07:50.422] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:07:50.422] [bbotk]                     3055        0.621 -0.9691144         <NA>   0.9779534 
INFO  [07:07:50.422] [bbotk]                                 uhash 
INFO  [07:07:50.422] [bbotk]  b25575c9-6529-4858-a059-c1fa61111f76 
DEBUG [07:07:51.586] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.449488e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  3.449488e-05 0.004769854 
  - best initial criterion value(s) :  267.5426 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -267.54  |proj g|=      0.59097
At iterate     1  f =      -274.21  |proj g|=        3.8253
At iterate     2  f =      -276.76  |proj g|=        3.6711
At iterate     3  f =       -280.6  |proj g|=        2.9588
At iterate     4  f =      -280.65  |proj g|=        2.8608
At iterate     5  f =      -280.69  |proj g|=        2.8505
At iterate     6  f =      -280.87  |proj g|=        2.8604
At iterate     7  f =      -280.87  |proj g|=        2.8966
At iterate     8  f =      -280.87  |proj g|=        2.8881
At iterate     9  f =      -280.87  |proj g|=        2.8878
At iterate    10  f =      -280.87  |proj g|=        2.8875
At iterate    11  f =      -280.87  |proj g|=        2.8865
At iterate    12  f =      -280.87  |proj g|=        2.8851
At iterate    13  f =      -280.87  |proj g|=        2.8826
At iterate    14  f =      -280.88  |proj g|=        2.8786
At iterate    15  f =      -280.88  |proj g|=        2.8719
At iterate    16  f =      -280.88  |proj g|=        2.8611
At iterate    17  f =      -280.89  |proj g|=        2.8444
At iterate    18  f =      -280.91  |proj g|=        2.8227
At iterate    19  f =      -280.95  |proj g|=        2.8085
At iterate    20  f =      -280.99  |proj g|=        2.8353
At iterate    21  f =         -281  |proj g|=        2.8565
At iterate    22  f =      -281.01  |proj g|=        2.8821
At iterate    23  f =      -281.02  |proj g|=        2.8974
At iterate    24  f =      -281.05  |proj g|=        2.9249
At iterate    25  f =      -281.12  |proj g|=         2.958
At iterate    26  f =      -281.31  |proj g|=        2.9914
At iterate    27  f =       -281.7  |proj g|=        2.9875
At iterate    28  f =      -281.91  |proj g|=        2.9336
At iterate    29  f =      -282.23  |proj g|=        2.6055
At iterate    30  f =      -282.28  |proj g|=        2.7224
At iterate    31  f =      -282.29  |proj g|=        2.7029
At iterate    32  f =      -282.29  |proj g|=        2.6981
At iterate    33  f =       -282.3  |proj g|=        2.6791
At iterate    34  f =      -282.31  |proj g|=         2.659
At iterate    35  f =      -282.33  |proj g|=        2.6441
At iterate    36  f =      -282.36  |proj g|=        2.6941
At iterate    37  f =      -282.36  |proj g|=        2.6858
At iterate    38  f =      -282.36  |proj g|=        2.6846
At iterate    39  f =      -282.36  |proj g|=        2.6846
At iterate    40  f =      -282.36  |proj g|=        2.6844
At iterate    41  f =      -282.36  |proj g|=        2.6831
At iterate    42  f =      -282.36  |proj g|=        2.6815
At iterate    43  f =      -282.36  |proj g|=        2.6786
At iterate    44  f =      -282.36  |proj g|=        2.6761
At iterate    45  f =      -282.36  |proj g|=        2.6702
At iterate    46  f =      -282.36  |proj g|=        2.6662
At iterate    47  f =      -282.38  |proj g|=        2.6545
At iterate    48  f =      -282.53  |proj g|=        2.5854
At iterate    49  f =      -282.99  |proj g|=        2.4086
At iterate    50  f =      -284.18  |proj g|=        2.0164
At iterate    51  f =      -284.24  |proj g|=        2.1563
At iterate    52  f =      -286.23  |proj g|=        1.5627
At iterate    53  f =      -288.65  |proj g|=         1.084
At iterate    54  f =      -292.35  |proj g|=        0.2675
At iterate    55  f =      -294.78  |proj g|=       0.15398
At iterate    56  f =      -295.23  |proj g|=       0.19178
At iterate    57  f =      -295.44  |proj g|=       0.81858
At iterate    58  f =      -295.47  |proj g|=       0.17766
At iterate    59  f =      -295.49  |proj g|=       0.82603
At iterate    60  f =      -295.49  |proj g|=      0.036111
At iterate    61  f =      -295.49  |proj g|=      0.013068
At iterate    62  f =      -295.49  |proj g|=     0.0014277

iterations 62
function evaluations 72
segments explored during Cauchy searches 66
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00142775
final function value -295.495

F = -295.495
final  value -295.494872 
converged
 
INFO  [07:07:51.591] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:07:51.680] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:07:51.687] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:08:00.581] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:08:10.819] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:08:17.833] [mlr3]  Finished benchmark 
INFO  [07:08:17.936] [bbotk] Result of batch 56: 
INFO  [07:08:17.938] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:08:17.938] [bbotk]              7.364798                 6.356667                       0.4878369 
INFO  [07:08:17.938] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:08:17.938] [bbotk]                     3632        0.786 -0.9683986         <NA>    0.978005 
INFO  [07:08:17.938] [bbotk]                                 uhash 
INFO  [07:08:17.938] [bbotk]  09a70d1f-2441-4e5d-b0cf-49116d31e5ca 
DEBUG [07:08:18.884] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.418318e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  3.418318e-05 0.004816006 
  - best initial criterion value(s) :  251.9593 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -251.96  |proj g|=       5.6388
At iterate     1  f =      -252.74  |proj g|=        1.6305
At iterate     2  f =      -253.59  |proj g|=        1.5673
At iterate     3  f =       -254.2  |proj g|=        1.0973
At iterate     4  f =      -254.49  |proj g|=       0.95026
At iterate     5  f =      -254.67  |proj g|=       0.93056
At iterate     6  f =      -254.79  |proj g|=       0.97525
At iterate     7  f =      -255.92  |proj g|=       0.99541
At iterate     8  f =      -256.06  |proj g|=       0.99541
At iterate     9  f =      -256.06  |proj g|=       0.99541
At iterate    10  f =      -256.06  |proj g|=       0.99541
At iterate    11  f =      -256.06  |proj g|=       0.99541
At iterate    12  f =      -256.06  |proj g|=       0.99541
At iterate    13  f =      -256.08  |proj g|=       0.99539
At iterate    14  f =       -256.3  |proj g|=       0.99514
At iterate    15  f =      -256.81  |proj g|=       0.99446
At iterate    16  f =      -259.19  |proj g|=       0.99128
At iterate    17  f =      -260.54  |proj g|=          0.99
At iterate    18  f =      -261.26  |proj g|=          0.99
At iterate    19  f =      -261.35  |proj g|=       0.98999
At iterate    20  f =      -261.36  |proj g|=       0.98999
At iterate    21  f =      -261.36  |proj g|=       0.98999
At iterate    22  f =      -261.36  |proj g|=       0.98998
At iterate    23  f =      -261.36  |proj g|=       0.98994
At iterate    24  f =      -261.37  |proj g|=       0.98985
At iterate    25  f =      -261.37  |proj g|=       0.98955
At iterate    26  f =      -261.37  |proj g|=       0.98877
At iterate    27  f =      -261.39  |proj g|=       0.98664
At iterate    28  f =      -261.44  |proj g|=       0.98092
At iterate    29  f =      -261.56  |proj g|=       0.96532
At iterate    30  f =      -261.89  |proj g|=       0.92291
At iterate    31  f =      -262.71  |proj g|=       0.92961
At iterate    32  f =      -264.03  |proj g|=        0.9956
At iterate    33  f =      -268.53  |proj g|=       0.66625
At iterate    34  f =      -279.18  |proj g|=       0.32918
At iterate    35  f =       -280.5  |proj g|=       0.32918
At iterate    36  f =      -280.65  |proj g|=       0.32918
At iterate    37  f =      -280.74  |proj g|=       0.32918
At iterate    38  f =      -280.75  |proj g|=       0.32918
At iterate    39  f =      -280.75  |proj g|=       0.32918
At iterate    40  f =      -280.75  |proj g|=       0.32918
At iterate    41  f =      -280.75  |proj g|=       0.32916
At iterate    42  f =      -280.75  |proj g|=       0.32912
At iterate    43  f =      -280.75  |proj g|=       0.32899
At iterate    44  f =      -280.76  |proj g|=       0.32866
At iterate    45  f =      -280.78  |proj g|=       0.32776
At iterate    46  f =      -280.84  |proj g|=       0.32537
At iterate    47  f =      -280.99  |proj g|=       0.31899
At iterate    48  f =      -281.37  |proj g|=       0.30242
At iterate    49  f =      -282.25  |proj g|=       0.26282
At iterate    50  f =      -283.93  |proj g|=       0.80869
At iterate    51  f =      -285.34  |proj g|=       0.84223
At iterate    52  f =      -287.57  |proj g|=       0.86387
At iterate    53  f =      -287.92  |proj g|=       0.85279
At iterate    54  f =      -287.93  |proj g|=       0.84988
At iterate    55  f =      -287.93  |proj g|=      0.019987
At iterate    56  f =      -287.93  |proj g|=      0.019987

iterations 56
function evaluations 70
segments explored during Cauchy searches 59
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0199867
final function value -287.931

F = -287.931
final  value -287.930825 
converged
 
INFO  [07:08:18.889] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:08:19.012] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:08:19.019] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:08:28.135] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:08:35.046] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:08:42.823] [mlr3]  Finished benchmark 
INFO  [07:08:42.970] [bbotk] Result of batch 57: 
INFO  [07:08:42.973] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:08:42.973] [bbotk]              4.542529                 8.219885                       0.1133295 
INFO  [07:08:42.973] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:08:42.973] [bbotk]                     3270        0.594 -0.9735531         <NA>   0.9729312 
INFO  [07:08:42.973] [bbotk]                                 uhash 
INFO  [07:08:42.973] [bbotk]  7eb2b306-b05d-4a5b-8702-2de28279ade0 
DEBUG [07:08:43.838] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.380536e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  3.380536e-05 0.004781257 
  - best initial criterion value(s) :  266.4875 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -266.49  |proj g|=       5.3105
At iterate     1  f =      -279.47  |proj g|=        4.3134
At iterate     2  f =      -279.51  |proj g|=        4.2738
At iterate     3  f =      -279.58  |proj g|=        4.4221
At iterate     4  f =      -279.58  |proj g|=        4.4444
At iterate     5  f =      -279.58  |proj g|=        4.4428
At iterate     6  f =      -279.58  |proj g|=        4.4417
At iterate     7  f =      -279.58  |proj g|=         4.437
At iterate     8  f =      -279.58  |proj g|=        4.4325
At iterate     9  f =      -279.58  |proj g|=        4.3952
At iterate    10  f =      -279.59  |proj g|=        4.4013
At iterate    11  f =      -279.65  |proj g|=        4.3904
At iterate    12  f =      -279.81  |proj g|=        4.3462
At iterate    13  f =      -280.53  |proj g|=         4.102
At iterate    14  f =      -281.95  |proj g|=        3.5868
At iterate    15  f =      -284.28  |proj g|=        2.7314
At iterate    16  f =      -284.56  |proj g|=        2.6793
At iterate    17  f =      -288.38  |proj g|=        1.6129
At iterate    18  f =      -292.34  |proj g|=        1.1152
At iterate    19  f =      -297.26  |proj g|=       0.94122
At iterate    20  f =      -298.49  |proj g|=       0.72413
At iterate    21  f =      -301.01  |proj g|=       0.84153
At iterate    22  f =      -301.17  |proj g|=       0.84363
At iterate    23  f =      -301.18  |proj g|=       0.27869
At iterate    24  f =      -301.18  |proj g|=       0.27868
At iterate    25  f =      -301.18  |proj g|=       0.27868

iterations 25
function evaluations 34
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.278684
final function value -301.182

F = -301.182
final  value -301.181928 
converged
 
INFO  [07:08:43.842] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:08:43.933] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:08:43.940] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:08:53.506] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:09:02.486] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:09:09.781] [mlr3]  Finished benchmark 
INFO  [07:09:09.927] [bbotk] Result of batch 58: 
INFO  [07:09:09.929] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:09:09.929] [bbotk]              6.097864                 7.191696                      0.02654475 
INFO  [07:09:09.929] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:09:09.929] [bbotk]                     3779        0.595 -0.9714131         <NA>   0.9643949 
INFO  [07:09:09.929] [bbotk]                                 uhash 
INFO  [07:09:09.929] [bbotk]  73dd5ad4-d82c-4c5a-9af8-644dd1752184 
DEBUG [07:09:10.864] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.344856e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  3.344856e-05 0.004741258 
  - best initial criterion value(s) :  273.5332 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -273.53  |proj g|=       6.3026
At iterate     1  f =      -275.43  |proj g|=        5.1761
At iterate     2  f =       -275.7  |proj g|=        5.3306
At iterate     3  f =      -275.74  |proj g|=        5.2842
At iterate     4  f =      -275.74  |proj g|=        5.2714
At iterate     5  f =      -275.75  |proj g|=        5.2703
At iterate     6  f =      -275.75  |proj g|=        5.2703
At iterate     7  f =      -275.75  |proj g|=        5.2687
At iterate     8  f =      -275.75  |proj g|=        5.2632
At iterate     9  f =      -275.76  |proj g|=        5.2838
At iterate    10  f =      -275.77  |proj g|=        5.2617
At iterate    11  f =      -275.79  |proj g|=        5.3504
At iterate    12  f =      -275.86  |proj g|=        5.2693
At iterate    13  f =      -276.12  |proj g|=        5.0721
At iterate    14  f =      -277.08  |proj g|=        4.6513
At iterate    15  f =      -281.24  |proj g|=        3.6446
At iterate    16  f =      -293.09  |proj g|=        2.2631
At iterate    17  f =      -296.05  |proj g|=        1.8085
At iterate    18  f =      -305.32  |proj g|=       0.88012
At iterate    19  f =      -305.88  |proj g|=        1.1019
At iterate    20  f =      -306.97  |proj g|=       0.99778
At iterate    21  f =       -307.4  |proj g|=       0.91297
At iterate    22  f =      -307.47  |proj g|=       0.89946
At iterate    23  f =      -307.48  |proj g|=         0.913
At iterate    24  f =      -307.48  |proj g|=       0.91345
At iterate    25  f =      -307.48  |proj g|=       0.91342
At iterate    26  f =      -307.48  |proj g|=       0.91341
At iterate    27  f =      -307.48  |proj g|=       0.91338
At iterate    28  f =      -307.48  |proj g|=       0.91334
At iterate    29  f =      -307.48  |proj g|=       0.91329
At iterate    30  f =      -307.48  |proj g|=       0.91245
At iterate    31  f =      -307.48  |proj g|=       0.91266
At iterate    32  f =      -307.48  |proj g|=       0.91302
At iterate    33  f =      -307.48  |proj g|=        0.9135
At iterate    34  f =      -307.48  |proj g|=       0.91394
At iterate    35  f =      -307.49  |proj g|=       0.91384
At iterate    36  f =      -307.51  |proj g|=       0.90942
At iterate    37  f =      -307.54  |proj g|=       0.91574
At iterate    38  f =      -307.61  |proj g|=       0.89627
At iterate    39  f =         -308  |proj g|=        0.8345
At iterate    40  f =      -308.56  |proj g|=       0.83906
At iterate    41  f =      -308.77  |proj g|=       0.15627
At iterate    42  f =      -308.98  |proj g|=       0.82897
At iterate    43  f =      -308.98  |proj g|=       0.82805
At iterate    44  f =      -308.98  |proj g|=      0.072083
At iterate    45  f =      -308.98  |proj g|=      0.021733
At iterate    46  f =      -308.98  |proj g|=    0.00090665

iterations 46
function evaluations 54
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000906646
final function value -308.985

F = -308.985
final  value -308.984866 
converged
 
INFO  [07:09:10.869] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:09:10.962] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:09:10.969] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:09:16.496] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:09:22.089] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:09:28.082] [mlr3]  Finished benchmark 
INFO  [07:09:28.234] [bbotk] Result of batch 59: 
INFO  [07:09:28.236] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:09:28.236] [bbotk]              9.234012                 8.408746                       0.4626125 
INFO  [07:09:28.236] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:09:28.236] [bbotk]                     2364        0.612 -0.9679149         <NA>   0.9773723 
INFO  [07:09:28.236] [bbotk]                                 uhash 
INFO  [07:09:28.236] [bbotk]  6b39b1e6-61e8-4c36-886f-7824a052620c 
DEBUG [07:09:29.156] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.314561e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  3.314561e-05 0.004715467 
  - best initial criterion value(s) :  264.6438 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -264.64  |proj g|=      0.98658
At iterate     1  f =      -277.55  |proj g|=       0.35433
At iterate     2  f =      -291.35  |proj g|=        2.6136
At iterate     3  f =      -291.94  |proj g|=        2.5205
At iterate     4  f =      -293.34  |proj g|=        2.1142
At iterate     5  f =      -293.52  |proj g|=        1.9233
At iterate     6  f =      -293.82  |proj g|=        1.9865
At iterate     7  f =      -294.49  |proj g|=        2.2197
At iterate     8  f =      -294.68  |proj g|=         2.282
At iterate     9  f =      -294.75  |proj g|=        2.2098
At iterate    10  f =      -294.76  |proj g|=        2.2269
At iterate    11  f =      -294.76  |proj g|=        2.2336
At iterate    12  f =      -294.76  |proj g|=        2.2276
At iterate    13  f =      -294.76  |proj g|=        2.2254
At iterate    14  f =       -294.8  |proj g|=        2.2055
At iterate    15  f =      -295.02  |proj g|=        2.1557
At iterate    16  f =      -296.04  |proj g|=        1.9537
At iterate    17  f =      -296.26  |proj g|=        1.9765
At iterate    18  f =      -296.28  |proj g|=        2.0364
At iterate    19  f =       -296.5  |proj g|=        2.0378
At iterate    20  f =      -296.53  |proj g|=        2.0608
At iterate    21  f =      -296.53  |proj g|=        2.0501
At iterate    22  f =      -296.53  |proj g|=        2.0507
At iterate    23  f =      -296.53  |proj g|=        2.0459
At iterate    24  f =      -296.54  |proj g|=        2.0629
At iterate    25  f =      -296.57  |proj g|=        2.0419
At iterate    26  f =      -296.72  |proj g|=        1.9427
At iterate    27  f =      -297.02  |proj g|=        1.7968
At iterate    28  f =       -297.8  |proj g|=        1.5092
At iterate    29  f =      -299.39  |proj g|=        1.1265
At iterate    30  f =      -302.65  |proj g|=        0.2709
At iterate    31  f =      -303.94  |proj g|=       0.24954
At iterate    32  f =      -304.92  |proj g|=       0.80835
At iterate    33  f =      -305.04  |proj g|=       0.20435
At iterate    34  f =      -305.05  |proj g|=       0.15012
At iterate    35  f =      -305.05  |proj g|=       0.19877
At iterate    36  f =      -305.05  |proj g|=     0.0037052
At iterate    37  f =      -305.05  |proj g|=     0.0033517

iterations 37
function evaluations 46
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00335167
final function value -305.055

F = -305.055
final  value -305.054760 
converged
 
INFO  [07:09:29.161] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:09:29.249] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:09:29.256] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:09:41.316] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:09:52.013] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:10:04.220] [mlr3]  Finished benchmark 
INFO  [07:10:04.318] [bbotk] Result of batch 60: 
INFO  [07:10:04.319] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:10:04.319] [bbotk]              6.397045                  7.52717                       0.3767367 
INFO  [07:10:04.319] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:10:04.319] [bbotk]                     4971         0.61 -0.9606461         <NA>   0.9783889 
INFO  [07:10:04.319] [bbotk]                                 uhash 
INFO  [07:10:04.319] [bbotk]  e35d8ff0-99da-4c93-b0f3-ca55c329647a 
DEBUG [07:10:05.164] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.286684e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9530 
  - variance bounds :  3.286684e-05 0.004694748 
  - best initial criterion value(s) :  271.2387 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -271.24  |proj g|=      0.57003
At iterate     1  f =      -272.09  |proj g|=       0.78709
At iterate     2  f =      -272.36  |proj g|=       0.61263
At iterate     3  f =       -272.4  |proj g|=       0.60486
At iterate     4  f =       -272.4  |proj g|=        0.6065
At iterate     5  f =      -272.41  |proj g|=       0.60698
At iterate     6  f =      -272.43  |proj g|=        0.6069
At iterate     7  f =       -272.5  |proj g|=       0.60312
At iterate     8  f =      -272.57  |proj g|=       0.81443
At iterate     9  f =      -272.63  |proj g|=       0.82387
At iterate    10  f =      -272.65  |proj g|=       0.82271
At iterate    11  f =      -272.65  |proj g|=       0.82205
At iterate    12  f =      -272.65  |proj g|=       0.82213
At iterate    13  f =      -272.65  |proj g|=       0.82213

iterations 13
function evaluations 18
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.822135
final function value -272.646

F = -272.646
final  value -272.646199 
converged
 
INFO  [07:10:05.168] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:10:05.270] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:10:05.277] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:10:11.906] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:10:21.286] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:10:30.377] [mlr3]  Finished benchmark 
INFO  [07:10:30.476] [bbotk] Result of batch 61: 
INFO  [07:10:30.478] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:10:30.478] [bbotk]               9.11316                 5.027485                       0.1326519 
INFO  [07:10:30.478] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:10:30.478] [bbotk]                     2853        0.623 -0.9804755         <NA>   0.9747368 
INFO  [07:10:30.478] [bbotk]                                 uhash 
INFO  [07:10:30.478] [bbotk]  8c9614cf-4ece-4030-a1e4-27ed772f786d 
DEBUG [07:10:31.550] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.253591e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9530 
  - variance bounds :  3.253591e-05 0.004663602 
  - best initial criterion value(s) :  272.7201 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -272.72  |proj g|=       1.2197
At iterate     1  f =      -289.26  |proj g|=        1.8775
At iterate     2  f =      -289.59  |proj g|=        1.9321
At iterate     3  f =      -289.68  |proj g|=        1.9149
At iterate     4  f =      -289.72  |proj g|=         1.895
At iterate     5  f =      -289.72  |proj g|=        1.8942
At iterate     6  f =      -289.72  |proj g|=        1.8931
At iterate     7  f =      -289.72  |proj g|=        1.8933
At iterate     8  f =      -289.72  |proj g|=        1.8933

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.89326
final function value -289.725

F = -289.725
final  value -289.724836 
converged
 
INFO  [07:10:31.554] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:10:31.639] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:10:31.646] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:10:33.865] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:10:36.119] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:10:38.757] [mlr3]  Finished benchmark 
INFO  [07:10:38.855] [bbotk] Result of batch 62: 
INFO  [07:10:38.857] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:10:38.857] [bbotk]              5.582578                  9.53657                        0.206717 
INFO  [07:10:38.857] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:10:38.857] [bbotk]                      976        0.766 -0.9762717         <NA>   0.9704973 
INFO  [07:10:38.857] [bbotk]                                 uhash 
INFO  [07:10:38.857] [bbotk]  69da2a9e-32f1-476d-992a-a8eea42df3bc 
DEBUG [07:10:39.737] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.218328e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9530 
  - variance bounds :  3.218328e-05 0.004567383 
  - best initial criterion value(s) :  294.4515 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -294.45  |proj g|=       1.3138
At iterate     1  f =      -294.72  |proj g|=        1.4068
At iterate     2  f =      -298.45  |proj g|=        1.0907
At iterate     3  f =      -299.03  |proj g|=        1.0434
At iterate     4  f =      -299.91  |proj g|=       0.99816
At iterate     5  f =      -299.92  |proj g|=       0.98465
At iterate     6  f =      -299.92  |proj g|=       0.99082
At iterate     7  f =      -299.92  |proj g|=       0.99527
At iterate     8  f =      -301.12  |proj g|=       0.85976
At iterate     9  f =       -302.9  |proj g|=       0.62625
At iterate    10  f =      -302.95  |proj g|=       0.62105
At iterate    11  f =      -302.96  |proj g|=       0.85123
At iterate    12  f =      -302.96  |proj g|=       0.72216
At iterate    13  f =      -302.96  |proj g|=       0.61166
At iterate    14  f =      -302.96  |proj g|=       0.61157
At iterate    15  f =      -302.96  |proj g|=       0.61156

iterations 15
function evaluations 28
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.611561
final function value -302.961

F = -302.961
final  value -302.961004 
converged
 
INFO  [07:10:39.741] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:10:39.828] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:10:39.835] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:10:44.289] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:10:49.012] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:10:53.667] [mlr3]  Finished benchmark 
INFO  [07:10:53.790] [bbotk] Result of batch 63: 
INFO  [07:10:53.792] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:10:53.792] [bbotk]              9.930228                 2.282911                      0.01475592 
INFO  [07:10:53.792] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:10:53.792] [bbotk]                     3003        0.611 -0.9744659         <NA>   0.9554327 
INFO  [07:10:53.792] [bbotk]                                 uhash 
INFO  [07:10:53.792] [bbotk]  2a34306b-d1b5-4cc1-b2e4-b079e953f2fb 
DEBUG [07:10:54.851] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.204866e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  3.204866e-05 0.004537138 
  - best initial criterion value(s) :  281.7708 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -281.77  |proj g|=       1.6774
At iterate     1  f =      -282.38  |proj g|=        1.8623
At iterate     2  f =      -283.24  |proj g|=        1.8271
At iterate     3  f =      -283.38  |proj g|=        1.7669
At iterate     4  f =      -283.47  |proj g|=        1.7953
At iterate     5  f =      -283.47  |proj g|=        1.7909
At iterate     6  f =      -283.48  |proj g|=        1.7869
At iterate     7  f =      -283.49  |proj g|=        1.7771
At iterate     8  f =      -283.53  |proj g|=        1.7568
At iterate     9  f =      -283.61  |proj g|=        1.7151
At iterate    10  f =      -283.74  |proj g|=        1.6493
At iterate    11  f =      -283.85  |proj g|=         1.602
At iterate    12  f =      -283.88  |proj g|=        1.6078
At iterate    13  f =      -283.88  |proj g|=         1.614
At iterate    14  f =      -283.88  |proj g|=        1.6143
At iterate    15  f =      -283.88  |proj g|=        1.6144
At iterate    16  f =      -283.88  |proj g|=        1.6148
At iterate    17  f =      -283.88  |proj g|=        1.6152
At iterate    18  f =      -283.88  |proj g|=         1.616
At iterate    19  f =      -283.88  |proj g|=        1.6173
At iterate    20  f =      -283.88  |proj g|=        1.6195
At iterate    21  f =      -283.89  |proj g|=        1.6236
At iterate    22  f =       -283.9  |proj g|=        1.6315
At iterate    23  f =      -283.91  |proj g|=        1.6462
At iterate    24  f =      -283.94  |proj g|=        1.6672
At iterate    25  f =      -283.95  |proj g|=        1.6616
At iterate    26  f =      -283.96  |proj g|=        1.6784
At iterate    27  f =      -289.96  |proj g|=        1.2133
At iterate    28  f =      -297.56  |proj g|=       0.59207
At iterate    29  f =      -298.26  |proj g|=        0.3354
At iterate    30  f =      -298.39  |proj g|=       0.35051
At iterate    31  f =      -298.46  |proj g|=       0.84236
At iterate    32  f =      -298.47  |proj g|=        0.3396
At iterate    33  f =      -298.47  |proj g|=       0.34081
At iterate    34  f =      -298.47  |proj g|=       0.34077

iterations 34
function evaluations 41
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.34077
final function value -298.468

F = -298.468
final  value -298.468179 
converged
 
INFO  [07:10:54.855] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:10:54.941] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:10:54.948] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:10:57.031] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:10:58.924] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:11:00.930] [mlr3]  Finished benchmark 
INFO  [07:11:01.030] [bbotk] Result of batch 64: 
INFO  [07:11:01.032] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:11:01.032] [bbotk]              6.586283                 6.420525                       0.3264121 
INFO  [07:11:01.032] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:11:01.032] [bbotk]                     1255        0.715 -0.9765636         <NA>   0.9746475 
INFO  [07:11:01.032] [bbotk]                                 uhash 
INFO  [07:11:01.032] [bbotk]  b8a51128-dee9-4fe9-bee7-d34d5ae61ce4 
DEBUG [07:11:02.114] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.173691e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  3.173691e-05 0.004445866 
  - best initial criterion value(s) :  311.6415 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -311.64  |proj g|=       3.6817
At iterate     1  f =      -312.34  |proj g|=        3.9811
At iterate     2  f =      -312.41  |proj g|=        3.9381
At iterate     3  f =      -312.46  |proj g|=        3.8844
At iterate     4  f =      -312.54  |proj g|=        3.8222
At iterate     5  f =      -312.79  |proj g|=        3.6299
At iterate     6  f =      -313.18  |proj g|=        3.3935
At iterate     7  f =      -313.53  |proj g|=        3.2036
At iterate     8  f =      -313.59  |proj g|=        3.2305
At iterate     9  f =      -313.59  |proj g|=        3.2527
At iterate    10  f =      -313.59  |proj g|=        3.2542
At iterate    11  f =      -313.59  |proj g|=        3.2549
At iterate    12  f =      -313.59  |proj g|=        3.2569
At iterate    13  f =      -313.59  |proj g|=        3.2593
At iterate    14  f =      -313.59  |proj g|=        3.2632
At iterate    15  f =      -313.59  |proj g|=        3.2685
At iterate    16  f =       -313.6  |proj g|=        3.2755
At iterate    17  f =      -313.62  |proj g|=        3.2831
At iterate    18  f =      -313.67  |proj g|=         3.286
At iterate    19  f =      -313.81  |proj g|=        3.2661
At iterate    20  f =      -314.17  |proj g|=        3.1728
At iterate    21  f =      -315.05  |proj g|=        2.8992
At iterate    22  f =      -317.04  |proj g|=        2.3262
At iterate    23  f =      -319.78  |proj g|=        1.9908
At iterate    24  f =      -320.61  |proj g|=        1.8487
At iterate    25  f =      -320.62  |proj g|=        1.8222
At iterate    26  f =      -320.62  |proj g|=         1.831
At iterate    27  f =      -320.63  |proj g|=        1.8364
At iterate    28  f =      -320.64  |proj g|=        1.8427
At iterate    29  f =       -320.7  |proj g|=        1.8537
At iterate    30  f =      -320.84  |proj g|=        1.8553
At iterate    31  f =      -321.19  |proj g|=        1.8242
At iterate    32  f =      -321.97  |proj g|=        1.7096
At iterate    33  f =      -323.63  |proj g|=        1.4276
At iterate    34  f =      -327.57  |proj g|=       0.45809
At iterate    35  f =       -328.9  |proj g|=       0.18666
At iterate    36  f =       -328.9  |proj g|=       0.18666
At iterate    37  f =       -328.9  |proj g|=       0.18664
At iterate    38  f =       -328.9  |proj g|=       0.18659
At iterate    39  f =       -328.9  |proj g|=       0.18646
At iterate    40  f =       -328.9  |proj g|=       0.18613
At iterate    41  f =      -328.92  |proj g|=       0.18524
At iterate    42  f =      -328.95  |proj g|=       0.18292
At iterate    43  f =      -329.04  |proj g|=       0.17735
At iterate    44  f =      -329.19  |proj g|=       0.82913
At iterate    45  f =       -329.4  |proj g|=       0.84325
At iterate    46  f =      -329.42  |proj g|=        0.2154
At iterate    47  f =      -329.42  |proj g|=      0.085248
At iterate    48  f =      -329.42  |proj g|=      0.010597
At iterate    49  f =      -329.42  |proj g|=      0.010597

iterations 49
function evaluations 56
segments explored during Cauchy searches 52
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0105971
final function value -329.421

F = -329.421
final  value -329.421463 
converged
 
INFO  [07:11:02.119] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:11:02.228] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:11:02.235] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:11:09.425] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:11:17.114] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:11:24.809] [mlr3]  Finished benchmark 
INFO  [07:11:24.940] [bbotk] Result of batch 65: 
INFO  [07:11:24.942] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:11:24.942] [bbotk]              2.962483                 2.519988                       0.4334645 
INFO  [07:11:24.942] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:11:24.942] [bbotk]                     4650        0.685 -0.9707802         <NA>   0.9752067 
INFO  [07:11:24.942] [bbotk]                                 uhash 
INFO  [07:11:24.942] [bbotk]  6c163f6d-95bd-4971-8a47-e462909f15ab 
DEBUG [07:11:25.992] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.143753e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  3.143753e-05 0.004419758 
  - best initial criterion value(s) :  290.8253 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -290.83  |proj g|=       1.5226
At iterate     1  f =      -307.99  |proj g|=        1.8768
At iterate     2  f =      -308.47  |proj g|=         2.049
At iterate     3  f =      -308.55  |proj g|=        2.0165
At iterate     4  f =      -308.57  |proj g|=        1.9915
At iterate     5  f =      -308.57  |proj g|=         1.994
At iterate     6  f =      -308.57  |proj g|=        1.9954
At iterate     7  f =      -308.57  |proj g|=        1.9955
At iterate     8  f =      -308.57  |proj g|=        1.9957
At iterate     9  f =      -308.57  |proj g|=         1.996
At iterate    10  f =      -308.57  |proj g|=        1.9966
At iterate    11  f =      -308.58  |proj g|=        1.9976
At iterate    12  f =      -308.58  |proj g|=        1.9993
At iterate    13  f =      -308.58  |proj g|=        1.9997
At iterate    14  f =      -308.58  |proj g|=        2.0057
At iterate    15  f =      -308.59  |proj g|=        2.0029
At iterate    16  f =      -308.64  |proj g|=        1.9936
At iterate    17  f =      -308.85  |proj g|=        1.9444
At iterate    18  f =       -309.3  |proj g|=        1.8302
At iterate    19  f =      -310.31  |proj g|=         1.569
At iterate    20  f =      -311.82  |proj g|=        1.2812
At iterate    21  f =      -312.67  |proj g|=        1.1283
At iterate    22  f =      -314.22  |proj g|=         1.047
At iterate    23  f =      -316.85  |proj g|=        0.2811
At iterate    24  f =      -319.63  |proj g|=       0.22356
At iterate    25  f =      -321.06  |proj g|=         0.828
At iterate    26  f =      -321.52  |proj g|=       0.85658
At iterate    27  f =      -321.65  |proj g|=       0.14606
At iterate    28  f =      -321.75  |proj g|=       0.15121
At iterate    29  f =      -321.77  |proj g|=        0.8487
At iterate    30  f =      -321.77  |proj g|=       0.10884
At iterate    31  f =      -321.77  |proj g|=      0.026454
At iterate    32  f =      -321.77  |proj g|=      0.027074

iterations 32
function evaluations 42
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0270738
final function value -321.768

F = -321.768
final  value -321.768323 
converged
 
INFO  [07:11:25.996] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:11:26.087] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:11:26.095] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:11:28.270] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:11:30.559] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:11:32.817] [mlr3]  Finished benchmark 
INFO  [07:11:32.920] [bbotk] Result of batch 66: 
INFO  [07:11:32.922] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:11:32.922] [bbotk]              6.692205                  2.57393                       0.0481813 
INFO  [07:11:32.922] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [07:11:32.922] [bbotk]                     1317        0.711 -0.973498         <NA>   0.9600608 
INFO  [07:11:32.922] [bbotk]                                 uhash 
INFO  [07:11:32.922] [bbotk]  a5ef8fdb-1b47-4cbb-a1da-f8c941df602e 
DEBUG [07:11:33.936] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.120183e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  3.120183e-05 0.004350766 
  - best initial criterion value(s) :  301.2506 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -301.25  |proj g|=        6.044
At iterate     1  f =      -316.02  |proj g|=        3.2364
At iterate     2  f =      -316.02  |proj g|=        3.3562
At iterate     3  f =       -316.6  |proj g|=        3.4581
At iterate     4  f =      -317.61  |proj g|=        3.7343
At iterate     5  f =      -317.71  |proj g|=        4.4111
At iterate     6  f =      -317.76  |proj g|=        4.1485
At iterate     7  f =      -317.76  |proj g|=        4.1568
At iterate     8  f =      -317.76  |proj g|=        4.1601
At iterate     9  f =      -317.77  |proj g|=        4.1659
At iterate    10  f =      -317.77  |proj g|=        4.1757
At iterate    11  f =      -317.79  |proj g|=        4.1897
At iterate    12  f =      -317.83  |proj g|=        4.1894
At iterate    13  f =      -317.92  |proj g|=        4.1369
At iterate    14  f =      -318.12  |proj g|=        4.0327
At iterate    15  f =      -318.51  |proj g|=        3.5921
At iterate    16  f =       -318.7  |proj g|=        3.5108
At iterate    17  f =      -319.47  |proj g|=        2.9121
At iterate    18  f =      -320.43  |proj g|=        2.4795
At iterate    19  f =      -324.18  |proj g|=        1.6503
At iterate    20  f =      -333.01  |proj g|=       0.80043
At iterate    21  f =      -337.44  |proj g|=        1.2388
At iterate    22  f =      -337.93  |proj g|=        1.3124
At iterate    23  f =         -338  |proj g|=        1.3696
At iterate    24  f =         -338  |proj g|=        1.3721
At iterate    25  f =         -338  |proj g|=         1.371
At iterate    26  f =      -338.01  |proj g|=        1.3616
At iterate    27  f =      -338.03  |proj g|=        1.3497
At iterate    28  f =       -338.1  |proj g|=        1.3206
At iterate    29  f =      -338.22  |proj g|=        1.2965
At iterate    30  f =      -338.39  |proj g|=        1.1465
At iterate    31  f =      -338.71  |proj g|=        1.1146
At iterate    32  f =      -340.81  |proj g|=        0.2237
At iterate    33  f =      -341.36  |proj g|=       0.20105
At iterate    34  f =      -341.67  |proj g|=       0.82151
At iterate    35  f =      -341.75  |proj g|=       0.17103
At iterate    36  f =      -341.76  |proj g|=       0.17464
At iterate    37  f =      -341.76  |proj g|=      0.088577
At iterate    38  f =      -341.76  |proj g|=      0.014487
At iterate    39  f =      -341.76  |proj g|=     0.0014404

iterations 39
function evaluations 46
segments explored during Cauchy searches 41
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00144036
final function value -341.759

F = -341.759
final  value -341.758708 
converged
 
INFO  [07:11:33.941] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:11:34.061] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:11:34.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:11:40.570] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:11:47.221] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:11:54.313] [mlr3]  Finished benchmark 
INFO  [07:11:54.452] [bbotk] Result of batch 67: 
INFO  [07:11:54.454] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:11:54.454] [bbotk]              2.338388                 2.913734                       0.3048316 
INFO  [07:11:54.454] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:11:54.454] [bbotk]                     4066        0.657 -0.9655962         <NA>   0.9673358 
INFO  [07:11:54.454] [bbotk]                                 uhash 
INFO  [07:11:54.454] [bbotk]  1b9bbe43-bdbc-48da-8606-0bdbb5c732da 
DEBUG [07:11:55.601] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.088451e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  3.088451e-05 0.004319264 
  - best initial criterion value(s) :  290.1549 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -290.15  |proj g|=       4.1327
At iterate     1  f =      -293.97  |proj g|=        3.9063
At iterate     2  f =      -294.71  |proj g|=        3.8743
At iterate     3  f =      -295.16  |proj g|=        4.0174
At iterate     4  f =      -295.17  |proj g|=        4.0062
At iterate     5  f =      -295.17  |proj g|=         4.006
At iterate     6  f =      -295.17  |proj g|=        4.0058
At iterate     7  f =      -295.17  |proj g|=        4.0057
At iterate     8  f =      -295.17  |proj g|=        4.0054
At iterate     9  f =      -295.17  |proj g|=         4.005
At iterate    10  f =      -295.17  |proj g|=        4.0043
At iterate    11  f =      -295.17  |proj g|=        4.0031
At iterate    12  f =      -295.17  |proj g|=        4.0011
At iterate    13  f =      -295.17  |proj g|=        3.9982
At iterate    14  f =      -295.18  |proj g|=        3.9933
At iterate    15  f =      -295.18  |proj g|=        3.9862
At iterate    16  f =      -295.19  |proj g|=        3.9801
At iterate    17  f =       -295.2  |proj g|=        3.9693
At iterate    18  f =      -295.41  |proj g|=        3.9122
At iterate    19  f =      -297.57  |proj g|=        3.3554
At iterate    20  f =      -311.74  |proj g|=        1.3926
At iterate    21  f =      -319.27  |proj g|=        1.2184
At iterate    22  f =      -319.48  |proj g|=        1.1649
At iterate    23  f =      -320.09  |proj g|=        1.1752
At iterate    24  f =      -320.12  |proj g|=        1.1677
At iterate    25  f =      -320.13  |proj g|=        1.1748
At iterate    26  f =      -320.13  |proj g|=        1.1735
At iterate    27  f =      -320.13  |proj g|=        1.1734
At iterate    28  f =      -320.13  |proj g|=        1.1734

iterations 28
function evaluations 33
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.17344
final function value -320.127

F = -320.127
final  value -320.127178 
converged
 
INFO  [07:11:55.606] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:11:55.694] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:11:55.702] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:11:59.552] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:12:03.267] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:12:06.500] [mlr3]  Finished benchmark 
INFO  [07:12:06.602] [bbotk] Result of batch 68: 
INFO  [07:12:06.604] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:12:06.604] [bbotk]              6.647637                  8.63655                       0.1892745 
INFO  [07:12:06.604] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:12:06.604] [bbotk]                     1252         0.84 -0.9752169         <NA>   0.9723827 
INFO  [07:12:06.604] [bbotk]                                 uhash 
INFO  [07:12:06.604] [bbotk]  80b310c4-4b1f-4f51-a142-346b4119094a 
DEBUG [07:12:07.589] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.057848e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  3.057848e-05 0.004235986 
  - best initial criterion value(s) :  310.1785 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -310.18  |proj g|=       3.7103
At iterate     1  f =      -311.44  |proj g|=        5.7623
At iterate     2  f =      -313.14  |proj g|=        5.4827
At iterate     3  f =      -314.93  |proj g|=        4.7291
At iterate     4  f =       -315.9  |proj g|=        4.2885
At iterate     5  f =      -318.52  |proj g|=        3.7039
At iterate     6  f =      -318.76  |proj g|=        3.8809
At iterate     7  f =      -318.82  |proj g|=        3.8463
At iterate     8  f =      -318.82  |proj g|=        3.8293
At iterate     9  f =      -318.82  |proj g|=         3.831
At iterate    10  f =      -318.82  |proj g|=        3.8354
At iterate    11  f =      -318.82  |proj g|=        3.8415
At iterate    12  f =      -318.83  |proj g|=        3.8517
At iterate    13  f =      -318.83  |proj g|=        3.8674
At iterate    14  f =      -318.85  |proj g|=        3.8922
At iterate    15  f =      -318.88  |proj g|=        3.9309
At iterate    16  f =      -318.97  |proj g|=         3.987
At iterate    17  f =      -319.14  |proj g|=        4.0488
At iterate    18  f =      -319.37  |proj g|=        4.0756
At iterate    19  f =      -319.63  |proj g|=        4.1332
At iterate    20  f =      -319.88  |proj g|=        3.9375
At iterate    21  f =      -320.39  |proj g|=        3.9494
At iterate    22  f =      -322.96  |proj g|=        3.6729
At iterate    23  f =      -349.12  |proj g|=       0.92495
At iterate    24  f =      -350.35  |proj g|=        1.0275
At iterate    25  f =      -350.46  |proj g|=          1.08
At iterate    26  f =      -350.46  |proj g|=        1.0864
At iterate    27  f =      -350.46  |proj g|=        1.0891
At iterate    28  f =      -350.46  |proj g|=        1.0892
At iterate    29  f =      -350.46  |proj g|=        1.0891
At iterate    30  f =      -350.46  |proj g|=        1.0886
At iterate    31  f =      -350.46  |proj g|=         1.088
At iterate    32  f =      -350.47  |proj g|=         1.087
At iterate    33  f =      -350.47  |proj g|=        1.0854
At iterate    34  f =      -350.47  |proj g|=        1.0832
At iterate    35  f =      -350.47  |proj g|=          1.08
At iterate    36  f =      -350.48  |proj g|=        1.0765
At iterate    37  f =      -350.49  |proj g|=        1.0571
At iterate    38  f =      -350.51  |proj g|=        1.0526
At iterate    39  f =      -350.61  |proj g|=       0.96258
At iterate    40  f =      -350.94  |proj g|=       0.91331
At iterate    41  f =      -351.66  |proj g|=       0.20678
At iterate    42  f =      -351.96  |proj g|=       0.19655
At iterate    43  f =      -352.14  |proj g|=       0.81646
At iterate    44  f =      -352.17  |proj g|=       0.81947
At iterate    45  f =      -352.17  |proj g|=       0.17495
At iterate    46  f =      -352.17  |proj g|=     0.0080916
At iterate    47  f =      -352.17  |proj g|=    0.00098151

iterations 47
function evaluations 52
segments explored during Cauchy searches 49
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000981509
final function value -352.174

F = -352.174
final  value -352.174272 
converged
 
INFO  [07:12:07.593] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:12:07.717] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:12:07.724] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:12:15.005] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:12:21.196] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:12:27.576] [mlr3]  Finished benchmark 
INFO  [07:12:27.736] [bbotk] Result of batch 69: 
INFO  [07:12:27.738] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:12:27.738] [bbotk]              2.200524                 4.631673                       0.4180582 
INFO  [07:12:27.738] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:12:27.738] [bbotk]                     3025        0.636 -0.9657531         <NA>   0.9651356 
INFO  [07:12:27.738] [bbotk]                                 uhash 
INFO  [07:12:27.738] [bbotk]  9306b126-81ad-4103-846e-64c66ccef1bc 
DEBUG [07:12:28.689] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.028786e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  3.028786e-05 0.004203566 
  - best initial criterion value(s) :  315.3071 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -315.31  |proj g|=       2.4797
At iterate     1  f =      -326.15  |proj g|=        4.4831
At iterate     2  f =      -327.12  |proj g|=        4.4209
At iterate     3  f =      -328.67  |proj g|=        4.1565
At iterate     4  f =      -328.69  |proj g|=        4.0727
At iterate     5  f =       -328.7  |proj g|=        4.1086
At iterate     6  f =      -328.72  |proj g|=        4.1264
At iterate     7  f =      -328.83  |proj g|=        4.2958
At iterate     8  f =      -328.88  |proj g|=        4.3838
At iterate     9  f =       -328.9  |proj g|=        4.3876
At iterate    10  f =       -328.9  |proj g|=        4.3847
At iterate    11  f =       -328.9  |proj g|=        4.3827
At iterate    12  f =       -328.9  |proj g|=        4.3779
At iterate    13  f =      -328.91  |proj g|=        4.3723
At iterate    14  f =      -328.94  |proj g|=        4.3682
At iterate    15  f =      -329.01  |proj g|=        4.3774
At iterate    16  f =      -329.15  |proj g|=        4.4376
At iterate    17  f =      -329.37  |proj g|=        4.4566
At iterate    18  f =      -329.85  |proj g|=        4.6605
At iterate    19  f =      -330.39  |proj g|=        4.5988
At iterate    20  f =      -330.99  |proj g|=        4.9464
At iterate    21  f =       -333.2  |proj g|=        4.3391
At iterate    22  f =      -336.84  |proj g|=        3.0885
At iterate    23  f =      -340.93  |proj g|=        2.0996
At iterate    24  f =      -345.09  |proj g|=        1.5862
At iterate    25  f =      -346.39  |proj g|=        1.7078
At iterate    26  f =      -347.63  |proj g|=        1.7665
At iterate    27  f =      -347.76  |proj g|=        1.7253
At iterate    28  f =      -347.79  |proj g|=        1.8129
At iterate    29  f =      -347.81  |proj g|=        1.7822
At iterate    30  f =      -347.81  |proj g|=        1.7814
At iterate    31  f =      -347.81  |proj g|=        1.7815
At iterate    32  f =      -347.81  |proj g|=        1.7816

iterations 32
function evaluations 40
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.78156
final function value -347.807

F = -347.807
final  value -347.807429 
converged
 
INFO  [07:12:28.693] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:12:28.783] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:12:28.790] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:12:37.737] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:12:45.771] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:12:53.855] [mlr3]  Finished benchmark 
INFO  [07:12:54.013] [bbotk] Result of batch 70: 
INFO  [07:12:54.015] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:12:54.015] [bbotk]              6.028058                 7.928256                       0.1200472 
INFO  [07:12:54.015] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:12:54.015] [bbotk]                     3644         0.64 -0.9681568         <NA>   0.9746868 
INFO  [07:12:54.015] [bbotk]                                 uhash 
INFO  [07:12:54.015] [bbotk]  f2b24ab4-626d-41c4-8ac0-6c26632991be 
DEBUG [07:12:55.180] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.001302e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  3.001302e-05 0.00417986 
  - best initial criterion value(s) :  319.3222 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -319.32  |proj g|=       1.2387
At iterate     1  f =      -331.41  |proj g|=        5.7514
At iterate     2  f =      -333.04  |proj g|=        5.4221
At iterate     3  f =      -335.04  |proj g|=         4.469
At iterate     4  f =      -335.22  |proj g|=        4.2345
At iterate     5  f =      -335.55  |proj g|=        4.1644
At iterate     6  f =      -336.09  |proj g|=        4.3146
At iterate     7  f =      -336.14  |proj g|=        4.4666
At iterate     8  f =      -336.15  |proj g|=        4.4342
At iterate     9  f =      -336.15  |proj g|=        4.4401
At iterate    10  f =      -336.15  |proj g|=        4.4404
At iterate    11  f =      -336.15  |proj g|=        4.4423
At iterate    12  f =      -336.15  |proj g|=        4.4442
At iterate    13  f =      -336.15  |proj g|=        4.4477
At iterate    14  f =      -336.15  |proj g|=        4.4535
At iterate    15  f =      -336.15  |proj g|=        4.4618
At iterate    16  f =      -336.15  |proj g|=        4.4725
At iterate    17  f =      -336.16  |proj g|=        4.4858
At iterate    18  f =      -336.17  |proj g|=        4.5145
At iterate    19  f =      -336.21  |proj g|=        4.5273
At iterate    20  f =      -336.21  |proj g|=        4.5748
At iterate    21  f =      -336.29  |proj g|=        4.5848
At iterate    22  f =      -339.17  |proj g|=        4.4632
At iterate    23  f =      -339.53  |proj g|=        4.3326
At iterate    24  f =      -339.92  |proj g|=        4.2281
At iterate    25  f =      -339.95  |proj g|=        4.2225
At iterate    26  f =      -339.95  |proj g|=        4.2286
At iterate    27  f =      -339.95  |proj g|=        4.2279
At iterate    28  f =      -339.95  |proj g|=        4.2261
At iterate    29  f =      -339.96  |proj g|=        4.2254
At iterate    30  f =      -339.96  |proj g|=        4.2097
At iterate    31  f =      -339.96  |proj g|=        4.2095
At iterate    32  f =      -339.97  |proj g|=        4.2058
At iterate    33  f =         -340  |proj g|=        4.1963
At iterate    34  f =      -340.07  |proj g|=        4.1658
At iterate    35  f =      -340.25  |proj g|=        4.0859
At iterate    36  f =      -340.63  |proj g|=        3.9718
At iterate    37  f =      -340.97  |proj g|=        2.8842
At iterate    38  f =      -342.11  |proj g|=        3.0798
At iterate    39  f =      -343.61  |proj g|=        2.9959
At iterate    40  f =      -346.59  |proj g|=        2.4944
At iterate    41  f =      -349.54  |proj g|=        1.9145
At iterate    42  f =      -349.71  |proj g|=       0.40584
At iterate    43  f =      -352.75  |proj g|=       0.68021
At iterate    44  f =      -355.95  |proj g|=       0.85795
At iterate    45  f =      -358.97  |proj g|=       0.86077
At iterate    46  f =      -360.06  |proj g|=       0.81234
At iterate    47  f =      -360.48  |proj g|=       0.81532
At iterate    48  f =       -360.5  |proj g|=       0.17666
At iterate    49  f =      -360.51  |proj g|=      0.070592
At iterate    50  f =      -360.51  |proj g|=       0.04942
At iterate    51  f =      -360.51  |proj g|=      0.014118
At iterate    52  f =      -360.51  |proj g|=       0.00319

iterations 52
function evaluations 63
segments explored during Cauchy searches 54
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00319003
final function value -360.507

F = -360.507
final  value -360.507018 
converged
 
INFO  [07:12:55.184] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:12:55.271] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:12:55.278] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:12:58.362] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:13:02.597] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:13:06.242] [mlr3]  Finished benchmark 
INFO  [07:13:06.344] [bbotk] Result of batch 71: 
INFO  [07:13:06.346] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:13:06.346] [bbotk]              8.726367                 8.179452                        0.334195 
INFO  [07:13:06.346] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:13:06.346] [bbotk]                     1533        0.766 -0.9652366         <NA>    0.975653 
INFO  [07:13:06.346] [bbotk]                                 uhash 
INFO  [07:13:06.346] [bbotk]  d21214db-ea4a-4e0f-8c96-56669cf0e15c 
DEBUG [07:13:07.513] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.975398e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.975398e-05 0.004102474 
  - best initial criterion value(s) :  323.516 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -323.52  |proj g|=       1.3229
At iterate     1  f =      -323.86  |proj g|=        1.3422
At iterate     2  f =       -323.9  |proj g|=        1.3388
At iterate     3  f =      -323.91  |proj g|=        1.3378
At iterate     4  f =      -323.91  |proj g|=        1.3379
At iterate     5  f =      -323.91  |proj g|=         1.338
At iterate     6  f =      -323.91  |proj g|=        1.3383
At iterate     7  f =      -323.91  |proj g|=        1.3392
At iterate     8  f =      -323.91  |proj g|=        1.3403
At iterate     9  f =      -323.91  |proj g|=        1.3414
At iterate    10  f =      -323.91  |proj g|=        1.3416
At iterate    11  f =      -323.91  |proj g|=        1.3415
At iterate    12  f =      -323.91  |proj g|=        1.3414
At iterate    13  f =      -323.91  |proj g|=        1.3413
At iterate    14  f =      -323.91  |proj g|=        1.3411
At iterate    15  f =      -323.91  |proj g|=        1.3407
At iterate    16  f =      -323.91  |proj g|=        1.3401
At iterate    17  f =      -323.91  |proj g|=        1.3388
At iterate    18  f =      -323.91  |proj g|=        1.3362
At iterate    19  f =      -323.91  |proj g|=         1.331
At iterate    20  f =      -323.92  |proj g|=        1.3238
At iterate    21  f =      -323.92  |proj g|=        1.3205
At iterate    22  f =      -323.92  |proj g|=        1.3201
At iterate    23  f =      -323.92  |proj g|=        1.3208
At iterate    24  f =      -323.92  |proj g|=        1.3215
At iterate    25  f =      -323.93  |proj g|=        1.3222
At iterate    26  f =      -323.94  |proj g|=        1.3222
At iterate    27  f =      -323.97  |proj g|=        1.3199
At iterate    28  f =      -324.05  |proj g|=        1.3105
At iterate    29  f =      -324.25  |proj g|=        1.2818
At iterate    30  f =      -324.79  |proj g|=        1.2053
At iterate    31  f =      -326.15  |proj g|=        1.0321
At iterate    32  f =      -328.77  |proj g|=       0.81843
At iterate    33  f =      -330.54  |proj g|=       0.47929
At iterate    34  f =      -330.58  |proj g|=       0.45242
At iterate    35  f =      -330.58  |proj g|=        0.4502
At iterate    36  f =      -330.58  |proj g|=       0.44855
At iterate    37  f =      -330.59  |proj g|=       0.44439
At iterate    38  f =      -330.59  |proj g|=       0.43957
At iterate    39  f =       -330.6  |proj g|=       0.43267
At iterate    40  f =      -330.63  |proj g|=       0.42811
At iterate    41  f =      -330.66  |proj g|=       0.43624
At iterate    42  f =      -330.67  |proj g|=       0.44581
At iterate    43  f =      -330.67  |proj g|=       0.44736
At iterate    44  f =      -330.67  |proj g|=       0.44743

iterations 44
function evaluations 50
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.447431
final function value -330.667

F = -330.667
final  value -330.666592 
converged
 
INFO  [07:13:07.518] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:13:07.654] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:13:07.661] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:13:10.777] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:13:13.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:13:16.376] [mlr3]  Finished benchmark 
INFO  [07:13:16.475] [bbotk] Result of batch 72: 
INFO  [07:13:16.477] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:13:16.477] [bbotk]              6.015121                 2.329491                       0.1103426 
INFO  [07:13:16.477] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:13:16.477] [bbotk]                     1282        0.785 -0.9755456         <NA>   0.9678111 
INFO  [07:13:16.477] [bbotk]                                 uhash 
INFO  [07:13:16.477] [bbotk]  5b6eb0c8-4447-4561-ace3-1bc4ab729d4e 
DEBUG [07:13:17.441] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.946497e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.946497e-05 0.004029037 
  - best initial criterion value(s) :  329.09 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -329.09  |proj g|=       2.9845
At iterate     1  f =      -329.17  |proj g|=        2.9956
At iterate     2  f =      -329.82  |proj g|=        2.8692
At iterate     3  f =      -331.16  |proj g|=        2.4713
At iterate     4  f =      -331.77  |proj g|=        2.3499
At iterate     5  f =      -331.78  |proj g|=        2.3885
At iterate     6  f =      -331.78  |proj g|=        2.3743
At iterate     7  f =      -331.79  |proj g|=        2.3671
At iterate     8  f =      -331.87  |proj g|=        2.3312
At iterate     9  f =      -332.04  |proj g|=        2.2668
At iterate    10  f =      -332.52  |proj g|=        2.1282
At iterate    11  f =      -333.82  |proj g|=        1.8418
At iterate    12  f =      -337.48  |proj g|=        1.3111
At iterate    13  f =      -344.41  |proj g|=       0.34509
At iterate    14  f =      -345.47  |proj g|=       0.88195
At iterate    15  f =      -345.71  |proj g|=       0.88242
At iterate    16  f =      -345.84  |proj g|=       0.88171
At iterate    17  f =      -345.99  |proj g|=       0.87946
At iterate    18  f =      -346.26  |proj g|=       0.87332
At iterate    19  f =      -346.62  |proj g|=       0.86165
At iterate    20  f =      -346.85  |proj g|=       0.85042
At iterate    21  f =      -346.86  |proj g|=       0.76568
At iterate    22  f =      -346.86  |proj g|=       0.60636
At iterate    23  f =      -346.86  |proj g|=       0.60511
At iterate    24  f =      -346.86  |proj g|=        0.6051

iterations 24
function evaluations 31
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.605102
final function value -346.865

F = -346.865
final  value -346.864501 
converged
 
INFO  [07:13:17.445] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:13:17.547] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:13:17.553] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:13:25.297] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:13:33.282] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:13:40.515] [mlr3]  Finished benchmark 
INFO  [07:13:40.613] [bbotk] Result of batch 73: 
INFO  [07:13:40.614] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:13:40.614] [bbotk]               9.07457                 7.062129                      0.08219654 
INFO  [07:13:40.614] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:13:40.614] [bbotk]                     3387        0.668 -0.9729942         <NA>   0.9736516 
INFO  [07:13:40.614] [bbotk]                                 uhash 
INFO  [07:13:40.614] [bbotk]  542b1e27-53de-4d66-aa83-d85ef8a4db51 
DEBUG [07:13:41.569] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.919578e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.919578e-05 0.004006119 
  - best initial criterion value(s) :  336.8549 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -336.85  |proj g|=       5.6381
At iterate     1  f =      -339.74  |proj g|=        7.4548
At iterate     2  f =      -341.48  |proj g|=        7.1695
At iterate     3  f =      -344.72  |proj g|=        5.7524
At iterate     4  f =      -346.48  |proj g|=        4.6224
At iterate     5  f =       -349.6  |proj g|=        4.0354
At iterate     6  f =      -349.62  |proj g|=        3.9419
At iterate     7  f =      -349.62  |proj g|=         3.944
At iterate     8  f =      -349.62  |proj g|=        3.9504
At iterate     9  f =      -349.63  |proj g|=        3.9657
At iterate    10  f =      -349.77  |proj g|=        4.0175
At iterate    11  f =      -350.16  |proj g|=        3.9875
At iterate    12  f =      -350.91  |proj g|=        4.0715
At iterate    13  f =      -352.31  |proj g|=         3.312
At iterate    14  f =      -354.39  |proj g|=        3.0699
At iterate    15  f =      -361.06  |proj g|=        2.1196
At iterate    16  f =      -369.22  |proj g|=         1.314
At iterate    17  f =      -370.68  |proj g|=        1.1649
At iterate    18  f =      -371.06  |proj g|=        1.0539
At iterate    19  f =      -371.43  |proj g|=         1.101
At iterate    20  f =       -371.5  |proj g|=        1.1279
At iterate    21  f =      -371.51  |proj g|=        1.1089
At iterate    22  f =      -371.51  |proj g|=        1.1127
At iterate    23  f =      -371.51  |proj g|=        1.1121
At iterate    24  f =      -371.51  |proj g|=        1.1121

iterations 24
function evaluations 30
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.11206
final function value -371.513

F = -371.513
final  value -371.513269 
converged
 
INFO  [07:13:41.571] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:13:41.646] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:13:41.653] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:13:46.668] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:13:52.167] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:13:56.703] [mlr3]  Finished benchmark 
INFO  [07:13:56.799] [bbotk] Result of batch 74: 
INFO  [07:13:56.801] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:13:56.801] [bbotk]              8.554056                 2.175259                       0.2780608 
INFO  [07:13:56.801] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:13:56.801] [bbotk]                     2398        0.659 -0.9649096         <NA>   0.9763944 
INFO  [07:13:56.801] [bbotk]                                 uhash 
INFO  [07:13:56.801] [bbotk]  94e72fb0-7826-4bfd-8c65-f9b656212447 
DEBUG [07:13:57.723] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.896027e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.896027e-05 0.003987878 
  - best initial criterion value(s) :  327.9428 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -327.94  |proj g|=      0.99724
At iterate     1  f =      -337.59  |proj g|=        1.1205
At iterate     2  f =      -337.78  |proj g|=        1.1012
At iterate     3  f =      -338.01  |proj g|=        1.0847
At iterate     4  f =      -338.06  |proj g|=        1.0815
At iterate     5  f =      -338.06  |proj g|=        1.0852
At iterate     6  f =      -338.06  |proj g|=        1.0842
At iterate     7  f =      -338.06  |proj g|=        1.0843
At iterate     8  f =      -338.06  |proj g|=        1.0843

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.08427
final function value -338.064

F = -338.064
final  value -338.064465 
converged
 
INFO  [07:13:57.727] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:13:57.816] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:13:57.841] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:14:02.424] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:14:07.486] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:14:13.507] [mlr3]  Finished benchmark 
INFO  [07:14:13.605] [bbotk] Result of batch 75: 
INFO  [07:14:13.607] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:14:13.607] [bbotk]              6.556375                 9.622393                      0.03711395 
INFO  [07:14:13.607] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:14:13.607] [bbotk]                     2201        0.684 -0.9753286         <NA>   0.9627216 
INFO  [07:14:13.607] [bbotk]                                 uhash 
INFO  [07:14:13.607] [bbotk]  e4c1ac22-f486-4bf1-92ed-621db4870676 
DEBUG [07:14:14.866] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.872869e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.872869e-05 0.003964961 
  - best initial criterion value(s) :  312.9299 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -312.93  |proj g|=       1.0023
At iterate     1  f =       -334.2  |proj g|=        2.4728
At iterate     2  f =      -335.76  |proj g|=        2.3975
At iterate     3  f =      -337.42  |proj g|=          1.93
At iterate     4  f =      -338.18  |proj g|=        2.1208
At iterate     5  f =      -338.34  |proj g|=        2.0766
At iterate     6  f =      -338.86  |proj g|=        2.0263
At iterate     7  f =      -339.85  |proj g|=        1.9797
At iterate     8  f =      -342.27  |proj g|=        1.9314
At iterate     9  f =      -343.47  |proj g|=        2.3567
At iterate    10  f =      -344.29  |proj g|=        2.3212
At iterate    11  f =       -344.3  |proj g|=        2.3212
At iterate    12  f =      -344.31  |proj g|=        2.3237
At iterate    13  f =      -344.63  |proj g|=        2.3588
At iterate    14  f =      -346.13  |proj g|=        2.3889
At iterate    15  f =      -350.39  |proj g|=        2.5125
At iterate    16  f =       -352.5  |proj g|=        1.2924
At iterate    17  f =      -357.86  |proj g|=         1.967
At iterate    18  f =      -357.92  |proj g|=        1.9036
At iterate    19  f =      -357.98  |proj g|=        1.8129
At iterate    20  f =         -358  |proj g|=        1.7916
At iterate    21  f =      -358.08  |proj g|=        1.7561
At iterate    22  f =      -358.14  |proj g|=        1.7902
At iterate    23  f =      -358.16  |proj g|=        1.8531
At iterate    24  f =      -358.16  |proj g|=        1.8567
At iterate    25  f =      -358.16  |proj g|=        1.8571
At iterate    26  f =      -358.16  |proj g|=        1.8573
At iterate    27  f =      -358.16  |proj g|=        1.8578
At iterate    28  f =      -358.16  |proj g|=        1.8584
At iterate    29  f =      -358.16  |proj g|=        1.8595
At iterate    30  f =      -358.16  |proj g|=         1.861
At iterate    31  f =      -358.16  |proj g|=        1.8626
At iterate    32  f =      -358.16  |proj g|=        1.8644
At iterate    33  f =      -358.17  |proj g|=        1.8651
At iterate    34  f =      -358.17  |proj g|=         1.873
At iterate    35  f =      -358.18  |proj g|=        1.8647
At iterate    36  f =      -358.19  |proj g|=         1.891
At iterate    37  f =      -358.22  |proj g|=        1.8752
At iterate    38  f =      -358.49  |proj g|=        1.8082
At iterate    39  f =      -359.49  |proj g|=        1.5853
At iterate    40  f =      -360.15  |proj g|=        1.3601
At iterate    41  f =      -362.84  |proj g|=       0.83258
At iterate    42  f =      -364.85  |proj g|=       0.26077
At iterate    43  f =      -365.24  |proj g|=       0.24009
At iterate    44  f =      -365.31  |proj g|=       0.77165
At iterate    45  f =      -365.31  |proj g|=        0.2097
At iterate    46  f =      -365.31  |proj g|=     0.0037322
At iterate    47  f =      -365.31  |proj g|=     0.0037326

iterations 47
function evaluations 54
segments explored during Cauchy searches 50
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00373256
final function value -365.308

F = -365.308
final  value -365.307614 
converged
 
INFO  [07:14:14.870] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:14:14.957] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:14:14.964] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:14:21.250] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:14:26.771] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:14:32.827] [mlr3]  Finished benchmark 
INFO  [07:14:32.952] [bbotk] Result of batch 76: 
INFO  [07:14:32.953] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:14:32.953] [bbotk]              6.114564                 2.042012                       0.1282617 
INFO  [07:14:32.953] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:14:32.953] [bbotk]                     2986        0.859 -0.9525895         <NA>   0.9743321 
INFO  [07:14:32.953] [bbotk]                                 uhash 
INFO  [07:14:32.953] [bbotk]  1d1526a0-d5f3-4a49-a959-c919de4601b7 
DEBUG [07:14:33.937] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.847945e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.847945e-05 0.003943618 
  - best initial criterion value(s) :  330.6617 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -330.66  |proj g|=       7.1612
At iterate     1  f =      -331.91  |proj g|=        7.6481
At iterate     2  f =      -334.09  |proj g|=        6.3895
At iterate     3  f =      -334.22  |proj g|=        6.2878
At iterate     4  f =      -334.34  |proj g|=        6.3142
At iterate     5  f =      -334.38  |proj g|=        6.4814
At iterate     6  f =      -334.38  |proj g|=        6.5026
At iterate     7  f =      -334.38  |proj g|=         6.498
At iterate     8  f =       -334.4  |proj g|=        6.4598
At iterate     9  f =      -334.43  |proj g|=         6.403
At iterate    10  f =      -334.51  |proj g|=        6.3015
At iterate    11  f =      -334.59  |proj g|=         6.373
At iterate    12  f =      -334.87  |proj g|=        6.0166
At iterate    13  f =      -335.27  |proj g|=        5.6639
At iterate    14  f =      -336.37  |proj g|=        4.9844
At iterate    15  f =      -338.44  |proj g|=        4.1088
At iterate    16  f =      -342.66  |proj g|=        3.0735
At iterate    17  f =      -352.72  |proj g|=         1.948
At iterate    18  f =       -375.3  |proj g|=        1.0284
At iterate    19  f =      -376.09  |proj g|=       0.99496
At iterate    20  f =      -378.22  |proj g|=        1.3397
At iterate    21  f =      -378.29  |proj g|=        1.3724
At iterate    22  f =      -378.29  |proj g|=        1.3864
At iterate    23  f =      -378.29  |proj g|=         1.389
At iterate    24  f =      -378.29  |proj g|=        1.3891

iterations 24
function evaluations 30
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.38914
final function value -378.294

F = -378.294
final  value -378.294105 
converged
 
INFO  [07:14:33.941] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:14:34.027] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:14:34.034] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:14:36.067] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:14:37.879] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:14:39.502] [mlr3]  Finished benchmark 
INFO  [07:14:39.637] [bbotk] Result of batch 77: 
INFO  [07:14:39.639] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:14:39.639] [bbotk]                6.1822                  9.66275                       0.3603021 
INFO  [07:14:39.639] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:14:39.639] [bbotk]                      644        0.672 -0.9680503         <NA>   0.9720237 
INFO  [07:14:39.639] [bbotk]                                 uhash 
INFO  [07:14:39.639] [bbotk]  d44e93fd-36e9-489c-9b64-26d94c7c0783 
DEBUG [07:14:40.632] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.821896e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.821896e-05 0.003871938 
  - best initial criterion value(s) :  340.1727 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -340.17  |proj g|=       1.4487
At iterate     1  f =      -357.23  |proj g|=        5.1467
At iterate     2  f =      -359.71  |proj g|=        4.8253
At iterate     3  f =      -363.96  |proj g|=        3.8276
At iterate     4  f =       -364.4  |proj g|=        3.4216
At iterate     5  f =      -364.67  |proj g|=        3.3985
At iterate     6  f =      -365.54  |proj g|=        3.5556
At iterate     7  f =      -365.64  |proj g|=        3.8152
At iterate     8  f =      -365.65  |proj g|=        3.7593
At iterate     9  f =      -365.65  |proj g|=        3.7569
At iterate    10  f =      -365.65  |proj g|=         3.759
At iterate    11  f =      -365.65  |proj g|=        3.7589
At iterate    12  f =      -365.65  |proj g|=        3.7672
At iterate    13  f =      -365.65  |proj g|=        3.7742
At iterate    14  f =      -365.66  |proj g|=        3.7975
At iterate    15  f =      -365.68  |proj g|=        3.8189
At iterate    16  f =      -365.74  |proj g|=        3.8329
At iterate    17  f =      -365.88  |proj g|=        3.7953
At iterate    18  f =      -366.17  |proj g|=        3.6147
At iterate    19  f =      -366.58  |proj g|=        3.2075
At iterate    20  f =      -366.71  |proj g|=        2.8927
At iterate    21  f =      -366.75  |proj g|=        2.9064
At iterate    22  f =      -367.16  |proj g|=        2.9256
At iterate    23  f =       -367.7  |proj g|=        2.8219
At iterate    24  f =      -368.17  |proj g|=        2.5315
At iterate    25  f =      -368.36  |proj g|=        2.5023
At iterate    26  f =      -368.39  |proj g|=        2.5475
At iterate    27  f =      -368.39  |proj g|=        2.5733
At iterate    28  f =      -368.39  |proj g|=        2.5733
At iterate    29  f =      -368.39  |proj g|=        2.5732

iterations 29
function evaluations 34
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.57323
final function value -368.388

F = -368.388
final  value -368.388019 
converged
 
INFO  [07:14:40.636] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:14:40.724] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:14:40.731] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:14:42.299] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:14:44.493] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:14:46.092] [mlr3]  Finished benchmark 
INFO  [07:14:46.192] [bbotk] Result of batch 78: 
INFO  [07:14:46.194] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:14:46.194] [bbotk]              9.000852                 7.286888                       0.4397165 
INFO  [07:14:46.194] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:14:46.194] [bbotk]                      681        0.668 -0.9686113         <NA>   0.9739346 
INFO  [07:14:46.194] [bbotk]                                 uhash 
INFO  [07:14:46.194] [bbotk]  e4e218e2-0a1e-4341-a533-d2ac42e7b718 
DEBUG [07:14:47.273] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.797513e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.797513e-05 0.003803779 
  - best initial criterion value(s) :  330.9297 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -330.93  |proj g|=        1.523
At iterate     1  f =      -340.33  |proj g|=        7.1472
At iterate     2  f =      -344.25  |proj g|=        6.4772
At iterate     3  f =      -349.06  |proj g|=         4.502
At iterate     4  f =      -349.59  |proj g|=        3.9925
At iterate     5  f =      -350.88  |proj g|=        3.5489
At iterate     6  f =      -353.95  |proj g|=         3.186
At iterate     7  f =      -355.06  |proj g|=        4.8602
At iterate     8  f =      -356.54  |proj g|=        4.1351
At iterate     9  f =      -356.77  |proj g|=         3.822
At iterate    10  f =      -356.79  |proj g|=        3.7754
At iterate    11  f =      -356.81  |proj g|=        3.7886
At iterate    12  f =      -356.82  |proj g|=        3.8168
At iterate    13  f =      -356.82  |proj g|=          3.83
At iterate    14  f =      -356.82  |proj g|=        3.8433
At iterate    15  f =      -356.83  |proj g|=        3.8596
At iterate    16  f =      -356.84  |proj g|=        3.8795
At iterate    17  f =      -356.88  |proj g|=         3.889
At iterate    18  f =      -356.95  |proj g|=        3.8479
At iterate    19  f =      -357.03  |proj g|=        3.9895
At iterate    20  f =      -357.23  |proj g|=        3.7908
At iterate    21  f =      -357.62  |proj g|=         3.472
At iterate    22  f =      -358.14  |proj g|=        3.2344
At iterate    23  f =      -358.41  |proj g|=         3.129
At iterate    24  f =      -359.82  |proj g|=        2.7808
At iterate    25  f =      -365.49  |proj g|=        1.7725
At iterate    26  f =      -373.06  |proj g|=       0.44298
At iterate    27  f =      -376.47  |proj g|=       0.63449
At iterate    28  f =      -381.46  |proj g|=        1.5619
At iterate    29  f =      -383.17  |proj g|=        1.3531
At iterate    30  f =      -384.46  |proj g|=       0.93714
At iterate    31  f =      -384.86  |proj g|=         1.114
At iterate    32  f =      -384.91  |proj g|=        1.0878
At iterate    33  f =      -384.94  |proj g|=        1.1088
At iterate    34  f =      -384.94  |proj g|=        1.1032
At iterate    35  f =      -384.94  |proj g|=        1.1031
At iterate    36  f =      -384.94  |proj g|=        1.1037
At iterate    37  f =      -384.94  |proj g|=        1.1058
At iterate    38  f =      -384.95  |proj g|=        1.1089
At iterate    39  f =      -384.95  |proj g|=        1.1142
At iterate    40  f =      -384.96  |proj g|=        1.1193
At iterate    41  f =      -384.99  |proj g|=        1.1239
At iterate    42  f =      -385.06  |proj g|=        1.1196
At iterate    43  f =       -385.2  |proj g|=         1.137
At iterate    44  f =      -385.51  |proj g|=        1.0511
At iterate    45  f =      -385.93  |proj g|=       0.73345
At iterate    46  f =      -386.27  |proj g|=       0.45014
At iterate    47  f =         -387  |proj g|=       0.23691
At iterate    48  f =      -387.18  |proj g|=       0.21573
At iterate    49  f =      -387.24  |proj g|=       0.78881
At iterate    50  f =      -387.24  |proj g|=      0.067794
At iterate    51  f =      -387.24  |proj g|=     0.0039636
At iterate    52  f =      -387.24  |proj g|=     0.0039625

iterations 52
function evaluations 59
segments explored during Cauchy searches 54
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00396252
final function value -387.244

F = -387.244
final  value -387.243673 
converged
 
INFO  [07:14:47.278] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:14:47.396] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:14:47.403] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:14:52.244] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:14:56.363] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:15:01.906] [mlr3]  Finished benchmark 
INFO  [07:15:02.010] [bbotk] Result of batch 79: 
INFO  [07:15:02.012] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:15:02.012] [bbotk]               3.30103                 5.744414                       0.1217464 
INFO  [07:15:02.012] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:15:02.012] [bbotk]                     2097        0.676 -0.9562617         <NA>   0.9664422 
INFO  [07:15:02.012] [bbotk]                                 uhash 
INFO  [07:15:02.012] [bbotk]  899dd01f-94d1-485f-934b-8b5462edc2ca 
DEBUG [07:15:03.134] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.772761e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.772761e-05 0.00378094 
  - best initial criterion value(s) :  340.1897 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -340.19  |proj g|=      0.83049
At iterate     1  f =      -349.71  |proj g|=       0.97841
At iterate     2  f =      -350.43  |proj g|=       0.97822
At iterate     3  f =      -350.89  |proj g|=       0.97757
At iterate     4  f =      -351.14  |proj g|=       0.97781
At iterate     5  f =      -351.17  |proj g|=       0.97774
At iterate     6  f =       -351.2  |proj g|=       0.97763
At iterate     7  f =      -351.28  |proj g|=       0.97732
At iterate     8  f =      -351.52  |proj g|=       0.97635
At iterate     9  f =      -352.17  |proj g|=        1.0188
At iterate    10  f =      -354.54  |proj g|=        1.2596
At iterate    11  f =      -363.89  |proj g|=        2.0019
At iterate    12  f =      -364.19  |proj g|=        2.0993
At iterate    13  f =      -364.41  |proj g|=        2.1674
At iterate    14  f =      -364.55  |proj g|=        2.1981
At iterate    15  f =      -364.56  |proj g|=        2.1994
At iterate    16  f =      -364.56  |proj g|=        2.2037
At iterate    17  f =      -364.57  |proj g|=        2.2111
At iterate    18  f =      -364.58  |proj g|=        2.2295
At iterate    19  f =      -364.61  |proj g|=        2.2516
At iterate    20  f =      -364.68  |proj g|=        2.2881
At iterate    21  f =      -364.86  |proj g|=        2.3421
At iterate    22  f =      -365.32  |proj g|=        2.4178
At iterate    23  f =      -366.32  |proj g|=        2.4794
At iterate    24  f =      -368.88  |proj g|=        2.4776
At iterate    25  f =      -372.42  |proj g|=        2.2208
At iterate    26  f =      -381.92  |proj g|=        1.0908
At iterate    27  f =      -382.14  |proj g|=         1.144
At iterate    28  f =      -382.24  |proj g|=         1.103
At iterate    29  f =      -382.29  |proj g|=        1.2176
At iterate    30  f =      -382.31  |proj g|=        1.1673
At iterate    31  f =      -382.31  |proj g|=        1.1654
At iterate    32  f =      -382.31  |proj g|=        1.1658
At iterate    33  f =      -382.31  |proj g|=        1.1661
At iterate    34  f =      -382.31  |proj g|=        1.1664
At iterate    35  f =      -382.31  |proj g|=        1.1673
At iterate    36  f =      -382.31  |proj g|=        1.1684
At iterate    37  f =      -382.31  |proj g|=        1.1712
At iterate    38  f =      -382.31  |proj g|=        1.1559
At iterate    39  f =      -382.32  |proj g|=        1.1708
At iterate    40  f =      -382.33  |proj g|=        1.1843
At iterate    41  f =      -382.37  |proj g|=        1.2123
At iterate    42  f =      -382.47  |proj g|=         1.239
At iterate    43  f =       -382.7  |proj g|=        1.2517
At iterate    44  f =      -383.15  |proj g|=        1.0826
At iterate    45  f =      -384.51  |proj g|=       0.75615
At iterate    46  f =      -384.57  |proj g|=       0.23915
At iterate    47  f =      -384.57  |proj g|=       0.23916
At iterate    48  f =      -384.57  |proj g|=       0.23915
At iterate    49  f =      -384.57  |proj g|=       0.23914
At iterate    50  f =      -384.57  |proj g|=       0.23911
At iterate    51  f =      -384.57  |proj g|=       0.23901
At iterate    52  f =      -384.57  |proj g|=       0.23874
At iterate    53  f =      -384.58  |proj g|=       0.23804
At iterate    54  f =      -384.59  |proj g|=       0.23623
At iterate    55  f =      -384.61  |proj g|=        0.2321
At iterate    56  f =      -384.64  |proj g|=       0.22461
At iterate    57  f =      -384.68  |proj g|=       0.22097
At iterate    58  f =      -384.68  |proj g|=       0.13927
At iterate    59  f =      -384.68  |proj g|=     0.0037127
At iterate    60  f =      -384.68  |proj g|=     0.0037126

iterations 60
function evaluations 66
segments explored during Cauchy searches 62
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00371259
final function value -384.682

F = -384.682
final  value -384.682243 
converged
 
INFO  [07:15:03.138] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:15:03.257] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:15:03.268] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:15:14.302] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:15:24.811] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:15:37.724] [mlr3]  Finished benchmark 
INFO  [07:15:37.828] [bbotk] Result of batch 80: 
INFO  [07:15:37.830] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:15:37.830] [bbotk]              4.204196                 5.188462                      0.09580618 
INFO  [07:15:37.830] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:15:37.830] [bbotk]                     4705        0.679 -0.9529999         <NA>   0.9731402 
INFO  [07:15:37.830] [bbotk]                                 uhash 
INFO  [07:15:37.830] [bbotk]  5306fd06-7693-41ed-954e-0bce9f7267d7 
DEBUG [07:15:38.998] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.748694e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.748694e-05 0.003759793 
  - best initial criterion value(s) :  358.7922 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -358.79  |proj g|=        3.739
At iterate     1  f =       -361.7  |proj g|=        4.1636
At iterate     2  f =      -362.32  |proj g|=        5.0076
At iterate     3  f =       -364.3  |proj g|=        4.6606
At iterate     4  f =      -365.91  |proj g|=        4.2384
At iterate     5  f =      -366.41  |proj g|=        4.1193
At iterate     6  f =      -366.81  |proj g|=         4.307
At iterate     7  f =      -366.87  |proj g|=        4.3219
At iterate     8  f =      -366.88  |proj g|=        4.2974
At iterate     9  f =      -366.88  |proj g|=        4.2966
At iterate    10  f =      -366.89  |proj g|=        4.3325
At iterate    11  f =      -366.95  |proj g|=        4.3209
At iterate    12  f =      -368.25  |proj g|=        4.1228
At iterate    13  f =       -372.6  |proj g|=        3.4574
At iterate    14  f =      -385.83  |proj g|=        2.2714
At iterate    15  f =      -399.58  |proj g|=        1.0249
At iterate    16  f =      -399.63  |proj g|=        1.1045
At iterate    17  f =      -399.69  |proj g|=         1.043
At iterate    18  f =      -399.69  |proj g|=        1.0346
At iterate    19  f =      -399.69  |proj g|=         1.035
At iterate    20  f =      -399.69  |proj g|=         1.035

iterations 20
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.03502
final function value -399.692

F = -399.692
final  value -399.691879 
converged
 
INFO  [07:15:39.002] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:15:39.233] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:15:39.240] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:15:44.462] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:15:49.340] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:15:53.582] [mlr3]  Finished benchmark 
INFO  [07:15:53.683] [bbotk] Result of batch 81: 
INFO  [07:15:53.685] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:15:53.685] [bbotk]              3.662791                 4.213531                       0.3808409 
INFO  [07:15:53.685] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [07:15:53.685] [bbotk]                     2063        0.824   -0.9631         <NA>   0.9743131 
INFO  [07:15:53.685] [bbotk]                                 uhash 
INFO  [07:15:53.685] [bbotk]  44a8b7d2-7b8e-42c4-94c6-069b60dc9db9 
DEBUG [07:15:54.698] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.725901e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.725901e-05 0.003737089 
  - best initial criterion value(s) :  328.7898 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -328.79  |proj g|=       5.3413
At iterate     1  f =      -342.64  |proj g|=        4.7725
At iterate     2  f =      -346.94  |proj g|=        5.8566
At iterate     3  f =      -347.44  |proj g|=        5.6668
At iterate     4  f =      -347.65  |proj g|=        5.4054
At iterate     5  f =      -347.65  |proj g|=        5.4086
At iterate     6  f =      -347.65  |proj g|=        5.4113
At iterate     7  f =      -347.65  |proj g|=        5.4095
At iterate     8  f =      -347.65  |proj g|=         5.399
At iterate     9  f =      -347.66  |proj g|=        5.3884
At iterate    10  f =      -347.67  |proj g|=        5.3675
At iterate    11  f =      -347.71  |proj g|=        5.3331
At iterate    12  f =      -347.81  |proj g|=        5.2754
At iterate    13  f =      -348.08  |proj g|=        5.1863
At iterate    14  f =      -348.83  |proj g|=        5.0512
At iterate    15  f =      -350.76  |proj g|=        4.8421
At iterate    16  f =      -353.53  |proj g|=        3.1993
At iterate    17  f =      -371.16  |proj g|=        3.1124
At iterate    18  f =      -393.69  |proj g|=        1.7951
At iterate    19  f =       -404.1  |proj g|=       0.87561
At iterate    20  f =      -404.94  |proj g|=       0.18421
At iterate    21  f =      -405.97  |proj g|=       0.16301
At iterate    22  f =      -406.31  |proj g|=       0.15813
At iterate    23  f =       -406.7  |proj g|=       0.67239
At iterate    24  f =       -406.8  |proj g|=       0.17495
At iterate    25  f =      -406.81  |proj g|=        0.5013
At iterate    26  f =      -406.81  |proj g|=      0.077963
At iterate    27  f =      -406.81  |proj g|=      0.036671
At iterate    28  f =      -406.81  |proj g|=      0.036671

iterations 28
function evaluations 31
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0366707
final function value -406.808

F = -406.808
final  value -406.807859 
converged
 
INFO  [07:15:54.702] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:15:54.896] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:15:54.903] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:16:01.328] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:16:09.711] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:16:15.569] [mlr3]  Finished benchmark 
INFO  [07:16:15.672] [bbotk] Result of batch 82: 
INFO  [07:16:15.674] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:16:15.674] [bbotk]              3.759483                 6.559617                       0.3486302 
INFO  [07:16:15.674] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:16:15.674] [bbotk]                     2749        0.691 -0.9650556         <NA>   0.9753196 
INFO  [07:16:15.674] [bbotk]                                 uhash 
INFO  [07:16:15.674] [bbotk]  eda32909-7b6f-48c6-b08e-6fd9dbaaebf0 
DEBUG [07:16:16.890] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.7044e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.7044e-05 0.003720789 
  - best initial criterion value(s) :  375.649 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -375.65  |proj g|=       1.0386
At iterate     1  f =      -381.03  |proj g|=         2.082
At iterate     2  f =      -396.76  |proj g|=        1.7629
At iterate     3  f =      -397.26  |proj g|=        1.8586
At iterate     4  f =      -398.09  |proj g|=        1.8718
At iterate     5  f =      -402.09  |proj g|=        1.9882
At iterate     6  f =      -402.46  |proj g|=        2.1698
At iterate     7  f =      -402.71  |proj g|=        2.1423
At iterate     8  f =      -402.76  |proj g|=        2.1242
At iterate     9  f =      -402.78  |proj g|=        2.1292
At iterate    10  f =      -402.92  |proj g|=        2.1467
At iterate    11  f =      -403.16  |proj g|=        2.1441
At iterate    12  f =       -404.2  |proj g|=        1.9773
At iterate    13  f =      -406.32  |proj g|=        1.5948
At iterate    14  f =      -406.69  |proj g|=        1.1206
At iterate    15  f =      -407.81  |proj g|=        1.0326
At iterate    16  f =      -408.45  |proj g|=       0.88793
At iterate    17  f =      -408.98  |proj g|=       0.83282
At iterate    18  f =       -409.1  |proj g|=       0.98983
At iterate    19  f =      -409.12  |proj g|=        0.9501
At iterate    20  f =      -409.12  |proj g|=        0.9448
At iterate    21  f =      -409.12  |proj g|=       0.94563
At iterate    22  f =      -409.12  |proj g|=       0.94562

iterations 22
function evaluations 28
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.945616
final function value -409.12

F = -409.12
final  value -409.120012 
converged
 
INFO  [07:16:16.895] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:16:17.025] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:16:17.032] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:16:23.128] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:16:29.504] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:16:37.894] [mlr3]  Finished benchmark 
INFO  [07:16:38.010] [bbotk] Result of batch 83: 
INFO  [07:16:38.012] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:16:38.012] [bbotk]              3.054833                 4.612583                      0.05808403 
INFO  [07:16:38.012] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:16:38.012] [bbotk]                     2892        0.858 -0.9613253         <NA>   0.9587284 
INFO  [07:16:38.012] [bbotk]                                 uhash 
INFO  [07:16:38.012] [bbotk]  6c3f862d-8ab2-4257-9a84-3044379538af 
DEBUG [07:16:39.166] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.691041e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.691041e-05 0.003701296 
  - best initial criterion value(s) :  365.9293 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -365.93  |proj g|=       1.5533
At iterate     1  f =      -376.09  |proj g|=        2.2149
At iterate     2  f =      -379.66  |proj g|=         2.189
At iterate     3  f =      -381.34  |proj g|=        2.1193
At iterate     4  f =      -381.51  |proj g|=        2.0911
At iterate     5  f =      -381.76  |proj g|=        2.0645
At iterate     6  f =      -381.89  |proj g|=        2.0379
At iterate     7  f =      -381.91  |proj g|=        2.0539
At iterate     8  f =      -381.91  |proj g|=        2.0511
At iterate     9  f =      -381.91  |proj g|=        2.0509
At iterate    10  f =      -381.91  |proj g|=        2.0509

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.05089
final function value -381.914

F = -381.914
final  value -381.913812 
converged
 
INFO  [07:16:39.170] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:16:39.256] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:16:39.263] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:16:48.853] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:16:56.586] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:17:04.076] [mlr3]  Finished benchmark 
INFO  [07:17:04.175] [bbotk] Result of batch 84: 
INFO  [07:17:04.177] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:17:04.177] [bbotk]              7.609836                 9.314655                       0.3973934 
INFO  [07:17:04.177] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:17:04.177] [bbotk]                     4616        0.891 -0.9734058         <NA>   0.9779855 
INFO  [07:17:04.177] [bbotk]                                 uhash 
INFO  [07:17:04.177] [bbotk]  d60d0a7a-dbd0-4dee-867f-3558560ac06e 
DEBUG [07:17:05.187] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.673534e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.673534e-05 0.00368873 
  - best initial criterion value(s) :  363.0527 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -363.05  |proj g|=        11.23
At iterate     1  f =      -377.29  |proj g|=        4.3344
At iterate     2  f =      -377.54  |proj g|=        5.1343
At iterate     3  f =       -377.7  |proj g|=        4.9438
At iterate     4  f =      -377.77  |proj g|=        4.8795
At iterate     5  f =      -377.84  |proj g|=        4.9438
At iterate     6  f =      -377.94  |proj g|=        5.2388
At iterate     7  f =      -377.99  |proj g|=        5.4007
At iterate     8  f =      -378.04  |proj g|=        5.5122
At iterate     9  f =      -378.21  |proj g|=        5.7214
At iterate    10  f =      -378.61  |proj g|=        5.9463
At iterate    11  f =      -379.73  |proj g|=        5.9894
At iterate    12  f =      -382.66  |proj g|=        5.2548
At iterate    13  f =      -386.52  |proj g|=        3.0011
At iterate    14  f =      -388.35  |proj g|=        2.7043
At iterate    15  f =      -396.43  |proj g|=        2.3166
At iterate    16  f =      -398.24  |proj g|=        1.9933
At iterate    17  f =      -412.91  |proj g|=        1.0665
At iterate    18  f =      -416.05  |proj g|=       0.93977
At iterate    19  f =      -416.88  |proj g|=        1.1442
At iterate    20  f =      -416.89  |proj g|=        1.1826
At iterate    21  f =      -416.89  |proj g|=        1.1791
At iterate    22  f =      -416.89  |proj g|=        1.1789

iterations 22
function evaluations 32
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.17892
final function value -416.892

F = -416.892
final  value -416.891654 
converged
 
INFO  [07:17:05.191] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:17:05.277] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:17:05.283] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:17:10.540] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:17:15.862] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:17:21.326] [mlr3]  Finished benchmark 
INFO  [07:17:21.447] [bbotk] Result of batch 85: 
INFO  [07:17:21.449] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:17:21.449] [bbotk]              9.767083                 7.286868                       0.4963832 
INFO  [07:17:21.449] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:17:21.449] [bbotk]                     3342        0.683 -0.9626898         <NA>   0.9771396 
INFO  [07:17:21.449] [bbotk]                                 uhash 
INFO  [07:17:21.449] [bbotk]  d2ac5fd2-df3c-4649-85da-b296aca9f0dd 
DEBUG [07:17:22.456] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.655077e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.655077e-05 0.003674823 
  - best initial criterion value(s) :  374.6752 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -374.68  |proj g|=       4.9089
At iterate     1  f =      -382.99  |proj g|=        4.2383
At iterate     2  f =      -383.12  |proj g|=        4.8989
At iterate     3  f =       -384.2  |proj g|=        4.7366
At iterate     4  f =      -385.25  |proj g|=        4.2451
At iterate     5  f =      -385.79  |proj g|=        4.7662
At iterate     6  f =      -385.83  |proj g|=        4.7654
At iterate     7  f =      -385.83  |proj g|=        4.7778
At iterate     8  f =      -385.84  |proj g|=        4.8034
At iterate     9  f =      -385.85  |proj g|=         4.829
At iterate    10  f =      -385.88  |proj g|=        4.8782
At iterate    11  f =      -385.95  |proj g|=        4.9336
At iterate    12  f =      -386.15  |proj g|=        4.9953
At iterate    13  f =      -386.63  |proj g|=        5.0148
At iterate    14  f =      -387.83  |proj g|=        4.8951
At iterate    15  f =      -390.76  |proj g|=        4.4327
At iterate    16  f =         -398  |proj g|=        3.3651
At iterate    17  f =      -412.78  |proj g|=        1.8035
At iterate    18  f =      -419.51  |proj g|=        1.2362
At iterate    19  f =      -420.47  |proj g|=        0.9913
At iterate    20  f =      -420.95  |proj g|=        1.0828
At iterate    21  f =      -420.99  |proj g|=        1.0891
At iterate    22  f =      -420.99  |proj g|=        1.0949
At iterate    23  f =      -420.99  |proj g|=        1.0968
At iterate    24  f =      -420.99  |proj g|=        1.0973
At iterate    25  f =      -420.99  |proj g|=        1.0973

iterations 25
function evaluations 30
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.09734
final function value -420.993

F = -420.993
final  value -420.993348 
converged
 
INFO  [07:17:22.460] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:17:22.547] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:17:22.554] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:17:24.963] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:17:27.234] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:17:29.578] [mlr3]  Finished benchmark 
INFO  [07:17:29.691] [bbotk] Result of batch 86: 
INFO  [07:17:29.693] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:17:29.693] [bbotk]              4.991092                 7.018955                       0.1468576 
INFO  [07:17:29.693] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:17:29.693] [bbotk]                     1463        0.682 -0.9597617         <NA>   0.9702565 
INFO  [07:17:29.693] [bbotk]                                 uhash 
INFO  [07:17:29.693] [bbotk]  c41b744c-460c-43b0-a9d9-65c40592aacc 
DEBUG [07:17:30.764] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.632211e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.632211e-05 0.003616989 
  - best initial criterion value(s) :  411.4033 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -411.4  |proj g|=       1.2744
At iterate     1  f =      -417.96  |proj g|=         1.768
At iterate     2  f =      -418.07  |proj g|=        1.7492
At iterate     3  f =      -418.21  |proj g|=        1.7125
At iterate     4  f =      -418.32  |proj g|=        1.7037
At iterate     5  f =      -419.04  |proj g|=        1.6887
At iterate     6  f =      -419.85  |proj g|=        1.7293
At iterate     7  f =      -420.37  |proj g|=        1.9701
At iterate     8  f =      -420.63  |proj g|=        1.9425
At iterate     9  f =      -420.65  |proj g|=        1.9282
At iterate    10  f =      -420.65  |proj g|=        1.9296
At iterate    11  f =      -420.65  |proj g|=        1.9303
At iterate    12  f =      -420.65  |proj g|=        1.9305
At iterate    13  f =      -420.65  |proj g|=        1.9321
At iterate    14  f =      -420.65  |proj g|=         1.934
At iterate    15  f =      -420.65  |proj g|=        1.9373
At iterate    16  f =      -420.65  |proj g|=         1.942
At iterate    17  f =      -420.66  |proj g|=        1.9503
At iterate    18  f =      -420.68  |proj g|=        1.9556
At iterate    19  f =      -420.69  |proj g|=        1.9762
At iterate    20  f =      -420.72  |proj g|=        1.9745
At iterate    21  f =      -421.01  |proj g|=        1.9422
At iterate    22  f =      -421.59  |proj g|=        1.8527
At iterate    23  f =      -423.11  |proj g|=        1.6086
At iterate    24  f =      -425.36  |proj g|=       0.68175
At iterate    25  f =       -425.4  |proj g|=       0.66779
At iterate    26  f =      -426.18  |proj g|=       0.65389
At iterate    27  f =      -426.93  |proj g|=        0.8289
At iterate    28  f =      -427.17  |proj g|=       0.68424
At iterate    29  f =       -427.2  |proj g|=        0.6692
At iterate    30  f =       -427.2  |proj g|=       0.69738
At iterate    31  f =       -427.2  |proj g|=       0.67122
At iterate    32  f =       -427.2  |proj g|=       0.67157
At iterate    33  f =       -427.2  |proj g|=       0.67155

iterations 33
function evaluations 39
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.671554
final function value -427.201

F = -427.201
final  value -427.200817 
converged
 
INFO  [07:17:30.768] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:17:30.864] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:17:30.873] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:17:32.043] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:17:33.240] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:17:34.409] [mlr3]  Finished benchmark 
INFO  [07:17:34.555] [bbotk] Result of batch 87: 
INFO  [07:17:34.557] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:17:34.557] [bbotk]              7.699272                 4.397298                       0.1864965 
INFO  [07:17:34.557] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:17:34.557] [bbotk]                      548        0.705 -0.9632673         <NA>   0.9657247 
INFO  [07:17:34.557] [bbotk]                                 uhash 
INFO  [07:17:34.557] [bbotk]  1fcb596f-0ccb-4501-8dd5-89413b4ea100 
DEBUG [07:17:35.648] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.611088e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.611088e-05 0.003562209 
  - best initial criterion value(s) :  409.457 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -409.46  |proj g|=       1.9702
At iterate     1  f =      -414.25  |proj g|=        2.4896
At iterate     2  f =      -414.44  |proj g|=        2.4538
At iterate     3  f =      -414.51  |proj g|=        2.4035
At iterate     4  f =      -414.51  |proj g|=        2.4121
At iterate     5  f =      -414.51  |proj g|=        2.4092
At iterate     6  f =      -414.52  |proj g|=        2.3899
At iterate     7  f =      -414.52  |proj g|=        2.3842
At iterate     8  f =      -414.53  |proj g|=        2.3848
At iterate     9  f =      -414.53  |proj g|=        2.3854
At iterate    10  f =      -414.53  |proj g|=        2.3857
At iterate    11  f =      -414.53  |proj g|=        2.3863
At iterate    12  f =      -414.53  |proj g|=        2.3873
At iterate    13  f =      -414.53  |proj g|=        2.3888
At iterate    14  f =      -414.53  |proj g|=        2.3913
At iterate    15  f =      -414.53  |proj g|=        2.3956
At iterate    16  f =      -414.53  |proj g|=        2.4028
At iterate    17  f =      -414.54  |proj g|=        2.4132
At iterate    18  f =      -414.55  |proj g|=        2.4212
At iterate    19  f =      -414.55  |proj g|=        2.4191
At iterate    20  f =      -414.55  |proj g|=        2.4151
At iterate    21  f =      -414.55  |proj g|=        2.4127
At iterate    22  f =      -414.55  |proj g|=        2.4101
At iterate    23  f =      -414.55  |proj g|=        2.4057
At iterate    24  f =      -414.56  |proj g|=        2.3991
At iterate    25  f =      -414.56  |proj g|=        2.3875
At iterate    26  f =      -414.58  |proj g|=        2.3704
At iterate    27  f =       -414.6  |proj g|=         2.348
At iterate    28  f =      -414.66  |proj g|=        2.3097
At iterate    29  f =      -414.73  |proj g|=        2.2853
At iterate    30  f =      -414.86  |proj g|=        2.2483
At iterate    31  f =      -415.53  |proj g|=         2.061
At iterate    32  f =      -416.72  |proj g|=        1.8166
At iterate    33  f =      -420.79  |proj g|=        1.2531
At iterate    34  f =      -424.82  |proj g|=       0.37381
At iterate    35  f =      -425.57  |proj g|=       0.49155
At iterate    36  f =      -425.78  |proj g|=       0.84955
At iterate    37  f =      -425.81  |proj g|=        0.8496
At iterate    38  f =      -425.84  |proj g|=       0.84862
At iterate    39  f =      -425.92  |proj g|=       0.84442
At iterate    40  f =         -426  |proj g|=       0.83842
At iterate    41  f =      -426.05  |proj g|=        0.8325
At iterate    42  f =      -426.05  |proj g|=       0.63039
At iterate    43  f =      -426.05  |proj g|=       0.63039
At iterate    44  f =      -426.05  |proj g|=       0.63039

iterations 44
function evaluations 48
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.630385
final function value -426.048

F = -426.048
final  value -426.047952 
converged
 
INFO  [07:17:35.652] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:17:35.750] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:17:35.758] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:17:37.123] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:17:38.374] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:17:39.618] [mlr3]  Finished benchmark 
INFO  [07:17:39.784] [bbotk] Result of batch 88: 
INFO  [07:17:39.786] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:17:39.786] [bbotk]              2.739331                 3.384635                       0.3964326 
INFO  [07:17:39.786] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:17:39.786] [bbotk]                      526        0.685 -0.9684558         <NA>   0.9567104 
INFO  [07:17:39.786] [bbotk]                                 uhash 
INFO  [07:17:39.786] [bbotk]  e6cc292a-a164-4b30-8bf0-3c7acc2464ec 
DEBUG [07:17:40.962] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.60318e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.60318e-05 0.003533327 
  - best initial criterion value(s) :  405.8578 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -405.86  |proj g|=       1.7657
At iterate     1  f =       -411.8  |proj g|=         2.213
At iterate     2  f =      -416.08  |proj g|=        2.4506
At iterate     3  f =       -418.2  |proj g|=        2.5501
At iterate     4  f =      -420.43  |proj g|=        2.4291
At iterate     5  f =      -421.72  |proj g|=         2.157
At iterate     6  f =      -421.75  |proj g|=        2.2671
At iterate     7  f =      -421.83  |proj g|=        2.2296
At iterate     8  f =      -421.84  |proj g|=        2.2166
At iterate     9  f =      -421.84  |proj g|=        2.2198
At iterate    10  f =      -421.84  |proj g|=        2.2198
At iterate    11  f =      -421.84  |proj g|=        2.2195
At iterate    12  f =      -421.84  |proj g|=        2.2184
At iterate    13  f =      -421.84  |proj g|=         2.217
At iterate    14  f =      -421.84  |proj g|=        2.2141
At iterate    15  f =      -421.84  |proj g|=        2.2125
At iterate    16  f =      -421.85  |proj g|=        2.2006
At iterate    17  f =      -421.86  |proj g|=        2.2012
At iterate    18  f =      -421.91  |proj g|=        2.1984
At iterate    19  f =      -422.04  |proj g|=        2.1841
At iterate    20  f =      -422.42  |proj g|=        2.1297
At iterate    21  f =      -423.34  |proj g|=        1.9794
At iterate    22  f =      -425.51  |proj g|=        1.7174
At iterate    23  f =      -429.54  |proj g|=        1.2171
At iterate    24  f =      -430.74  |proj g|=        1.3996
At iterate    25  f =      -432.28  |proj g|=        1.0679
At iterate    26  f =      -432.33  |proj g|=       0.93343
At iterate    27  f =      -432.37  |proj g|=        1.0034
At iterate    28  f =      -432.37  |proj g|=       0.99892
At iterate    29  f =      -432.37  |proj g|=       0.99845
At iterate    30  f =      -432.37  |proj g|=       0.99848

iterations 30
function evaluations 37
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.998478
final function value -432.365

F = -432.365
final  value -432.365271 
converged
 
INFO  [07:17:40.967] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:17:41.080] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:17:41.088] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:17:42.712] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:17:44.339] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:17:46.055] [mlr3]  Finished benchmark 
INFO  [07:17:46.157] [bbotk] Result of batch 89: 
INFO  [07:17:46.159] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:17:46.159] [bbotk]               4.57451                 9.962332                      0.09402271 
INFO  [07:17:46.159] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:17:46.159] [bbotk]                      936        0.779 -0.9633074         <NA>   0.9606871 
INFO  [07:17:46.159] [bbotk]                                 uhash 
INFO  [07:17:46.159] [bbotk]  e3e4fd59-d2af-4b80-9b61-19e0586ed020 
DEBUG [07:17:47.224] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.587938e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.587938e-05 0.003490304 
  - best initial criterion value(s) :  374.4341 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -374.43  |proj g|=       3.6831
At iterate     1  f =      -381.54  |proj g|=        3.5497
At iterate     2  f =      -381.65  |proj g|=        3.6314
At iterate     3  f =      -381.71  |proj g|=        3.6231
At iterate     4  f =      -381.76  |proj g|=        3.5948
At iterate     5  f =      -381.78  |proj g|=        3.6038
At iterate     6  f =      -381.78  |proj g|=        3.6027
At iterate     7  f =      -381.78  |proj g|=        3.6024
At iterate     8  f =      -381.78  |proj g|=        3.6027
At iterate     9  f =      -381.78  |proj g|=        3.6018
At iterate    10  f =      -381.78  |proj g|=        3.6021
At iterate    11  f =      -381.78  |proj g|=        3.6036
At iterate    12  f =      -381.78  |proj g|=        3.6049
At iterate    13  f =       -381.8  |proj g|=        3.6054
At iterate    14  f =      -381.83  |proj g|=        3.6014
At iterate    15  f =      -381.91  |proj g|=        3.5757
At iterate    16  f =      -381.95  |proj g|=        3.5919
At iterate    17  f =      -382.19  |proj g|=        3.5101
At iterate    18  f =       -388.5  |proj g|=        2.3618
At iterate    19  f =      -399.54  |proj g|=        1.6068
At iterate    20  f =      -404.35  |proj g|=        1.2974
At iterate    21  f =       -404.4  |proj g|=        1.2884
At iterate    22  f =      -404.41  |proj g|=         1.276
At iterate    23  f =      -404.41  |proj g|=        1.2753
At iterate    24  f =      -404.41  |proj g|=        1.2756
At iterate    25  f =      -404.41  |proj g|=        1.2756

iterations 25
function evaluations 32
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.27558
final function value -404.413

F = -404.413
final  value -404.412813 
converged
 
INFO  [07:17:47.228] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:17:47.348] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:17:47.355] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:17:52.988] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:17:59.671] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:18:07.768] [mlr3]  Finished benchmark 
INFO  [07:18:07.908] [bbotk] Result of batch 90: 
INFO  [07:18:07.910] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:18:07.910] [bbotk]              7.560759                 3.798969                       0.2314651 
INFO  [07:18:07.910] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:18:07.910] [bbotk]                     3627        0.712 -0.9747455         <NA>   0.9769039 
INFO  [07:18:07.910] [bbotk]                                 uhash 
INFO  [07:18:07.910] [bbotk]  8fb773b9-7150-4dd9-8b15-8bc0d5d017fb 
DEBUG [07:18:08.972] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.57086e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.57086e-05 0.003479289 
  - best initial criterion value(s) :  393.6824 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -393.68  |proj g|=       4.6046
At iterate     1  f =      -393.86  |proj g|=        8.4764
At iterate     2  f =      -396.34  |proj g|=        8.0258
At iterate     3  f =      -398.22  |proj g|=        6.8156
At iterate     4  f =       -398.6  |proj g|=        6.0798
At iterate     5  f =       -399.2  |proj g|=        5.7493
At iterate     6  f =      -400.02  |proj g|=        5.5171
At iterate     7  f =      -400.04  |proj g|=        5.4177
At iterate     8  f =      -400.04  |proj g|=        5.3941
At iterate     9  f =      -400.04  |proj g|=        5.3826
At iterate    10  f =      -400.05  |proj g|=        5.3531
At iterate    11  f =      -400.07  |proj g|=        5.2921
At iterate    12  f =      -400.11  |proj g|=         5.207
At iterate    13  f =      -400.22  |proj g|=        5.0673
At iterate    14  f =      -400.49  |proj g|=        4.8697
At iterate    15  f =      -400.78  |proj g|=        4.2219
At iterate    16  f =      -401.79  |proj g|=        4.2736
At iterate    17  f =      -404.71  |proj g|=        3.8842
At iterate    18  f =      -410.29  |proj g|=        3.3201
At iterate    19  f =      -428.89  |proj g|=        2.1893
At iterate    20  f =       -439.1  |proj g|=        1.0213
At iterate    21  f =      -443.55  |proj g|=       0.85452
At iterate    22  f =      -443.59  |proj g|=       0.88504
At iterate    23  f =       -443.6  |proj g|=       0.91084
At iterate    24  f =      -443.61  |proj g|=       0.91435
At iterate    25  f =      -443.61  |proj g|=       0.91462

iterations 25
function evaluations 29
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.914621
final function value -443.605

F = -443.605
final  value -443.605005 
converged
 
INFO  [07:18:08.976] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:18:09.066] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:18:09.073] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:18:11.841] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:18:14.418] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:18:18.313] [mlr3]  Finished benchmark 
INFO  [07:18:18.445] [bbotk] Result of batch 91: 
INFO  [07:18:18.447] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:18:18.447] [bbotk]              8.547236                 2.255517                      0.09544336 
INFO  [07:18:18.447] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:18:18.447] [bbotk]                     1299         0.72 -0.9565849         <NA>   0.9680573 
INFO  [07:18:18.447] [bbotk]                                 uhash 
INFO  [07:18:18.447] [bbotk]  f31e6126-70a2-4e24-a17d-fac0d2c79916 
DEBUG [07:18:19.713] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.549807e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.549807e-05 0.003427604 
  - best initial criterion value(s) :  412.6021 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -412.6  |proj g|=        1.215
At iterate     1  f =      -428.36  |proj g|=        1.7403
At iterate     2  f =      -428.53  |proj g|=        1.6986
At iterate     3  f =      -428.92  |proj g|=        1.6599
At iterate     4  f =      -429.85  |proj g|=         1.635
At iterate     5  f =      -432.76  |proj g|=         1.626
At iterate     6  f =      -435.99  |proj g|=        1.7085
At iterate     7  f =      -436.88  |proj g|=        1.7887
At iterate     8  f =       -437.2  |proj g|=        1.8626
At iterate     9  f =      -437.29  |proj g|=        1.9123
At iterate    10  f =       -437.3  |proj g|=        1.9295
At iterate    11  f =       -437.3  |proj g|=        1.9325
At iterate    12  f =       -437.3  |proj g|=        1.9325
At iterate    13  f =       -437.3  |proj g|=        1.9323
At iterate    14  f =       -437.3  |proj g|=        1.9319
At iterate    15  f =       -437.3  |proj g|=        1.9309
At iterate    16  f =       -437.3  |proj g|=        1.9288
At iterate    17  f =      -437.31  |proj g|=        1.9263
At iterate    18  f =      -437.34  |proj g|=        1.9021
At iterate    19  f =      -437.36  |proj g|=        1.9152
At iterate    20  f =      -437.42  |proj g|=        1.8941
At iterate    21  f =      -438.11  |proj g|=        1.8182
At iterate    22  f =      -439.24  |proj g|=        1.9116
At iterate    23  f =      -440.17  |proj g|=        2.0576
At iterate    24  f =      -441.15  |proj g|=        2.0523
At iterate    25  f =      -441.48  |proj g|=        2.2871
At iterate    26  f =      -441.64  |proj g|=        2.0876
At iterate    27  f =      -441.64  |proj g|=        2.1068
At iterate    28  f =      -441.64  |proj g|=        2.1048
At iterate    29  f =      -441.64  |proj g|=        2.1045
At iterate    30  f =      -441.64  |proj g|=        2.1043

iterations 30
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.10428
final function value -441.641

F = -441.641
final  value -441.640929 
converged
 
INFO  [07:18:19.718] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:18:19.813] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:18:19.820] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:18:28.959] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:18:38.638] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:18:48.443] [mlr3]  Finished benchmark 
INFO  [07:18:48.552] [bbotk] Result of batch 92: 
INFO  [07:18:48.554] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:18:48.554] [bbotk]              6.355163                 2.312423                       0.1392456 
INFO  [07:18:48.554] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:18:48.554] [bbotk]                     4296        0.889 -0.9579997         <NA>   0.9759796 
INFO  [07:18:48.554] [bbotk]                                 uhash 
INFO  [07:18:48.554] [bbotk]  6548003a-3261-42f0-9594-b6c2b0952988 
DEBUG [07:18:49.598] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.532233e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.532233e-05 0.003415985 
  - best initial criterion value(s) :  367.3753 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -367.38  |proj g|=       3.4691
At iterate     1  f =      -371.05  |proj g|=        3.6112
At iterate     2  f =      -371.22  |proj g|=        3.5426
At iterate     3  f =      -371.23  |proj g|=        3.5295
At iterate     4  f =      -371.23  |proj g|=        3.5559
At iterate     5  f =      -371.24  |proj g|=        3.5493
At iterate     6  f =      -371.25  |proj g|=        3.5385
At iterate     7  f =      -371.28  |proj g|=        3.5185
At iterate     8  f =      -372.19  |proj g|=        3.1485
At iterate     9  f =      -376.01  |proj g|=        2.4321
At iterate    10  f =      -385.14  |proj g|=        1.2271
At iterate    11  f =      -385.18  |proj g|=        1.2303
At iterate    12  f =      -389.29  |proj g|=       0.25443
At iterate    13  f =      -389.31  |proj g|=       0.24975
At iterate    14  f =      -389.32  |proj g|=       0.61793
At iterate    15  f =      -389.32  |proj g|=       0.21942
At iterate    16  f =      -389.32  |proj g|=       0.22086
At iterate    17  f =      -389.32  |proj g|=       0.22088

iterations 17
function evaluations 27
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.220879
final function value -389.322

F = -389.322
final  value -389.321629 
converged
 
INFO  [07:18:49.602] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:18:49.689] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:18:49.697] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:18:59.467] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:19:09.158] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:19:21.593] [mlr3]  Finished benchmark 
INFO  [07:19:21.738] [bbotk] Result of batch 93: 
INFO  [07:19:21.740] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:19:21.740] [bbotk]               3.33397                 3.153258                       0.1070548 
INFO  [07:19:21.740] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:19:21.740] [bbotk]                     4386        0.716 -0.9795625         <NA>    0.970849 
INFO  [07:19:21.740] [bbotk]                                 uhash 
INFO  [07:19:21.740] [bbotk]  73ccd546-5797-49ca-932a-5371c9fdd585 
DEBUG [07:19:22.869] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.511765e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.511765e-05 0.00339857 
  - best initial criterion value(s) :  431.0098 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -431.01  |proj g|=       3.1483
At iterate     1  f =      -434.22  |proj g|=        3.4346
At iterate     2  f =      -434.59  |proj g|=        3.1212
At iterate     3  f =       -437.6  |proj g|=        2.9932
At iterate     4  f =      -440.95  |proj g|=        2.8594
At iterate     5  f =      -442.22  |proj g|=        3.1776
At iterate     6  f =      -442.24  |proj g|=         3.258
At iterate     7  f =      -442.25  |proj g|=        3.2665
At iterate     8  f =      -442.25  |proj g|=        3.2634
At iterate     9  f =      -442.25  |proj g|=        3.2611
At iterate    10  f =      -442.25  |proj g|=        3.2473
At iterate    11  f =      -442.26  |proj g|=        3.2278
At iterate    12  f =      -442.28  |proj g|=        3.1939
At iterate    13  f =      -442.33  |proj g|=        3.1316
At iterate    14  f =      -442.46  |proj g|=        3.0245
At iterate    15  f =      -442.77  |proj g|=        2.8604
At iterate    16  f =      -443.39  |proj g|=        2.5763
At iterate    17  f =      -444.65  |proj g|=        2.2859
At iterate    18  f =      -446.02  |proj g|=        1.6961
At iterate    19  f =      -447.48  |proj g|=        1.8324
At iterate    20  f =      -449.94  |proj g|=        2.0127
At iterate    21  f =      -450.32  |proj g|=        1.9025
At iterate    22  f =      -450.39  |proj g|=        1.8594
At iterate    23  f =      -450.39  |proj g|=        1.8392
At iterate    24  f =      -450.39  |proj g|=        1.8414
At iterate    25  f =      -450.39  |proj g|=        1.8413

iterations 25
function evaluations 34
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.84126
final function value -450.394

F = -450.394
final  value -450.393741 
converged
 
INFO  [07:19:22.874] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:19:22.959] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:19:22.965] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:19:33.768] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:19:45.325] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:19:54.318] [mlr3]  Finished benchmark 
INFO  [07:19:54.415] [bbotk] Result of batch 94: 
INFO  [07:19:54.417] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:19:54.417] [bbotk]              3.928256                  6.97976                       0.2859697 
INFO  [07:19:54.417] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:19:54.417] [bbotk]                     4488        0.724 -0.9633571         <NA>    0.976354 
INFO  [07:19:54.417] [bbotk]                                 uhash 
INFO  [07:19:54.417] [bbotk]  ba6e7a33-874b-4f74-9c7f-ae9681f562e6 
DEBUG [07:19:55.408] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.49511e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.49511e-05 0.003387734 
  - best initial criterion value(s) :  380.8474 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -380.85  |proj g|=       1.9185
At iterate     1  f =      -381.06  |proj g|=        1.9534
At iterate     2  f =      -381.17  |proj g|=        1.9438
At iterate     3  f =      -381.21  |proj g|=        1.9392
At iterate     4  f =      -381.29  |proj g|=        1.9351
At iterate     5  f =      -381.56  |proj g|=        1.9245
At iterate     6  f =      -382.12  |proj g|=        1.8978
At iterate     7  f =      -383.22  |proj g|=        1.8146
At iterate     8  f =      -384.41  |proj g|=        1.7577
At iterate     9  f =      -384.71  |proj g|=        1.6833
At iterate    10  f =      -385.03  |proj g|=        1.5544
At iterate    11  f =      -385.03  |proj g|=        1.5485
At iterate    12  f =      -385.03  |proj g|=        1.5466
At iterate    13  f =      -385.03  |proj g|=        1.5467

iterations 13
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.54666
final function value -385.03

F = -385.03
final  value -385.030066 
converged
 
INFO  [07:19:55.412] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:19:55.500] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:19:55.507] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:20:00.958] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:20:06.924] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:20:14.172] [mlr3]  Finished benchmark 
INFO  [07:20:14.287] [bbotk] Result of batch 95: 
INFO  [07:20:14.289] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:20:14.289] [bbotk]              5.353551                 6.086644                       0.2543432 
INFO  [07:20:14.289] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [07:20:14.289] [bbotk]                     2761         0.71 -0.980274         <NA>   0.9761499 
INFO  [07:20:14.289] [bbotk]                                 uhash 
INFO  [07:20:14.289] [bbotk]  a1d4d3a4-177a-4fe7-8bc4-4e72efceb2a7 
DEBUG [07:20:15.464] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.478452e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.478452e-05 0.003375332 
  - best initial criterion value(s) :  425.9125 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -425.91  |proj g|=       2.7971
At iterate     1  f =      -436.06  |proj g|=        2.5191
At iterate     2  f =      -441.34  |proj g|=        3.4236
At iterate     3  f =      -441.63  |proj g|=        3.4131
At iterate     4  f =      -442.39  |proj g|=        3.2334
At iterate     5  f =       -442.4  |proj g|=        3.1968
At iterate     6  f =      -442.41  |proj g|=        3.2194
At iterate     7  f =      -442.41  |proj g|=        3.2171
At iterate     8  f =      -442.41  |proj g|=        3.2145
At iterate     9  f =      -442.41  |proj g|=        3.2104
At iterate    10  f =      -442.41  |proj g|=        3.2038
At iterate    11  f =      -442.41  |proj g|=        3.1927
At iterate    12  f =      -442.42  |proj g|=        3.1744
At iterate    13  f =      -442.44  |proj g|=        3.1425
At iterate    14  f =      -442.51  |proj g|=        3.0859
At iterate    15  f =      -442.69  |proj g|=         2.982
At iterate    16  f =      -443.19  |proj g|=        2.7903
At iterate    17  f =      -444.43  |proj g|=        2.4629
At iterate    18  f =      -446.59  |proj g|=        2.0631
At iterate    19  f =      -448.65  |proj g|=         2.651
At iterate    20  f =      -452.46  |proj g|=        1.8521
At iterate    21  f =      -452.79  |proj g|=        1.6037
At iterate    22  f =      -452.84  |proj g|=        1.5474
At iterate    23  f =      -452.89  |proj g|=        1.5619
At iterate    24  f =      -453.04  |proj g|=        1.6463
At iterate    25  f =      -455.03  |proj g|=        1.8953
At iterate    26  f =      -459.49  |proj g|=        2.1914
At iterate    27  f =      -464.01  |proj g|=        1.7581
At iterate    28  f =      -464.83  |proj g|=        1.5173
At iterate    29  f =      -465.04  |proj g|=         1.316
At iterate    30  f =      -465.07  |proj g|=         1.354
At iterate    31  f =      -465.07  |proj g|=         1.362
At iterate    32  f =      -465.07  |proj g|=        1.3624
At iterate    33  f =      -465.07  |proj g|=        1.3624

iterations 33
function evaluations 43
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.36237
final function value -465.072

F = -465.072
final  value -465.071886 
converged
 
INFO  [07:20:15.469] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:20:15.555] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:20:15.562] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:20:17.030] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:20:18.558] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:20:20.311] [mlr3]  Finished benchmark 
INFO  [07:20:20.409] [bbotk] Result of batch 96: 
INFO  [07:20:20.411] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:20:20.411] [bbotk]              2.628067                 2.815358                       0.2468353 
INFO  [07:20:20.411] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:20:20.411] [bbotk]                      669        0.762 -0.9534503         <NA>   0.9514513 
INFO  [07:20:20.411] [bbotk]                                 uhash 
INFO  [07:20:20.411] [bbotk]  f9c2c30f-7d90-4bb2-95f4-abe5b240a7c3 
DEBUG [07:20:21.645] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.485146e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.485146e-05 0.003336707 
  - best initial criterion value(s) :  364.932 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -364.93  |proj g|=       7.2552
At iterate     1  f =      -374.25  |proj g|=        2.7422
At iterate     2  f =      -381.58  |proj g|=        3.0956
At iterate     3  f =      -388.93  |proj g|=        2.9372
At iterate     4  f =      -394.13  |proj g|=        2.7092
At iterate     5  f =      -394.38  |proj g|=         2.803
At iterate     6  f =       -394.4  |proj g|=        2.8337
At iterate     7  f =       -394.4  |proj g|=        2.8393
At iterate     8  f =       -394.4  |proj g|=        2.8396
At iterate     9  f =      -395.12  |proj g|=        2.7394
At iterate    10  f =      -398.47  |proj g|=        2.3649
At iterate    11  f =      -400.08  |proj g|=          2.13
At iterate    12  f =      -400.11  |proj g|=        2.1421
At iterate    13  f =      -400.13  |proj g|=        2.1603
At iterate    14  f =      -400.13  |proj g|=        2.1616
At iterate    15  f =      -400.13  |proj g|=        2.1617
At iterate    16  f =      -400.13  |proj g|=        2.1615
At iterate    17  f =      -400.13  |proj g|=        2.1597
At iterate    18  f =      -400.13  |proj g|=        2.1571
At iterate    19  f =      -400.13  |proj g|=        2.1528
At iterate    20  f =      -400.14  |proj g|=        2.1459
At iterate    21  f =      -400.17  |proj g|=        2.1348
At iterate    22  f =      -400.23  |proj g|=        2.1174
At iterate    23  f =      -400.42  |proj g|=        2.0894
At iterate    24  f =      -400.99  |proj g|=        2.0405
At iterate    25  f =      -406.59  |proj g|=        1.5252
At iterate    26  f =      -406.89  |proj g|=        1.4884
At iterate    27  f =      -408.43  |proj g|=        1.6267
At iterate    28  f =      -408.44  |proj g|=        1.6171
At iterate    29  f =      -408.45  |proj g|=        1.6078
At iterate    30  f =      -408.45  |proj g|=        1.6087
At iterate    31  f =      -408.45  |proj g|=        1.6087

iterations 31
function evaluations 54
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.60869
final function value -408.448

F = -408.448
final  value -408.448069 
converged
 
INFO  [07:20:21.649] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:20:21.751] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:20:21.757] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:20:32.704] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:20:44.899] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:20:55.573] [mlr3]  Finished benchmark 
INFO  [07:20:55.717] [bbotk] Result of batch 97: 
INFO  [07:20:55.719] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:20:55.719] [bbotk]              3.539809                 4.039525                       0.3510912 
INFO  [07:20:55.719] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:20:55.719] [bbotk]                     4930        0.759 -0.9782187         <NA>   0.9764164 
INFO  [07:20:55.719] [bbotk]                                 uhash 
INFO  [07:20:55.719] [bbotk]  1b181ef3-0f1a-4649-9c4d-826c57a7b020 
DEBUG [07:20:57.086] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.469202e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.469202e-05 0.003325163 
  - best initial criterion value(s) :  410.7679 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -410.77  |proj g|=      0.46315
At iterate     1  f =      -420.66  |proj g|=        13.244
At iterate     2  f =      -423.59  |proj g|=        12.533
At iterate     3  f =      -426.19  |proj g|=        9.9519
At iterate     4  f =      -426.27  |proj g|=         9.308
At iterate     5  f =      -426.33  |proj g|=        9.4242
At iterate     6  f =       -426.7  |proj g|=        9.8968
At iterate     7  f =      -426.72  |proj g|=        9.6553
At iterate     8  f =      -426.72  |proj g|=        9.6118
At iterate     9  f =      -426.72  |proj g|=        9.6168
At iterate    10  f =      -426.72  |proj g|=        9.6204
At iterate    11  f =      -426.72  |proj g|=        9.6262
At iterate    12  f =      -426.72  |proj g|=        9.6398
At iterate    13  f =      -426.73  |proj g|=        9.6591
At iterate    14  f =      -426.73  |proj g|=        9.6907
At iterate    15  f =      -426.73  |proj g|=        9.7328
At iterate    16  f =      -426.74  |proj g|=        9.7798
At iterate    17  f =      -426.77  |proj g|=        9.8356
At iterate    18  f =      -426.85  |proj g|=        9.8211
At iterate    19  f =      -426.87  |proj g|=        10.059
At iterate    20  f =      -427.05  |proj g|=        9.9005
At iterate    21  f =      -433.31  |proj g|=         7.692
At iterate    22  f =      -448.41  |proj g|=        5.1622
At iterate    23  f =      -467.16  |proj g|=        2.7044
At iterate    24  f =      -472.57  |proj g|=        1.1024
At iterate    25  f =      -475.94  |proj g|=        1.1027
At iterate    26  f =      -476.11  |proj g|=        1.1026
At iterate    27  f =      -476.14  |proj g|=        1.1037
At iterate    28  f =      -476.16  |proj g|=        1.1057
At iterate    29  f =      -476.16  |proj g|=        1.1055
At iterate    30  f =      -476.16  |proj g|=         1.103
At iterate    31  f =      -476.17  |proj g|=        1.0976
At iterate    32  f =      -476.18  |proj g|=        1.0778
At iterate    33  f =      -476.22  |proj g|=        1.0407
At iterate    34  f =      -476.29  |proj g|=       0.97039
At iterate    35  f =      -476.84  |proj g|=       0.40604
At iterate    36  f =      -477.29  |proj g|=       0.26667
At iterate    37  f =      -477.61  |proj g|=       0.25479
At iterate    38  f =      -477.89  |proj g|=       0.77896
At iterate    39  f =      -477.91  |proj g|=       0.77598
At iterate    40  f =      -477.92  |proj g|=       0.22518
At iterate    41  f =      -477.92  |proj g|=       0.01368
At iterate    42  f =      -477.92  |proj g|=      0.001998

iterations 42
function evaluations 50
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00199795
final function value -477.92

F = -477.92
final  value -477.920450 
converged
 
INFO  [07:20:57.091] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:20:57.180] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:20:57.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:21:02.333] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:21:07.252] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:21:12.607] [mlr3]  Finished benchmark 
INFO  [07:21:12.709] [bbotk] Result of batch 98: 
INFO  [07:21:12.711] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:21:12.711] [bbotk]              9.816971                 9.959625                       0.2648916 
INFO  [07:21:12.711] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:21:12.711] [bbotk]                     2441        0.916 -0.9524881         <NA>   0.9758235 
INFO  [07:21:12.711] [bbotk]                                 uhash 
INFO  [07:21:12.711] [bbotk]  8e89b525-7398-4fa7-b83d-e003668dfadc 
DEBUG [07:21:13.816] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.452857e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.452857e-05 0.00331285 
  - best initial criterion value(s) :  451.2466 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -451.25  |proj g|=       2.0161
At iterate     1  f =      -454.09  |proj g|=        2.8187
At iterate     2  f =      -456.95  |proj g|=        2.7387
At iterate     3  f =      -458.47  |proj g|=         2.611
At iterate     4  f =      -458.73  |proj g|=          2.57
At iterate     5  f =      -459.19  |proj g|=        2.5556
At iterate     6  f =      -460.75  |proj g|=        2.6012
At iterate     7  f =      -462.06  |proj g|=        2.9361
At iterate     8  f =      -462.11  |proj g|=        2.9631
At iterate     9  f =      -462.11  |proj g|=        2.9702
At iterate    10  f =      -462.11  |proj g|=        2.9727
At iterate    11  f =      -462.12  |proj g|=        2.9761
At iterate    12  f =      -462.12  |proj g|=        2.9804
At iterate    13  f =      -462.14  |proj g|=        3.0297
At iterate    14  f =      -462.17  |proj g|=        3.0047
At iterate    15  f =      -462.25  |proj g|=        2.9632
At iterate    16  f =      -462.57  |proj g|=        2.8375
At iterate    17  f =      -463.28  |proj g|=        2.6255
At iterate    18  f =      -465.16  |proj g|=        2.2019
At iterate    19  f =      -468.83  |proj g|=        1.6226
At iterate    20  f =      -473.27  |proj g|=       0.82116
At iterate    21  f =      -475.04  |proj g|=        1.1124
At iterate    22  f =      -476.17  |proj g|=         1.465
At iterate    23  f =       -476.4  |proj g|=        1.6197
At iterate    24  f =      -476.44  |proj g|=        1.6863
At iterate    25  f =      -476.46  |proj g|=        1.7134
At iterate    26  f =      -476.53  |proj g|=         1.758
At iterate    27  f =      -476.68  |proj g|=        1.7978
At iterate    28  f =      -477.04  |proj g|=        1.7791
At iterate    29  f =      -477.34  |proj g|=        1.6163
At iterate    30  f =      -477.36  |proj g|=        1.5147
At iterate    31  f =      -477.37  |proj g|=        1.5481
At iterate    32  f =      -477.37  |proj g|=        1.5453
At iterate    33  f =      -477.37  |proj g|=        1.5452

iterations 33
function evaluations 37
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.54516
final function value -477.366

F = -477.366
final  value -477.365832 
converged
 
INFO  [07:21:13.820] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:21:13.935] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:21:13.942] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:21:20.075] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:21:27.297] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:21:33.840] [mlr3]  Finished benchmark 
INFO  [07:21:33.940] [bbotk] Result of batch 99: 
INFO  [07:21:33.942] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:21:33.942] [bbotk]              4.484732                 3.906863                      0.07343297 
INFO  [07:21:33.942] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:21:33.942] [bbotk]                     2944        0.725 -0.9530675         <NA>   0.9693715 
INFO  [07:21:33.942] [bbotk]                                 uhash 
INFO  [07:21:33.942] [bbotk]  42cc3ac7-738b-4006-b9a6-062ed4a7763e 
DEBUG [07:21:34.988] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.433852e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.433852e-05 0.003296034 
  - best initial criterion value(s) :  438.0637 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -438.06  |proj g|=      0.65941
At iterate     1  f =      -444.17  |proj g|=        1.1332
At iterate     2  f =      -447.07  |proj g|=       0.96348
At iterate     3  f =      -449.44  |proj g|=       0.60612
At iterate     4  f =      -449.54  |proj g|=        0.5017
At iterate     5  f =      -451.23  |proj g|=       0.76912
At iterate     6  f =      -451.85  |proj g|=       0.81392
At iterate     7  f =      -452.08  |proj g|=       0.82131
At iterate     8  f =      -452.08  |proj g|=       0.41143
At iterate     9  f =      -452.09  |proj g|=       0.41224
At iterate    10  f =      -452.09  |proj g|=       0.41323
At iterate    11  f =      -452.09  |proj g|=       0.41302

iterations 11
function evaluations 18
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.413015
final function value -452.088

F = -452.088
final  value -452.088092 
converged
 
INFO  [07:21:34.992] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:21:35.107] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:21:35.114] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:21:40.809] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:21:48.988] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:21:56.550] [mlr3]  Finished benchmark 
INFO  [07:21:56.688] [bbotk] Result of batch 100: 
INFO  [07:21:56.690] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:21:56.690] [bbotk]                6.7421                 6.563678                      0.09629295 
INFO  [07:21:56.690] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:21:56.690] [bbotk]                     2839         0.73 -0.9706494         <NA>   0.9731324 
INFO  [07:21:56.690] [bbotk]                                 uhash 
INFO  [07:21:56.690] [bbotk]  b8842f8a-7851-4f14-bce1-0a410cae6022 
DEBUG [07:21:57.781] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.416027e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.416027e-05 0.003311146 
  - best initial criterion value(s) :  416.1049 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -416.1  |proj g|=       1.9764
At iterate     1  f =      -430.47  |proj g|=        9.8686
At iterate     2  f =      -449.17  |proj g|=        5.9894
At iterate     3  f =      -449.19  |proj g|=        5.9534
At iterate     4  f =      -449.27  |proj g|=        5.8749
At iterate     5  f =      -449.29  |proj g|=        5.7515
At iterate     6  f =      -449.29  |proj g|=        5.7761
At iterate     7  f =      -449.29  |proj g|=        5.8048
At iterate     8  f =       -449.3  |proj g|=        5.8539
At iterate     9  f =      -449.35  |proj g|=        5.9609
At iterate    10  f =      -449.46  |proj g|=        6.0715
At iterate    11  f =      -449.73  |proj g|=        6.1495
At iterate    12  f =      -450.33  |proj g|=        6.0418
At iterate    13  f =      -451.43  |proj g|=        5.5647
At iterate    14  f =      -452.98  |proj g|=        4.7034
At iterate    15  f =      -454.35  |proj g|=        4.1127
At iterate    16  f =      -455.56  |proj g|=        4.0943
At iterate    17  f =      -456.07  |proj g|=        4.4024
At iterate    18  f =      -456.24  |proj g|=         4.593
At iterate    19  f =      -456.24  |proj g|=         4.572
At iterate    20  f =      -456.24  |proj g|=        4.6211
At iterate    21  f =      -456.25  |proj g|=        4.6255
At iterate    22  f =      -456.25  |proj g|=        4.6255

iterations 22
function evaluations 30
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.62552
final function value -456.246

F = -456.246
final  value -456.246137 
converged
 
INFO  [07:21:57.785] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:21:57.873] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:21:57.880] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:22:03.606] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:22:09.698] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:22:16.105] [mlr3]  Finished benchmark 
INFO  [07:22:16.208] [bbotk] Result of batch 101: 
INFO  [07:22:16.210] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:22:16.210] [bbotk]              2.876689                  5.86999                        0.195115 
INFO  [07:22:16.210] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:22:16.210] [bbotk]                     2727        0.739 -0.9655781         <NA>    0.968347 
INFO  [07:22:16.210] [bbotk]                                 uhash 
INFO  [07:22:16.210] [bbotk]  2666f923-67ba-430c-8a38-aec1b7a8d8e0 
DEBUG [07:22:17.413] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.397729e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.397729e-05 0.003292912 
  - best initial criterion value(s) :  463.397 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -463.4  |proj g|=       1.6153
At iterate     1  f =      -463.99  |proj g|=        3.0659
At iterate     2  f =      -467.94  |proj g|=        2.8943
At iterate     3  f =      -470.78  |proj g|=        2.5119
At iterate     4  f =      -471.11  |proj g|=        2.2387
At iterate     5  f =      -471.54  |proj g|=        2.2557
At iterate     6  f =      -473.68  |proj g|=        1.9283
At iterate     7  f =      -473.93  |proj g|=        1.7831
At iterate     8  f =      -473.94  |proj g|=        1.7212
At iterate     9  f =      -473.94  |proj g|=        1.7402
At iterate    10  f =      -473.94  |proj g|=        1.7389
At iterate    11  f =      -473.95  |proj g|=        1.7385
At iterate    12  f =      -473.95  |proj g|=         1.738
At iterate    13  f =      -473.95  |proj g|=        1.7374
At iterate    14  f =      -473.95  |proj g|=        1.7363
At iterate    15  f =      -473.95  |proj g|=        1.7347
At iterate    16  f =      -473.95  |proj g|=        1.7326
At iterate    17  f =      -473.95  |proj g|=        1.7309
At iterate    18  f =      -473.95  |proj g|=        1.7332
At iterate    19  f =      -473.96  |proj g|=         1.746
At iterate    20  f =      -473.96  |proj g|=        1.7418
At iterate    21  f =      -473.97  |proj g|=        1.7529
At iterate    22  f =      -478.42  |proj g|=        1.1807
At iterate    23  f =      -478.46  |proj g|=        1.2174
At iterate    24  f =      -478.47  |proj g|=        1.2352
At iterate    25  f =      -478.47  |proj g|=        1.2387
At iterate    26  f =      -478.47  |proj g|=        1.2392
At iterate    27  f =      -478.47  |proj g|=        1.2407
At iterate    28  f =      -478.47  |proj g|=        1.2421
At iterate    29  f =      -478.47  |proj g|=        1.2447
At iterate    30  f =      -478.47  |proj g|=        1.2475
At iterate    31  f =      -478.69  |proj g|=        1.2127
At iterate    32  f =      -481.01  |proj g|=       0.82601
At iterate    33  f =      -481.02  |proj g|=       0.82599
At iterate    34  f =      -481.35  |proj g|=       0.80223
At iterate    35  f =      -481.35  |proj g|=       0.18574
At iterate    36  f =      -481.35  |proj g|=      0.032232
At iterate    37  f =      -481.35  |proj g|=      0.025828

iterations 37
function evaluations 45
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0258282
final function value -481.352

F = -481.352
final  value -481.351982 
converged
 
INFO  [07:22:17.417] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:22:17.539] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:22:17.546] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:22:18.488] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:22:19.643] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:22:20.961] [mlr3]  Finished benchmark 
INFO  [07:22:21.107] [bbotk] Result of batch 102: 
INFO  [07:22:21.109] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:22:21.109] [bbotk]              5.983336                 6.868454                       0.1245065 
INFO  [07:22:21.109] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:22:21.109] [bbotk]                      356        0.755 -0.9651452         <NA>   0.9536814 
INFO  [07:22:21.109] [bbotk]                                 uhash 
INFO  [07:22:21.109] [bbotk]  2921772d-741e-4eb2-85f0-933735fa4b5e 
DEBUG [07:22:22.407] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.398905e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.398905e-05 0.003253089 
  - best initial criterion value(s) :  436.5905 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -436.59  |proj g|=       1.2796
At iterate     1  f =      -460.72  |proj g|=        3.7794
At iterate     2  f =      -479.88  |proj g|=         3.193
At iterate     3  f =      -484.25  |proj g|=        2.4287
At iterate     4  f =      -484.28  |proj g|=        2.5208
At iterate     5  f =      -484.32  |proj g|=        2.4904
At iterate     6  f =      -484.43  |proj g|=        2.3882
At iterate     7  f =      -484.47  |proj g|=        2.3953
At iterate     8  f =      -484.48  |proj g|=        2.4191
At iterate     9  f =      -484.48  |proj g|=        2.4177
At iterate    10  f =      -484.48  |proj g|=        2.4176
At iterate    11  f =      -484.48  |proj g|=        2.4171
At iterate    12  f =      -484.48  |proj g|=        2.4163
At iterate    13  f =      -484.48  |proj g|=         2.415
At iterate    14  f =      -484.48  |proj g|=        2.4134
At iterate    15  f =      -484.48  |proj g|=        2.4108
At iterate    16  f =      -484.48  |proj g|=        2.4081
At iterate    17  f =      -484.49  |proj g|=        2.4024
At iterate    18  f =       -484.5  |proj g|=        2.4026
At iterate    19  f =      -484.51  |proj g|=        2.3787
At iterate    20  f =      -484.54  |proj g|=        2.3707
At iterate    21  f =      -485.41  |proj g|=        2.1267
At iterate    22  f =      -488.41  |proj g|=        1.5783
At iterate    23  f =      -488.77  |proj g|=        1.7603
At iterate    24  f =       -488.8  |proj g|=        1.7903
At iterate    25  f =       -488.8  |proj g|=        1.7894
At iterate    26  f =       -488.8  |proj g|=         1.793
At iterate    27  f =       -488.8  |proj g|=        1.7922
At iterate    28  f =       -488.8  |proj g|=        1.7916
At iterate    29  f =       -488.8  |proj g|=        1.7917
At iterate    30  f =       -488.8  |proj g|=         1.792
At iterate    31  f =       -488.8  |proj g|=        1.7911
At iterate    32  f =      -488.81  |proj g|=        1.7941
At iterate    33  f =      -488.81  |proj g|=        1.7825
At iterate    34  f =      -488.81  |proj g|=        1.7845
At iterate    35  f =      -488.87  |proj g|=        1.7877
At iterate    36  f =      -489.08  |proj g|=        1.7809
At iterate    37  f =      -489.13  |proj g|=        1.8064
At iterate    38  f =       -489.4  |proj g|=        1.7718
At iterate    39  f =      -489.98  |proj g|=        1.7038
At iterate    40  f =      -492.41  |proj g|=       0.21746
At iterate    41  f =      -492.69  |proj g|=       0.21839
At iterate    42  f =      -492.81  |proj g|=       0.21932
At iterate    43  f =      -492.82  |proj g|=        0.2195
At iterate    44  f =      -492.82  |proj g|=       0.21947
At iterate    45  f =      -492.82  |proj g|=       0.21918
At iterate    46  f =      -492.83  |proj g|=       0.21826
At iterate    47  f =      -492.85  |proj g|=       0.21553
At iterate    48  f =      -492.89  |proj g|=       0.78496
At iterate    49  f =      -492.92  |proj g|=        0.7911
At iterate    50  f =      -492.94  |proj g|=       0.79332
At iterate    51  f =      -492.94  |proj g|=      0.099259
At iterate    52  f =      -492.94  |proj g|=      0.017354
At iterate    53  f =      -492.94  |proj g|=      0.017354

iterations 53
function evaluations 65
segments explored during Cauchy searches 56
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0173535
final function value -492.936

F = -492.936
final  value -492.935565 
converged
 
INFO  [07:22:22.411] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:22:22.499] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:22:22.506] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:22:32.881] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:22:44.050] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:22:55.798] [mlr3]  Finished benchmark 
INFO  [07:22:55.901] [bbotk] Result of batch 103: 
INFO  [07:22:55.902] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:22:55.902] [bbotk]              4.172295                 6.840531                       0.1381873 
INFO  [07:22:55.902] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:22:55.902] [bbotk]                     4781        0.751 -0.9625801         <NA>   0.9746618 
INFO  [07:22:55.902] [bbotk]                                 uhash 
INFO  [07:22:55.902] [bbotk]  9979d29e-48ec-4809-b394-835100190aaf 
DEBUG [07:22:57.264] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.382781e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.382781e-05 0.00324029 
  - best initial criterion value(s) :  431.7966 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -431.8  |proj g|=       7.5892
At iterate     1  f =      -435.06  |proj g|=        9.6549
At iterate     2  f =      -438.75  |proj g|=        8.2903
At iterate     3  f =      -443.03  |proj g|=        7.0247
At iterate     4  f =      -455.47  |proj g|=        2.6555
At iterate     5  f =      -456.89  |proj g|=        3.8216
At iterate     6  f =      -457.17  |proj g|=        3.5429
At iterate     7  f =      -457.21  |proj g|=        3.4347
At iterate     8  f =      -457.21  |proj g|=        3.4483
At iterate     9  f =      -457.21  |proj g|=        3.4484
At iterate    10  f =      -457.21  |proj g|=        3.4486
At iterate    11  f =      -457.21  |proj g|=        3.4495
At iterate    12  f =      -457.21  |proj g|=        3.4515
At iterate    13  f =      -457.21  |proj g|=        3.4572
At iterate    14  f =      -457.21  |proj g|=        3.4679
At iterate    15  f =      -457.22  |proj g|=        3.4855
At iterate    16  f =      -457.23  |proj g|=        3.5173
At iterate    17  f =      -457.23  |proj g|=        3.5049
At iterate    18  f =      -457.25  |proj g|=          3.55
At iterate    19  f =      -459.75  |proj g|=         3.486
At iterate    20  f =      -465.34  |proj g|=        2.5266
At iterate    21  f =       -467.8  |proj g|=         1.385
At iterate    22  f =      -473.52  |proj g|=        1.2636
At iterate    23  f =      -473.61  |proj g|=        1.2213
At iterate    24  f =      -475.05  |proj g|=       0.87074
At iterate    25  f =      -475.06  |proj g|=       0.87073
At iterate    26  f =      -475.07  |proj g|=       0.87071
At iterate    27  f =      -475.07  |proj g|=       0.87071
At iterate    28  f =      -475.07  |proj g|=        0.8707
At iterate    29  f =      -475.07  |proj g|=        0.8707
At iterate    30  f =      -475.07  |proj g|=        0.8707

iterations 30
function evaluations 38
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.870701
final function value -475.068

F = -475.068
final  value -475.067553 
converged
 
INFO  [07:22:57.269] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:22:57.357] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:22:57.364] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:23:03.924] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:23:11.016] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:23:17.944] [mlr3]  Finished benchmark 
INFO  [07:23:18.056] [bbotk] Result of batch 104: 
INFO  [07:23:18.058] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:23:18.058] [bbotk]              3.036477                 2.535546                       0.2283527 
INFO  [07:23:18.058] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:23:18.058] [bbotk]                     4161        0.948 -0.9690141         <NA>   0.9726691 
INFO  [07:23:18.058] [bbotk]                                 uhash 
INFO  [07:23:18.058] [bbotk]  92e04d50-dd60-42e1-a228-e29d69b289a4 
DEBUG [07:23:19.458] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.36568e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.36568e-05 0.003226094 
  - best initial criterion value(s) :  467.6997 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -467.7  |proj g|=       4.1353
At iterate     1  f =      -469.27  |proj g|=        4.8193
At iterate     2  f =      -469.39  |proj g|=        4.7414
At iterate     3  f =      -469.55  |proj g|=        4.5855
At iterate     4  f =      -469.75  |proj g|=        4.4499
At iterate     5  f =      -470.49  |proj g|=        3.9979
At iterate     6  f =      -471.25  |proj g|=        3.6549
At iterate     7  f =      -471.55  |proj g|=        3.6134
At iterate     8  f =      -471.56  |proj g|=        3.6627
At iterate     9  f =      -471.56  |proj g|=        3.6741
At iterate    10  f =      -471.56  |proj g|=        3.6776
At iterate    11  f =      -471.56  |proj g|=        3.6902
At iterate    12  f =      -471.57  |proj g|=         3.705
At iterate    13  f =      -471.58  |proj g|=        3.7284
At iterate    14  f =      -471.61  |proj g|=        3.7621
At iterate    15  f =       -471.7  |proj g|=        3.8106
At iterate    16  f =      -471.94  |proj g|=        3.8771
At iterate    17  f =      -472.57  |proj g|=        3.9531
At iterate    18  f =      -474.21  |proj g|=        3.9894
At iterate    19  f =      -478.34  |proj g|=        3.7928
At iterate    20  f =      -481.95  |proj g|=        2.9245
At iterate    21  f =      -487.98  |proj g|=        2.5225
At iterate    22  f =      -489.08  |proj g|=        2.3555
At iterate    23  f =      -489.69  |proj g|=        2.2215
At iterate    24  f =      -490.06  |proj g|=        2.1369
At iterate    25  f =      -492.47  |proj g|=        2.0202
At iterate    26  f =      -500.18  |proj g|=       0.37132
At iterate    27  f =      -504.36  |proj g|=       0.73985
At iterate    28  f =      -505.93  |proj g|=       0.77343
At iterate    29  f =      -506.46  |proj g|=       0.78234
At iterate    30  f =      -506.47  |proj g|=       0.21303
At iterate    31  f =      -506.47  |proj g|=       0.21371
At iterate    32  f =      -506.47  |proj g|=       0.27261
At iterate    33  f =      -506.47  |proj g|=       0.16934
At iterate    34  f =      -506.47  |proj g|=       0.06354
At iterate    35  f =      -506.47  |proj g|=       0.13646
At iterate    36  f =      -506.48  |proj g|=       0.78322
At iterate    37  f =      -506.48  |proj g|=       0.78451
At iterate    38  f =      -506.49  |proj g|=       0.78663
At iterate    39  f =      -506.49  |proj g|=       0.78664
At iterate    40  f =      -506.49  |proj g|=        0.7868
At iterate    41  f =       -506.5  |proj g|=       0.78549
At iterate    42  f =       -506.5  |proj g|=       0.21298
At iterate    43  f =       -506.5  |proj g|=       0.21366
At iterate    44  f =       -506.5  |proj g|=      0.061892
At iterate    45  f =       -506.5  |proj g|=      0.011292

iterations 45
function evaluations 57
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0112916
final function value -506.505

F = -506.505
final  value -506.504979 
converged
 
INFO  [07:23:19.463] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:23:19.581] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:23:19.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:23:21.572] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:23:23.465] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:23:25.426] [mlr3]  Finished benchmark 
INFO  [07:23:25.543] [bbotk] Result of batch 105: 
INFO  [07:23:25.545] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:23:25.545] [bbotk]              3.171212                 9.883633                       0.4000165 
INFO  [07:23:25.545] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:23:25.545] [bbotk]                     1195        0.807 -0.9596293         <NA>    0.970072 
INFO  [07:23:25.545] [bbotk]                                 uhash 
INFO  [07:23:25.545] [bbotk]  ac6302d2-e5dc-4078-aeab-65de2d36faa2 
DEBUG [07:23:26.834] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.348169e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.348169e-05 0.003180981 
  - best initial criterion value(s) :  465.9909 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -465.99  |proj g|=       2.0137
At iterate     1  f =      -470.58  |proj g|=        3.7317
At iterate     2  f =      -475.94  |proj g|=        3.6905
At iterate     3  f =      -482.58  |proj g|=        3.3846
At iterate     4  f =      -483.04  |proj g|=        3.2316
At iterate     5  f =      -483.56  |proj g|=         3.288
At iterate     6  f =      -488.42  |proj g|=        3.8223
At iterate     7  f =      -488.91  |proj g|=        3.8946
At iterate     8  f =      -488.97  |proj g|=        3.7704
At iterate     9  f =         -489  |proj g|=        3.8042
At iterate    10  f =       -489.1  |proj g|=        3.8597
At iterate    11  f =      -489.41  |proj g|=        3.9575
At iterate    12  f =      -490.21  |proj g|=        4.1152
At iterate    13  f =      -491.76  |proj g|=         4.312
At iterate    14  f =      -493.46  |proj g|=        4.4726
At iterate    15  f =      -495.13  |proj g|=         4.003
At iterate    16  f =      -495.66  |proj g|=        4.1256
At iterate    17  f =       -495.7  |proj g|=        4.0888
At iterate    18  f =       -495.7  |proj g|=        4.0962
At iterate    19  f =       -495.7  |proj g|=        4.0976
At iterate    20  f =       -495.7  |proj g|=         4.098
At iterate    21  f =       -495.7  |proj g|=        4.0986
At iterate    22  f =       -495.7  |proj g|=        4.1001
At iterate    23  f =       -495.7  |proj g|=        4.1022
At iterate    24  f =       -495.7  |proj g|=        4.1057
At iterate    25  f =       -495.7  |proj g|=        4.1108
At iterate    26  f =       -495.7  |proj g|=        4.1174
At iterate    27  f =       -495.7  |proj g|=         4.126
At iterate    28  f =      -495.71  |proj g|=        4.1331
At iterate    29  f =      -495.72  |proj g|=         4.159
At iterate    30  f =      -495.74  |proj g|=        4.1586
At iterate    31  f =      -495.92  |proj g|=        4.1348
At iterate    32  f =      -497.35  |proj g|=        3.8747
At iterate    33  f =      -501.04  |proj g|=        3.1194
At iterate    34  f =      -506.41  |proj g|=        2.2006
At iterate    35  f =      -507.72  |proj g|=        1.7175
At iterate    36  f =      -511.73  |proj g|=       0.35343
At iterate    37  f =       -514.3  |proj g|=       0.30239
At iterate    38  f =      -515.45  |proj g|=       0.79012
At iterate    39  f =      -515.83  |proj g|=       0.23903
At iterate    40  f =      -515.85  |proj g|=       0.23176
At iterate    41  f =      -515.86  |proj g|=       0.36666
At iterate    42  f =      -515.86  |proj g|=     0.0043801
At iterate    43  f =      -515.86  |proj g|=      0.001961

iterations 43
function evaluations 51
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.001961
final function value -515.855

F = -515.855
final  value -515.855315 
converged
 
INFO  [07:23:26.838] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:23:26.923] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:23:26.930] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:23:28.295] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:23:29.682] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:23:31.052] [mlr3]  Finished benchmark 
INFO  [07:23:31.166] [bbotk] Result of batch 106: 
INFO  [07:23:31.168] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:23:31.168] [bbotk]              9.900474                 5.221029                        0.333958 
INFO  [07:23:31.168] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:23:31.168] [bbotk]                      742        0.775 -0.9503136         <NA>   0.9730862 
INFO  [07:23:31.168] [bbotk]                                 uhash 
INFO  [07:23:31.168] [bbotk]  77719841-1c62-46b2-9ee5-9cca49c89477 
DEBUG [07:23:32.257] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.331758e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.331758e-05 0.003135816 
  - best initial criterion value(s) :  470.4513 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -470.45  |proj g|=       1.2516
At iterate     1  f =      -500.24  |proj g|=       0.52598
At iterate     2  f =      -501.51  |proj g|=       0.98263
At iterate     3  f =       -501.6  |proj g|=       0.97839
At iterate     4  f =      -501.69  |proj g|=       0.98876
At iterate     5  f =      -501.69  |proj g|=        1.0001
At iterate     6  f =      -501.69  |proj g|=         1.008
At iterate     7  f =      -501.69  |proj g|=        1.0095
At iterate     8  f =      -501.69  |proj g|=        1.0096

iterations 8
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.00957
final function value -501.69

F = -501.69
final  value -501.690420 
converged
 
INFO  [07:23:32.262] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:23:32.381] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:23:32.389] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:23:33.836] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:23:35.385] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:23:36.895] [mlr3]  Finished benchmark 
INFO  [07:23:37.012] [bbotk] Result of batch 107: 
INFO  [07:23:37.015] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:23:37.015] [bbotk]              5.472411                 5.972361                       0.3813578 
INFO  [07:23:37.015] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:23:37.015] [bbotk]                      858        0.789 -0.9653789         <NA>    0.973312 
INFO  [07:23:37.015] [bbotk]                                 uhash 
INFO  [07:23:37.015] [bbotk]  aa7d2c94-67c9-422e-a0f1-c290290077e0 
DEBUG [07:23:38.181] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.31569e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.31569e-05 0.003093265 
  - best initial criterion value(s) :  471.158 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -471.16  |proj g|=        3.571
At iterate     1  f =      -475.81  |proj g|=        5.9584
At iterate     2  f =      -478.15  |proj g|=        5.7467
At iterate     3  f =      -481.83  |proj g|=        5.0045
At iterate     4  f =      -483.94  |proj g|=         3.976
At iterate     5  f =      -489.78  |proj g|=        3.6795
At iterate     6  f =      -492.74  |proj g|=        3.0559
At iterate     7  f =      -493.04  |proj g|=          3.18
At iterate     8  f =      -493.05  |proj g|=        3.1055
At iterate     9  f =      -493.05  |proj g|=        3.1312
At iterate    10  f =      -493.05  |proj g|=        3.1164
At iterate    11  f =      -493.08  |proj g|=        3.0696
At iterate    12  f =      -493.14  |proj g|=        2.9862
At iterate    13  f =      -493.32  |proj g|=        2.8305
At iterate    14  f =      -493.82  |proj g|=         2.525
At iterate    15  f =      -495.17  |proj g|=        1.9405
At iterate    16  f =       -498.6  |proj g|=         1.011
At iterate    17  f =      -503.11  |proj g|=       0.86992
At iterate    18  f =      -504.35  |proj g|=       0.86209
At iterate    19  f =      -506.23  |proj g|=       0.83887
At iterate    20  f =      -506.75  |proj g|=       0.87532
At iterate    21  f =      -506.86  |proj g|=       0.94699
At iterate    22  f =      -506.87  |proj g|=       0.97126
At iterate    23  f =      -506.87  |proj g|=       0.97487
At iterate    24  f =      -506.87  |proj g|=       0.97582
At iterate    25  f =      -506.87  |proj g|=       0.97589

iterations 25
function evaluations 33
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.975891
final function value -506.872

F = -506.872
final  value -506.871526 
converged
 
INFO  [07:23:38.186] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:23:38.560] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:23:38.568] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:23:41.383] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:23:44.240] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:23:47.098] [mlr3]  Finished benchmark 
INFO  [07:23:47.212] [bbotk] Result of batch 108: 
INFO  [07:23:47.215] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:23:47.215] [bbotk]              3.916012                 2.158965                     0.008275701 
INFO  [07:23:47.215] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:23:47.215] [bbotk]                     1779        0.759 -0.9653782         <NA>   0.9122013 
INFO  [07:23:47.215] [bbotk]                                 uhash 
INFO  [07:23:47.215] [bbotk]  3b426e1c-cfee-4172-b1f7-0331d17d8f58 
DEBUG [07:23:48.813] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.536872e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.536872e-05 0.00326559 
  - best initial criterion value(s) :  478.1082 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -478.11  |proj g|=       1.7072
At iterate     1  f =      -496.64  |proj g|=        3.2138
At iterate     2  f =      -499.68  |proj g|=        2.9114
At iterate     3  f =      -502.92  |proj g|=        2.0685
At iterate     4  f =      -502.94  |proj g|=        1.9545
At iterate     5  f =      -502.94  |proj g|=        1.9879
At iterate     6  f =      -502.95  |proj g|=        1.9972
At iterate     7  f =      -502.97  |proj g|=        2.0198
At iterate     8  f =      -502.98  |proj g|=         2.015
At iterate     9  f =      -502.99  |proj g|=        1.9859
At iterate    10  f =      -502.99  |proj g|=         1.985
At iterate    11  f =      -502.99  |proj g|=        1.9849
At iterate    12  f =      -502.99  |proj g|=        1.9846
At iterate    13  f =      -502.99  |proj g|=        1.9843
At iterate    14  f =      -502.99  |proj g|=        1.9835
At iterate    15  f =      -502.99  |proj g|=        1.9825
At iterate    16  f =      -502.99  |proj g|=        1.9808
At iterate    17  f =      -502.99  |proj g|=        1.9782
At iterate    18  f =      -502.99  |proj g|=        1.9748
At iterate    19  f =      -502.99  |proj g|=        1.9729
At iterate    20  f =         -503  |proj g|=        1.9781
At iterate    21  f =         -503  |proj g|=        1.9761
At iterate    22  f =      -503.01  |proj g|=        1.9707
At iterate    23  f =      -503.06  |proj g|=        1.9686
At iterate    24  f =      -503.36  |proj g|=        1.9783
At iterate    25  f =      -503.86  |proj g|=        2.0274
At iterate    26  f =      -503.87  |proj g|=          2.01
At iterate    27  f =      -504.79  |proj g|=        2.1537
At iterate    28  f =      -505.39  |proj g|=        2.2948
At iterate    29  f =      -505.47  |proj g|=        2.3424
At iterate    30  f =      -505.48  |proj g|=        2.3658
At iterate    31  f =      -505.48  |proj g|=        2.3692
At iterate    32  f =      -505.48  |proj g|=        2.3691
At iterate    33  f =      -505.48  |proj g|=        2.3689
At iterate    34  f =      -505.48  |proj g|=        2.3685
At iterate    35  f =      -505.48  |proj g|=        2.3732
At iterate    36  f =      -505.49  |proj g|=        2.3865
At iterate    37  f =      -505.52  |proj g|=        2.4018
At iterate    38  f =      -505.59  |proj g|=        2.4252
At iterate    39  f =      -505.79  |proj g|=        2.4489
At iterate    40  f =       -506.3  |proj g|=        2.4488
At iterate    41  f =      -507.72  |proj g|=        2.3389
At iterate    42  f =      -509.61  |proj g|=        2.1076
At iterate    43  f =      -511.13  |proj g|=        1.8526
At iterate    44  f =      -511.79  |proj g|=         1.393
At iterate    45  f =      -511.96  |proj g|=        1.5012
At iterate    46  f =      -512.23  |proj g|=          1.21
At iterate    47  f =      -513.18  |proj g|=       0.25204
At iterate    48  f =      -513.29  |proj g|=       0.25121
At iterate    49  f =      -513.29  |proj g|=       0.25117
At iterate    50  f =      -513.33  |proj g|=       0.25052
At iterate    51  f =      -513.39  |proj g|=       0.24897
At iterate    52  f =      -513.57  |proj g|=         0.243
At iterate    53  f =      -513.94  |proj g|=       0.22989
At iterate    54  f =      -514.67  |proj g|=       0.20321
At iterate    55  f =      -515.43  |proj g|=       0.17404
At iterate    56  f =      -515.48  |proj g|=       0.50738
At iterate    57  f =      -515.48  |proj g|=      0.062717
At iterate    58  f =      -515.48  |proj g|=     0.0043299
At iterate    59  f =      -515.48  |proj g|=       0.00433

iterations 59
function evaluations 69
segments explored during Cauchy searches 61
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00432996
final function value -515.481

F = -515.481
final  value -515.481247 
converged
 
INFO  [07:23:48.817] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:23:48.959] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:23:48.968] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:23:51.176] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:23:53.272] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:23:55.400] [mlr3]  Finished benchmark 
INFO  [07:23:55.517] [bbotk] Result of batch 109: 
INFO  [07:23:55.519] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:23:55.519] [bbotk]                8.5767                 9.112853                       0.3825437 
INFO  [07:23:55.519] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [07:23:55.519] [bbotk]                     1191        0.956 -0.955911         <NA>   0.9752285 
INFO  [07:23:55.519] [bbotk]                                 uhash 
INFO  [07:23:55.519] [bbotk]  dd08a64f-3702-4e3c-b34a-1aca6b6c637a 
DEBUG [07:23:56.914] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.521132e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.521132e-05 0.003221373 
  - best initial criterion value(s) :  469.7606 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -469.76  |proj g|=        6.352
At iterate     1  f =      -474.86  |proj g|=        3.8976
At iterate     2  f =      -478.39  |proj g|=        7.1046
At iterate     3  f =      -479.29  |proj g|=        6.5394
At iterate     4  f =       -479.7  |proj g|=        5.9272
At iterate     5  f =      -479.94  |proj g|=        6.1341
At iterate     6  f =      -480.15  |proj g|=        6.4004
At iterate     7  f =      -480.19  |proj g|=        6.5416
At iterate     8  f =       -480.2  |proj g|=        6.4106
At iterate     9  f =      -480.21  |proj g|=        6.4331
At iterate    10  f =      -480.21  |proj g|=        6.4468
At iterate    11  f =      -480.21  |proj g|=        6.4774
At iterate    12  f =      -480.22  |proj g|=        6.5225
At iterate    13  f =      -480.25  |proj g|=        6.5826
At iterate    14  f =      -480.32  |proj g|=        6.6695
At iterate    15  f =       -480.5  |proj g|=        6.7436
At iterate    16  f =      -480.91  |proj g|=        6.8828
At iterate    17  f =      -481.97  |proj g|=        6.7583
At iterate    18  f =      -485.14  |proj g|=        6.2579
At iterate    19  f =      -491.85  |proj g|=        4.9127
At iterate    20  f =       -505.8  |proj g|=        2.3097
At iterate    21  f =       -510.2  |proj g|=        2.0082
At iterate    22  f =      -515.38  |proj g|=        1.5996
At iterate    23  f =       -517.3  |proj g|=         1.032
At iterate    24  f =      -518.87  |proj g|=        1.2118
At iterate    25  f =      -519.27  |proj g|=        1.4008
At iterate    26  f =      -519.33  |proj g|=         1.396
At iterate    27  f =      -519.34  |proj g|=         1.363
At iterate    28  f =      -519.34  |proj g|=         1.365
At iterate    29  f =      -519.34  |proj g|=        1.3661
At iterate    30  f =      -519.34  |proj g|=        1.3666
At iterate    31  f =      -519.34  |proj g|=        1.3673
At iterate    32  f =      -519.34  |proj g|=        1.3685
At iterate    33  f =      -519.35  |proj g|=        1.3701
At iterate    34  f =      -519.35  |proj g|=        1.3722
At iterate    35  f =      -519.35  |proj g|=        1.3751
At iterate    36  f =      -519.35  |proj g|=        1.3765
At iterate    37  f =      -519.35  |proj g|=         1.392
At iterate    38  f =      -519.36  |proj g|=        1.3885
At iterate    39  f =       -519.4  |proj g|=        1.3728
At iterate    40  f =      -519.56  |proj g|=        1.3239
At iterate    41  f =      -520.22  |proj g|=        1.1438
At iterate    42  f =      -522.37  |proj g|=       0.83794
At iterate    43  f =      -522.38  |proj g|=       0.83759
At iterate    44  f =      -522.68  |proj g|=       0.82155
At iterate    45  f =      -522.71  |proj g|=       0.34756
At iterate    46  f =      -522.72  |proj g|=       0.18209
At iterate    47  f =      -522.72  |proj g|=      0.057787
At iterate    48  f =      -522.72  |proj g|=      0.005747

iterations 48
function evaluations 59
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.005747
final function value -522.715

F = -522.715
final  value -522.715191 
converged
 
INFO  [07:23:56.919] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:23:57.019] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:23:57.027] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:24:02.822] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:24:08.579] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:24:14.356] [mlr3]  Finished benchmark 
INFO  [07:24:14.523] [bbotk] Result of batch 110: 
INFO  [07:24:14.525] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:24:14.525] [bbotk]              8.857217                 8.842659                       0.4971045 
INFO  [07:24:14.525] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:24:14.525] [bbotk]                     3581        0.796 -0.9524633         <NA>   0.9780457 
INFO  [07:24:14.525] [bbotk]                                 uhash 
INFO  [07:24:14.525] [bbotk]  c18cde71-7be0-4698-86ad-6e698c333653 
DEBUG [07:24:15.722] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.508496e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.508496e-05 0.003225655 
  - best initial criterion value(s) :  488.0194 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -488.02  |proj g|=       1.8512
At iterate     1  f =      -491.22  |proj g|=        1.8519
At iterate     2  f =       -492.5  |proj g|=         2.021
At iterate     3  f =      -492.53  |proj g|=        2.0239
At iterate     4  f =      -492.53  |proj g|=        2.0274
At iterate     5  f =      -492.53  |proj g|=        2.0283
At iterate     6  f =      -492.53  |proj g|=        2.0288
At iterate     7  f =      -492.53  |proj g|=        2.0289

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.02888
final function value -492.535

F = -492.535
final  value -492.534609 
converged
 
INFO  [07:24:15.727] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:24:15.825] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:24:15.833] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:24:19.684] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:24:24.425] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:24:29.084] [mlr3]  Finished benchmark 
INFO  [07:24:29.222] [bbotk] Result of batch 111: 
INFO  [07:24:29.224] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:24:29.224] [bbotk]              3.850563                 6.152004                        0.405485 
INFO  [07:24:29.224] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:24:29.224] [bbotk]                     2080        0.874 -0.9683704         <NA>    0.975032 
INFO  [07:24:29.224] [bbotk]                                 uhash 
INFO  [07:24:29.224] [bbotk]  33d049e6-e2ed-415e-8196-06ebc655b823 
DEBUG [07:24:30.530] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.492936e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.492936e-05 0.003211289 
  - best initial criterion value(s) :  443.0805 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -443.08  |proj g|=       9.0947
At iterate     1  f =      -487.66  |proj g|=        4.5151
At iterate     2  f =      -493.16  |proj g|=        6.6921
At iterate     3  f =      -494.45  |proj g|=        6.1629
At iterate     4  f =      -495.64  |proj g|=        4.7922
At iterate     5  f =      -495.65  |proj g|=          4.91
At iterate     6  f =      -495.65  |proj g|=        4.9043
At iterate     7  f =      -495.65  |proj g|=        4.9034
At iterate     8  f =      -495.65  |proj g|=        4.9088
At iterate     9  f =      -495.65  |proj g|=        4.9131
At iterate    10  f =      -495.65  |proj g|=        4.9359
At iterate    11  f =      -495.66  |proj g|=        5.0795
At iterate    12  f =      -495.67  |proj g|=        5.0305
At iterate    13  f =      -495.71  |proj g|=        4.9498
At iterate    14  f =       -495.8  |proj g|=        4.8068
At iterate    15  f =      -496.06  |proj g|=        4.5026
At iterate    16  f =      -496.77  |proj g|=        3.9406
At iterate    17  f =      -498.88  |proj g|=        2.9301
At iterate    18  f =      -505.48  |proj g|=        2.3356
At iterate    19  f =      -516.04  |proj g|=        2.4282
At iterate    20  f =      -517.85  |proj g|=        2.3921
At iterate    21  f =      -521.74  |proj g|=        2.1657
At iterate    22  f =       -522.9  |proj g|=        2.2577
At iterate    23  f =      -522.92  |proj g|=        2.2558
At iterate    24  f =      -522.92  |proj g|=        2.2592
At iterate    25  f =      -522.92  |proj g|=        2.2605
At iterate    26  f =      -522.92  |proj g|=        2.2605
At iterate    27  f =      -522.92  |proj g|=        2.2606
At iterate    28  f =      -522.92  |proj g|=        2.2606
At iterate    29  f =      -522.92  |proj g|=        2.2604
At iterate    30  f =      -522.94  |proj g|=        2.2591
At iterate    31  f =      -522.96  |proj g|=        2.2411
At iterate    32  f =      -523.02  |proj g|=        2.2593
At iterate    33  f =      -523.13  |proj g|=        2.2073
At iterate    34  f =      -523.55  |proj g|=         2.091
At iterate    35  f =      -524.91  |proj g|=        1.7955
At iterate    36  f =      -527.35  |proj g|=       0.24407
At iterate    37  f =       -528.7  |proj g|=        0.2269
At iterate    38  f =       -529.9  |proj g|=       0.82772
At iterate    39  f =      -530.06  |proj g|=       0.18136
At iterate    40  f =      -530.07  |proj g|=       0.17873
At iterate    41  f =      -530.07  |proj g|=      0.024481
At iterate    42  f =      -530.07  |proj g|=      0.015403

iterations 42
function evaluations 50
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0154031
final function value -530.067

F = -530.067
final  value -530.066923 
converged
 
INFO  [07:24:30.534] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:24:30.621] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:24:30.629] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:24:33.777] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:24:36.888] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:24:40.638] [mlr3]  Finished benchmark 
INFO  [07:24:40.739] [bbotk] Result of batch 112: 
INFO  [07:24:40.741] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:24:40.741] [bbotk]              6.218995                 6.443133                       0.3638469 
INFO  [07:24:40.741] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:24:40.741] [bbotk]                     1505        0.787 -0.9558063         <NA>   0.9756521 
INFO  [07:24:40.741] [bbotk]                                 uhash 
INFO  [07:24:40.741] [bbotk]  349e4c4d-342c-4b52-bc10-bd10e1658832 
DEBUG [07:24:41.933] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.478075e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.478075e-05 0.003168738 
  - best initial criterion value(s) :  501.694 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -501.69  |proj g|=       3.7336
At iterate     1  f =      -502.74  |proj g|=        3.9998
At iterate     2  f =       -502.9  |proj g|=        3.9421
At iterate     3  f =      -503.66  |proj g|=        3.5579
At iterate     4  f =      -503.87  |proj g|=        3.5399
At iterate     5  f =      -503.89  |proj g|=        3.5388
At iterate     6  f =      -503.89  |proj g|=        3.5427
At iterate     7  f =       -503.9  |proj g|=        3.5464
At iterate     8  f =       -503.9  |proj g|=        3.5523
At iterate     9  f =       -503.9  |proj g|=        3.5661
At iterate    10  f =      -503.92  |proj g|=        3.5848
At iterate    11  f =      -503.95  |proj g|=        3.6144
At iterate    12  f =      -504.04  |proj g|=        3.6588
At iterate    13  f =      -504.26  |proj g|=        3.7211
At iterate    14  f =       -504.7  |proj g|=        3.7831
At iterate    15  f =      -505.58  |proj g|=        3.8089
At iterate    16  f =      -506.68  |proj g|=        3.6124
At iterate    17  f =      -507.92  |proj g|=        3.5738
At iterate    18  f =      -511.94  |proj g|=        3.1542
At iterate    19  f =      -525.01  |proj g|=        1.7308
At iterate    20  f =      -525.99  |proj g|=        1.8004
At iterate    21  f =      -530.75  |proj g|=        1.1128
At iterate    22  f =      -530.88  |proj g|=       0.96845
At iterate    23  f =       -530.9  |proj g|=       0.93794
At iterate    24  f =       -530.9  |proj g|=       0.94155
At iterate    25  f =       -530.9  |proj g|=       0.94133

iterations 25
function evaluations 32
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.941327
final function value -530.898

F = -530.898
final  value -530.897968 
converged
 
INFO  [07:24:41.937] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:24:42.026] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:24:42.033] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:24:43.171] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:24:44.555] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:24:46.399] [mlr3]  Finished benchmark 
INFO  [07:24:46.501] [bbotk] Result of batch 113: 
INFO  [07:24:46.503] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:24:46.503] [bbotk]              2.655459                 6.835425                       0.2365679 
INFO  [07:24:46.503] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:24:46.503] [bbotk]                      361        0.774 -0.9580562         <NA>   0.9420524 
INFO  [07:24:46.503] [bbotk]                                 uhash 
INFO  [07:24:46.503] [bbotk]  fbfc3401-d6e4-43f4-8c1e-9f471bb65823 
DEBUG [07:24:47.808] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.513015e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.513014e-05 0.003212545 
  - best initial criterion value(s) :  459.0439 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -459.04  |proj g|=        11.77
At iterate     1  f =      -466.07  |proj g|=        8.5262
At iterate     2  f =      -488.25  |proj g|=        5.2059
At iterate     3  f =      -492.46  |proj g|=        3.8946
At iterate     4  f =      -498.96  |proj g|=        2.4891
At iterate     5  f =      -499.25  |proj g|=        2.6477
At iterate     6  f =      -499.26  |proj g|=        2.5975
At iterate     7  f =      -499.27  |proj g|=         2.603
At iterate     8  f =      -499.43  |proj g|=        2.6429
At iterate     9  f =      -499.81  |proj g|=        2.6696
At iterate    10  f =      -500.72  |proj g|=        2.6396
At iterate    11  f =      -502.76  |proj g|=        2.4762
At iterate    12  f =      -506.53  |proj g|=        2.1191
At iterate    13  f =      -508.87  |proj g|=        1.7705
At iterate    14  f =      -513.99  |proj g|=       0.94606
At iterate    15  f =       -514.3  |proj g|=        0.9458
At iterate    16  f =      -514.66  |proj g|=       0.75295
At iterate    17  f =      -514.67  |proj g|=       0.84086
At iterate    18  f =      -514.69  |proj g|=       0.79931
At iterate    19  f =      -514.69  |proj g|=       0.79789
At iterate    20  f =      -514.69  |proj g|=       0.79819

iterations 20
function evaluations 27
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.798189
final function value -514.689

F = -514.689
final  value -514.688565 
converged
 
INFO  [07:24:47.812] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:24:47.900] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:24:47.907] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:24:54.209] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:24:59.729] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:25:05.080] [mlr3]  Finished benchmark 
INFO  [07:25:05.179] [bbotk] Result of batch 114: 
INFO  [07:25:05.181] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:25:05.181] [bbotk]               7.77422                 3.867173                      0.01226994 
INFO  [07:25:05.181] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:25:05.181] [bbotk]                     2278        0.927 -0.9659136         <NA>   0.9477545 
INFO  [07:25:05.181] [bbotk]                                 uhash 
INFO  [07:25:05.181] [bbotk]  8b4d3fad-21fc-4f5d-b762-33fe136c8800 
DEBUG [07:25:06.435] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.527567e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.527567e-05 0.003217745 
  - best initial criterion value(s) :  489.4005 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -489.4  |proj g|=       4.2198
At iterate     1  f =      -491.97  |proj g|=        4.5339
At iterate     2  f =      -492.22  |proj g|=         4.496
At iterate     3  f =      -493.54  |proj g|=        4.1452
At iterate     4  f =      -498.42  |proj g|=         3.632
At iterate     5  f =      -499.42  |proj g|=        3.1063
At iterate     6  f =         -500  |proj g|=        3.3532
At iterate     7  f =      -500.02  |proj g|=         3.298
At iterate     8  f =      -500.02  |proj g|=        3.2991
At iterate     9  f =      -500.02  |proj g|=        3.2994
At iterate    10  f =      -500.02  |proj g|=        3.2995
At iterate    11  f =      -500.02  |proj g|=        3.2996
At iterate    12  f =      -500.02  |proj g|=        3.2997
At iterate    13  f =      -500.03  |proj g|=        3.2996
At iterate    14  f =      -500.03  |proj g|=        3.2987
At iterate    15  f =      -500.05  |proj g|=        3.2976
At iterate    16  f =      -500.09  |proj g|=        3.2978
At iterate    17  f =      -500.19  |proj g|=        3.3052
At iterate    18  f =      -500.41  |proj g|=        3.3336
At iterate    19  f =      -500.72  |proj g|=        3.3868
At iterate    20  f =      -501.05  |proj g|=        3.3857
At iterate    21  f =      -501.69  |proj g|=        3.5048
At iterate    22  f =       -502.3  |proj g|=        3.4332
At iterate    23  f =      -507.04  |proj g|=        2.7546
At iterate    24  f =      -512.41  |proj g|=        2.1282
At iterate    25  f =      -522.26  |proj g|=       0.30845
At iterate    26  f =      -525.91  |proj g|=       0.48144
At iterate    27  f =      -526.69  |proj g|=       0.83193
At iterate    28  f =      -526.72  |proj g|=       0.59577
At iterate    29  f =      -526.73  |proj g|=       0.55815
At iterate    30  f =      -526.73  |proj g|=       0.55351
At iterate    31  f =      -526.73  |proj g|=       0.55414
At iterate    32  f =      -526.73  |proj g|=       0.55416

iterations 32
function evaluations 36
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.554159
final function value -526.731

F = -526.731
final  value -526.730833 
converged
 
INFO  [07:25:06.439] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:25:06.541] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:25:06.548] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:25:08.622] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:25:10.769] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:25:12.977] [mlr3]  Finished benchmark 
INFO  [07:25:13.095] [bbotk] Result of batch 115: 
INFO  [07:25:13.097] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:25:13.097] [bbotk]              7.357351                 9.529769                      0.03784967 
INFO  [07:25:13.097] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:25:13.097] [bbotk]                      936        0.781 -0.9634218         <NA>   0.9518127 
INFO  [07:25:13.097] [bbotk]                                 uhash 
INFO  [07:25:13.097] [bbotk]  6cd87ccd-6e29-4c8d-b01b-516d6498412b 
DEBUG [07:25:14.304] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.530719e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.530719e-05 0.003209412 
  - best initial criterion value(s) :  468.3368 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -468.34  |proj g|=       5.0968
At iterate     1  f =      -483.87  |proj g|=        5.5314
At iterate     2  f =      -512.77  |proj g|=        3.2886
At iterate     3  f =      -516.81  |proj g|=        2.2516
At iterate     4  f =      -517.04  |proj g|=        2.3633
At iterate     5  f =       -517.2  |proj g|=        2.3384
At iterate     6  f =      -517.36  |proj g|=         2.322
At iterate     7  f =      -517.66  |proj g|=         2.323
At iterate     8  f =      -518.16  |proj g|=        2.3562
At iterate     9  f =      -518.48  |proj g|=        2.4081
At iterate    10  f =      -518.63  |proj g|=        2.4601
At iterate    11  f =      -518.66  |proj g|=        2.4908
At iterate    12  f =      -518.66  |proj g|=        2.5002
At iterate    13  f =      -518.66  |proj g|=        2.5013
At iterate    14  f =      -518.66  |proj g|=        2.5015
At iterate    15  f =      -518.66  |proj g|=        2.5025
At iterate    16  f =      -518.66  |proj g|=        2.5033
At iterate    17  f =      -518.66  |proj g|=        2.5041
At iterate    18  f =      -518.66  |proj g|=        2.5054
At iterate    19  f =      -518.67  |proj g|=        2.5072
At iterate    20  f =      -518.67  |proj g|=         2.508
At iterate    21  f =      -518.69  |proj g|=        2.5037
At iterate    22  f =      -518.69  |proj g|=        2.5194
At iterate    23  f =      -518.72  |proj g|=        2.5138
At iterate    24  f =      -520.01  |proj g|=        2.6324
At iterate    25  f =      -520.39  |proj g|=        2.7182
At iterate    26  f =      -520.43  |proj g|=        2.7374
At iterate    27  f =      -520.43  |proj g|=        2.7416
At iterate    28  f =      -520.43  |proj g|=        2.7422
At iterate    29  f =      -520.43  |proj g|=        2.7419
At iterate    30  f =      -520.43  |proj g|=        2.7418

iterations 30
function evaluations 36
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.74179
final function value -520.43

F = -520.43
final  value -520.429697 
converged
 
INFO  [07:25:14.308] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:25:14.393] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:25:14.400] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:25:24.491] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:25:34.642] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:25:43.404] [mlr3]  Finished benchmark 
INFO  [07:25:43.502] [bbotk] Result of batch 116: 
INFO  [07:25:43.504] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:25:43.504] [bbotk]              8.288028                 4.600445                       0.2349061 
INFO  [07:25:43.504] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:25:43.504] [bbotk]                     4215        0.763 -0.9602132         <NA>   0.9770305 
INFO  [07:25:43.504] [bbotk]                                 uhash 
INFO  [07:25:43.504] [bbotk]  589df4f7-adf5-4ef4-a581-4d92c63e6121 
DEBUG [07:25:44.574] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.51774e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.51774e-05 0.003202096 
  - best initial criterion value(s) :  502.5929 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -502.59  |proj g|=       2.4041
At iterate     1  f =      -509.16  |proj g|=         2.884
At iterate     2  f =      -509.93  |proj g|=         2.561
At iterate     3  f =      -510.71  |proj g|=        2.7351
At iterate     4  f =      -510.82  |proj g|=        2.7197
At iterate     5  f =       -510.9  |proj g|=         2.694
At iterate     6  f =      -510.91  |proj g|=        2.7043
At iterate     7  f =      -510.91  |proj g|=        2.7031
At iterate     8  f =      -510.91  |proj g|=         2.703

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.70305
final function value -510.907

F = -510.907
final  value -510.906999 
converged
 
INFO  [07:25:44.579] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:25:44.667] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:25:44.674] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:25:50.968] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:25:55.925] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:26:00.656] [mlr3]  Finished benchmark 
INFO  [07:26:00.778] [bbotk] Result of batch 117: 
INFO  [07:26:00.780] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:26:00.780] [bbotk]              7.537927                 3.884744                       0.4974358 
INFO  [07:26:00.780] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:26:00.780] [bbotk]                     2367        0.778 -0.9654904         <NA>   0.9773405 
INFO  [07:26:00.780] [bbotk]                                 uhash 
INFO  [07:26:00.780] [bbotk]  43ef78a9-7353-4b5f-bed3-db42f7e98f3d 
DEBUG [07:26:01.989] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.505219e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.505219e-05 0.003195159 
  - best initial criterion value(s) :  473.2833 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -473.28  |proj g|=       8.9218
At iterate     1  f =      -475.39  |proj g|=        2.2179
At iterate     2  f =      -476.76  |proj g|=        2.5972
At iterate     3  f =      -478.21  |proj g|=        2.9143
At iterate     4  f =      -486.75  |proj g|=        5.4724
At iterate     5  f =      -486.92  |proj g|=        5.5799
At iterate     6  f =      -487.33  |proj g|=        6.5688
At iterate     7  f =      -487.35  |proj g|=        6.8178
At iterate     8  f =      -487.38  |proj g|=        6.7269
At iterate     9  f =      -487.38  |proj g|=        6.7425
At iterate    10  f =      -487.39  |proj g|=        6.7616
At iterate    11  f =      -487.42  |proj g|=        6.7906
At iterate    12  f =      -487.49  |proj g|=        6.8433
At iterate    13  f =      -487.69  |proj g|=        6.9035
At iterate    14  f =      -488.28  |proj g|=        6.8487
At iterate    15  f =      -490.08  |proj g|=        6.4186
At iterate    16  f =      -495.22  |proj g|=        5.5455
At iterate    17  f =      -513.85  |proj g|=        3.0673
At iterate    18  f =      -524.88  |proj g|=       0.73825
At iterate    19  f =      -528.01  |proj g|=       0.93749
At iterate    20  f =      -528.02  |proj g|=        0.9612
At iterate    21  f =      -528.02  |proj g|=       0.97832
At iterate    22  f =      -528.02  |proj g|=       0.97907
At iterate    23  f =      -528.02  |proj g|=        0.9791

iterations 23
function evaluations 28
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.979097
final function value -528.022

F = -528.022
final  value -528.021559 
converged
 
INFO  [07:26:01.994] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:26:02.083] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:26:02.090] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:26:09.640] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:26:17.422] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:26:25.324] [mlr3]  Finished benchmark 
INFO  [07:26:25.425] [bbotk] Result of batch 118: 
INFO  [07:26:25.426] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:26:25.426] [bbotk]              9.320088                 3.924283                         0.27259 
INFO  [07:26:25.426] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:26:25.426] [bbotk]                     3538        0.811 -0.9642954         <NA>   0.9771457 
INFO  [07:26:25.426] [bbotk]                                 uhash 
INFO  [07:26:25.426] [bbotk]  f8621a4a-4a31-464c-9ff0-55aab70227f3 
DEBUG [07:26:26.697] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.492594e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.492594e-05 0.003189803 
  - best initial criterion value(s) :  501.2236 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -501.22  |proj g|=       2.4484
At iterate     1  f =      -516.66  |proj g|=        1.7544
At iterate     2  f =      -537.46  |proj g|=         2.474
At iterate     3  f =       -539.5  |proj g|=        2.5096
At iterate     4  f =      -543.55  |proj g|=        2.5675
At iterate     5  f =      -544.75  |proj g|=        2.5939
At iterate     6  f =      -545.33  |proj g|=         2.658
At iterate     7  f =      -545.52  |proj g|=        2.7217
At iterate     8  f =      -545.55  |proj g|=        2.7679
At iterate     9  f =      -545.56  |proj g|=        2.7656
At iterate    10  f =      -545.56  |proj g|=        2.7748
At iterate    11  f =      -545.56  |proj g|=        2.7728
At iterate    12  f =      -545.56  |proj g|=        2.7726
At iterate    13  f =      -545.56  |proj g|=        2.7711
At iterate    14  f =      -545.56  |proj g|=        2.7687
At iterate    15  f =      -545.58  |proj g|=        2.7637
At iterate    16  f =      -545.61  |proj g|=        2.7057
At iterate    17  f =      -545.67  |proj g|=         2.721
At iterate    18  f =      -546.08  |proj g|=        2.7621
At iterate    19  f =      -546.88  |proj g|=        2.7547
At iterate    20  f =      -549.15  |proj g|=        2.3106
At iterate    21  f =      -553.95  |proj g|=        1.1226
At iterate    22  f =      -555.29  |proj g|=        1.1211
At iterate    23  f =      -556.61  |proj g|=       0.90768
At iterate    24  f =      -556.71  |proj g|=       0.78699
At iterate    25  f =      -556.73  |proj g|=       0.78076
At iterate    26  f =      -556.73  |proj g|=       0.75978
At iterate    27  f =      -556.73  |proj g|=       0.75981

iterations 27
function evaluations 33
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.759812
final function value -556.731

F = -556.731
final  value -556.730667 
converged
 
INFO  [07:26:26.701] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:26:26.788] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:26:26.795] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:26:31.493] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:26:36.659] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:26:40.997] [mlr3]  Finished benchmark 
INFO  [07:26:41.129] [bbotk] Result of batch 119: 
INFO  [07:26:41.131] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:26:41.131] [bbotk]              2.768529                 5.578161                       0.1230313 
INFO  [07:26:41.131] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:26:41.131] [bbotk]                     2153        0.814 -0.9455294         <NA>   0.9606086 
INFO  [07:26:41.131] [bbotk]                                 uhash 
INFO  [07:26:41.131] [bbotk]  6594b714-5a71-4c19-9f98-41448525044f 
DEBUG [07:26:42.655] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.480778e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.480778e-05 0.003176806 
  - best initial criterion value(s) :  491.471 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -491.47  |proj g|=       3.2177
At iterate     1  f =      -519.65  |proj g|=        1.7733
At iterate     2  f =      -533.78  |proj g|=        4.0446
At iterate     3  f =      -534.45  |proj g|=        3.8711
At iterate     4  f =      -535.83  |proj g|=        2.5993
At iterate     5  f =      -535.94  |proj g|=        2.9694
At iterate     6  f =      -535.95  |proj g|=        2.9034
At iterate     7  f =      -535.95  |proj g|=        2.8892
At iterate     8  f =      -535.95  |proj g|=        2.8737
At iterate     9  f =      -535.95  |proj g|=        2.8794
At iterate    10  f =      -535.95  |proj g|=        2.8835
At iterate    11  f =      -535.95  |proj g|=        2.8841
At iterate    12  f =      -535.95  |proj g|=        2.8849
At iterate    13  f =      -535.95  |proj g|=         2.886
At iterate    14  f =      -535.95  |proj g|=         2.888
At iterate    15  f =      -535.95  |proj g|=        2.8912
At iterate    16  f =      -535.95  |proj g|=        2.8962
At iterate    17  f =      -535.95  |proj g|=        2.9042
At iterate    18  f =      -535.95  |proj g|=        2.9163
At iterate    19  f =      -535.96  |proj g|=        2.9319
At iterate    20  f =      -535.96  |proj g|=        2.9427
At iterate    21  f =      -535.97  |proj g|=        2.9169
At iterate    22  f =      -535.97  |proj g|=         2.888
At iterate    23  f =      -535.97  |proj g|=        2.8833
At iterate    24  f =      -535.97  |proj g|=        2.8824
At iterate    25  f =      -535.97  |proj g|=        2.8807
At iterate    26  f =      -535.97  |proj g|=        2.8779
At iterate    27  f =      -535.97  |proj g|=        2.8751
At iterate    28  f =      -535.97  |proj g|=        2.8675
At iterate    29  f =      -535.97  |proj g|=        2.8583
At iterate    30  f =      -535.98  |proj g|=        2.8202
At iterate    31  f =         -536  |proj g|=        2.7974
At iterate    32  f =      -536.06  |proj g|=         2.702
At iterate    33  f =       -536.2  |proj g|=        2.6078
At iterate    34  f =      -536.56  |proj g|=        2.1624
At iterate    35  f =       -537.4  |proj g|=        2.1197
At iterate    36  f =      -542.68  |proj g|=        1.9933
At iterate    37  f =      -547.42  |proj g|=       0.85758
At iterate    38  f =      -549.51  |proj g|=       0.84462
At iterate    39  f =      -551.04  |proj g|=         0.819
At iterate    40  f =      -551.14  |proj g|=       0.81912
At iterate    41  f =      -551.67  |proj g|=       0.79906
At iterate    42  f =      -551.72  |proj g|=       0.79129
At iterate    43  f =      -551.73  |proj g|=       0.20623
At iterate    44  f =      -551.73  |proj g|=       0.16143
At iterate    45  f =      -551.73  |proj g|=        0.1366
At iterate    46  f =      -551.73  |proj g|=       0.13664

iterations 46
function evaluations 50
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.136641
final function value -551.726

F = -551.726
final  value -551.725698 
converged
 
INFO  [07:26:42.659] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:26:42.746] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:26:42.753] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:26:44.838] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:26:46.686] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:26:49.289] [mlr3]  Finished benchmark 
INFO  [07:26:49.390] [bbotk] Result of batch 120: 
INFO  [07:26:49.392] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:26:49.392] [bbotk]              5.655499                 3.715758                       0.2566273 
INFO  [07:26:49.392] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:26:49.392] [bbotk]                      715        0.788 -0.9549611         <NA>   0.9699171 
INFO  [07:26:49.392] [bbotk]                                 uhash 
INFO  [07:26:49.392] [bbotk]  88b66111-6620-4e5e-814b-5923b0b1fb55 
DEBUG [07:26:50.683] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.46428e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.46428e-05 0.003137629 
  - best initial criterion value(s) :  505.4795 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -505.48  |proj g|=       3.0695
At iterate     1  f =      -518.96  |proj g|=         2.953
At iterate     2  f =      -551.16  |proj g|=        3.3443
At iterate     3  f =      -551.45  |proj g|=        3.3907
At iterate     4  f =      -552.38  |proj g|=        3.6157
At iterate     5  f =      -552.66  |proj g|=        3.5196
At iterate     6  f =      -552.91  |proj g|=        3.3747
At iterate     7  f =      -552.93  |proj g|=        3.2951
At iterate     8  f =      -552.93  |proj g|=        3.3096
At iterate     9  f =      -552.93  |proj g|=        3.3093
At iterate    10  f =      -552.93  |proj g|=        3.3053
At iterate    11  f =      -552.95  |proj g|=        3.2712
At iterate    12  f =      -552.99  |proj g|=        3.2286
At iterate    13  f =      -553.11  |proj g|=        3.1391
At iterate    14  f =      -553.45  |proj g|=        2.9816
At iterate    15  f =      -554.46  |proj g|=        2.6757
At iterate    16  f =      -557.56  |proj g|=        2.1647
At iterate    17  f =      -564.15  |proj g|=       0.22664
At iterate    18  f =      -565.27  |proj g|=       0.32892
At iterate    19  f =      -566.27  |proj g|=       0.61304
At iterate    20  f =      -566.73  |proj g|=       0.80567
At iterate    21  f =      -566.83  |proj g|=       0.90832
At iterate    22  f =      -566.85  |proj g|=       0.94833
At iterate    23  f =      -566.85  |proj g|=       0.95781
At iterate    24  f =      -566.85  |proj g|=       0.95849
At iterate    25  f =      -566.85  |proj g|=       0.95844

iterations 25
function evaluations 33
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.958441
final function value -566.847

F = -566.847
final  value -566.846955 
converged
 
INFO  [07:26:50.687] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:26:50.777] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:26:50.784] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:26:57.816] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:27:04.809] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:27:11.648] [mlr3]  Finished benchmark 
INFO  [07:27:11.763] [bbotk] Result of batch 121: 
INFO  [07:27:11.765] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:27:11.765] [bbotk]              4.710918                 2.085523                      0.03571436 
INFO  [07:27:11.765] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:27:11.765] [bbotk]                     2916        0.831 -0.9448412         <NA>   0.9627154 
INFO  [07:27:11.765] [bbotk]                                 uhash 
INFO  [07:27:11.765] [bbotk]  bbda12d4-1ac3-4c17-b035-f8da1a7bd34d 
DEBUG [07:27:13.114] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.450677e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.450677e-05 0.003122261 
  - best initial criterion value(s) :  438.9169 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -438.92  |proj g|=       2.6433
At iterate     1  f =      -452.73  |proj g|=        8.3835
At iterate     2  f =      -452.76  |proj g|=        7.6952
At iterate     3  f =      -452.77  |proj g|=        6.9224
At iterate     4  f =      -452.77  |proj g|=        6.9552
At iterate     5  f =      -452.77  |proj g|=         7.069
At iterate     6  f =      -452.78  |proj g|=        7.1795
At iterate     7  f =      -452.78  |proj g|=        7.2174
At iterate     8  f =      -452.78  |proj g|=        7.1751
At iterate     9  f =      -452.78  |proj g|=        7.1531
At iterate    10  f =      -452.78  |proj g|=        7.1476
At iterate    11  f =      -452.78  |proj g|=        7.1372
At iterate    12  f =      -452.78  |proj g|=        7.1152
At iterate    13  f =      -452.78  |proj g|=         7.084
At iterate    14  f =      -452.78  |proj g|=        7.0308
At iterate    15  f =      -452.78  |proj g|=        6.9492
At iterate    16  f =      -452.78  |proj g|=        6.8302
At iterate    17  f =      -452.78  |proj g|=        6.6483
At iterate    18  f =      -452.79  |proj g|=        6.4206
At iterate    19  f =      -452.79  |proj g|=        6.2579
At iterate    20  f =      -452.81  |proj g|=        5.9813
At iterate    21  f =      -453.04  |proj g|=        5.3583
At iterate    22  f =      -481.62  |proj g|=        12.852
At iterate    23  f =      -482.91  |proj g|=        12.615
At iterate    24  f =      -501.78  |proj g|=        10.586
At iterate    25  f =      -523.28  |proj g|=        6.7286
At iterate    26  f =      -528.46  |proj g|=        5.9738
At iterate    27  f =      -548.81  |proj g|=         3.969
At iterate    28  f =       -551.9  |proj g|=        3.6676
At iterate    29  f =      -552.57  |proj g|=        4.1674
At iterate    30  f =      -553.88  |proj g|=        4.1043
At iterate    31  f =      -554.11  |proj g|=        3.9986
At iterate    32  f =      -554.12  |proj g|=        3.9397
At iterate    33  f =      -554.13  |proj g|=        3.9567
At iterate    34  f =      -554.13  |proj g|=        3.9555
At iterate    35  f =      -554.13  |proj g|=        3.9555

iterations 35
function evaluations 47
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 3.95546
final function value -554.127

F = -554.127
final  value -554.126634 
converged
 
INFO  [07:27:13.119] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:27:13.206] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:27:13.213] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:27:17.625] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:27:22.992] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:27:27.768] [mlr3]  Finished benchmark 
INFO  [07:27:27.910] [bbotk] Result of batch 122: 
INFO  [07:27:27.912] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:27:27.912] [bbotk]              3.482589                 7.161135                       0.4761261 
INFO  [07:27:27.912] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:27:27.912] [bbotk]                     1976        0.801 -0.9524073         <NA>   0.9744941 
INFO  [07:27:27.912] [bbotk]                                 uhash 
INFO  [07:27:27.912] [bbotk]  ddd856bb-1d05-4839-8fec-9b2b5cded8e9 
DEBUG [07:27:29.424] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.436457e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.436457e-05 0.003107765 
  - best initial criterion value(s) :  492.6851 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -492.69  |proj g|=       5.5249
At iterate     1  f =      -517.62  |proj g|=        11.342
At iterate     2  f =         -526  |proj g|=        10.107
At iterate     3  f =      -541.45  |proj g|=        6.7796
At iterate     4  f =      -542.98  |proj g|=        5.4283
At iterate     5  f =      -543.16  |proj g|=        5.1069
At iterate     6  f =      -543.78  |proj g|=        4.3582
At iterate     7  f =      -544.47  |proj g|=        3.6995
At iterate     8  f =      -544.77  |proj g|=         3.955
At iterate     9  f =      -544.82  |proj g|=        3.6903
At iterate    10  f =      -544.82  |proj g|=        3.6198
At iterate    11  f =      -544.82  |proj g|=        3.6152
At iterate    12  f =      -544.83  |proj g|=        3.5935
At iterate    13  f =      -544.84  |proj g|=        3.5766
At iterate    14  f =      -544.87  |proj g|=        3.4469
At iterate    15  f =      -544.87  |proj g|=        3.5954
At iterate    16  f =      -544.95  |proj g|=        3.3827
At iterate    17  f =      -545.12  |proj g|=        3.0776
At iterate    18  f =      -545.52  |proj g|=        2.7029
At iterate    19  f =      -546.55  |proj g|=        2.7309
At iterate    20  f =      -549.04  |proj g|=        2.8471
At iterate    21  f =      -549.75  |proj g|=        2.7755
At iterate    22  f =      -554.01  |proj g|=        3.1142
At iterate    23  f =      -555.19  |proj g|=        3.3779
At iterate    24  f =      -555.55  |proj g|=        3.2822
At iterate    25  f =      -555.59  |proj g|=        3.2508
At iterate    26  f =       -555.6  |proj g|=         3.239
At iterate    27  f =       -555.6  |proj g|=        3.2455
At iterate    28  f =       -555.6  |proj g|=        3.2394
At iterate    29  f =       -555.6  |proj g|=        3.2399
At iterate    30  f =       -555.6  |proj g|=        3.2399
At iterate    31  f =       -555.6  |proj g|=        3.2398
At iterate    32  f =       -555.6  |proj g|=        3.2385
At iterate    33  f =       -555.6  |proj g|=        3.2384
At iterate    34  f =       -555.6  |proj g|=         3.238
At iterate    35  f =       -555.6  |proj g|=        3.2427
At iterate    36  f =      -555.61  |proj g|=        3.2413
At iterate    37  f =      -555.61  |proj g|=        3.2274
At iterate    38  f =      -555.64  |proj g|=         3.222
At iterate    39  f =      -556.08  |proj g|=        3.1627
At iterate    40  f =      -559.17  |proj g|=        2.7411
At iterate    41  f =      -559.18  |proj g|=        2.7225
At iterate    42  f =      -565.05  |proj g|=       0.84843
At iterate    43  f =      -565.96  |proj g|=       0.85145
At iterate    44  f =      -567.83  |proj g|=       0.82824
At iterate    45  f =      -568.72  |proj g|=       0.80172
At iterate    46  f =      -568.82  |proj g|=       0.20379
At iterate    47  f =      -568.83  |proj g|=       0.79079
At iterate    48  f =      -568.83  |proj g|=       0.39268
At iterate    49  f =      -568.83  |proj g|=      0.055665
At iterate    50  f =      -568.83  |proj g|=      0.011462
At iterate    51  f =      -568.83  |proj g|=      0.011463

iterations 51
function evaluations 66
segments explored during Cauchy searches 55
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0114626
final function value -568.832

F = -568.832
final  value -568.831515 
converged
 
INFO  [07:27:29.428] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:27:29.517] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:27:29.524] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:27:35.152] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:27:40.808] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:27:45.757] [mlr3]  Finished benchmark 
INFO  [07:27:45.904] [bbotk] Result of batch 123: 
INFO  [07:27:45.906] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:27:45.906] [bbotk]              3.177685                 9.462254                       0.4206763 
INFO  [07:27:45.906] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:27:45.906] [bbotk]                     2485        0.816 -0.9523547         <NA>   0.9738401 
INFO  [07:27:45.906] [bbotk]                                 uhash 
INFO  [07:27:45.906] [bbotk]  7fea45b5-d31d-47ab-b018-ea2afa1c98e3 
DEBUG [07:27:47.522] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.42197e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.42197e-05 0.003117366 
  - best initial criterion value(s) :  503.3982 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -503.4  |proj g|=       3.4441
At iterate     1  f =      -510.38  |proj g|=        4.6543
At iterate     2  f =       -513.6  |proj g|=        4.6129
At iterate     3  f =      -517.65  |proj g|=        4.2934
At iterate     4  f =      -518.53  |proj g|=        3.8639
At iterate     5  f =      -520.47  |proj g|=        3.8692
At iterate     6  f =      -524.12  |proj g|=        3.0761
At iterate     7  f =      -525.09  |proj g|=        3.3642
At iterate     8  f =      -525.49  |proj g|=        3.2037
At iterate     9  f =      -525.51  |proj g|=        3.1591
At iterate    10  f =      -525.51  |proj g|=        3.1678
At iterate    11  f =      -525.51  |proj g|=        3.1684
At iterate    12  f =      -525.51  |proj g|=        3.1681
At iterate    13  f =      -525.51  |proj g|=        3.1669
At iterate    14  f =      -525.51  |proj g|=        3.1615
At iterate    15  f =      -525.52  |proj g|=        3.1532
At iterate    16  f =      -525.53  |proj g|=        3.1382
At iterate    17  f =      -525.55  |proj g|=        3.1096
At iterate    18  f =      -525.55  |proj g|=        3.1128
At iterate    19  f =      -525.62  |proj g|=        3.0614
At iterate    20  f =      -526.14  |proj g|=        2.9174
At iterate    21  f =      -531.81  |proj g|=        1.9688
At iterate    22  f =      -537.41  |proj g|=         1.762
At iterate    23  f =      -537.83  |proj g|=        1.8273
At iterate    24  f =      -537.84  |proj g|=        1.8868
At iterate    25  f =      -537.89  |proj g|=        1.8957
At iterate    26  f =      -537.89  |proj g|=        1.9007
At iterate    27  f =      -537.89  |proj g|=        1.9015
At iterate    28  f =      -537.89  |proj g|=        1.9027
At iterate    29  f =      -537.89  |proj g|=        1.9056
At iterate    30  f =      -537.89  |proj g|=        1.9103
At iterate    31  f =      -537.89  |proj g|=        1.9191
At iterate    32  f =      -537.89  |proj g|=        1.9293
At iterate    33  f =       -537.9  |proj g|=        1.9499
At iterate    34  f =      -537.92  |proj g|=        1.9672
At iterate    35  f =      -537.98  |proj g|=         1.986
At iterate    36  f =      -538.11  |proj g|=         1.958
At iterate    37  f =      -538.11  |proj g|=        2.0165
At iterate    38  f =      -538.37  |proj g|=        1.8814
At iterate    39  f =      -538.95  |proj g|=        1.5625
At iterate    40  f =      -540.24  |proj g|=       0.90717
At iterate    41  f =      -541.72  |proj g|=       0.30493
At iterate    42  f =      -541.74  |proj g|=       0.23681
At iterate    43  f =      -541.76  |proj g|=        0.2017
At iterate    44  f =      -541.87  |proj g|=      0.069346
At iterate    45  f =      -541.88  |proj g|=       0.04514
At iterate    46  f =      -541.88  |proj g|=      0.045134
At iterate    47  f =      -541.88  |proj g|=      0.045135

iterations 47
function evaluations 61
segments explored during Cauchy searches 49
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0451346
final function value -541.876

F = -541.876
final  value -541.875948 
converged
 
INFO  [07:27:47.526] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:27:47.617] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:27:47.624] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:27:50.322] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:27:52.322] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:27:53.383] [mlr3]  Finished benchmark 
INFO  [07:27:53.481] [bbotk] Result of batch 124: 
INFO  [07:27:53.483] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:27:53.483] [bbotk]              4.656108                 2.409589                       0.3429239 
INFO  [07:27:53.483] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:27:53.483] [bbotk]                      321        0.963 -0.9671827         <NA>   0.9629195 
INFO  [07:27:53.483] [bbotk]                                 uhash 
INFO  [07:27:53.483] [bbotk]  5aace159-13cf-47d6-aa5a-7f2a28ecc221 
DEBUG [07:27:54.769] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.408759e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.408759e-05 0.003067374 
  - best initial criterion value(s) :  488.2667 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -488.27  |proj g|=       2.1857
At iterate     1  f =       -490.7  |proj g|=        2.1728
At iterate     2  f =      -491.27  |proj g|=        2.1265
At iterate     3  f =      -491.56  |proj g|=        2.0858
At iterate     4  f =      -491.58  |proj g|=        2.0655
At iterate     5  f =      -491.58  |proj g|=        2.0717
At iterate     6  f =      -491.58  |proj g|=        2.0716
At iterate     7  f =      -491.58  |proj g|=        2.0715
At iterate     8  f =      -491.58  |proj g|=        2.0713
At iterate     9  f =      -491.58  |proj g|=         2.071
At iterate    10  f =      -491.58  |proj g|=        2.0705
At iterate    11  f =      -491.58  |proj g|=        2.0697
At iterate    12  f =      -491.58  |proj g|=        2.0685
At iterate    13  f =      -491.59  |proj g|=        2.0662
At iterate    14  f =      -491.59  |proj g|=        2.0626
At iterate    15  f =       -491.6  |proj g|=        2.0567
At iterate    16  f =      -491.61  |proj g|=        2.0467
At iterate    17  f =      -491.63  |proj g|=        2.0207
At iterate    18  f =      -491.69  |proj g|=        2.0132
At iterate    19  f =      -492.04  |proj g|=        1.9572
At iterate    20  f =      -492.68  |proj g|=         1.862
At iterate    21  f =      -494.38  |proj g|=        1.6396
At iterate    22  f =      -497.37  |proj g|=        1.3023
At iterate    23  f =      -498.35  |proj g|=        1.0496
At iterate    24  f =      -501.48  |proj g|=        0.8308
At iterate    25  f =      -502.29  |proj g|=       0.83035
At iterate    26  f =      -502.34  |proj g|=        0.8244
At iterate    27  f =      -502.34  |proj g|=       0.34628
At iterate    28  f =      -502.34  |proj g|=       0.22644
At iterate    29  f =      -502.34  |proj g|=       0.22637

iterations 29
function evaluations 35
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.22637
final function value -502.343

F = -502.343
final  value -502.343062 
converged
 
INFO  [07:27:54.773] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:27:54.860] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:27:54.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:28:00.929] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:28:08.007] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:28:14.135] [mlr3]  Finished benchmark 
INFO  [07:28:14.252] [bbotk] Result of batch 125: 
INFO  [07:28:14.254] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:28:14.254] [bbotk]                4.4944                 7.743315                       0.1156186 
INFO  [07:28:14.254] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:28:14.254] [bbotk]                     2884        0.813 -0.9770296         <NA>   0.9723559 
INFO  [07:28:14.254] [bbotk]                                 uhash 
INFO  [07:28:14.254] [bbotk]  33db4b21-824d-402d-b7e7-fffed6f1dc6e 
DEBUG [07:28:15.562] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.393888e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.393888e-05 0.003074674 
  - best initial criterion value(s) :  535.101 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -535.1  |proj g|=       1.5617
At iterate     1  f =      -536.38  |proj g|=        2.1348
At iterate     2  f =      -536.41  |proj g|=        2.0814
At iterate     3  f =      -536.42  |proj g|=        2.0507
At iterate     4  f =      -536.43  |proj g|=        2.0316
At iterate     5  f =      -536.48  |proj g|=        1.9644
At iterate     6  f =      -536.55  |proj g|=        1.8804
At iterate     7  f =      -536.67  |proj g|=         1.784
At iterate     8  f =      -536.74  |proj g|=        1.7759
At iterate     9  f =      -536.75  |proj g|=         1.817
At iterate    10  f =      -536.75  |proj g|=        1.8286
At iterate    11  f =      -536.75  |proj g|=        1.8292
At iterate    12  f =      -536.75  |proj g|=        1.8295
At iterate    13  f =      -536.75  |proj g|=        1.8304
At iterate    14  f =      -536.75  |proj g|=        1.8315
At iterate    15  f =      -536.75  |proj g|=        1.8336
At iterate    16  f =      -536.75  |proj g|=        1.8367
At iterate    17  f =      -536.75  |proj g|=        1.8419
At iterate    18  f =      -536.75  |proj g|=        1.8495
At iterate    19  f =      -536.76  |proj g|=        1.8585
At iterate    20  f =      -536.76  |proj g|=        1.8766
At iterate    21  f =      -536.77  |proj g|=        1.8892
At iterate    22  f =       -536.8  |proj g|=        1.9287
At iterate    23  f =      -536.86  |proj g|=        1.9379
At iterate    24  f =      -536.97  |proj g|=        2.0662
At iterate    25  f =      -537.18  |proj g|=        2.0056
At iterate    26  f =      -538.66  |proj g|=        1.4635
At iterate    27  f =      -540.04  |proj g|=        1.0039
At iterate    28  f =       -540.5  |proj g|=          1.06
At iterate    29  f =      -540.82  |proj g|=        1.1228
At iterate    30  f =      -540.87  |proj g|=        1.1637
At iterate    31  f =      -540.87  |proj g|=          1.14
At iterate    32  f =      -540.88  |proj g|=        1.1328
At iterate    33  f =      -540.88  |proj g|=        1.1328
At iterate    34  f =      -540.88  |proj g|=        1.1328

iterations 34
function evaluations 38
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.13275
final function value -540.875

F = -540.875
final  value -540.875059 
converged
 
INFO  [07:28:15.566] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:28:15.653] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:28:15.659] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:28:25.511] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:28:33.970] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:28:42.436] [mlr3]  Finished benchmark 
INFO  [07:28:42.534] [bbotk] Result of batch 126: 
INFO  [07:28:42.536] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:28:42.536] [bbotk]              8.130864                 7.499709                      0.06205979 
INFO  [07:28:42.536] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:28:42.536] [bbotk]                     4040        0.812 -0.9698153         <NA>   0.9730205 
INFO  [07:28:42.536] [bbotk]                                 uhash 
INFO  [07:28:42.536] [bbotk]  20db9cce-e35e-41a4-b3ae-67c415acc5c3 
DEBUG [07:28:44.012] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.3795e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.3795e-05 0.003065615 
  - best initial criterion value(s) :  499.5554 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -499.56  |proj g|=       10.633
At iterate     1  f =      -521.68  |proj g|=        4.7768
At iterate     2  f =      -545.13  |proj g|=        4.6651
At iterate     3  f =      -549.33  |proj g|=         4.475
At iterate     4  f =      -554.39  |proj g|=        4.1144
At iterate     5  f =      -556.78  |proj g|=        3.9339
At iterate     6  f =      -558.37  |proj g|=        3.8902
At iterate     7  f =      -558.95  |proj g|=         4.971
At iterate     8  f =      -559.75  |proj g|=        4.5938
At iterate     9  f =      -560.04  |proj g|=        4.4691
At iterate    10  f =      -560.12  |proj g|=        4.4774
At iterate    11  f =      -560.13  |proj g|=        4.5105
At iterate    12  f =      -560.13  |proj g|=        4.5247
At iterate    13  f =      -560.13  |proj g|=        4.5248
At iterate    14  f =      -560.14  |proj g|=        4.5377
At iterate    15  f =      -560.14  |proj g|=        4.5444
At iterate    16  f =      -560.15  |proj g|=         4.549
At iterate    17  f =      -560.17  |proj g|=        4.5406
At iterate    18  f =      -560.23  |proj g|=        4.5056
At iterate    19  f =      -560.35  |proj g|=        4.3292
At iterate    20  f =      -560.37  |proj g|=        4.4948
At iterate    21  f =      -560.62  |proj g|=         4.208
At iterate    22  f =      -562.83  |proj g|=        3.7794
At iterate    23  f =      -574.43  |proj g|=        3.6593
At iterate    24  f =      -582.49  |proj g|=        3.4004
At iterate    25  f =      -588.34  |proj g|=        3.0456
At iterate    26  f =      -588.59  |proj g|=        2.9612
At iterate    27  f =      -588.64  |proj g|=        3.0299
At iterate    28  f =      -588.64  |proj g|=         3.034
At iterate    29  f =      -588.64  |proj g|=        3.0348
At iterate    30  f =      -588.64  |proj g|=        3.0353
At iterate    31  f =      -588.64  |proj g|=        3.0357
At iterate    32  f =      -588.64  |proj g|=        3.0365
At iterate    33  f =      -588.64  |proj g|=        3.0367
At iterate    34  f =      -588.65  |proj g|=        3.0482
At iterate    35  f =      -588.65  |proj g|=        3.0422
At iterate    36  f =      -588.65  |proj g|=        3.0307
At iterate    37  f =      -588.66  |proj g|=        3.0141
At iterate    38  f =       -588.7  |proj g|=        2.9833
At iterate    39  f =      -588.79  |proj g|=        2.9325
At iterate    40  f =      -589.04  |proj g|=        2.8369
At iterate    41  f =      -589.79  |proj g|=        2.5635
At iterate    42  f =      -591.85  |proj g|=        1.3484
At iterate    43  f =      -595.04  |proj g|=       0.82773
At iterate    44  f =      -596.58  |proj g|=       0.80206
At iterate    45  f =      -597.11  |proj g|=        0.2152
At iterate    46  f =       -597.2  |proj g|=       0.77156
At iterate    47  f =      -597.21  |proj g|=       0.44577
At iterate    48  f =      -597.21  |proj g|=     0.0032412
At iterate    49  f =      -597.21  |proj g|=     0.0098662

iterations 49
function evaluations 57
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00986621
final function value -597.207

F = -597.207
final  value -597.207245 
converged
 
INFO  [07:28:44.016] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:28:44.120] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:28:44.127] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:28:53.904] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:29:03.456] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:29:13.835] [mlr3]  Finished benchmark 
INFO  [07:29:14.001] [bbotk] Result of batch 127: 
INFO  [07:29:14.003] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:29:14.003] [bbotk]              7.403329                 5.855512                       0.3303794 
INFO  [07:29:14.003] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:29:14.003] [bbotk]                     4386         0.82 -0.9407089         <NA>   0.9776328 
INFO  [07:29:14.003] [bbotk]                                 uhash 
INFO  [07:29:14.003] [bbotk]  2950c649-6e45-42b7-a0d8-ba4c84f1ec43 
DEBUG [07:29:15.517] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.368877e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.368877e-05 0.003042583 
  - best initial criterion value(s) :  555.4069 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -555.41  |proj g|=       2.2602
At iterate     1  f =      -561.53  |proj g|=        2.8941
At iterate     2  f =       -564.9  |proj g|=        2.8603
At iterate     3  f =      -566.69  |proj g|=        2.7878
At iterate     4  f =      -566.87  |proj g|=        2.7144
At iterate     5  f =      -566.93  |proj g|=        2.7401
At iterate     6  f =      -566.93  |proj g|=        2.7367
At iterate     7  f =      -566.98  |proj g|=        2.7014
At iterate     8  f =      -567.01  |proj g|=        2.6772
At iterate     9  f =      -567.04  |proj g|=        2.6612
At iterate    10  f =      -567.04  |proj g|=        2.6642
At iterate    11  f =      -567.04  |proj g|=        2.6652
At iterate    12  f =      -567.04  |proj g|=        2.6658
At iterate    13  f =      -567.04  |proj g|=        2.6665
At iterate    14  f =      -567.04  |proj g|=        2.6685
At iterate    15  f =      -567.04  |proj g|=        2.6711
At iterate    16  f =      -567.04  |proj g|=        2.6757
At iterate    17  f =      -567.05  |proj g|=        2.6829
At iterate    18  f =      -567.06  |proj g|=        2.6942
At iterate    19  f =      -567.09  |proj g|=         2.708
At iterate    20  f =      -567.14  |proj g|=        2.7234
At iterate    21  f =      -567.27  |proj g|=        2.7278
At iterate    22  f =      -567.42  |proj g|=        2.7434
At iterate    23  f =      -567.73  |proj g|=        2.6994
At iterate    24  f =      -569.46  |proj g|=        2.3636
At iterate    25  f =      -571.21  |proj g|=        1.5012
At iterate    26  f =      -573.29  |proj g|=       0.94796
At iterate    27  f =      -574.18  |proj g|=       0.70125
At iterate    28  f =      -574.35  |proj g|=       0.91348
At iterate    29  f =      -574.37  |proj g|=       0.84799
At iterate    30  f =      -574.37  |proj g|=       0.85777
At iterate    31  f =      -574.37  |proj g|=       0.85684
At iterate    32  f =      -574.37  |proj g|=       0.85669

iterations 32
function evaluations 37
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.856687
final function value -574.367

F = -574.367
final  value -574.366871 
converged
 
INFO  [07:29:15.521] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:29:15.607] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:29:15.614] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:29:18.582] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:29:23.071] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:29:25.588] [mlr3]  Finished benchmark 
INFO  [07:29:25.687] [bbotk] Result of batch 128: 
INFO  [07:29:25.689] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:29:25.689] [bbotk]              6.136816                 2.385351                      0.08178742 
INFO  [07:29:25.689] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:29:25.689] [bbotk]                     1194        0.801 -0.9618188         <NA>   0.9641545 
INFO  [07:29:25.689] [bbotk]                                 uhash 
INFO  [07:29:25.689] [bbotk]  2692965a-a0a8-434d-aa21-e9140affa348 
DEBUG [07:29:26.982] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.3555e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.3555e-05 0.003011663 
  - best initial criterion value(s) :  539.109 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -539.11  |proj g|=       2.4488
At iterate     1  f =      -565.64  |proj g|=       0.90533
At iterate     2  f =      -589.87  |proj g|=         3.284
At iterate     3  f =      -590.24  |proj g|=        3.2117
At iterate     4  f =      -590.95  |proj g|=        2.9024
At iterate     5  f =      -590.97  |proj g|=        2.8591
At iterate     6  f =      -590.98  |proj g|=        2.8579
At iterate     7  f =      -590.99  |proj g|=        2.9417
At iterate     8  f =      -590.99  |proj g|=        2.9402
At iterate     9  f =      -591.32  |proj g|=        2.9276
At iterate    10  f =      -593.42  |proj g|=        2.5254
At iterate    11  f =      -594.63  |proj g|=        2.2302
At iterate    12  f =       -595.1  |proj g|=        2.2303
At iterate    13  f =      -595.31  |proj g|=        1.9398
At iterate    14  f =      -595.49  |proj g|=        1.9404
At iterate    15  f =      -595.52  |proj g|=        1.9926
At iterate    16  f =      -595.52  |proj g|=        1.9728
At iterate    17  f =      -595.52  |proj g|=        1.9755
At iterate    18  f =      -595.52  |proj g|=        1.9752

iterations 18
function evaluations 28
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.97522
final function value -595.518

F = -595.518
final  value -595.517767 
converged
 
INFO  [07:29:26.986] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:29:27.102] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:29:27.109] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:29:29.919] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:29:33.091] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:29:36.218] [mlr3]  Finished benchmark 
INFO  [07:29:36.317] [bbotk] Result of batch 129: 
INFO  [07:29:36.319] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:29:36.319] [bbotk]              3.583337                 5.237205                       0.2706909 
INFO  [07:29:36.319] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:29:36.319] [bbotk]                     1203        0.848 -0.9561551         <NA>   0.9699316 
INFO  [07:29:36.319] [bbotk]                                 uhash 
INFO  [07:29:36.319] [bbotk]  ad5ed7f4-60ae-4cf0-98c2-d5f6fa2271c2 
DEBUG [07:29:37.705] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.340719e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.340719e-05 0.002976407 
  - best initial criterion value(s) :  549.8367 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -549.84  |proj g|=       11.065
At iterate     1  f =      -568.17  |proj g|=        3.0384
At iterate     2  f =      -570.24  |proj g|=        6.0155
At iterate     3  f =      -570.88  |proj g|=        5.1407
At iterate     4  f =      -570.95  |proj g|=        4.7818
At iterate     5  f =      -570.95  |proj g|=        4.8341
At iterate     6  f =      -570.97  |proj g|=        4.9684
At iterate     7  f =      -571.48  |proj g|=         4.089
At iterate     8  f =      -575.94  |proj g|=        3.3239
At iterate     9  f =      -590.03  |proj g|=        3.2699
At iterate    10  f =      -597.55  |proj g|=        3.3565
At iterate    11  f =       -602.2  |proj g|=        3.2544
At iterate    12  f =      -603.33  |proj g|=         3.146
At iterate    13  f =      -603.41  |proj g|=         3.104
At iterate    14  f =      -603.41  |proj g|=        3.0971
At iterate    15  f =      -603.41  |proj g|=        3.0992
At iterate    16  f =      -603.41  |proj g|=        3.0991
At iterate    17  f =      -603.41  |proj g|=        3.0984
At iterate    18  f =      -603.41  |proj g|=        3.0975
At iterate    19  f =      -603.41  |proj g|=        3.0958
At iterate    20  f =      -603.41  |proj g|=        3.0932
At iterate    21  f =      -603.41  |proj g|=        3.0892
At iterate    22  f =      -603.41  |proj g|=        3.0835
At iterate    23  f =      -603.42  |proj g|=        3.0749
At iterate    24  f =      -603.44  |proj g|=        3.0626
At iterate    25  f =      -603.48  |proj g|=        3.0226
At iterate    26  f =      -603.58  |proj g|=        2.9953
At iterate    27  f =      -603.66  |proj g|=        2.9058
At iterate    28  f =      -603.83  |proj g|=        2.9631
At iterate    29  f =      -604.86  |proj g|=        2.6427
At iterate    30  f =      -608.43  |proj g|=       0.82787
At iterate    31  f =      -610.38  |proj g|=       0.82781
At iterate    32  f =      -611.73  |proj g|=       0.80368
At iterate    33  f =      -612.07  |proj g|=       0.78995
At iterate    34  f =      -612.18  |proj g|=        0.7806
At iterate    35  f =       -612.2  |proj g|=       0.77738
At iterate    36  f =       -612.2  |proj g|=      0.030987
At iterate    37  f =       -612.2  |proj g|=      0.002999

iterations 37
function evaluations 45
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00299897
final function value -612.203

F = -612.203
final  value -612.203092 
converged
 
INFO  [07:29:37.709] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:29:37.837] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:29:37.844] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:29:41.619] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:29:45.685] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:29:49.683] [mlr3]  Finished benchmark 
INFO  [07:29:49.825] [bbotk] Result of batch 130: 
INFO  [07:29:49.827] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:29:49.827] [bbotk]              4.858438                 9.571842                       0.3823265 
INFO  [07:29:49.827] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:29:49.827] [bbotk]                     1936        0.814 -0.9451625         <NA>   0.9760077 
INFO  [07:29:49.827] [bbotk]                                 uhash 
INFO  [07:29:49.827] [bbotk]  df6dc2c2-69d0-4d4f-a077-a7b7edac2cca 
DEBUG [07:29:51.458] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.328972e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.328972e-05 0.002983591 
  - best initial criterion value(s) :  521.5026 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -521.5  |proj g|=       2.0762
At iterate     1  f =      -527.89  |proj g|=        2.4638
At iterate     2  f =      -528.54  |proj g|=        2.4355
At iterate     3  f =      -528.86  |proj g|=         2.384
At iterate     4  f =      -528.93  |proj g|=        2.4027
At iterate     5  f =         -529  |proj g|=        2.4205
At iterate     6  f =      -529.43  |proj g|=        2.5227
At iterate     7  f =      -530.17  |proj g|=        2.7057
At iterate     8  f =      -531.44  |proj g|=        3.0529
At iterate     9  f =      -532.87  |proj g|=        3.5374
At iterate    10  f =      -533.94  |proj g|=        3.5076
At iterate    11  f =      -535.03  |proj g|=        4.2485
At iterate    12  f =      -535.41  |proj g|=        4.8689
At iterate    13  f =      -540.96  |proj g|=        5.5523
At iterate    14  f =      -569.45  |proj g|=        4.7402
At iterate    15  f =      -595.86  |proj g|=        2.2432
At iterate    16  f =      -601.89  |proj g|=        2.0656
At iterate    17  f =      -604.47  |proj g|=        1.2544
At iterate    18  f =      -605.01  |proj g|=         1.403
At iterate    19  f =      -605.85  |proj g|=        1.5555
At iterate    20  f =      -605.93  |proj g|=        1.4747
At iterate    21  f =      -605.94  |proj g|=          1.42
At iterate    22  f =      -605.94  |proj g|=        1.4191
At iterate    23  f =      -605.94  |proj g|=        1.4189
At iterate    24  f =      -605.94  |proj g|=        1.4183
At iterate    25  f =      -605.94  |proj g|=        1.4173
At iterate    26  f =      -605.94  |proj g|=        1.4156
At iterate    27  f =      -605.94  |proj g|=        1.4129
At iterate    28  f =      -605.94  |proj g|=        1.4085
At iterate    29  f =      -605.94  |proj g|=        1.4012
At iterate    30  f =      -605.95  |proj g|=        1.3892
At iterate    31  f =      -605.95  |proj g|=        1.3691
At iterate    32  f =      -605.97  |proj g|=        1.3345
At iterate    33  f =      -606.01  |proj g|=         1.274
At iterate    34  f =       -606.1  |proj g|=        1.1669
At iterate    35  f =      -606.34  |proj g|=       0.98211
At iterate    36  f =      -606.88  |proj g|=       0.69331
At iterate    37  f =      -607.92  |proj g|=       0.22804
At iterate    38  f =      -608.45  |proj g|=       0.22027
At iterate    39  f =      -608.85  |proj g|=       0.79013
At iterate    40  f =      -608.85  |proj g|=      0.072035
At iterate    41  f =      -608.85  |proj g|=     0.0052623

iterations 41
function evaluations 47
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 3
norm of the final projected gradient 0.00526231
final function value -608.849

F = -608.849
final  value -608.848788 
converged
 
INFO  [07:29:51.462] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:29:51.551] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:29:51.558] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:29:53.660] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:29:55.910] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:29:57.611] [mlr3]  Finished benchmark 
INFO  [07:29:57.743] [bbotk] Result of batch 131: 
INFO  [07:29:57.746] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:29:57.746] [bbotk]              4.205219                 3.663271                       0.3907521 
INFO  [07:29:57.746] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:29:57.746] [bbotk]                      771        1.014 -0.9369081         <NA>   0.9712879 
INFO  [07:29:57.746] [bbotk]                                 uhash 
INFO  [07:29:57.746] [bbotk]  8c6211b0-13a6-41ca-8d06-7ddc21a350b2 
DEBUG [07:29:59.253] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.314765e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.314765e-05 0.002930263 
  - best initial criterion value(s) :  526.9772 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -526.98  |proj g|=       7.9197
At iterate     1  f =      -550.27  |proj g|=        6.0375
At iterate     2  f =      -554.89  |proj g|=        7.2922
At iterate     3  f =      -555.91  |proj g|=        7.1236
At iterate     4  f =      -557.38  |proj g|=         6.566
At iterate     5  f =       -557.6  |proj g|=        6.3034
At iterate     6  f =      -557.66  |proj g|=        6.1717
At iterate     7  f =      -557.71  |proj g|=        6.3029
At iterate     8  f =      -557.72  |proj g|=        6.2007
At iterate     9  f =      -557.72  |proj g|=        6.1882
At iterate    10  f =      -557.72  |proj g|=        6.1752
At iterate    11  f =      -557.73  |proj g|=        6.1535
At iterate    12  f =      -557.74  |proj g|=        6.1206
At iterate    13  f =      -557.77  |proj g|=        5.9763
At iterate    14  f =       -557.8  |proj g|=        5.9218
At iterate    15  f =      -557.88  |proj g|=        5.8823
At iterate    16  f =      -558.33  |proj g|=        5.6882
At iterate    17  f =         -559  |proj g|=        5.3936
At iterate    18  f =      -564.11  |proj g|=        3.8966
At iterate    19  f =      -572.57  |proj g|=        2.5717
At iterate    20  f =       -593.1  |proj g|=       0.67057
At iterate    21  f =      -594.68  |proj g|=       0.80528
At iterate    22  f =      -594.93  |proj g|=       0.22433
At iterate    23  f =      -594.98  |proj g|=       0.21469
At iterate    24  f =      -594.99  |proj g|=       0.14881
At iterate    25  f =      -594.99  |proj g|=      0.098937
At iterate    26  f =      -594.99  |proj g|=      0.098686

iterations 26
function evaluations 31
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0986858
final function value -594.986

F = -594.986
final  value -594.986419 
converged
 
INFO  [07:29:59.259] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:29:59.350] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:29:59.357] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:30:05.189] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:30:11.660] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:30:17.669] [mlr3]  Finished benchmark 
INFO  [07:30:17.815] [bbotk] Result of batch 132: 
INFO  [07:30:17.817] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:30:17.817] [bbotk]              8.905257                 3.980334                       0.4218809 
INFO  [07:30:17.817] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:30:17.817] [bbotk]                     2973        1.005 -0.9595225         <NA>   0.9775204 
INFO  [07:30:17.817] [bbotk]                                 uhash 
INFO  [07:30:17.817] [bbotk]  0489989a-ebf3-4472-9a6a-3a0bbb74987a 
DEBUG [07:30:19.222] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.304672e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.304672e-05 0.002923033 
  - best initial criterion value(s) :  520.2096 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -520.21  |proj g|=       14.078
At iterate     1  f =       -537.8  |proj g|=        9.0096
At iterate     2  f =      -566.27  |proj g|=        6.2296
At iterate     3  f =      -575.26  |proj g|=        3.4336
At iterate     4  f =      -576.63  |proj g|=        2.5957
At iterate     5  f =      -577.17  |proj g|=        2.0367
At iterate     6  f =      -577.19  |proj g|=        1.9069
At iterate     7  f =      -577.19  |proj g|=        1.9255
At iterate     8  f =      -577.19  |proj g|=        1.9252
At iterate     9  f =      -577.19  |proj g|=        1.9231
At iterate    10  f =      -577.19  |proj g|=        1.9221
At iterate    11  f =      -577.19  |proj g|=        1.9232
At iterate    12  f =      -577.19  |proj g|=        1.9318
At iterate    13  f =       -577.2  |proj g|=        1.9554
At iterate    14  f =       -577.2  |proj g|=        2.0013
At iterate    15  f =       -577.2  |proj g|=        2.0243
At iterate    16  f =      -577.21  |proj g|=        2.0656
At iterate    17  f =      -577.22  |proj g|=        2.1064
At iterate    18  f =      -577.25  |proj g|=        2.1786
At iterate    19  f =      -577.32  |proj g|=        2.2772
At iterate    20  f =       -577.5  |proj g|=        2.4207
At iterate    21  f =      -577.92  |proj g|=         2.584
At iterate    22  f =      -578.76  |proj g|=        2.6766
At iterate    23  f =      -579.66  |proj g|=        2.3682
At iterate    24  f =      -582.02  |proj g|=        1.8824
At iterate    25  f =      -583.27  |proj g|=        1.3111
At iterate    26  f =      -584.33  |proj g|=       0.70578
At iterate    27  f =      -585.27  |proj g|=        0.2265
At iterate    28  f =      -585.55  |proj g|=       0.20593
At iterate    29  f =      -585.57  |proj g|=       0.20894
At iterate    30  f =      -585.57  |proj g|=       0.17935
At iterate    31  f =      -585.57  |proj g|=      0.060652
At iterate    32  f =      -585.57  |proj g|=      0.060619

iterations 32
function evaluations 39
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.0606193
final function value -585.569

F = -585.569
final  value -585.568626 
converged
 
INFO  [07:30:19.226] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:30:19.318] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:30:19.325] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:30:23.000] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:30:25.819] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:30:28.551] [mlr3]  Finished benchmark 
INFO  [07:30:29.047] [bbotk] Result of batch 133: 
INFO  [07:30:29.049] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:30:29.049] [bbotk]              7.254321                 2.052663                      0.02562556 
INFO  [07:30:29.049] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:30:29.049] [bbotk]                     1038        0.844 -0.9651103         <NA>   0.9461991 
INFO  [07:30:29.049] [bbotk]                                 uhash 
INFO  [07:30:29.049] [bbotk]  1e81f9b0-cd39-4fa4-a847-fffcfacbf6b9 
DEBUG [07:30:30.420] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.323077e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.323077e-05 0.002934243 
  - best initial criterion value(s) :  575.6667 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -575.67  |proj g|=       3.6177
At iterate     1  f =      -594.33  |proj g|=        1.8969
At iterate     2  f =      -604.21  |proj g|=        2.4729
At iterate     3  f =      -604.84  |proj g|=        2.4937
At iterate     4  f =      -605.31  |proj g|=        2.6165
At iterate     5  f =      -605.36  |proj g|=        2.6813
At iterate     6  f =      -605.37  |proj g|=        2.7279
At iterate     7  f =      -605.37  |proj g|=        2.7663
At iterate     8  f =      -605.37  |proj g|=        2.7742
At iterate     9  f =      -605.37  |proj g|=         2.775
At iterate    10  f =      -605.37  |proj g|=        2.7759
At iterate    11  f =      -605.37  |proj g|=        2.7796
At iterate    12  f =      -605.38  |proj g|=        2.7846
At iterate    13  f =      -605.38  |proj g|=        2.7922
At iterate    14  f =      -605.38  |proj g|=        2.7996
At iterate    15  f =      -605.39  |proj g|=        2.8488
At iterate    16  f =      -605.41  |proj g|=        2.8478
At iterate    17  f =      -605.43  |proj g|=        2.9656
At iterate    18  f =      -605.52  |proj g|=        2.9254
At iterate    19  f =      -606.07  |proj g|=        2.7617
At iterate    20  f =      -609.26  |proj g|=        1.9161
At iterate    21  f =       -615.3  |proj g|=       0.86413
At iterate    22  f =      -617.72  |proj g|=        1.0177
At iterate    23  f =      -618.21  |proj g|=       0.50895
At iterate    24  f =      -618.25  |proj g|=       0.78346
At iterate    25  f =      -618.25  |proj g|=        0.6343
At iterate    26  f =      -618.25  |proj g|=       0.62953
At iterate    27  f =      -618.25  |proj g|=       0.63066
At iterate    28  f =      -618.25  |proj g|=       0.63069

iterations 28
function evaluations 36
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.630686
final function value -618.254

F = -618.254
final  value -618.254253 
converged
 
INFO  [07:30:30.424] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:30:30.509] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:30:30.515] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:30:37.887] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:30:49.495] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:30:56.993] [mlr3]  Finished benchmark 
INFO  [07:30:57.091] [bbotk] Result of batch 134: 
INFO  [07:30:57.093] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:30:57.093] [bbotk]              8.454522                 6.407805                       0.4425737 
INFO  [07:30:57.093] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:30:57.093] [bbotk]                     2746        0.846 -0.9534242         <NA>   0.9772266 
INFO  [07:30:57.093] [bbotk]                                 uhash 
INFO  [07:30:57.093] [bbotk]  f88d5d69-762a-4aa7-8ce4-e3a016adc1ed 
DEBUG [07:30:59.061] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.312855e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.312855e-05 0.002945663 
  - best initial criterion value(s) :  570.1421 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -570.14  |proj g|=        2.384
At iterate     1  f =      -588.22  |proj g|=        4.0274
At iterate     2  f =      -615.18  |proj g|=        2.8977
At iterate     3  f =      -615.25  |proj g|=        2.8676
At iterate     4  f =      -615.33  |proj g|=        2.8613
At iterate     5  f =      -615.43  |proj g|=         2.889
At iterate     6  f =      -615.48  |proj g|=        2.9283
At iterate     7  f =      -615.49  |proj g|=         2.954
At iterate     8  f =      -615.49  |proj g|=        2.9597
At iterate     9  f =      -615.49  |proj g|=        2.9598
At iterate    10  f =      -615.49  |proj g|=          2.96
At iterate    11  f =      -615.49  |proj g|=        2.9613
At iterate    12  f =      -615.49  |proj g|=        2.9627
At iterate    13  f =      -615.49  |proj g|=        2.9651
At iterate    14  f =      -615.49  |proj g|=        2.9688
At iterate    15  f =      -615.49  |proj g|=        2.9748
At iterate    16  f =      -615.49  |proj g|=        2.9836
At iterate    17  f =      -615.51  |proj g|=        2.9962
At iterate    18  f =      -615.54  |proj g|=         3.011
At iterate    19  f =      -615.63  |proj g|=        3.0188
At iterate    20  f =      -615.82  |proj g|=        2.9914
At iterate    21  f =      -616.16  |proj g|=        2.8748
At iterate    22  f =      -616.33  |proj g|=        2.7812
At iterate    23  f =      -616.38  |proj g|=        2.6929
At iterate    24  f =      -616.38  |proj g|=        2.7166
At iterate    25  f =      -616.38  |proj g|=        2.7154
At iterate    26  f =      -616.38  |proj g|=        2.7126
At iterate    27  f =      -616.39  |proj g|=        2.7089
At iterate    28  f =      -616.39  |proj g|=        2.7025
At iterate    29  f =       -616.4  |proj g|=        2.6931
At iterate    30  f =      -616.41  |proj g|=        2.6788
At iterate    31  f =      -616.46  |proj g|=        2.6593
At iterate    32  f =      -616.56  |proj g|=        2.6414
At iterate    33  f =      -616.73  |proj g|=        2.6521
At iterate    34  f =      -616.76  |proj g|=         2.737
At iterate    35  f =      -616.84  |proj g|=        2.7201
At iterate    36  f =      -617.17  |proj g|=        2.6615
At iterate    37  f =      -618.54  |proj g|=        2.1116
At iterate    38  f =       -621.4  |proj g|=        2.6339
At iterate    39  f =      -621.58  |proj g|=        2.7015
At iterate    40  f =      -621.58  |proj g|=        2.6477
At iterate    41  f =      -621.59  |proj g|=        2.6991
At iterate    42  f =      -621.59  |proj g|=        2.6952
At iterate    43  f =      -621.59  |proj g|=        2.6954
At iterate    44  f =      -621.59  |proj g|=        2.6964
At iterate    45  f =      -621.59  |proj g|=        2.6978
At iterate    46  f =      -621.59  |proj g|=        2.7126
At iterate    47  f =      -621.59  |proj g|=          2.71
At iterate    48  f =      -621.59  |proj g|=        2.7024
At iterate    49  f =       -621.6  |proj g|=         2.691
At iterate    50  f =      -621.63  |proj g|=        2.6665
At iterate    51  f =       -621.7  |proj g|=        2.6148
At iterate    52  f =      -621.74  |proj g|=        2.4105
At iterate    53  f =      -621.97  |proj g|=        2.3608
At iterate    54  f =      -622.73  |proj g|=        2.1701
At iterate    55  f =      -624.17  |proj g|=        1.7988
At iterate    56  f =      -627.01  |proj g|=        1.1317
At iterate    57  f =      -630.81  |proj g|=       0.78899
At iterate    58  f =      -631.04  |proj g|=       0.77261
At iterate    59  f =      -631.41  |proj g|=       0.76534
At iterate    60  f =      -631.44  |proj g|=       0.67681
At iterate    61  f =      -631.44  |proj g|=       0.10307
At iterate    62  f =      -631.44  |proj g|=     0.0047463
At iterate    63  f =      -631.44  |proj g|=    0.00080083

iterations 63
function evaluations 75
segments explored during Cauchy searches 66
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000800835
final function value -631.443

F = -631.443
final  value -631.443374 
converged
 
INFO  [07:30:59.065] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:30:59.151] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:30:59.158] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:31:06.617] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:31:13.499] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:31:19.840] [mlr3]  Finished benchmark 
INFO  [07:31:19.942] [bbotk] Result of batch 135: 
INFO  [07:31:19.944] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:31:19.944] [bbotk]              2.276917                 4.252933                       0.1951843 
INFO  [07:31:19.944] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:31:19.944] [bbotk]                     3228        1.114 -0.9422581         <NA>   0.9611921 
INFO  [07:31:19.944] [bbotk]                                 uhash 
INFO  [07:31:19.944] [bbotk]  4919a0ca-2e32-4ab4-8dfc-35fff4ae0d68 
DEBUG [07:31:21.231] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.30271e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.30271e-05 0.002934815 
  - best initial criterion value(s) :  537.3706 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -537.37  |proj g|=       3.6397
At iterate     1  f =      -555.16  |proj g|=        12.718
At iterate     2  f =       -566.4  |proj g|=        12.501
At iterate     3  f =      -584.62  |proj g|=        10.635
At iterate     4  f =      -588.52  |proj g|=        7.4147
At iterate     5  f =      -594.95  |proj g|=        5.5809
At iterate     6  f =      -608.34  |proj g|=         7.333
At iterate     7  f =      -620.79  |proj g|=        3.8238
At iterate     8  f =      -623.64  |proj g|=        2.1424
At iterate     9  f =       -623.9  |proj g|=        1.7189
At iterate    10  f =      -623.99  |proj g|=        1.6508
At iterate    11  f =      -624.12  |proj g|=        1.7862
At iterate    12  f =      -624.46  |proj g|=        2.1256
At iterate    13  f =      -624.59  |proj g|=        2.0248
At iterate    14  f =      -625.16  |proj g|=        1.7181
At iterate    15  f =      -628.66  |proj g|=       0.85153
At iterate    16  f =      -632.69  |proj g|=       0.32633
At iterate    17  f =      -632.74  |proj g|=       0.32617
At iterate    18  f =      -632.74  |proj g|=       0.32609
At iterate    19  f =      -632.74  |proj g|=       0.32609
At iterate    20  f =      -632.74  |proj g|=       0.32609

iterations 20
function evaluations 25
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.326091
final function value -632.741

F = -632.741
final  value -632.741444 
converged
 
INFO  [07:31:21.236] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:31:21.336] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:31:21.343] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:31:28.489] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:31:36.039] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:31:42.416] [mlr3]  Finished benchmark 
INFO  [07:31:42.517] [bbotk] Result of batch 136: 
INFO  [07:31:42.519] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:31:42.519] [bbotk]              4.358394                 6.520888                      0.02701907 
INFO  [07:31:42.519] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:31:42.519] [bbotk]                     3246        0.854 -0.9387419         <NA>   0.9600338 
INFO  [07:31:42.519] [bbotk]                                 uhash 
INFO  [07:31:42.519] [bbotk]  ee1c74ff-c584-4b0b-9316-d368ad2617a1 
DEBUG [07:31:44.332] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.293828e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.293827e-05 0.002923719 
  - best initial criterion value(s) :  532.6264 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -532.63  |proj g|=       3.1798
At iterate     1  f =       -544.2  |proj g|=        9.9476
At iterate     2  f =      -577.73  |proj g|=        6.8636
At iterate     3  f =      -579.24  |proj g|=        6.3665
At iterate     4  f =      -587.24  |proj g|=        5.7362
At iterate     5  f =      -588.33  |proj g|=        6.8483
At iterate     6  f =      -591.92  |proj g|=        6.2386
At iterate     7  f =      -593.15  |proj g|=        5.9395
At iterate     8  f =      -593.55  |proj g|=        5.9398
At iterate     9  f =      -593.83  |proj g|=        6.0776
At iterate    10  f =      -593.96  |proj g|=        6.2607
At iterate    11  f =      -593.99  |proj g|=        6.3921
At iterate    12  f =      -593.99  |proj g|=        6.3998
At iterate    13  f =      -593.99  |proj g|=          6.43
At iterate    14  f =      -594.07  |proj g|=        6.4335
At iterate    15  f =      -594.63  |proj g|=        6.3846
At iterate    16  f =      -596.17  |proj g|=        6.1994
At iterate    17  f =      -607.39  |proj g|=        6.1602
At iterate    18  f =      -612.24  |proj g|=        5.6234
At iterate    19  f =      -612.82  |proj g|=        5.1267
At iterate    20  f =      -612.83  |proj g|=        5.0621
At iterate    21  f =      -612.83  |proj g|=        5.0549
At iterate    22  f =      -612.83  |proj g|=        5.0558
At iterate    23  f =      -612.83  |proj g|=        5.0561
At iterate    24  f =      -612.83  |proj g|=        5.0575
At iterate    25  f =      -612.83  |proj g|=        5.0591
At iterate    26  f =      -612.84  |proj g|=         5.062
At iterate    27  f =      -612.84  |proj g|=        5.0666
At iterate    28  f =      -612.84  |proj g|=        5.0741
At iterate    29  f =      -612.84  |proj g|=        5.0862
At iterate    30  f =      -612.84  |proj g|=        5.1059
At iterate    31  f =      -612.85  |proj g|=        5.1377
At iterate    32  f =      -612.87  |proj g|=        5.1876
At iterate    33  f =      -612.93  |proj g|=        5.2606
At iterate    34  f =      -613.09  |proj g|=        5.3482
At iterate    35  f =      -613.43  |proj g|=        5.3886
At iterate    36  f =      -614.13  |proj g|=        5.0526
At iterate    37  f =      -614.19  |proj g|=        4.9117
At iterate    38  f =      -614.19  |proj g|=        4.8895
At iterate    39  f =      -614.19  |proj g|=        4.8851
At iterate    40  f =      -614.19  |proj g|=        4.8718
At iterate    41  f =       -614.2  |proj g|=        4.8558
At iterate    42  f =       -614.2  |proj g|=        4.8268
At iterate    43  f =      -614.22  |proj g|=        4.7829
At iterate    44  f =      -614.26  |proj g|=        4.7127
At iterate    45  f =      -614.37  |proj g|=        4.6125
At iterate    46  f =       -614.6  |proj g|=        4.5078
At iterate    47  f =      -614.76  |proj g|=          4.65
At iterate    48  f =       -615.2  |proj g|=        4.8291
At iterate    49  f =       -615.2  |proj g|=        4.8093
At iterate    50  f =       -615.2  |proj g|=        4.8077
At iterate    51  f =       -615.2  |proj g|=        4.8031
At iterate    52  f =       -615.2  |proj g|=        4.7967
At iterate    53  f =       -615.2  |proj g|=        4.7856
At iterate    54  f =      -615.21  |proj g|=        4.7679
At iterate    55  f =      -615.21  |proj g|=        4.7388
At iterate    56  f =      -615.23  |proj g|=        4.6909
At iterate    57  f =      -615.28  |proj g|=        4.6132
At iterate    58  f =      -615.42  |proj g|=        4.4976
At iterate    59  f =      -615.49  |proj g|=        4.5679
At iterate    60  f =      -616.19  |proj g|=        4.6261
At iterate    61  f =      -616.53  |proj g|=        4.5498
At iterate    62  f =      -616.55  |proj g|=        4.6461
At iterate    63  f =      -616.59  |proj g|=        4.5911
At iterate    64  f =      -616.59  |proj g|=        4.5834
At iterate    65  f =      -617.52  |proj g|=        4.4517
At iterate    66  f =      -618.05  |proj g|=        4.3561
At iterate    67  f =      -619.41  |proj g|=        4.0441
At iterate    68  f =      -633.91  |proj g|=        1.4626
At iterate    69  f =      -640.31  |proj g|=        0.2909
At iterate    70  f =      -641.17  |proj g|=       0.25377
At iterate    71  f =      -641.24  |proj g|=       0.24447
At iterate    72  f =      -641.26  |proj g|=       0.75561
At iterate    73  f =      -641.26  |proj g|=      0.017111
At iterate    74  f =      -641.26  |proj g|=    0.00068652

iterations 74
function evaluations 91
segments explored during Cauchy searches 77
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000686523
final function value -641.256

F = -641.256
final  value -641.256226 
converged
 
INFO  [07:31:44.336] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:31:44.423] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:31:44.430] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:31:51.857] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:32:00.013] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:32:06.700] [mlr3]  Finished benchmark 
INFO  [07:32:06.816] [bbotk] Result of batch 137: 
INFO  [07:32:06.818] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:32:06.818] [bbotk]              6.271235                 5.360839                      0.04818941 
INFO  [07:32:06.818] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:32:06.818] [bbotk]                     3213        0.846 -0.9410731         <NA>   0.9689074 
INFO  [07:32:06.818] [bbotk]                                 uhash 
INFO  [07:32:06.818] [bbotk]  fc8a422d-205e-4063-b2ff-7e79959b4527 
DEBUG [07:32:08.233] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.280094e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.280094e-05 0.002913259 
  - best initial criterion value(s) :  538.8748 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -538.87  |proj g|=       6.9195
At iterate     1  f =      -575.99  |proj g|=        2.9205
At iterate     2  f =       -598.8  |proj g|=        8.0181
At iterate     3  f =      -598.98  |proj g|=        7.6768
At iterate     4  f =      -599.18  |proj g|=        7.4214
At iterate     5  f =      -599.45  |proj g|=        7.2844
At iterate     6  f =      -599.74  |proj g|=        7.4684
At iterate     7  f =      -599.84  |proj g|=         7.668
At iterate     8  f =      -599.85  |proj g|=        7.7585
At iterate     9  f =      -599.85  |proj g|=        7.7695
At iterate    10  f =      -599.86  |proj g|=        7.7691
At iterate    11  f =      -599.86  |proj g|=        7.7874
At iterate    12  f =      -599.87  |proj g|=        7.7797
At iterate    13  f =       -599.9  |proj g|=        7.7521
At iterate    14  f =      -599.96  |proj g|=        7.8917
At iterate    15  f =      -600.08  |proj g|=        7.7394
At iterate    16  f =      -600.52  |proj g|=        7.6204
At iterate    17  f =      -601.28  |proj g|=        7.0698
At iterate    18  f =      -602.14  |proj g|=        6.5099
At iterate    19  f =      -602.82  |proj g|=         6.093
At iterate    20  f =      -603.43  |proj g|=        5.7208
At iterate    21  f =      -606.03  |proj g|=        4.3252
At iterate    22  f =      -608.67  |proj g|=        3.5194
At iterate    23  f =      -616.71  |proj g|=         2.383
At iterate    24  f =      -629.26  |proj g|=       0.52327
At iterate    25  f =      -634.39  |proj g|=       0.38427
At iterate    26  f =      -640.55  |proj g|=        2.0587
At iterate    27  f =      -641.99  |proj g|=        1.6619
At iterate    28  f =      -643.03  |proj g|=        1.1835
At iterate    29  f =      -643.14  |proj g|=        1.0868
At iterate    30  f =      -643.16  |proj g|=        1.2595
At iterate    31  f =      -643.17  |proj g|=        1.1987
At iterate    32  f =      -643.17  |proj g|=        1.1954
At iterate    33  f =      -643.17  |proj g|=        1.1957

iterations 33
function evaluations 38
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.19566
final function value -643.166

F = -643.166
final  value -643.166247 
converged
 
INFO  [07:32:08.237] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:32:08.326] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:32:08.333] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:32:09.764] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:32:11.340] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:32:12.445] [mlr3]  Finished benchmark 
INFO  [07:32:12.545] [bbotk] Result of batch 138: 
INFO  [07:32:12.546] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:32:12.546] [bbotk]              6.626781                 8.603435                       0.2489467 
INFO  [07:32:12.546] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [07:32:12.546] [bbotk]                      553        0.857 -0.945082         <NA>   0.9680689 
INFO  [07:32:12.546] [bbotk]                                 uhash 
INFO  [07:32:12.546] [bbotk]  bb9bd538-c9fd-4f7a-95cf-b3fab8b3f8a1 
DEBUG [07:32:14.419] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.266586e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.266586e-05 0.002881831 
  - best initial criterion value(s) :  594.4023 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -594.4  |proj g|=       4.1254
At iterate     1  f =      -603.02  |proj g|=        5.3525
At iterate     2  f =      -603.07  |proj g|=        5.3218
At iterate     3  f =      -603.17  |proj g|=        5.2235
At iterate     4  f =      -603.26  |proj g|=        5.1521
At iterate     5  f =       -603.6  |proj g|=        4.8934
At iterate     6  f =       -603.9  |proj g|=        4.7092
At iterate     7  f =      -604.02  |proj g|=        4.6782
At iterate     8  f =      -604.02  |proj g|=        4.6981
At iterate     9  f =      -604.02  |proj g|=        4.7013
At iterate    10  f =      -604.02  |proj g|=        4.7047
At iterate    11  f =      -604.02  |proj g|=        4.7112
At iterate    12  f =      -604.02  |proj g|=         4.721
At iterate    13  f =      -604.03  |proj g|=        4.7376
At iterate    14  f =      -604.04  |proj g|=        4.7666
At iterate    15  f =      -604.07  |proj g|=        4.8141
At iterate    16  f =      -604.12  |proj g|=         4.877
At iterate    17  f =       -604.2  |proj g|=        4.9496
At iterate    18  f =      -604.39  |proj g|=        5.0098
At iterate    19  f =      -604.66  |proj g|=        5.0717
At iterate    20  f =      -604.88  |proj g|=        4.9347
At iterate    21  f =       -605.9  |proj g|=        4.9318
At iterate    22  f =      -608.68  |proj g|=        4.5511
At iterate    23  f =      -616.67  |proj g|=        3.0909
At iterate    24  f =      -620.78  |proj g|=        4.5771
At iterate    25  f =      -621.72  |proj g|=        5.1446
At iterate    26  f =      -621.77  |proj g|=        4.9207
At iterate    27  f =      -621.87  |proj g|=        4.9565
At iterate    28  f =      -621.88  |proj g|=        4.9467
At iterate    29  f =      -621.88  |proj g|=        4.9224
At iterate    30  f =      -621.88  |proj g|=        4.9061
At iterate    31  f =      -621.88  |proj g|=        4.9059
At iterate    32  f =      -621.88  |proj g|=         4.905
At iterate    33  f =      -621.88  |proj g|=        4.9034
At iterate    34  f =      -621.88  |proj g|=        4.9006
At iterate    35  f =      -621.88  |proj g|=        4.8957
At iterate    36  f =      -621.88  |proj g|=        4.8776
At iterate    37  f =      -621.88  |proj g|=        4.8685
At iterate    38  f =      -621.88  |proj g|=        4.8577
At iterate    39  f =      -621.88  |proj g|=        4.8527
At iterate    40  f =      -621.88  |proj g|=         4.849
At iterate    41  f =      -621.88  |proj g|=        4.8465
At iterate    42  f =      -621.88  |proj g|=        4.8457
At iterate    43  f =      -621.88  |proj g|=        4.8407
At iterate    44  f =      -621.88  |proj g|=        4.8263
At iterate    45  f =      -621.88  |proj g|=        4.8153
At iterate    46  f =       -621.9  |proj g|=        4.7821
At iterate    47  f =      -621.95  |proj g|=        4.7616
At iterate    48  f =      -621.99  |proj g|=        4.4326
At iterate    49  f =      -622.22  |proj g|=        4.4336
At iterate    50  f =      -622.37  |proj g|=        4.9382
At iterate    51  f =      -622.95  |proj g|=        5.4186
At iterate    52  f =      -624.84  |proj g|=        4.7305
At iterate    53  f =      -629.01  |proj g|=        2.1942
At iterate    54  f =      -632.15  |proj g|=        1.4015
At iterate    55  f =      -634.98  |proj g|=       0.82065
At iterate    56  f =      -636.13  |proj g|=       0.20599
At iterate    57  f =      -636.33  |proj g|=       0.21256
At iterate    58  f =      -636.43  |proj g|=       0.21787
At iterate    59  f =      -636.44  |proj g|=       0.29742
At iterate    60  f =      -636.44  |proj g|=      0.055163
At iterate    61  f =      -636.44  |proj g|=      0.015588

iterations 61
function evaluations 71
segments explored during Cauchy searches 63
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0155876
final function value -636.436

F = -636.436
final  value -636.435728 
converged
 
INFO  [07:32:14.424] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:32:14.527] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:32:14.533] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:32:19.785] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:32:23.795] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:32:27.803] [mlr3]  Finished benchmark 
INFO  [07:32:27.948] [bbotk] Result of batch 139: 
INFO  [07:32:27.951] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:32:27.951] [bbotk]              5.588171                 8.824493                      0.02998237 
INFO  [07:32:27.951] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:32:27.951] [bbotk]                     2284        0.853 -0.9546927         <NA>   0.9597824 
INFO  [07:32:27.951] [bbotk]                                 uhash 
INFO  [07:32:27.951] [bbotk]  0cc22f1d-0e21-414a-8187-d0631f439d39 
DEBUG [07:32:29.146] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.258281e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.258281e-05 0.002871449 
  - best initial criterion value(s) :  554.4391 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -554.44  |proj g|=       1.3881
At iterate     1  f =       -604.8  |proj g|=        4.7675
At iterate     2  f =      -645.52  |proj g|=        1.8567
At iterate     3  f =      -646.07  |proj g|=        1.8496
At iterate     4  f =      -648.48  |proj g|=        1.7917
At iterate     5  f =      -648.61  |proj g|=        1.7774
At iterate     6  f =      -648.63  |proj g|=        1.7721
At iterate     7  f =      -648.67  |proj g|=        1.7675
At iterate     8  f =      -648.68  |proj g|=        1.7659
At iterate     9  f =      -648.68  |proj g|=        1.7656
At iterate    10  f =      -648.68  |proj g|=        1.7656

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.76556
final function value -648.683

F = -648.683
final  value -648.683375 
converged
 
INFO  [07:32:29.150] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:32:29.239] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:32:29.247] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:32:34.151] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:32:39.204] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:32:44.072] [mlr3]  Finished benchmark 
INFO  [07:32:44.174] [bbotk] Result of batch 140: 
INFO  [07:32:44.176] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:32:44.176] [bbotk]              3.612884                 2.288213                       0.1577497 
INFO  [07:32:44.176] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:32:44.176] [bbotk]                     3129        0.843 -0.9493103         <NA>   0.9720943 
INFO  [07:32:44.176] [bbotk]                                 uhash 
INFO  [07:32:44.176] [bbotk]  7e03cb2b-a14f-4374-98e4-cd736c3e4e5b 
DEBUG [07:32:45.901] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.245541e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.245541e-05 0.002860824 
  - best initial criterion value(s) :  590.3309 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -590.33  |proj g|=       2.7676
At iterate     1  f =         -602  |proj g|=        8.9856
At iterate     2  f =      -604.62  |proj g|=        8.6274
At iterate     3  f =       -606.4  |proj g|=        7.9022
At iterate     4  f =      -606.49  |proj g|=        7.6094
At iterate     5  f =      -606.51  |proj g|=        7.6875
At iterate     6  f =      -606.53  |proj g|=         7.778
At iterate     7  f =      -606.59  |proj g|=         7.953
At iterate     8  f =      -606.64  |proj g|=        8.0736
At iterate     9  f =      -606.65  |proj g|=          7.97
At iterate    10  f =      -606.66  |proj g|=        8.0229
At iterate    11  f =      -607.26  |proj g|=        8.1612
At iterate    12  f =      -610.95  |proj g|=        7.8793
At iterate    13  f =      -621.27  |proj g|=        6.0039
At iterate    14  f =      -626.81  |proj g|=         4.947
At iterate    15  f =      -627.81  |proj g|=         4.305
At iterate    16  f =      -628.61  |proj g|=        4.0647
At iterate    17  f =      -628.78  |proj g|=        3.8582
At iterate    18  f =      -629.06  |proj g|=         3.676
At iterate    19  f =      -629.14  |proj g|=        3.7126
At iterate    20  f =      -629.15  |proj g|=         3.842
At iterate    21  f =      -629.15  |proj g|=        3.8411
At iterate    22  f =      -629.15  |proj g|=        3.8406
At iterate    23  f =      -629.15  |proj g|=         3.839
At iterate    24  f =      -629.15  |proj g|=        3.8371
At iterate    25  f =      -629.15  |proj g|=        3.8335
At iterate    26  f =      -629.15  |proj g|=        3.8274
At iterate    27  f =      -629.15  |proj g|=         3.817
At iterate    28  f =      -629.16  |proj g|=        3.7992
At iterate    29  f =      -629.16  |proj g|=         3.773
At iterate    30  f =      -629.16  |proj g|=        3.7632
At iterate    31  f =      -629.16  |proj g|=        3.7264
At iterate    32  f =      -629.17  |proj g|=        3.7482
At iterate    33  f =      -629.17  |proj g|=        3.7459
At iterate    34  f =      -629.17  |proj g|=        3.7438
At iterate    35  f =      -629.17  |proj g|=        3.7388
At iterate    36  f =      -629.17  |proj g|=        3.7332
At iterate    37  f =      -629.17  |proj g|=        3.7285
At iterate    38  f =      -629.17  |proj g|=        3.7204
At iterate    39  f =      -629.19  |proj g|=        3.7422
At iterate    40  f =      -629.37  |proj g|=        3.7385
At iterate    41  f =      -629.48  |proj g|=         3.679
At iterate    42  f =      -629.66  |proj g|=        3.7443
At iterate    43  f =      -629.66  |proj g|=        3.7302
At iterate    44  f =      -629.87  |proj g|=        3.8694
At iterate    45  f =      -630.22  |proj g|=        3.9298
At iterate    46  f =      -630.38  |proj g|=        3.8472
At iterate    47  f =      -632.62  |proj g|=        4.0158
At iterate    48  f =      -657.32  |proj g|=         1.091
At iterate    49  f =      -657.54  |proj g|=        1.5825
At iterate    50  f =      -659.98  |proj g|=       0.83656
At iterate    51  f =      -661.32  |proj g|=       0.31503
At iterate    52  f =      -661.32  |proj g|=      0.056678
At iterate    53  f =      -661.32  |proj g|=       0.12259
At iterate    54  f =      -661.32  |proj g|=       0.06435
At iterate    55  f =      -661.32  |proj g|=    0.00082338

iterations 55
function evaluations 72
segments explored during Cauchy searches 57
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000823385
final function value -661.324

F = -661.324
final  value -661.324449 
converged
 
INFO  [07:32:45.906] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:32:46.028] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:32:46.035] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:32:53.861] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:33:01.544] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:33:08.944] [mlr3]  Finished benchmark 
INFO  [07:33:09.046] [bbotk] Result of batch 141: 
INFO  [07:33:09.048] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:33:09.048] [bbotk]              9.376227                 4.755636                       0.2025684 
INFO  [07:33:09.048] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:33:09.048] [bbotk]                     4710        0.861 -0.9419783         <NA>   0.9770798 
INFO  [07:33:09.048] [bbotk]                                 uhash 
INFO  [07:33:09.048] [bbotk]  01643986-a72b-4edf-84cb-f68c824da4ae 
DEBUG [07:33:11.157] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.236146e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.236146e-05 0.002857458 
  - best initial criterion value(s) :  593.1467 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -593.15  |proj g|=        3.514
At iterate     1  f =      -616.51  |proj g|=        3.3054
At iterate     2  f =      -637.69  |proj g|=        3.7345
At iterate     3  f =       -637.8  |proj g|=        3.6642
At iterate     4  f =      -637.86  |proj g|=        3.5686
At iterate     5  f =      -637.88  |proj g|=        3.5513
At iterate     6  f =      -637.92  |proj g|=        3.5259
At iterate     7  f =      -637.92  |proj g|=        3.5402
At iterate     8  f =      -637.92  |proj g|=        3.5431
At iterate     9  f =      -637.92  |proj g|=        3.5437
At iterate    10  f =      -637.92  |proj g|=        3.5472
At iterate    11  f =      -637.92  |proj g|=        3.5512
At iterate    12  f =      -637.92  |proj g|=        3.5585
At iterate    13  f =      -637.93  |proj g|=        3.5689
At iterate    14  f =      -637.94  |proj g|=        3.5833
At iterate    15  f =      -637.96  |proj g|=        3.5964
At iterate    16  f =      -638.01  |proj g|=        3.5898
At iterate    17  f =      -638.06  |proj g|=        3.5776
At iterate    18  f =      -638.07  |proj g|=         3.533
At iterate    19  f =      -638.17  |proj g|=        3.5249
At iterate    20  f =      -638.55  |proj g|=        3.5008
At iterate    21  f =      -640.35  |proj g|=        3.3663
At iterate    22  f =      -643.92  |proj g|=        3.1179
At iterate    23  f =      -654.36  |proj g|=         2.171
At iterate    24  f =      -655.95  |proj g|=       0.42088
At iterate    25  f =      -659.69  |proj g|=        1.4984
At iterate    26  f =       -660.4  |proj g|=        1.4285
At iterate    27  f =       -660.7  |proj g|=        1.3664
At iterate    28  f =      -660.72  |proj g|=        1.3689
At iterate    29  f =      -660.72  |proj g|=        1.3812
At iterate    30  f =      -660.72  |proj g|=        1.4023
At iterate    31  f =      -660.72  |proj g|=        1.4087
At iterate    32  f =      -660.72  |proj g|=        1.4127
At iterate    33  f =      -660.72  |proj g|=        1.4178
At iterate    34  f =      -660.72  |proj g|=        1.4321
At iterate    35  f =      -660.72  |proj g|=        1.4508
At iterate    36  f =      -660.73  |proj g|=        1.4816
At iterate    37  f =      -660.76  |proj g|=        1.5254
At iterate    38  f =      -660.82  |proj g|=        1.5829
At iterate    39  f =      -660.98  |proj g|=        1.6359
At iterate    40  f =      -661.38  |proj g|=        1.6082
At iterate    41  f =      -661.96  |proj g|=        1.4161
At iterate    42  f =      -662.32  |proj g|=        1.2141
At iterate    43  f =      -662.56  |proj g|=        0.9721
At iterate    44  f =      -662.62  |proj g|=       0.83994
At iterate    45  f =      -662.65  |proj g|=        0.7929
At iterate    46  f =      -662.79  |proj g|=         0.631
At iterate    47  f =      -663.03  |proj g|=       0.45819
At iterate    48  f =      -663.56  |proj g|=       0.28461
At iterate    49  f =      -664.16  |proj g|=       0.27484
At iterate    50  f =       -664.6  |proj g|=       0.73976
At iterate    51  f =      -664.68  |proj g|=       0.57309
At iterate    52  f =      -664.74  |proj g|=       0.23811
At iterate    53  f =      -664.75  |proj g|=       0.39597
At iterate    54  f =      -664.75  |proj g|=     0.0025318
At iterate    55  f =      -664.75  |proj g|=     0.0025315

iterations 55
function evaluations 60
segments explored during Cauchy searches 58
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0025315
final function value -664.746

F = -664.746
final  value -664.746221 
converged
 
INFO  [07:33:11.161] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:33:11.249] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:33:11.256] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:33:14.185] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:33:16.976] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:33:19.778] [mlr3]  Finished benchmark 
INFO  [07:33:19.925] [bbotk] Result of batch 142: 
INFO  [07:33:19.927] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:33:19.927] [bbotk]              9.323015                 8.850419                      0.01615584 
INFO  [07:33:19.927] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:33:19.927] [bbotk]                     1798        1.249 -0.9392043         <NA>   0.9491428 
INFO  [07:33:19.927] [bbotk]                                 uhash 
INFO  [07:33:19.927] [bbotk]  20e1e5e5-2341-48e1-a60a-7612a4827530 
DEBUG [07:33:21.666] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.246189e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.246189e-05 0.00286382 
  - best initial criterion value(s) :  559.0582 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -559.06  |proj g|=       3.7176
At iterate     1  f =      -572.31  |proj g|=        12.382
At iterate     2  f =      -590.55  |proj g|=        12.905
At iterate     3  f =      -592.62  |proj g|=        12.302
At iterate     4  f =      -595.33  |proj g|=        9.6852
At iterate     5  f =       -597.2  |proj g|=        8.4912
At iterate     6  f =      -597.28  |proj g|=         8.466
At iterate     7  f =      -597.28  |proj g|=        8.4573
At iterate     8  f =      -597.28  |proj g|=        8.4546
At iterate     9  f =      -597.28  |proj g|=        8.4407
At iterate    10  f =       -597.3  |proj g|=        8.4209
At iterate    11  f =      -597.34  |proj g|=        8.3828
At iterate    12  f =      -597.46  |proj g|=        8.3103
At iterate    13  f =      -597.75  |proj g|=        8.0856
At iterate    14  f =      -598.44  |proj g|=        7.9593
At iterate    15  f =      -600.12  |proj g|=         7.302
At iterate    16  f =      -604.92  |proj g|=        6.1994
At iterate    17  f =       -613.7  |proj g|=        4.3645
At iterate    18  f =      -624.18  |proj g|=        3.7363
At iterate    19  f =      -627.44  |proj g|=        2.6154
At iterate    20  f =       -631.8  |proj g|=        4.4427
At iterate    21  f =      -633.01  |proj g|=        4.5077
At iterate    22  f =      -634.42  |proj g|=        4.0623
At iterate    23  f =       -635.3  |proj g|=        3.5161
At iterate    24  f =      -635.34  |proj g|=         3.191
At iterate    25  f =       -635.4  |proj g|=        3.4664
At iterate    26  f =       -635.4  |proj g|=        3.4339
At iterate    27  f =       -635.4  |proj g|=        3.4213
At iterate    28  f =       -635.4  |proj g|=        3.3945
At iterate    29  f =       -635.4  |proj g|=        3.4054
At iterate    30  f =       -635.4  |proj g|=        3.4119
At iterate    31  f =       -635.4  |proj g|=        3.4295
At iterate    32  f =       -635.4  |proj g|=        3.4279
At iterate    33  f =       -635.4  |proj g|=        3.4481
At iterate    34  f =       -636.4  |proj g|=        3.3951
At iterate    35  f =      -646.33  |proj g|=        2.6075
At iterate    36  f =      -650.23  |proj g|=        1.7293
At iterate    37  f =      -654.02  |proj g|=       0.88078
At iterate    38  f =      -655.26  |proj g|=        1.1049
At iterate    39  f =      -655.85  |proj g|=       0.57636
At iterate    40  f =       -655.9  |proj g|=       0.47007
At iterate    41  f =      -655.99  |proj g|=        0.6098
At iterate    42  f =      -656.05  |proj g|=       0.54098
At iterate    43  f =      -656.42  |proj g|=       0.26717
At iterate    44  f =      -656.75  |proj g|=       0.23269
At iterate    45  f =      -656.79  |proj g|=       0.75952
At iterate    46  f =      -656.79  |proj g|=      0.012181
At iterate    47  f =      -656.79  |proj g|=       0.15277
At iterate    48  f =      -656.79  |proj g|=      0.012161
At iterate    49  f =      -656.79  |proj g|=      0.012161

iterations 49
function evaluations 64
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0121606
final function value -656.789

F = -656.789
final  value -656.789238 
converged
 
INFO  [07:33:21.670] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:33:21.772] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:33:21.780] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:33:23.324] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:33:24.849] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:33:26.453] [mlr3]  Finished benchmark 
INFO  [07:33:26.625] [bbotk] Result of batch 143: 
INFO  [07:33:26.628] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:33:26.628] [bbotk]                8.0144                 4.734739                       0.1055921 
INFO  [07:33:26.628] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:33:26.628] [bbotk]                      819         0.95 -0.9530455         <NA>   0.9643227 
INFO  [07:33:26.628] [bbotk]                                 uhash 
INFO  [07:33:26.628] [bbotk]  2b4d8b8b-e31e-41d5-b68c-60e59c31df02 
DEBUG [07:33:28.209] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.234459e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.234459e-05 0.002837325 
  - best initial criterion value(s) :  574.6857 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -574.69  |proj g|=       2.7854
At iterate     1  f =       -577.4  |proj g|=        8.2286
At iterate     2  f =      -636.45  |proj g|=        4.0455
At iterate     3  f =      -640.02  |proj g|=        3.6607
At iterate     4  f =      -641.89  |proj g|=        3.0762
At iterate     5  f =      -641.96  |proj g|=        2.9695
At iterate     6  f =      -642.01  |proj g|=        2.8902
At iterate     7  f =      -642.11  |proj g|=        2.7544
At iterate     8  f =      -642.19  |proj g|=        2.7153
At iterate     9  f =      -642.21  |proj g|=        2.7951
At iterate    10  f =      -642.22  |proj g|=        2.7702
At iterate    11  f =      -642.22  |proj g|=        2.7708
At iterate    12  f =      -642.22  |proj g|=        2.7718
At iterate    13  f =      -642.22  |proj g|=        2.7776
At iterate    14  f =      -642.23  |proj g|=        2.7841
At iterate    15  f =      -642.24  |proj g|=        2.8561
At iterate    16  f =      -642.26  |proj g|=        2.8284
At iterate    17  f =      -642.34  |proj g|=        2.7656
At iterate    18  f =      -642.55  |proj g|=        2.6472
At iterate    19  f =      -643.03  |proj g|=        2.4414
At iterate    20  f =      -643.59  |proj g|=        2.3791
At iterate    21  f =      -649.77  |proj g|=       0.67194
At iterate    22  f =      -653.58  |proj g|=       0.27983
At iterate    23  f =      -655.72  |proj g|=        1.5827
At iterate    24  f =      -655.73  |proj g|=        1.5606
At iterate    25  f =      -655.75  |proj g|=        1.4403
At iterate    26  f =      -655.75  |proj g|=        1.4388
At iterate    27  f =      -655.75  |proj g|=        1.4384

iterations 27
function evaluations 32
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 1.43842
final function value -655.754

F = -655.754
final  value -655.754458 
converged
 
INFO  [07:33:28.214] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:33:28.316] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:33:28.325] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:33:31.929] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:33:36.160] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:33:41.249] [mlr3]  Finished benchmark 
INFO  [07:33:41.356] [bbotk] Result of batch 144: 
INFO  [07:33:41.358] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:33:41.358] [bbotk]              5.982841                 9.559146                      0.09342199 
INFO  [07:33:41.358] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:33:41.358] [bbotk]                     2003        0.995 -0.9453488         <NA>   0.9702791 
INFO  [07:33:41.358] [bbotk]                                 uhash 
INFO  [07:33:41.358] [bbotk]  46024093-6861-4ba8-8be2-5769ff0b2b92 
DEBUG [07:33:42.842] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.221716e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.221716e-05 0.002824845 
  - best initial criterion value(s) :  610.7469 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -610.75  |proj g|=       2.2337
At iterate     1  f =      -621.29  |proj g|=        5.9702
At iterate     2  f =      -628.09  |proj g|=        5.4368
At iterate     3  f =      -638.11  |proj g|=        3.6749
At iterate     4  f =      -638.53  |proj g|=        3.2019
At iterate     5  f =      -638.55  |proj g|=        3.1535
At iterate     6  f =      -638.59  |proj g|=        3.0982
At iterate     7  f =      -638.64  |proj g|=        3.0853
At iterate     8  f =      -638.67  |proj g|=        3.1534
At iterate     9  f =      -638.67  |proj g|=           3.2
At iterate    10  f =      -638.67  |proj g|=        3.2042
At iterate    11  f =      -638.67  |proj g|=        3.2044

iterations 11
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.20435
final function value -638.671

F = -638.671
final  value -638.670952 
converged
 
INFO  [07:33:42.847] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:33:42.984] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:33:42.991] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:33:44.310] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:33:45.649] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:33:47.092] [mlr3]  Finished benchmark 
INFO  [07:33:47.197] [bbotk] Result of batch 145: 
INFO  [07:33:47.199] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:33:47.199] [bbotk]              4.961703                 6.179916                      0.09761274 
INFO  [07:33:47.199] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:33:47.199] [bbotk]                      422        1.093 -0.9636719         <NA>   0.9503511 
INFO  [07:33:47.199] [bbotk]                                 uhash 
INFO  [07:33:47.199] [bbotk]  d8f07648-f8fa-49b7-864a-cb706db86e1b 
DEBUG [07:33:48.672] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.228726e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.228726e-05 0.002829579 
  - best initial criterion value(s) :  594.4207 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -594.42  |proj g|=       5.5418
At iterate     1  f =      -639.23  |proj g|=        2.7884
At iterate     2  f =      -643.96  |proj g|=        2.3592
At iterate     3  f =      -650.45  |proj g|=       0.91672
At iterate     4  f =      -653.11  |proj g|=        1.6025
At iterate     5  f =      -657.31  |proj g|=        1.4431
At iterate     6  f =      -666.34  |proj g|=        1.2225
At iterate     7  f =      -670.17  |proj g|=        1.1374
At iterate     8  f =      -671.37  |proj g|=        1.1374
At iterate     9  f =      -671.82  |proj g|=        1.1374
At iterate    10  f =      -671.86  |proj g|=        1.1374
At iterate    11  f =      -671.86  |proj g|=        1.1374
At iterate    12  f =      -671.86  |proj g|=        1.1374
At iterate    13  f =      -671.86  |proj g|=        1.1374
At iterate    14  f =      -671.86  |proj g|=        1.1374
At iterate    15  f =      -671.87  |proj g|=        1.1374
At iterate    16  f =      -671.88  |proj g|=        1.1373
At iterate    17  f =       -671.9  |proj g|=        1.1373
At iterate    18  f =      -671.96  |proj g|=        1.1372
At iterate    19  f =      -672.11  |proj g|=        1.1369
At iterate    20  f =      -672.39  |proj g|=        1.1362
At iterate    21  f =      -672.71  |proj g|=         1.136
At iterate    22  f =      -672.81  |proj g|=        1.1353
At iterate    23  f =      -672.82  |proj g|=        1.1352
At iterate    24  f =      -672.82  |proj g|=        1.1352
At iterate    25  f =      -673.45  |proj g|=       0.75525
At iterate    26  f =      -674.68  |proj g|=        0.7482
At iterate    27  f =      -674.89  |proj g|=        0.7492
At iterate    28  f =      -674.96  |proj g|=       0.23644
At iterate    29  f =      -674.96  |proj g|=       0.19812
At iterate    30  f =      -674.96  |proj g|=       0.23765
At iterate    31  f =      -674.96  |proj g|=       0.18154
At iterate    32  f =      -674.96  |proj g|=      0.030566
At iterate    33  f =      -674.96  |proj g|=     0.0032539

iterations 33
function evaluations 41
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00325389
final function value -674.964

F = -674.964
final  value -674.964321 
converged
 
INFO  [07:33:48.677] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:33:48.806] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:33:48.817] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:33:51.996] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:33:54.406] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:33:58.108] [mlr3]  Finished benchmark 
INFO  [07:33:58.213] [bbotk] Result of batch 146: 
INFO  [07:33:58.215] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:33:58.215] [bbotk]              6.707869                 2.883959                       0.3270354 
INFO  [07:33:58.215] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:33:58.215] [bbotk]                     1129        0.862 -0.9436086         <NA>   0.9743639 
INFO  [07:33:58.215] [bbotk]                                 uhash 
INFO  [07:33:58.215] [bbotk]  96bd72bb-1df2-44d1-988e-81264e194e13 
DEBUG [07:33:59.889] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.217769e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.217769e-05 0.002799651 
  - best initial criterion value(s) :  604.4337 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -604.43  |proj g|=       8.1518
At iterate     1  f =      -621.52  |proj g|=        2.2305
At iterate     2  f =      -642.78  |proj g|=        2.7376
At iterate     3  f =         -648  |proj g|=        2.5295
At iterate     4  f =      -652.58  |proj g|=        2.4106
At iterate     5  f =      -654.73  |proj g|=        2.5208
At iterate     6  f =      -656.06  |proj g|=        2.7925
At iterate     7  f =      -656.24  |proj g|=        4.6232
At iterate     8  f =      -657.08  |proj g|=        3.7043
At iterate     9  f =      -657.11  |proj g|=        3.7256
At iterate    10  f =      -657.11  |proj g|=        3.7455
At iterate    11  f =      -657.11  |proj g|=        3.7508
At iterate    12  f =      -657.11  |proj g|=        3.7559
At iterate    13  f =      -657.11  |proj g|=        3.7634
At iterate    14  f =      -657.11  |proj g|=        3.7745
At iterate    15  f =      -657.12  |proj g|=        3.7911
At iterate    16  f =      -657.12  |proj g|=        3.8096
At iterate    17  f =      -657.14  |proj g|=        3.8136
At iterate    18  f =      -657.17  |proj g|=          3.78
At iterate    19  f =      -657.23  |proj g|=        3.8729
At iterate    20  f =      -657.35  |proj g|=         3.769
At iterate    21  f =      -657.37  |proj g|=        3.9621
At iterate    22  f =       -657.9  |proj g|=        3.4745
At iterate    23  f =      -659.03  |proj g|=         2.849
At iterate    24  f =       -662.5  |proj g|=         2.781
At iterate    25  f =      -669.05  |proj g|=        2.7626
At iterate    26  f =      -673.17  |proj g|=        2.3871
At iterate    27  f =      -675.19  |proj g|=        2.1924
At iterate    28  f =      -675.98  |proj g|=        1.9878
At iterate    29  f =      -676.13  |proj g|=        1.9871
At iterate    30  f =      -676.13  |proj g|=         1.987
At iterate    31  f =      -676.13  |proj g|=         1.987
At iterate    32  f =      -676.13  |proj g|=         1.987
At iterate    33  f =      -676.13  |proj g|=         1.987
At iterate    34  f =      -676.13  |proj g|=         1.987
At iterate    35  f =      -676.13  |proj g|=        1.9869
At iterate    36  f =      -676.16  |proj g|=        1.9734
At iterate    37  f =       -676.4  |proj g|=        1.8297
At iterate    38  f =      -677.54  |proj g|=        1.0985
At iterate    39  f =      -678.27  |proj g|=       0.60981
At iterate    40  f =      -679.52  |proj g|=       0.27738
At iterate    41  f =      -679.71  |proj g|=       0.26511
At iterate    42  f =       -680.1  |proj g|=       0.23299
At iterate    43  f =      -680.11  |proj g|=       0.75661
At iterate    44  f =      -680.11  |proj g|=      0.043484
At iterate    45  f =      -680.11  |proj g|=      0.026953
At iterate    46  f =      -680.11  |proj g|=     0.0032824

iterations 46
function evaluations 57
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00328243
final function value -680.111

F = -680.111
final  value -680.111066 
converged
 
INFO  [07:33:59.893] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:34:00.007] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:34:00.019] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:34:01.181] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:34:02.373] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:34:03.496] [mlr3]  Finished benchmark 
INFO  [07:34:03.598] [bbotk] Result of batch 147: 
INFO  [07:34:03.600] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:34:03.600] [bbotk]              8.668418                  4.78811                       0.3242536 
INFO  [07:34:03.600] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:34:03.600] [bbotk]                      403        0.884 -0.9437612         <NA>   0.9686872 
INFO  [07:34:03.600] [bbotk]                                 uhash 
INFO  [07:34:03.600] [bbotk]  890022f0-2c7d-4ec8-b15a-c2f40577c934 
DEBUG [07:34:05.305] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.205242e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.205242e-05 0.002770631 
  - best initial criterion value(s) :  592.9845 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -592.98  |proj g|=       6.6484
At iterate     1  f =      -631.03  |proj g|=         2.869
At iterate     2  f =      -653.62  |proj g|=        2.8371
At iterate     3  f =      -654.57  |proj g|=        2.7528
At iterate     4  f =      -654.58  |proj g|=        2.7427
At iterate     5  f =      -654.61  |proj g|=        2.7506
At iterate     6  f =      -654.69  |proj g|=        2.8108
At iterate     7  f =       -654.7  |proj g|=        2.8126
At iterate     8  f =       -654.7  |proj g|=        2.8126
At iterate     9  f =       -654.7  |proj g|=        2.8125
At iterate    10  f =       -654.7  |proj g|=        2.8123
At iterate    11  f =       -654.7  |proj g|=        2.8114
At iterate    12  f =      -654.71  |proj g|=        2.8095
At iterate    13  f =      -654.73  |proj g|=        2.8063
At iterate    14  f =      -654.77  |proj g|=        2.8026
At iterate    15  f =      -654.87  |proj g|=        2.7997
At iterate    16  f =      -655.07  |proj g|=          2.79
At iterate    17  f =      -655.43  |proj g|=        2.7596
At iterate    18  f =      -655.44  |proj g|=        2.7813
At iterate    19  f =      -655.89  |proj g|=        2.7087
At iterate    20  f =      -656.57  |proj g|=        2.3317
At iterate    21  f =      -657.13  |proj g|=        2.5132
At iterate    22  f =      -657.17  |proj g|=        2.4907
At iterate    23  f =      -657.17  |proj g|=        2.4796
At iterate    24  f =      -657.17  |proj g|=        2.4843
At iterate    25  f =      -657.17  |proj g|=        2.4836
At iterate    26  f =      -657.17  |proj g|=        2.4823
At iterate    27  f =      -657.17  |proj g|=        2.4817
At iterate    28  f =      -657.19  |proj g|=        2.4739
At iterate    29  f =      -657.24  |proj g|=        2.4548
At iterate    30  f =      -657.37  |proj g|=        2.3445
At iterate    31  f =      -657.66  |proj g|=        2.0749
At iterate    32  f =      -657.83  |proj g|=        1.7286
At iterate    33  f =       -658.5  |proj g|=        1.3758
At iterate    34  f =      -660.13  |proj g|=       0.73649
At iterate    35  f =      -660.64  |proj g|=       0.58898
At iterate    36  f =      -662.26  |proj g|=       0.26521
At iterate    37  f =       -662.9  |proj g|=       0.79047
At iterate    38  f =      -663.11  |proj g|=       0.27299
At iterate    39  f =       -663.2  |proj g|=       0.13604
At iterate    40  f =      -663.21  |proj g|=       0.67235
At iterate    41  f =      -663.21  |proj g|=        0.2178
At iterate    42  f =      -663.21  |proj g|=       0.22091
At iterate    43  f =      -663.22  |proj g|=       0.12932
At iterate    44  f =      -663.22  |proj g|=      0.032067
At iterate    45  f =      -663.22  |proj g|=      0.032066

iterations 45
function evaluations 59
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0320664
final function value -663.215

F = -663.215
final  value -663.215017 
converged
 
INFO  [07:34:05.309] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:34:05.430] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:34:05.441] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:34:15.555] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:34:24.113] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:34:33.253] [mlr3]  Finished benchmark 
INFO  [07:34:33.374] [bbotk] Result of batch 148: 
INFO  [07:34:33.376] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:34:33.376] [bbotk]              5.378878                  5.60356                      0.04506777 
INFO  [07:34:33.376] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:34:33.376] [bbotk]                     3704        0.903 -0.9601292         <NA>   0.9686674 
INFO  [07:34:33.376] [bbotk]                                 uhash 
INFO  [07:34:33.376] [bbotk]  bb4bd891-939b-44e9-8bf5-e400b9cf6b91 
DEBUG [07:34:34.982] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.192856e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.192856e-05 0.002761263 
  - best initial criterion value(s) :  658.4772 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -658.48  |proj g|=       3.1335
At iterate     1  f =      -662.44  |proj g|=         5.408
At iterate     2  f =      -662.49  |proj g|=        5.3408
At iterate     3  f =      -662.79  |proj g|=        4.8032
At iterate     4  f =      -663.03  |proj g|=        4.5425
At iterate     5  f =      -663.73  |proj g|=        3.9661
At iterate     6  f =      -663.84  |proj g|=        4.2476
At iterate     7  f =      -663.85  |proj g|=         4.193
At iterate     8  f =      -663.85  |proj g|=        4.1979
At iterate     9  f =      -663.85  |proj g|=        4.2077
At iterate    10  f =      -663.85  |proj g|=        4.2298
At iterate    11  f =      -663.87  |proj g|=        4.2573
At iterate    12  f =      -663.88  |proj g|=        4.3604
At iterate    13  f =      -663.92  |proj g|=        4.3615
At iterate    14  f =      -664.05  |proj g|=        4.3368
At iterate    15  f =      -664.36  |proj g|=        4.2399
At iterate    16  f =       -665.1  |proj g|=          3.96
At iterate    17  f =      -666.58  |proj g|=        3.3485
At iterate    18  f =      -668.87  |proj g|=        2.8679
At iterate    19  f =       -670.6  |proj g|=        1.0839
At iterate    20  f =      -672.38  |proj g|=        1.6882
At iterate    21  f =      -673.73  |proj g|=        2.1506
At iterate    22  f =      -673.82  |proj g|=         2.157
At iterate    23  f =      -673.83  |proj g|=        2.0899
At iterate    24  f =      -673.83  |proj g|=          2.05
At iterate    25  f =      -673.83  |proj g|=        2.0523
At iterate    26  f =      -673.83  |proj g|=        2.0522

iterations 26
function evaluations 31
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.05224
final function value -673.834

F = -673.834
final  value -673.834478 
converged
 
INFO  [07:34:34.986] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:34:35.078] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:34:35.086] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:34:46.438] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:34:59.483] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:35:11.506] [mlr3]  Finished benchmark 
INFO  [07:35:11.614] [bbotk] Result of batch 149: 
INFO  [07:35:11.616] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:35:11.616] [bbotk]              9.145589                 9.302014                       0.4436233 
INFO  [07:35:11.616] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:35:11.616] [bbotk]                     4968        0.891 -0.9611545         <NA>   0.9787442 
INFO  [07:35:11.616] [bbotk]                                 uhash 
INFO  [07:35:11.616] [bbotk]  e11143e4-63a0-47ee-9e4b-6e047479982c 
DEBUG [07:35:13.102] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.185992e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.185992e-05 0.002745106 
  - best initial criterion value(s) :  612.6774 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -612.68  |proj g|=       6.4125
At iterate     1  f =      -627.05  |proj g|=         4.588
At iterate     2  f =      -628.97  |proj g|=        5.5744
At iterate     3  f =      -629.24  |proj g|=        5.3754
At iterate     4  f =      -629.35  |proj g|=        5.1598
At iterate     5  f =      -629.36  |proj g|=        5.1622
At iterate     6  f =      -629.36  |proj g|=        5.1795
At iterate     7  f =      -629.36  |proj g|=        5.1827
At iterate     8  f =      -629.36  |proj g|=        5.1842
At iterate     9  f =      -629.36  |proj g|=        5.1868
At iterate    10  f =      -629.36  |proj g|=        5.1905
At iterate    11  f =      -629.36  |proj g|=        5.1964
At iterate    12  f =      -629.36  |proj g|=        5.2042
At iterate    13  f =      -629.36  |proj g|=        5.2113
At iterate    14  f =      -629.37  |proj g|=         5.212
At iterate    15  f =      -629.37  |proj g|=        5.3033
At iterate    16  f =      -629.39  |proj g|=        5.2469
At iterate    17  f =      -629.44  |proj g|=        5.1619
At iterate    18  f =      -629.56  |proj g|=        5.0158
At iterate    19  f =      -629.87  |proj g|=        4.7392
At iterate    20  f =       -630.6  |proj g|=        4.3926
At iterate    21  f =      -632.21  |proj g|=        4.0348
At iterate    22  f =      -635.78  |proj g|=        3.4573
At iterate    23  f =       -642.3  |proj g|=         2.815
At iterate    24  f =      -643.28  |proj g|=        2.7034
At iterate    25  f =      -656.66  |proj g|=        2.3104
At iterate    26  f =      -663.26  |proj g|=        2.1162
At iterate    27  f =      -665.65  |proj g|=        1.1145
At iterate    28  f =      -665.75  |proj g|=        1.1145
At iterate    29  f =      -665.77  |proj g|=        1.1145
At iterate    30  f =      -665.77  |proj g|=        1.1145
At iterate    31  f =      -665.77  |proj g|=        1.1145
At iterate    32  f =      -665.77  |proj g|=        1.1145

iterations 32
function evaluations 38
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.11448
final function value -665.772

F = -665.772
final  value -665.771940 
converged
 
INFO  [07:35:13.107] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:35:13.201] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:35:13.229] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:35:15.126] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:35:17.625] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:35:20.666] [mlr3]  Finished benchmark 
INFO  [07:35:20.781] [bbotk] Result of batch 150: 
INFO  [07:35:20.783] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:35:20.783] [bbotk]              4.542345                 9.008088                        0.133637 
INFO  [07:35:20.783] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:35:20.783] [bbotk]                      856         0.87 -0.9614089         <NA>   0.9631897 
INFO  [07:35:20.783] [bbotk]                                 uhash 
INFO  [07:35:20.783] [bbotk]  3a85385a-86e9-486f-8a77-a4707f243d9b 
DEBUG [07:35:22.377] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.175682e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.175682e-05 0.002721995 
  - best initial criterion value(s) :  613.7584 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -613.76  |proj g|=       7.3895
At iterate     1  f =      -636.42  |proj g|=        6.2662
At iterate     2  f =      -637.34  |proj g|=        6.5792
At iterate     3  f =      -637.59  |proj g|=        6.4302
At iterate     4  f =      -637.69  |proj g|=        6.2565
At iterate     5  f =       -637.7  |proj g|=         6.233
At iterate     6  f =       -637.7  |proj g|=        6.2244
At iterate     7  f =       -637.7  |proj g|=        6.2248
At iterate     8  f =       -637.7  |proj g|=        6.2253
At iterate     9  f =      -637.71  |proj g|=        6.2264
At iterate    10  f =      -637.71  |proj g|=        6.2272
At iterate    11  f =      -637.71  |proj g|=        6.2273
At iterate    12  f =      -637.71  |proj g|=        6.2246
At iterate    13  f =      -637.72  |proj g|=        6.2107
At iterate    14  f =      -637.73  |proj g|=        6.1755
At iterate    15  f =      -637.73  |proj g|=        6.1938
At iterate    16  f =      -637.76  |proj g|=        6.1462
At iterate    17  f =      -653.38  |proj g|=        4.0965
At iterate    18  f =       -673.5  |proj g|=        1.4415
At iterate    19  f =       -678.1  |proj g|=        0.8178
At iterate    20  f =      -678.26  |proj g|=       0.78693
At iterate    21  f =      -678.26  |proj g|=       0.59216
At iterate    22  f =      -678.26  |proj g|=       0.59984
At iterate    23  f =      -678.26  |proj g|=       0.59981

iterations 23
function evaluations 28
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.599814
final function value -678.26

F = -678.26
final  value -678.260309 
converged
 
INFO  [07:35:22.381] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:35:22.469] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:35:22.476] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:35:25.167] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:35:28.588] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:35:31.126] [mlr3]  Finished benchmark 
INFO  [07:35:31.225] [bbotk] Result of batch 151: 
INFO  [07:35:31.227] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:35:31.227] [bbotk]              2.708858                 9.973318                       0.1434687 
INFO  [07:35:31.227] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:35:31.227] [bbotk]                     1165        1.066 -0.9608562         <NA>   0.9530778 
INFO  [07:35:31.227] [bbotk]                                 uhash 
INFO  [07:35:31.227] [bbotk]  8fb4bcd3-a954-4573-8050-b78a2e25bb82 
DEBUG [07:35:32.724] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.177452e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.177452e-05 0.002715221 
  - best initial criterion value(s) :  619.0089 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -619.01  |proj g|=       2.4243
At iterate     1  f =      -641.73  |proj g|=        6.4541
At iterate     2  f =      -686.58  |proj g|=        2.9717
At iterate     3  f =      -686.89  |proj g|=        2.8043
At iterate     4  f =      -686.93  |proj g|=        2.7137
At iterate     5  f =      -686.93  |proj g|=         2.711
At iterate     6  f =      -686.93  |proj g|=        2.7108
At iterate     7  f =      -686.93  |proj g|=        2.7137
At iterate     8  f =      -686.93  |proj g|=         2.719
At iterate     9  f =      -686.93  |proj g|=        2.7178
At iterate    10  f =      -686.93  |proj g|=        2.7176
At iterate    11  f =      -686.93  |proj g|=        2.7168
At iterate    12  f =      -686.93  |proj g|=        2.7157
At iterate    13  f =      -686.93  |proj g|=        2.7142
At iterate    14  f =      -686.93  |proj g|=        2.7126
At iterate    15  f =      -686.93  |proj g|=        2.7104
At iterate    16  f =      -686.94  |proj g|=        2.7088
At iterate    17  f =      -686.94  |proj g|=        2.7064
At iterate    18  f =      -686.95  |proj g|=        2.7142
At iterate    19  f =      -686.95  |proj g|=        2.6913
At iterate    20  f =      -686.96  |proj g|=        2.6976
At iterate    21  f =      -687.17  |proj g|=         2.685
At iterate    22  f =      -688.95  |proj g|=        2.4528
At iterate    23  f =      -691.92  |proj g|=        2.2354
At iterate    24  f =      -693.01  |proj g|=        2.6327
At iterate    25  f =      -693.25  |proj g|=        2.1467
At iterate    26  f =      -694.02  |proj g|=        2.0868
At iterate    27  f =      -694.15  |proj g|=        2.3913
At iterate    28  f =      -694.16  |proj g|=        2.2684
At iterate    29  f =      -694.16  |proj g|=        2.2926
At iterate    30  f =      -694.16  |proj g|=         2.289
At iterate    31  f =      -694.16  |proj g|=        2.2886

iterations 31
function evaluations 36
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.28864
final function value -694.159

F = -694.159
final  value -694.158586 
converged
 
INFO  [07:35:32.728] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:35:32.813] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:35:32.819] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:35:44.179] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:35:54.231] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:36:05.036] [mlr3]  Finished benchmark 
INFO  [07:36:05.138] [bbotk] Result of batch 152: 
INFO  [07:36:05.140] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:36:05.140] [bbotk]              9.745615                 9.012359                      0.08517581 
INFO  [07:36:05.140] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [07:36:05.140] [bbotk]                     4835        0.897 -0.951322         <NA>   0.9748392 
INFO  [07:36:05.140] [bbotk]                                 uhash 
INFO  [07:36:05.140] [bbotk]  dca0aa51-2fb3-47b6-95b9-e44335d6c618 
DEBUG [07:36:06.822] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.167459e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.167459e-05 0.002707805 
  - best initial criterion value(s) :  671.5307 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -671.53  |proj g|=       2.1337
At iterate     1  f =      -674.71  |proj g|=         3.418
At iterate     2  f =      -681.15  |proj g|=        2.6674
At iterate     3  f =       -685.7  |proj g|=        1.8403
At iterate     4  f =      -686.31  |proj g|=        1.8119
At iterate     5  f =      -691.33  |proj g|=        1.8731
At iterate     6  f =      -694.62  |proj g|=        2.1534
At iterate     7  f =      -695.73  |proj g|=        2.3435
At iterate     8  f =      -696.13  |proj g|=        2.4907
At iterate     9  f =      -696.24  |proj g|=        2.5877
At iterate    10  f =      -696.25  |proj g|=        2.6214
At iterate    11  f =      -696.25  |proj g|=        2.6253
At iterate    12  f =      -696.25  |proj g|=        2.6279
At iterate    13  f =      -696.25  |proj g|=        2.6285
At iterate    14  f =      -696.25  |proj g|=        2.6316
At iterate    15  f =      -696.25  |proj g|=         2.636
At iterate    16  f =      -696.25  |proj g|=        2.6433
At iterate    17  f =      -696.25  |proj g|=        2.6545
At iterate    18  f =      -696.26  |proj g|=        2.6716
At iterate    19  f =      -696.29  |proj g|=        2.6949
At iterate    20  f =      -696.34  |proj g|=        2.7427
At iterate    21  f =      -696.46  |proj g|=        2.7764
At iterate    22  f =      -696.59  |proj g|=        2.8754
At iterate    23  f =      -697.08  |proj g|=         2.881
At iterate    24  f =      -698.31  |proj g|=        2.2352
At iterate    25  f =      -700.69  |proj g|=       0.56938
At iterate    26  f =      -701.38  |proj g|=       0.34048
At iterate    27  f =      -702.14  |proj g|=       0.33561
At iterate    28  f =      -702.14  |proj g|=       0.33557
At iterate    29  f =      -702.14  |proj g|=       0.33557
At iterate    30  f =      -702.14  |proj g|=       0.33556
At iterate    31  f =      -702.15  |proj g|=       0.33546
At iterate    32  f =      -702.16  |proj g|=        0.3352
At iterate    33  f =      -702.19  |proj g|=       0.33437
At iterate    34  f =      -702.26  |proj g|=       0.33219
At iterate    35  f =      -702.44  |proj g|=       0.32657
At iterate    36  f =      -702.86  |proj g|=       0.31321
At iterate    37  f =      -703.77  |proj g|=       0.71137
At iterate    38  f =      -705.42  |proj g|=       0.76456
At iterate    39  f =      -706.24  |proj g|=       0.77694
At iterate    40  f =      -706.32  |proj g|=        0.2296
At iterate    41  f =      -706.33  |proj g|=       0.17456
At iterate    42  f =      -706.33  |proj g|=      0.017326
At iterate    43  f =      -706.33  |proj g|=     0.0067868
At iterate    44  f =      -706.33  |proj g|=      0.003784

iterations 44
function evaluations 52
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.003784
final function value -706.33

F = -706.33
final  value -706.329673 
converged
 
INFO  [07:36:06.826] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:36:06.926] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:36:06.933] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:36:17.761] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:36:28.658] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:36:38.996] [mlr3]  Finished benchmark 
INFO  [07:36:39.094] [bbotk] Result of batch 153: 
INFO  [07:36:39.096] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:36:39.096] [bbotk]              2.265092                  4.02248                       0.3462603 
INFO  [07:36:39.096] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:36:39.096] [bbotk]                     4817        0.898 -0.9504796         <NA>   0.9682546 
INFO  [07:36:39.096] [bbotk]                                 uhash 
INFO  [07:36:39.096] [bbotk]  1d7bc264-b696-4d65-8732-59a9a9bdfc2b 
DEBUG [07:36:40.770] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.155635e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.155635e-05 0.00269468 
  - best initial criterion value(s) :  645.1341 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -645.13  |proj g|=       8.2834
At iterate     1  f =      -660.77  |proj g|=         3.286
At iterate     2  f =      -666.55  |proj g|=        7.2893
At iterate     3  f =       -666.8  |proj g|=        6.8356
At iterate     4  f =      -666.89  |proj g|=        6.6305
At iterate     5  f =      -666.98  |proj g|=        6.5636
At iterate     6  f =      -667.07  |proj g|=        6.6964
At iterate     7  f =       -667.1  |proj g|=        6.9667
At iterate     8  f =       -667.1  |proj g|=        6.9393
At iterate     9  f =       -667.1  |proj g|=        6.9269
At iterate    10  f =       -667.1  |proj g|=         6.909
At iterate    11  f =      -667.11  |proj g|=         6.861
At iterate    12  f =      -667.12  |proj g|=        6.7943
At iterate    13  f =      -667.14  |proj g|=        6.6775
At iterate    14  f =      -667.21  |proj g|=         6.486
At iterate    15  f =      -667.39  |proj g|=        6.1525
At iterate    16  f =      -667.86  |proj g|=        5.5822
At iterate    17  f =      -669.03  |proj g|=        4.7488
At iterate    18  f =      -671.06  |proj g|=        3.9793
At iterate    19  f =       -671.1  |proj g|=        4.3389
At iterate    20  f =      -672.61  |proj g|=        3.5717
At iterate    21  f =       -681.5  |proj g|=        3.1126
At iterate    22  f =      -703.16  |proj g|=        3.2205
At iterate    23  f =      -705.18  |proj g|=        2.3216
At iterate    24  f =      -705.85  |proj g|=        1.3572
At iterate    25  f =         -706  |proj g|=        1.8744
At iterate    26  f =      -706.02  |proj g|=        1.7739
At iterate    27  f =      -706.02  |proj g|=        1.7521
At iterate    28  f =      -706.02  |proj g|=         1.754
At iterate    29  f =      -706.02  |proj g|=        1.7538

iterations 29
function evaluations 36
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.7538
final function value -706.024

F = -706.024
final  value -706.023754 
converged
 
INFO  [07:36:40.774] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:36:40.860] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:36:40.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:36:46.868] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:36:54.250] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:37:00.687] [mlr3]  Finished benchmark 
INFO  [07:37:00.804] [bbotk] Result of batch 154: 
INFO  [07:37:00.806] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:37:00.806] [bbotk]              7.641846                 2.241686                       0.1025486 
INFO  [07:37:00.806] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:37:00.806] [bbotk]                     2818        0.881 -0.9561059         <NA>    0.973545 
INFO  [07:37:00.806] [bbotk]                                 uhash 
INFO  [07:37:00.806] [bbotk]  b98b991a-2a5b-4aee-87d6-78397cf29646 
DEBUG [07:37:02.131] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.145105e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.145105e-05 0.002686231 
  - best initial criterion value(s) :  629.3692 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -629.37  |proj g|=       3.8472
At iterate     1  f =      -655.12  |proj g|=        7.0725
At iterate     2  f =      -659.23  |proj g|=        6.8928
At iterate     3  f =       -664.9  |proj g|=        6.0933
At iterate     4  f =       -665.4  |proj g|=        5.7777
At iterate     5  f =       -665.8  |proj g|=        5.6398
At iterate     6  f =       -667.1  |proj g|=        4.9091
At iterate     7  f =      -668.06  |proj g|=         5.329
At iterate     8  f =      -668.13  |proj g|=        5.2488
At iterate     9  f =      -668.14  |proj g|=        5.2576
At iterate    10  f =      -668.14  |proj g|=        5.2535
At iterate    11  f =      -668.14  |proj g|=        5.2526
At iterate    12  f =      -668.14  |proj g|=        5.2525

iterations 12
function evaluations 16
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 5.25252
final function value -668.141

F = -668.141
final  value -668.141129 
converged
 
INFO  [07:37:02.136] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:37:02.222] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:37:02.228] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:37:11.248] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:37:19.770] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:37:29.052] [mlr3]  Finished benchmark 
INFO  [07:37:29.153] [bbotk] Result of batch 155: 
INFO  [07:37:29.155] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:37:29.155] [bbotk]              9.752756                 5.541068                       0.3864533 
INFO  [07:37:29.155] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:37:29.155] [bbotk]                     4275        0.893 -0.9660908         <NA>   0.9771673 
INFO  [07:37:29.155] [bbotk]                                 uhash 
INFO  [07:37:29.155] [bbotk]  838a3de5-8707-4340-9e0a-259f97636438 
DEBUG [07:37:30.623] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.137195e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.137195e-05 0.002684742 
  - best initial criterion value(s) :  578.7735 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -578.77  |proj g|=       14.877
At iterate     1  f =      -632.48  |proj g|=        3.7571
At iterate     2  f =      -638.53  |proj g|=        3.7091
At iterate     3  f =      -640.87  |proj g|=        3.9477
At iterate     4  f =      -641.69  |proj g|=        4.1831
At iterate     5  f =      -641.96  |proj g|=        4.0926
At iterate     6  f =      -641.98  |proj g|=        4.0867
At iterate     7  f =      -641.99  |proj g|=        4.0761
At iterate     8  f =      -641.99  |proj g|=        4.0561
At iterate     9  f =      -641.99  |proj g|=        4.0174
At iterate    10  f =      -642.08  |proj g|=        3.9568
At iterate    11  f =      -643.13  |proj g|=        3.4752
At iterate    12  f =      -644.96  |proj g|=        2.9859
At iterate    13  f =       -651.1  |proj g|=        2.0573
At iterate    14  f =      -661.59  |proj g|=       0.92467
At iterate    15  f =      -666.65  |proj g|=        2.3399
At iterate    16  f =      -676.22  |proj g|=        1.6267
At iterate    17  f =      -684.47  |proj g|=         1.137
At iterate    18  f =      -687.88  |proj g|=       0.81507
At iterate    19  f =      -689.08  |proj g|=         0.378
At iterate    20  f =      -689.46  |proj g|=       0.21416
At iterate    21  f =      -689.59  |proj g|=       0.21586
At iterate    22  f =       -689.6  |proj g|=       0.21769
At iterate    23  f =       -689.6  |proj g|=       0.12199
At iterate    24  f =       -689.6  |proj g|=       0.10008
At iterate    25  f =       -689.6  |proj g|=       0.10008

iterations 25
function evaluations 29
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.100083
final function value -689.6

F = -689.6
final  value -689.600246 
converged
 
INFO  [07:37:30.627] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:37:30.729] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:37:30.736] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:37:33.370] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:37:36.578] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:37:39.360] [mlr3]  Finished benchmark 
INFO  [07:37:39.467] [bbotk] Result of batch 156: 
INFO  [07:37:39.469] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:37:39.469] [bbotk]              2.165184                 9.236065                       0.3791461 
INFO  [07:37:39.469] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:37:39.469] [bbotk]                     1243        0.911 -0.9625021         <NA>   0.9581718 
INFO  [07:37:39.469] [bbotk]                                 uhash 
INFO  [07:37:39.469] [bbotk]  36867105-ffde-4f73-bca4-4bd9c3f1d817 
DEBUG [07:37:41.476] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.131897e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.131897e-05 0.002669332 
  - best initial criterion value(s) :  652.4658 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -652.47  |proj g|=       7.4703
At iterate     1  f =      -677.12  |proj g|=        10.991
At iterate     2  f =      -681.87  |proj g|=        9.0386
At iterate     3  f =      -683.64  |proj g|=        5.5551
At iterate     4  f =      -685.54  |proj g|=        5.9739
At iterate     5  f =      -685.91  |proj g|=        5.3893
At iterate     6  f =      -685.92  |proj g|=          5.24
At iterate     7  f =      -685.93  |proj g|=        5.1947
At iterate     8  f =      -685.93  |proj g|=        5.1708
At iterate     9  f =      -685.93  |proj g|=        5.1114
At iterate    10  f =      -685.95  |proj g|=        5.0237
At iterate    11  f =      -685.99  |proj g|=        4.8611
At iterate    12  f =      -686.08  |proj g|=        4.6081
At iterate    13  f =       -686.3  |proj g|=        4.2391
At iterate    14  f =      -686.73  |proj g|=        3.6904
At iterate    15  f =      -687.77  |proj g|=        3.0525
At iterate    16  f =      -688.71  |proj g|=        2.1978
At iterate    17  f =      -691.28  |proj g|=        2.4831
At iterate    18  f =      -698.27  |proj g|=        2.7926
At iterate    19  f =      -706.01  |proj g|=        2.8597
At iterate    20  f =      -706.26  |proj g|=        2.6777
At iterate    21  f =         -710  |proj g|=        2.7514
At iterate    22  f =      -710.99  |proj g|=         3.681
At iterate    23  f =      -712.25  |proj g|=        3.4882
At iterate    24  f =      -712.25  |proj g|=        3.4777
At iterate    25  f =      -712.25  |proj g|=        3.4709
At iterate    26  f =      -712.25  |proj g|=        3.4773
At iterate    27  f =      -712.25  |proj g|=        3.4711
At iterate    28  f =      -712.25  |proj g|=        3.4756
At iterate    29  f =      -712.25  |proj g|=        3.4881
At iterate    30  f =      -712.28  |proj g|=        3.5356
At iterate    31  f =      -712.34  |proj g|=        3.6026
At iterate    32  f =      -712.46  |proj g|=        3.6863
At iterate    33  f =      -712.64  |proj g|=         3.744
At iterate    34  f =      -712.87  |proj g|=        3.4807
At iterate    35  f =      -712.89  |proj g|=        3.5587
At iterate    36  f =      -712.89  |proj g|=        3.5594
At iterate    37  f =      -712.89  |proj g|=        3.5589
At iterate    38  f =      -713.21  |proj g|=        3.4835
At iterate    39  f =      -715.31  |proj g|=        2.9394
At iterate    40  f =      -717.47  |proj g|=        2.4815
At iterate    41  f =      -718.26  |proj g|=         2.767
At iterate    42  f =      -721.39  |proj g|=        1.9124
At iterate    43  f =      -725.58  |proj g|=       0.75922
At iterate    44  f =      -727.24  |proj g|=       0.72642
At iterate    45  f =      -727.74  |proj g|=       0.25974
At iterate    46  f =      -728.12  |proj g|=       0.24276
At iterate    47  f =      -728.19  |proj g|=       0.22796
At iterate    48  f =      -728.19  |proj g|=       0.66266
At iterate    49  f =      -728.19  |proj g|=     0.0020031
At iterate    50  f =      -728.19  |proj g|=       0.00249

iterations 50
function evaluations 61
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00249003
final function value -728.194

F = -728.194
final  value -728.194099 
converged
 
INFO  [07:37:41.480] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:37:41.568] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:37:41.574] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:37:43.801] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:37:45.793] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:37:48.133] [mlr3]  Finished benchmark 
INFO  [07:37:48.237] [bbotk] Result of batch 157: 
INFO  [07:37:48.238] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:37:48.238] [bbotk]              3.169636                 2.717118                       0.1671004 
INFO  [07:37:48.238] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:37:48.238] [bbotk]                      889        0.892 -0.9458143         <NA>   0.9586387 
INFO  [07:37:48.238] [bbotk]                                 uhash 
INFO  [07:37:48.238] [bbotk]  3edb1100-0c19-4f3a-b5ff-4863efdc4217 
DEBUG [07:37:49.771] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.12607e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.12607e-05 0.002654025 
  - best initial criterion value(s) :  641.2741 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -641.27  |proj g|=       1.5601
At iterate     1  f =      -667.41  |proj g|=        8.8221
At iterate     2  f =      -716.29  |proj g|=        4.2317
At iterate     3  f =      -717.55  |proj g|=        3.8353
At iterate     4  f =      -719.22  |proj g|=        2.3104
At iterate     5  f =       -719.4  |proj g|=        2.5082
At iterate     6  f =      -719.86  |proj g|=        2.7138
At iterate     7  f =      -720.18  |proj g|=        2.5828
At iterate     8  f =      -720.21  |proj g|=         2.287
At iterate     9  f =      -720.22  |proj g|=        2.3814
At iterate    10  f =      -720.22  |proj g|=        2.3771
At iterate    11  f =      -720.22  |proj g|=        2.3763
At iterate    12  f =      -720.22  |proj g|=        2.3734
At iterate    13  f =      -720.22  |proj g|=        2.3696
At iterate    14  f =      -720.22  |proj g|=        2.3644
At iterate    15  f =      -720.22  |proj g|=        2.3554
At iterate    16  f =      -720.22  |proj g|=        2.3415
At iterate    17  f =      -720.23  |proj g|=        2.3237
At iterate    18  f =      -720.23  |proj g|=        2.3058
At iterate    19  f =      -720.24  |proj g|=        2.2703
At iterate    20  f =      -720.27  |proj g|=        2.2607
At iterate    21  f =      -720.27  |proj g|=        2.1799
At iterate    22  f =      -720.33  |proj g|=        2.1657
At iterate    23  f =      -720.71  |proj g|=        2.0904
At iterate    24  f =      -723.48  |proj g|=        1.6132
At iterate    25  f =      -724.45  |proj g|=        1.6284
At iterate    26  f =      -725.38  |proj g|=        2.1344
At iterate    27  f =      -725.92  |proj g|=        1.9507
At iterate    28  f =      -725.93  |proj g|=        1.7472
At iterate    29  f =      -725.94  |proj g|=        1.8277
At iterate    30  f =      -725.94  |proj g|=        1.8239
At iterate    31  f =      -725.94  |proj g|=        1.8235

iterations 31
function evaluations 34
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.8235
final function value -725.938

F = -725.938
final  value -725.937775 
converged
 
INFO  [07:37:49.776] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:37:49.897] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:37:49.905] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:38:00.241] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:38:13.435] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:38:23.013] [mlr3]  Finished benchmark 
INFO  [07:38:23.114] [bbotk] Result of batch 158: 
INFO  [07:38:23.116] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:38:23.116] [bbotk]              7.941337                 9.677668                       0.1542591 
INFO  [07:38:23.116] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:38:23.116] [bbotk]                     4559        0.908 -0.9481912         <NA>   0.9764862 
INFO  [07:38:23.116] [bbotk]                                 uhash 
INFO  [07:38:23.116] [bbotk]  aa64744f-235b-4ad1-af70-81edf7452292 
DEBUG [07:38:24.861] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.11787e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.11787e-05 0.002650682 
  - best initial criterion value(s) :  627.1841 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -627.18  |proj g|=        8.279
At iterate     1  f =      -669.96  |proj g|=        4.1495
At iterate     2  f =       -694.2  |proj g|=        4.1117
At iterate     3  f =      -695.48  |proj g|=        3.9814
At iterate     4  f =       -695.5  |proj g|=        3.9651
At iterate     5  f =      -695.57  |proj g|=        3.9867
At iterate     6  f =      -695.72  |proj g|=        4.1024
At iterate     7  f =      -695.74  |proj g|=        4.1452
At iterate     8  f =      -695.74  |proj g|=         4.153
At iterate     9  f =      -695.74  |proj g|=        4.1547
At iterate    10  f =      -695.74  |proj g|=        4.1618
At iterate    11  f =      -695.74  |proj g|=        4.1671
At iterate    12  f =      -695.74  |proj g|=        4.1768
At iterate    13  f =      -695.76  |proj g|=        4.1929
At iterate    14  f =      -695.82  |proj g|=        4.2205
At iterate    15  f =      -695.82  |proj g|=         4.219
At iterate    16  f =      -695.82  |proj g|=        4.2206
At iterate    17  f =      -695.82  |proj g|=         4.219
At iterate    18  f =      -695.82  |proj g|=        4.2206
At iterate    19  f =      -695.82  |proj g|=        4.2194
At iterate    20  f =      -695.83  |proj g|=        4.2131
At iterate    21  f =       -695.9  |proj g|=         4.188
At iterate    22  f =      -696.06  |proj g|=        4.1592
At iterate    23  f =      -696.44  |proj g|=        4.1296
At iterate    24  f =      -697.12  |proj g|=        4.1183
At iterate    25  f =      -697.92  |proj g|=        4.1721
At iterate    26  f =      -698.19  |proj g|=        4.2306
At iterate    27  f =      -698.24  |proj g|=        4.2696
At iterate    28  f =      -698.25  |proj g|=        4.2839
At iterate    29  f =      -698.25  |proj g|=        4.2855
At iterate    30  f =      -698.25  |proj g|=        4.2855

iterations 30
function evaluations 38
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.28554
final function value -698.246

F = -698.246
final  value -698.246215 
converged
 
INFO  [07:38:24.865] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:38:24.956] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:38:24.963] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:38:31.695] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:38:39.554] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:38:47.168] [mlr3]  Finished benchmark 
INFO  [07:38:47.274] [bbotk] Result of batch 159: 
INFO  [07:38:47.276] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:38:47.276] [bbotk]              6.553035                 9.247519                       0.2298357 
INFO  [07:38:47.276] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:38:47.276] [bbotk]                     2803        1.077 -0.9589154         <NA>   0.9761986 
INFO  [07:38:47.276] [bbotk]                                 uhash 
INFO  [07:38:47.276] [bbotk]  8e33d81c-cc0d-422d-8a6f-73ce346aded5 
DEBUG [07:38:48.763] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.109498e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.109498e-05 0.002645331 
  - best initial criterion value(s) :  681.8415 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -681.84  |proj g|=       1.4101
At iterate     1  f =      -704.94  |proj g|=        9.2077
At iterate     2  f =       -705.8  |proj g|=        8.7152
At iterate     3  f =      -706.77  |proj g|=        6.7987
At iterate     4  f =      -707.01  |proj g|=        7.3526
At iterate     5  f =      -707.23  |proj g|=        7.4858
At iterate     6  f =      -709.15  |proj g|=        7.9278
At iterate     7  f =      -711.37  |proj g|=         7.715
At iterate     8  f =      -713.34  |proj g|=        6.3393
At iterate     9  f =      -713.52  |proj g|=        5.8824
At iterate    10  f =      -713.54  |proj g|=        5.8209
At iterate    11  f =      -713.54  |proj g|=        5.8772
At iterate    12  f =      -713.54  |proj g|=        5.8547
At iterate    13  f =      -714.38  |proj g|=        5.4484
At iterate    14  f =      -718.26  |proj g|=        3.4971
At iterate    15  f =      -718.91  |proj g|=        2.8583
At iterate    16  f =      -718.99  |proj g|=        2.9076
At iterate    17  f =      -718.99  |proj g|=        2.9118
At iterate    18  f =      -718.99  |proj g|=        2.9102
At iterate    19  f =      -718.99  |proj g|=        2.9101

iterations 19
function evaluations 27
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.91013
final function value -718.995

F = -718.995
final  value -718.994568 
converged
 
INFO  [07:38:48.768] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:38:48.855] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:38:48.862] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:39:00.768] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:39:12.545] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:39:23.914] [mlr3]  Finished benchmark 
INFO  [07:39:24.049] [bbotk] Result of batch 160: 
INFO  [07:39:24.051] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:39:24.051] [bbotk]              3.291204                 6.246543                       0.2603515 
INFO  [07:39:24.051] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:39:24.051] [bbotk]                     4930        0.934 -0.9606385         <NA>   0.9750814 
INFO  [07:39:24.051] [bbotk]                                 uhash 
INFO  [07:39:24.051] [bbotk]  0a9388ac-9a35-4f8c-947d-41d79ea06466 
DEBUG [07:39:25.640] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.100397e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.100397e-05 0.00263619 
  - best initial criterion value(s) :  643.6371 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -643.64  |proj g|=       3.3797
At iterate     1  f =      -646.33  |proj g|=        4.7282
At iterate     2  f =      -650.16  |proj g|=         4.573
At iterate     3  f =      -652.77  |proj g|=        4.1561
At iterate     4  f =      -653.44  |proj g|=        3.9745
At iterate     5  f =      -656.53  |proj g|=        3.2241
At iterate     6  f =      -659.14  |proj g|=        2.9373
At iterate     7  f =      -659.29  |proj g|=        3.1366
At iterate     8  f =      -659.34  |proj g|=        3.0736
At iterate     9  f =      -659.34  |proj g|=        3.0636
At iterate    10  f =      -659.34  |proj g|=        3.0639
At iterate    11  f =      -659.34  |proj g|=        3.0641
At iterate    12  f =      -659.34  |proj g|=        3.0585
At iterate    13  f =      -659.45  |proj g|=        3.0601
At iterate    14  f =       -660.8  |proj g|=         2.919
At iterate    15  f =      -663.08  |proj g|=        2.5232
At iterate    16  f =      -666.08  |proj g|=        1.9743
At iterate    17  f =      -668.44  |proj g|=        1.5689
At iterate    18  f =       -668.7  |proj g|=        1.1828
At iterate    19  f =      -669.88  |proj g|=        1.6425
At iterate    20  f =      -670.94  |proj g|=        1.7184
At iterate    21  f =      -671.49  |proj g|=        1.6247
At iterate    22  f =      -671.51  |proj g|=        1.5655
At iterate    23  f =      -671.52  |proj g|=        1.5899
At iterate    24  f =      -671.52  |proj g|=        1.5854
At iterate    25  f =      -671.52  |proj g|=        1.5871
At iterate    26  f =      -671.52  |proj g|=         1.587

iterations 26
function evaluations 37
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.58701
final function value -671.518

F = -671.518
final  value -671.517615 
converged
 
INFO  [07:39:25.644] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:39:25.731] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:39:25.738] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:39:37.287] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:39:47.806] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:39:58.797] [mlr3]  Finished benchmark 
INFO  [07:39:58.902] [bbotk] Result of batch 161: 
INFO  [07:39:58.904] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:39:58.904] [bbotk]              3.963349                 3.206786                       0.3174305 
INFO  [07:39:58.904] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:39:58.904] [bbotk]                     4800        0.924 -0.9686342         <NA>   0.9767466 
INFO  [07:39:58.904] [bbotk]                                 uhash 
INFO  [07:39:58.904] [bbotk]  e0530c0e-c7f3-48ae-a3cc-b1478bd6d2a3 
DEBUG [07:40:01.006] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.09258e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.09258e-05 0.002633025 
  - best initial criterion value(s) :  670.7898 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -670.79  |proj g|=       3.9138
At iterate     1  f =       -700.9  |proj g|=        4.4331
At iterate     2  f =      -702.66  |proj g|=        4.7973
At iterate     3  f =      -704.94  |proj g|=        5.3275
At iterate     4  f =      -705.67  |proj g|=        5.1645
At iterate     5  f =      -705.78  |proj g|=        4.9861
At iterate     6  f =      -705.79  |proj g|=        5.0298
At iterate     7  f =      -705.79  |proj g|=        5.0331
At iterate     8  f =      -705.79  |proj g|=        5.0298
At iterate     9  f =      -705.79  |proj g|=        5.0297
At iterate    10  f =      -705.79  |proj g|=        5.0295
At iterate    11  f =       -705.8  |proj g|=        5.0293
At iterate    12  f =       -705.8  |proj g|=        5.0208
At iterate    13  f =      -705.81  |proj g|=        5.0375
At iterate    14  f =      -705.82  |proj g|=        5.0206
At iterate    15  f =      -705.88  |proj g|=        4.9784
At iterate    16  f =      -710.28  |proj g|=        4.0888
At iterate    17  f =      -719.29  |proj g|=        2.4389
At iterate    18  f =       -719.3  |proj g|=        2.5016
At iterate    19  f =      -719.31  |proj g|=        2.4972
At iterate    20  f =      -719.43  |proj g|=        2.4943
At iterate    21  f =      -719.43  |proj g|=         2.479
At iterate    22  f =      -719.43  |proj g|=        2.4832
At iterate    23  f =      -719.43  |proj g|=        2.4835
At iterate    24  f =      -719.43  |proj g|=        2.4859
At iterate    25  f =      -719.43  |proj g|=        2.4893
At iterate    26  f =      -719.43  |proj g|=        2.4902
At iterate    27  f =      -719.43  |proj g|=        2.4928
At iterate    28  f =      -719.43  |proj g|=        2.4948
At iterate    29  f =      -719.43  |proj g|=         2.495
At iterate    30  f =      -719.43  |proj g|=        2.4946
At iterate    31  f =      -719.43  |proj g|=        2.4924
At iterate    32  f =      -719.43  |proj g|=         2.489
At iterate    33  f =      -719.43  |proj g|=        2.4806
At iterate    34  f =      -719.44  |proj g|=        2.4719
At iterate    35  f =      -719.44  |proj g|=        2.4216
At iterate    36  f =      -719.45  |proj g|=        2.3729
At iterate    37  f =      -719.45  |proj g|=           2.4
At iterate    38  f =      -719.46  |proj g|=        2.4295
At iterate    39  f =      -719.48  |proj g|=        2.4773
At iterate    40  f =      -719.53  |proj g|=        2.7278
At iterate    41  f =      -719.59  |proj g|=        2.6588
At iterate    42  f =      -720.27  |proj g|=        2.8539
At iterate    43  f =      -722.35  |proj g|=        2.8809
At iterate    44  f =      -724.27  |proj g|=        2.0274
At iterate    45  f =      -726.46  |proj g|=       0.83473
At iterate    46  f =      -727.11  |proj g|=        1.5066
At iterate    47  f =      -729.42  |proj g|=       0.79538
At iterate    48  f =      -730.29  |proj g|=       0.77642
At iterate    49  f =       -730.4  |proj g|=        0.7671
At iterate    50  f =      -730.42  |proj g|=        0.4351
At iterate    51  f =      -730.42  |proj g|=        0.7632
At iterate    52  f =      -730.42  |proj g|=       0.76175
At iterate    53  f =      -730.42  |proj g|=      0.079424
At iterate    54  f =      -730.42  |proj g|=      0.028933

iterations 54
function evaluations 68
segments explored during Cauchy searches 57
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.028933
final function value -730.416

F = -730.416
final  value -730.416336 
converged
 
INFO  [07:40:01.010] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:40:01.212] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:40:01.219] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:40:12.693] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:40:21.935] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:40:33.661] [mlr3]  Finished benchmark 
INFO  [07:40:33.766] [bbotk] Result of batch 162: 
INFO  [07:40:33.768] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:40:33.768] [bbotk]              7.366654                 9.294099                       0.2027881 
INFO  [07:40:33.768] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:40:33.768] [bbotk]                     4296        0.905 -0.9577039         <NA>   0.9769634 
INFO  [07:40:33.768] [bbotk]                                 uhash 
INFO  [07:40:33.768] [bbotk]  ae5315db-53f3-44cf-9f2e-98da05f6eea0 
DEBUG [07:40:35.534] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.08499e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.08499e-05 0.002630535 
  - best initial criterion value(s) :  686.4923 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -686.49  |proj g|=       3.1755
At iterate     1  f =      -709.96  |proj g|=         3.341
At iterate     2  f =      -717.44  |proj g|=        3.9468
At iterate     3  f =      -717.89  |proj g|=        3.8931
At iterate     4  f =      -718.22  |proj g|=        3.7738
At iterate     5  f =      -718.22  |proj g|=         3.775
At iterate     6  f =      -718.22  |proj g|=         3.776
At iterate     7  f =      -718.22  |proj g|=         3.776
At iterate     8  f =      -718.22  |proj g|=        3.7759
At iterate     9  f =      -718.22  |proj g|=        3.7759
At iterate    10  f =      -718.22  |proj g|=        3.7761
At iterate    11  f =      -718.22  |proj g|=        3.7747
At iterate    12  f =      -718.22  |proj g|=        3.7773
At iterate    13  f =      -718.22  |proj g|=        3.7762
At iterate    14  f =      -718.23  |proj g|=        3.7688
At iterate    15  f =      -718.25  |proj g|=        3.7585
At iterate    16  f =      -718.29  |proj g|=        3.7344
At iterate    17  f =       -718.4  |proj g|=        3.6832
At iterate    18  f =      -718.66  |proj g|=        3.5828
At iterate    19  f =      -719.13  |proj g|=        3.4403
At iterate    20  f =      -719.97  |proj g|=        2.9066
At iterate    21  f =      -725.38  |proj g|=        1.9908
At iterate    22  f =      -731.25  |proj g|=        1.9428
At iterate    23  f =       -733.7  |proj g|=        1.7306
At iterate    24  f =      -734.38  |proj g|=        1.3177
At iterate    25  f =      -734.46  |proj g|=       0.91897
At iterate    26  f =      -734.49  |proj g|=        1.0924
At iterate    27  f =      -734.49  |proj g|=        1.0716
At iterate    28  f =      -734.49  |proj g|=        1.0649
At iterate    29  f =      -734.49  |proj g|=        1.0671
At iterate    30  f =      -734.49  |proj g|=        1.0534
At iterate    31  f =       -734.5  |proj g|=        1.0238
At iterate    32  f =      -734.55  |proj g|=        0.9432
At iterate    33  f =      -734.64  |proj g|=       0.81002
At iterate    34  f =      -734.82  |proj g|=       0.79843
At iterate    35  f =      -735.13  |proj g|=       0.79855
At iterate    36  f =      -735.51  |proj g|=       0.79051
At iterate    37  f =      -735.94  |proj g|=       0.76964
At iterate    38  f =      -735.98  |proj g|=       0.06305
At iterate    39  f =      -735.99  |proj g|=       0.23424
At iterate    40  f =      -735.99  |proj g|=      0.027994
At iterate    41  f =      -735.99  |proj g|=      0.034596

iterations 41
function evaluations 51
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0345956
final function value -735.985

F = -735.985
final  value -735.985497 
converged
 
INFO  [07:40:35.538] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:40:35.670] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:40:35.678] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:40:43.995] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:40:53.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:41:00.821] [mlr3]  Finished benchmark 
INFO  [07:41:00.925] [bbotk] Result of batch 163: 
INFO  [07:41:00.927] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:41:00.927] [bbotk]              6.409005                 3.086526                        0.202517 
INFO  [07:41:00.927] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:41:00.927] [bbotk]                     4085        0.933 -0.9573292         <NA>   0.9769587 
INFO  [07:41:00.927] [bbotk]                                 uhash 
INFO  [07:41:00.927] [bbotk]  6b7f9586-1a0d-4dae-967a-bae5dd6c4f2e 
DEBUG [07:41:02.572] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.07744e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.07744e-05 0.002629029 
  - best initial criterion value(s) :  645.0213 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -645.02  |proj g|=       4.6901
At iterate     1  f =      -648.62  |proj g|=        6.5402
At iterate     2  f =      -655.02  |proj g|=        6.6739
At iterate     3  f =      -665.16  |proj g|=         5.725
At iterate     4  f =      -666.02  |proj g|=        5.2147
At iterate     5  f =      -666.23  |proj g|=        4.8826
At iterate     6  f =       -666.5  |proj g|=        4.2294
At iterate     7  f =      -668.01  |proj g|=        4.1163
At iterate     8  f =      -686.09  |proj g|=        3.4346
At iterate     9  f =      -727.86  |proj g|=        0.9255
At iterate    10  f =      -740.26  |proj g|=       0.89195
At iterate    11  f =      -744.83  |proj g|=       0.88173
At iterate    12  f =      -750.66  |proj g|=       0.84765
At iterate    13  f =      -753.22  |proj g|=       0.81552
At iterate    14  f =       -753.3  |proj g|=       0.81221
At iterate    15  f =      -753.32  |proj g|=       0.79323
At iterate    16  f =      -753.32  |proj g|=       0.79323
At iterate    17  f =      -753.32  |proj g|=       0.79323

iterations 17
function evaluations 25
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.79323
final function value -753.321

F = -753.321
final  value -753.321273 
converged
 
INFO  [07:41:02.576] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:41:02.704] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:41:02.716] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:41:08.477] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:41:13.042] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:41:17.981] [mlr3]  Finished benchmark 
INFO  [07:41:18.114] [bbotk] Result of batch 164: 
INFO  [07:41:18.116] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:41:18.116] [bbotk]              2.442554                 5.908458                       0.0273995 
INFO  [07:41:18.116] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:41:18.116] [bbotk]                     2244        1.095 -0.9421071         <NA>   0.9302092 
INFO  [07:41:18.116] [bbotk]                                 uhash 
INFO  [07:41:18.116] [bbotk]  8c038cd7-a933-410f-8ed2-cfbf64d72a7b 
DEBUG [07:41:19.857] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.144116e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.144116e-05 0.002678848 
  - best initial criterion value(s) :  669.9657 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -669.97  |proj g|=       11.296
At iterate     1  f =      -697.56  |proj g|=        6.5528
At iterate     2  f =      -700.29  |proj g|=        6.6461
At iterate     3  f =      -702.08  |proj g|=        6.1548
At iterate     4  f =      -702.84  |proj g|=        5.7283
At iterate     5  f =       -703.1  |proj g|=        5.5476
At iterate     6  f =      -703.27  |proj g|=        5.4579
At iterate     7  f =      -703.37  |proj g|=         5.516
At iterate     8  f =      -703.38  |proj g|=        5.4594
At iterate     9  f =      -703.38  |proj g|=        5.4873
At iterate    10  f =      -703.38  |proj g|=        5.4561
At iterate    11  f =      -703.38  |proj g|=        5.4454
At iterate    12  f =      -703.39  |proj g|=        5.4249
At iterate    13  f =      -703.39  |proj g|=        5.3787
At iterate    14  f =      -703.41  |proj g|=        5.3108
At iterate    15  f =      -703.46  |proj g|=        5.1982
At iterate    16  f =       -703.6  |proj g|=        5.0042
At iterate    17  f =      -703.92  |proj g|=        4.7105
At iterate    18  f =      -704.77  |proj g|=        4.2589
At iterate    19  f =      -706.67  |proj g|=        3.4818
At iterate    20  f =      -710.63  |proj g|=        2.9792
At iterate    21  f =      -714.55  |proj g|=        2.5222
At iterate    22  f =      -742.18  |proj g|=        2.1555
At iterate    23  f =      -744.12  |proj g|=        2.1555
At iterate    24  f =      -744.96  |proj g|=        2.1555
At iterate    25  f =      -745.06  |proj g|=        2.1555
At iterate    26  f =      -745.06  |proj g|=        2.1555
At iterate    27  f =      -745.06  |proj g|=        2.1555
At iterate    28  f =      -745.06  |proj g|=        2.1555
At iterate    29  f =      -745.06  |proj g|=        2.1555
At iterate    30  f =      -745.06  |proj g|=        2.1555
At iterate    31  f =      -745.06  |proj g|=        2.1555
At iterate    32  f =      -745.07  |proj g|=        2.1555
At iterate    33  f =      -745.08  |proj g|=        2.1555
At iterate    34  f =       -745.1  |proj g|=        2.1554
At iterate    35  f =      -745.15  |proj g|=        2.1552
At iterate    36  f =      -745.28  |proj g|=        2.1546
At iterate    37  f =      -745.56  |proj g|=        2.1535
At iterate    38  f =         -746  |proj g|=        2.1516
At iterate    39  f =      -746.17  |proj g|=        2.1514
At iterate    40  f =      -746.17  |proj g|=        2.1513
At iterate    41  f =      -746.17  |proj g|=        2.1513
At iterate    42  f =      -746.17  |proj g|=        2.1513

iterations 42
function evaluations 48
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.15134
final function value -746.175

F = -746.175
final  value -746.174986 
converged
 
INFO  [07:41:19.861] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:41:19.953] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:41:19.961] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:41:27.674] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:41:35.363] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:41:40.980] [mlr3]  Finished benchmark 
INFO  [07:41:41.118] [bbotk] Result of batch 165: 
INFO  [07:41:41.120] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:41:41.120] [bbotk]               9.71018                  6.51786                       0.4899493 
INFO  [07:41:41.120] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [07:41:41.120] [bbotk]                     3554        0.931 -0.954029         <NA>   0.9773159 
INFO  [07:41:41.120] [bbotk]                                 uhash 
INFO  [07:41:41.120] [bbotk]  25d44cf5-3429-4333-a1c1-1b0f034057f5 
DEBUG [07:41:43.087] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.136772e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.136772e-05 0.002676395 
  - best initial criterion value(s) :  715.9977 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -716  |proj g|=       1.7245
At iterate     1  f =      -724.46  |proj g|=        3.0259
At iterate     2  f =      -733.02  |proj g|=        5.2521
At iterate     3  f =      -733.52  |proj g|=        5.4851
At iterate     4  f =      -734.57  |proj g|=        5.3468
At iterate     5  f =      -734.85  |proj g|=         4.753
At iterate     6  f =      -734.85  |proj g|=        4.6629
At iterate     7  f =      -734.86  |proj g|=        4.6931
At iterate     8  f =      -734.86  |proj g|=        4.6923
At iterate     9  f =      -734.86  |proj g|=        4.6868
At iterate    10  f =      -734.86  |proj g|=        4.6794
At iterate    11  f =      -734.86  |proj g|=        4.6777
At iterate    12  f =      -734.86  |proj g|=        4.6521
At iterate    13  f =      -734.86  |proj g|=        4.6479
At iterate    14  f =      -734.89  |proj g|=        4.6335
At iterate    15  f =      -735.08  |proj g|=        4.5656
At iterate    16  f =      -735.75  |proj g|=        4.3494
At iterate    17  f =       -737.9  |proj g|=        3.7629
At iterate    18  f =      -737.95  |proj g|=        3.4926
At iterate    19  f =      -743.46  |proj g|=        2.9599
At iterate    20  f =      -761.62  |proj g|=        2.2022
At iterate    21  f =      -769.87  |proj g|=       0.20186
At iterate    22  f =      -770.24  |proj g|=       0.20988
At iterate    23  f =      -770.98  |proj g|=       0.30769
At iterate    24  f =      -771.14  |proj g|=        0.7673
At iterate    25  f =      -771.18  |proj g|=       0.59501
At iterate    26  f =      -771.18  |proj g|=       0.60528
At iterate    27  f =      -771.18  |proj g|=       0.60695
At iterate    28  f =      -771.18  |proj g|=       0.60704

iterations 28
function evaluations 36
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.607044
final function value -771.184

F = -771.184
final  value -771.183778 
converged
 
INFO  [07:41:43.092] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:41:43.180] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:41:43.188] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:41:44.404] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:41:45.612] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:41:47.236] [mlr3]  Finished benchmark 
INFO  [07:41:47.364] [bbotk] Result of batch 166: 
INFO  [07:41:47.366] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:41:47.366] [bbotk]              2.904799                 5.964793                      0.09039085 
INFO  [07:41:47.366] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:41:47.366] [bbotk]                      578        1.236 -0.9467023         <NA>   0.9361649 
INFO  [07:41:47.366] [bbotk]                                 uhash 
INFO  [07:41:47.366] [bbotk]  df954767-bf94-4b0c-976b-838210305721 
DEBUG [07:41:49.075] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.180262e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.180262e-05 0.002732826 
  - best initial criterion value(s) :  695.2641 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -695.26  |proj g|=       12.905
At iterate     1  f =      -721.67  |proj g|=        10.475
At iterate     2  f =      -725.02  |proj g|=        9.1625
At iterate     3  f =      -733.86  |proj g|=        4.8112
At iterate     4  f =      -734.05  |proj g|=         4.192
At iterate     5  f =      -734.08  |proj g|=        4.2518
At iterate     6  f =      -734.08  |proj g|=        4.2352
At iterate     7  f =      -734.08  |proj g|=        4.2184
At iterate     8  f =       -734.1  |proj g|=        4.1973
At iterate     9  f =      -734.15  |proj g|=        4.1288
At iterate    10  f =      -734.25  |proj g|=        4.0299
At iterate    11  f =      -734.56  |proj g|=        3.8848
At iterate    12  f =      -735.31  |proj g|=        3.4125
At iterate    13  f =      -735.51  |proj g|=        3.6636
At iterate    14  f =      -737.13  |proj g|=        3.1609
At iterate    15  f =      -759.94  |proj g|=        3.1416
At iterate    16  f =      -763.15  |proj g|=        3.2059
At iterate    17  f =      -765.01  |proj g|=        2.8515
At iterate    18  f =      -765.94  |proj g|=        2.6735
At iterate    19  f =      -766.07  |proj g|=        3.1904
At iterate    20  f =      -766.17  |proj g|=         3.041
At iterate    21  f =      -766.18  |proj g|=        3.0269
At iterate    22  f =      -766.18  |proj g|=        3.0294
At iterate    23  f =      -766.18  |proj g|=        3.0303

iterations 23
function evaluations 29
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 3.0303
final function value -766.177

F = -766.177
final  value -766.176978 
converged
 
INFO  [07:41:49.079] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:41:49.264] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:41:49.276] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:41:52.288] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:41:55.931] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:41:58.945] [mlr3]  Finished benchmark 
INFO  [07:41:59.047] [bbotk] Result of batch 167: 
INFO  [07:41:59.049] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:41:59.049] [bbotk]              3.211264                 3.510451                       0.3295725 
INFO  [07:41:59.049] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:41:59.049] [bbotk]                     1828        1.054 -0.9526212         <NA>    0.971447 
INFO  [07:41:59.049] [bbotk]                                 uhash 
INFO  [07:41:59.049] [bbotk]  3b16275c-7c54-4ca6-8e1b-49af2bbdb358 
DEBUG [07:42:01.023] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.169567e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.169567e-05 0.002721476 
  - best initial criterion value(s) :  634.2928 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -634.29  |proj g|=       3.5823
At iterate     1  f =      -647.12  |proj g|=        8.8285
At iterate     2  f =      -674.39  |proj g|=        8.9299
At iterate     3  f =      -676.07  |proj g|=        8.4081
At iterate     4  f =      -676.16  |proj g|=        8.5691
At iterate     5  f =      -676.41  |proj g|=        8.7587
At iterate     6  f =      -677.91  |proj g|=        10.345
At iterate     7  f =      -678.35  |proj g|=        10.841
At iterate     8  f =      -681.25  |proj g|=        11.323
At iterate     9  f =      -694.71  |proj g|=        10.814
At iterate    10  f =      -695.19  |proj g|=        11.579
At iterate    11  f =      -710.64  |proj g|=        8.3981
At iterate    12  f =      -723.12  |proj g|=        7.0664
At iterate    13  f =      -731.44  |proj g|=        6.3393
At iterate    14  f =      -738.82  |proj g|=        5.4139
At iterate    15  f =      -748.19  |proj g|=        7.3273
At iterate    16  f =      -753.37  |proj g|=        7.2419
At iterate    17  f =       -753.5  |proj g|=        7.7184
At iterate    18  f =      -753.63  |proj g|=        7.2025
At iterate    19  f =      -753.63  |proj g|=        7.2735
At iterate    20  f =      -753.63  |proj g|=        7.2731
At iterate    21  f =      -753.63  |proj g|=        7.2767
At iterate    22  f =      -753.65  |proj g|=         7.284
At iterate    23  f =      -753.66  |proj g|=        7.1518
At iterate    24  f =      -753.72  |proj g|=        7.1855
At iterate    25  f =      -753.93  |proj g|=        7.2171
At iterate    26  f =      -754.41  |proj g|=        7.1473
At iterate    27  f =       -755.6  |proj g|=        6.7875
At iterate    28  f =      -758.36  |proj g|=        5.8618
At iterate    29  f =      -764.18  |proj g|=        3.7594
At iterate    30  f =      -769.14  |proj g|=        3.4726
At iterate    31  f =      -774.02  |proj g|=        1.6371
At iterate    32  f =      -775.97  |proj g|=       0.82625
At iterate    33  f =      -777.96  |proj g|=       0.22622
At iterate    34  f =      -777.98  |proj g|=       0.12723
At iterate    35  f =      -777.98  |proj g|=     0.0034614
At iterate    36  f =      -777.98  |proj g|=     0.0034614

iterations 36
function evaluations 49
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 3
norm of the final projected gradient 0.00346143
final function value -777.976

F = -777.976
final  value -777.975701 
converged
 
INFO  [07:42:01.027] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:42:01.114] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:42:01.122] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:42:04.760] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:42:08.551] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:42:12.270] [mlr3]  Finished benchmark 
INFO  [07:42:12.371] [bbotk] Result of batch 168: 
INFO  [07:42:12.388] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:42:12.388] [bbotk]              2.944544                  2.20978                      0.08557872 
INFO  [07:42:12.388] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:42:12.388] [bbotk]                     2421        1.034 -0.9385397         <NA>   0.9602175 
INFO  [07:42:12.388] [bbotk]                                 uhash 
INFO  [07:42:12.388] [bbotk]  f9767d3d-f064-4162-82f3-8fba659f34db 
DEBUG [07:42:14.609] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.162265e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  2.162265e-05 0.002713591 
  - best initial criterion value(s) :  673.3073 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -673.31  |proj g|=        7.249
At iterate     1  f =      -725.18  |proj g|=        10.147
At iterate     2  f =      -736.23  |proj g|=        8.5706
At iterate     3  f =      -749.36  |proj g|=        1.3907
At iterate     4  f =      -753.25  |proj g|=        2.9791
At iterate     5  f =      -755.22  |proj g|=        2.9011
At iterate     6  f =      -765.94  |proj g|=        2.3489
At iterate     7  f =       -767.2  |proj g|=        3.2071
At iterate     8  f =      -772.52  |proj g|=         2.609
At iterate     9  f =      -774.83  |proj g|=        2.2463
At iterate    10  f =      -774.92  |proj g|=        2.3256
At iterate    11  f =      -774.97  |proj g|=        2.4366
At iterate    12  f =      -775.02  |proj g|=        2.4747
At iterate    13  f =      -775.26  |proj g|=        2.5262
At iterate    14  f =      -776.02  |proj g|=        2.5222
At iterate    15  f =      -778.53  |proj g|=        1.9717
At iterate    16  f =      -785.05  |proj g|=       0.74029
At iterate    17  f =      -785.15  |proj g|=       0.74578
At iterate    18  f =      -785.15  |proj g|=       0.56699
At iterate    19  f =      -785.15  |proj g|=       0.27697
At iterate    20  f =      -785.15  |proj g|=       0.27697
At iterate    21  f =      -785.15  |proj g|=       0.27697
At iterate    22  f =      -785.15  |proj g|=       0.27696
At iterate    23  f =      -785.15  |proj g|=       0.38688
At iterate    24  f =      -785.15  |proj g|=       0.65966
At iterate    25  f =      -785.15  |proj g|=       0.74381
At iterate    26  f =      -785.15  |proj g|=       0.74352
At iterate    27  f =      -785.15  |proj g|=       0.74285
At iterate    28  f =      -785.15  |proj g|=        0.7416
At iterate    29  f =      -785.16  |proj g|=       0.26976
At iterate    30  f =      -785.16  |proj g|=       0.26974
At iterate    31  f =      -785.16  |proj g|=       0.26961
At iterate    32  f =      -785.16  |proj g|=       0.26903
At iterate    33  f =      -785.16  |proj g|=       0.26754
At iterate    34  f =      -785.16  |proj g|=       0.26339
At iterate    35  f =      -785.17  |proj g|=       0.25876
At iterate    36  f =      -785.18  |proj g|=       0.26124
At iterate    37  f =       -785.2  |proj g|=       0.26224
At iterate    38  f =      -785.21  |proj g|=       0.26375
At iterate    39  f =      -785.21  |proj g|=       0.26407
At iterate    40  f =      -785.23  |proj g|=       0.26516
At iterate    41  f =      -785.31  |proj g|=       0.26944
At iterate    42  f =      -785.42  |proj g|=        0.2728
At iterate    43  f =      -785.54  |proj g|=       0.27113
At iterate    44  f =      -785.72  |proj g|=        0.2608
At iterate    45  f =      -785.74  |proj g|=       0.36624
At iterate    46  f =      -785.76  |proj g|=       0.25165
At iterate    47  f =      -785.76  |proj g|=       0.03524
At iterate    48  f =      -785.76  |proj g|=     0.0054018
At iterate    49  f =      -785.76  |proj g|=     0.0025544

iterations 49
function evaluations 58
segments explored during Cauchy searches 52
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00255444
final function value -785.76

F = -785.76
final  value -785.759707 
converged
 
INFO  [07:42:14.613] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:42:14.698] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:42:14.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:42:16.839] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:42:19.078] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:42:21.372] [mlr3]  Finished benchmark 
INFO  [07:42:21.470] [bbotk] Result of batch 169: 
INFO  [07:42:21.472] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:42:21.472] [bbotk]              2.204289                  9.43306                       0.1041324 
INFO  [07:42:21.472] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:42:21.472] [bbotk]                     1401        0.937 -0.9406219         <NA>   0.9436634 
INFO  [07:42:21.472] [bbotk]                                 uhash 
INFO  [07:42:21.472] [bbotk]  ab1ab5bd-44ba-40b3-b8bc-9d5b72177f88 
DEBUG [07:42:21.543] [bbotk]  
INFO  [07:42:21.556] [bbotk] Finished optimizing after 200 evaluation(s) 
INFO  [07:42:21.558] [bbotk] Result: 
INFO  [07:42:21.560] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:42:21.560] [bbotk]              9.145589                 9.302014                       0.4436233 
INFO  [07:42:21.560] [bbotk]  ps_cboost_anneal2.mstop learner_param_vals  x_domain classif.auc 
INFO  [07:42:21.560] [bbotk]                     4968         <list[19]> <list[4]>   0.9787442 
INFO  [07:42:29.974] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2.tuned' on task 'spam' (iter 2/5) 
INFO  [07:42:30.176] [bbotk] Starting to optimize 4 parameter(s) with '<OptimizerInterMBO>' and '<TerminatorEvals> [n_evals=200]' 
DEBUG [07:42:30.247] [bbotk]  
INFO  [07:42:30.254] [bbotk] Evaluating 32 configuration(s) 
INFO  [07:42:32.856] [mlr3]  Running benchmark with 96 resampling iterations 
INFO  [07:42:32.865] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:42:39.825] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:42:44.063] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:42:45.885] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:42:48.644] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:42:49.713] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:42:57.972] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:43:05.299] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:43:12.192] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:43:21.647] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:43:24.097] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:43:29.934] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:43:35.639] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:43:45.697] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:43:49.232] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:43:58.709] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:44:05.200] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:44:07.647] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:44:08.716] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:44:13.271] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:44:21.134] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:44:23.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:44:26.485] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:44:35.596] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:44:43.479] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:44:47.963] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:44:55.156] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:44:56.772] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:44:58.671] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:45:00.660] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:45:13.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:45:16.082] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:45:24.050] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:45:26.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:45:29.538] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:45:36.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:45:38.377] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:45:48.771] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:45:59.901] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:46:09.890] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:46:17.512] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:46:28.157] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:46:32.647] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:46:35.263] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:46:38.830] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:46:43.704] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:46:48.651] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:46:55.136] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:47:01.884] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:47:10.580] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:47:12.526] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:47:14.018] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:47:19.455] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:47:23.763] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:47:27.093] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:47:30.491] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:47:40.169] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:47:47.172] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:47:54.973] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:47:57.747] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:48:05.466] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:48:15.250] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:48:18.642] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:48:27.706] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:48:31.796] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:48:33.704] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:48:42.373] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:48:48.516] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:48:59.488] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:49:02.413] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:49:05.459] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:49:06.936] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:49:15.708] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:49:27.192] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:49:32.829] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:49:34.371] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:49:37.796] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:49:44.623] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:49:55.024] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:50:02.326] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:50:08.083] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:50:17.598] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:50:24.322] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:50:29.155] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:50:33.487] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:50:45.216] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:50:46.112] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:50:56.586] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:51:04.821] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:51:10.022] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:51:14.008] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:51:20.647] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:51:27.834] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:51:33.387] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:51:38.453] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:51:43.431] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:51:49.810] [mlr3]  Finished benchmark 
INFO  [07:51:52.763] [bbotk] Result of batch 1: 
INFO  [07:51:52.766] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:51:52.766] [bbotk]              7.382588                 7.360463                      0.42052506 
INFO  [07:51:52.766] [bbotk]              7.075744                 4.194041                      0.29938892 
INFO  [07:51:52.766] [bbotk]              2.698429                 3.806669                      0.11327982 
INFO  [07:51:52.766] [bbotk]              8.537928                 8.421579                      0.35194404 
INFO  [07:51:52.766] [bbotk]              7.995831                 7.553623                      0.24205185 
INFO  [07:51:52.766] [bbotk]              4.414902                 3.398832                      0.23090601 
INFO  [07:51:52.766] [bbotk]              6.524168                 5.732777                      0.40030396 
INFO  [07:51:52.766] [bbotk]              4.625839                 2.504424                      0.42577178 
INFO  [07:51:52.766] [bbotk]              6.901985                 4.860892                      0.36031671 
INFO  [07:51:52.766] [bbotk]              5.852156                 6.223421                      0.33974574 
INFO  [07:51:52.766] [bbotk]              9.199641                 6.457382                      0.06479632 
INFO  [07:51:52.766] [bbotk]              3.536887                 6.666414                      0.19683793 
INFO  [07:51:52.766] [bbotk]              2.778027                 7.054083                      0.14560324 
INFO  [07:51:52.766] [bbotk]              8.078688                 7.920386                      0.46450949 
INFO  [07:51:52.766] [bbotk]              5.652236                 9.514397                      0.18437821 
INFO  [07:51:52.766] [bbotk]              7.704495                 4.280221                      0.25606016 
INFO  [07:51:52.766] [bbotk]              4.007327                 4.591169                      0.44662503 
INFO  [07:51:52.766] [bbotk]              8.774511                 8.142801                      0.10775924 
INFO  [07:51:52.766] [bbotk]              3.987978                 9.315324                      0.27234077 
INFO  [07:51:52.766] [bbotk]              5.306477                 5.816083                      0.08872164 
INFO  [07:51:52.766] [bbotk]              4.936174                 2.389755                      0.29300508 
INFO  [07:51:52.766] [bbotk]              2.111496                 3.652846                      0.06043182 
INFO  [07:51:52.766] [bbotk]              2.311346                 9.135144                      0.14091672 
INFO  [07:51:52.766] [bbotk]              8.483072                 2.916731                      0.01405946 
INFO  [07:51:52.766] [bbotk]              9.459723                 5.424768                      0.31929852 
INFO  [07:51:52.766] [bbotk]              9.677967                 8.739087                      0.17226956 
INFO  [07:51:52.766] [bbotk]              6.252171                 8.960882                      0.38640020 
INFO  [07:51:52.766] [bbotk]              3.359823                 6.793270                      0.48781428 
INFO  [07:51:52.766] [bbotk]              3.106875                 2.092543                      0.20932618 
INFO  [07:51:52.766] [bbotk]              6.021814                 5.162673                      0.01786507 
INFO  [07:51:52.766] [bbotk]              5.190354                 9.978139                      0.04155143 
INFO  [07:51:52.766] [bbotk]              9.822385                 3.171916                      0.47733021 
INFO  [07:51:52.766] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:51:52.766] [bbotk]  ps_cboost_anneal2.mstop classif.auc                                uhash 
INFO  [07:51:52.766] [bbotk]                     2108   0.9770077 2f85efb7-cecd-4f6c-b21e-3ce32117ca68 
INFO  [07:51:52.766] [bbotk]                     3313   0.9771886 b8d3d3e9-dee2-4bbb-9a33-46d9fc6ca439 
INFO  [07:51:52.766] [bbotk]                     1981   0.9562897 ede7bb1b-0291-4877-ab57-cf8017903146 
INFO  [07:51:52.766] [bbotk]                      735   0.9715380 19b920fa-3366-48f9-98d0-e37a0942ff74 
INFO  [07:51:52.766] [bbotk]                     3652   0.9771656 11158da4-35d7-4a77-acf8-7b33119afb12 
INFO  [07:51:52.766] [bbotk]                     2931   0.9744185 48b67ac8-1e45-4bef-8374-9a6281cbaed0 
INFO  [07:51:52.766] [bbotk]                      858   0.9725214 903e7536-21b9-48e4-b972-2cc4a9f42a8c 
INFO  [07:51:52.766] [bbotk]                      553   0.9686992 a2066034-0e77-47b8-8c0a-4e679ac1d9b9 
INFO  [07:51:52.766] [bbotk]                     4460   0.9785630 3d25504c-6658-419e-9759-844f83c50eb3 
INFO  [07:51:52.766] [bbotk]                     2335   0.9760378 d639aea7-04f1-4e94-8435-c0a0c7214783 
INFO  [07:51:52.766] [bbotk]                     3162   0.9700443 91548272-5528-4702-b0d0-944b0e8fddcb 
INFO  [07:51:52.766] [bbotk]                     4750   0.9738215 62b3ba97-d36b-4e52-ac56-1801f8778c60 
INFO  [07:51:52.766] [bbotk]                     2201   0.9615437 04e5361e-0423-45b0-9d69-e35eabc75a35 
INFO  [07:51:52.766] [bbotk]                     2640   0.9781019 44a016e5-86ff-4508-a0ce-7b398583a5f5 
INFO  [07:51:52.766] [bbotk]                     3992   0.9757055 1fef3a69-814e-46de-930e-1ddc70eddfdc 
INFO  [07:51:52.766] [bbotk]                     2834   0.9763702 c07abd67-f8c3-463c-8d1b-cb4360697926 
INFO  [07:51:52.766] [bbotk]                     1254   0.9728413 fce9492b-cc8b-4b3d-b1c9-3f8ee9509da6 
INFO  [07:51:52.766] [bbotk]                     1518   0.9681269 0cc76f09-d96f-41f9-be37-0700fa2ea690 
INFO  [07:51:52.766] [bbotk]                     1744   0.9718536 16c4872c-e052-4ab8-84c9-c5ff7ab3e410 
INFO  [07:51:52.766] [bbotk]                     1600   0.9648569 1fea81c4-a43f-430a-9691-ce6cd1aa32c3 
INFO  [07:51:52.766] [bbotk]                     4625   0.9772213 d1c961e3-0aea-4757-8910-5a1b2158899e 
INFO  [07:51:52.766] [bbotk]                     3515   0.9502691 62b5ead4-76c1-4c26-9ff7-2e56b196a933 
INFO  [07:51:52.766] [bbotk]                     3897   0.9596451 c3872857-9cd1-4bc9-b944-6d4743ee6af0 
INFO  [07:51:52.766] [bbotk]                     2517   0.9480685 4ddd4708-b721-448c-84d0-9403255668ec 
INFO  [07:51:52.766] [bbotk]                     1061   0.9732698 02b5209b-484b-4361-8ce2-5c14883f08d0 
INFO  [07:51:52.766] [bbotk]                     4101   0.9764841 89f9a7fe-aa1f-45bf-8c24-3455f2361ecb 
INFO  [07:51:52.766] [bbotk]                      245   0.9616147 23ff2be1-eb82-46b8-ab25-3d8fa7a558b5 
INFO  [07:51:52.766] [bbotk]                     4264   0.9760309 e45b4ba8-c5a6-4396-a965-b164b706290b 
INFO  [07:51:52.766] [bbotk]                     1222   0.9629460 5227e762-ad0a-4fae-adcb-45fa7a8e179a 
INFO  [07:51:52.766] [bbotk]                     4877   0.9604882 1e94feed-ed7e-48c7-9279-ca6af5aebcc9 
INFO  [07:51:52.766] [bbotk]                      476   0.9320018 93e2017b-bffa-44b5-bea5-a02c7e008121 
INFO  [07:51:52.766] [bbotk]                     3427   0.9781207 5a6358f3-13e4-4b46-b41f-494f1caeaf0f 
INFO  [07:51:52.766] [bbotk]  ps_cboost_anneal2.mstop classif.auc                                uhash 
DEBUG [07:51:53.525] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.139485e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.139485e-05 0.001271175 
  - best initial criterion value(s) :  111.6996 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -111.7  |proj g|=      0.82403
At iterate     1  f =      -116.39  |proj g|=       0.76321
At iterate     2  f =      -116.49  |proj g|=       0.76166
At iterate     3  f =       -116.6  |proj g|=       0.75571
At iterate     4  f =      -116.62  |proj g|=       0.75671
At iterate     5  f =      -116.74  |proj g|=       0.74463
At iterate     6  f =      -117.08  |proj g|=       0.68927
At iterate     7  f =      -117.17  |proj g|=       0.53263
At iterate     8  f =      -117.19  |proj g|=        0.5322
At iterate     9  f =      -117.19  |proj g|=       0.55405
At iterate    10  f =      -117.19  |proj g|=       0.55574
At iterate    11  f =      -117.19  |proj g|=       0.55652
At iterate    12  f =      -117.19  |proj g|=       0.55615
At iterate    13  f =      -117.19  |proj g|=       0.55608

iterations 13
function evaluations 19
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.556082
final function value -117.192

F = -117.192
final  value -117.192236 
converged
 
INFO  [07:51:53.529] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:51:53.620] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:51:53.627] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:51:57.267] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:52:00.786] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:52:04.318] [mlr3]  Finished benchmark 
INFO  [07:52:04.498] [bbotk] Result of batch 2: 
INFO  [07:52:04.500] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:52:04.500] [bbotk]              5.987591                 5.864937                       0.1672679 
INFO  [07:52:04.500] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:52:04.500] [bbotk]                     2240        0.484 -0.9680045         <NA>   0.9726997 
INFO  [07:52:04.500] [bbotk]                                 uhash 
INFO  [07:52:04.500] [bbotk]  baab73a0-f8b8-4a47-81ee-f46b901d5ecf 
DEBUG [07:52:05.182] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.10869e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.10869e-05 0.00124341 
  - best initial criterion value(s) :  116.1865 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -116.19  |proj g|=       1.2017
At iterate     1  f =      -118.82  |proj g|=        0.9969
At iterate     2  f =      -118.88  |proj g|=        1.1454
At iterate     3  f =      -118.91  |proj g|=        1.1157
At iterate     4  f =      -118.91  |proj g|=        1.1022
At iterate     5  f =      -118.91  |proj g|=        1.1055
At iterate     6  f =      -118.91  |proj g|=        1.1068
At iterate     7  f =      -118.91  |proj g|=        1.1068

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.10678
final function value -118.914

F = -118.914
final  value -118.913671 
converged
 
INFO  [07:52:05.186] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:52:05.276] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:52:05.283] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:52:08.587] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:52:11.957] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:52:15.364] [mlr3]  Finished benchmark 
INFO  [07:52:15.483] [bbotk] Result of batch 3: 
INFO  [07:52:15.485] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:52:15.485] [bbotk]              2.992231                 3.671332                       0.2327327 
INFO  [07:52:15.485] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:52:15.485] [bbotk]                     2177        0.496 -0.9711159         <NA>   0.9676819 
INFO  [07:52:15.485] [bbotk]                                 uhash 
INFO  [07:52:15.485] [bbotk]  0607399e-2d73-49cf-8cd7-632d35cdcc6d 
DEBUG [07:52:16.210] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.075484e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.075484e-05 0.001209028 
  - best initial criterion value(s) :  123.7905 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -123.79  |proj g|=       0.4494
At iterate     1  f =      -125.12  |proj g|=       0.65843
At iterate     2  f =      -126.01  |proj g|=       0.64217
At iterate     3  f =      -126.68  |proj g|=       0.61977
At iterate     4  f =       -126.7  |proj g|=        0.6142
At iterate     5  f =      -126.77  |proj g|=       0.59783
At iterate     6  f =      -126.98  |proj g|=       0.31267
At iterate     7  f =      -126.99  |proj g|=       0.44653
At iterate     8  f =      -126.99  |proj g|=       0.39667
At iterate     9  f =      -126.99  |proj g|=       0.35255
At iterate    10  f =      -126.99  |proj g|=       0.33884
At iterate    11  f =      -126.99  |proj g|=       0.33903

iterations 11
function evaluations 17
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.339027
final function value -126.987

F = -126.987
final  value -126.987385 
converged
 
INFO  [07:52:16.214] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:52:16.317] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:52:16.326] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:52:19.593] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:52:22.325] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:52:25.039] [mlr3]  Finished benchmark 
INFO  [07:52:25.166] [bbotk] Result of batch 4: 
INFO  [07:52:25.169] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:52:25.169] [bbotk]              6.916132                 8.252588                       0.4126776 
INFO  [07:52:25.169] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:52:25.169] [bbotk]                     1224        0.514 -0.9669363         <NA>    0.974624 
INFO  [07:52:25.169] [bbotk]                                 uhash 
INFO  [07:52:25.169] [bbotk]  8325b14f-a316-4170-a67e-09270539434e 
DEBUG [07:52:25.852] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.05354e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.05354e-05 0.001170518 
  - best initial criterion value(s) :  128.9146 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -128.91  |proj g|=      0.79602
At iterate     1  f =      -129.93  |proj g|=       0.71987
At iterate     2  f =      -130.99  |proj g|=       0.65783
At iterate     3  f =      -131.23  |proj g|=       0.61153
At iterate     4  f =      -131.29  |proj g|=       0.34662
At iterate     5  f =       -131.3  |proj g|=       0.37431
At iterate     6  f =       -131.3  |proj g|=        0.3636
At iterate     7  f =       -131.3  |proj g|=       0.36598
At iterate     8  f =       -131.3  |proj g|=        0.3661
At iterate     9  f =       -131.3  |proj g|=       0.36613

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.366125
final function value -131.299

F = -131.299
final  value -131.298505 
converged
 
INFO  [07:52:25.855] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:52:25.965] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:52:25.973] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:52:26.864] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:52:27.777] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:52:28.814] [mlr3]  Finished benchmark 
INFO  [07:52:28.918] [bbotk] Result of batch 5: 
INFO  [07:52:28.920] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:52:28.920] [bbotk]              8.613352                 9.491209                       0.1228651 
INFO  [07:52:28.920] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [07:52:28.920] [bbotk]                      247        0.482  -0.96737         <NA>   0.9452403 
INFO  [07:52:28.920] [bbotk]                                 uhash 
INFO  [07:52:28.920] [bbotk]  ce215165-55f9-4af4-8020-70cac8f9dd84 
DEBUG [07:52:29.571] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.179821e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.179821e-05 0.001360842 
  - best initial criterion value(s) :  128.2167 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -128.22  |proj g|=      0.77838
At iterate     1  f =      -128.34  |proj g|=        1.0093
At iterate     2  f =      -128.52  |proj g|=       0.95033
At iterate     3  f =      -128.65  |proj g|=       0.85686
At iterate     4  f =      -128.74  |proj g|=        0.8744
At iterate     5  f =      -128.97  |proj g|=       0.90904
At iterate     6  f =      -128.99  |proj g|=       0.94455
At iterate     7  f =      -128.99  |proj g|=       0.93436
At iterate     8  f =      -128.99  |proj g|=        0.9308
At iterate     9  f =      -128.99  |proj g|=       0.93099
At iterate    10  f =      -128.99  |proj g|=         0.931

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.931004
final function value -128.994

F = -128.994
final  value -128.993743 
converged
 
INFO  [07:52:29.575] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:52:29.666] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:52:29.674] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:52:31.516] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:52:32.977] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:52:34.640] [mlr3]  Finished benchmark 
INFO  [07:52:34.738] [bbotk] Result of batch 6: 
INFO  [07:52:34.740] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:52:34.740] [bbotk]              4.833293                 9.608076                       0.4218734 
INFO  [07:52:34.740] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:52:34.740] [bbotk]                      633        0.481 -0.9727194         <NA>   0.9698268 
INFO  [07:52:34.740] [bbotk]                                 uhash 
INFO  [07:52:34.740] [bbotk]  2ceddfc6-05ec-4ec5-b9ff-196f88c196bf 
DEBUG [07:52:35.398] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.147672e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.147672e-05 0.001311482 
  - best initial criterion value(s) :  133.5164 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -133.52  |proj g|=      0.69135
At iterate     1  f =      -133.62  |proj g|=        1.0084
At iterate     2  f =       -134.3  |proj g|=       0.92995
At iterate     3  f =      -134.74  |proj g|=       0.83735
At iterate     4  f =      -135.15  |proj g|=       0.61955
At iterate     5  f =      -135.79  |proj g|=       0.62505
At iterate     6  f =      -136.79  |proj g|=        0.5106
At iterate     7  f =      -136.93  |proj g|=       0.65189
At iterate     8  f =      -136.98  |proj g|=       0.49798
At iterate     9  f =      -136.98  |proj g|=       0.49166
At iterate    10  f =      -136.98  |proj g|=       0.62545
At iterate    11  f =      -136.98  |proj g|=       0.62572
At iterate    12  f =      -136.98  |proj g|=       0.62571

iterations 12
function evaluations 18
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.625712
final function value -136.977

F = -136.977
final  value -136.977455 
converged
 
INFO  [07:52:35.402] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:52:35.485] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:52:35.492] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:52:45.707] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:52:54.400] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:53:01.977] [mlr3]  Finished benchmark 
INFO  [07:53:02.075] [bbotk] Result of batch 7: 
INFO  [07:53:02.077] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:53:02.077] [bbotk]              7.509672                 8.648715                       0.4622157 
INFO  [07:53:02.077] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:53:02.077] [bbotk]                     3697        0.475 -0.9699252         <NA>   0.9788793 
INFO  [07:53:02.077] [bbotk]                                 uhash 
INFO  [07:53:02.077] [bbotk]  d203ecb5-33c2-4764-a111-71b10c4d1eff 
DEBUG [07:53:02.735] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.145832e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.145832e-05 0.001317016 
  - best initial criterion value(s) :  137.8646 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -137.86  |proj g|=      0.45873
At iterate     1  f =      -140.73  |proj g|=        1.1377
At iterate     2  f =      -140.92  |proj g|=        1.0684
At iterate     3  f =      -141.06  |proj g|=       0.83466
At iterate     4  f =       -141.1  |proj g|=       0.93161
At iterate     5  f =       -141.1  |proj g|=       0.92146
At iterate     6  f =      -141.14  |proj g|=       0.88818
At iterate     7  f =      -141.19  |proj g|=       0.87019
At iterate     8  f =      -141.33  |proj g|=       0.88541
At iterate     9  f =      -141.46  |proj g|=       0.96876
At iterate    10  f =      -141.51  |proj g|=        1.0501
At iterate    11  f =      -141.51  |proj g|=        1.0829
At iterate    12  f =      -141.51  |proj g|=        1.0902
At iterate    13  f =      -141.51  |proj g|=        1.0906
At iterate    14  f =      -141.51  |proj g|=        1.0906

iterations 14
function evaluations 17
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.09059
final function value -141.515

F = -141.515
final  value -141.514685 
converged
 
INFO  [07:53:02.739] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:53:02.825] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:53:02.832] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:53:05.233] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:53:07.515] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:53:10.457] [mlr3]  Finished benchmark 
INFO  [07:53:10.555] [bbotk] Result of batch 8: 
INFO  [07:53:10.556] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:53:10.556] [bbotk]              3.712777                 3.838873                      0.09007092 
INFO  [07:53:10.556] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:53:10.556] [bbotk]                      946        0.475 -0.9709225         <NA>   0.9546475 
INFO  [07:53:10.556] [bbotk]                                 uhash 
INFO  [07:53:10.556] [bbotk]  c2ae5bf4-d7b9-4d19-9026-e0bb159f3e3e 
DEBUG [07:53:11.212] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.165784e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.165784e-05 0.001347063 
  - best initial criterion value(s) :  144.9585 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -144.96  |proj g|=      0.74185
At iterate     1  f =      -145.67  |proj g|=       0.69078
At iterate     2  f =      -146.02  |proj g|=       0.69511
At iterate     3  f =      -146.41  |proj g|=       0.69546
At iterate     4  f =      -146.52  |proj g|=       0.68505
At iterate     5  f =      -146.81  |proj g|=       0.62755
At iterate     6  f =      -146.81  |proj g|=       0.46308
At iterate     7  f =      -146.82  |proj g|=       0.48446
At iterate     8  f =      -146.82  |proj g|=       0.48677
At iterate     9  f =      -146.82  |proj g|=       0.48705
At iterate    10  f =      -146.82  |proj g|=       0.48704

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.487044
final function value -146.823

F = -146.823
final  value -146.822866 
converged
 
INFO  [07:53:11.216] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:53:11.318] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:53:11.324] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:53:17.289] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:53:25.794] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:53:32.080] [mlr3]  Finished benchmark 
INFO  [07:53:32.178] [bbotk] Result of batch 9: 
INFO  [07:53:32.180] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:53:32.180] [bbotk]              7.616054                  6.10287                      0.06649949 
INFO  [07:53:32.180] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:53:32.180] [bbotk]                     2861        0.472 -0.9688223         <NA>   0.9690047 
INFO  [07:53:32.180] [bbotk]                                 uhash 
INFO  [07:53:32.180] [bbotk]  59900f74-a6c2-497e-a2e5-f9f68ca55ef3 
DEBUG [07:53:32.872] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.136028e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.136028e-05 0.001313244 
  - best initial criterion value(s) :  150.7914 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -150.79  |proj g|=      0.73396
At iterate     1  f =      -152.43  |proj g|=        0.6376
At iterate     2  f =      -152.96  |proj g|=       0.58377
At iterate     3  f =      -153.02  |proj g|=        0.5569
At iterate     4  f =      -153.03  |proj g|=       0.35632
At iterate     5  f =      -153.03  |proj g|=       0.40587
At iterate     6  f =      -153.03  |proj g|=       0.40466
At iterate     7  f =      -153.03  |proj g|=       0.39807
At iterate     8  f =      -153.03  |proj g|=       0.39684

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.396844
final function value -153.028

F = -153.028
final  value -153.028177 
converged
 
INFO  [07:53:32.876] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:53:32.965] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:53:32.972] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:53:41.178] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:53:51.711] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:53:58.751] [mlr3]  Finished benchmark 
INFO  [07:53:58.867] [bbotk] Result of batch 10: 
INFO  [07:53:58.869] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:53:58.869] [bbotk]              7.703171                 3.686009                       0.3165135 
INFO  [07:53:58.869] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:53:58.869] [bbotk]                     3716        0.504 -0.9679414         <NA>   0.9778857 
INFO  [07:53:58.869] [bbotk]                                 uhash 
INFO  [07:53:58.869] [bbotk]  9ddd17eb-0b4b-4063-91e6-0cbefc8542f1 
DEBUG [07:53:59.540] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.130102e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.130102e-05 0.001317981 
  - best initial criterion value(s) :  155.8435 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -155.84  |proj g|=      0.34379
At iterate     1  f =      -157.23  |proj g|=        0.7413
At iterate     2  f =      -157.24  |proj g|=       0.72251
At iterate     3  f =      -157.31  |proj g|=       0.63798
At iterate     4  f =      -157.39  |proj g|=       0.60611
At iterate     5  f =      -157.64  |proj g|=       0.60721
At iterate     6  f =      -157.89  |proj g|=       0.74959
At iterate     7  f =      -157.97  |proj g|=        0.8628
At iterate     8  f =      -157.98  |proj g|=       0.91639
At iterate     9  f =      -157.98  |proj g|=       0.93178
At iterate    10  f =      -157.98  |proj g|=        0.9333
At iterate    11  f =      -157.98  |proj g|=       0.93333

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.933329
final function value -157.982

F = -157.982
final  value -157.982091 
converged
 
INFO  [07:53:59.544] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:53:59.631] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:53:59.638] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:54:08.123] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:54:17.424] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:54:27.997] [mlr3]  Finished benchmark 
INFO  [07:54:28.099] [bbotk] Result of batch 11: 
INFO  [07:54:28.101] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:54:28.101] [bbotk]              2.199508                 4.686905                       0.3600102 
INFO  [07:54:28.101] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:54:28.101] [bbotk]                     4144        0.488 -0.9681303         <NA>   0.9656287 
INFO  [07:54:28.101] [bbotk]                                 uhash 
INFO  [07:54:28.101] [bbotk]  b9010fe0-469d-4aeb-a100-442a11e8c7c8 
DEBUG [07:54:28.806] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.10453e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.104529e-05 0.001288437 
  - best initial criterion value(s) :  157.3457 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -157.35  |proj g|=       0.6342
At iterate     1  f =      -159.59  |proj g|=       0.55892
At iterate     2  f =      -160.43  |proj g|=        0.5083
At iterate     3  f =       -161.1  |proj g|=       0.45676
At iterate     4  f =      -161.12  |proj g|=       0.45552
At iterate     5  f =      -161.22  |proj g|=       0.43006
At iterate     6  f =       -161.3  |proj g|=       0.58439
At iterate     7  f =       -161.3  |proj g|=        0.3699
At iterate     8  f =       -161.3  |proj g|=       0.37959
At iterate     9  f =      -161.31  |proj g|=       0.24104
At iterate    10  f =      -161.31  |proj g|=       0.23375
At iterate    11  f =      -161.31  |proj g|=       0.22161
At iterate    12  f =      -161.31  |proj g|=       0.21177
At iterate    13  f =      -161.31  |proj g|=       0.21208
At iterate    14  f =      -161.31  |proj g|=       0.21278
At iterate    15  f =      -161.31  |proj g|=       0.21171
At iterate    16  f =      -161.31  |proj g|=       0.21429
At iterate    17  f =      -161.31  |proj g|=        0.2163
At iterate    18  f =      -161.31  |proj g|=       0.49501
At iterate    19  f =      -161.31  |proj g|=       0.57617
At iterate    20  f =      -161.33  |proj g|=       0.57825
At iterate    21  f =      -161.36  |proj g|=       0.58091
At iterate    22  f =      -161.43  |proj g|=       0.58572
At iterate    23  f =      -161.54  |proj g|=        0.5984
At iterate    24  f =      -161.55  |proj g|=       0.60795
At iterate    25  f =      -161.64  |proj g|=       0.61784
At iterate    26  f =      -161.74  |proj g|=       0.36117
At iterate    27  f =      -161.78  |proj g|=       0.14862
At iterate    28  f =      -161.79  |proj g|=       0.16683
At iterate    29  f =      -161.79  |proj g|=       0.13786
At iterate    30  f =      -161.79  |proj g|=       0.12228
At iterate    31  f =      -161.79  |proj g|=       0.12226

iterations 31
function evaluations 40
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.122263
final function value -161.791

F = -161.791
final  value -161.791419 
converged
 
INFO  [07:54:28.810] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:54:28.901] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:54:28.908] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:54:39.138] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:54:49.836] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:55:02.442] [mlr3]  Finished benchmark 
INFO  [07:55:02.553] [bbotk] Result of batch 12: 
INFO  [07:55:02.555] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:55:02.555] [bbotk]              2.255571                 8.294278                       0.1683241 
INFO  [07:55:02.555] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:55:02.555] [bbotk]                     4370        0.494 -0.9654671         <NA>   0.9611666 
INFO  [07:55:02.555] [bbotk]                                 uhash 
INFO  [07:55:02.555] [bbotk]  18067121-4bfb-4e1a-989a-072ad288f7ea 
DEBUG [07:55:03.264] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.090574e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.090574e-05 0.001256542 
  - best initial criterion value(s) :  161.5195 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -161.52  |proj g|=       2.3562
At iterate     1  f =      -161.63  |proj g|=        2.5087
At iterate     2  f =      -161.85  |proj g|=        2.3467
At iterate     3  f =      -162.38  |proj g|=        1.5169
At iterate     4  f =      -162.39  |proj g|=        1.6413
At iterate     5  f =      -162.39  |proj g|=        1.6243
At iterate     6  f =      -162.39  |proj g|=        1.6238
At iterate     7  f =      -162.39  |proj g|=        1.6232
At iterate     8  f =      -162.39  |proj g|=        1.6214
At iterate     9  f =      -162.39  |proj g|=        1.6164
At iterate    10  f =      -162.39  |proj g|=        1.6058
At iterate    11  f =       -162.4  |proj g|=        1.5901
At iterate    12  f =       -162.4  |proj g|=        1.5623
At iterate    13  f =       -162.4  |proj g|=        1.5375
At iterate    14  f =      -162.41  |proj g|=        1.5028
At iterate    15  f =      -162.45  |proj g|=        1.4332
At iterate    16  f =      -162.53  |proj g|=         1.324
At iterate    17  f =      -162.77  |proj g|=        1.1341
At iterate    18  f =      -163.37  |proj g|=       0.85247
At iterate    19  f =      -163.87  |proj g|=       0.67723
At iterate    20  f =      -165.52  |proj g|=       0.65962
At iterate    21  f =      -166.54  |proj g|=       0.63206
At iterate    22  f =      -167.13  |proj g|=       0.59912
At iterate    23  f =      -167.15  |proj g|=       0.58401
At iterate    24  f =      -167.15  |proj g|=       0.26811
At iterate    25  f =      -167.15  |proj g|=       0.02057
At iterate    26  f =      -167.16  |proj g|=      0.011538
At iterate    27  f =      -167.16  |proj g|=      0.011501

iterations 27
function evaluations 35
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0115012
final function value -167.155

F = -167.155
final  value -167.155011 
converged
 
INFO  [07:55:03.269] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:55:03.357] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:55:03.365] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:55:05.022] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:55:06.412] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:55:07.940] [mlr3]  Finished benchmark 
INFO  [07:55:08.063] [bbotk] Result of batch 13: 
INFO  [07:55:08.066] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:55:08.066] [bbotk]              7.872955                 8.994652                       0.3659785 
INFO  [07:55:08.066] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:55:08.066] [bbotk]                      547        0.502 -0.9643717         <NA>   0.9695447 
INFO  [07:55:08.066] [bbotk]                                 uhash 
INFO  [07:55:08.066] [bbotk]  97164d49-0bba-4928-b1f2-15ef7b7b03c3 
DEBUG [07:55:08.783] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.065574e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.065574e-05 0.001211036 
  - best initial criterion value(s) :  168.0753 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -168.08  |proj g|=      0.95872
At iterate     1  f =      -169.43  |proj g|=       0.65691
At iterate     2  f =      -169.97  |proj g|=       0.88688
At iterate     3  f =      -170.02  |proj g|=       0.89967
At iterate     4  f =      -170.03  |proj g|=       0.90707
At iterate     5  f =      -170.03  |proj g|=       0.90885
At iterate     6  f =      -170.03  |proj g|=       0.90984
At iterate     7  f =      -170.03  |proj g|=       0.91039
At iterate     8  f =      -170.03  |proj g|=       0.91088
At iterate     9  f =      -170.03  |proj g|=       0.91289
At iterate    10  f =      -170.03  |proj g|=       0.91332
At iterate    11  f =      -170.07  |proj g|=       0.89868
At iterate    12  f =      -170.27  |proj g|=       0.78812
At iterate    13  f =      -170.72  |proj g|=       0.52725
At iterate    14  f =      -171.19  |proj g|=       0.47808
At iterate    15  f =      -171.19  |proj g|=       0.47826
At iterate    16  f =      -171.62  |proj g|=       0.46956
At iterate    17  f =      -171.86  |proj g|=         0.522
At iterate    18  f =      -171.88  |proj g|=        0.5344
At iterate    19  f =       -171.9  |proj g|=       0.42684
At iterate    20  f =       -171.9  |proj g|=       0.10306
At iterate    21  f =       -171.9  |proj g|=       0.31506
At iterate    22  f =       -171.9  |proj g|=       0.10372
At iterate    23  f =       -171.9  |proj g|=       0.10406
At iterate    24  f =       -171.9  |proj g|=       0.10372
At iterate    25  f =       -171.9  |proj g|=        0.1037

iterations 25
function evaluations 34
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.103696
final function value -171.903

F = -171.903
final  value -171.903417 
converged
 
INFO  [07:55:08.788] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:55:08.882] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:55:08.889] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:55:09.729] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:55:10.597] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:55:11.626] [mlr3]  Finished benchmark 
INFO  [07:55:11.727] [bbotk] Result of batch 14: 
INFO  [07:55:11.729] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:55:11.729] [bbotk]              9.770236                  8.80219                       0.1055842 
INFO  [07:55:11.729] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:55:11.729] [bbotk]                      265        0.495 -0.9658927         <NA>    0.944526 
INFO  [07:55:11.729] [bbotk]                                 uhash 
INFO  [07:55:11.729] [bbotk]  98bd4466-4773-4953-9e63-823104cf7708 
DEBUG [07:55:12.430] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.167073e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.167073e-05 0.001356434 
  - best initial criterion value(s) :  171.2144 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -171.21  |proj g|=      0.61795
At iterate     1  f =      -175.19  |proj g|=       0.66038
At iterate     2  f =      -175.23  |proj g|=       0.65861
At iterate     3  f =      -175.28  |proj g|=       0.65344
At iterate     4  f =      -175.37  |proj g|=       0.64404
At iterate     5  f =      -175.74  |proj g|=       0.59238
At iterate     6  f =      -175.74  |proj g|=       0.57447
At iterate     7  f =      -175.89  |proj g|=       0.46499
At iterate     8  f =       -175.9  |proj g|=        0.4181
At iterate     9  f =       -175.9  |proj g|=       0.42776
At iterate    10  f =       -175.9  |proj g|=       0.42782
At iterate    11  f =       -175.9  |proj g|=        0.4278
At iterate    12  f =       -175.9  |proj g|=       0.42779

iterations 12
function evaluations 16
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.427795
final function value -175.896

F = -175.896
final  value -175.895920 
converged
 
INFO  [07:55:12.434] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:55:12.556] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:55:12.563] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:55:13.340] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:55:14.082] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:55:15.174] [mlr3]  Finished benchmark 
INFO  [07:55:15.280] [bbotk] Result of batch 15: 
INFO  [07:55:15.282] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:55:15.282] [bbotk]              6.169472                  5.60687                       0.0677412 
INFO  [07:55:15.282] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:55:15.282] [bbotk]                      203        0.514 -0.9648512         <NA>    0.927221 
INFO  [07:55:15.282] [bbotk]                                 uhash 
INFO  [07:55:15.282] [bbotk]  84adb02b-186a-4654-ad86-581947f44c0a 
DEBUG [07:55:16.043] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.498797e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9348 
  - variance bounds :  1.498797e-05 0.001826199 
  - best initial criterion value(s) :  165.5556 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -165.56  |proj g|=      0.78391
At iterate     1  f =      -167.04  |proj g|=       0.45258
At iterate     2  f =      -168.14  |proj g|=       0.43907
At iterate     3  f =      -168.32  |proj g|=       0.41059
At iterate     4  f =      -168.56  |proj g|=       0.34786
At iterate     5  f =      -168.59  |proj g|=       0.30108
At iterate     6  f =       -168.6  |proj g|=        0.3224
At iterate     7  f =       -168.6  |proj g|=       0.31879
At iterate     8  f =       -168.6  |proj g|=       0.31888
At iterate     9  f =       -168.6  |proj g|=       0.31889

iterations 9
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.318889
final function value -168.601

F = -168.601
final  value -168.601184 
converged
 
INFO  [07:55:16.045] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:55:16.124] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:55:16.131] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:55:22.136] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:55:28.284] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:55:34.408] [mlr3]  Finished benchmark 
INFO  [07:55:34.562] [bbotk] Result of batch 16: 
INFO  [07:55:34.564] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:55:34.564] [bbotk]              2.212588                 4.137776                       0.2084466 
INFO  [07:55:34.564] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:55:34.564] [bbotk]                     3676        0.568 -0.9715241         <NA>   0.9610491 
INFO  [07:55:34.564] [bbotk]                                 uhash 
INFO  [07:55:34.564] [bbotk]  29d61dbb-7eda-4055-aa2f-9576e7a6409c 
DEBUG [07:55:35.542] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.4735e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9348 
  - variance bounds :  1.4735e-05 0.001793371 
  - best initial criterion value(s) :  176.7737 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -176.77  |proj g|=      0.73547
At iterate     1  f =      -177.33  |proj g|=       0.52455
At iterate     2  f =      -178.76  |proj g|=       0.51044
At iterate     3  f =      -180.18  |proj g|=       0.31229
At iterate     4  f =      -180.18  |proj g|=       0.32469
At iterate     5  f =      -180.18  |proj g|=       0.27551
At iterate     6  f =      -180.18  |proj g|=       0.27578
At iterate     7  f =      -180.18  |proj g|=       0.27577

iterations 7
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.275772
final function value -180.185

F = -180.185
final  value -180.184695 
converged
 
INFO  [07:55:35.547] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:55:35.648] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:55:35.657] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:55:40.972] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:55:46.141] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:55:51.717] [mlr3]  Finished benchmark 
INFO  [07:55:51.837] [bbotk] Result of batch 17: 
INFO  [07:55:51.839] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:55:51.839] [bbotk]              5.580936                 3.853637                      0.06793677 
INFO  [07:55:51.839] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:55:51.839] [bbotk]                     3235         0.73 -0.9648242         <NA>   0.9690936 
INFO  [07:55:51.839] [bbotk]                                 uhash 
INFO  [07:55:51.839] [bbotk]  e5431be4-e986-49ab-95e6-5cb2cc34c297 
DEBUG [07:55:52.544] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.443268e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9348 
  - variance bounds :  1.443268e-05 0.0017686 
  - best initial criterion value(s) :  178.5174 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -178.52  |proj g|=      0.56399
At iterate     1  f =      -179.35  |proj g|=       0.58093
At iterate     2  f =      -179.73  |proj g|=       0.53338
At iterate     3  f =       -180.2  |proj g|=       0.50257
At iterate     4  f =      -180.57  |proj g|=       0.57668
At iterate     5  f =      -180.58  |proj g|=        0.5875
At iterate     6  f =      -180.58  |proj g|=       0.60282
At iterate     7  f =      -180.58  |proj g|=       0.58884
At iterate     8  f =      -180.58  |proj g|=       0.58884

iterations 8
function evaluations 13
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.588837
final function value -180.581

F = -180.581
final  value -180.581364 
converged
 
INFO  [07:55:52.549] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:55:52.640] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:55:52.647] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:55:58.985] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:56:05.397] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:56:11.824] [mlr3]  Finished benchmark 
INFO  [07:56:11.981] [bbotk] Result of batch 18: 
INFO  [07:56:11.983] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:56:11.983] [bbotk]              4.661103                 6.390652                       0.2812383 
INFO  [07:56:11.983] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:56:11.983] [bbotk]                     3922        0.508 -0.9684145         <NA>   0.9765752 
INFO  [07:56:11.983] [bbotk]                                 uhash 
INFO  [07:56:11.983] [bbotk]  531c6367-332f-4a91-90b0-bf5fcdeacce4 
DEBUG [07:56:12.697] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.432603e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9348 
  - variance bounds :  1.432603e-05 0.001768798 
  - best initial criterion value(s) :  178.9594 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -178.96  |proj g|=       1.4486
At iterate     1  f =      -180.03  |proj g|=        1.6011
At iterate     2  f =      -183.08  |proj g|=        1.3318
At iterate     3  f =      -183.19  |proj g|=        1.3789
At iterate     4  f =       -183.2  |proj g|=        1.3734
At iterate     5  f =      -183.21  |proj g|=        1.3543
At iterate     6  f =      -183.21  |proj g|=        1.3537
At iterate     7  f =      -183.21  |proj g|=        1.3538
At iterate     8  f =      -183.21  |proj g|=        1.3538

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.35379
final function value -183.211

F = -183.211
final  value -183.210696 
converged
 
INFO  [07:56:12.701] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:56:12.792] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:56:12.799] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:56:21.051] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:56:29.782] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:56:41.786] [mlr3]  Finished benchmark 
INFO  [07:56:41.890] [bbotk] Result of batch 19: 
INFO  [07:56:41.892] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:56:41.892] [bbotk]                4.7342                 5.480481                      0.08036977 
INFO  [07:56:41.892] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:56:41.892] [bbotk]                     4998         0.53 -0.9653363         <NA>    0.972245 
INFO  [07:56:41.892] [bbotk]                                 uhash 
INFO  [07:56:41.892] [bbotk]  580e5a92-4926-470c-a578-4eae9e164803 
DEBUG [07:56:42.660] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.408819e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9590 
  - variance bounds :  1.408819e-05 0.001739921 
  - best initial criterion value(s) :  176.4264 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -176.43  |proj g|=         1.05
At iterate     1  f =      -180.54  |proj g|=       0.68996
At iterate     2  f =      -181.67  |proj g|=       0.66987
At iterate     3  f =      -184.11  |proj g|=       0.65315
At iterate     4  f =      -184.56  |proj g|=       0.62656
At iterate     5  f =      -185.53  |proj g|=       0.53777
At iterate     6  f =       -187.1  |proj g|=       0.69475
At iterate     7  f =      -187.18  |proj g|=       0.50083
At iterate     8  f =      -187.41  |proj g|=       0.49261
At iterate     9  f =      -187.44  |proj g|=       0.48058
At iterate    10  f =      -187.46  |proj g|=       0.64292
At iterate    11  f =      -187.46  |proj g|=       0.48576
At iterate    12  f =      -187.46  |proj g|=       0.48589
At iterate    13  f =      -187.46  |proj g|=       0.48593
At iterate    14  f =      -187.46  |proj g|=       0.48594
At iterate    15  f =      -187.46  |proj g|=       0.48597
At iterate    16  f =      -187.46  |proj g|=        0.4931
At iterate    17  f =      -187.46  |proj g|=       0.53275
At iterate    18  f =      -187.46  |proj g|=       0.64534
At iterate    19  f =      -187.46  |proj g|=       0.64578
At iterate    20  f =      -187.46  |proj g|=       0.64738
At iterate    21  f =      -187.46  |proj g|=       0.64938
At iterate    22  f =      -187.47  |proj g|=        0.6529
At iterate    23  f =      -187.48  |proj g|=       0.65825
At iterate    24  f =       -187.5  |proj g|=       0.66743
At iterate    25  f =      -187.56  |proj g|=       0.67511
At iterate    26  f =      -187.68  |proj g|=       0.68344
At iterate    27  f =      -187.76  |proj g|=       0.37778
At iterate    28  f =      -188.19  |proj g|=       0.67614
At iterate    29  f =      -188.24  |proj g|=       0.30748
At iterate    30  f =      -188.24  |proj g|=       0.30908
At iterate    31  f =      -188.24  |proj g|=       0.30913
At iterate    32  f =      -188.24  |proj g|=       0.30917

iterations 32
function evaluations 42
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.309174
final function value -188.24

F = -188.24
final  value -188.240220 
converged
 
INFO  [07:56:42.664] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:56:42.782] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:56:42.793] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:56:48.403] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:56:53.878] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:56:58.710] [mlr3]  Finished benchmark 
INFO  [07:56:58.813] [bbotk] Result of batch 20: 
INFO  [07:56:58.815] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:56:58.815] [bbotk]              9.113906                 6.932357                        0.183599 
INFO  [07:56:58.815] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:56:58.815] [bbotk]                     2302        0.522 -0.9698094         <NA>   0.9745353 
INFO  [07:56:58.815] [bbotk]                                 uhash 
INFO  [07:56:58.815] [bbotk]  0fc0f343-d7de-464a-8e67-6fcfce767845 
DEBUG [07:56:59.528] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.391401e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9590 
  - variance bounds :  1.391401e-05 0.001732248 
  - best initial criterion value(s) :  192.9166 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -192.92  |proj g|=        1.247
At iterate     1  f =      -196.67  |proj g|=       0.68965
At iterate     2  f =      -196.84  |proj g|=       0.68728
At iterate     3  f =      -196.97  |proj g|=       0.68107
At iterate     4  f =         -197  |proj g|=       0.68127
At iterate     5  f =      -197.05  |proj g|=       0.67929
At iterate     6  f =      -197.23  |proj g|=       0.66788
At iterate     7  f =      -197.49  |proj g|=       0.64328
At iterate     8  f =      -197.77  |proj g|=       0.60606
At iterate     9  f =      -197.88  |proj g|=       0.57995
At iterate    10  f =       -197.9  |proj g|=         0.522
At iterate    11  f =       -197.9  |proj g|=        0.5178
At iterate    12  f =       -197.9  |proj g|=       0.51759
At iterate    13  f =       -197.9  |proj g|=       0.51773
At iterate    14  f =       -197.9  |proj g|=       0.51767

iterations 14
function evaluations 17
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.517675
final function value -197.903

F = -197.903
final  value -197.903186 
converged
 
INFO  [07:56:59.532] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:57:00.038] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:57:00.045] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:57:04.011] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:57:11.655] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:57:15.682] [mlr3]  Finished benchmark 
INFO  [07:57:15.808] [bbotk] Result of batch 21: 
INFO  [07:57:15.810] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:57:15.810] [bbotk]              9.263302                 8.162353                       0.4962336 
INFO  [07:57:15.810] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:57:15.810] [bbotk]                     1989        0.522 -0.9644919         <NA>   0.9775516 
INFO  [07:57:15.810] [bbotk]                                 uhash 
INFO  [07:57:15.810] [bbotk]  234bde72-eda8-4b41-af81-6fef19fe7497 
DEBUG [07:57:16.523] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.384435e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.384435e-05 0.001735165 
  - best initial criterion value(s) :  191.3301 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -191.33  |proj g|=      0.67885
At iterate     1  f =       -191.4  |proj g|=         0.317
At iterate     2  f =      -191.45  |proj g|=        0.3157
At iterate     3  f =      -191.46  |proj g|=       0.31586
At iterate     4  f =      -191.46  |proj g|=       0.31585
At iterate     5  f =      -191.46  |proj g|=       0.31585
At iterate     6  f =      -191.46  |proj g|=       0.31585

iterations 6
function evaluations 9
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.315851
final function value -191.455

F = -191.455
final  value -191.455468 
converged
 
INFO  [07:57:16.527] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:57:16.612] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:57:16.619] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:57:21.531] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:57:30.418] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:57:34.804] [mlr3]  Finished benchmark 
INFO  [07:57:34.902] [bbotk] Result of batch 22: 
INFO  [07:57:34.904] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:57:34.904] [bbotk]              7.156222                 3.271565                       0.2019465 
INFO  [07:57:34.904] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:57:34.904] [bbotk]                     2073        0.529 -0.9725509         <NA>   0.9737329 
INFO  [07:57:34.904] [bbotk]                                 uhash 
INFO  [07:57:34.904] [bbotk]  680fe2fa-7ce6-4ef8-b7d0-ba8337885fa6 
DEBUG [07:57:35.655] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.36521e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.36521e-05 0.001725219 
  - best initial criterion value(s) :  196.7965 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -196.8  |proj g|=       1.8953
At iterate     1  f =      -198.84  |proj g|=          2.01
At iterate     2  f =      -199.12  |proj g|=        1.9877
At iterate     3  f =      -199.82  |proj g|=        1.8021
At iterate     4  f =      -199.98  |proj g|=        1.8364
At iterate     5  f =      -200.06  |proj g|=        1.8185
At iterate     6  f =      -200.08  |proj g|=        1.7936
At iterate     7  f =      -200.08  |proj g|=        1.7916
At iterate     8  f =      -200.08  |proj g|=        1.7888
At iterate     9  f =      -200.08  |proj g|=        1.7885
At iterate    10  f =      -200.08  |proj g|=         1.788
At iterate    11  f =      -200.08  |proj g|=        1.7858
At iterate    12  f =      -200.08  |proj g|=        1.7823
At iterate    13  f =      -200.09  |proj g|=        1.7769
At iterate    14  f =       -200.1  |proj g|=        1.7517
At iterate    15  f =      -200.11  |proj g|=        1.7426
At iterate    16  f =      -200.14  |proj g|=        1.7331
At iterate    17  f =      -200.26  |proj g|=        1.6871
At iterate    18  f =      -200.46  |proj g|=        1.6088
At iterate    19  f =      -201.31  |proj g|=        1.3053
At iterate    20  f =      -203.08  |proj g|=       0.88521
At iterate    21  f =      -206.23  |proj g|=        0.6232
At iterate    22  f =      -207.27  |proj g|=       0.95124
At iterate    23  f =      -207.31  |proj g|=       0.99177
At iterate    24  f =      -207.34  |proj g|=        1.0374
At iterate    25  f =      -207.35  |proj g|=        1.0215
At iterate    26  f =      -207.36  |proj g|=       0.96662
At iterate    27  f =      -207.36  |proj g|=       0.96727
At iterate    28  f =      -207.36  |proj g|=       0.96696

iterations 28
function evaluations 33
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.966958
final function value -207.356

F = -207.356
final  value -207.355621 
converged
 
INFO  [07:57:35.659] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:57:35.760] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:57:35.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:57:37.883] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:57:41.074] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:57:43.324] [mlr3]  Finished benchmark 
INFO  [07:57:43.423] [bbotk] Result of batch 23: 
INFO  [07:57:43.425] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:57:43.425] [bbotk]              8.428872                 4.642203                       0.4442623 
INFO  [07:57:43.425] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [07:57:43.425] [bbotk]                     1010        0.539 -0.964013         <NA>     0.97459 
INFO  [07:57:43.425] [bbotk]                                 uhash 
INFO  [07:57:43.425] [bbotk]  7785b832-61c0-433a-bf48-163ea014f576 
DEBUG [07:57:44.157] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.348528e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.348528e-05 0.001678941 
  - best initial criterion value(s) :  192.1271 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -192.13  |proj g|=      0.82661
At iterate     1  f =      -198.43  |proj g|=       0.81362
At iterate     2  f =      -199.72  |proj g|=       0.55981
At iterate     3  f =      -200.05  |proj g|=       0.54354
At iterate     4  f =      -200.28  |proj g|=       0.52502
At iterate     5  f =      -200.34  |proj g|=       0.51771
At iterate     6  f =      -200.36  |proj g|=       0.52354
At iterate     7  f =      -200.37  |proj g|=       0.52571
At iterate     8  f =      -200.37  |proj g|=       0.52578
At iterate     9  f =      -200.37  |proj g|=       0.52577

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.525769
final function value -200.365

F = -200.365
final  value -200.365358 
converged
 
INFO  [07:57:44.161] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:57:44.248] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:57:44.255] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:57:53.751] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:58:02.226] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:58:10.148] [mlr3]  Finished benchmark 
INFO  [07:58:10.271] [bbotk] Result of batch 24: 
INFO  [07:58:10.273] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:58:10.273] [bbotk]              6.336593                 3.491461                       0.1580893 
INFO  [07:58:10.273] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:58:10.273] [bbotk]                     3788        0.541 -0.9724927         <NA>   0.9751151 
INFO  [07:58:10.273] [bbotk]                                 uhash 
INFO  [07:58:10.273] [bbotk]  9002f447-675c-48f4-a50e-0f010b950d4f 
DEBUG [07:58:11.029] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.333503e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.333503e-05 0.001669296 
  - best initial criterion value(s) :  209.0441 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -209.04  |proj g|=      0.95802
At iterate     1  f =      -211.38  |proj g|=        2.2993
At iterate     2  f =      -211.47  |proj g|=        2.2123
At iterate     3  f =      -211.59  |proj g|=        2.0077
At iterate     4  f =      -211.91  |proj g|=        1.7716
At iterate     5  f =      -212.77  |proj g|=        1.3066
At iterate     6  f =      -213.15  |proj g|=        1.4423
At iterate     7  f =      -213.17  |proj g|=        1.5412
At iterate     8  f =      -213.17  |proj g|=        1.5161
At iterate     9  f =      -213.17  |proj g|=        1.5142
At iterate    10  f =      -213.17  |proj g|=        1.5142

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.51419
final function value -213.173

F = -213.173
final  value -213.172572 
converged
 
INFO  [07:58:11.033] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:58:11.121] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:58:11.128] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:58:18.174] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:58:23.768] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:58:30.165] [mlr3]  Finished benchmark 
INFO  [07:58:30.265] [bbotk] Result of batch 25: 
INFO  [07:58:30.267] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:58:30.267] [bbotk]              9.157503                 4.163937                      0.01991887 
INFO  [07:58:30.267] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:58:30.267] [bbotk]                     2648        0.562 -0.9669959         <NA>   0.9555889 
INFO  [07:58:30.267] [bbotk]                                 uhash 
INFO  [07:58:30.267] [bbotk]  75a61101-2a91-42f4-802a-a40c4bcd4e10 
DEBUG [07:58:31.197] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.336116e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.336116e-05 0.00165902 
  - best initial criterion value(s) :  209.1882 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -209.19  |proj g|=       1.1844
At iterate     1  f =      -215.63  |proj g|=       0.96582
At iterate     2  f =       -216.2  |proj g|=       0.91275
At iterate     3  f =      -216.89  |proj g|=       0.79158
At iterate     4  f =      -217.09  |proj g|=       0.69207
At iterate     5  f =      -217.94  |proj g|=       0.68072
At iterate     6  f =      -217.99  |proj g|=        0.7017
At iterate     7  f =      -218.04  |proj g|=       0.69667
At iterate     8  f =      -218.05  |proj g|=       0.69101
At iterate     9  f =      -218.05  |proj g|=       0.69515
At iterate    10  f =      -218.05  |proj g|=       0.69416
At iterate    11  f =      -218.05  |proj g|=       0.69415

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.694148
final function value -218.045

F = -218.045
final  value -218.045296 
converged
 
INFO  [07:58:31.201] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:58:31.290] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:58:31.314] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:58:37.239] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:58:42.998] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:58:48.483] [mlr3]  Finished benchmark 
INFO  [07:58:48.583] [bbotk] Result of batch 26: 
INFO  [07:58:48.585] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:58:48.585] [bbotk]              5.339034                 2.638189                       0.2047654 
INFO  [07:58:48.585] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:58:48.585] [bbotk]                     2468        0.731 -0.9651906         <NA>   0.9738917 
INFO  [07:58:48.585] [bbotk]                                 uhash 
INFO  [07:58:48.585] [bbotk]  b6f7ee14-ffe5-4580-87b0-ae05688b3b27 
DEBUG [07:58:49.285] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.319127e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.319127e-05 0.001647771 
  - best initial criterion value(s) :  222.1157 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -222.12  |proj g|=      0.64143
At iterate     1  f =       -222.3  |proj g|=       0.72307
At iterate     2  f =      -222.31  |proj g|=       0.71998
At iterate     3  f =      -222.34  |proj g|=        0.7122
At iterate     4  f =      -222.35  |proj g|=       0.71753
At iterate     5  f =      -222.36  |proj g|=        0.7265
At iterate     6  f =      -222.36  |proj g|=       0.72957
At iterate     7  f =      -222.36  |proj g|=       0.73011
At iterate     8  f =      -222.36  |proj g|=       0.73011

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.730111
final function value -222.358

F = -222.358
final  value -222.357944 
converged
 
INFO  [07:58:49.289] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:58:49.377] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:58:49.384] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:58:51.897] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:58:53.997] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:58:56.215] [mlr3]  Finished benchmark 
INFO  [07:58:56.571] [bbotk] Result of batch 27: 
INFO  [07:58:56.573] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:58:56.573] [bbotk]              7.632305                 9.113243                       0.1727899 
INFO  [07:58:56.573] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:58:56.573] [bbotk]                      991        0.512 -0.9656113         <NA>   0.9681434 
INFO  [07:58:56.573] [bbotk]                                 uhash 
INFO  [07:58:56.573] [bbotk]  fc1d58de-5847-4c4d-972a-a5e25dd6fa4e 
DEBUG [07:58:57.286] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.296012e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.296012e-05 0.001602491 
  - best initial criterion value(s) :  221.361 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -221.36  |proj g|=      0.88393
At iterate     1  f =      -222.62  |proj g|=        1.9036
At iterate     2  f =         -224  |proj g|=        1.6233
At iterate     3  f =      -224.72  |proj g|=        1.2783
At iterate     4  f =      -224.82  |proj g|=        1.0834
At iterate     5  f =      -225.03  |proj g|=        1.2345
At iterate     6  f =       -225.3  |proj g|=         1.381
At iterate     7  f =      -225.33  |proj g|=        1.4092
At iterate     8  f =      -225.33  |proj g|=        1.4206
At iterate     9  f =      -225.33  |proj g|=        1.4177
At iterate    10  f =      -225.33  |proj g|=        1.4179

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.41789
final function value -225.333

F = -225.333
final  value -225.333237 
converged
 
INFO  [07:58:57.290] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:58:57.409] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:58:57.416] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:59:04.127] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:59:13.833] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:59:19.066] [mlr3]  Finished benchmark 
INFO  [07:59:19.168] [bbotk] Result of batch 28: 
INFO  [07:59:19.170] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:59:19.170] [bbotk]              7.490481                 4.179333                       0.4887853 
INFO  [07:59:19.170] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:59:19.170] [bbotk]                     2450        0.521 -0.9632807         <NA>   0.9778694 
INFO  [07:59:19.170] [bbotk]                                 uhash 
INFO  [07:59:19.170] [bbotk]  55aa1df2-79c3-42c2-9c0b-ff2098a13fc8 
DEBUG [07:59:19.913] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.29102e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.29102e-05 0.001609287 
  - best initial criterion value(s) :  225.2836 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -225.28  |proj g|=       1.4261
At iterate     1  f =      -225.64  |proj g|=        1.3672
At iterate     2  f =      -225.67  |proj g|=         1.373
At iterate     3  f =      -225.67  |proj g|=        1.3735
At iterate     4  f =      -225.67  |proj g|=        1.3736
At iterate     5  f =      -225.67  |proj g|=        1.3736

iterations 5
function evaluations 8
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.37357
final function value -225.673

F = -225.673
final  value -225.673470 
converged
 
INFO  [07:59:19.918] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:59:20.009] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:59:20.018] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:59:22.640] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:59:25.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:59:27.854] [mlr3]  Finished benchmark 
INFO  [07:59:27.964] [bbotk] Result of batch 29: 
INFO  [07:59:27.966] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:59:27.966] [bbotk]               3.85524                 6.655068                       0.1490753 
INFO  [07:59:27.966] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:59:27.966] [bbotk]                     1544        0.547 -0.9689003         <NA>   0.9664815 
INFO  [07:59:27.966] [bbotk]                                 uhash 
INFO  [07:59:27.966] [bbotk]  a86b257d-2ea1-46bf-be97-a549be662c7b 
DEBUG [07:59:28.814] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.269485e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.269485e-05 0.001573611 
  - best initial criterion value(s) :  225.1871 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -225.19  |proj g|=        2.141
At iterate     1  f =      -228.82  |proj g|=        1.0354
At iterate     2  f =      -236.13  |proj g|=       0.66609
At iterate     3  f =      -236.36  |proj g|=       0.74972
At iterate     4  f =      -236.37  |proj g|=        0.7458
At iterate     5  f =      -236.42  |proj g|=       0.73774
At iterate     6  f =      -236.44  |proj g|=       0.74355
At iterate     7  f =      -236.44  |proj g|=       0.75198
At iterate     8  f =      -236.44  |proj g|=       0.75492
At iterate     9  f =      -236.44  |proj g|=       0.75544
At iterate    10  f =      -236.44  |proj g|=       0.75546

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.755457
final function value -236.444

F = -236.444
final  value -236.444188 
converged
 
INFO  [07:59:28.819] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:59:28.910] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:59:28.918] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:59:33.512] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:59:38.088] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:59:42.560] [mlr3]  Finished benchmark 
INFO  [07:59:42.712] [bbotk] Result of batch 30: 
INFO  [07:59:42.714] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:59:42.714] [bbotk]              6.078503                 5.860577                      0.08537591 
INFO  [07:59:42.714] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:59:42.714] [bbotk]                     2907        0.631 -0.9654456         <NA>   0.9702984 
INFO  [07:59:42.714] [bbotk]                                 uhash 
INFO  [07:59:42.714] [bbotk]  1c8887a4-9ca4-40f3-8350-f23018d2c1a7 
DEBUG [07:59:43.455] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.249271e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.249271e-05 0.001554503 
  - best initial criterion value(s) :  231.4263 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -231.43  |proj g|=      0.53901
At iterate     1  f =       -232.9  |proj g|=       0.90519
At iterate     2  f =         -233  |proj g|=        0.8102
At iterate     3  f =      -233.11  |proj g|=       0.68554
At iterate     4  f =       -233.2  |proj g|=       0.67477
At iterate     5  f =         -234  |proj g|=       0.58186
At iterate     6  f =      -234.92  |proj g|=       0.57683
At iterate     7  f =      -235.38  |proj g|=       0.71264
At iterate     8  f =      -235.65  |proj g|=       0.62194
At iterate     9  f =      -235.69  |proj g|=       0.60452
At iterate    10  f =       -235.7  |proj g|=       0.66505
At iterate    11  f =       -235.7  |proj g|=       0.60656
At iterate    12  f =       -235.7  |proj g|=       0.60655

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.606554
final function value -235.697

F = -235.697
final  value -235.696693 
converged
 
INFO  [07:59:43.460] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:59:43.560] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:59:43.569] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:59:44.949] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:59:46.356] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:59:47.703] [mlr3]  Finished benchmark 
INFO  [07:59:48.074] [bbotk] Result of batch 31: 
INFO  [07:59:48.076] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:59:48.076] [bbotk]              4.926145                 6.034627                      0.05404664 
INFO  [07:59:48.076] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:59:48.076] [bbotk]                      674         0.55 -0.9701919         <NA>   0.9436497 
INFO  [07:59:48.076] [bbotk]                                 uhash 
INFO  [07:59:48.076] [bbotk]  de5eb4d8-d4b5-4500-b772-b90242e4817e 
DEBUG [07:59:48.916] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.323936e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.323936e-05 0.001654994 
  - best initial criterion value(s) :  238.2371 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -238.24  |proj g|=       4.3778
At iterate     1  f =      -238.62  |proj g|=        4.7044
At iterate     2  f =      -240.22  |proj g|=        4.6188
At iterate     3  f =      -242.65  |proj g|=        3.5927
At iterate     4  f =      -243.43  |proj g|=        2.5604
At iterate     5  f =      -243.76  |proj g|=        1.8607
At iterate     6  f =      -243.93  |proj g|=        2.0585
At iterate     7  f =      -243.93  |proj g|=        2.0113
At iterate     8  f =      -243.93  |proj g|=        2.0148
At iterate     9  f =      -243.93  |proj g|=        2.0111
At iterate    10  f =      -243.93  |proj g|=        1.9988
At iterate    11  f =      -243.93  |proj g|=        1.9665
At iterate    12  f =      -243.93  |proj g|=        1.9241
At iterate    13  f =      -243.95  |proj g|=        1.8512
At iterate    14  f =      -243.97  |proj g|=        1.7314
At iterate    15  f =      -244.03  |proj g|=        1.5805
At iterate    16  f =      -244.08  |proj g|=       0.95833
At iterate    17  f =      -244.31  |proj g|=         1.114
At iterate    18  f =      -244.89  |proj g|=        1.3049
At iterate    19  f =      -246.47  |proj g|=        1.3064
At iterate    20  f =       -248.8  |proj g|=        1.0164
At iterate    21  f =      -248.85  |proj g|=       0.98321
At iterate    22  f =      -249.76  |proj g|=       0.82188
At iterate    23  f =      -251.25  |proj g|=        0.7691
At iterate    24  f =      -251.54  |proj g|=       0.70504
At iterate    25  f =      -251.62  |proj g|=       0.67771
At iterate    26  f =      -251.64  |proj g|=       0.67298
At iterate    27  f =      -251.65  |proj g|=       0.67635
At iterate    28  f =      -251.65  |proj g|=        0.6828
At iterate    29  f =      -251.65  |proj g|=       0.68115
At iterate    30  f =      -251.65  |proj g|=       0.68114

iterations 30
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.681143
final function value -251.647

F = -251.647
final  value -251.647490 
converged
 
INFO  [07:59:48.921] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:59:49.018] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:59:49.026] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [07:59:50.547] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [07:59:52.070] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [07:59:53.555] [mlr3]  Finished benchmark 
INFO  [07:59:53.675] [bbotk] Result of batch 32: 
INFO  [07:59:53.677] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [07:59:53.677] [bbotk]              3.163408                 3.615194                       0.1954965 
INFO  [07:59:53.677] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [07:59:53.677] [bbotk]                      727        0.601 -0.9575086         <NA>   0.9567038 
INFO  [07:59:53.677] [bbotk]                                 uhash 
INFO  [07:59:53.677] [bbotk]  f89e868a-1f7c-4946-ab2b-3239ab63cf43 
DEBUG [07:59:54.433] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.321241e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.321241e-05 0.001646658 
  - best initial criterion value(s) :  244.7221 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -244.72  |proj g|=      0.58254
At iterate     1  f =       -245.1  |proj g|=       0.66858
At iterate     2  f =      -245.12  |proj g|=       0.65742
At iterate     3  f =      -245.12  |proj g|=       0.65308
At iterate     4  f =      -245.13  |proj g|=       0.64842
At iterate     5  f =      -245.14  |proj g|=        0.6403
At iterate     6  f =      -245.15  |proj g|=       0.64367
At iterate     7  f =      -245.15  |proj g|=       0.64456
At iterate     8  f =      -245.15  |proj g|=       0.64438
At iterate     9  f =      -245.15  |proj g|=       0.64436

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.644364
final function value -245.15

F = -245.15
final  value -245.150475 
converged
 
INFO  [07:59:54.437] [bbotk] Evaluating 1 configuration(s) 
INFO  [07:59:54.527] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [07:59:54.534] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:00:01.297] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:00:08.124] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:00:14.936] [mlr3]  Finished benchmark 
INFO  [08:00:15.040] [bbotk] Result of batch 33: 
INFO  [08:00:15.042] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:00:15.042] [bbotk]              7.562574                 7.776588                       0.1520432 
INFO  [08:00:15.042] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:00:15.042] [bbotk]                     4180        0.541 -0.9697026         <NA>   0.9758058 
INFO  [08:00:15.042] [bbotk]                                 uhash 
INFO  [08:00:15.042] [bbotk]  f7768b36-5cad-484e-82b9-0509bf22a132 
DEBUG [08:00:15.786] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.311378e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.311378e-05 0.001643151 
  - best initial criterion value(s) :  232.9296 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -232.93  |proj g|=      0.90774
At iterate     1  f =      -233.57  |proj g|=        1.6363
At iterate     2  f =      -235.55  |proj g|=        1.3938
At iterate     3  f =      -238.68  |proj g|=        1.0511
At iterate     4  f =      -239.73  |proj g|=       0.93341
At iterate     5  f =      -242.79  |proj g|=       0.81122
At iterate     6  f =      -245.78  |proj g|=        0.7501
At iterate     7  f =      -245.89  |proj g|=       0.97915
At iterate     8  f =      -246.69  |proj g|=       0.95327
At iterate     9  f =       -247.1  |proj g|=       0.87363
At iterate    10  f =      -247.16  |proj g|=       0.88134
At iterate    11  f =      -247.16  |proj g|=       0.87912
At iterate    12  f =      -247.16  |proj g|=       0.87942
At iterate    13  f =      -247.16  |proj g|=       0.87933
At iterate    14  f =      -247.16  |proj g|=       0.87933

iterations 14
function evaluations 21
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.879331
final function value -247.161

F = -247.161
final  value -247.161063 
converged
 
INFO  [08:00:15.791] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:00:15.928] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:00:15.937] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:00:22.818] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:00:29.773] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:00:39.404] [mlr3]  Finished benchmark 
INFO  [08:00:39.511] [bbotk] Result of batch 34: 
INFO  [08:00:39.513] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:00:39.513] [bbotk]              8.755937                 9.546277                      0.08913087 
INFO  [08:00:39.513] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:00:39.513] [bbotk]                     4241        0.528 -0.9702578         <NA>   0.9736997 
INFO  [08:00:39.513] [bbotk]                                 uhash 
INFO  [08:00:39.513] [bbotk]  f9b91c01-63f8-4a04-877e-e9ebdca886f3 
DEBUG [08:00:40.641] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.296791e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.296791e-05 0.001631921 
  - best initial criterion value(s) :  255.5924 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -255.59  |proj g|=       1.4692
At iterate     1  f =      -260.07  |proj g|=        0.4622
At iterate     2  f =      -260.08  |proj g|=        0.4628
At iterate     3  f =       -260.1  |proj g|=       0.46249
At iterate     4  f =      -260.12  |proj g|=        0.4604
At iterate     5  f =       -260.2  |proj g|=        0.4432
At iterate     6  f =      -260.29  |proj g|=        0.4185
At iterate     7  f =      -260.38  |proj g|=       0.38675
At iterate     8  f =      -260.39  |proj g|=       0.41778
At iterate     9  f =      -260.39  |proj g|=       0.47581
At iterate    10  f =      -260.39  |proj g|=       0.49063
At iterate    11  f =      -260.39  |proj g|=       0.48975

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.489753
final function value -260.394

F = -260.394
final  value -260.393826 
converged
 
INFO  [08:00:40.644] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:00:40.725] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:00:40.731] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:00:54.837] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:01:05.283] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:01:16.784] [mlr3]  Finished benchmark 
INFO  [08:01:16.882] [bbotk] Result of batch 35: 
INFO  [08:01:16.884] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:01:16.884] [bbotk]              5.480533                 2.596944                       0.4921247 
INFO  [08:01:16.884] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:01:16.884] [bbotk]                     4743        0.543 -0.9670152         <NA>   0.9790503 
INFO  [08:01:16.884] [bbotk]                                 uhash 
INFO  [08:01:16.884] [bbotk]  1a5840db-507a-4130-9013-d32657b186e2 
DEBUG [08:01:17.706] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.296703e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.296702e-05 0.001644968 
  - best initial criterion value(s) :  252.2028 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -252.2  |proj g|=       9.4581
At iterate     1  f =      -257.86  |proj g|=        5.4222
At iterate     2  f =      -261.58  |proj g|=        4.3556
At iterate     3  f =      -266.06  |proj g|=        2.6244
At iterate     4  f =      -266.61  |proj g|=        1.8069
At iterate     5  f =      -266.99  |proj g|=        1.4113
At iterate     6  f =      -267.15  |proj g|=         1.124
At iterate     7  f =      -267.15  |proj g|=        1.0929
At iterate     8  f =      -267.15  |proj g|=        1.0946
At iterate     9  f =      -267.15  |proj g|=        1.0961
At iterate    10  f =      -267.15  |proj g|=        1.0981
At iterate    11  f =      -267.15  |proj g|=        1.1015
At iterate    12  f =      -267.15  |proj g|=        1.1067
At iterate    13  f =      -267.15  |proj g|=         1.115
At iterate    14  f =      -267.15  |proj g|=        1.1276
At iterate    15  f =      -267.15  |proj g|=        1.1462
At iterate    16  f =      -267.16  |proj g|=        1.1704
At iterate    17  f =      -267.19  |proj g|=        1.1926
At iterate    18  f =      -267.25  |proj g|=        1.1835
At iterate    19  f =      -267.38  |proj g|=        1.0781
At iterate    20  f =      -267.63  |proj g|=       0.78551
At iterate    21  f =      -267.79  |proj g|=       0.64476
At iterate    22  f =      -267.88  |proj g|=       0.64861
At iterate    23  f =      -267.89  |proj g|=       0.64818
At iterate    24  f =      -267.92  |proj g|=       0.64896
At iterate    25  f =      -268.05  |proj g|=       0.64767
At iterate    26  f =       -268.6  |proj g|=        0.6328
At iterate    27  f =      -269.92  |proj g|=       0.72059
At iterate    28  f =      -270.91  |proj g|=       0.56135
At iterate    29  f =      -270.99  |proj g|=       0.62685
At iterate    30  f =         -271  |proj g|=       0.62296
At iterate    31  f =         -271  |proj g|=       0.62367
At iterate    32  f =         -271  |proj g|=       0.62469
At iterate    33  f =         -271  |proj g|=       0.62515
At iterate    34  f =         -271  |proj g|=        0.6252

iterations 34
function evaluations 42
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.625204
final function value -271

F = -271
final  value -271.000264 
converged
 
INFO  [08:01:17.710] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:01:17.796] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:01:17.803] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:01:26.910] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:01:35.562] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:01:42.381] [mlr3]  Finished benchmark 
INFO  [08:01:42.482] [bbotk] Result of batch 36: 
INFO  [08:01:42.484] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:01:42.484] [bbotk]              7.734727                 7.982693                       0.3382609 
INFO  [08:01:42.484] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:01:42.484] [bbotk]                     3253        0.555 -0.9594648         <NA>   0.9777024 
INFO  [08:01:42.484] [bbotk]                                 uhash 
INFO  [08:01:42.484] [bbotk]  69ce8885-9cdf-45b4-abd2-5960b9a4af8c 
DEBUG [08:01:43.262] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.291767e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.291767e-05 0.001644929 
  - best initial criterion value(s) :  261.2195 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -261.22  |proj g|=       1.5229
At iterate     1  f =      -264.95  |proj g|=       0.68774
At iterate     2  f =       -265.2  |proj g|=       0.65597
At iterate     3  f =      -265.33  |proj g|=       0.58464
At iterate     4  f =      -265.35  |proj g|=       0.60599
At iterate     5  f =      -265.45  |proj g|=       0.59013
At iterate     6  f =      -265.65  |proj g|=       0.55617
At iterate     7  f =      -265.68  |proj g|=       0.57982
At iterate     8  f =      -265.69  |proj g|=       0.61321
At iterate     9  f =      -265.69  |proj g|=       0.61283
At iterate    10  f =      -265.69  |proj g|=       0.61284

iterations 10
function evaluations 16
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.612839
final function value -265.685

F = -265.685
final  value -265.685110 
converged
 
INFO  [08:01:43.266] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:01:43.370] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:01:43.377] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:01:47.371] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:01:52.605] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:01:57.038] [mlr3]  Finished benchmark 
INFO  [08:01:57.136] [bbotk] Result of batch 37: 
INFO  [08:01:57.138] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:01:57.138] [bbotk]              5.955996                 9.964204                       0.1374349 
INFO  [08:01:57.138] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:01:57.138] [bbotk]                     1971        0.562 -0.9687849         <NA>   0.9708092 
INFO  [08:01:57.138] [bbotk]                                 uhash 
INFO  [08:01:57.138] [bbotk]  87eea9be-1c14-4ea8-8b53-6651b805d427 
DEBUG [08:01:57.916] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.273712e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.273712e-05 0.001628644 
  - best initial criterion value(s) :  269.8665 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -269.87  |proj g|=       1.3526
At iterate     1  f =      -272.51  |proj g|=       0.82509
At iterate     2  f =      -272.61  |proj g|=         0.794
At iterate     3  f =      -272.65  |proj g|=       0.75299
At iterate     4  f =      -272.86  |proj g|=       0.78171
At iterate     5  f =      -273.16  |proj g|=       0.79917
At iterate     6  f =      -273.19  |proj g|=       0.79317
At iterate     7  f =      -273.19  |proj g|=       0.79795
At iterate     8  f =      -273.19  |proj g|=       0.80093
At iterate     9  f =      -273.19  |proj g|=        0.8013
At iterate    10  f =      -273.19  |proj g|=       0.80132

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.801316
final function value -273.193

F = -273.193
final  value -273.193276 
converged
 
INFO  [08:01:57.920] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:01:58.007] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:01:58.013] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:02:04.171] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:02:11.069] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:02:20.271] [mlr3]  Finished benchmark 
INFO  [08:02:20.371] [bbotk] Result of batch 38: 
INFO  [08:02:20.373] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:02:20.373] [bbotk]              9.328738                 2.525699                       0.1186217 
INFO  [08:02:20.373] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:02:20.373] [bbotk]                     3238        0.572 -0.9661562         <NA>   0.9740228 
INFO  [08:02:20.373] [bbotk]                                 uhash 
INFO  [08:02:20.373] [bbotk]  d491b9ce-197f-475f-a243-758fe2b059e0 
DEBUG [08:02:21.194] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.2603e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.2603e-05 0.001622025 
  - best initial criterion value(s) :  264.598 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -264.6  |proj g|=        2.026
At iterate     1  f =      -268.35  |proj g|=        3.1746
At iterate     2  f =      -269.67  |proj g|=        3.1157
At iterate     3  f =      -270.91  |proj g|=        2.8896
At iterate     4  f =      -270.98  |proj g|=        2.7858
At iterate     5  f =      -271.05  |proj g|=        2.7765
At iterate     6  f =       -271.3  |proj g|=        2.5881
At iterate     7  f =       -271.3  |proj g|=        2.6168
At iterate     8  f =      -271.31  |proj g|=        2.6132
At iterate     9  f =      -271.31  |proj g|=         2.613
At iterate    10  f =      -271.31  |proj g|=        2.6134
At iterate    11  f =      -271.31  |proj g|=        2.6124
At iterate    12  f =      -271.31  |proj g|=        2.6061
At iterate    13  f =      -271.31  |proj g|=        2.5952
At iterate    14  f =      -271.33  |proj g|=        2.5653
At iterate    15  f =      -271.38  |proj g|=        2.5126
At iterate    16  f =      -271.38  |proj g|=        2.4899
At iterate    17  f =      -271.51  |proj g|=        2.3966
At iterate    18  f =      -271.85  |proj g|=        2.2119
At iterate    19  f =      -272.69  |proj g|=        1.8803
At iterate    20  f =      -274.73  |proj g|=        1.3583
At iterate    21  f =      -278.47  |proj g|=       0.78194
At iterate    22  f =      -278.53  |proj g|=       0.74038
At iterate    23  f =      -281.86  |proj g|=       0.63878
At iterate    24  f =      -282.66  |proj g|=       0.57554
At iterate    25  f =      -282.74  |proj g|=       0.55322
At iterate    26  f =      -282.74  |proj g|=        0.1423
At iterate    27  f =      -282.74  |proj g|=       0.14767
At iterate    28  f =      -282.74  |proj g|=       0.14882

iterations 28
function evaluations 36
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.14882
final function value -282.744

F = -282.744
final  value -282.744274 
converged
 
INFO  [08:02:21.198] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:02:21.300] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:02:21.307] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:02:26.730] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:02:34.323] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:02:40.435] [mlr3]  Finished benchmark 
INFO  [08:02:40.537] [bbotk] Result of batch 39: 
INFO  [08:02:40.539] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:02:40.539] [bbotk]              7.124694                 7.732655                       0.3079442 
INFO  [08:02:40.539] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:02:40.539] [bbotk]                     2796        0.572 -0.9643499         <NA>   0.9767775 
INFO  [08:02:40.539] [bbotk]                                 uhash 
INFO  [08:02:40.539] [bbotk]  09c0f5bf-dd72-4035-aa1f-2edbe432815e 
DEBUG [08:02:41.303] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.252909e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.252909e-05 0.00162032 
  - best initial criterion value(s) :  269.4639 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -269.46  |proj g|=      0.80069
At iterate     1  f =       -272.7  |proj g|=       0.78098
At iterate     2  f =      -275.81  |proj g|=       0.81433
At iterate     3  f =      -276.03  |proj g|=       0.79874
At iterate     4  f =      -276.36  |proj g|=       0.76632
At iterate     5  f =       -276.4  |proj g|=       0.75323
At iterate     6  f =       -276.4  |proj g|=       0.76266
At iterate     7  f =      -276.41  |proj g|=       0.75943
At iterate     8  f =      -276.41  |proj g|=        0.7592
At iterate     9  f =      -276.41  |proj g|=       0.75921

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.759206
final function value -276.406

F = -276.406
final  value -276.405799 
converged
 
INFO  [08:02:41.310] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:02:41.705] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:02:41.717] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:02:46.412] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:02:50.926] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:02:55.705] [mlr3]  Finished benchmark 
INFO  [08:02:55.839] [bbotk] Result of batch 40: 
INFO  [08:02:55.841] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:02:55.841] [bbotk]              5.516436                 3.128689                       0.1673998 
INFO  [08:02:55.841] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:02:55.841] [bbotk]                     1990        0.568 -0.9702006         <NA>   0.9718263 
INFO  [08:02:55.841] [bbotk]                                 uhash 
INFO  [08:02:55.841] [bbotk]  88a1383b-cc35-4a28-b838-f6deef1bd464 
DEBUG [08:02:56.624] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.236886e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.236886e-05 0.001607121 
  - best initial criterion value(s) :  269.4111 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -269.41  |proj g|=       1.2427
At iterate     1  f =      -269.61  |proj g|=        1.2002
At iterate     2  f =      -269.81  |proj g|=        1.1995
At iterate     3  f =      -269.91  |proj g|=        1.2085
At iterate     4  f =      -269.93  |proj g|=        1.2089
At iterate     5  f =      -269.94  |proj g|=        1.2082
At iterate     6  f =      -269.94  |proj g|=        1.2084
At iterate     7  f =      -269.94  |proj g|=        1.2084

iterations 7
function evaluations 11
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.2084
final function value -269.936

F = -269.936
final  value -269.935621 
converged
 
INFO  [08:02:56.629] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:02:56.717] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:02:56.724] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:03:00.102] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:03:03.690] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:03:07.330] [mlr3]  Finished benchmark 
INFO  [08:03:07.431] [bbotk] Result of batch 41: 
INFO  [08:03:07.433] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:03:07.433] [bbotk]              9.907933                 4.612394                         0.37294 
INFO  [08:03:07.433] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:03:07.433] [bbotk]                     1578        0.576 -0.9725235         <NA>   0.9759928 
INFO  [08:03:07.433] [bbotk]                                 uhash 
INFO  [08:03:07.433] [bbotk]  dd502645-7c45-4790-bc2e-e29ab282292e 
DEBUG [08:03:08.297] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.227837e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.227837e-05 0.001573135 
  - best initial criterion value(s) :  271.773 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -271.77  |proj g|=       6.1252
At iterate     1  f =      -283.89  |proj g|=       0.72574
At iterate     2  f =      -285.77  |proj g|=        2.4389
At iterate     3  f =      -286.04  |proj g|=        2.1962
At iterate     4  f =      -286.13  |proj g|=        1.9108
At iterate     5  f =      -286.15  |proj g|=        2.0128
At iterate     6  f =      -286.15  |proj g|=        2.0474
At iterate     7  f =      -286.16  |proj g|=        2.0762
At iterate     8  f =      -286.16  |proj g|=        2.0729
At iterate     9  f =      -286.16  |proj g|=        2.0722
At iterate    10  f =      -286.16  |proj g|=        2.0718
At iterate    11  f =      -286.16  |proj g|=        2.0707
At iterate    12  f =      -286.16  |proj g|=        2.0691
At iterate    13  f =      -286.16  |proj g|=        2.0663
At iterate    14  f =      -286.16  |proj g|=        2.0619
At iterate    15  f =      -286.16  |proj g|=        2.0551
At iterate    16  f =      -286.16  |proj g|=        2.0473
At iterate    17  f =      -286.16  |proj g|=        2.0221
At iterate    18  f =      -286.16  |proj g|=        2.0284
At iterate    19  f =      -286.16  |proj g|=        2.0349
At iterate    20  f =      -286.17  |proj g|=        2.0408
At iterate    21  f =      -286.18  |proj g|=        2.0426
At iterate    22  f =      -286.22  |proj g|=        2.0132
At iterate    23  f =       -286.3  |proj g|=        1.9492
At iterate    24  f =      -286.48  |proj g|=        1.7875
At iterate    25  f =       -286.8  |proj g|=        1.4663
At iterate    26  f =       -286.8  |proj g|=        1.4923
At iterate    27  f =      -287.26  |proj g|=         1.147
At iterate    28  f =      -288.76  |proj g|=       0.80736
At iterate    29  f =      -289.59  |proj g|=       0.80785
At iterate    30  f =      -289.82  |proj g|=       0.77985
At iterate    31  f =      -289.85  |proj g|=        0.7611
At iterate    32  f =      -289.86  |proj g|=       0.76457
At iterate    33  f =      -289.86  |proj g|=         0.765
At iterate    34  f =      -289.86  |proj g|=       0.76506

iterations 34
function evaluations 38
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.765062
final function value -289.856

F = -289.856
final  value -289.856099 
converged
 
INFO  [08:03:08.301] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:03:08.426] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:03:08.433] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:03:09.974] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:03:11.398] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:03:13.836] [mlr3]  Finished benchmark 
INFO  [08:03:13.936] [bbotk] Result of batch 42: 
INFO  [08:03:13.938] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:03:13.938] [bbotk]              8.958287                 5.516148                       0.2981967 
INFO  [08:03:13.938] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [08:03:13.938] [bbotk]                      521        0.607 -0.968501         <NA>   0.9677547 
INFO  [08:03:13.938] [bbotk]                                 uhash 
INFO  [08:03:13.938] [bbotk]  47061f82-0626-4c50-ab0a-0e7154261aba 
DEBUG [08:03:14.818] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.21083e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.21083e-05 0.001534263 
  - best initial criterion value(s) :  286.1313 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -286.13  |proj g|=       2.6921
At iterate     1  f =      -293.74  |proj g|=        2.4984
At iterate     2  f =      -295.43  |proj g|=        2.0186
At iterate     3  f =      -296.93  |proj g|=       0.81686
At iterate     4  f =       -297.4  |proj g|=       0.93366
At iterate     5  f =      -297.78  |proj g|=        1.0392
At iterate     6  f =      -299.17  |proj g|=        1.0733
At iterate     7  f =      -299.72  |proj g|=        1.0212
At iterate     8  f =      -299.82  |proj g|=        1.0825
At iterate     9  f =      -299.85  |proj g|=        1.0722
At iterate    10  f =      -299.86  |proj g|=        1.0656
At iterate    11  f =      -299.86  |proj g|=        1.0663
At iterate    12  f =      -299.86  |proj g|=        1.0665
At iterate    13  f =      -299.86  |proj g|=        1.0665
At iterate    14  f =      -299.86  |proj g|=         1.067
At iterate    15  f =      -299.86  |proj g|=        1.0675
At iterate    16  f =      -299.86  |proj g|=        1.0684
At iterate    17  f =      -299.86  |proj g|=        1.0694
At iterate    18  f =      -299.86  |proj g|=        1.0712
At iterate    19  f =      -299.86  |proj g|=        1.0721
At iterate    20  f =      -299.86  |proj g|=        1.0745
At iterate    21  f =      -299.88  |proj g|=        1.0789
At iterate    22  f =      -299.93  |proj g|=        1.0873
At iterate    23  f =      -300.07  |proj g|=        1.1021
At iterate    24  f =       -300.1  |proj g|=        1.0771
At iterate    25  f =      -300.34  |proj g|=        1.1052
At iterate    26  f =      -300.64  |proj g|=          1.13
At iterate    27  f =      -300.79  |proj g|=        1.1406
At iterate    28  f =      -300.81  |proj g|=         1.134
At iterate    29  f =      -300.81  |proj g|=        1.1232
At iterate    30  f =      -300.81  |proj g|=        1.1223
At iterate    31  f =      -300.81  |proj g|=        1.1214
At iterate    32  f =      -300.81  |proj g|=        1.1214

iterations 32
function evaluations 37
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.12139
final function value -300.809

F = -300.809
final  value -300.809306 
converged
 
INFO  [08:03:14.822] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:03:14.912] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:03:14.919] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:03:16.242] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:03:17.435] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:03:18.792] [mlr3]  Finished benchmark 
INFO  [08:03:18.895] [bbotk] Result of batch 43: 
INFO  [08:03:18.897] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:03:18.897] [bbotk]              8.945124                 8.991219                        0.405852 
INFO  [08:03:18.897] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:03:18.897] [bbotk]                      510        0.626 -0.9598521         <NA>   0.9701307 
INFO  [08:03:18.897] [bbotk]                                 uhash 
INFO  [08:03:18.897] [bbotk]  ba16cbbf-34d9-43f1-a8d5-9905e12590ae 
DEBUG [08:03:19.877] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.194682e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.194682e-05 0.001500772 
  - best initial criterion value(s) :  298.0151 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -298.02  |proj g|=       1.3721
At iterate     1  f =      -298.49  |proj g|=        1.2832
At iterate     2  f =       -298.5  |proj g|=        1.2631
At iterate     3  f =      -298.54  |proj g|=        1.2273
At iterate     4  f =      -298.54  |proj g|=        1.2389
At iterate     5  f =      -298.54  |proj g|=        1.2379
At iterate     6  f =      -298.54  |proj g|=        1.2379

iterations 6
function evaluations 10
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.23786
final function value -298.541

F = -298.541
final  value -298.540656 
converged
 
INFO  [08:03:19.881] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:03:19.970] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:03:19.977] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:03:26.827] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:03:31.162] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:03:35.599] [mlr3]  Finished benchmark 
INFO  [08:03:35.720] [bbotk] Result of batch 44: 
INFO  [08:03:35.722] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:03:35.722] [bbotk]              7.106932                 6.452558                        0.290749 
INFO  [08:03:35.722] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:03:35.722] [bbotk]                     2786        0.732 -0.9677954         <NA>   0.9765622 
INFO  [08:03:35.722] [bbotk]                                 uhash 
INFO  [08:03:35.722] [bbotk]  e6074a95-0a3b-41b9-bd8d-b054ab4f35ca 
DEBUG [08:03:36.985] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.187523e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.187523e-05 0.001498918 
  - best initial criterion value(s) :  304.2065 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -304.21  |proj g|=      0.79252
At iterate     1  f =      -311.19  |proj g|=       0.86727
At iterate     2  f =      -313.39  |proj g|=       0.67652
At iterate     3  f =      -313.56  |proj g|=       0.57882
At iterate     4  f =      -313.63  |proj g|=       0.53793
At iterate     5  f =      -313.63  |proj g|=       0.53837
At iterate     6  f =      -313.63  |proj g|=       0.53844
At iterate     7  f =      -313.63  |proj g|=       0.53851
At iterate     8  f =      -313.63  |proj g|=       0.53854
At iterate     9  f =      -313.63  |proj g|=        0.5387
At iterate    10  f =      -313.63  |proj g|=       0.53879
At iterate    11  f =      -313.63  |proj g|=        0.5386
At iterate    12  f =      -313.63  |proj g|=       0.53756
At iterate    13  f =      -313.63  |proj g|=       0.53381
At iterate    14  f =      -313.64  |proj g|=       0.52272
At iterate    15  f =      -313.65  |proj g|=       0.57942
At iterate    16  f =      -313.69  |proj g|=       0.58658
At iterate    17  f =      -313.72  |proj g|=       0.37872
At iterate    18  f =      -313.87  |proj g|=       0.59648
At iterate    19  f =      -313.97  |proj g|=       0.59687
At iterate    20  f =      -314.04  |proj g|=       0.58491
At iterate    21  f =      -314.09  |proj g|=       0.56621
At iterate    22  f =      -314.09  |proj g|=        0.2966
At iterate    23  f =      -314.09  |proj g|=       0.29688
At iterate    24  f =      -314.09  |proj g|=       0.29692
At iterate    25  f =      -314.09  |proj g|=       0.30202
At iterate    26  f =      -314.09  |proj g|=       0.29842
At iterate    27  f =      -314.09  |proj g|=       0.29546
At iterate    28  f =      -314.09  |proj g|=       0.40145
At iterate    29  f =      -314.09  |proj g|=       0.40158
At iterate    30  f =      -314.09  |proj g|=       0.40202
At iterate    31  f =       -314.1  |proj g|=       0.40292
At iterate    32  f =      -314.11  |proj g|=       0.40515
At iterate    33  f =      -314.15  |proj g|=       0.41018
At iterate    34  f =      -314.21  |proj g|=       0.41927
At iterate    35  f =      -314.23  |proj g|=       0.42311
At iterate    36  f =      -314.26  |proj g|=       0.43147
At iterate    37  f =      -314.27  |proj g|=       0.43062
At iterate    38  f =      -314.28  |proj g|=       0.29852
At iterate    39  f =      -314.28  |proj g|=     0.0072973
At iterate    40  f =      -314.28  |proj g|=      0.002793
At iterate    41  f =      -314.28  |proj g|=      0.020146
At iterate    42  f =      -314.28  |proj g|=     0.0027891
At iterate    43  f =      -314.28  |proj g|=      0.011438
At iterate    44  f =      -314.28  |proj g|=      0.032495
At iterate    45  f =      -314.28  |proj g|=      0.082618
At iterate    46  f =      -314.28  |proj g|=       0.15184
At iterate    47  f =      -314.28  |proj g|=       0.20346
At iterate    48  f =      -314.28  |proj g|=       0.28731
At iterate    49  f =      -314.29  |proj g|=       0.39744
At iterate    50  f =      -314.29  |proj g|=       0.42382
At iterate    51  f =      -314.29  |proj g|=       0.38723
At iterate    52  f =      -314.29  |proj g|=       0.24314
At iterate    53  f =      -314.29  |proj g|=       0.32927
At iterate    54  f =      -314.29  |proj g|=       0.21885
At iterate    55  f =      -314.29  |proj g|=       0.15648
At iterate    56  f =      -314.29  |proj g|=       0.24857
At iterate    57  f =      -314.29  |proj g|=       0.54546
At iterate    58  f =       -314.3  |proj g|=          0.55
At iterate    59  f =      -314.31  |proj g|=       0.55423
At iterate    60  f =      -314.34  |proj g|=        0.5609
At iterate    61  f =      -314.34  |proj g|=       0.55632
At iterate    62  f =      -314.43  |proj g|=        0.5647
At iterate    63  f =      -314.57  |proj g|=       0.56513
At iterate    64  f =      -314.73  |proj g|=       0.41851
At iterate    65  f =      -314.83  |proj g|=       0.46397
At iterate    66  f =      -314.84  |proj g|=       0.46271
At iterate    67  f =      -314.84  |proj g|=       0.46127
At iterate    68  f =      -314.84  |proj g|=       0.46018
At iterate    69  f =      -314.85  |proj g|=       0.45914
At iterate    70  f =      -314.85  |proj g|=       0.45715
At iterate    71  f =      -314.87  |proj g|=       0.45935
At iterate    72  f =      -314.92  |proj g|=        0.5329
At iterate    73  f =      -315.03  |proj g|=       0.62508
At iterate    74  f =      -315.26  |proj g|=       0.60575
At iterate    75  f =       -315.3  |proj g|=       0.64875
At iterate    76  f =      -315.57  |proj g|=       0.55308
At iterate    77  f =      -315.82  |proj g|=       0.54798
At iterate    78  f =      -315.89  |proj g|=       0.53805
At iterate    79  f =      -315.91  |proj g|=       0.53038
At iterate    80  f =      -315.92  |proj g|=       0.53102
At iterate    81  f =      -315.93  |proj g|=       0.52907
At iterate    82  f =      -315.94  |proj g|=       0.52345
At iterate    83  f =      -316.05  |proj g|=        0.5013
At iterate    84  f =      -316.11  |proj g|=       0.25469
At iterate    85  f =      -316.11  |proj g|=      0.071193
At iterate    86  f =      -316.11  |proj g|=      0.083995
At iterate    87  f =      -316.11  |proj g|=      0.020824
At iterate    88  f =      -316.11  |proj g|=      0.046433
At iterate    89  f =      -316.11  |proj g|=      0.028323
At iterate    90  f =      -316.11  |proj g|=     0.0010276
At iterate    91  f =      -316.11  |proj g|=    0.00045954
At iterate    92  f =      -316.11  |proj g|=    0.00045956

iterations 92
function evaluations 118
segments explored during Cauchy searches 94
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00045956
final function value -316.111

F = -316.111
final  value -316.111433 
converged
 
INFO  [08:03:36.990] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:03:37.161] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:03:37.170] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:03:41.265] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:03:45.404] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:03:49.563] [mlr3]  Finished benchmark 
INFO  [08:03:49.665] [bbotk] Result of batch 45: 
INFO  [08:03:49.667] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:03:49.667] [bbotk]              4.513519                 9.585363                      0.06129873 
INFO  [08:03:49.667] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:03:49.667] [bbotk]                     2644        0.754 -0.9613742         <NA>   0.9649906 
INFO  [08:03:49.667] [bbotk]                                 uhash 
INFO  [08:03:49.667] [bbotk]  19871ecd-4e12-47e1-b266-98c35b21325d 
DEBUG [08:03:50.505] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.173276e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.173276e-05 0.001483635 
  - best initial criterion value(s) :  305.3535 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -305.35  |proj g|=       2.7874
At iterate     1  f =       -305.7  |proj g|=        1.3398
At iterate     2  f =       -309.5  |proj g|=        1.2968
At iterate     3  f =      -314.49  |proj g|=        1.0851
At iterate     4  f =      -314.71  |proj g|=        1.0192
At iterate     5  f =      -315.11  |proj g|=        1.0341
At iterate     6  f =      -316.05  |proj g|=        1.1303
At iterate     7  f =      -316.15  |proj g|=         1.159
At iterate     8  f =      -316.17  |proj g|=        1.1755
At iterate     9  f =      -316.17  |proj g|=        1.1798
At iterate    10  f =      -316.17  |proj g|=        1.1811
At iterate    11  f =      -316.17  |proj g|=        1.1809
At iterate    12  f =      -316.17  |proj g|=        1.1808

iterations 12
function evaluations 18
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.18084
final function value -316.168

F = -316.168
final  value -316.168367 
converged
 
INFO  [08:03:50.510] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:03:50.625] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:03:50.637] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:03:52.128] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:03:53.768] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:03:55.565] [mlr3]  Finished benchmark 
INFO  [08:03:55.714] [bbotk] Result of batch 46: 
INFO  [08:03:55.716] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:03:55.716] [bbotk]              5.084667                 2.140417                       0.3335027 
INFO  [08:03:55.716] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:03:55.716] [bbotk]                      906        0.609 -0.9633208         <NA>   0.9708741 
INFO  [08:03:55.716] [bbotk]                                 uhash 
INFO  [08:03:55.716] [bbotk]  b1b9c9b5-75aa-46e8-8d1d-98a1e685b92d 
DEBUG [08:03:56.717] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.158622e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.158622e-05 0.001449963 
  - best initial criterion value(s) :  314.745 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -314.75  |proj g|=       2.2307
At iterate     1  f =      -315.34  |proj g|=        1.2386
At iterate     2  f =         -318  |proj g|=        1.1622
At iterate     3  f =      -319.61  |proj g|=        1.0172
At iterate     4  f =      -319.79  |proj g|=        1.0092
At iterate     5  f =         -321  |proj g|=        1.0499
At iterate     6  f =      -321.87  |proj g|=        1.1645
At iterate     7  f =      -322.06  |proj g|=        1.2227
At iterate     8  f =       -322.1  |proj g|=        1.2557
At iterate     9  f =       -322.1  |proj g|=        1.2683
At iterate    10  f =       -322.1  |proj g|=        1.2702
At iterate    11  f =       -322.1  |proj g|=        1.2703

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.27028
final function value -322.101

F = -322.101
final  value -322.100526 
converged
 
INFO  [08:03:56.722] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:03:56.814] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:03:56.821] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:04:02.658] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:04:08.532] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:04:14.389] [mlr3]  Finished benchmark 
INFO  [08:04:14.940] [bbotk] Result of batch 47: 
INFO  [08:04:14.942] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:04:14.942] [bbotk]              3.696904                 5.891861                       0.1937482 
INFO  [08:04:14.942] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:04:14.942] [bbotk]                     3703        0.766 -0.9624529         <NA>   0.9731458 
INFO  [08:04:14.942] [bbotk]                                 uhash 
INFO  [08:04:14.942] [bbotk]  8f546325-9a89-41ca-8e57-06b9ce294c56 
DEBUG [08:04:15.849] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.146404e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.146404e-05 0.001443203 
  - best initial criterion value(s) :  315.8463 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -315.85  |proj g|=       1.2308
At iterate     1  f =      -316.36  |proj g|=        1.3956
At iterate     2  f =      -316.49  |proj g|=        1.3679
At iterate     3  f =      -316.79  |proj g|=          1.29
At iterate     4  f =      -316.97  |proj g|=        1.2924
At iterate     5  f =      -317.08  |proj g|=         1.388
At iterate     6  f =      -317.15  |proj g|=         1.344
At iterate     7  f =      -317.16  |proj g|=        1.3316
At iterate     8  f =      -317.16  |proj g|=        1.3329
At iterate     9  f =      -317.16  |proj g|=        1.3329

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.33291
final function value -317.155

F = -317.155
final  value -317.155200 
converged
 
INFO  [08:04:15.853] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:04:15.939] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:04:15.946] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:04:23.181] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:04:30.388] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:04:37.758] [mlr3]  Finished benchmark 
INFO  [08:04:37.855] [bbotk] Result of batch 48: 
INFO  [08:04:37.857] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:04:37.857] [bbotk]              6.444082                 9.334605                      0.01917498 
INFO  [08:04:37.857] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:04:37.857] [bbotk]                     4433        0.694 -0.9664973         <NA>   0.9605568 
INFO  [08:04:37.857] [bbotk]                                 uhash 
INFO  [08:04:37.857] [bbotk]  98298968-f43e-4a71-a510-df6f05450c75 
DEBUG [08:04:38.958] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.139711e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.139711e-05 0.001428505 
  - best initial criterion value(s) :  316.3042 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -316.3  |proj g|=       2.1577
At iterate     1  f =      -321.55  |proj g|=        2.4919
At iterate     2  f =      -322.54  |proj g|=        2.4254
At iterate     3  f =      -322.95  |proj g|=        2.1424
At iterate     4  f =      -323.22  |proj g|=        2.2929
At iterate     5  f =      -323.26  |proj g|=         2.263
At iterate     6  f =       -323.3  |proj g|=        2.2251
At iterate     7  f =      -323.37  |proj g|=        2.1786
At iterate     8  f =      -323.46  |proj g|=        2.1198
At iterate     9  f =      -323.51  |proj g|=        2.1183
At iterate    10  f =      -323.51  |proj g|=        2.1277
At iterate    11  f =      -323.51  |proj g|=        2.1288
At iterate    12  f =      -323.51  |proj g|=        2.1289
At iterate    13  f =      -323.51  |proj g|=        2.1291
At iterate    14  f =      -323.51  |proj g|=        2.1296
At iterate    15  f =      -323.51  |proj g|=        2.1302
At iterate    16  f =      -323.51  |proj g|=         2.131
At iterate    17  f =      -323.51  |proj g|=        2.1321
At iterate    18  f =      -323.51  |proj g|=         2.133
At iterate    19  f =      -323.51  |proj g|=        2.1327
At iterate    20  f =      -323.51  |proj g|=        2.1283
At iterate    21  f =      -323.52  |proj g|=        2.1134
At iterate    22  f =      -323.52  |proj g|=        2.1015
At iterate    23  f =      -323.52  |proj g|=        2.1003
At iterate    24  f =      -323.52  |proj g|=        2.0943
At iterate    25  f =      -323.53  |proj g|=        2.0857
At iterate    26  f =      -323.55  |proj g|=         2.067
At iterate    27  f =       -323.6  |proj g|=        2.0367
At iterate    28  f =      -323.74  |proj g|=        1.9798
At iterate    29  f =       -324.1  |proj g|=        1.8763
At iterate    30  f =      -325.01  |proj g|=         1.706
At iterate    31  f =      -326.46  |proj g|=        1.5376
At iterate    32  f =      -327.11  |proj g|=        1.6001
At iterate    33  f =      -327.12  |proj g|=        1.5972
At iterate    34  f =       -327.2  |proj g|=        1.5973
At iterate    35  f =      -327.35  |proj g|=        1.5993
At iterate    36  f =      -327.69  |proj g|=        1.5858
At iterate    37  f =      -328.23  |proj g|=         1.552
At iterate    38  f =      -329.08  |proj g|=        1.4072
At iterate    39  f =      -330.23  |proj g|=        1.4336
At iterate    40  f =      -330.39  |proj g|=        1.0939
At iterate    41  f =       -330.4  |proj g|=        1.1652
At iterate    42  f =      -330.43  |proj g|=        1.1326
At iterate    43  f =      -330.43  |proj g|=        1.1279
At iterate    44  f =      -330.43  |proj g|=         1.128
At iterate    45  f =      -330.43  |proj g|=        1.1302
At iterate    46  f =      -330.43  |proj g|=        1.1309
At iterate    47  f =      -330.43  |proj g|=        1.1313
At iterate    48  f =      -330.43  |proj g|=        1.1313

iterations 48
function evaluations 51
segments explored during Cauchy searches 50
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.13125
final function value -330.43

F = -330.43
final  value -330.429600 
converged
 
INFO  [08:04:38.962] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:04:39.048] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:04:39.055] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:04:47.584] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:04:58.469] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:05:10.570] [mlr3]  Finished benchmark 
INFO  [08:05:10.687] [bbotk] Result of batch 49: 
INFO  [08:05:10.689] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:05:10.689] [bbotk]              3.117737                  3.95658                      0.02216859 
INFO  [08:05:10.689] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:05:10.689] [bbotk]                     4541        0.737 -0.9655062         <NA>    0.951687 
INFO  [08:05:10.689] [bbotk]                                 uhash 
INFO  [08:05:10.689] [bbotk]  75f6ca1c-796f-4d9a-b0fc-fbcff0c28f4c 
DEBUG [08:05:11.492] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.160234e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.160234e-05 0.00144309 
  - best initial criterion value(s) :  311.438 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -311.44  |proj g|=      0.99105
At iterate     1  f =      -326.35  |proj g|=        4.3218
At iterate     2  f =       -326.7  |proj g|=        4.1725
At iterate     3  f =      -327.19  |proj g|=        3.0314
At iterate     4  f =      -327.47  |proj g|=        3.6285
At iterate     5  f =      -327.56  |proj g|=        3.5413
At iterate     6  f =      -327.92  |proj g|=        3.1425
At iterate     7  f =      -328.32  |proj g|=        3.0004
At iterate     8  f =      -329.48  |proj g|=          2.46
At iterate     9  f =      -330.07  |proj g|=        3.3192
At iterate    10  f =      -330.09  |proj g|=         3.265
At iterate    11  f =       -330.1  |proj g|=        3.2169
At iterate    12  f =       -330.1  |proj g|=        3.2183
At iterate    13  f =       -330.1  |proj g|=        3.2182

iterations 13
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.21821
final function value -330.096

F = -330.096
final  value -330.096334 
converged
 
INFO  [08:05:11.496] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:05:11.585] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:05:11.592] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:05:20.284] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:05:29.531] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:05:40.108] [mlr3]  Finished benchmark 
INFO  [08:05:40.207] [bbotk] Result of batch 50: 
INFO  [08:05:40.208] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:05:40.208] [bbotk]              8.612959                 5.376888                       0.3614943 
INFO  [08:05:40.208] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:05:40.208] [bbotk]                     4109        0.582 -0.9677019         <NA>   0.9787717 
INFO  [08:05:40.208] [bbotk]                                 uhash 
INFO  [08:05:40.208] [bbotk]  ffaef29f-6091-4ae8-99ff-736a38d9eb1a 
DEBUG [08:05:41.008] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.159531e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.159531e-05 0.001449408 
  - best initial criterion value(s) :  330.4146 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -330.41  |proj g|=       1.0556
At iterate     1  f =      -330.62  |proj g|=        1.1033
At iterate     2  f =      -330.63  |proj g|=        1.1004
At iterate     3  f =      -330.75  |proj g|=        1.0716
At iterate     4  f =      -330.89  |proj g|=        1.0504
At iterate     5  f =       -331.2  |proj g|=        1.0062
At iterate     6  f =      -331.34  |proj g|=        1.0066
At iterate     7  f =      -331.35  |proj g|=        1.0172
At iterate     8  f =      -331.35  |proj g|=        1.0177
At iterate     9  f =      -331.35  |proj g|=        1.0178

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.01776
final function value -331.35

F = -331.35
final  value -331.350394 
converged
 
INFO  [08:05:41.012] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:05:41.099] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:05:41.106] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:05:42.704] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:05:44.184] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:05:45.658] [mlr3]  Finished benchmark 
INFO  [08:05:45.755] [bbotk] Result of batch 51: 
INFO  [08:05:45.757] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:05:45.757] [bbotk]              2.504419                 5.625366                       0.1223926 
INFO  [08:05:45.757] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:05:45.757] [bbotk]                      663        0.593 -0.9682112         <NA>   0.9391452 
INFO  [08:05:45.757] [bbotk]                                 uhash 
INFO  [08:05:45.757] [bbotk]  5734cd5d-da16-46cb-874f-1b5dd732d9fb 
DEBUG [08:05:46.621] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.249085e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.249085e-05 0.001566793 
  - best initial criterion value(s) :  336.7194 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -336.72  |proj g|=       1.6872
At iterate     1  f =      -338.08  |proj g|=        2.0835
At iterate     2  f =      -338.38  |proj g|=        2.0395
At iterate     3  f =      -338.77  |proj g|=        1.9027
At iterate     4  f =      -338.93  |proj g|=        1.9489
At iterate     5  f =      -339.13  |proj g|=        1.9819
At iterate     6  f =      -339.18  |proj g|=        1.9811
At iterate     7  f =      -339.18  |proj g|=        1.9826
At iterate     8  f =      -339.18  |proj g|=        1.9839
At iterate     9  f =      -339.18  |proj g|=         1.984
At iterate    10  f =       -340.4  |proj g|=        1.8023
At iterate    11  f =      -347.56  |proj g|=        1.1303
At iterate    12  f =      -347.88  |proj g|=        1.0597
At iterate    13  f =      -347.93  |proj g|=        0.9745
At iterate    14  f =      -347.93  |proj g|=       0.92659
At iterate    15  f =      -347.93  |proj g|=       0.92075
At iterate    16  f =      -347.93  |proj g|=       0.92119
At iterate    17  f =      -347.93  |proj g|=       0.92175
At iterate    18  f =      -347.93  |proj g|=       0.92498
At iterate    19  f =      -347.94  |proj g|=       0.92837
At iterate    20  f =      -347.94  |proj g|=       0.99972
At iterate    21  f =      -347.95  |proj g|=       0.95386
At iterate    22  f =      -347.97  |proj g|=       0.88981
At iterate    23  f =      -348.03  |proj g|=       0.74158
At iterate    24  f =      -348.17  |proj g|=       0.51835
At iterate    25  f =      -348.45  |proj g|=       0.48453
At iterate    26  f =       -348.8  |proj g|=       0.50468
At iterate    27  f =         -349  |proj g|=       0.53903
At iterate    28  f =      -349.04  |proj g|=        0.5399
At iterate    29  f =      -349.11  |proj g|=       0.48699
At iterate    30  f =      -349.24  |proj g|=       0.28363
At iterate    31  f =      -349.24  |proj g|=      0.025593
At iterate    32  f =      -349.24  |proj g|=      0.017786
At iterate    33  f =      -349.24  |proj g|=      0.015437
At iterate    34  f =      -349.24  |proj g|=     0.0031134

iterations 34
function evaluations 46
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00311335
final function value -349.237

F = -349.237
final  value -349.236757 
converged
 
INFO  [08:05:46.625] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:05:46.710] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:05:46.717] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:05:50.345] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:05:54.313] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:05:59.442] [mlr3]  Finished benchmark 
INFO  [08:05:59.544] [bbotk] Result of batch 52: 
INFO  [08:05:59.546] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:05:59.546] [bbotk]               6.48925                 7.146924                       0.4684058 
INFO  [08:05:59.546] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:05:59.546] [bbotk]                     1797        0.585 -0.9597521         <NA>   0.9764684 
INFO  [08:05:59.546] [bbotk]                                 uhash 
INFO  [08:05:59.546] [bbotk]  d1dd5a49-6255-47fb-af70-d49f989baae8 
DEBUG [08:06:00.372] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.242546e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.242546e-05 0.001554635 
  - best initial criterion value(s) :  343.6576 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -343.66  |proj g|=       2.4373
At iterate     1  f =      -343.72  |proj g|=        2.6436
At iterate     2  f =      -345.04  |proj g|=        1.9874
At iterate     3  f =      -345.52  |proj g|=        1.0082
At iterate     4  f =       -345.6  |proj g|=        1.3702
At iterate     5  f =      -345.61  |proj g|=        1.3063
At iterate     6  f =      -345.61  |proj g|=         1.305
At iterate     7  f =      -345.61  |proj g|=        1.3048
At iterate     8  f =      -345.61  |proj g|=        1.3051

iterations 8
function evaluations 14
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.30508
final function value -345.608

F = -345.608
final  value -345.607977 
converged
 
INFO  [08:06:00.377] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:06:00.498] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:06:00.505] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:06:04.969] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:06:09.500] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:06:15.408] [mlr3]  Finished benchmark 
INFO  [08:06:15.517] [bbotk] Result of batch 53: 
INFO  [08:06:15.519] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:06:15.519] [bbotk]              7.860242                  4.32178                       0.1692348 
INFO  [08:06:15.519] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:06:15.519] [bbotk]                     1948        0.607 -0.9649734         <NA>   0.9727091 
INFO  [08:06:15.519] [bbotk]                                 uhash 
INFO  [08:06:15.519] [bbotk]  f5f48224-5a04-4a57-a13e-b13143eb0fdb 
DEBUG [08:06:16.540] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.230131e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.230131e-05 0.00154702 
  - best initial criterion value(s) :  345.7447 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -345.74  |proj g|=      0.87762
At iterate     1  f =      -345.99  |proj g|=         2.594
At iterate     2  f =      -347.27  |proj g|=         2.178
At iterate     3  f =      -347.75  |proj g|=        1.1729
At iterate     4  f =      -348.26  |proj g|=        1.6405
At iterate     5  f =      -350.05  |proj g|=        1.5436
At iterate     6  f =      -350.91  |proj g|=       0.65201
At iterate     7  f =      -351.12  |proj g|=       0.68194
At iterate     8  f =      -351.13  |proj g|=        0.6428
At iterate     9  f =      -351.13  |proj g|=       0.65978
At iterate    10  f =      -351.13  |proj g|=       0.65239
At iterate    11  f =      -351.13  |proj g|=       0.65234

iterations 11
function evaluations 14
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.652344
final function value -351.129

F = -351.129
final  value -351.129206 
converged
 
INFO  [08:06:16.544] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:06:16.632] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:06:16.639] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:06:22.024] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:06:26.793] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:06:32.143] [mlr3]  Finished benchmark 
INFO  [08:06:32.269] [bbotk] Result of batch 54: 
INFO  [08:06:32.271] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:06:32.271] [bbotk]              9.991253                 7.069468                      0.06578129 
INFO  [08:06:32.271] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:06:32.271] [bbotk]                     2435        0.764 -0.9650911         <NA>   0.9682942 
INFO  [08:06:32.271] [bbotk]                                 uhash 
INFO  [08:06:32.271] [bbotk]  29787ba0-7eff-4e5e-a897-d020bbff923b 
DEBUG [08:06:33.280] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.21549e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.21549e-05 0.001533336 
  - best initial criterion value(s) :  326.4006 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -326.4  |proj g|=       1.4149
At iterate     1  f =      -335.72  |proj g|=        3.0608
At iterate     2  f =      -350.89  |proj g|=        1.9564
At iterate     3  f =      -351.07  |proj g|=        1.9205
At iterate     4  f =      -351.49  |proj g|=         1.842
At iterate     5  f =      -351.54  |proj g|=        1.8147
At iterate     6  f =      -351.55  |proj g|=        1.8327
At iterate     7  f =      -351.55  |proj g|=        1.8315
At iterate     8  f =      -351.55  |proj g|=        1.8315

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.83148
final function value -351.553

F = -351.553
final  value -351.553092 
converged
 
INFO  [08:06:33.285] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:06:33.377] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:06:33.385] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:06:43.406] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:06:51.364] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:07:01.547] [mlr3]  Finished benchmark 
INFO  [08:07:01.667] [bbotk] Result of batch 55: 
INFO  [08:07:01.669] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:07:01.669] [bbotk]              7.029702                 3.713035                       0.1769499 
INFO  [08:07:01.669] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:07:01.669] [bbotk]                     3998        0.742 -0.9658402         <NA>   0.9760062 
INFO  [08:07:01.669] [bbotk]                                 uhash 
INFO  [08:07:01.669] [bbotk]  df2b693e-2d3d-4361-859c-7e918e67f6bb 
DEBUG [08:07:02.579] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.208397e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.208397e-05 0.001530733 
  - best initial criterion value(s) :  351.3725 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -351.37  |proj g|=       2.2061
At iterate     1  f =      -352.47  |proj g|=        3.1385
At iterate     2  f =      -354.81  |proj g|=        3.0594
At iterate     3  f =      -356.13  |proj g|=        2.8698
At iterate     4  f =      -356.14  |proj g|=        2.8253
At iterate     5  f =      -356.15  |proj g|=        2.8423
At iterate     6  f =      -356.15  |proj g|=        2.8432
At iterate     7  f =      -356.15  |proj g|=        2.8518
At iterate     8  f =      -356.15  |proj g|=        2.8651
At iterate     9  f =      -356.15  |proj g|=        2.8663
At iterate    10  f =      -356.15  |proj g|=        2.8665
At iterate    11  f =      -356.15  |proj g|=        2.8666
At iterate    12  f =      -356.15  |proj g|=         2.867
At iterate    13  f =      -356.15  |proj g|=        2.8675
At iterate    14  f =      -356.15  |proj g|=        2.8684
At iterate    15  f =      -356.15  |proj g|=        2.8697
At iterate    16  f =      -356.15  |proj g|=        2.8715
At iterate    17  f =      -356.15  |proj g|=        2.8732
At iterate    18  f =      -356.16  |proj g|=        2.8731
At iterate    19  f =      -356.16  |proj g|=        2.8648
At iterate    20  f =      -356.17  |proj g|=        2.8366
At iterate    21  f =      -356.19  |proj g|=        2.7669
At iterate    22  f =      -356.19  |proj g|=        2.7694
At iterate    23  f =      -356.19  |proj g|=        2.7644
At iterate    24  f =      -356.19  |proj g|=        2.7745
At iterate    25  f =      -356.21  |proj g|=        2.7988
At iterate    26  f =      -356.27  |proj g|=        2.8374
At iterate    27  f =      -356.43  |proj g|=        2.8792
At iterate    28  f =      -356.92  |proj g|=        2.8987
At iterate    29  f =      -356.93  |proj g|=        2.8729
At iterate    30  f =      -357.85  |proj g|=        2.7656
At iterate    31  f =      -363.49  |proj g|=        1.4356
At iterate    32  f =      -364.18  |proj g|=        1.7458
At iterate    33  f =      -364.23  |proj g|=         1.401
At iterate    34  f =      -364.24  |proj g|=        1.4934
At iterate    35  f =      -364.24  |proj g|=        1.4907
At iterate    36  f =      -364.24  |proj g|=        1.4898

iterations 36
function evaluations 45
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.48985
final function value -364.237

F = -364.237
final  value -364.236859 
converged
 
INFO  [08:07:02.584] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:07:02.673] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:07:02.680] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:07:11.826] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:07:20.939] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:07:29.910] [mlr3]  Finished benchmark 
INFO  [08:07:30.049] [bbotk] Result of batch 56: 
INFO  [08:07:30.052] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:07:30.052] [bbotk]               3.16315                 6.873478                       0.4932785 
INFO  [08:07:30.052] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:07:30.052] [bbotk]                     4159        0.615 -0.9637464         <NA>   0.9752039 
INFO  [08:07:30.052] [bbotk]                                 uhash 
INFO  [08:07:30.052] [bbotk]  c2aa0982-6931-4329-b09c-948fb61ee822 
DEBUG [08:07:31.097] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.199945e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.199945e-05 0.001525587 
  - best initial criterion value(s) :  351.1438 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -351.14  |proj g|=       5.2238
At iterate     1  f =      -354.06  |proj g|=        4.3284
At iterate     2  f =       -356.4  |proj g|=        4.0142
At iterate     3  f =      -357.48  |proj g|=        3.6115
At iterate     4  f =      -357.86  |proj g|=        3.3643
At iterate     5  f =      -357.96  |proj g|=        3.2494
At iterate     6  f =      -357.98  |proj g|=        3.2141
At iterate     7  f =      -357.99  |proj g|=         3.242
At iterate     8  f =      -357.99  |proj g|=        3.2279
At iterate     9  f =      -357.99  |proj g|=        3.2301
At iterate    10  f =      -357.99  |proj g|=        3.2327
At iterate    11  f =      -357.99  |proj g|=        3.2361
At iterate    12  f =      -357.99  |proj g|=        3.2515
At iterate    13  f =         -358  |proj g|=        3.2713
At iterate    14  f =      -358.01  |proj g|=         3.311
At iterate    15  f =      -358.07  |proj g|=        3.3804
At iterate    16  f =      -358.18  |proj g|=         3.425
At iterate    17  f =      -358.47  |proj g|=        3.5901
At iterate    18  f =      -358.85  |proj g|=        3.2636
At iterate    19  f =      -360.76  |proj g|=        3.0748
At iterate    20  f =      -367.09  |proj g|=        1.9866
At iterate    21  f =       -372.6  |proj g|=        1.1241
At iterate    22  f =      -373.02  |proj g|=        1.0528
At iterate    23  f =      -375.23  |proj g|=       0.29549
At iterate    24  f =      -375.24  |proj g|=       0.44842
At iterate    25  f =      -375.24  |proj g|=       0.18923
At iterate    26  f =      -375.24  |proj g|=       0.18794
At iterate    27  f =      -375.24  |proj g|=       0.18797

iterations 27
function evaluations 35
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.187967
final function value -375.239

F = -375.239
final  value -375.238767 
converged
 
INFO  [08:07:31.102] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:07:31.195] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:07:31.202] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:07:34.978] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:07:39.000] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:07:41.618] [mlr3]  Finished benchmark 
INFO  [08:07:41.814] [bbotk] Result of batch 57: 
INFO  [08:07:41.817] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:07:41.817] [bbotk]              4.684902                  2.84836                       0.0911296 
INFO  [08:07:41.817] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [08:07:41.817] [bbotk]                     1128        0.756 -0.961924         <NA>   0.9604365 
INFO  [08:07:41.817] [bbotk]                                 uhash 
INFO  [08:07:41.817] [bbotk]  a9e49012-bb19-4fd3-8563-f0a49bc1b6c8 
DEBUG [08:07:42.907] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.193188e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.193188e-05 0.001510775 
  - best initial criterion value(s) :  374.9197 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -374.92  |proj g|=       1.5053
At iterate     1  f =      -375.36  |proj g|=        3.5674
At iterate     2  f =       -376.3  |proj g|=        3.0991
At iterate     3  f =      -376.44  |proj g|=        2.5268
At iterate     4  f =      -376.49  |proj g|=        2.7563
At iterate     5  f =      -376.49  |proj g|=        2.7254
At iterate     6  f =      -376.49  |proj g|=        2.6931
At iterate     7  f =       -376.5  |proj g|=        2.6363
At iterate     8  f =      -376.51  |proj g|=        2.5811
At iterate     9  f =      -376.51  |proj g|=        2.5772
At iterate    10  f =      -376.51  |proj g|=        2.5867
At iterate    11  f =      -376.51  |proj g|=        2.5893
At iterate    12  f =      -376.51  |proj g|=        2.5896

iterations 12
function evaluations 14
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.58963
final function value -376.511

F = -376.511
final  value -376.510522 
converged
 
INFO  [08:07:42.912] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:07:43.014] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:07:43.023] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:07:44.760] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:07:46.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:07:48.148] [mlr3]  Finished benchmark 
INFO  [08:07:48.300] [bbotk] Result of batch 58: 
INFO  [08:07:48.302] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:07:48.302] [bbotk]              2.896692                 9.728196                       0.2186503 
INFO  [08:07:48.302] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [08:07:48.302] [bbotk]                      971          0.8 -0.963201         <NA>   0.9584731 
INFO  [08:07:48.302] [bbotk]                                 uhash 
INFO  [08:07:48.302] [bbotk]  bb8f6685-de13-4fd4-aebc-759a86e31721 
DEBUG [08:07:49.525] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.190294e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.190294e-05 0.001503721 
  - best initial criterion value(s) :  378.8947 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -378.89  |proj g|=       1.8366
At iterate     1  f =      -382.04  |proj g|=        1.9908
At iterate     2  f =      -385.45  |proj g|=        1.0206
At iterate     3  f =      -385.72  |proj g|=         1.139
At iterate     4  f =      -385.73  |proj g|=        1.1388
At iterate     5  f =      -385.73  |proj g|=        1.1411
At iterate     6  f =      -385.73  |proj g|=         1.142
At iterate     7  f =      -385.73  |proj g|=        1.1422
At iterate     8  f =      -385.73  |proj g|=        1.1422

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.14223
final function value -385.734

F = -385.734
final  value -385.734337 
converged
 
INFO  [08:07:49.529] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:07:49.622] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:07:49.629] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:07:55.117] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:08:00.549] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:08:05.914] [mlr3]  Finished benchmark 
INFO  [08:08:06.520] [bbotk] Result of batch 59: 
INFO  [08:08:06.522] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:08:06.522] [bbotk]              8.083747                 3.147346                       0.2087425 
INFO  [08:08:06.522] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [08:08:06.522] [bbotk]                     3347         0.94 -0.961336         <NA>   0.9763935 
INFO  [08:08:06.522] [bbotk]                                 uhash 
INFO  [08:08:06.522] [bbotk]  8a8e4794-0595-4517-be93-05b2d7e24264 
DEBUG [08:08:07.531] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.184551e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.184551e-05 0.001502124 
  - best initial criterion value(s) :  365.7312 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -365.73  |proj g|=       1.9234
At iterate     1  f =       -368.1  |proj g|=        2.2785
At iterate     2  f =      -369.27  |proj g|=        2.2022
At iterate     3  f =      -371.43  |proj g|=        1.9249
At iterate     4  f =      -371.96  |proj g|=        1.8655
At iterate     5  f =      -373.12  |proj g|=        1.9222
At iterate     6  f =      -373.17  |proj g|=        1.9819
At iterate     7  f =      -373.34  |proj g|=        1.9702
At iterate     8  f =      -373.35  |proj g|=        1.9677
At iterate     9  f =      -373.35  |proj g|=        1.9682
At iterate    10  f =      -373.35  |proj g|=        1.9684
At iterate    11  f =      -373.35  |proj g|=        1.9686
At iterate    12  f =      -373.35  |proj g|=        1.9687
At iterate    13  f =      -373.35  |proj g|=        1.9692
At iterate    14  f =      -373.35  |proj g|=        1.9695
At iterate    15  f =      -373.35  |proj g|=        1.9704
At iterate    16  f =      -373.35  |proj g|=        1.9712
At iterate    17  f =      -373.35  |proj g|=        1.9732
At iterate    18  f =      -373.36  |proj g|=        1.9746
At iterate    19  f =      -373.36  |proj g|=        1.9797
At iterate    20  f =      -373.37  |proj g|=        1.9776
At iterate    21  f =      -373.38  |proj g|=        1.9896
At iterate    22  f =      -373.41  |proj g|=        1.9797
At iterate    23  f =      -375.88  |proj g|=        1.4689
At iterate    24  f =      -376.02  |proj g|=        1.2772
At iterate    25  f =      -376.06  |proj g|=        1.3443
At iterate    26  f =      -376.06  |proj g|=        1.3408
At iterate    27  f =      -376.06  |proj g|=        1.3324
At iterate    28  f =      -376.06  |proj g|=        1.3327
At iterate    29  f =      -376.06  |proj g|=        1.3342
At iterate    30  f =      -376.06  |proj g|=        1.3338
At iterate    31  f =      -376.06  |proj g|=        1.3338

iterations 31
function evaluations 39
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.33379
final function value -376.062

F = -376.062
final  value -376.062153 
converged
 
INFO  [08:08:07.536] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:08:07.621] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:08:07.627] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:08:09.450] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:08:11.332] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:08:13.222] [mlr3]  Finished benchmark 
INFO  [08:08:13.319] [bbotk] Result of batch 60: 
INFO  [08:08:13.321] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:08:13.321] [bbotk]              9.569572                 7.391537                      0.07175263 
INFO  [08:08:13.321] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:08:13.321] [bbotk]                     1075        0.698 -0.9667992         <NA>   0.9613065 
INFO  [08:08:13.321] [bbotk]                                 uhash 
INFO  [08:08:13.321] [bbotk]  f84f00a4-fb34-4019-b9fd-079bddfae045 
DEBUG [08:08:14.263] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.176609e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.176609e-05 0.001487097 
  - best initial criterion value(s) :  390.2796 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -390.28  |proj g|=       1.9917
At iterate     1  f =       -390.3  |proj g|=        2.8803
At iterate     2  f =      -390.59  |proj g|=        2.5452
At iterate     3  f =      -390.61  |proj g|=        2.4176
At iterate     4  f =      -390.65  |proj g|=        2.3379
At iterate     5  f =      -390.71  |proj g|=        2.1436
At iterate     6  f =      -390.71  |proj g|=        2.1561
At iterate     7  f =      -390.72  |proj g|=        2.1671
At iterate     8  f =      -390.72  |proj g|=        2.1776
At iterate     9  f =      -390.79  |proj g|=        2.2228
At iterate    10  f =      -390.94  |proj g|=         2.252
At iterate    11  f =      -391.32  |proj g|=        2.2078
At iterate    12  f =      -391.52  |proj g|=         2.724
At iterate    13  f =      -392.58  |proj g|=        1.9954
At iterate    14  f =      -393.59  |proj g|=        1.3161
At iterate    15  f =       -395.5  |proj g|=       0.52128
At iterate    16  f =      -396.14  |proj g|=       0.53069
At iterate    17  f =      -396.68  |proj g|=       0.68558
At iterate    18  f =      -396.68  |proj g|=       0.68584
At iterate    19  f =      -396.68  |proj g|=        0.6843
At iterate    20  f =      -396.68  |proj g|=       0.68362
At iterate    21  f =      -396.68  |proj g|=       0.68307

iterations 21
function evaluations 28
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.683072
final function value -396.68

F = -396.68
final  value -396.680395 
converged
 
INFO  [08:08:14.268] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:08:14.368] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:08:14.375] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:08:17.933] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:08:21.503] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:08:25.078] [mlr3]  Finished benchmark 
INFO  [08:08:25.198] [bbotk] Result of batch 61: 
INFO  [08:08:25.200] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:08:25.200] [bbotk]              6.349453                 2.193027                       0.3910405 
INFO  [08:08:25.200] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:08:25.200] [bbotk]                     2290        0.661 -0.9611752         <NA>   0.9766309 
INFO  [08:08:25.200] [bbotk]                                 uhash 
INFO  [08:08:25.200] [bbotk]  dc169d27-a6df-40e1-a2d3-c34887ea0f8e 
DEBUG [08:08:26.142] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.171548e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.171548e-05 0.001486711 
  - best initial criterion value(s) :  378.2151 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -378.22  |proj g|=       3.2496
At iterate     1  f =      -380.47  |proj g|=        3.9264
At iterate     2  f =      -385.28  |proj g|=        3.5772
At iterate     3  f =      -387.96  |proj g|=         3.173
At iterate     4  f =       -388.1  |proj g|=        3.0829
At iterate     5  f =      -388.14  |proj g|=        3.0755
At iterate     6  f =      -388.17  |proj g|=         3.107
At iterate     7  f =      -388.17  |proj g|=        3.1405
At iterate     8  f =      -388.17  |proj g|=        3.1355
At iterate     9  f =      -388.17  |proj g|=        3.1354
At iterate    10  f =      -388.17  |proj g|=        3.1353
At iterate    11  f =      -388.17  |proj g|=         3.135
At iterate    12  f =      -388.17  |proj g|=        3.1347
At iterate    13  f =      -388.17  |proj g|=        3.1343
At iterate    14  f =      -388.18  |proj g|=        3.1342
At iterate    15  f =      -388.18  |proj g|=        3.1353
At iterate    16  f =      -388.18  |proj g|=        3.1376
At iterate    17  f =      -388.19  |proj g|=        3.1384
At iterate    18  f =       -388.2  |proj g|=        3.1577
At iterate    19  f =      -388.22  |proj g|=        3.1256
At iterate    20  f =      -388.27  |proj g|=        3.1283
At iterate    21  f =      -388.86  |proj g|=        3.0514
At iterate    22  f =      -389.77  |proj g|=        2.8309
At iterate    23  f =      -392.48  |proj g|=        2.1935
At iterate    24  f =      -396.81  |proj g|=        1.4597
At iterate    25  f =      -397.22  |proj g|=        1.2931
At iterate    26  f =      -400.74  |proj g|=        1.1927
At iterate    27  f =      -400.87  |proj g|=        1.2053
At iterate    28  f =      -400.91  |proj g|=        1.2231
At iterate    29  f =      -400.91  |proj g|=        1.2278
At iterate    30  f =      -400.91  |proj g|=        1.2279
At iterate    31  f =      -400.91  |proj g|=        1.2299

iterations 31
function evaluations 39
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.22989
final function value -400.907

F = -400.907
final  value -400.907086 
converged
 
INFO  [08:08:26.148] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:08:26.245] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:08:26.254] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:08:31.043] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:08:35.709] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:08:40.266] [mlr3]  Finished benchmark 
INFO  [08:08:40.366] [bbotk] Result of batch 62: 
INFO  [08:08:40.368] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:08:40.368] [bbotk]              3.839743                 6.810533                       0.2492224 
INFO  [08:08:40.368] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:08:40.368] [bbotk]                     3044        0.627 -0.9613696         <NA>   0.9738767 
INFO  [08:08:40.368] [bbotk]                                 uhash 
INFO  [08:08:40.368] [bbotk]  b26fccc8-8b23-40a9-97f1-eb55e7b6ae5a 
DEBUG [08:08:41.294] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.16226e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.16226e-05 0.001481054 
  - best initial criterion value(s) :  393.9513 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -393.95  |proj g|=       2.1197
At iterate     1  f =      -394.33  |proj g|=        2.2735
At iterate     2  f =      -394.34  |proj g|=        2.2624
At iterate     3  f =      -394.41  |proj g|=        2.1752
At iterate     4  f =      -394.41  |proj g|=        2.1795
At iterate     5  f =      -394.41  |proj g|=        2.1827
At iterate     6  f =      -394.41  |proj g|=        2.1827

iterations 6
function evaluations 10
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.18271
final function value -394.415

F = -394.415
final  value -394.414553 
converged
 
INFO  [08:08:41.299] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:08:41.404] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:08:41.411] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:08:46.967] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:08:54.629] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:09:03.160] [mlr3]  Finished benchmark 
INFO  [08:09:03.259] [bbotk] Result of batch 63: 
INFO  [08:09:03.261] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:09:03.261] [bbotk]              6.368455                 2.377164                        0.387376 
INFO  [08:09:03.261] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:09:03.261] [bbotk]                     3662        0.695 -0.9643429         <NA>   0.9779896 
INFO  [08:09:03.261] [bbotk]                                 uhash 
INFO  [08:09:03.261] [bbotk]  a6048477-7c5c-4991-b85b-82c7437057ce 
DEBUG [08:09:04.116] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.159801e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.159801e-05 0.001482401 
  - best initial criterion value(s) :  382.5585 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -382.56  |proj g|=       1.4635
At iterate     1  f =      -389.33  |proj g|=        5.1389
At iterate     2  f =      -390.28  |proj g|=        4.8753
At iterate     3  f =      -391.43  |proj g|=        4.1003
At iterate     4  f =      -391.49  |proj g|=        3.9269
At iterate     5  f =      -391.59  |proj g|=        3.8307
At iterate     6  f =       -392.4  |proj g|=        3.0004
At iterate     7  f =      -392.98  |proj g|=        2.8382
At iterate     8  f =      -393.22  |proj g|=        3.0312
At iterate     9  f =      -393.22  |proj g|=        3.0557
At iterate    10  f =      -393.22  |proj g|=        3.0465
At iterate    11  f =      -393.22  |proj g|=        3.0471

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.04715
final function value -393.224

F = -393.224
final  value -393.223526 
converged
 
INFO  [08:09:04.120] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:09:04.205] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:09:04.212] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:09:05.681] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:09:08.779] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:09:11.883] [mlr3]  Finished benchmark 
INFO  [08:09:12.016] [bbotk] Result of batch 64: 
INFO  [08:09:12.018] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:09:12.018] [bbotk]              5.000514                 7.292445                      0.07721008 
INFO  [08:09:12.018] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:09:12.018] [bbotk]                      601        0.626 -0.9669844         <NA>   0.9495035 
INFO  [08:09:12.018] [bbotk]                                 uhash 
INFO  [08:09:12.018] [bbotk]  7911330c-90f6-4df8-92a1-d740671b9352 
DEBUG [08:09:12.890] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.184967e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.184967e-05 0.00151958 
  - best initial criterion value(s) :  385.9861 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -385.99  |proj g|=       1.9611
At iterate     1  f =       -392.4  |proj g|=        2.0767
At iterate     2  f =      -393.86  |proj g|=        1.8284
At iterate     3  f =      -394.79  |proj g|=        1.4541
At iterate     4  f =      -394.84  |proj g|=        1.2871
At iterate     5  f =      -394.85  |proj g|=        1.3296
At iterate     6  f =      -394.86  |proj g|=        1.3451
At iterate     7  f =       -394.9  |proj g|=         1.378
At iterate     8  f =      -394.93  |proj g|=        1.3622
At iterate     9  f =      -394.95  |proj g|=        1.3114
At iterate    10  f =      -394.95  |proj g|=        1.3032
At iterate    11  f =      -394.95  |proj g|=        1.3028
At iterate    12  f =      -394.95  |proj g|=        1.3028

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.30275
final function value -394.947

F = -394.947
final  value -394.947269 
converged
 
INFO  [08:09:12.894] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:09:12.982] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:09:12.989] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:09:23.139] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:09:32.612] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:09:44.133] [mlr3]  Finished benchmark 
INFO  [08:09:44.233] [bbotk] Result of batch 65: 
INFO  [08:09:44.235] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:09:44.235] [bbotk]              2.868393                 6.035142                      0.06820346 
INFO  [08:09:44.235] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:09:44.235] [bbotk]                     4328        0.624 -0.9622494         <NA>   0.9618823 
INFO  [08:09:44.235] [bbotk]                                 uhash 
INFO  [08:09:44.235] [bbotk]  359900dc-27fc-4055-86b4-0f1180c47985 
DEBUG [08:09:45.221] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.176626e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.176626e-05 0.001505848 
  - best initial criterion value(s) :  392.8325 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -392.83  |proj g|=       4.2283
At iterate     1  f =      -395.38  |proj g|=        5.4607
At iterate     2  f =      -395.45  |proj g|=        5.3557
At iterate     3  f =      -395.76  |proj g|=        4.6276
At iterate     4  f =      -395.97  |proj g|=        4.2868
At iterate     5  f =      -396.48  |proj g|=        3.3424
At iterate     6  f =      -396.48  |proj g|=        3.3596
At iterate     7  f =      -396.48  |proj g|=         3.362
At iterate     8  f =      -396.48  |proj g|=        3.3625
At iterate     9  f =      -396.48  |proj g|=        3.3652
At iterate    10  f =      -396.48  |proj g|=        3.3683
At iterate    11  f =      -396.48  |proj g|=        3.3742
At iterate    12  f =      -396.48  |proj g|=        3.3835
At iterate    13  f =      -396.48  |proj g|=        3.3996
At iterate    14  f =      -396.49  |proj g|=        3.4271
At iterate    15  f =      -396.49  |proj g|=         3.476
At iterate    16  f =      -396.51  |proj g|=        3.5641
At iterate    17  f =      -396.54  |proj g|=        3.7194
At iterate    18  f =      -396.62  |proj g|=        3.9626
At iterate    19  f =      -396.76  |proj g|=         4.211
At iterate    20  f =      -396.83  |proj g|=         3.964
At iterate    21  f =      -396.85  |proj g|=        4.1528
At iterate    22  f =      -396.85  |proj g|=        4.1498
At iterate    23  f =      -396.85  |proj g|=        4.1501
At iterate    24  f =      -396.85  |proj g|=         4.151
At iterate    25  f =      -396.85  |proj g|=        4.1527
At iterate    26  f =      -396.85  |proj g|=        4.1564
At iterate    27  f =      -396.85  |proj g|=        4.1606
At iterate    28  f =      -396.85  |proj g|=         4.175
At iterate    29  f =      -396.85  |proj g|=        4.1592
At iterate    30  f =      -396.85  |proj g|=        4.1808
At iterate    31  f =      -400.43  |proj g|=         3.774
At iterate    32  f =       -406.9  |proj g|=        2.4177
At iterate    33  f =       -412.3  |proj g|=        1.1709
At iterate    34  f =       -414.5  |proj g|=       0.88453
At iterate    35  f =      -414.94  |proj g|=        1.1613
At iterate    36  f =      -415.51  |proj g|=        1.0316
At iterate    37  f =      -415.58  |proj g|=        1.0083
At iterate    38  f =      -415.77  |proj g|=       0.96383
At iterate    39  f =      -415.77  |proj g|=       0.98093
At iterate    40  f =      -415.94  |proj g|=       0.97986
At iterate    41  f =      -415.94  |proj g|=       0.98151
At iterate    42  f =      -415.94  |proj g|=        0.9813

iterations 42
function evaluations 48
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.981301
final function value -415.944

F = -415.944
final  value -415.943728 
converged
 
INFO  [08:09:45.225] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:09:45.338] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:09:45.349] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:09:47.585] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:09:49.552] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:09:52.651] [mlr3]  Finished benchmark 
INFO  [08:09:52.752] [bbotk] Result of batch 66: 
INFO  [08:09:52.754] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:09:52.754] [bbotk]              5.478709                 8.047706                       0.4435069 
INFO  [08:09:52.754] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:09:52.754] [bbotk]                      914        0.649 -0.9532722         <NA>   0.9728844 
INFO  [08:09:52.754] [bbotk]                                 uhash 
INFO  [08:09:52.754] [bbotk]  3747680b-6a7f-4c49-b6e6-321751f88c33 
DEBUG [08:09:53.630] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.166714e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.166714e-05 0.001479717 
  - best initial criterion value(s) :  392.8647 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -392.86  |proj g|=       2.2365
At iterate     1  f =       -396.1  |proj g|=        3.2303
At iterate     2  f =      -404.03  |proj g|=        2.4339
At iterate     3  f =      -406.01  |proj g|=        1.4682
At iterate     4  f =      -406.05  |proj g|=        1.7697
At iterate     5  f =       -406.1  |proj g|=        1.6591
At iterate     6  f =      -406.11  |proj g|=        1.6273
At iterate     7  f =      -406.11  |proj g|=        1.6192
At iterate     8  f =      -406.11  |proj g|=        1.6252
At iterate     9  f =      -406.11  |proj g|=        1.6327
At iterate    10  f =      -406.11  |proj g|=        1.6327

iterations 10
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.63274
final function value -406.114

F = -406.114
final  value -406.114314 
converged
 
INFO  [08:09:53.634] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:09:53.721] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:09:53.728] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:09:59.812] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:10:08.297] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:10:16.057] [mlr3]  Finished benchmark 
INFO  [08:10:16.161] [bbotk] Result of batch 67: 
INFO  [08:10:16.163] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:10:16.163] [bbotk]              2.088346                 3.904088                       0.3702055 
INFO  [08:10:16.163] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:10:16.163] [bbotk]                     3056        0.645 -0.9620937         <NA>   0.9630628 
INFO  [08:10:16.163] [bbotk]                                 uhash 
INFO  [08:10:16.163] [bbotk]  e4b9d737-4705-4765-8733-5edeb8687e4a 
DEBUG [08:10:17.137] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.157342e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.157342e-05 0.001466212 
  - best initial criterion value(s) :  390.5167 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -390.52  |proj g|=       5.6569
At iterate     1  f =      -394.14  |proj g|=        3.3648
At iterate     2  f =       -398.8  |proj g|=         2.859
At iterate     3  f =      -401.48  |proj g|=        2.0269
At iterate     4  f =      -402.47  |proj g|=        1.6522
At iterate     5  f =      -402.83  |proj g|=        1.5374
At iterate     6  f =      -402.97  |proj g|=         1.557
At iterate     7  f =      -403.01  |proj g|=        1.7893
At iterate     8  f =      -403.02  |proj g|=        1.7038
At iterate     9  f =      -403.02  |proj g|=        1.7097
At iterate    10  f =      -403.02  |proj g|=        1.7105
At iterate    11  f =      -403.02  |proj g|=        1.7117
At iterate    12  f =      -403.02  |proj g|=        1.7153
At iterate    13  f =      -403.02  |proj g|=        1.7274
At iterate    14  f =      -403.02  |proj g|=        1.7309
At iterate    15  f =      -403.02  |proj g|=        1.7488
At iterate    16  f =      -403.02  |proj g|=         1.741
At iterate    17  f =      -403.03  |proj g|=        1.7702
At iterate    18  f =      -403.11  |proj g|=        1.8066
At iterate    19  f =      -403.94  |proj g|=        1.8454
At iterate    20  f =      -405.38  |proj g|=         1.458
At iterate    21  f =      -407.73  |proj g|=       0.85948
At iterate    22  f =      -407.94  |proj g|=       0.71673
At iterate    23  f =      -409.99  |proj g|=       0.48684
At iterate    24  f =      -411.57  |proj g|=       0.23537
At iterate    25  f =      -411.63  |proj g|=       0.51227
At iterate    26  f =      -411.66  |proj g|=       0.52598
At iterate    27  f =      -411.66  |proj g|=       0.44876
At iterate    28  f =      -411.66  |proj g|=       0.44728
At iterate    29  f =      -411.66  |proj g|=       0.44585
At iterate    30  f =      -411.66  |proj g|=       0.44586

iterations 30
function evaluations 37
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.445865
final function value -411.66

F = -411.66
final  value -411.660394 
converged
 
INFO  [08:10:17.141] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:10:17.270] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:10:17.278] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:10:22.982] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:10:26.851] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:10:32.390] [mlr3]  Finished benchmark 
INFO  [08:10:32.493] [bbotk] Result of batch 68: 
INFO  [08:10:32.495] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:10:32.495] [bbotk]              8.092162                 8.073931                       0.3390861 
INFO  [08:10:32.495] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:10:32.495] [bbotk]                     1769        0.664 -0.9570137         <NA>   0.9757614 
INFO  [08:10:32.495] [bbotk]                                 uhash 
INFO  [08:10:32.495] [bbotk]  10744ee1-416a-4b7d-8a97-a7db758bbc18 
DEBUG [08:10:33.403] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.151442e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.151442e-05 0.001453337 
  - best initial criterion value(s) :  407.7752 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -407.78  |proj g|=       1.7367
At iterate     1  f =      -409.26  |proj g|=        1.3149
At iterate     2  f =      -409.66  |proj g|=        1.5571
At iterate     3  f =      -409.82  |proj g|=        1.6832
At iterate     4  f =      -409.83  |proj g|=        1.7312
At iterate     5  f =      -409.83  |proj g|=        1.7448
At iterate     6  f =      -409.83  |proj g|=        1.7468
At iterate     7  f =      -409.83  |proj g|=        1.7471

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.74708
final function value -409.831

F = -409.831
final  value -409.831219 
converged
 
INFO  [08:10:33.407] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:10:33.495] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:10:33.502] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:10:42.496] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:10:52.618] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:11:00.872] [mlr3]  Finished benchmark 
INFO  [08:11:00.975] [bbotk] Result of batch 69: 
INFO  [08:11:00.977] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:11:00.977] [bbotk]              4.798426                 9.094798                      0.03256753 
INFO  [08:11:00.977] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:11:00.977] [bbotk]                     3814        0.667 -0.9641262         <NA>   0.9627664 
INFO  [08:11:00.977] [bbotk]                                 uhash 
INFO  [08:11:00.977] [bbotk]  1b1a0d9c-41db-4928-a9f3-ecb1b76f17a1 
DEBUG [08:11:02.216] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.142752e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.142752e-05 0.001438719 
  - best initial criterion value(s) :  408.2742 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -408.27  |proj g|=       2.1578
At iterate     1  f =      -414.44  |proj g|=        1.7209
At iterate     2  f =      -414.88  |proj g|=        1.6338
At iterate     3  f =      -416.14  |proj g|=       0.84357
At iterate     4  f =      -416.67  |proj g|=        1.1387
At iterate     5  f =      -416.85  |proj g|=        1.1479
At iterate     6  f =      -417.05  |proj g|=        1.1136
At iterate     7  f =      -417.06  |proj g|=        1.1354
At iterate     8  f =      -417.06  |proj g|=        1.1459
At iterate     9  f =      -417.06  |proj g|=        1.1475
At iterate    10  f =      -417.06  |proj g|=        1.1477

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.14774
final function value -417.06

F = -417.06
final  value -417.059863 
converged
 
INFO  [08:11:02.220] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:11:02.352] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:11:02.360] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:11:08.637] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:11:15.233] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:11:21.916] [mlr3]  Finished benchmark 
INFO  [08:11:22.020] [bbotk] Result of batch 70: 
INFO  [08:11:22.021] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:11:22.021] [bbotk]              5.700827                 4.248341                       0.2617126 
INFO  [08:11:22.021] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:11:22.021] [bbotk]                     2933        0.959 -0.9620881         <NA>   0.9758781 
INFO  [08:11:22.021] [bbotk]                                 uhash 
INFO  [08:11:22.021] [bbotk]  482bc584-9d01-46bb-9b22-660cd9aac017 
DEBUG [08:11:23.064] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.137261e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.137261e-05 0.001442017 
  - best initial criterion value(s) :  415.6174 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -415.62  |proj g|=       2.9633
At iterate     1  f =      -422.33  |proj g|=         4.592
At iterate     2  f =      -423.85  |proj g|=        4.5406
At iterate     3  f =      -424.88  |proj g|=        4.3977
At iterate     4  f =      -424.93  |proj g|=        4.3619
At iterate     5  f =      -424.95  |proj g|=        4.3919
At iterate     6  f =      -424.98  |proj g|=        4.5139
At iterate     7  f =         -425  |proj g|=        4.6293
At iterate     8  f =      -425.01  |proj g|=        4.6686
At iterate     9  f =      -425.01  |proj g|=          4.67
At iterate    10  f =      -425.01  |proj g|=        4.6739
At iterate    11  f =      -425.01  |proj g|=         4.678
At iterate    12  f =      -425.01  |proj g|=        4.6864
At iterate    13  f =      -425.01  |proj g|=        4.6996
At iterate    14  f =      -425.01  |proj g|=        4.7215
At iterate    15  f =      -425.02  |proj g|=        4.7546
At iterate    16  f =      -425.03  |proj g|=        4.8058
At iterate    17  f =      -425.05  |proj g|=        4.8851
At iterate    18  f =      -425.06  |proj g|=        4.9555
At iterate    19  f =      -425.11  |proj g|=        4.9979
At iterate    20  f =      -425.44  |proj g|=        5.0957
At iterate    21  f =      -426.16  |proj g|=        5.0558
At iterate    22  f =      -427.98  |proj g|=        4.5353
At iterate    23  f =      -430.42  |proj g|=        3.5203
At iterate    24  f =      -430.47  |proj g|=        3.3608
At iterate    25  f =      -432.43  |proj g|=        2.4909
At iterate    26  f =      -434.66  |proj g|=        2.0595
At iterate    27  f =      -435.59  |proj g|=        1.9366
At iterate    28  f =       -435.8  |proj g|=        2.1556
At iterate    29  f =      -435.82  |proj g|=        2.1877
At iterate    30  f =      -435.82  |proj g|=        2.1643
At iterate    31  f =      -435.82  |proj g|=        2.1853
At iterate    32  f =      -435.82  |proj g|=        2.1845
At iterate    33  f =      -435.82  |proj g|=        2.1845

iterations 33
function evaluations 40
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.18446
final function value -435.822

F = -435.822
final  value -435.821593 
converged
 
INFO  [08:11:23.068] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:11:23.201] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:11:23.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:11:31.685] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:11:41.755] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:11:50.486] [mlr3]  Finished benchmark 
INFO  [08:11:50.603] [bbotk] Result of batch 71: 
INFO  [08:11:50.604] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:11:50.604] [bbotk]              2.368412                 4.029089                       0.3360768 
INFO  [08:11:50.604] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:11:50.604] [bbotk]                     3928        0.723 -0.9594605         <NA>   0.9672663 
INFO  [08:11:50.604] [bbotk]                                 uhash 
INFO  [08:11:50.604] [bbotk]  742d93d9-e4e2-43d9-8eb5-8d2576b641b8 
DEBUG [08:11:51.718] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.126089e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.126089e-05 0.001427071 
  - best initial criterion value(s) :  410.3472 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -410.35  |proj g|=      0.84577
At iterate     1  f =      -417.75  |proj g|=        7.1579
At iterate     2  f =      -422.39  |proj g|=        5.9999
At iterate     3  f =      -424.12  |proj g|=        5.1491
At iterate     4  f =      -427.76  |proj g|=        3.7197
At iterate     5  f =      -434.07  |proj g|=        2.9206
At iterate     6  f =      -436.66  |proj g|=         3.932
At iterate     7  f =      -436.68  |proj g|=        4.0001
At iterate     8  f =      -436.68  |proj g|=        3.9799
At iterate     9  f =      -436.68  |proj g|=        3.9742
At iterate    10  f =      -436.68  |proj g|=        3.9745

iterations 10
function evaluations 17
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.9745
final function value -436.678

F = -436.678
final  value -436.678030 
converged
 
INFO  [08:11:51.722] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:11:51.809] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:11:51.816] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:11:59.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:12:08.289] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:12:16.455] [mlr3]  Finished benchmark 
INFO  [08:12:16.554] [bbotk] Result of batch 72: 
INFO  [08:12:16.556] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:12:16.556] [bbotk]              9.955244                 7.945011                       0.1255296 
INFO  [08:12:16.556] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:12:16.556] [bbotk]                     4981        0.789 -0.9596031         <NA>   0.9761078 
INFO  [08:12:16.556] [bbotk]                                 uhash 
INFO  [08:12:16.556] [bbotk]  4363119f-4845-4514-85a8-f7045877b6c9 
DEBUG [08:12:17.642] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.121116e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.121116e-05 0.001422943 
  - best initial criterion value(s) :  436.9597 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -436.96  |proj g|=       1.8269
At iterate     1  f =      -441.24  |proj g|=        2.5877
At iterate     2  f =      -444.01  |proj g|=        2.0785
At iterate     3  f =      -445.81  |proj g|=        1.3298
At iterate     4  f =      -446.11  |proj g|=        1.0153
At iterate     5  f =      -446.38  |proj g|=       0.99471
At iterate     6  f =      -447.98  |proj g|=        1.2467
At iterate     7  f =      -448.46  |proj g|=        1.6884
At iterate     8  f =      -448.55  |proj g|=        1.7175
At iterate     9  f =      -448.57  |proj g|=        1.7347
At iterate    10  f =      -448.57  |proj g|=        1.7326
At iterate    11  f =      -448.57  |proj g|=        1.7346
At iterate    12  f =      -448.97  |proj g|=        1.6499
At iterate    13  f =      -450.37  |proj g|=         1.183
At iterate    14  f =      -451.95  |proj g|=       0.74808
At iterate    15  f =      -452.63  |proj g|=       0.76645
At iterate    16  f =      -452.66  |proj g|=        0.7196
At iterate    17  f =      -453.06  |proj g|=       0.72712
At iterate    18  f =       -453.1  |proj g|=       0.73726
At iterate    19  f =       -453.1  |proj g|=       0.74154
At iterate    20  f =       -453.1  |proj g|=       0.74383
At iterate    21  f =       -453.1  |proj g|=       0.74433
At iterate    22  f =       -453.1  |proj g|=       0.74442

iterations 22
function evaluations 33
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.74442
final function value -453.1

F = -453.1
final  value -453.099944 
converged
 
INFO  [08:12:17.646] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:12:17.734] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:12:17.741] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:12:22.064] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:12:26.299] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:12:30.212] [mlr3]  Finished benchmark 
INFO  [08:12:30.328] [bbotk] Result of batch 73: 
INFO  [08:12:30.329] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:12:30.329] [bbotk]              2.598731                 5.261964                      0.02371887 
INFO  [08:12:30.329] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:12:30.329] [bbotk]                     2705        0.747 -0.9516667         <NA>   0.9362248 
INFO  [08:12:30.329] [bbotk]                                 uhash 
INFO  [08:12:30.329] [bbotk]  878382c2-9adb-47c1-8f45-ec4e097f1164 
DEBUG [08:12:31.229] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.209028e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.209028e-05 0.001472299 
  - best initial criterion value(s) :  421.6886 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -421.69  |proj g|=       1.0336
At iterate     1  f =      -423.44  |proj g|=       0.90554
At iterate     2  f =      -423.55  |proj g|=       0.86443
At iterate     3  f =      -423.58  |proj g|=       0.83161
At iterate     4  f =      -423.63  |proj g|=       0.81945
At iterate     5  f =      -424.04  |proj g|=       0.74276
At iterate     6  f =      -424.25  |proj g|=       0.72082
At iterate     7  f =      -424.32  |proj g|=       0.72956
At iterate     8  f =      -424.33  |proj g|=       0.74125
At iterate     9  f =      -424.33  |proj g|=       0.74712
At iterate    10  f =      -424.33  |proj g|=       0.74813
At iterate    11  f =      -424.33  |proj g|=       0.74814

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.748143
final function value -424.33

F = -424.33
final  value -424.330230 
converged
 
INFO  [08:12:31.233] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:12:31.321] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:12:31.328] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:12:36.339] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:12:41.595] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:12:46.797] [mlr3]  Finished benchmark 
INFO  [08:12:46.897] [bbotk] Result of batch 74: 
INFO  [08:12:46.899] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:12:46.899] [bbotk]              6.474885                 8.970507                       0.3445566 
INFO  [08:12:46.899] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:12:46.899] [bbotk]                     3462        0.645 -0.9633201         <NA>   0.9774987 
INFO  [08:12:46.899] [bbotk]                                 uhash 
INFO  [08:12:46.899] [bbotk]  5f85548b-9224-41c1-a1ee-7bb1e7eb5261 
DEBUG [08:12:47.918] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.206048e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.206048e-05 0.001473734 
  - best initial criterion value(s) :  412.1426 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -412.14  |proj g|=       5.1544
At iterate     1  f =      -419.42  |proj g|=        7.0581
At iterate     2  f =      -424.59  |proj g|=        5.9536
At iterate     3  f =      -425.64  |proj g|=        6.3146
At iterate     4  f =      -426.99  |proj g|=        5.8377
At iterate     5  f =      -429.47  |proj g|=        4.1255
At iterate     6  f =       -430.9  |proj g|=        3.3396
At iterate     7  f =      -431.17  |proj g|=        3.1569
At iterate     8  f =      -431.22  |proj g|=        3.0692
At iterate     9  f =      -431.22  |proj g|=        3.0945
At iterate    10  f =      -431.22  |proj g|=        3.0888
At iterate    11  f =      -431.22  |proj g|=        3.0882
At iterate    12  f =      -431.22  |proj g|=        3.0853
At iterate    13  f =      -431.22  |proj g|=        3.0819
At iterate    14  f =      -431.22  |proj g|=        3.0771
At iterate    15  f =      -431.22  |proj g|=         3.069
At iterate    16  f =      -431.22  |proj g|=        3.0564
At iterate    17  f =      -431.23  |proj g|=        3.0408
At iterate    18  f =      -431.26  |proj g|=          3.03
At iterate    19  f =      -431.31  |proj g|=        3.0557
At iterate    20  f =      -431.38  |proj g|=        3.1855
At iterate    21  f =      -431.42  |proj g|=        3.3262
At iterate    22  f =      -431.43  |proj g|=        3.3705
At iterate    23  f =      -431.43  |proj g|=        3.3884
At iterate    24  f =      -431.43  |proj g|=         3.396
At iterate    25  f =      -431.43  |proj g|=         3.408
At iterate    26  f =      -431.44  |proj g|=         3.417
At iterate    27  f =      -431.46  |proj g|=        3.4134
At iterate    28  f =      -431.51  |proj g|=        3.3639
At iterate    29  f =      -431.59  |proj g|=        3.2294
At iterate    30  f =       -431.6  |proj g|=        3.1484
At iterate    31  f =      -431.65  |proj g|=        3.0581
At iterate    32  f =      -431.96  |proj g|=        2.8698
At iterate    33  f =      -435.41  |proj g|=        1.9141
At iterate    34  f =      -437.41  |proj g|=        1.3102
At iterate    35  f =      -440.58  |proj g|=        1.1167
At iterate    36  f =      -443.48  |proj g|=       0.98424
At iterate    37  f =      -444.38  |proj g|=        1.0719
At iterate    38  f =      -444.42  |proj g|=         1.274
At iterate    39  f =      -444.43  |proj g|=        1.1987
At iterate    40  f =      -444.43  |proj g|=        1.2098
At iterate    41  f =      -444.43  |proj g|=        1.2094
At iterate    42  f =      -444.43  |proj g|=        1.2094

iterations 42
function evaluations 49
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.2094
final function value -444.427

F = -444.427
final  value -444.426651 
converged
 
INFO  [08:12:47.922] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:12:48.028] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:12:48.034] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:12:51.755] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:12:55.750] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:12:59.612] [mlr3]  Finished benchmark 
INFO  [08:12:59.775] [bbotk] Result of batch 75: 
INFO  [08:12:59.777] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:12:59.777] [bbotk]              4.220881                 9.080643                       0.2331466 
INFO  [08:12:59.777] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:12:59.777] [bbotk]                     2486        0.656 -0.9602003         <NA>   0.9734352 
INFO  [08:12:59.777] [bbotk]                                 uhash 
INFO  [08:12:59.777] [bbotk]  baf50b3b-e098-4465-906b-d15f24af7a4c 
DEBUG [08:13:00.664] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.197286e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.197286e-05 0.001468605 
  - best initial criterion value(s) :  448.9928 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -448.99  |proj g|=      0.90828
At iterate     1  f =      -451.35  |proj g|=        1.3601
At iterate     2  f =      -452.28  |proj g|=        1.2694
At iterate     3  f =      -453.12  |proj g|=        1.0141
At iterate     4  f =      -453.15  |proj g|=        1.0432
At iterate     5  f =      -453.16  |proj g|=        1.0488
At iterate     6  f =      -453.16  |proj g|=        1.0485
At iterate     7  f =      -453.16  |proj g|=        1.0482

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.04817
final function value -453.16

F = -453.16
final  value -453.159643 
converged
 
INFO  [08:13:00.669] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:13:00.766] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:13:00.775] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:13:09.020] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:13:19.738] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:13:28.669] [mlr3]  Finished benchmark 
INFO  [08:13:28.776] [bbotk] Result of batch 76: 
INFO  [08:13:28.778] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:13:28.778] [bbotk]              4.169855                 4.097354                      0.02616335 
INFO  [08:13:28.778] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:13:28.778] [bbotk]                     3709        0.658 -0.9586477         <NA>   0.9582445 
INFO  [08:13:28.778] [bbotk]                                 uhash 
INFO  [08:13:28.778] [bbotk]  396b3037-2726-4b45-947d-57a16ce5df57 
DEBUG [08:13:29.700] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.195091e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.195091e-05 0.001460646 
  - best initial criterion value(s) :  438.6297 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -438.63  |proj g|=      0.85741
At iterate     1  f =      -452.67  |proj g|=        3.6377
At iterate     2  f =      -454.06  |proj g|=         3.417
At iterate     3  f =      -455.53  |proj g|=        2.9283
At iterate     4  f =      -455.79  |proj g|=        2.4075
At iterate     5  f =      -455.96  |proj g|=        2.5522
At iterate     6  f =      -456.24  |proj g|=        2.5776
At iterate     7  f =      -456.64  |proj g|=        2.3579
At iterate     8  f =      -456.71  |proj g|=         2.145
At iterate     9  f =      -456.72  |proj g|=        2.1146
At iterate    10  f =      -456.72  |proj g|=        2.1194
At iterate    11  f =      -456.72  |proj g|=        2.1191

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.11912
final function value -456.718

F = -456.718
final  value -456.717871 
converged
 
INFO  [08:13:29.705] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:13:29.822] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:13:29.830] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:13:39.233] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:13:49.600] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:13:58.562] [mlr3]  Finished benchmark 
INFO  [08:13:58.663] [bbotk] Result of batch 77: 
INFO  [08:13:58.665] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:13:58.665] [bbotk]              5.634947                 3.938453                      0.02536417 
INFO  [08:13:58.665] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:13:58.665] [bbotk]                     3777        0.674 -0.9603629         <NA>   0.9611051 
INFO  [08:13:58.665] [bbotk]                                 uhash 
INFO  [08:13:58.665] [bbotk]  ba8aea96-848b-48e6-9fbb-5bc5136a2b0a 
DEBUG [08:13:59.688] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.18835e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.18835e-05 0.001453936 
  - best initial criterion value(s) :  428.96 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -428.96  |proj g|=       2.2669
At iterate     1  f =      -439.33  |proj g|=        5.0505
At iterate     2  f =      -439.75  |proj g|=        4.9356
At iterate     3  f =      -440.46  |proj g|=        4.1936
At iterate     4  f =      -440.83  |proj g|=        4.4696
At iterate     5  f =      -442.34  |proj g|=        4.4532
At iterate     6  f =      -444.07  |proj g|=        4.0264
At iterate     7  f =      -444.71  |proj g|=        3.6029
At iterate     8  f =      -444.74  |proj g|=        3.5015
At iterate     9  f =      -444.75  |proj g|=        3.5444
At iterate    10  f =      -444.75  |proj g|=        3.5392
At iterate    11  f =      -444.75  |proj g|=        3.5395
At iterate    12  f =      -444.75  |proj g|=        3.5436
At iterate    13  f =      -444.75  |proj g|=        3.5549
At iterate    14  f =      -444.75  |proj g|=        3.5742
At iterate    15  f =      -444.77  |proj g|=        3.6027
At iterate    16  f =       -444.8  |proj g|=        3.6446
At iterate    17  f =      -444.88  |proj g|=        3.7011
At iterate    18  f =      -445.06  |proj g|=        3.7565
At iterate    19  f =      -445.48  |proj g|=        3.7983
At iterate    20  f =      -446.41  |proj g|=        3.6101
At iterate    21  f =      -447.82  |proj g|=        3.8705
At iterate    22  f =      -449.92  |proj g|=        3.4679
At iterate    23  f =      -453.35  |proj g|=        2.4466
At iterate    24  f =      -456.47  |proj g|=        1.7545
At iterate    25  f =      -466.59  |proj g|=        1.0071
At iterate    26  f =      -467.72  |proj g|=       0.57245
At iterate    27  f =      -467.92  |proj g|=       0.55483
At iterate    28  f =      -468.48  |proj g|=       0.56347
At iterate    29  f =      -468.49  |proj g|=       0.48913
At iterate    30  f =      -468.49  |proj g|=       0.51405
At iterate    31  f =      -468.49  |proj g|=       0.51372
At iterate    32  f =      -468.49  |proj g|=       0.51382

iterations 32
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.513822
final function value -468.494

F = -468.494
final  value -468.494238 
converged
 
INFO  [08:13:59.692] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:13:59.778] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:13:59.786] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:14:02.844] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:14:06.730] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:14:09.521] [mlr3]  Finished benchmark 
INFO  [08:14:09.814] [bbotk] Result of batch 78: 
INFO  [08:14:09.816] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:14:09.816] [bbotk]              4.842601                 2.132967                       0.4059775 
INFO  [08:14:09.816] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:14:09.816] [bbotk]                     1418         0.68 -0.9531207         <NA>   0.9741409 
INFO  [08:14:09.816] [bbotk]                                 uhash 
INFO  [08:14:09.816] [bbotk]  7ec8946f-b304-4852-8830-a7d798647c6e 
DEBUG [08:14:11.042] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.180856e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.180856e-05 0.001433697 
  - best initial criterion value(s) :  449.5 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -449.5  |proj g|=       8.2763
At iterate     1  f =      -459.56  |proj g|=        4.0304
At iterate     2  f =      -463.67  |proj g|=         4.404
At iterate     3  f =      -465.63  |proj g|=        3.8512
At iterate     4  f =       -466.7  |proj g|=        3.4701
At iterate     5  f =      -467.06  |proj g|=        3.2569
At iterate     6  f =       -467.2  |proj g|=        3.1773
At iterate     7  f =      -467.26  |proj g|=        3.5747
At iterate     8  f =      -467.32  |proj g|=         3.328
At iterate     9  f =      -467.32  |proj g|=        3.3131
At iterate    10  f =      -467.32  |proj g|=        3.3238
At iterate    11  f =      -467.32  |proj g|=        3.3083
At iterate    12  f =      -467.32  |proj g|=        3.2887
At iterate    13  f =      -467.37  |proj g|=        3.1935
At iterate    14  f =      -467.57  |proj g|=        2.9649
At iterate    15  f =      -468.07  |proj g|=        2.5647
At iterate    16  f =      -468.98  |proj g|=        2.1976
At iterate    17  f =      -470.15  |proj g|=       0.70538
At iterate    18  f =      -472.11  |proj g|=       0.78906
At iterate    19  f =      -475.66  |proj g|=       0.71141
At iterate    20  f =       -476.4  |proj g|=       0.48351
At iterate    21  f =      -476.62  |proj g|=       0.51791
At iterate    22  f =      -476.66  |proj g|=      0.087421
At iterate    23  f =      -476.66  |proj g|=       0.11472
At iterate    24  f =      -476.66  |proj g|=        0.1157
At iterate    25  f =      -476.66  |proj g|=       0.11066
At iterate    26  f =      -476.66  |proj g|=        0.1108
At iterate    27  f =      -476.66  |proj g|=       0.10891
At iterate    28  f =      -476.66  |proj g|=       0.10857

iterations 28
function evaluations 34
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.108568
final function value -476.66

F = -476.66
final  value -476.660400 
converged
 
INFO  [08:14:11.046] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:14:11.159] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:14:11.171] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:14:15.312] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:14:19.797] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:14:24.398] [mlr3]  Finished benchmark 
INFO  [08:14:24.502] [bbotk] Result of batch 79: 
INFO  [08:14:24.503] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:14:24.503] [bbotk]              9.121798                 6.641675                       0.2093228 
INFO  [08:14:24.503] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:14:24.503] [bbotk]                     2169        0.889 -0.9536356         <NA>   0.9748862 
INFO  [08:14:24.503] [bbotk]                                 uhash 
INFO  [08:14:24.503] [bbotk]  773f0d69-52d7-4524-b316-141cc77e84e2 
DEBUG [08:14:25.552] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.174317e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.174317e-05 0.001428604 
  - best initial criterion value(s) :  458.866 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -458.87  |proj g|=      0.44725
At iterate     1  f =      -467.64  |proj g|=        5.1538
At iterate     2  f =      -469.37  |proj g|=        4.8044
At iterate     3  f =      -470.61  |proj g|=        4.1719
At iterate     4  f =      -470.67  |proj g|=        3.9302
At iterate     5  f =      -470.68  |proj g|=        4.0009
At iterate     6  f =      -470.69  |proj g|=        4.0509
At iterate     7  f =      -470.72  |proj g|=        4.1846
At iterate     8  f =      -470.74  |proj g|=        4.2594
At iterate     9  f =      -470.74  |proj g|=        4.1919
At iterate    10  f =      -470.74  |proj g|=        4.2456
At iterate    11  f =      -470.74  |proj g|=        4.2461
At iterate    12  f =      -470.74  |proj g|=        4.2465
At iterate    13  f =      -470.74  |proj g|=         4.247
At iterate    14  f =      -470.74  |proj g|=        4.2485
At iterate    15  f =      -470.74  |proj g|=        4.2511
At iterate    16  f =      -470.74  |proj g|=        4.2448
At iterate    17  f =      -470.74  |proj g|=        4.2511
At iterate    18  f =      -470.75  |proj g|=        4.2634
At iterate    19  f =      -470.77  |proj g|=        4.3164
At iterate    20  f =      -470.83  |proj g|=          4.38
At iterate    21  f =      -471.08  |proj g|=        4.4758
At iterate    22  f =      -471.08  |proj g|=        4.5197
At iterate    23  f =      -471.69  |proj g|=        4.5396
At iterate    24  f =      -472.96  |proj g|=        4.3089
At iterate    25  f =      -475.34  |proj g|=        3.6041
At iterate    26  f =       -478.4  |proj g|=        2.6259
At iterate    27  f =      -482.25  |proj g|=        1.7051
At iterate    28  f =      -482.61  |proj g|=        2.1118
At iterate    29  f =      -486.28  |proj g|=        1.4062
At iterate    30  f =      -491.22  |proj g|=        1.1257
At iterate    31  f =      -491.58  |proj g|=       0.87644
At iterate    32  f =      -491.58  |proj g|=       0.81871
At iterate    33  f =      -491.58  |proj g|=       0.83523
At iterate    34  f =      -491.58  |proj g|=        0.8347

iterations 34
function evaluations 44
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.834701
final function value -491.581

F = -491.581
final  value -491.580724 
converged
 
INFO  [08:14:25.556] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:14:25.648] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:14:25.655] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:14:31.784] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:14:37.031] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:14:42.198] [mlr3]  Finished benchmark 
INFO  [08:14:42.301] [bbotk] Result of batch 80: 
INFO  [08:14:42.303] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:14:42.303] [bbotk]              3.042527                 5.926115                       0.1991132 
INFO  [08:14:42.303] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:14:42.303] [bbotk]                     2449        0.664 -0.9527323         <NA>   0.9678341 
INFO  [08:14:42.303] [bbotk]                                 uhash 
INFO  [08:14:42.303] [bbotk]  d2cb0398-9c72-49cc-a07f-001310a8c600 
DEBUG [08:14:43.491] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.163647e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.163647e-05 0.001419398 
  - best initial criterion value(s) :  454.2301 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -454.23  |proj g|=       1.0856
At iterate     1  f =       -476.9  |proj g|=         6.838
At iterate     2  f =      -480.38  |proj g|=        5.9113
At iterate     3  f =      -481.14  |proj g|=        4.6295
At iterate     4  f =      -481.86  |proj g|=        4.6801
At iterate     5  f =      -482.19  |proj g|=         3.895
At iterate     6  f =      -482.25  |proj g|=        4.2634
At iterate     7  f =      -482.25  |proj g|=        4.1938
At iterate     8  f =      -482.25  |proj g|=        4.1905
At iterate     9  f =      -482.25  |proj g|=        4.1899
At iterate    10  f =      -482.25  |proj g|=        4.1887
At iterate    11  f =      -482.25  |proj g|=         4.187
At iterate    12  f =      -482.25  |proj g|=        4.1839
At iterate    13  f =      -482.25  |proj g|=        4.1795
At iterate    14  f =      -482.25  |proj g|=        4.1743
At iterate    15  f =      -482.26  |proj g|=        4.1724
At iterate    16  f =      -482.26  |proj g|=        4.1825
At iterate    17  f =      -482.27  |proj g|=        4.1954
At iterate    18  f =      -482.28  |proj g|=        4.2752
At iterate    19  f =       -482.3  |proj g|=        4.2548
At iterate    20  f =      -482.36  |proj g|=         4.315
At iterate    21  f =       -482.6  |proj g|=        4.2095
At iterate    22  f =      -483.13  |proj g|=        4.2065
At iterate    23  f =      -484.22  |proj g|=        3.7308
At iterate    24  f =      -485.97  |proj g|=        3.3117
At iterate    25  f =      -487.67  |proj g|=        2.2031
At iterate    26  f =      -489.53  |proj g|=        1.7239
At iterate    27  f =      -491.75  |proj g|=        1.1012
At iterate    28  f =      -492.14  |proj g|=       0.79885
At iterate    29  f =      -494.13  |proj g|=        1.0046
At iterate    30  f =      -494.82  |proj g|=        1.0925
At iterate    31  f =      -494.83  |proj g|=        1.0705
At iterate    32  f =      -494.85  |proj g|=        1.0624
At iterate    33  f =      -494.85  |proj g|=        1.0636
At iterate    34  f =      -494.85  |proj g|=        1.0636

iterations 34
function evaluations 40
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.06358
final function value -494.854

F = -494.854
final  value -494.854320 
converged
 
INFO  [08:14:43.495] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:14:43.587] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:14:43.605] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:14:48.174] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:14:53.625] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:14:58.197] [mlr3]  Finished benchmark 
INFO  [08:14:58.301] [bbotk] Result of batch 81: 
INFO  [08:14:58.303] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:14:58.303] [bbotk]              4.525404                 7.380989                       0.4224508 
INFO  [08:14:58.303] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:14:58.303] [bbotk]                     2088        0.822 -0.9503331         <NA>   0.9756934 
INFO  [08:14:58.303] [bbotk]                                 uhash 
INFO  [08:14:58.303] [bbotk]  83bc834b-a7a4-40d5-87b9-f69ef15f15dd 
DEBUG [08:14:59.273] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.158348e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.158348e-05 0.001416197 
  - best initial criterion value(s) :  469.3331 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -469.33  |proj g|=       4.1811
At iterate     1  f =      -483.49  |proj g|=        1.7781
At iterate     2  f =      -485.78  |proj g|=        1.6331
At iterate     3  f =       -488.2  |proj g|=        1.1394
At iterate     4  f =      -488.93  |proj g|=        1.2575
At iterate     5  f =      -489.79  |proj g|=        1.3546
At iterate     6  f =      -492.13  |proj g|=        1.4901
At iterate     7  f =      -493.25  |proj g|=        1.4598
At iterate     8  f =      -493.46  |proj g|=        1.5681
At iterate     9  f =       -493.5  |proj g|=        1.5263
At iterate    10  f =      -493.51  |proj g|=        1.4891
At iterate    11  f =      -493.51  |proj g|=        1.4896
At iterate    12  f =      -493.51  |proj g|=        1.4898

iterations 12
function evaluations 14
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.48975
final function value -493.514

F = -493.514
final  value -493.513919 
converged
 
INFO  [08:14:59.278] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:14:59.410] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:14:59.418] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:15:00.990] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:15:03.492] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:15:05.105] [mlr3]  Finished benchmark 
INFO  [08:15:05.206] [bbotk] Result of batch 82: 
INFO  [08:15:05.208] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:15:05.208] [bbotk]              9.052303                 4.518518                       0.4513256 
INFO  [08:15:05.208] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:15:05.208] [bbotk]                      683         0.71 -0.9531827         <NA>   0.9727005 
INFO  [08:15:05.208] [bbotk]                                 uhash 
INFO  [08:15:05.208] [bbotk]  cf547fac-6bf6-4c57-a3fe-e77290bf3a81 
DEBUG [08:15:06.167] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.149845e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.149845e-05 0.001396488 
  - best initial criterion value(s) :  461.1852 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -461.19  |proj g|=       4.7174
At iterate     1  f =      -479.16  |proj g|=        2.2286
At iterate     2  f =      -482.46  |proj g|=        2.0572
At iterate     3  f =      -487.27  |proj g|=        1.1581
At iterate     4  f =       -489.2  |proj g|=        1.4626
At iterate     5  f =      -490.88  |proj g|=        1.5605
At iterate     6  f =      -497.79  |proj g|=        1.6671
At iterate     7  f =      -500.29  |proj g|=        1.5585
At iterate     8  f =      -500.82  |proj g|=        1.9456
At iterate     9  f =      -501.68  |proj g|=        1.7582
At iterate    10  f =      -501.68  |proj g|=        1.7474
At iterate    11  f =      -501.68  |proj g|=        1.7426
At iterate    12  f =      -501.68  |proj g|=        1.7422

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.74219
final function value -501.684

F = -501.684
final  value -501.683638 
converged
 
INFO  [08:15:06.171] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:15:06.276] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:15:06.282] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:15:14.784] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:15:22.620] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:15:31.094] [mlr3]  Finished benchmark 
INFO  [08:15:31.212] [bbotk] Result of batch 83: 
INFO  [08:15:31.213] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:15:31.213] [bbotk]              5.191452                 8.102437                       0.1271477 
INFO  [08:15:31.213] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:15:31.213] [bbotk]                     3590        0.692 -0.9515361         <NA>   0.9733059 
INFO  [08:15:31.213] [bbotk]                                 uhash 
INFO  [08:15:31.213] [bbotk]  e356d209-c237-4d5b-9fdd-3936a6016c00 
DEBUG [08:15:32.292] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.141973e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.141973e-05 0.001390306 
  - best initial criterion value(s) :  481.2398 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -481.24  |proj g|=       3.9105
At iterate     1  f =      -489.53  |proj g|=        2.5964
At iterate     2  f =      -494.36  |proj g|=        2.1178
At iterate     3  f =      -500.06  |proj g|=       0.79348
At iterate     4  f =       -500.5  |proj g|=       0.69511
At iterate     5  f =      -500.86  |proj g|=       0.69495
At iterate     6  f =      -502.34  |proj g|=       0.69797
At iterate     7  f =      -503.87  |proj g|=       0.79835
At iterate     8  f =       -504.4  |proj g|=       0.68601
At iterate     9  f =      -504.46  |proj g|=       0.68494
At iterate    10  f =      -504.47  |proj g|=       0.70077
At iterate    11  f =      -504.47  |proj g|=       0.72043
At iterate    12  f =      -504.47  |proj g|=       0.72079
At iterate    13  f =      -504.47  |proj g|=       0.72094
At iterate    14  f =      -504.47  |proj g|=       0.72194
At iterate    15  f =      -504.48  |proj g|=        0.7232
At iterate    16  f =      -504.48  |proj g|=       0.72499
At iterate    17  f =      -504.48  |proj g|=       0.72438
At iterate    18  f =      -504.48  |proj g|=       0.74624
At iterate    19  f =      -504.49  |proj g|=       0.73402
At iterate    20  f =      -504.51  |proj g|=       0.69959
At iterate    21  f =      -504.57  |proj g|=       0.67897
At iterate    22  f =      -504.77  |proj g|=       0.67112
At iterate    23  f =      -505.12  |proj g|=       0.65812
At iterate    24  f =      -505.13  |proj g|=       0.65823
At iterate    25  f =      -505.25  |proj g|=       0.65078
At iterate    26  f =      -505.25  |proj g|=       0.65174
At iterate    27  f =      -505.25  |proj g|=       0.65198
At iterate    28  f =      -505.25  |proj g|=       0.65201

iterations 28
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.652013
final function value -505.252

F = -505.252
final  value -505.252256 
converged
 
INFO  [08:15:32.297] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:15:32.386] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:15:32.392] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:15:33.733] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:15:35.644] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:15:36.994] [mlr3]  Finished benchmark 
INFO  [08:15:37.094] [bbotk] Result of batch 84: 
INFO  [08:15:37.096] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:15:37.096] [bbotk]              2.705236                 8.128193                       0.1008035 
INFO  [08:15:37.096] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:15:37.096] [bbotk]                      517        0.712 -0.9532391         <NA>    0.932427 
INFO  [08:15:37.096] [bbotk]                                 uhash 
INFO  [08:15:37.096] [bbotk]  ba276c64-07cf-4b39-be71-bd7bb85939db 
DEBUG [08:15:38.165] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.2434e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.2434e-05 0.00154125 
  - best initial criterion value(s) :  472.2864 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -472.29  |proj g|=          2.2
At iterate     1  f =      -499.84  |proj g|=        4.3812
At iterate     2  f =         -501  |proj g|=        4.1034
At iterate     3  f =      -502.02  |proj g|=          3.01
At iterate     4  f =      -502.18  |proj g|=        3.4096
At iterate     5  f =      -502.19  |proj g|=          3.34
At iterate     6  f =      -502.19  |proj g|=        3.3328
At iterate     7  f =      -502.19  |proj g|=        3.3312
At iterate     8  f =      -502.19  |proj g|=        3.3245
At iterate     9  f =      -502.19  |proj g|=        3.3253
At iterate    10  f =      -502.19  |proj g|=        3.3267
At iterate    11  f =      -502.19  |proj g|=        3.3276
At iterate    12  f =      -502.19  |proj g|=        3.3286
At iterate    13  f =      -502.19  |proj g|=        3.3303
At iterate    14  f =      -502.19  |proj g|=         3.333
At iterate    15  f =      -502.19  |proj g|=        3.3372
At iterate    16  f =      -502.19  |proj g|=        3.3429
At iterate    17  f =      -502.19  |proj g|=        3.3486
At iterate    18  f =      -502.19  |proj g|=        3.3475
At iterate    19  f =       -502.2  |proj g|=        3.3304
At iterate    20  f =       -502.2  |proj g|=        3.3144
At iterate    21  f =       -502.2  |proj g|=        3.2917
At iterate    22  f =       -502.2  |proj g|=        3.2742
At iterate    23  f =      -502.21  |proj g|=        3.2408
At iterate    24  f =      -502.22  |proj g|=        3.1848
At iterate    25  f =      -502.26  |proj g|=        3.0856
At iterate    26  f =      -502.37  |proj g|=        2.9047
At iterate    27  f =      -502.66  |proj g|=        2.5633
At iterate    28  f =      -503.47  |proj g|=        1.9275
At iterate    29  f =      -505.57  |proj g|=       0.91688
At iterate    30  f =       -509.4  |proj g|=       0.43709
At iterate    31  f =      -511.94  |proj g|=       0.42431
At iterate    32  f =      -512.08  |proj g|=       0.54407
At iterate    33  f =       -512.1  |proj g|=       0.54543
At iterate    34  f =      -512.12  |proj g|=       0.54462
At iterate    35  f =      -512.22  |proj g|=       0.59822
At iterate    36  f =       -512.3  |proj g|=        0.6896
At iterate    37  f =      -512.35  |proj g|=       0.69147
At iterate    38  f =      -512.36  |proj g|=       0.67577
At iterate    39  f =      -512.36  |proj g|=       0.67069
At iterate    40  f =      -512.36  |proj g|=       0.66926
At iterate    41  f =      -512.36  |proj g|=       0.66922

iterations 41
function evaluations 43
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.669219
final function value -512.357

F = -512.357
final  value -512.356684 
converged
 
INFO  [08:15:38.169] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:15:38.272] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:15:38.279] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:15:49.847] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:16:01.233] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:16:10.089] [mlr3]  Finished benchmark 
INFO  [08:16:10.187] [bbotk] Result of batch 85: 
INFO  [08:16:10.189] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:16:10.189] [bbotk]              5.891103                 3.821024                      0.01811299 
INFO  [08:16:10.189] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:16:10.189] [bbotk]                     4641        0.699 -0.9527237         <NA>   0.9598432 
INFO  [08:16:10.189] [bbotk]                                 uhash 
INFO  [08:16:10.189] [bbotk]  a3015438-8424-4875-b763-278a286a1d3e 
DEBUG [08:16:11.248] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.238204e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.238204e-05 0.00152533 
  - best initial criterion value(s) :  468.744 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -468.74  |proj g|=       6.2807
At iterate     1  f =       -481.3  |proj g|=        2.5245
At iterate     2  f =      -501.17  |proj g|=        1.5542
At iterate     3  f =      -501.73  |proj g|=        1.5254
At iterate     4  f =      -504.98  |proj g|=        1.6953
At iterate     5  f =      -505.21  |proj g|=        1.5961
At iterate     6  f =      -505.23  |proj g|=        1.5899
At iterate     7  f =      -505.23  |proj g|=        1.6244
At iterate     8  f =      -505.23  |proj g|=        1.6083
At iterate     9  f =      -505.23  |proj g|=        1.6075
At iterate    10  f =      -505.23  |proj g|=        1.6074
At iterate    11  f =      -505.23  |proj g|=        1.6069
At iterate    12  f =      -505.23  |proj g|=        1.6062
At iterate    13  f =      -505.23  |proj g|=        1.6056
At iterate    14  f =      -505.23  |proj g|=        1.6047
At iterate    15  f =      -505.23  |proj g|=        1.5958
At iterate    16  f =      -505.24  |proj g|=        1.5987
At iterate    17  f =      -505.24  |proj g|=         1.607
At iterate    18  f =      -505.25  |proj g|=         1.617
At iterate    19  f =      -505.27  |proj g|=        1.6328
At iterate    20  f =      -505.31  |proj g|=         1.648
At iterate    21  f =      -505.37  |proj g|=        1.6882
At iterate    22  f =      -505.46  |proj g|=        1.6584
At iterate    23  f =      -505.52  |proj g|=        1.6536
At iterate    24  f =      -505.54  |proj g|=        1.6103
At iterate    25  f =      -505.55  |proj g|=        1.6087
At iterate    26  f =      -505.55  |proj g|=        1.6123
At iterate    27  f =      -505.55  |proj g|=        1.6115
At iterate    28  f =      -505.55  |proj g|=        1.6115

iterations 28
function evaluations 33
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.61149
final function value -505.548

F = -505.548
final  value -505.548465 
converged
 
INFO  [08:16:11.252] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:16:11.338] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:16:11.345] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:16:15.009] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:16:18.663] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:16:22.841] [mlr3]  Finished benchmark 
INFO  [08:16:22.958] [bbotk] Result of batch 86: 
INFO  [08:16:22.960] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:16:22.960] [bbotk]              8.936399                 9.021053                       0.2117297 
INFO  [08:16:22.960] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:16:22.960] [bbotk]                     2456        0.718 -0.9559236         <NA>   0.9754515 
INFO  [08:16:22.960] [bbotk]                                 uhash 
INFO  [08:16:22.960] [bbotk]  f303c02f-ac14-4063-b012-eb2c54f9b6ca 
DEBUG [08:16:23.945] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.232474e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.232474e-05 0.001525812 
  - best initial criterion value(s) :  463.1637 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -463.16  |proj g|=       5.8903
At iterate     1  f =      -487.55  |proj g|=        8.3628
At iterate     2  f =      -493.34  |proj g|=        7.4473
At iterate     3  f =      -495.08  |proj g|=        5.8731
At iterate     4  f =      -497.92  |proj g|=        5.7716
At iterate     5  f =      -502.16  |proj g|=        3.8251
At iterate     6  f =      -502.62  |proj g|=        3.1725
At iterate     7  f =      -502.64  |proj g|=         2.904
At iterate     8  f =      -502.65  |proj g|=        2.9563
At iterate     9  f =      -502.65  |proj g|=        2.9544
At iterate    10  f =      -502.65  |proj g|=        2.9539

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.95393
final function value -502.645

F = -502.645
final  value -502.645031 
converged
 
INFO  [08:16:23.949] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:16:24.079] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:16:24.095] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:16:30.936] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:16:38.123] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:16:44.973] [mlr3]  Finished benchmark 
INFO  [08:16:45.124] [bbotk] Result of batch 87: 
INFO  [08:16:45.126] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:16:45.126] [bbotk]               4.95092                 6.683156                       0.3345097 
INFO  [08:16:45.126] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:16:45.126] [bbotk]                     4247        0.709 -0.9617727         <NA>   0.9773485 
INFO  [08:16:45.126] [bbotk]                                 uhash 
INFO  [08:16:45.126] [bbotk]  a4838bd1-4aa4-4ff5-a2a5-866212de6d0a 
DEBUG [08:16:46.471] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.229489e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.229489e-05 0.001526409 
  - best initial criterion value(s) :  478.9404 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -478.94  |proj g|=       1.7181
At iterate     1  f =      -480.19  |proj g|=       0.91065
At iterate     2  f =      -480.19  |proj g|=       0.92535
At iterate     3  f =      -480.19  |proj g|=       0.95138
At iterate     4  f =       -480.2  |proj g|=       0.98039
At iterate     5  f =      -480.21  |proj g|=        1.0341
At iterate     6  f =      -480.24  |proj g|=        1.0846
At iterate     7  f =      -480.25  |proj g|=        1.0927
At iterate     8  f =      -480.26  |proj g|=        1.0613
At iterate     9  f =      -480.26  |proj g|=        1.0486
At iterate    10  f =      -480.26  |proj g|=        1.0475
At iterate    11  f =      -480.26  |proj g|=        1.0474

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.04737
final function value -480.26

F = -480.26
final  value -480.259746 
converged
 
INFO  [08:16:46.476] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:16:46.565] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:16:46.573] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:16:51.944] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:16:57.061] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:17:02.275] [mlr3]  Finished benchmark 
INFO  [08:17:02.413] [bbotk] Result of batch 88: 
INFO  [08:17:02.415] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:17:02.415] [bbotk]              2.132032                 3.891517                       0.1009782 
INFO  [08:17:02.415] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:17:02.415] [bbotk]                     3195        1.044 -0.9645015         <NA>     0.95516 
INFO  [08:17:02.415] [bbotk]                                 uhash 
INFO  [08:17:02.415] [bbotk]  ca535855-f62a-4902-8855-dd7a15b38300 
DEBUG [08:17:03.573] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.232904e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.232904e-05 0.001523297 
  - best initial criterion value(s) :  483.8248 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -483.82  |proj g|=       12.883
At iterate     1  f =      -497.19  |proj g|=        8.1441
At iterate     2  f =      -504.49  |proj g|=        5.6934
At iterate     3  f =      -507.55  |proj g|=        4.2546
At iterate     4  f =       -508.4  |proj g|=        3.1273
At iterate     5  f =      -508.68  |proj g|=        3.0893
At iterate     6  f =      -508.68  |proj g|=        3.0407
At iterate     7  f =      -508.68  |proj g|=        3.0396
At iterate     8  f =      -508.69  |proj g|=        3.0384
At iterate     9  f =       -508.7  |proj g|=        3.0366
At iterate    10  f =      -508.74  |proj g|=        3.0364
At iterate    11  f =      -508.82  |proj g|=         3.011
At iterate    12  f =      -509.05  |proj g|=        2.9301
At iterate    13  f =      -509.55  |proj g|=        2.7423
At iterate    14  f =      -510.63  |proj g|=        2.4166
At iterate    15  f =      -512.75  |proj g|=        1.9045
At iterate    16  f =       -512.9  |proj g|=        2.0096
At iterate    17  f =      -516.86  |proj g|=        1.9497
At iterate    18  f =      -525.68  |proj g|=       0.67999
At iterate    19  f =      -530.39  |proj g|=        1.5791
At iterate    20  f =       -531.9  |proj g|=        1.7223
At iterate    21  f =      -532.12  |proj g|=        1.8701
At iterate    22  f =      -532.16  |proj g|=         1.968
At iterate    23  f =      -532.16  |proj g|=        2.0109
At iterate    24  f =      -532.16  |proj g|=        2.0259
At iterate    25  f =      -532.16  |proj g|=        2.0267
At iterate    26  f =      -532.16  |proj g|=        2.0268

iterations 26
function evaluations 34
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.02683
final function value -532.161

F = -532.161
final  value -532.160562 
converged
 
INFO  [08:17:03.577] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:17:03.666] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:17:03.673] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:17:06.640] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:17:09.725] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:17:12.757] [mlr3]  Finished benchmark 
INFO  [08:17:12.875] [bbotk] Result of batch 89: 
INFO  [08:17:12.877] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:17:12.877] [bbotk]              2.736981                 4.001983                       0.4587444 
INFO  [08:17:12.877] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:17:12.877] [bbotk]                     1865        0.781 -0.9547906         <NA>   0.9685028 
INFO  [08:17:12.877] [bbotk]                                 uhash 
INFO  [08:17:12.877] [bbotk]  f0160a0a-557f-4ec0-ac98-614f4e5832a7 
DEBUG [08:17:14.126] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.222575e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.222575e-05 0.0015099 
  - best initial criterion value(s) :  478.3884 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -478.39  |proj g|=       7.5444
At iterate     1  f =      -501.56  |proj g|=         8.624
At iterate     2  f =      -510.78  |proj g|=        6.9072
At iterate     3  f =      -519.85  |proj g|=        3.8965
At iterate     4  f =      -521.52  |proj g|=        2.4831
At iterate     5  f =      -521.59  |proj g|=        2.3604
At iterate     6  f =      -521.62  |proj g|=        2.1468
At iterate     7  f =      -521.62  |proj g|=        2.1438
At iterate     8  f =      -521.62  |proj g|=        2.1441
At iterate     9  f =      -521.62  |proj g|=        2.1467
At iterate    10  f =      -521.62  |proj g|=        2.1499
At iterate    11  f =      -521.62  |proj g|=        2.1555
At iterate    12  f =      -521.62  |proj g|=        2.1633
At iterate    13  f =      -521.62  |proj g|=        2.1742
At iterate    14  f =      -521.63  |proj g|=        2.1862
At iterate    15  f =      -521.64  |proj g|=        2.1919
At iterate    16  f =      -521.65  |proj g|=        2.1662
At iterate    17  f =      -521.69  |proj g|=        2.0584
At iterate    18  f =      -521.74  |proj g|=        1.6712
At iterate    19  f =      -521.75  |proj g|=        1.7448
At iterate    20  f =      -521.75  |proj g|=        1.7401
At iterate    21  f =      -521.75  |proj g|=        1.7027
At iterate    22  f =      -521.75  |proj g|=        1.6589
At iterate    23  f =      -521.77  |proj g|=        1.5725
At iterate    24  f =      -521.79  |proj g|=        1.4662
At iterate    25  f =      -521.81  |proj g|=        1.3286
At iterate    26  f =      -521.89  |proj g|=        1.3315
At iterate    27  f =      -522.33  |proj g|=        1.3403
At iterate    28  f =      -523.47  |proj g|=        1.3478
At iterate    29  f =      -525.89  |proj g|=        1.3278
At iterate    30  f =         -526  |proj g|=        1.3239
At iterate    31  f =      -526.09  |proj g|=        1.4028
At iterate    32  f =      -527.24  |proj g|=        1.3473
At iterate    33  f =      -527.38  |proj g|=        1.3436
At iterate    34  f =      -527.39  |proj g|=        1.3529
At iterate    35  f =      -527.39  |proj g|=        1.3595
At iterate    36  f =      -527.39  |proj g|=         1.362
At iterate    37  f =      -527.39  |proj g|=        1.3624
At iterate    38  f =      -527.39  |proj g|=        1.3625

iterations 38
function evaluations 50
segments explored during Cauchy searches 41
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.36252
final function value -527.393

F = -527.393
final  value -527.393409 
converged
 
INFO  [08:17:14.131] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:17:14.295] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:17:14.305] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:17:24.093] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:17:33.656] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:17:43.757] [mlr3]  Finished benchmark 
INFO  [08:17:43.860] [bbotk] Result of batch 90: 
INFO  [08:17:43.862] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:17:43.862] [bbotk]              4.763078                 9.259301                       0.4852427 
INFO  [08:17:43.862] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:17:43.862] [bbotk]                     4207         0.79 -0.9556256         <NA>   0.9781042 
INFO  [08:17:43.862] [bbotk]                                 uhash 
INFO  [08:17:43.862] [bbotk]  0786c415-62ed-4b2c-8c02-29814a6efd0d 
DEBUG [08:17:44.932] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.221013e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.221013e-05 0.001510943 
  - best initial criterion value(s) :  509.4732 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -509.47  |proj g|=       2.5636
At iterate     1  f =       -513.8  |proj g|=         6.609
At iterate     2  f =      -516.43  |proj g|=        6.1677
At iterate     3  f =      -519.42  |proj g|=        4.4197
At iterate     4  f =      -519.71  |proj g|=        4.9157
At iterate     5  f =      -519.88  |proj g|=         4.873
At iterate     6  f =      -520.12  |proj g|=        4.7628
At iterate     7  f =      -520.13  |proj g|=        4.7372
At iterate     8  f =      -520.14  |proj g|=        4.7652
At iterate     9  f =      -520.14  |proj g|=        4.7581
At iterate    10  f =      -520.14  |proj g|=        4.7586
At iterate    11  f =      -520.14  |proj g|=        4.7593
At iterate    12  f =      -520.14  |proj g|=        4.7616
At iterate    13  f =      -520.14  |proj g|=        4.7645
At iterate    14  f =      -520.14  |proj g|=        4.7694
At iterate    15  f =      -520.14  |proj g|=        4.7764
At iterate    16  f =      -520.14  |proj g|=        4.7841
At iterate    17  f =      -520.15  |proj g|=         4.809
At iterate    18  f =      -520.16  |proj g|=        4.8201
At iterate    19  f =       -520.2  |proj g|=        4.8739
At iterate    20  f =       -520.3  |proj g|=        4.8623
At iterate    21  f =      -520.54  |proj g|=        5.0475
At iterate    22  f =      -521.01  |proj g|=        4.8987
At iterate    23  f =      -537.68  |proj g|=        1.9406
At iterate    24  f =      -540.25  |proj g|=        1.4121
At iterate    25  f =       -545.8  |proj g|=       0.70201
At iterate    26  f =      -547.22  |proj g|=       0.62791
At iterate    27  f =       -547.6  |proj g|=       0.43834
At iterate    28  f =      -548.04  |proj g|=       0.55694
At iterate    29  f =      -548.12  |proj g|=       0.53777
At iterate    30  f =      -548.12  |proj g|=      0.055881
At iterate    31  f =      -548.12  |proj g|=      0.010122
At iterate    32  f =      -548.12  |proj g|=      0.010211

iterations 32
function evaluations 36
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0102114
final function value -548.125

F = -548.125
final  value -548.124709 
converged
 
INFO  [08:17:44.936] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:17:45.190] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:17:45.197] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:17:57.421] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:18:08.537] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:18:19.495] [mlr3]  Finished benchmark 
INFO  [08:18:19.599] [bbotk] Result of batch 91: 
INFO  [08:18:19.601] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:18:19.601] [bbotk]              6.512087                 2.482351                       0.2488358 
INFO  [08:18:19.601] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:18:19.601] [bbotk]                     4974        0.708 -0.9488785         <NA>   0.9776304 
INFO  [08:18:19.601] [bbotk]                                 uhash 
INFO  [08:18:19.601] [bbotk]  8eea6372-cbf0-4898-a2cf-ca45fb53ba37 
DEBUG [08:18:20.735] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.218568e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.218568e-05 0.001505822 
  - best initial criterion value(s) :  493.8361 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -493.84  |proj g|=       3.2877
At iterate     1  f =      -504.02  |proj g|=        8.6388
At iterate     2  f =      -530.08  |proj g|=        5.6165
At iterate     3  f =      -531.64  |proj g|=        4.3669
At iterate     4  f =      -531.74  |proj g|=        4.5291
At iterate     5  f =      -532.01  |proj g|=        4.6563
At iterate     6  f =      -532.98  |proj g|=         4.722
At iterate     7  f =      -533.91  |proj g|=         4.384
At iterate     8  f =       -534.2  |proj g|=         3.951
At iterate     9  f =      -534.21  |proj g|=        3.8738
At iterate    10  f =      -534.21  |proj g|=        3.8687
At iterate    11  f =      -534.21  |proj g|=        3.8717
At iterate    12  f =      -534.21  |proj g|=        3.8706
At iterate    13  f =      -534.21  |proj g|=        3.8645
At iterate    14  f =      -534.21  |proj g|=        3.8468
At iterate    15  f =      -534.22  |proj g|=         3.822
At iterate    16  f =      -534.23  |proj g|=         3.776
At iterate    17  f =      -534.26  |proj g|=          3.69
At iterate    18  f =      -534.31  |proj g|=        3.6127
At iterate    19  f =      -534.42  |proj g|=        3.3284
At iterate    20  f =      -535.31  |proj g|=         2.633
At iterate    21  f =      -537.59  |proj g|=        1.7315
At iterate    22  f =      -543.56  |proj g|=        1.0223
At iterate    23  f =       -545.7  |proj g|=        1.3474
At iterate    24  f =      -546.07  |proj g|=        1.3111
At iterate    25  f =      -546.16  |proj g|=        1.2554
At iterate    26  f =       -546.2  |proj g|=        1.1581
At iterate    27  f =       -546.2  |proj g|=        1.1408
At iterate    28  f =       -546.2  |proj g|=        1.1463
At iterate    29  f =       -546.2  |proj g|=        1.1463
At iterate    30  f =       -546.2  |proj g|=        1.1463

iterations 30
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.14635
final function value -546.199

F = -546.199
final  value -546.199453 
converged
 
INFO  [08:18:20.740] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:18:20.848] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:18:20.855] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:18:21.955] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:18:23.004] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:18:24.101] [mlr3]  Finished benchmark 
INFO  [08:18:24.251] [bbotk] Result of batch 92: 
INFO  [08:18:24.253] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:18:24.253] [bbotk]              5.172129                 8.352702                       0.1922267 
INFO  [08:18:24.253] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:18:24.253] [bbotk]                      308        0.752 -0.9516349         <NA>   0.9540066 
INFO  [08:18:24.253] [bbotk]                                 uhash 
INFO  [08:18:24.253] [bbotk]  4eb2c106-5845-4025-b8dc-d10f936eb150 
DEBUG [08:18:25.465] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.224617e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.224617e-05 0.001514791 
  - best initial criterion value(s) :  499.8524 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -499.85  |proj g|=       12.903
At iterate     1  f =      -513.29  |proj g|=        4.5143
At iterate     2  f =      -525.63  |proj g|=        3.5504
At iterate     3  f =      -529.72  |proj g|=        2.5769
At iterate     4  f =      -532.91  |proj g|=        2.2918
At iterate     5  f =      -534.26  |proj g|=        2.1233
At iterate     6  f =      -535.23  |proj g|=        2.0478
At iterate     7  f =      -536.22  |proj g|=        2.7743
At iterate     8  f =      -536.94  |proj g|=        2.5471
At iterate     9  f =      -537.29  |proj g|=        2.4356
At iterate    10  f =      -537.42  |proj g|=        2.4261
At iterate    11  f =      -537.48  |proj g|=        2.4588
At iterate    12  f =      -537.49  |proj g|=        2.4878
At iterate    13  f =      -537.49  |proj g|=        2.4968
At iterate    14  f =      -537.49  |proj g|=        2.4964
At iterate    15  f =      -537.49  |proj g|=        2.5018
At iterate    16  f =      -537.49  |proj g|=        2.5075
At iterate    17  f =      -537.49  |proj g|=        2.5142
At iterate    18  f =       -537.5  |proj g|=        2.5321
At iterate    19  f =      -537.52  |proj g|=        2.5534
At iterate    20  f =      -537.58  |proj g|=        2.5723
At iterate    21  f =       -537.7  |proj g|=        2.5464
At iterate    22  f =      -537.89  |proj g|=        2.4591
At iterate    23  f =      -537.95  |proj g|=        2.6254
At iterate    24  f =       -538.3  |proj g|=        2.5093
At iterate    25  f =      -538.58  |proj g|=        2.2499
At iterate    26  f =      -540.68  |proj g|=        2.1029
At iterate    27  f =      -545.32  |proj g|=        1.8802
At iterate    28  f =      -545.55  |proj g|=        2.4066
At iterate    29  f =      -546.58  |proj g|=        2.3512
At iterate    30  f =      -546.63  |proj g|=        2.1828
At iterate    31  f =      -546.64  |proj g|=        2.2147
At iterate    32  f =      -546.64  |proj g|=        2.2157
At iterate    33  f =      -546.64  |proj g|=         2.214
At iterate    34  f =      -546.64  |proj g|=        2.2049
At iterate    35  f =      -546.65  |proj g|=        2.1936
At iterate    36  f =      -546.65  |proj g|=        2.1734
At iterate    37  f =      -546.67  |proj g|=        2.1405
At iterate    38  f =      -546.72  |proj g|=        2.0873
At iterate    39  f =      -546.84  |proj g|=         2.008
At iterate    40  f =      -547.12  |proj g|=        1.8988
At iterate    41  f =      -547.73  |proj g|=        1.5655
At iterate    42  f =      -549.33  |proj g|=        1.3284
At iterate    43  f =      -553.19  |proj g|=        1.3539
At iterate    44  f =      -555.14  |proj g|=       0.73511
At iterate    45  f =      -555.68  |proj g|=       0.46873
At iterate    46  f =      -555.89  |proj g|=       0.41148
At iterate    47  f =      -555.92  |proj g|=       0.16302
At iterate    48  f =      -555.92  |proj g|=       0.14655
At iterate    49  f =      -555.92  |proj g|=       0.14499
At iterate    50  f =      -555.92  |proj g|=       0.14396
At iterate    51  f =      -555.92  |proj g|=       0.14392
At iterate    52  f =      -555.92  |proj g|=       0.14398

iterations 52
function evaluations 60
segments explored during Cauchy searches 55
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.143979
final function value -555.916

F = -555.916
final  value -555.915931 
converged
 
INFO  [08:18:25.470] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:18:25.562] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:18:25.569] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:18:31.392] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:18:38.530] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:18:44.841] [mlr3]  Finished benchmark 
INFO  [08:18:45.368] [bbotk] Result of batch 93: 
INFO  [08:18:45.370] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:18:45.370] [bbotk]              2.131984                 5.799201                       0.1715721 
INFO  [08:18:45.370] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:18:45.370] [bbotk]                     2906         0.74 -0.9487355         <NA>   0.9584682 
INFO  [08:18:45.370] [bbotk]                                 uhash 
INFO  [08:18:45.370] [bbotk]  b7cfec37-cdad-4bcc-89cb-91ca26cf5040 
DEBUG [08:18:46.846] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.221892e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.221892e-05 0.001505984 
  - best initial criterion value(s) :  522.9538 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -522.95  |proj g|=       4.6151
At iterate     1  f =      -523.17  |proj g|=        7.6765
At iterate     2  f =      -534.54  |proj g|=        7.0259
At iterate     3  f =      -535.96  |proj g|=        5.9558
At iterate     4  f =      -538.97  |proj g|=        4.2452
At iterate     5  f =      -540.13  |proj g|=        2.8853
At iterate     6  f =      -540.34  |proj g|=        2.9861
At iterate     7  f =      -540.34  |proj g|=        3.0367
At iterate     8  f =      -540.35  |proj g|=         3.013
At iterate     9  f =      -540.35  |proj g|=        3.0146
At iterate    10  f =      -540.35  |proj g|=        3.0165
At iterate    11  f =      -540.35  |proj g|=        3.0279
At iterate    12  f =      -540.35  |proj g|=        3.0427
At iterate    13  f =      -540.35  |proj g|=        3.0671
At iterate    14  f =      -540.35  |proj g|=        3.1053
At iterate    15  f =      -540.36  |proj g|=        3.1687
At iterate    16  f =      -540.39  |proj g|=        3.2724
At iterate    17  f =      -540.46  |proj g|=        3.4408
At iterate    18  f =      -540.59  |proj g|=        3.6661
At iterate    19  f =      -540.75  |proj g|=        3.7872
At iterate    20  f =      -540.79  |proj g|=        3.7319
At iterate    21  f =       -540.8  |proj g|=        3.6609
At iterate    22  f =      -540.83  |proj g|=        3.5596
At iterate    23  f =      -540.91  |proj g|=         3.363
At iterate    24  f =       -541.1  |proj g|=        2.9936
At iterate    25  f =      -541.51  |proj g|=        2.3979
At iterate    26  f =      -542.43  |proj g|=         1.462
At iterate    27  f =      -543.51  |proj g|=       0.75277
At iterate    28  f =      -544.03  |proj g|=       0.70867
At iterate    29  f =      -544.33  |proj g|=       0.70848
At iterate    30  f =      -544.57  |proj g|=       0.70596
At iterate    31  f =      -544.92  |proj g|=       0.70088
At iterate    32  f =      -545.15  |proj g|=       0.69824
At iterate    33  f =      -546.31  |proj g|=         2.111
At iterate    34  f =      -546.93  |proj g|=          1.26
At iterate    35  f =      -547.57  |proj g|=        1.2087
At iterate    36  f =      -547.61  |proj g|=       0.99197
At iterate    37  f =      -547.62  |proj g|=        1.0963
At iterate    38  f =      -547.62  |proj g|=        1.0814
At iterate    39  f =      -547.62  |proj g|=        1.0805
At iterate    40  f =      -547.62  |proj g|=        1.0767
At iterate    41  f =      -547.62  |proj g|=        1.0649
At iterate    42  f =      -547.62  |proj g|=        1.0494
At iterate    43  f =      -547.63  |proj g|=        1.0192
At iterate    44  f =      -547.63  |proj g|=        1.0404
At iterate    45  f =      -547.65  |proj g|=       0.96195
At iterate    46  f =      -547.68  |proj g|=       0.88675
At iterate    47  f =      -547.78  |proj g|=       0.71627
At iterate    48  f =      -547.97  |proj g|=        0.4628
At iterate    49  f =      -548.31  |proj g|=       0.36581
At iterate    50  f =      -548.66  |proj g|=       0.38014
At iterate    51  f =      -548.87  |proj g|=       0.38862
At iterate    52  f =       -548.9  |proj g|=       0.39183
At iterate    53  f =      -548.91  |proj g|=       0.39284
At iterate    54  f =      -548.91  |proj g|=         0.393
At iterate    55  f =      -548.91  |proj g|=       0.39304
At iterate    56  f =      -548.91  |proj g|=       0.39304
At iterate    57  f =      -548.91  |proj g|=       0.39295
At iterate    58  f =      -548.91  |proj g|=        0.3927
At iterate    59  f =      -548.91  |proj g|=       0.11223
At iterate    60  f =      -548.91  |proj g|=       0.26699
At iterate    61  f =      -548.91  |proj g|=       0.17398
At iterate    62  f =      -548.91  |proj g|=      0.060601
At iterate    63  f =      -548.91  |proj g|=      0.012727
At iterate    64  f =      -548.91  |proj g|=      0.012727

iterations 64
function evaluations 71
segments explored during Cauchy searches 67
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0127272
final function value -548.91

F = -548.91
final  value -548.909559 
converged
 
INFO  [08:18:46.851] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:18:46.937] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:18:46.944] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:18:53.878] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:18:59.934] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:19:06.085] [mlr3]  Finished benchmark 
INFO  [08:19:06.184] [bbotk] Result of batch 94: 
INFO  [08:19:06.185] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:19:06.185] [bbotk]              4.663004                 8.505378                       0.4291585 
INFO  [08:19:06.185] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:19:06.185] [bbotk]                     2497         0.95 -0.9546325         <NA>   0.9765158 
INFO  [08:19:06.185] [bbotk]                                 uhash 
INFO  [08:19:06.185] [bbotk]  1dd7aa46-635c-49d8-b23d-5d63292f33cc 
DEBUG [08:19:07.269] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.21803e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.21803e-05 0.001505365 
  - best initial criterion value(s) :  507.3857 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -507.39  |proj g|=        6.578
At iterate     1  f =      -544.83  |proj g|=        1.8275
At iterate     2  f =      -545.14  |proj g|=         2.268
At iterate     3  f =      -545.14  |proj g|=        2.2738
At iterate     4  f =      -545.14  |proj g|=        2.2832
At iterate     5  f =      -545.15  |proj g|=        2.3059
At iterate     6  f =      -545.15  |proj g|=        2.3377
At iterate     7  f =      -545.17  |proj g|=        2.3916
At iterate     8  f =      -545.23  |proj g|=        2.4753
At iterate     9  f =      -547.93  |proj g|=        2.0193
At iterate    10  f =      -563.15  |proj g|=        1.2318
At iterate    11  f =      -566.94  |proj g|=       0.91008
At iterate    12  f =      -566.95  |proj g|=       0.91022
At iterate    13  f =      -566.95  |proj g|=       0.91022
At iterate    14  f =      -566.95  |proj g|=       0.91021
At iterate    15  f =      -566.95  |proj g|=       0.91021
At iterate    16  f =      -566.95  |proj g|=       0.91016
At iterate    17  f =      -566.95  |proj g|=       0.91005
At iterate    18  f =      -566.95  |proj g|=       0.90975
At iterate    19  f =      -566.95  |proj g|=       0.90896
At iterate    20  f =      -566.95  |proj g|=        0.9069
At iterate    21  f =      -566.96  |proj g|=       0.90161
At iterate    22  f =      -566.96  |proj g|=       0.88792
At iterate    23  f =      -566.99  |proj g|=       0.85286
At iterate    24  f =      -567.92  |proj g|=        0.4048
At iterate    25  f =      -568.02  |proj g|=       0.40309
At iterate    26  f =      -568.07  |proj g|=       0.39495
At iterate    27  f =      -568.12  |proj g|=      0.017537
At iterate    28  f =      -568.12  |proj g|=     0.0013366

iterations 28
function evaluations 40
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 3
norm of the final projected gradient 0.00133658
final function value -568.116

F = -568.116
final  value -568.116047 
converged
 
INFO  [08:19:07.273] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:19:07.377] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:19:07.384] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:19:11.819] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:19:15.884] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:19:20.162] [mlr3]  Finished benchmark 
INFO  [08:19:20.284] [bbotk] Result of batch 95: 
INFO  [08:19:20.286] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:19:20.286] [bbotk]              9.151274                 3.658953                       0.1137725 
INFO  [08:19:20.286] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [08:19:20.286] [bbotk]                     1848        0.703 -0.946508         <NA>   0.9701984 
INFO  [08:19:20.286] [bbotk]                                 uhash 
INFO  [08:19:20.286] [bbotk]  25f3655f-cd11-4cfd-9c5a-603a58c4a231 
DEBUG [08:19:21.440] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.208694e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.208694e-05 0.001496887 
  - best initial criterion value(s) :  504.4882 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -504.49  |proj g|=       6.4768
At iterate     1  f =      -518.22  |proj g|=        7.0994
At iterate     2  f =      -518.49  |proj g|=        6.9414
At iterate     3  f =      -519.09  |proj g|=        5.2377
At iterate     4  f =      -519.24  |proj g|=        5.5433
At iterate     5  f =      -519.28  |proj g|=        5.3238
At iterate     6  f =      -519.29  |proj g|=        5.0949
At iterate     7  f =      -519.29  |proj g|=        5.0637
At iterate     8  f =       -519.3  |proj g|=        4.9845
At iterate     9  f =      -519.34  |proj g|=        4.7853
At iterate    10  f =      -519.35  |proj g|=        4.7368
At iterate    11  f =      -519.45  |proj g|=        4.4488
At iterate    12  f =       -526.8  |proj g|=        3.3281
At iterate    13  f =      -546.42  |proj g|=        2.6946
At iterate    14  f =      -553.05  |proj g|=        2.1975
At iterate    15  f =      -556.95  |proj g|=        1.6574
At iterate    16  f =      -558.46  |proj g|=        2.5649
At iterate    17  f =      -560.71  |proj g|=        2.3639
At iterate    18  f =      -560.79  |proj g|=         2.483
At iterate    19  f =      -560.79  |proj g|=        2.4847
At iterate    20  f =      -560.79  |proj g|=        2.4852
At iterate    21  f =      -560.79  |proj g|=         2.486
At iterate    22  f =      -560.79  |proj g|=        2.4881
At iterate    23  f =      -560.79  |proj g|=         2.491
At iterate    24  f =      -560.79  |proj g|=        2.4958
At iterate    25  f =      -560.79  |proj g|=         2.503
At iterate    26  f =       -560.8  |proj g|=         2.514
At iterate    27  f =      -560.81  |proj g|=        2.5295
At iterate    28  f =      -560.84  |proj g|=        2.5494
At iterate    29  f =       -560.9  |proj g|=        2.5685
At iterate    30  f =      -561.08  |proj g|=        2.5678
At iterate    31  f =      -562.14  |proj g|=        2.3091
At iterate    32  f =      -568.73  |proj g|=        1.0493
At iterate    33  f =      -569.85  |proj g|=       0.54434
At iterate    34  f =      -569.86  |proj g|=        0.2958
At iterate    35  f =      -569.86  |proj g|=       0.29518
At iterate    36  f =      -569.86  |proj g|=        0.2952

iterations 36
function evaluations 48
segments explored during Cauchy searches 41
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.295201
final function value -569.862

F = -569.862
final  value -569.861842 
converged
 
INFO  [08:19:21.445] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:19:21.532] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:19:21.539] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:19:31.617] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:19:41.439] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:19:51.446] [mlr3]  Finished benchmark 
INFO  [08:19:51.544] [bbotk] Result of batch 96: 
INFO  [08:19:51.546] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:19:51.546] [bbotk]              5.372354                 8.379452                       0.4478073 
INFO  [08:19:51.546] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:19:51.546] [bbotk]                     4430        0.725 -0.9441301         <NA>   0.9785235 
INFO  [08:19:51.546] [bbotk]                                 uhash 
INFO  [08:19:51.546] [bbotk]  62bd1239-543e-48d8-8e94-770056245734 
DEBUG [08:19:52.719] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.207907e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.207907e-05 0.001495098 
  - best initial criterion value(s) :  518.7116 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -518.71  |proj g|=       6.7783
At iterate     1  f =      -527.13  |proj g|=        7.4395
At iterate     2  f =      -528.51  |proj g|=        7.1251
At iterate     3  f =       -531.7  |proj g|=        5.3137
At iterate     4  f =      -532.39  |proj g|=        4.0181
At iterate     5  f =      -532.82  |proj g|=        4.0558
At iterate     6  f =      -532.83  |proj g|=        4.0391
At iterate     7  f =      -532.83  |proj g|=        4.0412
At iterate     8  f =      -532.83  |proj g|=        4.0527
At iterate     9  f =      -532.84  |proj g|=        4.0631
At iterate    10  f =      -532.84  |proj g|=        4.0851
At iterate    11  f =      -532.86  |proj g|=        4.1149
At iterate    12  f =      -532.91  |proj g|=        4.1612
At iterate    13  f =      -533.03  |proj g|=         4.219
At iterate    14  f =      -533.35  |proj g|=        4.2672
At iterate    15  f =      -534.02  |proj g|=        4.2256
At iterate    16  f =      -535.15  |proj g|=        3.9215
At iterate    17  f =      -535.72  |proj g|=        3.6054
At iterate    18  f =      -536.08  |proj g|=        3.3004
At iterate    19  f =      -537.16  |proj g|=         3.034
At iterate    20  f =      -550.91  |proj g|=        1.3051
At iterate    21  f =      -563.32  |proj g|=        1.3748
At iterate    22  f =      -564.91  |proj g|=        1.2375
At iterate    23  f =      -566.16  |proj g|=        1.6244
At iterate    24  f =      -566.36  |proj g|=        1.7796
At iterate    25  f =      -566.38  |proj g|=        1.8399
At iterate    26  f =      -566.38  |proj g|=        1.8498
At iterate    27  f =      -566.38  |proj g|=        1.8508
At iterate    28  f =      -566.38  |proj g|=        1.8575
At iterate    29  f =      -566.38  |proj g|=        1.8653
At iterate    30  f =      -566.39  |proj g|=        1.8797
At iterate    31  f =       -566.4  |proj g|=        1.9018
At iterate    32  f =      -566.42  |proj g|=        1.9379
At iterate    33  f =      -566.49  |proj g|=        1.9951
At iterate    34  f =      -566.66  |proj g|=        2.0856
At iterate    35  f =       -567.1  |proj g|=        2.2204
At iterate    36  f =      -568.13  |proj g|=        2.3898
At iterate    37  f =      -570.37  |proj g|=        2.4714
At iterate    38  f =       -571.8  |proj g|=        2.1015
At iterate    39  f =      -573.19  |proj g|=        1.9494
At iterate    40  f =      -573.34  |proj g|=          1.99
At iterate    41  f =      -573.35  |proj g|=        1.9575
At iterate    42  f =      -573.35  |proj g|=        1.9654
At iterate    43  f =      -573.35  |proj g|=        1.9656

iterations 43
function evaluations 51
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.96562
final function value -573.347

F = -573.347
final  value -573.347087 
converged
 
INFO  [08:19:52.723] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:19:52.829] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:19:52.836] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:20:03.753] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:20:14.701] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:20:24.052] [mlr3]  Finished benchmark 
INFO  [08:20:24.151] [bbotk] Result of batch 97: 
INFO  [08:20:24.153] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:20:24.153] [bbotk]              9.767084                 7.117299                      0.04994094 
INFO  [08:20:24.153] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:20:24.153] [bbotk]                     4471        0.725 -0.9489779         <NA>   0.9707614 
INFO  [08:20:24.153] [bbotk]                                 uhash 
INFO  [08:20:24.153] [bbotk]  5d4be459-e57c-45b3-8bec-20dec9b08fd6 
DEBUG [08:20:25.405] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.198978e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.198978e-05 0.001483143 
  - best initial criterion value(s) :  509.7954 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -509.8  |proj g|=       13.431
At iterate     1  f =      -531.63  |proj g|=        5.3305
At iterate     2  f =      -550.38  |proj g|=        3.9313
At iterate     3  f =      -555.12  |proj g|=         2.909
At iterate     4  f =      -559.81  |proj g|=         2.333
At iterate     5  f =      -561.52  |proj g|=        1.9934
At iterate     6  f =       -562.8  |proj g|=        1.7764
At iterate     7  f =      -564.96  |proj g|=        2.9701
At iterate     8  f =      -566.56  |proj g|=        2.4917
At iterate     9  f =       -567.5  |proj g|=        2.1879
At iterate    10  f =      -567.95  |proj g|=        2.2102
At iterate    11  f =      -568.02  |proj g|=        2.3738
At iterate    12  f =      -568.03  |proj g|=        2.4348
At iterate    13  f =      -568.05  |proj g|=        2.4862
At iterate    14  f =      -568.19  |proj g|=        2.6214
At iterate    15  f =       -568.6  |proj g|=        2.8464
At iterate    16  f =      -572.72  |proj g|=        2.9585
At iterate    17  f =       -574.6  |proj g|=        2.6473
At iterate    18  f =      -575.78  |proj g|=        2.2972
At iterate    19  f =      -575.93  |proj g|=         2.371
At iterate    20  f =      -575.97  |proj g|=        2.3367
At iterate    21  f =      -575.97  |proj g|=         2.352
At iterate    22  f =      -575.97  |proj g|=        2.3395
At iterate    23  f =      -575.97  |proj g|=        2.3405
At iterate    24  f =      -575.97  |proj g|=        2.3405

iterations 24
function evaluations 33
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.34049
final function value -575.971

F = -575.971
final  value -575.970838 
converged
 
INFO  [08:20:25.409] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:20:25.497] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:20:25.504] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:20:28.846] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:20:33.110] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:20:37.154] [mlr3]  Finished benchmark 
INFO  [08:20:37.255] [bbotk] Result of batch 98: 
INFO  [08:20:37.257] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:20:37.257] [bbotk]              6.203594                 3.483024                     0.005895457 
INFO  [08:20:37.257] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:20:37.257] [bbotk]                     1494        0.877 -0.9499168         <NA>   0.9177614 
INFO  [08:20:37.257] [bbotk]                                 uhash 
INFO  [08:20:37.257] [bbotk]  ccc09221-4684-42c7-b2d3-d3cd2ba13d2d 
DEBUG [08:20:38.577] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.385676e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.385676e-05 0.001658933 
  - best initial criterion value(s) :  530.4692 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -530.47  |proj g|=       6.1223
At iterate     1  f =      -552.39  |proj g|=        6.1864
At iterate     2  f =      -555.93  |proj g|=        4.9764
At iterate     3  f =      -558.14  |proj g|=        1.7558
At iterate     4  f =      -558.63  |proj g|=        2.8374
At iterate     5  f =      -558.71  |proj g|=        2.7328
At iterate     6  f =      -559.35  |proj g|=        2.0169
At iterate     7  f =       -559.6  |proj g|=        2.0487
At iterate     8  f =      -559.65  |proj g|=        2.0991
At iterate     9  f =      -559.65  |proj g|=        2.1282
At iterate    10  f =      -559.65  |proj g|=        2.1355
At iterate    11  f =      -559.65  |proj g|=        2.1358
At iterate    12  f =      -559.65  |proj g|=        2.1375
At iterate    13  f =      -559.65  |proj g|=        2.1392
At iterate    14  f =      -559.65  |proj g|=        2.1415
At iterate    15  f =      -559.65  |proj g|=        2.1436
At iterate    16  f =      -559.65  |proj g|=        2.1424
At iterate    17  f =      -559.66  |proj g|=        2.1289
At iterate    18  f =      -559.67  |proj g|=        2.1262
At iterate    19  f =      -559.69  |proj g|=         2.051
At iterate    20  f =      -559.69  |proj g|=        2.1616
At iterate    21  f =      -559.75  |proj g|=        2.0068
At iterate    22  f =       -559.9  |proj g|=        1.7475
At iterate    23  f =      -560.37  |proj g|=        1.2826
At iterate    24  f =      -561.64  |proj g|=         1.267
At iterate    25  f =       -563.3  |proj g|=        1.3036
At iterate    26  f =       -563.3  |proj g|=        1.3045
At iterate    27  f =      -563.34  |proj g|=        1.3105
At iterate    28  f =      -563.34  |proj g|=        1.3111
At iterate    29  f =      -563.34  |proj g|=        1.3108
At iterate    30  f =      -563.34  |proj g|=        1.3109
At iterate    31  f =      -563.34  |proj g|=        1.3109
At iterate    32  f =      -563.34  |proj g|=        1.3109
At iterate    33  f =      -563.34  |proj g|=        1.3111
At iterate    34  f =      -563.34  |proj g|=        1.3114
At iterate    35  f =      -563.34  |proj g|=        1.3122
At iterate    36  f =      -563.34  |proj g|=        1.3122
At iterate    37  f =      -563.35  |proj g|=        1.3108
At iterate    38  f =      -563.35  |proj g|=        1.3108
At iterate    39  f =      -563.41  |proj g|=         1.281
At iterate    40  f =      -563.57  |proj g|=        1.1803
At iterate    41  f =      -563.97  |proj g|=       0.85461
At iterate    42  f =      -563.98  |proj g|=       0.83769
At iterate    43  f =      -564.65  |proj g|=       0.61292
At iterate    44  f =      -564.66  |proj g|=       0.61251
At iterate    45  f =      -564.86  |proj g|=        0.6116
At iterate    46  f =      -565.13  |proj g|=       0.61116
At iterate    47  f =      -565.77  |proj g|=       0.40577
At iterate    48  f =       -565.9  |proj g|=       0.39129
At iterate    49  f =      -565.91  |proj g|=       0.38984
At iterate    50  f =      -565.91  |proj g|=       0.38801
At iterate    51  f =      -565.92  |proj g|=       0.14377
At iterate    52  f =      -565.92  |proj g|=       0.60015
At iterate    53  f =      -565.93  |proj g|=       0.29195
At iterate    54  f =      -565.93  |proj g|=      0.034446
At iterate    55  f =      -565.93  |proj g|=      0.002912

iterations 55
function evaluations 68
segments explored during Cauchy searches 57
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00291197
final function value -565.925

F = -565.925
final  value -565.925133 
converged
 
INFO  [08:20:38.582] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:20:38.697] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:20:38.707] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:20:48.331] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:20:59.456] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:21:08.938] [mlr3]  Finished benchmark 
INFO  [08:21:09.080] [bbotk] Result of batch 99: 
INFO  [08:21:09.082] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:21:09.082] [bbotk]              2.857166                 2.815197                       0.1537216 
INFO  [08:21:09.082] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:21:09.082] [bbotk]                     4038        0.762 -0.9538528         <NA>   0.9677136 
INFO  [08:21:09.082] [bbotk]                                 uhash 
INFO  [08:21:09.082] [bbotk]  3c963542-06e0-4bd9-8417-d083ecafa48b 
DEBUG [08:21:10.139] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.374934e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.374934e-05 0.001647803 
  - best initial criterion value(s) :  479.5962 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -479.6  |proj g|=       14.165
At iterate     1  f =      -503.73  |proj g|=        8.9563
At iterate     2  f =      -515.58  |proj g|=        6.4477
At iterate     3  f =      -520.78  |proj g|=        4.7215
At iterate     4  f =      -521.87  |proj g|=        4.2739
At iterate     5  f =       -531.3  |proj g|=        3.2823
At iterate     6  f =      -537.76  |proj g|=        2.8248
At iterate     7  f =      -554.17  |proj g|=       0.68963
At iterate     8  f =      -560.34  |proj g|=        1.0687
At iterate     9  f =      -560.35  |proj g|=       0.95842
At iterate    10  f =      -560.36  |proj g|=       0.97202
At iterate    11  f =      -560.37  |proj g|=       0.97143
At iterate    12  f =      -560.37  |proj g|=       0.96866
At iterate    13  f =      -560.37  |proj g|=       0.96828

iterations 13
function evaluations 16
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.968281
final function value -560.367

F = -560.367
final  value -560.367357 
converged
 
INFO  [08:21:10.143] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:21:10.231] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:21:10.238] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:21:15.102] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:21:19.535] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:21:24.391] [mlr3]  Finished benchmark 
INFO  [08:21:24.508] [bbotk] Result of batch 100: 
INFO  [08:21:24.510] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:21:24.510] [bbotk]               6.80787                 3.242113                       0.2161218 
INFO  [08:21:24.510] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:21:24.510] [bbotk]                     1763        0.766 -0.9547936         <NA>    0.973212 
INFO  [08:21:24.510] [bbotk]                                 uhash 
INFO  [08:21:24.510] [bbotk]  f4b13244-ab8d-41d3-a92e-034807956fda 
DEBUG [08:21:25.958] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.366708e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.366708e-05 0.001635578 
  - best initial criterion value(s) :  543.4168 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -543.42  |proj g|=       8.2461
At iterate     1  f =      -552.21  |proj g|=        4.7315
At iterate     2  f =      -552.42  |proj g|=        4.6955
At iterate     3  f =      -552.51  |proj g|=        4.5044
At iterate     4  f =      -552.51  |proj g|=         4.599
At iterate     5  f =      -552.51  |proj g|=        4.5328
At iterate     6  f =      -552.51  |proj g|=          4.53
At iterate     7  f =      -552.53  |proj g|=        4.4988
At iterate     8  f =      -552.65  |proj g|=        4.3721
At iterate     9  f =      -552.97  |proj g|=        4.0812
At iterate    10  f =      -553.61  |proj g|=        3.1114
At iterate    11  f =      -554.59  |proj g|=        2.6507
At iterate    12  f =      -555.47  |proj g|=        2.1245
At iterate    13  f =      -557.98  |proj g|=        1.8839
At iterate    14  f =       -559.7  |proj g|=        1.8378
At iterate    15  f =       -560.9  |proj g|=        1.6529
At iterate    16  f =      -560.96  |proj g|=        1.6379
At iterate    17  f =      -560.99  |proj g|=        1.6474
At iterate    18  f =      -560.99  |proj g|=        1.6484
At iterate    19  f =      -560.99  |proj g|=        1.6487
At iterate    20  f =      -560.99  |proj g|=         1.649
At iterate    21  f =      -560.99  |proj g|=        1.6493
At iterate    22  f =      -560.99  |proj g|=        1.6498
At iterate    23  f =      -560.99  |proj g|=          1.65
At iterate    24  f =      -560.99  |proj g|=        1.6503
At iterate    25  f =      -560.99  |proj g|=         1.651
At iterate    26  f =      -560.99  |proj g|=        1.6522
At iterate    27  f =      -560.99  |proj g|=        1.6538
At iterate    28  f =      -560.99  |proj g|=        1.6532
At iterate    29  f =         -561  |proj g|=         1.653
At iterate    30  f =         -561  |proj g|=        1.6268
At iterate    31  f =         -561  |proj g|=        1.6209
At iterate    32  f =      -561.01  |proj g|=         1.606
At iterate    33  f =      -561.01  |proj g|=        1.5924
At iterate    34  f =      -561.01  |proj g|=        1.5685
At iterate    35  f =      -561.01  |proj g|=        1.5718
At iterate    36  f =      -561.02  |proj g|=        1.5726
At iterate    37  f =      -561.03  |proj g|=        1.5669
At iterate    38  f =      -561.07  |proj g|=         1.542
At iterate    39  f =      -561.15  |proj g|=        1.4581
At iterate    40  f =      -561.37  |proj g|=         1.217
At iterate    41  f =      -561.89  |proj g|=         0.708
At iterate    42  f =      -562.59  |proj g|=       0.70778
At iterate    43  f =      -562.89  |proj g|=        1.0094
At iterate    44  f =      -563.02  |proj g|=       0.82544
At iterate    45  f =      -563.14  |proj g|=       0.75584
At iterate    46  f =      -563.17  |proj g|=       0.77295
At iterate    47  f =      -563.17  |proj g|=       0.77865
At iterate    48  f =      -563.19  |proj g|=       0.78142
At iterate    49  f =      -563.23  |proj g|=       0.73557
At iterate    50  f =      -563.23  |proj g|=       0.78795
At iterate    51  f =      -563.31  |proj g|=       0.70361
At iterate    52  f =      -563.93  |proj g|=       0.29551
At iterate    53  f =      -564.05  |proj g|=       0.27709
At iterate    54  f =      -564.06  |proj g|=       0.70133
At iterate    55  f =      -564.06  |proj g|=       0.16204
At iterate    56  f =      -564.06  |proj g|=      0.013687
At iterate    57  f =      -564.06  |proj g|=      0.013687

iterations 57
function evaluations 66
segments explored during Cauchy searches 59
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0136873
final function value -564.059

F = -564.059
final  value -564.059172 
converged
 
INFO  [08:21:25.962] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:21:26.050] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:21:26.057] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:21:30.034] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:21:34.027] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:21:37.935] [mlr3]  Finished benchmark 
INFO  [08:21:38.065] [bbotk] Result of batch 101: 
INFO  [08:21:38.067] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:21:38.067] [bbotk]               2.64364                 8.426112                       0.1105067 
INFO  [08:21:38.067] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:21:38.067] [bbotk]                     1565        0.734 -0.9589476         <NA>   0.9520511 
INFO  [08:21:38.067] [bbotk]                                 uhash 
INFO  [08:21:38.067] [bbotk]  25021e16-0a48-4e06-91b2-c4c6d2558392 
DEBUG [08:21:39.377] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.374841e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.374841e-05 0.001642329 
  - best initial criterion value(s) :  528.2523 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -528.25  |proj g|=       6.5325
At iterate     1  f =      -539.44  |proj g|=        7.6122
At iterate     2  f =      -543.33  |proj g|=        6.5489
At iterate     3  f =      -545.57  |proj g|=        6.1421
At iterate     4  f =      -548.87  |proj g|=         4.803
At iterate     5  f =      -549.12  |proj g|=        4.4248
At iterate     6  f =      -549.38  |proj g|=        4.4602
At iterate     7  f =      -549.38  |proj g|=        4.4719
At iterate     8  f =      -549.38  |proj g|=        4.4676
At iterate     9  f =      -549.38  |proj g|=        4.4659
At iterate    10  f =      -549.38  |proj g|=        4.4607
At iterate    11  f =      -549.38  |proj g|=        4.4525
At iterate    12  f =      -549.38  |proj g|=        4.4405
At iterate    13  f =      -549.39  |proj g|=        4.4227
At iterate    14  f =       -549.4  |proj g|=        4.3943
At iterate    15  f =      -549.44  |proj g|=        4.3457
At iterate    16  f =      -549.55  |proj g|=        4.2566
At iterate    17  f =      -549.85  |proj g|=        4.0865
At iterate    18  f =       -550.7  |proj g|=        3.7575
At iterate    19  f =      -553.16  |proj g|=        3.1554
At iterate    20  f =      -560.38  |proj g|=        2.2078
At iterate    21  f =      -570.22  |proj g|=        2.2439
At iterate    22  f =      -570.91  |proj g|=        2.8967
At iterate    23  f =      -571.13  |proj g|=        3.3813
At iterate    24  f =      -571.15  |proj g|=        3.5199
At iterate    25  f =      -571.15  |proj g|=        3.5461
At iterate    26  f =      -571.15  |proj g|=        3.5567
At iterate    27  f =      -571.16  |proj g|=        3.5943
At iterate    28  f =      -571.16  |proj g|=        3.6462
At iterate    29  f =      -571.18  |proj g|=        3.7365
At iterate    30  f =      -571.22  |proj g|=        3.8779
At iterate    31  f =      -571.31  |proj g|=        4.0908
At iterate    32  f =       -571.5  |proj g|=        4.3504
At iterate    33  f =      -571.81  |proj g|=        4.4767
At iterate    34  f =         -572  |proj g|=        4.0076
At iterate    35  f =      -572.01  |proj g|=        4.1423
At iterate    36  f =      -572.01  |proj g|=         4.141
At iterate    37  f =      -572.01  |proj g|=        4.1411
At iterate    38  f =      -572.01  |proj g|=        4.1414
At iterate    39  f =      -572.01  |proj g|=        4.1365
At iterate    40  f =      -572.01  |proj g|=        4.1373
At iterate    41  f =      -572.01  |proj g|=         4.143
At iterate    42  f =      -572.03  |proj g|=         4.163
At iterate    43  f =      -572.05  |proj g|=        4.1787
At iterate    44  f =      -572.13  |proj g|=        4.1793
At iterate    45  f =      -572.17  |proj g|=        4.5885
At iterate    46  f =      -572.42  |proj g|=        4.2027
At iterate    47  f =      -572.83  |proj g|=        3.6184
At iterate    48  f =      -573.77  |proj g|=        2.5384
At iterate    49  f =      -575.42  |proj g|=        1.2021
At iterate    50  f =      -577.35  |proj g|=       0.32607
At iterate    51  f =      -577.53  |proj g|=       0.36957
At iterate    52  f =      -578.64  |proj g|=       0.33567
At iterate    53  f =       -578.8  |proj g|=       0.65814
At iterate    54  f =      -578.86  |proj g|=        0.6525
At iterate    55  f =      -578.87  |proj g|=       0.33158
At iterate    56  f =      -578.87  |proj g|=       0.33128
At iterate    57  f =      -578.87  |proj g|=       0.27078
At iterate    58  f =      -578.87  |proj g|=     0.0054421
At iterate    59  f =      -578.87  |proj g|=     0.0039987

iterations 59
function evaluations 70
segments explored during Cauchy searches 61
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00399865
final function value -578.872

F = -578.872
final  value -578.871904 
converged
 
INFO  [08:21:39.382] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:21:39.478] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:21:39.485] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:21:41.584] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:21:43.786] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:21:45.834] [mlr3]  Finished benchmark 
INFO  [08:21:45.980] [bbotk] Result of batch 102: 
INFO  [08:21:45.982] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:21:45.982] [bbotk]              5.832251                 2.606451                      0.01949599 
INFO  [08:21:45.982] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:21:45.982] [bbotk]                      922        0.737 -0.9555974         <NA>    0.931781 
INFO  [08:21:45.982] [bbotk]                                 uhash 
INFO  [08:21:45.982] [bbotk]  212acea0-d335-4f9e-9d5e-1fe1e7d2b428 
DEBUG [08:21:47.032] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.460823e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.460823e-05 0.001744562 
  - best initial criterion value(s) :  516.2357 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -516.24  |proj g|=       4.9714
At iterate     1  f =      -529.76  |proj g|=         2.288
At iterate     2  f =      -540.48  |proj g|=        2.5458
At iterate     3  f =      -550.41  |proj g|=        2.6402
At iterate     4  f =      -554.59  |proj g|=        2.6629
At iterate     5  f =      -564.32  |proj g|=        2.2611
At iterate     6  f =      -565.25  |proj g|=        2.0403
At iterate     7  f =      -565.39  |proj g|=        2.0502
At iterate     8  f =      -565.39  |proj g|=        2.0641
At iterate     9  f =      -565.39  |proj g|=         2.059
At iterate    10  f =      -565.39  |proj g|=        2.0591

iterations 10
function evaluations 18
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.05905
final function value -565.394

F = -565.394
final  value -565.393909 
converged
 
INFO  [08:21:47.036] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:21:47.127] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:21:47.134] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:21:48.931] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:21:50.344] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:21:52.288] [mlr3]  Finished benchmark 
INFO  [08:21:52.431] [bbotk] Result of batch 103: 
INFO  [08:21:52.434] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:21:52.434] [bbotk]              5.563889                   2.2771                        0.182917 
INFO  [08:21:52.434] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:21:52.434] [bbotk]                      347        0.743 -0.9580135         <NA>   0.9558138 
INFO  [08:21:52.434] [bbotk]                                 uhash 
INFO  [08:21:52.434] [bbotk]  91c5268c-56e5-4cbf-81a2-b4dc8ecda7d8 
DEBUG [08:21:53.593] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.459715e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.459715e-05 0.00173462 
  - best initial criterion value(s) :  536.2972 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -536.3  |proj g|=       5.8326
At iterate     1  f =      -538.16  |proj g|=        6.4096
At iterate     2  f =      -539.55  |proj g|=         6.189
At iterate     3  f =      -541.52  |proj g|=        5.6154
At iterate     4  f =      -543.48  |proj g|=        4.5346
At iterate     5  f =      -546.18  |proj g|=        4.1663
At iterate     6  f =       -547.1  |proj g|=        3.6763
At iterate     7  f =      -547.16  |proj g|=        3.8582
At iterate     8  f =      -547.17  |proj g|=        3.8252
At iterate     9  f =      -547.17  |proj g|=         3.824
At iterate    10  f =      -547.17  |proj g|=         3.823
At iterate    11  f =      -547.17  |proj g|=        3.8195
At iterate    12  f =      -547.17  |proj g|=        3.8125
At iterate    13  f =      -547.17  |proj g|=        3.8023
At iterate    14  f =      -547.18  |proj g|=        3.7774
At iterate    15  f =      -547.19  |proj g|=        3.7598
At iterate    16  f =      -547.21  |proj g|=          3.73
At iterate    17  f =      -547.45  |proj g|=         3.541
At iterate    18  f =      -547.91  |proj g|=        3.3097
At iterate    19  f =      -549.37  |proj g|=        2.8655
At iterate    20  f =      -553.26  |proj g|=        2.2022
At iterate    21  f =       -562.6  |proj g|=        1.3779
At iterate    22  f =      -565.49  |proj g|=        1.3678
At iterate    23  f =      -569.07  |proj g|=        1.3073
At iterate    24  f =       -569.8  |proj g|=       0.99126
At iterate    25  f =      -570.09  |proj g|=       0.28699
At iterate    26  f =      -570.14  |proj g|=       0.53569
At iterate    27  f =      -570.15  |proj g|=       0.48885
At iterate    28  f =      -570.15  |proj g|=       0.47391
At iterate    29  f =      -570.15  |proj g|=       0.47206
At iterate    30  f =      -570.15  |proj g|=       0.47295
At iterate    31  f =      -570.15  |proj g|=       0.47341

iterations 31
function evaluations 34
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.473414
final function value -570.148

F = -570.148
final  value -570.148019 
converged
 
INFO  [08:21:53.598] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:21:53.698] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:21:53.706] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:21:55.422] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:21:56.956] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:21:58.546] [mlr3]  Finished benchmark 
INFO  [08:21:58.700] [bbotk] Result of batch 104: 
INFO  [08:21:58.702] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:21:58.702] [bbotk]               2.20138                 2.293439                      0.02936738 
INFO  [08:21:58.702] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:21:58.702] [bbotk]                      639        0.765 -0.9610552         <NA>   0.9006195 
INFO  [08:21:58.702] [bbotk]                                 uhash 
INFO  [08:21:58.702] [bbotk]  abf7a81b-dccd-44f3-b190-9c7482ad98a3 
DEBUG [08:22:00.083] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.777506e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.777506e-05 0.00216323 
  - best initial criterion value(s) :  505.5527 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -505.55  |proj g|=       4.5931
At iterate     1  f =      -524.77  |proj g|=        7.6401
At iterate     2  f =      -527.06  |proj g|=         7.381
At iterate     3  f =      -528.49  |proj g|=        5.7188
At iterate     4  f =      -529.37  |proj g|=        6.7212
At iterate     5  f =      -529.47  |proj g|=        6.5774
At iterate     6  f =      -529.53  |proj g|=         6.525
At iterate     7  f =      -529.66  |proj g|=        6.5509
At iterate     8  f =       -529.9  |proj g|=         6.821
At iterate     9  f =      -529.98  |proj g|=        7.1345
At iterate    10  f =      -529.99  |proj g|=        7.1808
At iterate    11  f =      -529.99  |proj g|=        7.1879
At iterate    12  f =      -529.99  |proj g|=        7.1959
At iterate    13  f =      -529.99  |proj g|=        7.2285
At iterate    14  f =      -529.99  |proj g|=        7.2466
At iterate    15  f =      -530.01  |proj g|=        7.3379
At iterate    16  f =      -530.06  |proj g|=        7.4458
At iterate    17  f =      -530.18  |proj g|=        7.6123
At iterate    18  f =      -530.44  |proj g|=        7.8211
At iterate    19  f =      -531.03  |proj g|=        7.9484
At iterate    20  f =      -531.04  |proj g|=        8.3728
At iterate    21  f =      -532.11  |proj g|=        8.0983
At iterate    22  f =      -533.75  |proj g|=        7.3919
At iterate    23  f =      -536.19  |proj g|=        6.0455
At iterate    24  f =       -537.7  |proj g|=         5.223
At iterate    25  f =      -538.03  |proj g|=        5.3446
At iterate    26  f =      -538.14  |proj g|=        5.1161
At iterate    27  f =      -538.15  |proj g|=        5.0941
At iterate    28  f =      -538.15  |proj g|=        5.0971
At iterate    29  f =      -538.15  |proj g|=        5.0975
At iterate    30  f =      -538.15  |proj g|=        5.0982
At iterate    31  f =      -538.15  |proj g|=        5.0995
At iterate    32  f =      -538.15  |proj g|=        5.1018
At iterate    33  f =      -538.15  |proj g|=        5.1042
At iterate    34  f =      -538.15  |proj g|=        5.1098
At iterate    35  f =      -538.15  |proj g|=        5.1099
At iterate    36  f =      -538.15  |proj g|=        5.1152
At iterate    37  f =      -538.15  |proj g|=        5.1419
At iterate    38  f =      -538.15  |proj g|=        5.1094
At iterate    39  f =      -538.16  |proj g|=        5.1691
At iterate    40  f =      -538.19  |proj g|=        5.2432
At iterate    41  f =      -538.28  |proj g|=        5.3736
At iterate    42  f =      -538.49  |proj g|=        5.5612
At iterate    43  f =      -539.02  |proj g|=        5.8412
At iterate    44  f =      -540.45  |proj g|=        6.1188
At iterate    45  f =      -545.21  |proj g|=        5.7011
At iterate    46  f =      -547.32  |proj g|=        5.2194
At iterate    47  f =      -550.91  |proj g|=          3.96
At iterate    48  f =       -551.7  |proj g|=        3.5555
At iterate    49  f =      -552.02  |proj g|=        3.1861
At iterate    50  f =      -552.04  |proj g|=        3.1362
At iterate    51  f =      -552.06  |proj g|=        3.0745
At iterate    52  f =      -552.07  |proj g|=        3.0568
At iterate    53  f =      -552.11  |proj g|=         2.947
At iterate    54  f =      -552.16  |proj g|=        2.8721
At iterate    55  f =      -552.34  |proj g|=        2.6873
At iterate    56  f =      -552.72  |proj g|=        2.4468
At iterate    57  f =      -553.76  |proj g|=        2.0566
At iterate    58  f =      -556.37  |proj g|=        1.5367
At iterate    59  f =      -560.75  |proj g|=       0.77404
At iterate    60  f =      -568.21  |proj g|=       0.64231
At iterate    61  f =      -571.69  |proj g|=       0.55954
At iterate    62  f =      -573.51  |proj g|=       0.42042
At iterate    63  f =      -573.53  |proj g|=       0.55416
At iterate    64  f =      -573.55  |proj g|=       0.56038
At iterate    65  f =      -573.55  |proj g|=       0.25767
At iterate    66  f =      -573.55  |proj g|=     0.0013439
At iterate    67  f =      -573.55  |proj g|=     0.0013435

iterations 67
function evaluations 75
segments explored during Cauchy searches 69
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00134349
final function value -573.549

F = -573.549
final  value -573.548622 
converged
 
INFO  [08:22:00.088] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:22:00.179] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:22:00.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:22:04.793] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:22:09.387] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:22:14.718] [mlr3]  Finished benchmark 
INFO  [08:22:14.832] [bbotk] Result of batch 105: 
INFO  [08:22:14.834] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:22:14.834] [bbotk]              8.724073                 7.855664                       0.0898389 
INFO  [08:22:14.834] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:22:14.834] [bbotk]                     2020        0.751 -0.9496402         <NA>   0.9690159 
INFO  [08:22:14.834] [bbotk]                                 uhash 
INFO  [08:22:14.834] [bbotk]  cca57980-e445-433a-9fe1-4c37284bd3db 
DEBUG [08:22:16.187] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.76472e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.76472e-05 0.002143655 
  - best initial criterion value(s) :  542.9167 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -542.92  |proj g|=       5.2085
At iterate     1  f =      -555.84  |proj g|=        2.9542
At iterate     2  f =      -556.36  |proj g|=        2.9384
At iterate     3  f =      -556.77  |proj g|=        2.8849
At iterate     4  f =      -556.83  |proj g|=        2.9061
At iterate     5  f =      -557.11  |proj g|=        2.9585
At iterate     6  f =      -557.45  |proj g|=        3.1008
At iterate     7  f =       -557.5  |proj g|=        3.1577
At iterate     8  f =       -557.5  |proj g|=        3.1709
At iterate     9  f =       -557.5  |proj g|=        3.1722
At iterate    10  f =       -557.5  |proj g|=        3.1734
At iterate    11  f =       -557.5  |proj g|=        3.1759
At iterate    12  f =       -557.5  |proj g|=        3.1802
At iterate    13  f =       -557.5  |proj g|=        3.1872
At iterate    14  f =      -557.51  |proj g|=        3.1994
At iterate    15  f =      -557.52  |proj g|=        3.2164
At iterate    16  f =      -557.52  |proj g|=        3.2291
At iterate    17  f =      -557.55  |proj g|=        3.2468
At iterate    18  f =      -557.68  |proj g|=        3.2891
At iterate    19  f =      -558.18  |proj g|=        3.3365
At iterate    20  f =      -560.05  |proj g|=        3.3248
At iterate    21  f =      -564.02  |proj g|=        3.0151
At iterate    22  f =      -566.81  |proj g|=        2.3927
At iterate    23  f =      -567.42  |proj g|=        2.3955
At iterate    24  f =      -568.08  |proj g|=        2.3133
At iterate    25  f =      -568.58  |proj g|=        2.1477
At iterate    26  f =      -568.75  |proj g|=        2.2125
At iterate    27  f =      -568.76  |proj g|=        2.1957
At iterate    28  f =      -568.76  |proj g|=        2.1913
At iterate    29  f =      -568.76  |proj g|=        2.1919
At iterate    30  f =      -568.76  |proj g|=         2.192
At iterate    31  f =      -568.76  |proj g|=        2.1922
At iterate    32  f =      -568.76  |proj g|=        2.1926
At iterate    33  f =      -568.76  |proj g|=        2.1926

iterations 33
function evaluations 40
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.19258
final function value -568.764

F = -568.764
final  value -568.764471 
converged
 
INFO  [08:22:16.191] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:22:16.278] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:22:16.285] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:22:17.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:22:19.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:22:20.893] [mlr3]  Finished benchmark 
INFO  [08:22:20.991] [bbotk] Result of batch 106: 
INFO  [08:22:20.993] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:22:20.993] [bbotk]              7.494112                  5.21626                      0.09001407 
INFO  [08:22:20.993] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:22:20.993] [bbotk]                      509        0.911 -0.9589503         <NA>   0.9521699 
INFO  [08:22:20.993] [bbotk]                                 uhash 
INFO  [08:22:20.993] [bbotk]  5939cde8-5e90-4e22-b6ee-0d850885cc1b 
DEBUG [08:22:22.175] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.767273e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.767273e-05 0.002148326 
  - best initial criterion value(s) :  544.4136 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -544.41  |proj g|=       3.1893
At iterate     1  f =      -552.15  |proj g|=        2.8981
At iterate     2  f =      -557.16  |proj g|=         3.183
At iterate     3  f =      -557.78  |proj g|=        3.2871
At iterate     4  f =         -558  |proj g|=        3.5063
At iterate     5  f =      -558.04  |proj g|=        3.6252
At iterate     6  f =      -558.04  |proj g|=        3.7038
At iterate     7  f =      -558.05  |proj g|=        3.7323
At iterate     8  f =      -558.05  |proj g|=        3.7338
At iterate     9  f =      -558.05  |proj g|=        3.7362
At iterate    10  f =      -558.05  |proj g|=        3.7395
At iterate    11  f =      -558.05  |proj g|=        3.7484
At iterate    12  f =      -558.05  |proj g|=        3.7598
At iterate    13  f =      -558.05  |proj g|=        3.7794
At iterate    14  f =      -558.05  |proj g|=        3.8093
At iterate    15  f =      -558.06  |proj g|=        3.8494
At iterate    16  f =      -558.08  |proj g|=        3.8918
At iterate    17  f =      -558.12  |proj g|=         3.962
At iterate    18  f =      -558.22  |proj g|=        3.9606
At iterate    19  f =      -558.28  |proj g|=        4.1929
At iterate    20  f =      -558.49  |proj g|=        4.1112
At iterate    21  f =      -559.33  |proj g|=         3.798
At iterate    22  f =      -560.95  |proj g|=        3.2417
At iterate    23  f =       -564.7  |proj g|=        2.2559
At iterate    24  f =      -571.81  |proj g|=        1.0566
At iterate    25  f =      -574.91  |proj g|=       0.52164
At iterate    26  f =      -578.76  |proj g|=       0.76418
At iterate    27  f =      -582.93  |proj g|=       0.90863
At iterate    28  f =      -583.25  |proj g|=       0.90868
At iterate    29  f =      -583.32  |proj g|=        0.8598
At iterate    30  f =      -583.32  |proj g|=       0.86985
At iterate    31  f =      -583.32  |proj g|=         0.861
At iterate    32  f =      -583.32  |proj g|=       0.86138
At iterate    33  f =      -583.32  |proj g|=       0.86148

iterations 33
function evaluations 41
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.86148
final function value -583.32

F = -583.32
final  value -583.319836 
converged
 
INFO  [08:22:22.179] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:22:22.285] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:22:22.291] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:22:36.100] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:22:47.860] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:23:02.144] [mlr3]  Finished benchmark 
INFO  [08:23:02.263] [bbotk] Result of batch 107: 
INFO  [08:23:02.264] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:23:02.264] [bbotk]              9.711815                 8.833421                       0.2245312 
INFO  [08:23:02.264] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:23:02.264] [bbotk]                     4644        0.744 -0.9548203         <NA>   0.9773443 
INFO  [08:23:02.264] [bbotk]                                 uhash 
INFO  [08:23:02.264] [bbotk]  9747db82-cfe8-47f7-bd98-e5151c9f6958 
DEBUG [08:23:03.401] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.762662e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.762662e-05 0.002150222 
  - best initial criterion value(s) :  531.8525 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -531.85  |proj g|=       2.1945
At iterate     1  f =       -546.8  |proj g|=         2.595
At iterate     2  f =      -556.18  |proj g|=        3.6734
At iterate     3  f =      -561.46  |proj g|=        3.7744
At iterate     4  f =      -568.57  |proj g|=        3.1975
At iterate     5  f =      -570.03  |proj g|=         2.946
At iterate     6  f =      -570.49  |proj g|=        2.8652
At iterate     7  f =      -570.52  |proj g|=        2.9389
At iterate     8  f =      -570.53  |proj g|=        2.9228
At iterate     9  f =      -570.53  |proj g|=        2.9232
At iterate    10  f =      -570.53  |proj g|=        2.9237
At iterate    11  f =      -570.53  |proj g|=        2.9243
At iterate    12  f =      -570.53  |proj g|=         2.926
At iterate    13  f =      -570.53  |proj g|=        2.9281
At iterate    14  f =      -570.53  |proj g|=        2.9319
At iterate    15  f =      -570.53  |proj g|=        2.9368
At iterate    16  f =      -570.54  |proj g|=        2.9449
At iterate    17  f =      -570.55  |proj g|=        2.9511
At iterate    18  f =      -570.55  |proj g|=        2.9704
At iterate    19  f =      -570.58  |proj g|=        2.9689
At iterate    20  f =      -572.72  |proj g|=        2.5648
At iterate    21  f =      -575.72  |proj g|=        2.9618
At iterate    22  f =      -575.88  |proj g|=        2.8239
At iterate    23  f =      -575.89  |proj g|=        2.9418
At iterate    24  f =      -575.89  |proj g|=        2.9198
At iterate    25  f =      -575.89  |proj g|=         2.919

iterations 25
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.91904
final function value -575.887

F = -575.887
final  value -575.886869 
converged
 
INFO  [08:23:03.405] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:23:03.491] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:23:03.498] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:23:07.517] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:23:11.050] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:23:15.308] [mlr3]  Finished benchmark 
INFO  [08:23:15.408] [bbotk] Result of batch 108: 
INFO  [08:23:15.410] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:23:15.410] [bbotk]              2.626361                 8.313686                       0.3071141 
INFO  [08:23:15.410] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:23:15.410] [bbotk]                     1700         0.75 -0.9585596         <NA>    0.963853 
INFO  [08:23:15.410] [bbotk]                                 uhash 
INFO  [08:23:15.410] [bbotk]  f5e77f4b-89f7-4711-ba3f-cacf2b1e0efb 
DEBUG [08:23:16.818] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.750483e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.750483e-05 0.002129425 
  - best initial criterion value(s) :  520.4589 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -520.46  |proj g|=       4.8596
At iterate     1  f =      -525.06  |proj g|=        6.6412
At iterate     2  f =      -554.71  |proj g|=        4.6359
At iterate     3  f =      -564.05  |proj g|=        4.2516
At iterate     4  f =       -564.8  |proj g|=        4.1472
At iterate     5  f =      -564.83  |proj g|=        4.1168
At iterate     6  f =      -564.87  |proj g|=        4.0954
At iterate     7  f =         -565  |proj g|=        3.9736
At iterate     8  f =      -565.01  |proj g|=        3.9702
At iterate     9  f =      -565.01  |proj g|=        3.9723
At iterate    10  f =      -565.01  |proj g|=        3.9727
At iterate    11  f =      -565.01  |proj g|=         3.974
At iterate    12  f =      -565.01  |proj g|=         3.977
At iterate    13  f =      -565.02  |proj g|=        3.9838
At iterate    14  f =      -565.02  |proj g|=        3.9996
At iterate    15  f =      -565.04  |proj g|=        4.0326
At iterate    16  f =      -565.07  |proj g|=        4.0925
At iterate    17  f =      -565.14  |proj g|=        4.1738
At iterate    18  f =       -565.2  |proj g|=        4.1317
At iterate    19  f =      -565.21  |proj g|=        4.1976
At iterate    20  f =      -565.21  |proj g|=        4.1942
At iterate    21  f =      -565.21  |proj g|=        4.1966
At iterate    22  f =      -565.21  |proj g|=        4.1969
At iterate    23  f =      -565.21  |proj g|=        4.1988
At iterate    24  f =      -565.21  |proj g|=        4.2017
At iterate    25  f =      -565.21  |proj g|=        4.2076
At iterate    26  f =      -565.21  |proj g|=        4.2167
At iterate    27  f =      -565.22  |proj g|=        4.2278
At iterate    28  f =      -565.22  |proj g|=        4.2418
At iterate    29  f =      -565.23  |proj g|=        4.2665
At iterate    30  f =      -565.26  |proj g|=        4.2743
At iterate    31  f =      -565.26  |proj g|=        4.2772
At iterate    32  f =      -565.29  |proj g|=        4.2542
At iterate    33  f =      -565.31  |proj g|=        4.1557
At iterate    34  f =      -565.31  |proj g|=        4.1512
At iterate    35  f =      -565.31  |proj g|=        4.1513
At iterate    36  f =      -565.31  |proj g|=        4.1514
At iterate    37  f =      -565.31  |proj g|=        4.1517
At iterate    38  f =      -565.31  |proj g|=         4.151
At iterate    39  f =      -565.31  |proj g|=        4.1505
At iterate    40  f =      -565.31  |proj g|=        4.1464
At iterate    41  f =      -565.31  |proj g|=        4.1417
At iterate    42  f =      -565.31  |proj g|=        4.1337
At iterate    43  f =      -565.31  |proj g|=        4.1208
At iterate    44  f =      -565.32  |proj g|=        4.0953
At iterate    45  f =      -565.32  |proj g|=        4.0875
At iterate    46  f =      -565.33  |proj g|=        4.0557
At iterate    47  f =      -565.34  |proj g|=        4.0561
At iterate    48  f =      -565.36  |proj g|=        3.9979
At iterate    49  f =       -586.3  |proj g|=       0.95407
At iterate    50  f =      -588.59  |proj g|=        0.3205
At iterate    51  f =      -588.84  |proj g|=       0.66523
At iterate    52  f =       -588.9  |proj g|=       0.65857
At iterate    53  f =      -588.92  |proj g|=      0.088076
At iterate    54  f =      -588.92  |proj g|=       0.11055
At iterate    55  f =      -588.92  |proj g|=      0.087445
At iterate    56  f =      -588.92  |proj g|=       0.12452
At iterate    57  f =      -588.92  |proj g|=      0.011587
At iterate    58  f =      -588.92  |proj g|=      0.011588

iterations 58
function evaluations 72
segments explored during Cauchy searches 61
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0115882
final function value -588.921

F = -588.921
final  value -588.920535 
converged
 
INFO  [08:23:16.822] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:23:16.929] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:23:16.935] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:23:22.591] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:23:27.989] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:23:32.648] [mlr3]  Finished benchmark 
INFO  [08:23:32.747] [bbotk] Result of batch 109: 
INFO  [08:23:32.749] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:23:32.749] [bbotk]              5.651706                 7.141582                       0.3085188 
INFO  [08:23:32.749] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:23:32.749] [bbotk]                     2460        0.778 -0.9561265         <NA>   0.9758326 
INFO  [08:23:32.749] [bbotk]                                 uhash 
INFO  [08:23:32.749] [bbotk]  9d451b92-13f6-4483-99ea-13c2cb347cc7 
DEBUG [08:23:33.822] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.74384e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.74384e-05 0.002126088 
  - best initial criterion value(s) :  531.5311 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -531.53  |proj g|=       2.5251
At iterate     1  f =      -542.29  |proj g|=        3.3431
At iterate     2  f =      -544.57  |proj g|=          3.25
At iterate     3  f =         -548  |proj g|=        2.9369
At iterate     4  f =      -549.21  |proj g|=        2.6807
At iterate     5  f =      -552.06  |proj g|=        2.6523
At iterate     6  f =      -554.94  |proj g|=        2.6164
At iterate     7  f =      -554.97  |proj g|=        2.5882
At iterate     8  f =      -554.97  |proj g|=         2.596
At iterate     9  f =      -554.97  |proj g|=        2.5925
At iterate    10  f =      -554.97  |proj g|=        2.5924

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.59239
final function value -554.974

F = -554.974
final  value -554.974452 
converged
 
INFO  [08:23:33.826] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:23:33.911] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:23:33.918] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:23:37.806] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:23:42.152] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:23:46.235] [mlr3]  Finished benchmark 
INFO  [08:23:46.336] [bbotk] Result of batch 110: 
INFO  [08:23:46.338] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:23:46.338] [bbotk]              7.046372                 2.879808                       0.4794665 
INFO  [08:23:46.338] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:23:46.338] [bbotk]                     2016        0.765 -0.9628906         <NA>   0.9770828 
INFO  [08:23:46.338] [bbotk]                                 uhash 
INFO  [08:23:46.338] [bbotk]  a7656483-9d29-43d8-9be6-e2da18c06092 
DEBUG [08:23:47.791] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.738925e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.738925e-05 0.002112851 
  - best initial criterion value(s) :  504.1002 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -504.1  |proj g|=       2.9599
At iterate     1  f =      -506.95  |proj g|=        13.569
At iterate     2  f =      -519.04  |proj g|=        13.372
At iterate     3  f =      -535.54  |proj g|=        10.098
At iterate     4  f =      -538.52  |proj g|=        5.3156
At iterate     5  f =      -544.04  |proj g|=        3.0637
At iterate     6  f =       -557.1  |proj g|=       0.74472
At iterate     7  f =      -563.38  |proj g|=       0.69413
At iterate     8  f =      -569.88  |proj g|=       0.64159
At iterate     9  f =      -573.72  |proj g|=       0.58127
At iterate    10  f =      -574.16  |proj g|=         1.462
At iterate    11  f =      -576.06  |proj g|=         1.608
At iterate    12  f =      -576.23  |proj g|=        1.2232
At iterate    13  f =      -576.23  |proj g|=        1.1479
At iterate    14  f =      -576.23  |proj g|=        1.1416
At iterate    15  f =      -576.23  |proj g|=        1.1322
At iterate    16  f =      -576.24  |proj g|=        1.1081
At iterate    17  f =      -576.24  |proj g|=        1.0746
At iterate    18  f =      -576.25  |proj g|=        1.0167
At iterate    19  f =      -576.28  |proj g|=       0.92558
At iterate    20  f =      -576.36  |proj g|=       0.78205
At iterate    21  f =      -576.55  |proj g|=       0.56755
At iterate    22  f =      -577.09  |proj g|=       0.45695
At iterate    23  f =       -578.9  |proj g|=       0.43227
At iterate    24  f =      -581.05  |proj g|=        0.3949
At iterate    25  f =      -582.21  |proj g|=       0.37545
At iterate    26  f =      -583.19  |proj g|=       0.34051
At iterate    27  f =      -583.21  |proj g|=       0.54725
At iterate    28  f =      -583.21  |proj g|=       0.31957
At iterate    29  f =       -583.5  |proj g|=        0.6515
At iterate    30  f =      -583.82  |proj g|=       0.65157
At iterate    31  f =      -583.83  |proj g|=        0.1015
At iterate    32  f =      -583.83  |proj g|=     0.0063959
At iterate    33  f =      -583.83  |proj g|=     0.0063959

iterations 33
function evaluations 48
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 3
norm of the final projected gradient 0.00639592
final function value -583.832

F = -583.832
final  value -583.831940 
converged
 
INFO  [08:23:47.795] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:23:47.911] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:23:47.919] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:23:54.502] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:24:00.795] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:24:07.309] [mlr3]  Finished benchmark 
INFO  [08:24:07.422] [bbotk] Result of batch 111: 
INFO  [08:24:07.424] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:24:07.424] [bbotk]              4.690478                 4.706498                       0.2010609 
INFO  [08:24:07.424] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:24:07.424] [bbotk]                     3996         0.95 -0.9393235         <NA>   0.9754195 
INFO  [08:24:07.424] [bbotk]                                 uhash 
INFO  [08:24:07.424] [bbotk]  44b3ed55-5e2d-4277-afff-68a8396867ce 
DEBUG [08:24:08.653] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.731771e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.731771e-05 0.002110828 
  - best initial criterion value(s) :  560.706 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -560.71  |proj g|=       9.3628
At iterate     1  f =      -568.09  |proj g|=        8.5152
At iterate     2  f =      -570.11  |proj g|=        6.2236
At iterate     3  f =      -571.57  |proj g|=        3.2479
At iterate     4  f =      -571.64  |proj g|=        2.8149
At iterate     5  f =      -571.65  |proj g|=        2.7391
At iterate     6  f =      -571.65  |proj g|=        2.7516
At iterate     7  f =      -571.65  |proj g|=        2.7604
At iterate     8  f =      -571.65  |proj g|=        2.7712
At iterate     9  f =      -571.65  |proj g|=        2.7893
At iterate    10  f =      -571.66  |proj g|=        2.8144
At iterate    11  f =      -571.66  |proj g|=        2.8443
At iterate    12  f =      -571.69  |proj g|=        2.8596
At iterate    13  f =      -571.73  |proj g|=        2.8052
At iterate    14  f =      -571.83  |proj g|=        2.6804
At iterate    15  f =      -572.02  |proj g|=        2.5577
At iterate    16  f =      -572.36  |proj g|=        1.9494
At iterate    17  f =      -572.79  |proj g|=        2.0375
At iterate    18  f =      -574.48  |proj g|=         2.242
At iterate    19  f =       -578.6  |proj g|=        1.9362
At iterate    20  f =      -587.88  |proj g|=        1.3245
At iterate    21  f =      -597.86  |proj g|=        1.3236
At iterate    22  f =      -601.69  |proj g|=        1.3226
At iterate    23  f =      -601.84  |proj g|=        1.3224
At iterate    24  f =      -602.66  |proj g|=        1.3218
At iterate    25  f =       -602.8  |proj g|=        1.3214
At iterate    26  f =      -602.81  |proj g|=        1.3207
At iterate    27  f =      -602.81  |proj g|=        1.3204
At iterate    28  f =      -602.81  |proj g|=        1.3203
At iterate    29  f =      -602.81  |proj g|=        1.3192
At iterate    30  f =      -602.81  |proj g|=        1.3186
At iterate    31  f =      -602.81  |proj g|=        1.3172
At iterate    32  f =      -602.83  |proj g|=         1.303
At iterate    33  f =      -602.87  |proj g|=        1.2719
At iterate    34  f =      -603.03  |proj g|=        1.1556
At iterate    35  f =      -603.39  |proj g|=       0.92815
At iterate    36  f =      -604.79  |proj g|=       0.50256
At iterate    37  f =      -605.24  |proj g|=       0.48744
At iterate    38  f =      -605.69  |proj g|=       0.53168
At iterate    39  f =      -605.76  |proj g|=       0.54887
At iterate    40  f =      -605.76  |proj g|=      0.069274
At iterate    41  f =      -605.76  |proj g|=     0.0031269
At iterate    42  f =      -605.76  |proj g|=     0.0031268

iterations 42
function evaluations 47
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00312683
final function value -605.759

F = -605.759
final  value -605.758560 
converged
 
INFO  [08:24:08.658] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:24:08.747] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:24:08.754] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:24:15.627] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:24:22.759] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:24:29.838] [mlr3]  Finished benchmark 
INFO  [08:24:29.944] [bbotk] Result of batch 112: 
INFO  [08:24:29.946] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:24:29.946] [bbotk]              4.254423                 6.181935                       0.1110323 
INFO  [08:24:29.946] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:24:29.946] [bbotk]                     4383        0.745 -0.9467764         <NA>   0.9725821 
INFO  [08:24:29.946] [bbotk]                                 uhash 
INFO  [08:24:29.946] [bbotk]  45e7efe6-ec82-430b-bbd8-bb767897247d 
DEBUG [08:24:31.223] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.72183e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.72183e-05 0.002104273 
  - best initial criterion value(s) :  548.9491 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -548.95  |proj g|=       14.079
At iterate     1  f =      -571.56  |proj g|=        7.5346
At iterate     2  f =      -581.65  |proj g|=        7.2927
At iterate     3  f =      -585.07  |proj g|=        5.5243
At iterate     4  f =      -587.84  |proj g|=        3.5758
At iterate     5  f =       -588.4  |proj g|=        2.9912
At iterate     6  f =      -589.09  |proj g|=        3.6788
At iterate     7  f =      -589.39  |proj g|=        3.0827
At iterate     8  f =      -589.47  |proj g|=        2.9175
At iterate     9  f =       -593.2  |proj g|=        2.9831
At iterate    10  f =      -599.88  |proj g|=        3.1278
At iterate    11  f =      -602.88  |proj g|=        3.0292
At iterate    12  f =      -604.98  |proj g|=         2.822
At iterate    13  f =      -607.91  |proj g|=        2.7213
At iterate    14  f =      -608.52  |proj g|=        2.8072
At iterate    15  f =      -608.67  |proj g|=        2.8459
At iterate    16  f =      -608.68  |proj g|=        2.8323
At iterate    17  f =      -608.68  |proj g|=        2.8242
At iterate    18  f =      -608.68  |proj g|=        2.8236
At iterate    19  f =      -608.68  |proj g|=        2.8237
At iterate    20  f =      -608.68  |proj g|=        2.8238

iterations 20
function evaluations 28
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.82384
final function value -608.678

F = -608.678
final  value -608.678276 
converged
 
INFO  [08:24:31.227] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:24:31.317] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:24:31.324] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:24:35.111] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:24:38.940] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:24:42.896] [mlr3]  Finished benchmark 
INFO  [08:24:43.076] [bbotk] Result of batch 113: 
INFO  [08:24:43.079] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:24:43.079] [bbotk]              9.082396                 8.399302                       0.3314089 
INFO  [08:24:43.079] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:24:43.079] [bbotk]                     2425        0.857 -0.9521377         <NA>   0.9768761 
INFO  [08:24:43.079] [bbotk]                                 uhash 
INFO  [08:24:43.079] [bbotk]  16eb5818-0155-4603-8490-5896094f3650 
DEBUG [08:24:44.393] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.716639e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.716639e-05 0.002101014 
  - best initial criterion value(s) :  553.6343 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -553.63  |proj g|=       7.6194
At iterate     1  f =      -583.57  |proj g|=        5.4657
At iterate     2  f =      -590.07  |proj g|=        4.4588
At iterate     3  f =      -598.38  |proj g|=         2.385
At iterate     4  f =      -600.18  |proj g|=        2.2202
At iterate     5  f =       -604.9  |proj g|=        2.2962
At iterate     6  f =      -608.76  |proj g|=        2.4244
At iterate     7  f =      -609.99  |proj g|=        2.4934
At iterate     8  f =      -610.62  |proj g|=        2.5784
At iterate     9  f =      -610.86  |proj g|=        2.6569
At iterate    10  f =       -610.9  |proj g|=        2.7489
At iterate    11  f =      -610.93  |proj g|=        2.7384
At iterate    12  f =      -610.93  |proj g|=        2.7388
At iterate    13  f =      -610.93  |proj g|=        2.7419
At iterate    14  f =      -610.93  |proj g|=        2.7482
At iterate    15  f =      -610.94  |proj g|=        2.7614
At iterate    16  f =      -610.96  |proj g|=        2.7797
At iterate    17  f =      -611.02  |proj g|=        2.8119
At iterate    18  f =      -611.15  |proj g|=        2.8561
At iterate    19  f =      -611.39  |proj g|=        2.8953
At iterate    20  f =      -611.67  |proj g|=        2.8788
At iterate    21  f =      -611.94  |proj g|=         2.912
At iterate    22  f =      -612.05  |proj g|=        2.8301
At iterate    23  f =      -612.28  |proj g|=        2.9111
At iterate    24  f =       -612.3  |proj g|=        2.9104
At iterate    25  f =       -612.3  |proj g|=        2.9135
At iterate    26  f =       -612.3  |proj g|=        2.9141
At iterate    27  f =       -612.3  |proj g|=        2.9141

iterations 27
function evaluations 33
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.91414
final function value -612.299

F = -612.299
final  value -612.298665 
converged
 
INFO  [08:24:44.398] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:24:44.497] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:24:44.506] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:24:47.984] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:24:51.533] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:24:55.229] [mlr3]  Finished benchmark 
INFO  [08:24:55.350] [bbotk] Result of batch 114: 
INFO  [08:24:55.353] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:24:55.353] [bbotk]              2.045562                 8.090536                       0.2307454 
INFO  [08:24:55.353] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:24:55.353] [bbotk]                     2205        0.858 -0.9493349         <NA>   0.9584769 
INFO  [08:24:55.353] [bbotk]                                 uhash 
INFO  [08:24:55.353] [bbotk]  e529ac27-e603-4f68-86a4-b9fbe49e78c0 
DEBUG [08:24:56.698] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.709743e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9806764 9590 
  - variance bounds :  1.709743e-05 0.002089655 
  - best initial criterion value(s) :  539.9065 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -539.91  |proj g|=       7.8557
At iterate     1  f =       -544.5  |proj g|=        9.2535
At iterate     2  f =      -573.18  |proj g|=        5.1369
At iterate     3  f =      -578.87  |proj g|=        4.0609
At iterate     4  f =      -587.12  |proj g|=        3.8885
At iterate     5  f =      -587.79  |proj g|=        3.9547
At iterate     6  f =      -587.81  |proj g|=         3.984
At iterate     7  f =      -587.83  |proj g|=        3.9732
At iterate     8  f =      -587.83  |proj g|=        3.9726
At iterate     9  f =      -587.83  |proj g|=        3.9684
At iterate    10  f =      -587.84  |proj g|=        3.9638
At iterate    11  f =      -587.84  |proj g|=         3.962
At iterate    12  f =      -587.88  |proj g|=        3.9486
At iterate    13  f =      -587.94  |proj g|=        3.9354
At iterate    14  f =      -588.15  |proj g|=        3.8982
At iterate    15  f =       -588.6  |proj g|=        3.8274
At iterate    16  f =      -589.61  |proj g|=        3.6758
At iterate    17  f =      -590.94  |proj g|=        3.4732
At iterate    18  f =      -592.03  |proj g|=        3.6038
At iterate    19  f =      -592.73  |proj g|=        3.3819
At iterate    20  f =      -592.85  |proj g|=        3.2855
At iterate    21  f =      -592.88  |proj g|=        3.2554
At iterate    22  f =      -592.89  |proj g|=        3.2489
At iterate    23  f =      -592.89  |proj g|=        3.2519
At iterate    24  f =      -592.89  |proj g|=        3.2535
At iterate    25  f =      -592.89  |proj g|=        3.2541
At iterate    26  f =      -592.89  |proj g|=        3.2537
At iterate    27  f =      -592.89  |proj g|=        3.2514
At iterate    28  f =      -592.89  |proj g|=        3.2498
At iterate    29  f =      -592.89  |proj g|=        3.2498
At iterate    30  f =      -592.89  |proj g|=        3.2501
At iterate    31  f =      -592.89  |proj g|=        3.2505
At iterate    32  f =      -592.89  |proj g|=        3.2509
At iterate    33  f =      -592.89  |proj g|=        3.2513
At iterate    34  f =      -592.89  |proj g|=        3.2513

iterations 34
function evaluations 42
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.25126
final function value -592.893

F = -592.893
final  value -592.892824 
converged
 
INFO  [08:24:56.702] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:24:56.804] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:24:56.813] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:25:03.448] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:25:12.594] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:25:22.980] [mlr3]  Finished benchmark 
INFO  [08:25:23.085] [bbotk] Result of batch 115: 
INFO  [08:25:23.087] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:25:23.087] [bbotk]              6.164867                 7.182275                       0.4965897 
INFO  [08:25:23.087] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [08:25:23.087] [bbotk]                     3753        0.829 -0.959287         <NA>    0.978705 
INFO  [08:25:23.087] [bbotk]                                 uhash 
INFO  [08:25:23.087] [bbotk]  b151b490-2f95-483a-a5e4-a41a1128f1e8 
DEBUG [08:25:24.453] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.70741e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.707409e-05 0.002094158 
  - best initial criterion value(s) :  539.7989 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -539.8  |proj g|=        5.265
At iterate     1  f =      -565.17  |proj g|=        9.1685
At iterate     2  f =      -571.93  |proj g|=        6.9078
At iterate     3  f =         -576  |proj g|=         3.369
At iterate     4  f =       -577.8  |proj g|=         4.947
At iterate     5  f =      -578.07  |proj g|=        4.7405
At iterate     6  f =      -578.88  |proj g|=        4.2571
At iterate     7  f =      -580.21  |proj g|=        3.8476
At iterate     8  f =      -582.62  |proj g|=        3.5826
At iterate     9  f =      -584.23  |proj g|=        3.5032
At iterate    10  f =       -585.7  |proj g|=         3.654
At iterate    11  f =      -586.66  |proj g|=        3.6138
At iterate    12  f =       -586.7  |proj g|=        4.4837
At iterate    13  f =       -587.3  |proj g|=        4.0295
At iterate    14  f =      -587.32  |proj g|=        3.9951
At iterate    15  f =      -587.34  |proj g|=        3.9468
At iterate    16  f =      -587.38  |proj g|=        3.7574
At iterate    17  f =      -587.39  |proj g|=        3.7375
At iterate    18  f =      -587.51  |proj g|=        3.5628
At iterate    19  f =      -587.74  |proj g|=        3.3464
At iterate    20  f =       -588.4  |proj g|=        2.9498
At iterate    21  f =      -590.08  |proj g|=        2.3568
At iterate    22  f =      -594.72  |proj g|=        1.5446
At iterate    23  f =      -603.47  |proj g|=        1.2285
At iterate    24  f =      -610.12  |proj g|=        1.9869
At iterate    25  f =      -616.16  |proj g|=         3.241
At iterate    26  f =      -616.24  |proj g|=        3.2196
At iterate    27  f =       -616.3  |proj g|=        3.1459
At iterate    28  f =       -616.3  |proj g|=        3.1697
At iterate    29  f =       -616.3  |proj g|=        3.1655
At iterate    30  f =       -616.3  |proj g|=        3.1652
At iterate    31  f =       -616.3  |proj g|=        3.1654
At iterate    32  f =       -616.3  |proj g|=        3.1685
At iterate    33  f =       -616.3  |proj g|=        3.1685
At iterate    34  f =      -616.31  |proj g|=        3.1679
At iterate    35  f =      -616.31  |proj g|=        3.1698
At iterate    36  f =      -616.32  |proj g|=        3.2329
At iterate    37  f =      -616.35  |proj g|=        3.1968
At iterate    38  f =      -616.44  |proj g|=         3.133
At iterate    39  f =      -616.63  |proj g|=        3.0278
At iterate    40  f =      -617.21  |proj g|=        2.8067
At iterate    41  f =      -618.78  |proj g|=        2.4096
At iterate    42  f =      -623.51  |proj g|=       0.43656
At iterate    43  f =      -625.82  |proj g|=       0.43694
At iterate    44  f =      -627.11  |proj g|=       0.43697
At iterate    45  f =      -627.29  |proj g|=       0.43696
At iterate    46  f =       -627.3  |proj g|=       0.54441
At iterate    47  f =       -627.3  |proj g|=        0.5444
At iterate    48  f =       -627.3  |proj g|=        0.5444

iterations 48
function evaluations 55
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.544404
final function value -627.304

F = -627.304
final  value -627.303839 
converged
 
INFO  [08:25:24.457] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:25:24.577] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:25:24.588] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:25:33.060] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:25:41.751] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:25:51.097] [mlr3]  Finished benchmark 
INFO  [08:25:51.201] [bbotk] Result of batch 116: 
INFO  [08:25:51.203] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:25:51.203] [bbotk]              2.075654                 6.235984                       0.1722617 
INFO  [08:25:51.203] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:25:51.203] [bbotk]                     3641        0.797 -0.9468967         <NA>   0.9599219 
INFO  [08:25:51.203] [bbotk]                                 uhash 
INFO  [08:25:51.203] [bbotk]  d4c866d2-dd70-4317-8d1f-30b53a470866 
DEBUG [08:25:52.598] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.699157e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.699157e-05 0.002086272 
  - best initial criterion value(s) :  577.7408 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -577.74  |proj g|=       13.204
At iterate     1  f =      -604.01  |proj g|=        2.5751
At iterate     2  f =      -605.52  |proj g|=        2.6859
At iterate     3  f =      -606.95  |proj g|=        2.6798
At iterate     4  f =      -607.03  |proj g|=        2.6703
At iterate     5  f =      -607.03  |proj g|=        2.6708
At iterate     6  f =      -607.03  |proj g|=        2.6712
At iterate     7  f =      -607.03  |proj g|=        2.6716
At iterate     8  f =      -607.03  |proj g|=        2.6722
At iterate     9  f =      -607.03  |proj g|=        2.6732
At iterate    10  f =      -607.03  |proj g|=        2.6749
At iterate    11  f =      -607.04  |proj g|=        2.6774
At iterate    12  f =      -607.05  |proj g|=        2.6805
At iterate    13  f =      -607.07  |proj g|=        2.6833
At iterate    14  f =      -607.12  |proj g|=        2.6924
At iterate    15  f =      -607.22  |proj g|=        2.6967
At iterate    16  f =      -607.27  |proj g|=        2.7165
At iterate    17  f =      -607.72  |proj g|=        2.7223
At iterate    18  f =      -608.83  |proj g|=        2.7342
At iterate    19  f =      -611.53  |proj g|=        2.7513
At iterate    20  f =      -615.99  |proj g|=        2.7543
At iterate    21  f =      -618.84  |proj g|=        2.7328
At iterate    22  f =       -618.9  |proj g|=        2.7795
At iterate    23  f =      -619.82  |proj g|=        2.7427
At iterate    24  f =         -620  |proj g|=         2.736
At iterate    25  f =         -620  |proj g|=        2.7378
At iterate    26  f =      -620.03  |proj g|=         2.749
At iterate    27  f =      -620.03  |proj g|=        2.7506
At iterate    28  f =      -620.03  |proj g|=        2.7514
At iterate    29  f =      -620.03  |proj g|=        2.7513

iterations 29
function evaluations 35
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.75132
final function value -620.03

F = -620.03
final  value -620.030133 
converged
 
INFO  [08:25:52.603] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:25:53.097] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:25:53.104] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:26:01.877] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:26:09.140] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:26:16.769] [mlr3]  Finished benchmark 
INFO  [08:26:16.866] [bbotk] Result of batch 117: 
INFO  [08:26:16.868] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:26:16.868] [bbotk]               6.31477                  8.74539                       0.3193701 
INFO  [08:26:16.868] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:26:16.868] [bbotk]                     3147        0.945 -0.9571222         <NA>    0.976939 
INFO  [08:26:16.868] [bbotk]                                 uhash 
INFO  [08:26:16.868] [bbotk]  deb709fa-b799-4435-a847-f21533fb628f 
DEBUG [08:26:18.090] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.694291e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.694291e-05 0.002091672 
  - best initial criterion value(s) :  557.5877 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -557.59  |proj g|=        1.503
At iterate     1  f =      -577.66  |proj g|=        2.2861
At iterate     2  f =      -597.27  |proj g|=        5.8946
At iterate     3  f =       -602.3  |proj g|=         6.655
At iterate     4  f =      -604.86  |proj g|=        5.0523
At iterate     5  f =      -605.64  |proj g|=        3.4773
At iterate     6  f =      -605.65  |proj g|=        3.2021
At iterate     7  f =      -605.65  |proj g|=        3.2966
At iterate     8  f =      -605.65  |proj g|=        3.2926
At iterate     9  f =      -605.65  |proj g|=        3.2829
At iterate    10  f =      -605.65  |proj g|=        3.2766
At iterate    11  f =      -605.65  |proj g|=        3.2532
At iterate    12  f =      -605.66  |proj g|=        3.2234
At iterate    13  f =      -605.66  |proj g|=        3.1697
At iterate    14  f =      -605.67  |proj g|=        3.0905
At iterate    15  f =       -605.7  |proj g|=        2.9883
At iterate    16  f =      -605.76  |proj g|=        2.9101
At iterate    17  f =      -605.86  |proj g|=        2.9282
At iterate    18  f =      -605.86  |proj g|=        2.7784
At iterate    19  f =      -606.01  |proj g|=        2.7741
At iterate    20  f =      -608.18  |proj g|=        2.2415
At iterate    21  f =      -612.11  |proj g|=        2.3633
At iterate    22  f =      -613.33  |proj g|=         2.663
At iterate    23  f =      -614.03  |proj g|=        2.6072
At iterate    24  f =      -615.44  |proj g|=        2.9605
At iterate    25  f =      -615.57  |proj g|=        2.9236
At iterate    26  f =      -615.57  |proj g|=        2.9574
At iterate    27  f =      -620.01  |proj g|=        2.4945
At iterate    28  f =      -626.39  |proj g|=       0.84712
At iterate    29  f =       -628.2  |proj g|=       0.62238
At iterate    30  f =       -628.2  |proj g|=       0.35697
At iterate    31  f =       -628.2  |proj g|=     0.0056981
At iterate    32  f =       -628.2  |proj g|=      0.005698

iterations 32
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 3
norm of the final projected gradient 0.00569802
final function value -628.2

F = -628.2
final  value -628.200176 
converged
 
INFO  [08:26:18.094] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:26:18.179] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:26:18.186] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:26:19.794] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:26:21.594] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:26:23.636] [mlr3]  Finished benchmark 
INFO  [08:26:23.760] [bbotk] Result of batch 118: 
INFO  [08:26:23.762] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:26:23.762] [bbotk]              2.317373                 8.991016                      0.06391326 
INFO  [08:26:23.762] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:26:23.762] [bbotk]                      591        0.771 -0.9412288         <NA>   0.9197111 
INFO  [08:26:23.762] [bbotk]                                 uhash 
INFO  [08:26:23.762] [bbotk]  1ca200f5-5673-46ee-b7cd-ada14517c5cb 
DEBUG [08:26:24.832] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.833267e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.833267e-05 0.00228737 
  - best initial criterion value(s) :  567.6424 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -567.64  |proj g|=        1.294
At iterate     1  f =      -569.24  |proj g|=        1.4637
At iterate     2  f =      -569.39  |proj g|=        1.2446
At iterate     3  f =      -569.39  |proj g|=        1.2428
At iterate     4  f =      -569.39  |proj g|=        1.2421
At iterate     5  f =      -569.39  |proj g|=        1.2421

iterations 5
function evaluations 8
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.24208
final function value -569.394

F = -569.394
final  value -569.394204 
converged
 
INFO  [08:26:24.836] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:26:24.922] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:26:24.929] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:26:27.620] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:26:30.601] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:26:33.232] [mlr3]  Finished benchmark 
INFO  [08:26:33.334] [bbotk] Result of batch 119: 
INFO  [08:26:33.336] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:26:33.336] [bbotk]              3.470574                 9.648757                       0.3775099 
INFO  [08:26:33.336] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:26:33.336] [bbotk]                     1303        0.793 -0.9656306         <NA>   0.9703903 
INFO  [08:26:33.336] [bbotk]                                 uhash 
INFO  [08:26:33.336] [bbotk]  d62db947-b6ce-4c19-beff-73c62000e2bb 
DEBUG [08:26:34.464] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.821853e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.821853e-05 0.002262375 
  - best initial criterion value(s) :  596.1197 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -596.12  |proj g|=      0.49718
At iterate     1  f =      -600.06  |proj g|=        2.0366
At iterate     2  f =       -602.2  |proj g|=        1.6412
At iterate     3  f =      -603.98  |proj g|=        1.0422
At iterate     4  f =      -605.16  |proj g|=       0.43084
At iterate     5  f =      -607.27  |proj g|=       0.39549
At iterate     6  f =      -611.59  |proj g|=       0.90826
At iterate     7  f =      -611.77  |proj g|=       0.71556
At iterate     8  f =      -611.89  |proj g|=       0.78478
At iterate     9  f =      -611.89  |proj g|=       0.83421
At iterate    10  f =      -611.89  |proj g|=       0.81019
At iterate    11  f =      -611.89  |proj g|=       0.81047

iterations 11
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.810468
final function value -611.889

F = -611.889
final  value -611.888746 
converged
 
INFO  [08:26:34.468] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:26:34.554] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:26:34.561] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:26:35.872] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:26:37.056] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:26:38.327] [mlr3]  Finished benchmark 
INFO  [08:26:38.451] [bbotk] Result of batch 120: 
INFO  [08:26:38.453] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:26:38.453] [bbotk]              3.649643                 5.764284                       0.2659875 
INFO  [08:26:38.453] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:26:38.453] [bbotk]                      301          0.8 -0.9611186         <NA>   0.9533883 
INFO  [08:26:38.453] [bbotk]                                 uhash 
INFO  [08:26:38.453] [bbotk]  f7c65780-527b-4d27-8e5e-2ef2a431dfc0 
DEBUG [08:26:39.611] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.821549e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.821549e-05 0.002257083 
  - best initial criterion value(s) :  627.4734 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -627.47  |proj g|=       2.1189
At iterate     1  f =      -628.18  |proj g|=        2.2052
At iterate     2  f =       -630.3  |proj g|=        2.0145
At iterate     3  f =      -631.67  |proj g|=        1.7838
At iterate     4  f =      -631.81  |proj g|=        1.6738
At iterate     5  f =      -631.83  |proj g|=        1.7014
At iterate     6  f =      -631.83  |proj g|=        1.6996
At iterate     7  f =      -631.83  |proj g|=        1.6996
At iterate     8  f =      -631.83  |proj g|=        1.6997

iterations 8
function evaluations 15
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.69971
final function value -631.83

F = -631.83
final  value -631.829721 
converged
 
INFO  [08:26:39.615] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:26:39.704] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:26:39.711] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:26:48.613] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:26:58.703] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:27:08.922] [mlr3]  Finished benchmark 
INFO  [08:27:09.024] [bbotk] Result of batch 121: 
INFO  [08:27:09.026] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:27:09.026] [bbotk]              9.216591                 2.401306                       0.4636281 
INFO  [08:27:09.026] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:27:09.026] [bbotk]                     4278        0.824 -0.9599576         <NA>   0.9791612 
INFO  [08:27:09.026] [bbotk]                                 uhash 
INFO  [08:27:09.026] [bbotk]  a192b117-486f-4c45-9163-05b7e861d41c 
DEBUG [08:27:10.430] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.819748e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.819748e-05 0.002263176 
  - best initial criterion value(s) :  627.9417 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -627.94  |proj g|=       3.6526
At iterate     1  f =      -650.16  |proj g|=        3.3473
At iterate     2  f =      -651.63  |proj g|=        3.2231
At iterate     3  f =      -653.91  |proj g|=        2.9617
At iterate     4  f =       -654.3  |proj g|=        2.8999
At iterate     5  f =      -654.61  |proj g|=        3.0438
At iterate     6  f =      -654.62  |proj g|=        3.0667
At iterate     7  f =      -654.62  |proj g|=        3.0658
At iterate     8  f =      -654.62  |proj g|=        3.0657
At iterate     9  f =      -654.62  |proj g|=        3.0654
At iterate    10  f =      -654.62  |proj g|=         3.065
At iterate    11  f =      -654.62  |proj g|=        3.0644
At iterate    12  f =      -654.62  |proj g|=        3.0634
At iterate    13  f =      -654.62  |proj g|=        3.0618
At iterate    14  f =      -654.62  |proj g|=          3.06
At iterate    15  f =      -654.63  |proj g|=        3.0592
At iterate    16  f =      -654.63  |proj g|=        3.0624
At iterate    17  f =      -654.64  |proj g|=        3.0575
At iterate    18  f =      -654.66  |proj g|=        3.0607
At iterate    19  f =      -654.67  |proj g|=         3.052
At iterate    20  f =      -654.74  |proj g|=        3.0504
At iterate    21  f =      -659.11  |proj g|=        2.2962
At iterate    22  f =      -659.12  |proj g|=        2.0821
At iterate    23  f =      -659.13  |proj g|=        2.1788
At iterate    24  f =      -659.13  |proj g|=        2.1735
At iterate    25  f =      -659.13  |proj g|=        2.1732

iterations 25
function evaluations 30
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.17323
final function value -659.129

F = -659.129
final  value -659.129173 
converged
 
INFO  [08:27:10.435] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:27:10.721] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:27:10.728] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:27:18.194] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:27:24.807] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:27:31.907] [mlr3]  Finished benchmark 
INFO  [08:27:32.010] [bbotk] Result of batch 122: 
INFO  [08:27:32.012] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:27:32.012] [bbotk]              5.234483                 4.915171                       0.1677535 
INFO  [08:27:32.012] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:27:32.012] [bbotk]                     3039        0.957 -0.9569039         <NA>   0.9738731 
INFO  [08:27:32.012] [bbotk]                                 uhash 
INFO  [08:27:32.012] [bbotk]  d22bd7a1-54e6-40a1-8318-a7e3d5381d7e 
DEBUG [08:27:33.128] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.811089e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.811089e-05 0.002259759 
  - best initial criterion value(s) :  643.9943 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -643.99  |proj g|=       3.6652
At iterate     1  f =      -661.92  |proj g|=        2.6771
At iterate     2  f =      -666.51  |proj g|=        1.6735
At iterate     3  f =      -667.18  |proj g|=        1.2739
At iterate     4  f =      -667.43  |proj g|=       0.94793
At iterate     5  f =      -667.44  |proj g|=       0.95283
At iterate     6  f =      -667.44  |proj g|=       0.94777
At iterate     7  f =      -667.44  |proj g|=        0.9486

iterations 7
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.948598
final function value -667.436

F = -667.436
final  value -667.436114 
converged
 
INFO  [08:27:33.132] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:27:33.249] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:27:33.256] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:27:37.785] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:27:42.039] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:27:46.009] [mlr3]  Finished benchmark 
INFO  [08:27:46.111] [bbotk] Result of batch 123: 
INFO  [08:27:46.113] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:27:46.113] [bbotk]              9.304431                 5.792165                        0.376363 
INFO  [08:27:46.113] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:27:46.113] [bbotk]                     1946        0.802 -0.9544544         <NA>    0.976583 
INFO  [08:27:46.113] [bbotk]                                 uhash 
INFO  [08:27:46.113] [bbotk]  a00dccdc-39ab-4509-9347-e752bc9fd416 
DEBUG [08:27:47.254] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.805466e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.805466e-05 0.002249626 
  - best initial criterion value(s) :  644.3017 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -644.3  |proj g|=      0.84349
At iterate     1  f =      -662.83  |proj g|=       0.74266
At iterate     2  f =      -667.61  |proj g|=        2.7721
At iterate     3  f =      -668.21  |proj g|=        2.5285
At iterate     4  f =      -668.57  |proj g|=        1.8375
At iterate     5  f =      -668.63  |proj g|=        2.0733
At iterate     6  f =      -668.63  |proj g|=        2.0309
At iterate     7  f =      -668.63  |proj g|=         2.021
At iterate     8  f =      -668.63  |proj g|=        2.0174
At iterate     9  f =      -668.63  |proj g|=        2.0182
At iterate    10  f =      -668.63  |proj g|=        2.0191
At iterate    11  f =      -668.63  |proj g|=        2.0193

iterations 11
function evaluations 14
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.01925
final function value -668.63

F = -668.63
final  value -668.630324 
converged
 
INFO  [08:27:47.258] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:27:47.378] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:27:47.386] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:27:52.724] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:27:56.842] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:28:04.106] [mlr3]  Finished benchmark 
INFO  [08:28:04.249] [bbotk] Result of batch 124: 
INFO  [08:28:04.251] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:28:04.251] [bbotk]              9.866466                 4.400691                       0.2892199 
INFO  [08:28:04.251] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:28:04.251] [bbotk]                     2142        0.828 -0.9575336         <NA>   0.9761449 
INFO  [08:28:04.251] [bbotk]                                 uhash 
INFO  [08:28:04.251] [bbotk]  dc11678c-3a27-49e8-a4c3-6b9cb5dc343f 
DEBUG [08:28:05.391] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.799299e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.799299e-05 0.002246021 
  - best initial criterion value(s) :  634.5146 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -634.51  |proj g|=       5.8835
At iterate     1  f =      -646.86  |proj g|=        1.6872
At iterate     2  f =      -650.97  |proj g|=        1.6756
At iterate     3  f =      -651.24  |proj g|=        1.6518
At iterate     4  f =      -651.45  |proj g|=        1.6196
At iterate     5  f =      -651.47  |proj g|=        1.6076
At iterate     6  f =      -651.47  |proj g|=        1.6063
At iterate     7  f =      -651.47  |proj g|=        1.6063

iterations 7
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.60626
final function value -651.467

F = -651.467
final  value -651.467382 
converged
 
INFO  [08:28:05.395] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:28:05.486] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:28:05.493] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:28:16.104] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:28:27.353] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:28:37.856] [mlr3]  Finished benchmark 
INFO  [08:28:37.960] [bbotk] Result of batch 125: 
INFO  [08:28:37.962] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:28:37.962] [bbotk]              9.517024                 7.626327                       0.1060694 
INFO  [08:28:37.962] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:28:37.962] [bbotk]                     4725        0.822 -0.9584069         <NA>   0.9753502 
INFO  [08:28:37.962] [bbotk]                                 uhash 
INFO  [08:28:37.962] [bbotk]  d7fa73d8-6415-4321-b645-7232d4d5de33 
DEBUG [08:28:39.154] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.792243e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.792243e-05 0.002236401 
  - best initial criterion value(s) :  624.1943 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -624.19  |proj g|=       3.5822
At iterate     1  f =      -637.46  |proj g|=        4.9923
At iterate     2  f =      -645.73  |proj g|=        5.2865
At iterate     3  f =      -655.08  |proj g|=         5.458
At iterate     4  f =      -658.35  |proj g|=        5.2524
At iterate     5  f =      -666.78  |proj g|=        3.9518
At iterate     6  f =      -668.65  |proj g|=        1.8678
At iterate     7  f =      -671.58  |proj g|=        2.3192
At iterate     8  f =      -671.67  |proj g|=        2.0837
At iterate     9  f =      -671.68  |proj g|=        2.1653
At iterate    10  f =      -671.69  |proj g|=        2.1175
At iterate    11  f =      -671.69  |proj g|=        2.1114
At iterate    12  f =      -671.69  |proj g|=        2.1121

iterations 12
function evaluations 17
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.11211
final function value -671.689

F = -671.689
final  value -671.689019 
converged
 
INFO  [08:28:39.158] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:28:39.283] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:28:39.290] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:28:44.751] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:28:50.869] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:28:57.553] [mlr3]  Finished benchmark 
INFO  [08:28:57.706] [bbotk] Result of batch 126: 
INFO  [08:28:57.708] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:28:57.708] [bbotk]              2.880864                 8.956167                       0.2477746 
INFO  [08:28:57.708] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [08:28:57.708] [bbotk]                     2681        0.813 -0.954446         <NA>   0.9682928 
INFO  [08:28:57.708] [bbotk]                                 uhash 
INFO  [08:28:57.708] [bbotk]  05cabc5c-3c41-44e7-b142-fac74beb61e8 
DEBUG [08:28:59.289] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.780864e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.780864e-05 0.002225952 
  - best initial criterion value(s) :  617.8141 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -617.81  |proj g|=       4.7404
At iterate     1  f =      -618.65  |proj g|=        5.5819
At iterate     2  f =      -639.32  |proj g|=        5.6512
At iterate     3  f =      -640.88  |proj g|=        5.7521
At iterate     4  f =      -652.32  |proj g|=        4.2763
At iterate     5  f =      -652.67  |proj g|=        4.1495
At iterate     6  f =      -652.67  |proj g|=         4.138
At iterate     7  f =      -652.67  |proj g|=        4.1359
At iterate     8  f =      -652.67  |proj g|=        4.1362
At iterate     9  f =      -652.67  |proj g|=        4.1363
At iterate    10  f =      -652.67  |proj g|=        4.1365
At iterate    11  f =      -652.67  |proj g|=         4.137
At iterate    12  f =      -652.67  |proj g|=        4.1376
At iterate    13  f =      -652.67  |proj g|=        4.1386
At iterate    14  f =      -652.68  |proj g|=        4.1407
At iterate    15  f =      -652.68  |proj g|=        4.1454
At iterate    16  f =      -652.68  |proj g|=         4.154
At iterate    17  f =       -652.7  |proj g|=        4.1639
At iterate    18  f =      -652.73  |proj g|=        4.1866
At iterate    19  f =      -652.74  |proj g|=        4.1782
At iterate    20  f =      -652.81  |proj g|=        4.1868
At iterate    21  f =      -653.19  |proj g|=        4.1621
At iterate    22  f =      -653.96  |proj g|=        4.0123
At iterate    23  f =      -655.61  |proj g|=        3.5641
At iterate    24  f =      -657.58  |proj g|=        3.5787
At iterate    25  f =      -658.05  |proj g|=        3.5894
At iterate    26  f =      -659.79  |proj g|=        4.6468
At iterate    27  f =      -661.41  |proj g|=        5.1244
At iterate    28  f =      -661.57  |proj g|=        4.5459
At iterate    29  f =      -661.66  |proj g|=        4.6692
At iterate    30  f =      -661.67  |proj g|=        4.6856
At iterate    31  f =      -661.67  |proj g|=        4.6846
At iterate    32  f =      -661.67  |proj g|=        4.6773
At iterate    33  f =      -661.67  |proj g|=        4.6781

iterations 33
function evaluations 47
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.67815
final function value -661.674

F = -661.674
final  value -661.674435 
converged
 
INFO  [08:28:59.294] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:28:59.386] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:28:59.393] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:29:07.333] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:29:14.641] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:29:22.765] [mlr3]  Finished benchmark 
INFO  [08:29:23.277] [bbotk] Result of batch 127: 
INFO  [08:29:23.279] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:29:23.279] [bbotk]               2.83874                 6.979309                       0.3230337 
INFO  [08:29:23.279] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:29:23.279] [bbotk]                     2885        0.988 -0.9620006         <NA>   0.9697311 
INFO  [08:29:23.279] [bbotk]                                 uhash 
INFO  [08:29:23.279] [bbotk]  dbdee0ae-f89d-4556-ba83-a6f8e3b880a7 
DEBUG [08:29:24.525] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.769998e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.769998e-05 0.002221539 
  - best initial criterion value(s) :  623.7925 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -623.79  |proj g|=       14.087
At iterate     1  f =      -665.29  |proj g|=        6.1651
At iterate     2  f =      -674.28  |proj g|=        6.8547
At iterate     3  f =      -677.89  |proj g|=        5.1152
At iterate     4  f =       -680.1  |proj g|=        3.5676
At iterate     5  f =      -680.53  |proj g|=        3.1591
At iterate     6  f =       -681.4  |proj g|=        3.2801
At iterate     7  f =      -681.94  |proj g|=        3.3618
At iterate     8  f =      -682.27  |proj g|=        3.0984
At iterate     9  f =      -682.58  |proj g|=        2.8924
At iterate    10  f =      -683.21  |proj g|=        2.7976
At iterate    11  f =      -684.05  |proj g|=        2.1904
At iterate    12  f =      -685.14  |proj g|=        1.8707
At iterate    13  f =      -685.49  |proj g|=       0.70847
At iterate    14  f =      -689.82  |proj g|=       0.66446
At iterate    15  f =      -693.71  |proj g|=       0.57281
At iterate    16  f =      -697.18  |proj g|=       0.58132
At iterate    17  f =      -698.69  |proj g|=       0.58507
At iterate    18  f =      -698.72  |proj g|=       0.42155
At iterate    19  f =      -698.75  |proj g|=       0.41052
At iterate    20  f =      -698.75  |proj g|=       0.57128
At iterate    21  f =      -698.75  |proj g|=      0.016136
At iterate    22  f =      -698.75  |proj g|=      0.015911

iterations 22
function evaluations 25
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0159112
final function value -698.752

F = -698.752
final  value -698.751882 
converged
 
INFO  [08:29:24.529] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:29:24.614] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:29:24.621] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:29:32.002] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:29:37.763] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:29:44.743] [mlr3]  Finished benchmark 
INFO  [08:29:44.843] [bbotk] Result of batch 128: 
INFO  [08:29:44.845] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:29:44.845] [bbotk]              5.046705                 5.257964                        0.173083 
INFO  [08:29:44.845] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:29:44.845] [bbotk]                     2987        0.819 -0.9498995         <NA>   0.9737988 
INFO  [08:29:44.845] [bbotk]                                 uhash 
INFO  [08:29:44.845] [bbotk]  04a81d5f-5a7d-4d84-b7ac-e2789bbfcfeb 
DEBUG [08:29:46.375] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.761699e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.761699e-05 0.002222148 
  - best initial criterion value(s) :  630.0746 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -630.07  |proj g|=       7.7481
At iterate     1  f =      -662.99  |proj g|=         7.527
At iterate     2  f =      -692.19  |proj g|=        2.7207
At iterate     3  f =      -692.43  |proj g|=        2.3742
At iterate     4  f =      -692.66  |proj g|=        2.4272
At iterate     5  f =      -693.19  |proj g|=        2.5018
At iterate     6  f =       -693.9  |proj g|=        2.5484
At iterate     7  f =      -694.23  |proj g|=        2.5411
At iterate     8  f =      -694.25  |proj g|=        2.5392
At iterate     9  f =      -694.25  |proj g|=         2.539
At iterate    10  f =      -694.25  |proj g|=        2.5387
At iterate    11  f =      -694.25  |proj g|=        2.5387
At iterate    12  f =      -694.25  |proj g|=        2.5382
At iterate    13  f =      -694.26  |proj g|=        2.5375
At iterate    14  f =      -694.28  |proj g|=         2.536
At iterate    15  f =      -694.33  |proj g|=        2.5336
At iterate    16  f =      -694.45  |proj g|=        2.5294
At iterate    17  f =      -694.72  |proj g|=        2.5217
At iterate    18  f =      -694.84  |proj g|=        2.5159
At iterate    19  f =      -695.38  |proj g|=         2.506
At iterate    20  f =      -696.55  |proj g|=        2.4888
At iterate    21  f =      -698.13  |proj g|=        2.4678
At iterate    22  f =      -698.96  |proj g|=        2.4569
At iterate    23  f =      -699.15  |proj g|=         2.462
At iterate    24  f =      -699.22  |proj g|=        2.4728
At iterate    25  f =      -699.23  |proj g|=        2.4726
At iterate    26  f =      -699.23  |proj g|=        2.4724
At iterate    27  f =      -699.23  |proj g|=        2.4724
At iterate    28  f =      -699.23  |proj g|=        2.4724
At iterate    29  f =      -699.23  |proj g|=        2.4724
At iterate    30  f =      -699.23  |proj g|=        2.4724
At iterate    31  f =      -699.23  |proj g|=        2.4722
At iterate    32  f =      -699.23  |proj g|=        2.4715
At iterate    33  f =      -699.23  |proj g|=        2.4689
At iterate    34  f =      -699.24  |proj g|=        2.4682
At iterate    35  f =      -699.26  |proj g|=        2.4601
At iterate    36  f =      -699.31  |proj g|=        2.4355
At iterate    37  f =      -699.45  |proj g|=         2.357
At iterate    38  f =      -699.77  |proj g|=        2.1477
At iterate    39  f =      -700.52  |proj g|=        1.6288
At iterate    40  f =       -702.1  |proj g|=        1.0312
At iterate    41  f =      -703.55  |proj g|=       0.96208
At iterate    42  f =      -705.04  |proj g|=       0.59452
At iterate    43  f =      -705.36  |proj g|=       0.59716
At iterate    44  f =      -705.37  |proj g|=       0.59764
At iterate    45  f =      -705.37  |proj g|=       0.59751
At iterate    46  f =      -705.37  |proj g|=       0.59739
At iterate    47  f =      -705.37  |proj g|=       0.59651
At iterate    48  f =      -705.37  |proj g|=       0.59507
At iterate    49  f =      -705.38  |proj g|=        0.5929
At iterate    50  f =      -705.38  |proj g|=        0.5919
At iterate    51  f =      -705.38  |proj g|=       0.59193
At iterate    52  f =      -705.38  |proj g|=       0.59196

iterations 52
function evaluations 62
segments explored during Cauchy searches 54
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.591955
final function value -705.381

F = -705.381
final  value -705.380814 
converged
 
INFO  [08:29:46.380] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:29:46.468] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:29:46.475] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:29:49.975] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:29:53.790] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:29:57.657] [mlr3]  Finished benchmark 
INFO  [08:29:57.776] [bbotk] Result of batch 129: 
INFO  [08:29:57.778] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:29:57.778] [bbotk]              7.637964                 4.853903                       0.1755099 
INFO  [08:29:57.778] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:29:57.778] [bbotk]                     1658        0.829 -0.9510575         <NA>   0.9719128 
INFO  [08:29:57.778] [bbotk]                                 uhash 
INFO  [08:29:57.778] [bbotk]  b7875bd1-671d-49ba-81a4-34a735c8fe81 
DEBUG [08:29:59.115] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.7521e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.7521e-05 0.002205993 
  - best initial criterion value(s) :  604.4662 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -604.47  |proj g|=       11.455
At iterate     1  f =      -632.36  |proj g|=         6.785
At iterate     2  f =      -689.78  |proj g|=        2.2314
At iterate     3  f =      -690.29  |proj g|=         2.289
At iterate     4  f =      -692.06  |proj g|=        2.9439
At iterate     5  f =      -692.96  |proj g|=        2.9451
At iterate     6  f =      -693.31  |proj g|=        3.1826
At iterate     7  f =      -693.39  |proj g|=         3.127
At iterate     8  f =      -693.41  |proj g|=        3.0412
At iterate     9  f =      -693.41  |proj g|=         3.024
At iterate    10  f =      -693.41  |proj g|=        3.0224
At iterate    11  f =      -693.41  |proj g|=        2.9938
At iterate    12  f =      -693.41  |proj g|=        2.9913
At iterate    13  f =      -693.44  |proj g|=        2.9369
At iterate    14  f =      -693.52  |proj g|=         2.846
At iterate    15  f =      -693.73  |proj g|=        2.7178
At iterate    16  f =      -693.91  |proj g|=        2.2932
At iterate    17  f =      -694.72  |proj g|=        2.4125
At iterate    18  f =      -696.55  |proj g|=          2.47
At iterate    19  f =       -700.8  |proj g|=        2.0644
At iterate    20  f =      -704.02  |proj g|=        1.5289
At iterate    21  f =      -704.41  |proj g|=        1.5267
At iterate    22  f =      -707.29  |proj g|=         1.525
At iterate    23  f =      -708.12  |proj g|=        1.5231
At iterate    24  f =      -708.21  |proj g|=        1.5218
At iterate    25  f =      -708.22  |proj g|=        1.5222
At iterate    26  f =      -708.22  |proj g|=        1.5221
At iterate    27  f =      -708.22  |proj g|=        1.5221
At iterate    28  f =      -708.22  |proj g|=        1.5221

iterations 28
function evaluations 33
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.52213
final function value -708.22

F = -708.22
final  value -708.219897 
converged
 
INFO  [08:29:59.119] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:29:59.205] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:29:59.212] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:30:00.706] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:30:03.054] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:30:04.911] [mlr3]  Finished benchmark 
INFO  [08:30:05.037] [bbotk] Result of batch 130: 
INFO  [08:30:05.039] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:30:05.039] [bbotk]              4.622738                 3.792779                       0.4124834 
INFO  [08:30:05.039] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:30:05.039] [bbotk]                      521        0.845 -0.9492276         <NA>   0.9679345 
INFO  [08:30:05.039] [bbotk]                                 uhash 
INFO  [08:30:05.039] [bbotk]  c1a33496-c696-40f4-911c-1871bea90301 
DEBUG [08:30:06.374] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.741195e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.741195e-05 0.002174809 
  - best initial criterion value(s) :  632.6706 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -632.67  |proj g|=       3.0501
At iterate     1  f =      -633.32  |proj g|=        1.9686
At iterate     2  f =      -634.61  |proj g|=        2.1206
At iterate     3  f =      -635.84  |proj g|=        2.3128
At iterate     4  f =      -635.93  |proj g|=        2.1045
At iterate     5  f =      -635.93  |proj g|=        2.0456
At iterate     6  f =      -635.93  |proj g|=        2.0396
At iterate     7  f =      -635.93  |proj g|=        2.0392

iterations 7
function evaluations 10
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.03922
final function value -635.932

F = -635.932
final  value -635.932261 
converged
 
INFO  [08:30:06.378] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:30:06.464] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:30:06.471] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:30:12.973] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:30:19.906] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:30:27.146] [mlr3]  Finished benchmark 
INFO  [08:30:27.247] [bbotk] Result of batch 131: 
INFO  [08:30:27.249] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:30:27.249] [bbotk]              2.646955                 9.930119                       0.3469202 
INFO  [08:30:27.249] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:30:27.249] [bbotk]                     3211        1.014 -0.9623629         <NA>   0.9690141 
INFO  [08:30:27.249] [bbotk]                                 uhash 
INFO  [08:30:27.249] [bbotk]  bf0759b6-93ef-41e0-9fcb-b2fe6c462c19 
DEBUG [08:30:28.609] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.73061e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.73061e-05 0.002171915 
  - best initial criterion value(s) :  655.4566 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -655.46  |proj g|=       4.2228
At iterate     1  f =      -668.03  |proj g|=        6.9088
At iterate     2  f =      -670.65  |proj g|=        6.8514
At iterate     3  f =      -672.55  |proj g|=        6.6344
At iterate     4  f =      -672.65  |proj g|=        6.5628
At iterate     5  f =      -672.69  |proj g|=        6.6039
At iterate     6  f =      -672.83  |proj g|=        6.8664
At iterate     7  f =      -672.88  |proj g|=        7.0232
At iterate     8  f =      -672.89  |proj g|=        7.0113
At iterate     9  f =      -672.89  |proj g|=        7.0445
At iterate    10  f =      -672.89  |proj g|=        7.0612
At iterate    11  f =      -672.89  |proj g|=         7.092
At iterate    12  f =      -672.92  |proj g|=        7.1669
At iterate    13  f =      -672.97  |proj g|=        7.2736
At iterate    14  f =       -673.1  |proj g|=        7.4676
At iterate    15  f =      -673.41  |proj g|=        7.6942
At iterate    16  f =      -673.54  |proj g|=        7.8533
At iterate    17  f =      -674.31  |proj g|=         8.008
At iterate    18  f =      -678.62  |proj g|=        7.6742
At iterate    19  f =      -687.98  |proj g|=         5.599
At iterate    20  f =      -694.56  |proj g|=        3.7336
At iterate    21  f =      -695.64  |proj g|=        3.7139
At iterate    22  f =      -695.71  |proj g|=         3.364
At iterate    23  f =      -695.78  |proj g|=        3.5283
At iterate    24  f =      -695.78  |proj g|=        3.5539
At iterate    25  f =      -695.78  |proj g|=        3.5493
At iterate    26  f =      -695.78  |proj g|=        3.5489
At iterate    27  f =      -695.78  |proj g|=        3.5485
At iterate    28  f =      -695.78  |proj g|=         3.549

iterations 28
function evaluations 36
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.54903
final function value -695.779

F = -695.779
final  value -695.779493 
converged
 
INFO  [08:30:28.613] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:30:28.699] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:30:28.706] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:30:33.530] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:30:38.192] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:30:43.245] [mlr3]  Finished benchmark 
INFO  [08:30:43.377] [bbotk] Result of batch 132: 
INFO  [08:30:43.379] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:30:43.379] [bbotk]              4.323107                  4.05606                       0.2213086 
INFO  [08:30:43.379] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [08:30:43.379] [bbotk]                     2096        0.825 -0.957434         <NA>   0.9724697 
INFO  [08:30:43.379] [bbotk]                                 uhash 
INFO  [08:30:43.379] [bbotk]  2b4e2165-6506-43c0-ac15-d805b8612bb6 
DEBUG [08:30:44.761] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.721701e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.7217e-05 0.002164741 
  - best initial criterion value(s) :  654.7967 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -654.8  |proj g|=       8.4798
At iterate     1  f =      -682.74  |proj g|=        5.0873
At iterate     2  f =      -685.86  |proj g|=         4.821
At iterate     3  f =      -686.05  |proj g|=        4.8572
At iterate     4  f =      -686.07  |proj g|=        4.8372
At iterate     5  f =      -686.07  |proj g|=        4.8453
At iterate     6  f =      -686.07  |proj g|=        4.8446
At iterate     7  f =      -686.07  |proj g|=        4.8441
At iterate     8  f =      -686.07  |proj g|=        4.8426
At iterate     9  f =      -686.07  |proj g|=        4.8403
At iterate    10  f =      -686.07  |proj g|=        4.8364
At iterate    11  f =      -686.08  |proj g|=        4.8301
At iterate    12  f =      -686.08  |proj g|=        4.8187
At iterate    13  f =      -686.09  |proj g|=        4.8022
At iterate    14  f =      -686.11  |proj g|=        4.7694
At iterate    15  f =      -686.11  |proj g|=        4.7653
At iterate    16  f =      -686.16  |proj g|=        4.7253
At iterate    17  f =      -686.58  |proj g|=        4.6116
At iterate    18  f =      -690.05  |proj g|=        4.0601
At iterate    19  f =       -699.9  |proj g|=        3.1504
At iterate    20  f =      -708.26  |proj g|=        2.7448
At iterate    21  f =      -709.05  |proj g|=        1.4487
At iterate    22  f =      -711.75  |proj g|=        1.9284
At iterate    23  f =         -713  |proj g|=        1.8827
At iterate    24  f =      -714.16  |proj g|=        1.5963
At iterate    25  f =      -714.34  |proj g|=        1.3631
At iterate    26  f =      -714.38  |proj g|=        1.2322
At iterate    27  f =      -714.38  |proj g|=        1.1929
At iterate    28  f =      -714.38  |proj g|=        1.1884
At iterate    29  f =      -714.38  |proj g|=        1.1884

iterations 29
function evaluations 35
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.18839
final function value -714.382

F = -714.382
final  value -714.382401 
converged
 
INFO  [08:30:44.765] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:30:44.854] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:30:44.861] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:30:53.851] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:31:03.643] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:31:13.088] [mlr3]  Finished benchmark 
INFO  [08:31:13.190] [bbotk] Result of batch 133: 
INFO  [08:31:13.192] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:31:13.192] [bbotk]              7.274455                 2.241824                     0.005399197 
INFO  [08:31:13.192] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:31:13.192] [bbotk]                     4128        0.865 -0.9531167         <NA>   0.9380539 
INFO  [08:31:13.192] [bbotk]                                 uhash 
INFO  [08:31:13.192] [bbotk]  f94099b6-b641-4c71-9301-f8c57f89d817 
DEBUG [08:31:14.570] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.762677e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9823811 9590 
  - variance bounds :  1.762677e-05 0.002195656 
  - best initial criterion value(s) :  645.1901 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -645.19  |proj g|=       5.8348
At iterate     1  f =      -686.44  |proj g|=        3.5217
At iterate     2  f =      -689.11  |proj g|=        3.2827
At iterate     3  f =      -692.17  |proj g|=        2.6922
At iterate     4  f =      -692.32  |proj g|=        2.3998
At iterate     5  f =      -692.36  |proj g|=        2.5011
At iterate     6  f =      -692.39  |proj g|=        2.4952
At iterate     7  f =      -692.45  |proj g|=         2.511
At iterate     8  f =      -692.45  |proj g|=        2.5253
At iterate     9  f =      -692.45  |proj g|=        2.5245
At iterate    10  f =      -692.45  |proj g|=        2.5242
At iterate    11  f =      -692.45  |proj g|=        2.5236
At iterate    12  f =      -692.45  |proj g|=        2.5224
At iterate    13  f =      -692.45  |proj g|=        2.5204
At iterate    14  f =      -692.45  |proj g|=        2.5171
At iterate    15  f =      -692.45  |proj g|=        2.5128
At iterate    16  f =      -692.46  |proj g|=        2.5086
At iterate    17  f =      -692.47  |proj g|=        2.5047
At iterate    18  f =      -692.49  |proj g|=        2.5025
At iterate    19  f =      -692.55  |proj g|=        2.4928
At iterate    20  f =      -692.66  |proj g|=         2.553
At iterate    21  f =      -692.86  |proj g|=        2.4116
At iterate    22  f =       -693.3  |proj g|=        2.3624
At iterate    23  f =      -694.68  |proj g|=        2.0003
At iterate    24  f =      -694.81  |proj g|=        2.1482
At iterate    25  f =      -694.97  |proj g|=        2.0109
At iterate    26  f =      -694.97  |proj g|=        2.0191
At iterate    27  f =      -694.97  |proj g|=        2.0231
At iterate    28  f =      -694.97  |proj g|=        2.0232

iterations 28
function evaluations 34
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.02317
final function value -694.969

F = -694.969
final  value -694.968660 
converged
 
INFO  [08:31:14.574] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:31:14.663] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:31:14.670] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:31:17.568] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:31:21.980] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:31:25.637] [mlr3]  Finished benchmark 
INFO  [08:31:25.778] [bbotk] Result of batch 134: 
INFO  [08:31:25.780] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:31:25.780] [bbotk]              5.567077                  6.97608                        0.331276 
INFO  [08:31:25.780] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [08:31:25.780] [bbotk]                     1631        0.856 -0.949273         <NA>   0.9743377 
INFO  [08:31:25.780] [bbotk]                                 uhash 
INFO  [08:31:25.780] [bbotk]  cf59f4c9-6d6e-4c04-a754-cae8241fe546 
DEBUG [08:31:27.411] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.755237e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9823811 9590 
  - variance bounds :  1.755237e-05 0.002178289 
  - best initial criterion value(s) :  665.6061 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -665.61  |proj g|=       3.6748
At iterate     1  f =         -676  |proj g|=        12.864
At iterate     2  f =      -682.95  |proj g|=        12.677
At iterate     3  f =      -686.62  |proj g|=        9.8606
At iterate     4  f =       -686.9  |proj g|=        7.9519
At iterate     5  f =      -686.98  |proj g|=        8.1641
At iterate     6  f =      -687.41  |proj g|=        8.3437
At iterate     7  f =      -687.87  |proj g|=         7.669
At iterate     8  f =      -688.05  |proj g|=        6.5215
At iterate     9  f =      -688.06  |proj g|=        6.5098
At iterate    10  f =      -688.06  |proj g|=        6.5449
At iterate    11  f =      -688.06  |proj g|=        6.5552
At iterate    12  f =      -688.06  |proj g|=        6.5594
At iterate    13  f =      -688.06  |proj g|=        6.5691
At iterate    14  f =      -688.06  |proj g|=        6.5827
At iterate    15  f =      -688.06  |proj g|=        6.6059
At iterate    16  f =      -688.07  |proj g|=        6.6406
At iterate    17  f =      -688.07  |proj g|=        6.6889
At iterate    18  f =      -688.08  |proj g|=          6.74
At iterate    19  f =      -688.11  |proj g|=        6.7404
At iterate    20  f =      -688.17  |proj g|=        6.5423
At iterate    21  f =      -688.22  |proj g|=        5.7524
At iterate    22  f =      -688.22  |proj g|=        5.8993
At iterate    23  f =      -688.24  |proj g|=        6.0499
At iterate    24  f =       -688.3  |proj g|=        6.3558
At iterate    25  f =      -688.46  |proj g|=        6.8487
At iterate    26  f =      -688.86  |proj g|=        7.5578
At iterate    27  f =      -689.66  |proj g|=        8.0551
At iterate    28  f =      -690.66  |proj g|=        7.8208
At iterate    29  f =      -691.37  |proj g|=        5.9495
At iterate    30  f =      -693.89  |proj g|=        4.3664
At iterate    31  f =      -696.83  |proj g|=         2.111
At iterate    32  f =       -699.6  |proj g|=        2.3883
At iterate    33  f =      -702.63  |proj g|=         2.737
At iterate    34  f =      -706.23  |proj g|=        3.2049
At iterate    35  f =      -706.32  |proj g|=        3.1115
At iterate    36  f =      -706.67  |proj g|=         3.194
At iterate    37  f =      -706.93  |proj g|=         3.007
At iterate    38  f =      -706.93  |proj g|=        2.9807
At iterate    39  f =      -706.93  |proj g|=        2.9869
At iterate    40  f =      -706.93  |proj g|=        2.9867

iterations 40
function evaluations 46
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.98669
final function value -706.929

F = -706.929
final  value -706.929219 
converged
 
INFO  [08:31:27.415] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:31:27.505] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:31:27.513] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:31:29.884] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:31:31.403] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:31:32.830] [mlr3]  Finished benchmark 
INFO  [08:31:32.998] [bbotk] Result of batch 135: 
INFO  [08:31:33.000] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:31:33.000] [bbotk]              8.801706                  8.58774                       0.3187529 
INFO  [08:31:33.000] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:31:33.000] [bbotk]                      635        1.039 -0.9396577         <NA>   0.9699079 
INFO  [08:31:33.000] [bbotk]                                 uhash 
INFO  [08:31:33.000] [bbotk]  80ed7d68-8ef1-4e54-8f2c-5e1675dd357b 
DEBUG [08:31:34.600] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.74511e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9823811 9590 
  - variance bounds :  1.74511e-05 0.002153842 
  - best initial criterion value(s) :  660.3522 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -660.35  |proj g|=       4.5222
At iterate     1  f =      -672.92  |proj g|=        12.404
At iterate     2  f =      -683.45  |proj g|=        12.171
At iterate     3  f =      -696.39  |proj g|=        10.182
At iterate     4  f =      -697.22  |proj g|=        8.6023
At iterate     5  f =      -697.25  |proj g|=        8.3301
At iterate     6  f =      -697.27  |proj g|=        8.2154
At iterate     7  f =      -697.37  |proj g|=        7.6617
At iterate     8  f =      -697.38  |proj g|=        7.6242
At iterate     9  f =      -697.39  |proj g|=        7.6512
At iterate    10  f =      -697.39  |proj g|=        7.6626
At iterate    11  f =      -697.39  |proj g|=        7.6654
At iterate    12  f =      -697.39  |proj g|=        7.6748
At iterate    13  f =      -697.39  |proj g|=         7.685
At iterate    14  f =      -697.39  |proj g|=         7.699
At iterate    15  f =      -697.39  |proj g|=        7.7099
At iterate    16  f =       -697.4  |proj g|=        7.6953
At iterate    17  f =      -697.41  |proj g|=        7.6017
At iterate    18  f =      -697.41  |proj g|=        7.3352
At iterate    19  f =      -697.42  |proj g|=         7.375
At iterate    20  f =      -697.42  |proj g|=        7.4883
At iterate    21  f =      -697.44  |proj g|=        7.6397
At iterate    22  f =      -697.49  |proj g|=        7.9055
At iterate    23  f =       -697.6  |proj g|=        8.2916
At iterate    24  f =      -697.87  |proj g|=        8.7608
At iterate    25  f =      -697.96  |proj g|=        9.2111
At iterate    26  f =      -698.63  |proj g|=        9.3415
At iterate    27  f =      -701.72  |proj g|=        6.8517
At iterate    28  f =      -706.25  |proj g|=        5.4451
At iterate    29  f =       -711.6  |proj g|=         2.554
At iterate    30  f =      -711.83  |proj g|=        2.3898
At iterate    31  f =      -711.94  |proj g|=        2.2674
At iterate    32  f =      -711.94  |proj g|=         2.198
At iterate    33  f =      -711.94  |proj g|=        2.2188
At iterate    34  f =      -711.94  |proj g|=        2.2222
At iterate    35  f =      -711.94  |proj g|=        2.2321
At iterate    36  f =      -711.94  |proj g|=         2.245
At iterate    37  f =      -711.94  |proj g|=         2.266
At iterate    38  f =      -711.95  |proj g|=         2.292
At iterate    39  f =      -711.95  |proj g|=          2.32
At iterate    40  f =      -711.97  |proj g|=         2.327
At iterate    41  f =      -711.99  |proj g|=        2.2582
At iterate    42  f =      -712.01  |proj g|=        2.2355
At iterate    43  f =      -712.02  |proj g|=        2.1007
At iterate    44  f =      -712.07  |proj g|=        2.0631
At iterate    45  f =      -712.48  |proj g|=        1.8987
At iterate    46  f =      -714.87  |proj g|=        1.2506
At iterate    47  f =      -717.53  |proj g|=       0.67848
At iterate    48  f =      -718.52  |proj g|=       0.64748
At iterate    49  f =      -718.65  |proj g|=       0.63314
At iterate    50  f =      -718.82  |proj g|=       0.61673
At iterate    51  f =      -718.84  |proj g|=       0.61088
At iterate    52  f =      -718.85  |proj g|=       0.15245
At iterate    53  f =      -718.85  |proj g|=      0.011815
At iterate    54  f =      -718.85  |proj g|=      0.006517
At iterate    55  f =      -718.85  |proj g|=     0.0065152

iterations 55
function evaluations 62
segments explored during Cauchy searches 59
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00651518
final function value -718.85

F = -718.85
final  value -718.850455 
converged
 
INFO  [08:31:34.604] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:31:34.695] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:31:34.702] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:31:37.983] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:31:41.269] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:31:44.640] [mlr3]  Finished benchmark 
INFO  [08:31:44.834] [bbotk] Result of batch 136: 
INFO  [08:31:44.837] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:31:44.837] [bbotk]               2.44588                 2.265771                       0.3779584 
INFO  [08:31:44.837] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:31:44.837] [bbotk]                     2099        0.878 -0.9462732         <NA>   0.9644984 
INFO  [08:31:44.837] [bbotk]                                 uhash 
INFO  [08:31:44.837] [bbotk]  2e2a2470-a2e1-4c4f-9d06-60c90c3ea478 
DEBUG [08:31:46.222] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.734976e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9823811 9590 
  - variance bounds :  1.734976e-05 0.002144092 
  - best initial criterion value(s) :  666.3141 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -666.31  |proj g|=       8.5403
At iterate     1  f =      -699.54  |proj g|=        1.2932
At iterate     2  f =      -700.87  |proj g|=        1.2967
At iterate     3  f =      -703.13  |proj g|=        1.3071
At iterate     4  f =      -703.38  |proj g|=        1.3128
At iterate     5  f =      -704.24  |proj g|=        1.3256
At iterate     6  f =      -708.58  |proj g|=        1.4323
At iterate     7  f =      -709.51  |proj g|=        1.4705
At iterate     8  f =      -709.87  |proj g|=        1.5071
At iterate     9  f =      -709.95  |proj g|=        1.5227
At iterate    10  f =      -709.96  |proj g|=        1.5201
At iterate    11  f =      -709.97  |proj g|=        1.5272
At iterate    12  f =      -709.97  |proj g|=        1.5276
At iterate    13  f =      -709.97  |proj g|=        1.5294
At iterate    14  f =      -709.97  |proj g|=        1.5311
At iterate    15  f =      -709.98  |proj g|=        1.5343
At iterate    16  f =         -710  |proj g|=        1.5399
At iterate    17  f =      -710.06  |proj g|=        1.5469
At iterate    18  f =      -710.18  |proj g|=        1.5595
At iterate    19  f =      -710.22  |proj g|=        1.5537
At iterate    20  f =      -710.48  |proj g|=        1.5651
At iterate    21  f =      -712.34  |proj g|=        1.5004
At iterate    22  f =      -713.33  |proj g|=        1.4104
At iterate    23  f =      -713.42  |proj g|=        1.3802
At iterate    24  f =      -713.42  |proj g|=         1.386
At iterate    25  f =      -713.42  |proj g|=        1.3862
At iterate    26  f =      -713.42  |proj g|=        1.3877
At iterate    27  f =      -713.42  |proj g|=        1.3877

iterations 27
function evaluations 37
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.38774
final function value -713.422

F = -713.422
final  value -713.422315 
converged
 
INFO  [08:31:46.226] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:31:46.330] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:31:46.339] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:31:47.464] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:31:48.524] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:31:49.665] [mlr3]  Finished benchmark 
INFO  [08:31:49.890] [bbotk] Result of batch 137: 
INFO  [08:31:49.892] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:31:49.892] [bbotk]              6.229046                 2.881685                        0.151973 
INFO  [08:31:49.892] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:31:49.892] [bbotk]                      501        0.843 -0.9525009         <NA>   0.9590212 
INFO  [08:31:49.892] [bbotk]                                 uhash 
INFO  [08:31:49.892] [bbotk]  8211e510-d376-487f-acb9-85c89b431e12 
DEBUG [08:31:51.628] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.728373e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9823811 9590 
  - variance bounds :  1.728373e-05 0.002125788 
  - best initial criterion value(s) :  685.7532 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -685.75  |proj g|=       12.721
At iterate     1  f =      -696.43  |proj g|=         3.775
At iterate     2  f =      -700.41  |proj g|=         3.752
At iterate     3  f =      -705.03  |proj g|=         2.759
At iterate     4  f =      -707.41  |proj g|=        2.6057
At iterate     5  f =      -708.62  |proj g|=        2.4548
At iterate     6  f =      -709.25  |proj g|=        2.4139
At iterate     7  f =      -709.49  |proj g|=        2.7443
At iterate     8  f =      -709.77  |proj g|=        2.6336
At iterate     9  f =      -709.87  |proj g|=        2.6187
At iterate    10  f =      -709.92  |proj g|=        2.6371
At iterate    11  f =      -709.95  |proj g|=        2.6613
At iterate    12  f =      -709.99  |proj g|=        2.6897
At iterate    13  f =      -710.07  |proj g|=        2.6271
At iterate    14  f =      -710.13  |proj g|=        2.8045
At iterate    15  f =      -710.27  |proj g|=         2.727
At iterate    16  f =      -710.82  |proj g|=        2.5323
At iterate    17  f =      -712.26  |proj g|=        2.2929
At iterate    18  f =      -718.95  |proj g|=         1.882
At iterate    19  f =      -727.28  |proj g|=        2.0271
At iterate    20  f =      -727.39  |proj g|=        2.2264
At iterate    21  f =      -727.39  |proj g|=        2.1818
At iterate    22  f =       -727.4  |proj g|=        2.1837
At iterate    23  f =       -727.4  |proj g|=        2.1868
At iterate    24  f =       -727.4  |proj g|=        2.1859
At iterate    25  f =       -727.4  |proj g|=        2.1866
At iterate    26  f =       -727.4  |proj g|=        2.1889
At iterate    27  f =       -727.4  |proj g|=        2.1927
At iterate    28  f =      -727.41  |proj g|=        2.1976
At iterate    29  f =      -727.41  |proj g|=        2.2105
At iterate    30  f =      -727.43  |proj g|=        2.2115
At iterate    31  f =      -727.49  |proj g|=        2.2062
At iterate    32  f =      -727.69  |proj g|=          2.18
At iterate    33  f =       -728.2  |proj g|=        2.1035
At iterate    34  f =      -729.98  |proj g|=       0.97726
At iterate    35  f =      -730.01  |proj g|=       0.94318
At iterate    36  f =      -731.36  |proj g|=       0.66853
At iterate    37  f =      -732.28  |proj g|=       0.63824
At iterate    38  f =      -732.79  |proj g|=       0.59988
At iterate    39  f =      -732.83  |proj g|=       0.51496
At iterate    40  f =      -732.83  |proj g|=       0.14683
At iterate    41  f =      -732.83  |proj g|=      0.050888
At iterate    42  f =      -732.83  |proj g|=     0.0048118
At iterate    43  f =      -732.83  |proj g|=     0.0083472

iterations 43
function evaluations 58
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00834719
final function value -732.828

F = -732.828
final  value -732.827528 
converged
 
INFO  [08:31:51.632] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:31:51.723] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:31:51.730] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:31:52.476] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:31:53.295] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:31:54.601] [mlr3]  Finished benchmark 
INFO  [08:31:54.736] [bbotk] Result of batch 138: 
INFO  [08:31:54.739] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:31:54.739] [bbotk]              8.112323                 9.635445                       0.4996574 
INFO  [08:31:54.739] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:31:54.739] [bbotk]                      200        0.946 -0.9410285         <NA>   0.9634854 
INFO  [08:31:54.739] [bbotk]                                 uhash 
INFO  [08:31:54.739] [bbotk]  5328336b-cbe9-499f-ab16-fba2459b1bb0 
DEBUG [08:31:56.338] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.718796e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.718796e-05 0.002101401 
  - best initial criterion value(s) :  694.5612 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -694.56  |proj g|=         3.31
At iterate     1  f =      -708.12  |proj g|=        5.5707
At iterate     2  f =      -710.64  |proj g|=        5.3168
At iterate     3  f =      -711.65  |proj g|=        4.2874
At iterate     4  f =      -712.28  |proj g|=        4.8561
At iterate     5  f =      -712.34  |proj g|=        4.7548
At iterate     6  f =      -712.34  |proj g|=        4.7271
At iterate     7  f =      -712.35  |proj g|=        4.7134
At iterate     8  f =      -712.36  |proj g|=        4.6651
At iterate     9  f =      -712.37  |proj g|=          4.65
At iterate    10  f =      -712.37  |proj g|=        4.6731
At iterate    11  f =      -712.37  |proj g|=        4.6638
At iterate    12  f =      -712.37  |proj g|=        4.6634

iterations 12
function evaluations 14
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.66335
final function value -712.371

F = -712.371
final  value -712.370667 
converged
 
INFO  [08:31:56.342] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:31:56.438] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:31:56.446] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:31:57.435] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:31:58.426] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:31:59.410] [mlr3]  Finished benchmark 
INFO  [08:31:59.511] [bbotk] Result of batch 139: 
INFO  [08:31:59.513] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:31:59.513] [bbotk]              4.545614                 3.924807                       0.1555718 
INFO  [08:31:59.513] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:31:59.513] [bbotk]                      393        1.206 -0.9535888         <NA>   0.9534245 
INFO  [08:31:59.513] [bbotk]                                 uhash 
INFO  [08:31:59.513] [bbotk]  a4558ac1-f32d-4816-9a68-a659b948ffdd 
DEBUG [08:32:01.143] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.719353e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.719353e-05 0.002102388 
  - best initial criterion value(s) :  669.7399 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -669.74  |proj g|=       8.8044
At iterate     1  f =      -714.15  |proj g|=        3.7627
At iterate     2  f =       -718.8  |proj g|=        3.5551
At iterate     3  f =      -724.75  |proj g|=        2.9797
At iterate     4  f =      -725.49  |proj g|=        2.4703
At iterate     5  f =      -725.75  |proj g|=        2.6199
At iterate     6  f =      -725.98  |proj g|=        2.6681
At iterate     7  f =      -727.05  |proj g|=        2.7146
At iterate     8  f =      -728.05  |proj g|=        2.5988
At iterate     9  f =      -728.08  |proj g|=        2.5246
At iterate    10  f =      -728.16  |proj g|=        2.5175
At iterate    11  f =      -728.16  |proj g|=        2.5165
At iterate    12  f =      -728.16  |proj g|=        2.5168
At iterate    13  f =      -728.16  |proj g|=        2.5178
At iterate    14  f =      -728.16  |proj g|=        2.5173
At iterate    15  f =      -728.16  |proj g|=        2.5162
At iterate    16  f =       -728.3  |proj g|=        2.4818
At iterate    17  f =      -728.71  |proj g|=        2.4031
At iterate    18  f =      -728.72  |proj g|=        2.4105
At iterate    19  f =      -728.72  |proj g|=        2.4163
At iterate    20  f =      -728.72  |proj g|=        2.4178
At iterate    21  f =      -728.72  |proj g|=        2.4183
At iterate    22  f =      -728.72  |proj g|=        2.4191
At iterate    23  f =      -728.72  |proj g|=        2.4205
At iterate    24  f =      -728.72  |proj g|=        2.4225
At iterate    25  f =      -728.72  |proj g|=         2.426
At iterate    26  f =      -728.72  |proj g|=        2.4314
At iterate    27  f =      -728.72  |proj g|=          2.44
At iterate    28  f =      -728.73  |proj g|=         2.452
At iterate    29  f =      -728.74  |proj g|=        2.4639
At iterate    30  f =      -728.75  |proj g|=         2.459
At iterate    31  f =      -728.75  |proj g|=        2.4311
At iterate    32  f =      -728.75  |proj g|=        2.4337
At iterate    33  f =      -728.75  |proj g|=        2.4369
At iterate    34  f =      -728.75  |proj g|=        2.4417
At iterate    35  f =      -728.76  |proj g|=        2.4484
At iterate    36  f =      -728.77  |proj g|=        2.4518
At iterate    37  f =      -728.78  |proj g|=          2.45
At iterate    38  f =      -728.83  |proj g|=        2.4694
At iterate    39  f =      -728.93  |proj g|=        2.4293
At iterate    40  f =      -728.93  |proj g|=        2.5127
At iterate    41  f =      -729.21  |proj g|=         2.384
At iterate    42  f =      -729.84  |proj g|=        2.1314
At iterate    43  f =      -731.26  |proj g|=        1.6694
At iterate    44  f =      -734.23  |proj g|=       0.50788
At iterate    45  f =         -736  |proj g|=       0.42746
At iterate    46  f =      -736.08  |proj g|=       0.58689
At iterate    47  f =      -736.26  |proj g|=        0.6046
At iterate    48  f =      -736.27  |proj g|=        0.3506
At iterate    49  f =      -736.27  |proj g|=       0.35958
At iterate    50  f =      -736.27  |proj g|=       0.35826
At iterate    51  f =      -736.27  |proj g|=       0.35827

iterations 51
function evaluations 62
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.358274
final function value -736.268

F = -736.268
final  value -736.268330 
converged
 
INFO  [08:32:01.147] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:32:01.232] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:32:01.239] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:32:08.728] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:32:16.309] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:32:23.974] [mlr3]  Finished benchmark 
INFO  [08:32:24.091] [bbotk] Result of batch 140: 
INFO  [08:32:24.093] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:32:24.093] [bbotk]              9.066913                 6.197768                       0.3572002 
INFO  [08:32:24.093] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:32:24.093] [bbotk]                     4632        0.854 -0.9460986         <NA>   0.9789208 
INFO  [08:32:24.093] [bbotk]                                 uhash 
INFO  [08:32:24.093] [bbotk]  162524da-af21-41d8-9204-5a83f444b52c 
DEBUG [08:32:25.441] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.717761e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.717761e-05 0.002103878 
  - best initial criterion value(s) :  686.8797 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -686.88  |proj g|=        2.261
At iterate     1  f =      -691.13  |proj g|=        3.2896
At iterate     2  f =      -691.42  |proj g|=        3.0584
At iterate     3  f =      -691.67  |proj g|=        2.9186
At iterate     4  f =      -691.84  |proj g|=        2.8856
At iterate     5  f =      -693.77  |proj g|=        2.5532
At iterate     6  f =      -695.24  |proj g|=        2.5848
At iterate     7  f =      -695.81  |proj g|=        2.6898
At iterate     8  f =      -695.82  |proj g|=        2.6873
At iterate     9  f =      -695.82  |proj g|=        2.6817
At iterate    10  f =      -695.82  |proj g|=        2.6829
At iterate    11  f =      -695.82  |proj g|=        2.6828

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.68281
final function value -695.822

F = -695.822
final  value -695.822171 
converged
 
INFO  [08:32:25.445] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:32:25.532] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:32:25.539] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:32:31.976] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:32:38.386] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:32:48.065] [mlr3]  Finished benchmark 
INFO  [08:32:48.164] [bbotk] Result of batch 141: 
INFO  [08:32:48.166] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:32:48.166] [bbotk]              7.482853                 4.482061                      0.02894299 
INFO  [08:32:48.166] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:32:48.166] [bbotk]                     4103        0.954 -0.9624293         <NA>    0.964449 
INFO  [08:32:48.166] [bbotk]                                 uhash 
INFO  [08:32:48.166] [bbotk]  57e7c267-f8ed-4852-8840-006bc9d02d6e 
DEBUG [08:32:49.424] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.70807e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.70807e-05 0.002091174 
  - best initial criterion value(s) :  670.4529 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -670.45  |proj g|=       3.3224
At iterate     1  f =       -683.4  |proj g|=        9.4211
At iterate     2  f =      -697.24  |proj g|=        9.2476
At iterate     3  f =      -707.08  |proj g|=         8.407
At iterate     4  f =      -714.05  |proj g|=        6.7718
At iterate     5  f =      -719.54  |proj g|=        4.8318
At iterate     6  f =      -721.09  |proj g|=        3.7248
At iterate     7  f =      -721.43  |proj g|=        2.9546
At iterate     8  f =      -721.46  |proj g|=         3.359
At iterate     9  f =      -721.47  |proj g|=        3.2476
At iterate    10  f =      -721.47  |proj g|=        3.2355
At iterate    11  f =      -721.47  |proj g|=        3.2367
At iterate    12  f =      -721.47  |proj g|=         3.237

iterations 12
function evaluations 17
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.23699
final function value -721.471

F = -721.471
final  value -721.470851 
converged
 
INFO  [08:32:49.428] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:32:49.515] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:32:49.522] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:32:58.680] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:33:07.387] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:33:15.987] [mlr3]  Finished benchmark 
INFO  [08:33:16.352] [bbotk] Result of batch 142: 
INFO  [08:33:16.354] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:33:16.354] [bbotk]              4.683685                 7.670487                       0.1593438 
INFO  [08:33:16.354] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:33:16.354] [bbotk]                     3647         0.86 -0.9504186         <NA>   0.9740352 
INFO  [08:33:16.354] [bbotk]                                 uhash 
INFO  [08:33:16.354] [bbotk]  e4313eef-8a51-477a-9ba1-aac8b9ad3973 
DEBUG [08:33:18.548] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.701078e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.701078e-05 0.002089047 
  - best initial criterion value(s) :  714.0753 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -714.08  |proj g|=       1.2747
At iterate     1  f =      -719.67  |proj g|=        5.8616
At iterate     2  f =      -722.53  |proj g|=        4.7994
At iterate     3  f =      -723.62  |proj g|=        2.7356
At iterate     4  f =      -723.99  |proj g|=        3.5119
At iterate     5  f =      -724.72  |proj g|=        3.8033
At iterate     6  f =      -727.06  |proj g|=        4.1132
At iterate     7  f =      -727.64  |proj g|=        3.9401
At iterate     8  f =      -727.71  |proj g|=         3.927
At iterate     9  f =      -727.71  |proj g|=        4.0005
At iterate    10  f =      -727.71  |proj g|=        3.9839
At iterate    11  f =      -727.71  |proj g|=        3.9826
At iterate    12  f =      -727.71  |proj g|=        3.9809
At iterate    13  f =      -727.71  |proj g|=        3.9767
At iterate    14  f =      -727.71  |proj g|=        3.9703
At iterate    15  f =      -727.72  |proj g|=        3.9355
At iterate    16  f =      -727.72  |proj g|=        3.9285
At iterate    17  f =      -727.72  |proj g|=        3.8665
At iterate    18  f =      -727.75  |proj g|=        3.8462
At iterate    19  f =      -727.86  |proj g|=        3.7722
At iterate    20  f =      -728.45  |proj g|=        3.4347
At iterate    21  f =      -731.62  |proj g|=        3.4568
At iterate    22  f =      -732.13  |proj g|=        4.0228
At iterate    23  f =      -732.15  |proj g|=        3.9228
At iterate    24  f =      -732.16  |proj g|=        3.9882
At iterate    25  f =      -732.16  |proj g|=         3.993
At iterate    26  f =      -732.16  |proj g|=        4.0047
At iterate    27  f =      -732.16  |proj g|=        4.0161
At iterate    28  f =      -732.16  |proj g|=        4.0396
At iterate    29  f =      -732.17  |proj g|=        4.1007
At iterate    30  f =      -732.17  |proj g|=        4.0821
At iterate    31  f =      -732.19  |proj g|=        4.1034
At iterate    32  f =      -732.21  |proj g|=        4.0879
At iterate    33  f =      -732.21  |proj g|=        4.0538
At iterate    34  f =      -732.21  |proj g|=        4.0536
At iterate    35  f =      -732.22  |proj g|=        4.0244
At iterate    36  f =      -732.22  |proj g|=        4.0279
At iterate    37  f =      -732.22  |proj g|=        4.0347
At iterate    38  f =      -732.22  |proj g|=        4.0481
At iterate    39  f =      -732.23  |proj g|=        4.0671
At iterate    40  f =      -732.25  |proj g|=         4.096
At iterate    41  f =      -732.32  |proj g|=        4.1306
At iterate    42  f =      -732.47  |proj g|=        4.1422
At iterate    43  f =      -732.84  |proj g|=        4.0385
At iterate    44  f =      -733.55  |proj g|=        3.6721
At iterate    45  f =      -734.35  |proj g|=        3.1908
At iterate    46  f =      -734.74  |proj g|=        3.0797
At iterate    47  f =      -734.89  |proj g|=        2.8043
At iterate    48  f =      -734.94  |proj g|=        2.7085
At iterate    49  f =      -735.28  |proj g|=        2.3014
At iterate    50  f =      -735.91  |proj g|=        1.9443
At iterate    51  f =      -737.69  |proj g|=        1.8879
At iterate    52  f =      -741.35  |proj g|=        2.4366
At iterate    53  f =      -743.45  |proj g|=        1.7455
At iterate    54  f =      -747.32  |proj g|=       0.78668
At iterate    55  f =       -751.5  |proj g|=        1.3439
At iterate    56  f =      -751.56  |proj g|=        1.4786
At iterate    57  f =      -751.58  |proj g|=        1.5838
At iterate    58  f =      -751.58  |proj g|=        1.5934
At iterate    59  f =      -751.58  |proj g|=        1.5939
At iterate    60  f =      -751.58  |proj g|=        1.5949
At iterate    61  f =      -751.58  |proj g|=         1.599
At iterate    62  f =      -751.58  |proj g|=         1.604
At iterate    63  f =      -751.58  |proj g|=        1.6135
At iterate    64  f =      -751.58  |proj g|=         1.626
At iterate    65  f =      -751.59  |proj g|=        1.6392
At iterate    66  f =      -751.62  |proj g|=        1.6379
At iterate    67  f =      -751.67  |proj g|=        1.5835
At iterate    68  f =      -751.74  |proj g|=        1.4233
At iterate    69  f =      -751.78  |proj g|=        1.3096
At iterate    70  f =      -751.81  |proj g|=        1.1972
At iterate    71  f =      -751.83  |proj g|=        1.1434
At iterate    72  f =      -751.91  |proj g|=        1.0281
At iterate    73  f =      -752.11  |proj g|=         0.846
At iterate    74  f =       -752.6  |proj g|=       0.71993
At iterate    75  f =      -753.65  |proj g|=       0.28788
At iterate    76  f =      -755.15  |proj g|=       0.31739
At iterate    77  f =       -756.9  |proj g|=       0.65254
At iterate    78  f =         -757  |proj g|=       0.64937
At iterate    79  f =      -757.01  |proj g|=       0.64933
At iterate    80  f =      -757.01  |proj g|=       0.64931
At iterate    81  f =      -757.01  |proj g|=       0.64927
At iterate    82  f =      -757.01  |proj g|=       0.64915
At iterate    83  f =      -757.01  |proj g|=       0.64886
At iterate    84  f =      -757.01  |proj g|=       0.64807
At iterate    85  f =      -757.02  |proj g|=        0.6461
At iterate    86  f =      -757.05  |proj g|=       0.64156
At iterate    87  f =      -757.09  |proj g|=       0.63322
At iterate    88  f =      -757.12  |proj g|=       0.63259
At iterate    89  f =      -757.13  |proj g|=       0.28268
At iterate    90  f =      -757.13  |proj g|=     0.0030038
At iterate    91  f =      -757.13  |proj g|=      0.001038

iterations 91
function evaluations 101
segments explored during Cauchy searches 95
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00103799
final function value -757.129

F = -757.129
final  value -757.129301 
converged
 
INFO  [08:33:18.553] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:33:18.665] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:33:18.672] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:33:27.762] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:33:36.286] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:33:44.544] [mlr3]  Finished benchmark 
INFO  [08:33:44.646] [bbotk] Result of batch 143: 
INFO  [08:33:44.648] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:33:44.648] [bbotk]              3.704267                 5.657236                        0.161132 
INFO  [08:33:44.648] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:33:44.648] [bbotk]                     3641        0.861 -0.9376899         <NA>   0.9721229 
INFO  [08:33:44.648] [bbotk]                                 uhash 
INFO  [08:33:44.648] [bbotk]  cb3c8c73-5935-4cdc-a318-03f1c79c05b4 
DEBUG [08:33:46.009] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.692784e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.692784e-05 0.002086105 
  - best initial criterion value(s) :  705.3345 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -705.33  |proj g|=        6.239
At iterate     1  f =      -734.81  |proj g|=        5.1096
At iterate     2  f =      -738.45  |proj g|=        4.7448
At iterate     3  f =      -741.54  |proj g|=        3.1346
At iterate     4  f =      -742.45  |proj g|=        3.7899
At iterate     5  f =      -743.49  |proj g|=        3.5698
At iterate     6  f =      -745.62  |proj g|=        3.2346
At iterate     7  f =      -746.11  |proj g|=        4.0849
At iterate     8  f =      -746.84  |proj g|=        3.6577
At iterate     9  f =      -746.89  |proj g|=        3.5099
At iterate    10  f =      -746.89  |proj g|=        3.5021
At iterate    11  f =      -746.89  |proj g|=        3.5009
At iterate    12  f =      -746.89  |proj g|=        3.5017
At iterate    13  f =      -746.89  |proj g|=        3.5026
At iterate    14  f =      -746.89  |proj g|=        3.5041
At iterate    15  f =      -746.89  |proj g|=        3.5064
At iterate    16  f =      -746.89  |proj g|=        3.5094
At iterate    17  f =      -746.89  |proj g|=         3.522
At iterate    18  f =      -746.89  |proj g|=        3.5235
At iterate    19  f =       -746.9  |proj g|=        3.5787
At iterate    20  f =      -746.92  |proj g|=        3.5828
At iterate    21  f =      -747.04  |proj g|=        3.5857
At iterate    22  f =      -747.24  |proj g|=        3.5806
At iterate    23  f =      -747.29  |proj g|=        3.5432
At iterate    24  f =      -747.29  |proj g|=        3.5436

iterations 24
function evaluations 28
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.54355
final function value -747.292

F = -747.292
final  value -747.291929 
converged
 
INFO  [08:33:46.014] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:33:46.101] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:33:46.108] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:33:57.189] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:34:04.662] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:34:14.494] [mlr3]  Finished benchmark 
INFO  [08:34:14.626] [bbotk] Result of batch 144: 
INFO  [08:34:14.627] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:34:14.627] [bbotk]              3.397216                 4.839824                      0.09910388 
INFO  [08:34:14.627] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:34:14.627] [bbotk]                     3626        0.869 -0.9449534         <NA>   0.9681605 
INFO  [08:34:14.627] [bbotk]                                 uhash 
INFO  [08:34:14.627] [bbotk]  8bf81e4a-8bdd-41ef-a364-608c31a6e8b1 
DEBUG [08:34:16.382] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.683136e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.683136e-05 0.002077816 
  - best initial criterion value(s) :  674.1329 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -674.13  |proj g|=       3.5424
At iterate     1  f =      -681.21  |proj g|=        13.105
At iterate     2  f =       -694.1  |proj g|=        12.878
At iterate     3  f =      -704.94  |proj g|=        11.096
At iterate     4  f =      -706.01  |proj g|=        8.9809
At iterate     5  f =      -707.75  |proj g|=        7.7352
At iterate     6  f =      -713.93  |proj g|=        4.5979
At iterate     7  f =      -716.59  |proj g|=        8.9171
At iterate     8  f =       -721.3  |proj g|=        5.2944
At iterate     9  f =      -721.91  |proj g|=        4.3427
At iterate    10  f =      -722.24  |proj g|=         4.005
At iterate    11  f =      -726.03  |proj g|=        6.2536
At iterate    12  f =      -728.12  |proj g|=        5.4266
At iterate    13  f =      -729.24  |proj g|=        4.9367
At iterate    14  f =      -733.08  |proj g|=        3.4967
At iterate    15  f =       -748.5  |proj g|=        2.2164
At iterate    16  f =      -756.55  |proj g|=        2.6131
At iterate    17  f =       -762.3  |proj g|=        2.3372
At iterate    18  f =      -766.93  |proj g|=        1.4262
At iterate    19  f =      -766.99  |proj g|=        1.2636
At iterate    20  f =      -767.09  |proj g|=        1.2803
At iterate    21  f =      -767.09  |proj g|=        1.2882
At iterate    22  f =      -767.09  |proj g|=        1.2882
At iterate    23  f =      -767.09  |proj g|=        1.2885
At iterate    24  f =      -767.09  |proj g|=        1.2891
At iterate    25  f =      -767.09  |proj g|=        1.2971
At iterate    26  f =      -767.09  |proj g|=        1.2944
At iterate    27  f =      -767.09  |proj g|=        1.2885
At iterate    28  f =       -767.1  |proj g|=        1.2798
At iterate    29  f =       -767.1  |proj g|=         1.265
At iterate    30  f =      -767.11  |proj g|=        1.2437
At iterate    31  f =      -767.12  |proj g|=        1.2143
At iterate    32  f =      -767.17  |proj g|=        1.1795
At iterate    33  f =      -767.25  |proj g|=        1.1588
At iterate    34  f =      -767.33  |proj g|=        0.9934
At iterate    35  f =      -767.52  |proj g|=       0.98566
At iterate    36  f =      -768.26  |proj g|=       0.40764
At iterate    37  f =      -768.56  |proj g|=       0.41212
At iterate    38  f =      -768.81  |proj g|=       0.39794
At iterate    39  f =      -769.13  |proj g|=       0.62313
At iterate    40  f =      -769.25  |proj g|=         0.636
At iterate    41  f =      -769.27  |proj g|=       0.35051
At iterate    42  f =      -769.27  |proj g|=      0.019531
At iterate    43  f =      -769.27  |proj g|=      0.004181
At iterate    44  f =      -769.27  |proj g|=    0.00064719

iterations 44
function evaluations 52
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000647187
final function value -769.269

F = -769.269
final  value -769.268982 
converged
 
INFO  [08:34:16.386] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:34:16.474] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:34:16.481] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:34:27.413] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:34:37.387] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:34:45.358] [mlr3]  Finished benchmark 
INFO  [08:34:45.459] [bbotk] Result of batch 145: 
INFO  [08:34:45.461] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:34:45.461] [bbotk]              5.320761                 7.339225                       0.2791532 
INFO  [08:34:45.461] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [08:34:45.461] [bbotk]                     3829        1.041 -0.934303         <NA>   0.9767831 
INFO  [08:34:45.461] [bbotk]                                 uhash 
INFO  [08:34:45.461] [bbotk]  70bfea68-0646-4255-a6a4-ea1366554125 
DEBUG [08:34:46.893] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.678974e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.678974e-05 0.002076974 
  - best initial criterion value(s) :  709.0656 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -709.07  |proj g|=        8.157
At iterate     1  f =       -720.5  |proj g|=        1.4309
At iterate     2  f =      -731.53  |proj g|=        3.7427
At iterate     3  f =      -738.32  |proj g|=        3.3948
At iterate     4  f =      -741.97  |proj g|=         3.057
At iterate     5  f =      -743.79  |proj g|=        3.0162
At iterate     6  f =      -745.14  |proj g|=         3.143
At iterate     7  f =      -746.03  |proj g|=        5.2881
At iterate     8  f =      -747.07  |proj g|=         4.274
At iterate     9  f =      -747.23  |proj g|=        4.1515
At iterate    10  f =      -747.31  |proj g|=        4.3803
At iterate    11  f =      -747.32  |proj g|=        4.2692
At iterate    12  f =      -747.32  |proj g|=         4.255
At iterate    13  f =      -747.32  |proj g|=        4.2488
At iterate    14  f =      -747.32  |proj g|=        4.2444
At iterate    15  f =      -747.34  |proj g|=        4.2321
At iterate    16  f =      -747.36  |proj g|=        4.0746
At iterate    17  f =      -747.43  |proj g|=        4.1081
At iterate    18  f =      -747.57  |proj g|=        4.0596
At iterate    19  f =      -748.49  |proj g|=        3.6924
At iterate    20  f =      -750.33  |proj g|=        3.0038
At iterate    21  f =         -754  |proj g|=        1.9278
At iterate    22  f =      -762.35  |proj g|=         2.139
At iterate    23  f =      -770.96  |proj g|=        1.3601
At iterate    24  f =      -771.86  |proj g|=        1.3601
At iterate    25  f =      -772.07  |proj g|=          1.36
At iterate    26  f =      -772.16  |proj g|=          1.36
At iterate    27  f =      -772.16  |proj g|=          1.36
At iterate    28  f =      -772.16  |proj g|=          1.36
At iterate    29  f =      -772.16  |proj g|=          1.36

iterations 29
function evaluations 35
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.36004
final function value -772.157

F = -772.157
final  value -772.157227 
converged
 
INFO  [08:34:46.897] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:34:47.013] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:34:47.020] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:34:56.166] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:35:05.090] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:35:13.452] [mlr3]  Finished benchmark 
INFO  [08:35:13.553] [bbotk] Result of batch 146: 
INFO  [08:35:13.555] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:35:13.555] [bbotk]              3.709621                 7.120155                      0.09025562 
INFO  [08:35:13.555] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [08:35:13.555] [bbotk]                     3518        0.865 -0.939447         <NA>   0.9686875 
INFO  [08:35:13.555] [bbotk]                                 uhash 
INFO  [08:35:13.555] [bbotk]  cd06ac97-32cc-4f95-a8d3-1596d1a6f2cf 
DEBUG [08:35:14.951] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.669588e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.669588e-05 0.002068602 
  - best initial criterion value(s) :  691.1382 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -691.14  |proj g|=       8.1745
At iterate     1  f =       -731.7  |proj g|=         1.182
At iterate     2  f =      -747.76  |proj g|=        2.8804
At iterate     3  f =      -749.93  |proj g|=        3.8835
At iterate     4  f =      -753.05  |proj g|=        3.1369
At iterate     5  f =      -754.81  |proj g|=        2.4706
At iterate     6  f =      -755.19  |proj g|=        3.4774
At iterate     7  f =      -755.24  |proj g|=        3.3184
At iterate     8  f =      -755.24  |proj g|=        3.2562
At iterate     9  f =      -755.24  |proj g|=        3.2886
At iterate    10  f =      -755.24  |proj g|=        3.2876
At iterate    11  f =      -755.24  |proj g|=        3.2829
At iterate    12  f =      -755.25  |proj g|=        3.2758
At iterate    13  f =      -755.26  |proj g|=        3.2673
At iterate    14  f =      -755.28  |proj g|=        3.2506
At iterate    15  f =      -755.35  |proj g|=        3.2369
At iterate    16  f =      -755.52  |proj g|=        3.2416
At iterate    17  f =      -755.92  |proj g|=        3.2855
At iterate    18  f =       -756.8  |proj g|=        2.7802
At iterate    19  f =      -759.01  |proj g|=        2.6326
At iterate    20  f =      -759.19  |proj g|=       0.39878
At iterate    21  f =      -766.76  |proj g|=         2.616
At iterate    22  f =      -769.07  |proj g|=        3.5036
At iterate    23  f =      -769.15  |proj g|=        3.3744
At iterate    24  f =      -769.19  |proj g|=        3.1699
At iterate    25  f =      -769.19  |proj g|=        3.2109
At iterate    26  f =      -769.19  |proj g|=        3.2079
At iterate    27  f =      -769.19  |proj g|=        3.2071

iterations 27
function evaluations 29
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 3.2071
final function value -769.188

F = -769.188
final  value -769.188202 
converged
 
INFO  [08:35:14.955] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:35:15.075] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:35:15.082] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:35:19.463] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:35:25.556] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:35:29.639] [mlr3]  Finished benchmark 
INFO  [08:35:29.740] [bbotk] Result of batch 147: 
INFO  [08:35:29.742] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:35:29.742] [bbotk]               6.88458                 6.780352                       0.1787818 
INFO  [08:35:29.742] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:35:29.742] [bbotk]                     2158        0.876 -0.9472049         <NA>    0.973302 
INFO  [08:35:29.742] [bbotk]                                 uhash 
INFO  [08:35:29.742] [bbotk]  1f3758b1-c09b-499c-a22b-c1e64c74c6e6 
DEBUG [08:35:31.179] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.662353e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.662352e-05 0.002061876 
  - best initial criterion value(s) :  708.7243 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -708.72  |proj g|=       5.8629
At iterate     1  f =      -745.79  |proj g|=        4.3637
At iterate     2  f =      -752.04  |proj g|=        3.9039
At iterate     3  f =      -760.77  |proj g|=        2.5505
At iterate     4  f =       -761.2  |proj g|=        2.1304
At iterate     5  f =      -761.29  |proj g|=         2.039
At iterate     6  f =      -761.48  |proj g|=        1.8828
At iterate     7  f =       -761.5  |proj g|=        1.9701
At iterate     8  f =      -761.51  |proj g|=        1.9107
At iterate     9  f =      -761.51  |proj g|=        1.9054
At iterate    10  f =      -761.51  |proj g|=        1.9044
At iterate    11  f =      -761.51  |proj g|=        1.9038
At iterate    12  f =      -761.52  |proj g|=        1.9015
At iterate    13  f =      -761.54  |proj g|=        1.8706
At iterate    14  f =      -761.55  |proj g|=        1.9293
At iterate    15  f =       -761.6  |proj g|=        1.8718
At iterate    16  f =      -761.92  |proj g|=        1.7396
At iterate    17  f =      -764.19  |proj g|=        1.2753
At iterate    18  f =      -767.83  |proj g|=        1.0322
At iterate    19  f =      -768.42  |proj g|=       0.97171
At iterate    20  f =      -768.45  |proj g|=       0.89523
At iterate    21  f =      -768.45  |proj g|=       0.88639
At iterate    22  f =      -768.45  |proj g|=        0.8866

iterations 22
function evaluations 32
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.886601
final function value -768.454

F = -768.454
final  value -768.454095 
converged
 
INFO  [08:35:31.184] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:35:31.301] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:35:31.308] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:35:34.416] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:35:37.736] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:35:42.030] [mlr3]  Finished benchmark 
INFO  [08:35:42.134] [bbotk] Result of batch 148: 
INFO  [08:35:42.136] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:35:42.136] [bbotk]              6.624863                 5.907719                       0.4596069 
INFO  [08:35:42.136] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:35:42.136] [bbotk]                     1199        0.888 -0.9473809         <NA>   0.9749257 
INFO  [08:35:42.136] [bbotk]                                 uhash 
INFO  [08:35:42.136] [bbotk]  f0623a8a-51b0-41c2-b6c1-03d26daba219 
DEBUG [08:35:44.062] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.656449e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.656449e-05 0.002044846 
  - best initial criterion value(s) :  738.9063 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -738.91  |proj g|=       4.9393
At iterate     1  f =      -763.04  |proj g|=        4.6745
At iterate     2  f =      -769.17  |proj g|=        3.9487
At iterate     3  f =       -775.7  |proj g|=        2.4218
At iterate     4  f =      -776.96  |proj g|=        1.4911
At iterate     5  f =      -780.24  |proj g|=        1.4634
At iterate     6  f =      -784.42  |proj g|=        1.4015
At iterate     7  f =       -786.1  |proj g|=        1.3244
At iterate     8  f =      -787.03  |proj g|=        1.2304
At iterate     9  f =      -787.46  |proj g|=        1.2257
At iterate    10  f =      -787.59  |proj g|=        1.2967
At iterate    11  f =      -787.74  |proj g|=        1.2709
At iterate    12  f =      -787.77  |proj g|=        1.2586
At iterate    13  f =      -787.78  |proj g|=        1.2557
At iterate    14  f =      -787.78  |proj g|=        1.2553
At iterate    15  f =      -787.78  |proj g|=        1.2552
At iterate    16  f =      -787.78  |proj g|=        1.2549
At iterate    17  f =      -787.78  |proj g|=        1.2544
At iterate    18  f =      -787.78  |proj g|=        1.2534
At iterate    19  f =      -787.78  |proj g|=        1.2517
At iterate    20  f =      -787.78  |proj g|=        1.2479
At iterate    21  f =      -787.79  |proj g|=         1.242
At iterate    22  f =      -787.81  |proj g|=        1.2348
At iterate    23  f =      -787.85  |proj g|=        1.2251
At iterate    24  f =      -787.86  |proj g|=        1.2242
At iterate    25  f =      -788.03  |proj g|=        1.1897
At iterate    26  f =      -788.26  |proj g|=        1.1747
At iterate    27  f =      -789.06  |proj g|=        1.1724
At iterate    28  f =      -789.73  |proj g|=         1.169
At iterate    29  f =      -789.89  |proj g|=         1.168
At iterate    30  f =      -789.92  |proj g|=        1.1684
At iterate    31  f =      -789.92  |proj g|=        1.1683
At iterate    32  f =      -789.93  |proj g|=        1.1683
At iterate    33  f =      -789.93  |proj g|=        1.1683
At iterate    34  f =      -789.93  |proj g|=        1.1683
At iterate    35  f =      -789.93  |proj g|=        1.1682
At iterate    36  f =      -789.93  |proj g|=         1.168
At iterate    37  f =      -789.93  |proj g|=        1.1673
At iterate    38  f =      -789.93  |proj g|=        1.1656
At iterate    39  f =      -789.93  |proj g|=         1.161
At iterate    40  f =      -789.94  |proj g|=        1.1485
At iterate    41  f =      -789.97  |proj g|=        1.1162
At iterate    42  f =      -790.04  |proj g|=        1.0414
At iterate    43  f =      -790.15  |proj g|=       0.91612
At iterate    44  f =      -790.18  |proj g|=        0.8706
At iterate    45  f =       -790.2  |proj g|=       0.87906
At iterate    46  f =      -790.21  |proj g|=       0.87491
At iterate    47  f =      -790.27  |proj g|=       0.84567
At iterate    48  f =      -790.42  |proj g|=        0.7527
At iterate    49  f =       -790.8  |proj g|=       0.46947
At iterate    50  f =         -791  |proj g|=       0.45205
At iterate    51  f =      -791.94  |proj g|=       0.36245
At iterate    52  f =      -791.96  |proj g|=        0.3606
At iterate    53  f =      -791.96  |proj g|=       0.35933
At iterate    54  f =      -791.96  |proj g|=       0.35854
At iterate    55  f =      -791.97  |proj g|=       0.63258
At iterate    56  f =      -791.97  |proj g|=       0.63558
At iterate    57  f =      -791.97  |proj g|=       0.35145
At iterate    58  f =      -791.97  |proj g|=       0.00921
At iterate    59  f =      -791.97  |proj g|=     0.0022093

iterations 59
function evaluations 68
segments explored during Cauchy searches 61
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00220927
final function value -791.973

F = -791.973
final  value -791.972756 
converged
 
INFO  [08:35:44.066] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:35:44.154] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:35:44.161] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:35:47.608] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:35:51.214] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:35:54.549] [mlr3]  Finished benchmark 
INFO  [08:35:54.668] [bbotk] Result of batch 149: 
INFO  [08:35:54.669] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:35:54.669] [bbotk]              7.085822                 6.647618                     0.005320183 
INFO  [08:35:54.669] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:35:54.669] [bbotk]                     1614        0.869 -0.9390633         <NA>   0.9186124 
INFO  [08:35:54.669] [bbotk]                                 uhash 
INFO  [08:35:54.669] [bbotk]  b025ce28-766b-4bc0-a4ce-9c91b2477c62 
DEBUG [08:35:56.054] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.777957e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.777957e-05 0.002152136 
  - best initial criterion value(s) :  717.0727 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -717.07  |proj g|=       11.682
At iterate     1  f =      -727.36  |proj g|=        4.8026
At iterate     2  f =      -730.63  |proj g|=        5.2117
At iterate     3  f =      -745.12  |proj g|=        7.9505
At iterate     4  f =      -751.41  |proj g|=        6.9663
At iterate     5  f =      -762.72  |proj g|=        3.9064
At iterate     6  f =       -766.5  |proj g|=         2.816
At iterate     7  f =      -771.23  |proj g|=         4.318
At iterate     8  f =      -776.74  |proj g|=        3.9419
At iterate     9  f =       -777.4  |proj g|=        3.4819
At iterate    10  f =      -777.42  |proj g|=        3.6098
At iterate    11  f =      -777.45  |proj g|=        3.5095
At iterate    12  f =      -777.45  |proj g|=        3.5302
At iterate    13  f =      -777.45  |proj g|=        3.5245
At iterate    14  f =      -777.45  |proj g|=        3.5245

iterations 14
function evaluations 25
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 3.52449
final function value -777.451

F = -777.451
final  value -777.450895 
converged
 
INFO  [08:35:56.058] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:35:56.148] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:35:56.155] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:35:58.197] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:36:00.597] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:36:03.213] [mlr3]  Finished benchmark 
INFO  [08:36:03.333] [bbotk] Result of batch 150: 
INFO  [08:36:03.335] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:36:03.335] [bbotk]              6.109895                 6.563135                       0.2242414 
INFO  [08:36:03.335] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:36:03.335] [bbotk]                      872        0.878 -0.9525877         <NA>    0.968572 
INFO  [08:36:03.335] [bbotk]                                 uhash 
INFO  [08:36:03.335] [bbotk]  5b41954c-6d0f-4e13-8dd0-8301d7a7c98c 
DEBUG [08:36:05.076] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.768241e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.768241e-05 0.002129071 
  - best initial criterion value(s) :  751.7457 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -751.75  |proj g|=       4.7349
At iterate     1  f =      -773.13  |proj g|=        5.9931
At iterate     2  f =      -773.31  |proj g|=        5.3815
At iterate     3  f =      -773.64  |proj g|=        5.3131
At iterate     4  f =      -774.32  |proj g|=        5.2613
At iterate     5  f =      -774.38  |proj g|=        5.7527
At iterate     6  f =      -774.39  |proj g|=        5.6198
At iterate     7  f =      -774.39  |proj g|=        5.6308
At iterate     8  f =      -774.39  |proj g|=        5.6294
At iterate     9  f =      -774.39  |proj g|=        5.6268
At iterate    10  f =      -774.39  |proj g|=        5.6222
At iterate    11  f =      -774.39  |proj g|=        5.6115
At iterate    12  f =      -774.39  |proj g|=        5.5947
At iterate    13  f =       -774.4  |proj g|=        5.5692
At iterate    14  f =      -774.41  |proj g|=        5.5385
At iterate    15  f =      -774.45  |proj g|=         5.496
At iterate    16  f =      -774.56  |proj g|=        5.4437
At iterate    17  f =      -774.83  |proj g|=        5.3234
At iterate    18  f =      -775.54  |proj g|=        5.3354
At iterate    19  f =      -775.71  |proj g|=        4.6902
At iterate    20  f =      -777.69  |proj g|=        4.4515
At iterate    21  f =      -786.72  |proj g|=        3.1237
At iterate    22  f =      -788.11  |proj g|=        2.7834
At iterate    23  f =      -790.01  |proj g|=         2.699
At iterate    24  f =       -790.2  |proj g|=         2.808
At iterate    25  f =      -790.25  |proj g|=        3.0373
At iterate    26  f =      -790.26  |proj g|=        2.9813
At iterate    27  f =      -790.26  |proj g|=        2.9709
At iterate    28  f =      -790.26  |proj g|=        2.9715
At iterate    29  f =      -790.26  |proj g|=        2.9718
At iterate    30  f =      -790.26  |proj g|=        2.9734
At iterate    31  f =      -790.26  |proj g|=        2.9753
At iterate    32  f =      -790.26  |proj g|=        2.9787
At iterate    33  f =      -790.26  |proj g|=        2.9837
At iterate    34  f =      -790.26  |proj g|=          2.99
At iterate    35  f =      -790.26  |proj g|=        3.0108
At iterate    36  f =      -790.27  |proj g|=          3.02
At iterate    37  f =      -790.27  |proj g|=        3.1486
At iterate    38  f =       -790.3  |proj g|=        3.0882
At iterate    39  f =      -790.35  |proj g|=        3.0012
At iterate    40  f =       -790.5  |proj g|=        2.8435
At iterate    41  f =      -790.86  |proj g|=        2.5783
At iterate    42  f =      -791.66  |proj g|=        2.1593
At iterate    43  f =      -793.26  |proj g|=        1.2072
At iterate    44  f =      -795.71  |proj g|=       0.54095
At iterate    45  f =      -796.17  |proj g|=       0.82048
At iterate    46  f =      -799.47  |proj g|=       0.35189
At iterate    47  f =      -800.27  |proj g|=        0.6812
At iterate    48  f =      -800.31  |proj g|=       0.31916
At iterate    49  f =      -800.32  |proj g|=       0.31923
At iterate    50  f =      -800.32  |proj g|=     0.0027268
At iterate    51  f =      -800.32  |proj g|=     0.0027277

iterations 51
function evaluations 61
segments explored during Cauchy searches 54
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00272767
final function value -800.317

F = -800.317
final  value -800.317439 
converged
 
INFO  [08:36:05.081] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:36:05.170] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:36:05.178] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:36:16.057] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:36:26.073] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:36:35.230] [mlr3]  Finished benchmark 
INFO  [08:36:35.336] [bbotk] Result of batch 151: 
INFO  [08:36:35.338] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:36:35.338] [bbotk]              4.313697                 9.966152                       0.2570977 
INFO  [08:36:35.338] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [08:36:35.338] [bbotk]                     4218        0.899 -0.938687         <NA>   0.9762013 
INFO  [08:36:35.338] [bbotk]                                 uhash 
INFO  [08:36:35.338] [bbotk]  b742d2d6-58a3-47ff-9c82-c01ca18545b1 
DEBUG [08:36:37.150] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.763259e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.763259e-05 0.002127615 
  - best initial criterion value(s) :  745.0845 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -745.08  |proj g|=       5.7398
At iterate     1  f =      -755.12  |proj g|=        5.4166
At iterate     2  f =      -765.53  |proj g|=        4.7131
At iterate     3  f =      -782.56  |proj g|=        2.8059
At iterate     4  f =      -783.97  |proj g|=         2.452
At iterate     5  f =      -785.57  |proj g|=        2.2237
At iterate     6  f =      -789.41  |proj g|=        1.9289
At iterate     7  f =      -789.63  |proj g|=        2.6112
At iterate     8  f =       -792.1  |proj g|=         2.203
At iterate     9  f =      -792.44  |proj g|=        2.0834
At iterate    10  f =       -792.5  |proj g|=        2.0783
At iterate    11  f =      -792.53  |proj g|=         2.114
At iterate    12  f =      -792.53  |proj g|=        2.1398
At iterate    13  f =      -792.54  |proj g|=        2.1459
At iterate    14  f =      -792.54  |proj g|=        2.1465
At iterate    15  f =      -792.54  |proj g|=        2.1495
At iterate    16  f =      -792.54  |proj g|=        2.1533
At iterate    17  f =      -792.54  |proj g|=          2.16
At iterate    18  f =      -792.54  |proj g|=        2.1705
At iterate    19  f =      -792.54  |proj g|=        2.1879
At iterate    20  f =      -792.56  |proj g|=        2.2158
At iterate    21  f =      -792.59  |proj g|=        2.2589
At iterate    22  f =      -792.66  |proj g|=        2.3143
At iterate    23  f =       -792.8  |proj g|=        2.3443
At iterate    24  f =      -792.89  |proj g|=        2.2139
At iterate    25  f =      -792.91  |proj g|=        2.2448
At iterate    26  f =      -792.94  |proj g|=        2.2482
At iterate    27  f =      -793.25  |proj g|=         2.302
At iterate    28  f =      -793.25  |proj g|=        2.3348
At iterate    29  f =      -793.25  |proj g|=        2.3415
At iterate    30  f =      -793.25  |proj g|=        2.3446
At iterate    31  f =      -793.25  |proj g|=        2.3416
At iterate    32  f =      -793.25  |proj g|=        2.3436
At iterate    33  f =      -793.25  |proj g|=        2.3479
At iterate    34  f =      -793.26  |proj g|=        2.3622
At iterate    35  f =      -793.26  |proj g|=        2.3812
At iterate    36  f =      -793.28  |proj g|=        2.4145
At iterate    37  f =      -793.32  |proj g|=        2.4626
At iterate    38  f =       -793.4  |proj g|=        2.5242
At iterate    39  f =      -793.54  |proj g|=        2.5641
At iterate    40  f =      -793.63  |proj g|=         2.442
At iterate    41  f =      -793.65  |proj g|=        2.4639
At iterate    42  f =      -793.66  |proj g|=        2.4653
At iterate    43  f =      -793.66  |proj g|=        2.4646
At iterate    44  f =      -793.66  |proj g|=        2.4647

iterations 44
function evaluations 54
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.46469
final function value -793.655

F = -793.655
final  value -793.655354 
converged
 
INFO  [08:36:37.154] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:36:37.244] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:36:37.252] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:36:42.929] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:36:51.877] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:37:00.643] [mlr3]  Finished benchmark 
INFO  [08:37:00.749] [bbotk] Result of batch 152: 
INFO  [08:37:00.751] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:37:00.751] [bbotk]              5.173645                 7.450903                       0.1914984 
INFO  [08:37:00.751] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:37:00.751] [bbotk]                     2704        0.873 -0.9443373         <NA>    0.973926 
INFO  [08:37:00.751] [bbotk]                                 uhash 
INFO  [08:37:00.751] [bbotk]  f4a811e5-3434-4b86-8798-b97050892f34 
DEBUG [08:37:02.256] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.756254e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.756254e-05 0.002127206 
  - best initial criterion value(s) :  759.7534 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -759.75  |proj g|=       3.2183
At iterate     1  f =      -782.58  |proj g|=        4.2354
At iterate     2  f =      -783.14  |proj g|=        3.9182
At iterate     3  f =      -783.83  |proj g|=        2.9443
At iterate     4  f =      -784.01  |proj g|=        3.0518
At iterate     5  f =      -786.17  |proj g|=        3.5366
At iterate     6  f =       -789.6  |proj g|=        3.5223
At iterate     7  f =      -792.83  |proj g|=        2.7851
At iterate     8  f =      -793.61  |proj g|=        2.2751
At iterate     9  f =      -793.68  |proj g|=        2.1311
At iterate    10  f =       -793.7  |proj g|=        2.2264
At iterate    11  f =       -793.7  |proj g|=        2.1898
At iterate    12  f =       -793.7  |proj g|=        2.1889
At iterate    13  f =       -793.7  |proj g|=        2.1874
At iterate    14  f =      -793.71  |proj g|=        2.1824
At iterate    15  f =      -793.71  |proj g|=         2.176
At iterate    16  f =      -793.71  |proj g|=         2.115
At iterate    17  f =      -793.73  |proj g|=        2.1375
At iterate    18  f =      -793.83  |proj g|=        2.1342
At iterate    19  f =      -794.12  |proj g|=        2.0741
At iterate    20  f =      -795.09  |proj g|=        1.9041
At iterate    21  f =      -796.38  |proj g|=        2.2068
At iterate    22  f =      -796.67  |proj g|=        2.1083
At iterate    23  f =      -797.71  |proj g|=        2.4139
At iterate    24  f =      -799.24  |proj g|=        2.3819
At iterate    25  f =      -799.29  |proj g|=        2.2839
At iterate    26  f =       -799.3  |proj g|=         2.269
At iterate    27  f =       -799.3  |proj g|=        2.2711
At iterate    28  f =       -799.3  |proj g|=        2.2714

iterations 28
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.27139
final function value -799.296

F = -799.296
final  value -799.295759 
converged
 
INFO  [08:37:02.260] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:37:02.729] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:37:02.741] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:37:07.848] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:37:14.027] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:37:19.713] [mlr3]  Finished benchmark 
INFO  [08:37:19.821] [bbotk] Result of batch 153: 
INFO  [08:37:19.823] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:37:19.823] [bbotk]              7.769056                 7.231226                       0.4558429 
INFO  [08:37:19.823] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:37:19.823] [bbotk]                     2642        0.894 -0.9454052         <NA>   0.9780091 
INFO  [08:37:19.823] [bbotk]                                 uhash 
INFO  [08:37:19.823] [bbotk]  d2b3e83f-5ab0-45a9-aaed-cc905305126a 
DEBUG [08:37:21.523] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.753296e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.753296e-05 0.002127026 
  - best initial criterion value(s) :  707.8851 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -707.89  |proj g|=        6.921
At iterate     1  f =      -751.84  |proj g|=         10.58
At iterate     2  f =      -752.76  |proj g|=        10.646
At iterate     3  f =      -754.49  |proj g|=        10.671
At iterate     4  f =      -754.93  |proj g|=        10.593
At iterate     5  f =      -755.41  |proj g|=        10.286
At iterate     6  f =      -755.77  |proj g|=         9.286
At iterate     7  f =      -755.77  |proj g|=        9.3223
At iterate     8  f =      -755.77  |proj g|=         9.319
At iterate     9  f =      -755.77  |proj g|=        9.3062
At iterate    10  f =      -755.77  |proj g|=        9.2896
At iterate    11  f =      -755.78  |proj g|=        9.2594
At iterate    12  f =      -755.78  |proj g|=        9.2103
At iterate    13  f =      -755.79  |proj g|=         9.127
At iterate    14  f =      -755.82  |proj g|=        8.9885
At iterate    15  f =      -755.89  |proj g|=        8.7699
At iterate    16  f =      -756.05  |proj g|=        8.4377
At iterate    17  f =      -756.47  |proj g|=        7.9146
At iterate    18  f =      -756.56  |proj g|=        7.6459
At iterate    19  f =      -757.48  |proj g|=        7.0542
At iterate    20  f =      -762.06  |proj g|=        5.6944
At iterate    21  f =      -765.69  |proj g|=        4.8978
At iterate    22  f =      -767.86  |proj g|=        6.0567
At iterate    23  f =      -768.42  |proj g|=        5.5053
At iterate    24  f =      -768.47  |proj g|=        5.7624
At iterate    25  f =       -768.5  |proj g|=        5.6182
At iterate    26  f =      -768.51  |proj g|=        5.6395
At iterate    27  f =      -768.51  |proj g|=        5.6322
At iterate    28  f =      -768.51  |proj g|=        5.6329

iterations 28
function evaluations 33
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 5.6329
final function value -768.507

F = -768.507
final  value -768.506503 
converged
 
INFO  [08:37:21.533] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:37:21.673] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:37:21.681] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:37:32.562] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:37:42.265] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:37:51.533] [mlr3]  Finished benchmark 
INFO  [08:37:51.676] [bbotk] Result of batch 154: 
INFO  [08:37:51.678] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:37:51.678] [bbotk]              4.826971                 3.903293                       0.4007143 
INFO  [08:37:51.678] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:37:51.678] [bbotk]                     3955        1.101 -0.9532812         <NA>    0.977511 
INFO  [08:37:51.678] [bbotk]                                 uhash 
INFO  [08:37:51.678] [bbotk]  6df22db3-3f03-4a08-be8b-a8a9821f64ca 
DEBUG [08:37:53.150] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.749719e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.749719e-05 0.002127889 
  - best initial criterion value(s) :  752.8302 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -752.83  |proj g|=       5.5065
At iterate     1  f =      -756.35  |proj g|=        2.9585
At iterate     2  f =      -756.64  |proj g|=        3.2125
At iterate     3  f =      -757.39  |proj g|=        3.7335
At iterate     4  f =      -757.41  |proj g|=         3.648
At iterate     5  f =      -757.41  |proj g|=        3.6401
At iterate     6  f =      -757.42  |proj g|=          3.63
At iterate     7  f =      -757.43  |proj g|=        3.5872
At iterate     8  f =      -757.43  |proj g|=        3.5952
At iterate     9  f =      -757.48  |proj g|=        3.5148
At iterate    10  f =      -757.58  |proj g|=        3.3827
At iterate    11  f =      -757.87  |proj g|=        3.1432
At iterate    12  f =      -758.55  |proj g|=        2.7454
At iterate    13  f =      -760.14  |proj g|=        2.1323
At iterate    14  f =      -760.21  |proj g|=        2.0193
At iterate    15  f =      -763.53  |proj g|=        1.4295
At iterate    16  f =      -767.79  |proj g|=       0.79531
At iterate    17  f =      -769.08  |proj g|=       0.77578
At iterate    18  f =      -769.84  |proj g|=       0.75115
At iterate    19  f =      -769.92  |proj g|=       0.42054
At iterate    20  f =      -769.93  |proj g|=       0.74316
At iterate    21  f =      -769.93  |proj g|=       0.51153
At iterate    22  f =      -769.93  |proj g|=       0.51555
At iterate    23  f =      -769.93  |proj g|=       0.51566

iterations 23
function evaluations 31
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.515657
final function value -769.929

F = -769.929
final  value -769.929250 
converged
 
INFO  [08:37:53.155] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:37:53.262] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:37:53.269] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:37:57.131] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:38:01.469] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:38:05.848] [mlr3]  Finished benchmark 
INFO  [08:38:05.980] [bbotk] Result of batch 155: 
INFO  [08:38:05.982] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:38:05.982] [bbotk]              8.532572                 6.268038                       0.3512846 
INFO  [08:38:05.982] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:38:05.982] [bbotk]                     1974        0.902 -0.9574077         <NA>   0.9764474 
INFO  [08:38:05.982] [bbotk]                                 uhash 
INFO  [08:38:05.982] [bbotk]  00745679-4ea8-4206-a567-61d46b20c9e1 
DEBUG [08:38:07.850] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.744986e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.744985e-05 0.002116876 
  - best initial criterion value(s) :  777.8383 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -777.84  |proj g|=       1.6454
At iterate     1  f =       -787.1  |proj g|=        11.736
At iterate     2  f =      -790.75  |proj g|=        10.665
At iterate     3  f =      -791.97  |proj g|=        6.3562
At iterate     4  f =      -792.49  |proj g|=        8.2912
At iterate     5  f =      -792.54  |proj g|=        8.0224
At iterate     6  f =      -792.61  |proj g|=        7.7098
At iterate     7  f =      -792.79  |proj g|=        7.2926
At iterate     8  f =      -793.13  |proj g|=        6.8658
At iterate     9  f =      -793.51  |proj g|=         7.145
At iterate    10  f =      -793.59  |proj g|=        7.3145
At iterate    11  f =       -793.6  |proj g|=        7.4078
At iterate    12  f =       -793.6  |proj g|=        7.4295
At iterate    13  f =       -793.6  |proj g|=        7.4309
At iterate    14  f =       -793.6  |proj g|=        7.4341
At iterate    15  f =       -793.6  |proj g|=        7.4396
At iterate    16  f =       -793.6  |proj g|=        7.4473
At iterate    17  f =       -793.6  |proj g|=        7.4595
At iterate    18  f =       -793.6  |proj g|=        7.4737
At iterate    19  f =      -793.61  |proj g|=        7.4796
At iterate    20  f =      -793.62  |proj g|=        7.4846
At iterate    21  f =      -793.64  |proj g|=        7.4252
At iterate    22  f =      -793.64  |proj g|=        7.5385
At iterate    23  f =      -793.69  |proj g|=        7.4275
At iterate    24  f =      -794.41  |proj g|=        7.1015
At iterate    25  f =      -804.07  |proj g|=        5.1107
At iterate    26  f =       -807.2  |proj g|=        5.6998
At iterate    27  f =      -808.04  |proj g|=        5.4475
At iterate    28  f =      -808.24  |proj g|=         4.934
At iterate    29  f =      -808.27  |proj g|=        4.7239
At iterate    30  f =      -808.31  |proj g|=        4.8683
At iterate    31  f =      -808.31  |proj g|=        4.8472
At iterate    32  f =      -808.31  |proj g|=        4.8467
At iterate    33  f =      -808.31  |proj g|=        4.8429
At iterate    34  f =      -808.31  |proj g|=        4.8386
At iterate    35  f =      -808.31  |proj g|=        4.8282
At iterate    36  f =      -808.31  |proj g|=          4.81
At iterate    37  f =      -808.33  |proj g|=        4.7916
At iterate    38  f =      -808.33  |proj g|=        4.6675
At iterate    39  f =      -808.37  |proj g|=        4.6674
At iterate    40  f =      -808.51  |proj g|=        4.6358
At iterate    41  f =      -808.95  |proj g|=         4.528
At iterate    42  f =      -811.28  |proj g|=        3.9375
At iterate    43  f =      -817.84  |proj g|=         3.155
At iterate    44  f =      -818.29  |proj g|=        2.4979
At iterate    45  f =      -826.99  |proj g|=       0.72269
At iterate    46  f =      -828.12  |proj g|=       0.32677
At iterate    47  f =      -828.27  |proj g|=       0.31477
At iterate    48  f =       -828.3  |proj g|=       0.31399
At iterate    49  f =      -828.31  |proj g|=       0.67197
At iterate    50  f =      -828.32  |proj g|=      0.090858
At iterate    51  f =      -828.32  |proj g|=      0.035123
At iterate    52  f =      -828.32  |proj g|=     0.0023348

iterations 52
function evaluations 67
segments explored during Cauchy searches 55
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00233476
final function value -828.316

F = -828.316
final  value -828.316023 
converged
 
INFO  [08:38:07.854] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:38:07.946] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:38:07.953] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:38:09.740] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:38:12.893] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:38:15.439] [mlr3]  Finished benchmark 
INFO  [08:38:15.607] [bbotk] Result of batch 156: 
INFO  [08:38:15.609] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:38:15.609] [bbotk]              2.069749                 9.742519                       0.2786151 
INFO  [08:38:15.609] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:38:15.609] [bbotk]                      656        0.912 -0.9388872         <NA>   0.9481791 
INFO  [08:38:15.609] [bbotk]                                 uhash 
INFO  [08:38:15.609] [bbotk]  382f7379-6567-422f-a466-b74aff66d3f1 
DEBUG [08:38:17.321] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.754797e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.754797e-05 0.00213107 
  - best initial criterion value(s) :  753.4425 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -753.44  |proj g|=       7.9106
At iterate     1  f =      -768.16  |proj g|=        9.2686
At iterate     2  f =       -781.9  |proj g|=        6.0625
At iterate     3  f =      -785.55  |proj g|=        4.6834
At iterate     4  f =      -795.29  |proj g|=        3.6122
At iterate     5  f =      -795.68  |proj g|=        3.5457
At iterate     6  f =      -795.71  |proj g|=        3.5105
At iterate     7  f =      -795.71  |proj g|=        3.5207
At iterate     8  f =      -795.71  |proj g|=        3.5196
At iterate     9  f =      -795.71  |proj g|=         3.519
At iterate    10  f =      -795.71  |proj g|=        3.5168
At iterate    11  f =      -795.71  |proj g|=        3.5131
At iterate    12  f =      -795.71  |proj g|=        3.5055
At iterate    13  f =      -795.72  |proj g|=        3.4362
At iterate    14  f =      -795.73  |proj g|=        3.4484
At iterate    15  f =      -795.78  |proj g|=        3.4706
At iterate    16  f =      -795.91  |proj g|=        3.5054
At iterate    17  f =      -796.24  |proj g|=        3.5589
At iterate    18  f =      -797.09  |proj g|=        3.6353
At iterate    19  f =      -799.24  |proj g|=        3.6131
At iterate    20  f =       -804.8  |proj g|=        3.6992
At iterate    21  f =      -811.02  |proj g|=        2.7596
At iterate    22  f =      -816.53  |proj g|=        2.8029
At iterate    23  f =      -817.17  |proj g|=         2.611
At iterate    24  f =      -817.31  |proj g|=        2.6877
At iterate    25  f =      -817.31  |proj g|=        2.7265
At iterate    26  f =      -817.32  |proj g|=        2.7261
At iterate    27  f =      -817.32  |proj g|=        2.7274
At iterate    28  f =      -817.32  |proj g|=        2.7273

iterations 28
function evaluations 34
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.72735
final function value -817.315

F = -817.315
final  value -817.315044 
converged
 
INFO  [08:38:17.326] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:38:17.421] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:38:17.428] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:38:19.888] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:38:22.469] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:38:27.319] [mlr3]  Finished benchmark 
INFO  [08:38:27.418] [bbotk] Result of batch 157: 
INFO  [08:38:27.420] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:38:27.420] [bbotk]              3.482599                 9.895719                       0.1752251 
INFO  [08:38:27.420] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:38:27.420] [bbotk]                     1136        1.092 -0.9513397         <NA>   0.9630162 
INFO  [08:38:27.420] [bbotk]                                 uhash 
INFO  [08:38:27.420] [bbotk]  f54cd6f3-d8ef-409c-b27d-5dcde35d0312 
DEBUG [08:38:29.202] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.746267e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.746267e-05 0.002115435 
  - best initial criterion value(s) :  789.8878 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -789.89  |proj g|=       5.4289
At iterate     1  f =      -791.31  |proj g|=        8.3937
At iterate     2  f =      -795.36  |proj g|=        4.0654
At iterate     3  f =      -798.76  |proj g|=        6.1904
At iterate     4  f =      -802.98  |proj g|=         6.102
At iterate     5  f =      -803.28  |proj g|=        5.7576
At iterate     6  f =      -803.31  |proj g|=        6.1657
At iterate     7  f =      -803.34  |proj g|=        6.0105
At iterate     8  f =      -803.34  |proj g|=        6.0089
At iterate     9  f =      -803.34  |proj g|=        6.0107
At iterate    10  f =      -803.34  |proj g|=        6.0121
At iterate    11  f =      -803.34  |proj g|=        6.0141
At iterate    12  f =      -803.34  |proj g|=        6.0176
At iterate    13  f =      -803.34  |proj g|=        6.0226
At iterate    14  f =      -803.34  |proj g|=        6.0287
At iterate    15  f =      -803.34  |proj g|=        6.0338
At iterate    16  f =      -803.34  |proj g|=        6.0362
At iterate    17  f =      -803.35  |proj g|=        6.0317
At iterate    18  f =      -803.37  |proj g|=        6.0186
At iterate    19  f =      -803.41  |proj g|=        5.8536
At iterate    20  f =      -803.48  |proj g|=        5.9001
At iterate    21  f =      -803.65  |proj g|=        5.8383
At iterate    22  f =      -805.01  |proj g|=        5.2047
At iterate    23  f =      -805.37  |proj g|=        4.4774
At iterate    24  f =      -808.44  |proj g|=        3.5294
At iterate    25  f =      -819.16  |proj g|=        1.8786
At iterate    26  f =      -819.42  |proj g|=        1.4996
At iterate    27  f =      -819.42  |proj g|=        1.4208
At iterate    28  f =      -819.42  |proj g|=        1.4336
At iterate    29  f =      -819.42  |proj g|=        1.4365
At iterate    30  f =      -819.42  |proj g|=        1.4351
At iterate    31  f =      -819.42  |proj g|=        1.4338
At iterate    32  f =      -819.42  |proj g|=        1.4325
At iterate    33  f =      -819.42  |proj g|=        1.4298
At iterate    34  f =      -819.42  |proj g|=        1.4265
At iterate    35  f =      -819.42  |proj g|=        1.4224
At iterate    36  f =      -819.43  |proj g|=        1.4182
At iterate    37  f =      -819.43  |proj g|=        1.4089
At iterate    38  f =      -819.45  |proj g|=        1.3603
At iterate    39  f =      -819.54  |proj g|=        1.2427
At iterate    40  f =      -819.85  |proj g|=       0.94017
At iterate    41  f =      -819.94  |proj g|=        0.7306
At iterate    42  f =      -820.54  |proj g|=       0.72877
At iterate    43  f =      -821.18  |proj g|=       0.71205
At iterate    44  f =      -821.47  |proj g|=       0.69266
At iterate    45  f =      -821.53  |proj g|=       0.68245
At iterate    46  f =      -821.54  |proj g|=      0.068337
At iterate    47  f =      -821.54  |proj g|=       0.67914
At iterate    48  f =      -821.54  |proj g|=      0.058846
At iterate    49  f =      -821.54  |proj g|=      0.063942
At iterate    50  f =      -821.54  |proj g|=      0.019329
At iterate    51  f =      -821.54  |proj g|=      0.019328

iterations 51
function evaluations 61
segments explored during Cauchy searches 54
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0193278
final function value -821.538

F = -821.538
final  value -821.537981 
converged
 
INFO  [08:38:29.207] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:38:29.307] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:38:29.314] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:38:31.022] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:38:32.791] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:38:34.777] [mlr3]  Finished benchmark 
INFO  [08:38:34.876] [bbotk] Result of batch 158: 
INFO  [08:38:34.878] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:38:34.878] [bbotk]              9.630152                 6.372909                       0.2688947 
INFO  [08:38:34.878] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:38:34.878] [bbotk]                      535        0.893 -0.9480889         <NA>   0.9673429 
INFO  [08:38:34.878] [bbotk]                                 uhash 
INFO  [08:38:34.878] [bbotk]  27b0c868-2923-4930-9538-79a0b17fadbc 
DEBUG [08:38:36.862] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.736985e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.736985e-05 0.00209174 
  - best initial criterion value(s) :  755.7408 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -755.74  |proj g|=       6.4033
At iterate     1  f =      -770.12  |proj g|=        2.9918
At iterate     2  f =      -787.14  |proj g|=        3.4739
At iterate     3  f =       -793.6  |proj g|=        3.1568
At iterate     4  f =      -798.95  |proj g|=        2.7813
At iterate     5  f =      -801.16  |proj g|=        2.8859
At iterate     6  f =      -802.76  |proj g|=        3.1314
At iterate     7  f =       -803.9  |proj g|=         5.395
At iterate     8  f =      -804.76  |proj g|=        4.5664
At iterate     9  f =       -804.9  |proj g|=        4.5287
At iterate    10  f =      -804.96  |proj g|=        4.6488
At iterate    11  f =      -804.97  |proj g|=        4.7164
At iterate    12  f =      -804.97  |proj g|=         4.734
At iterate    13  f =      -804.97  |proj g|=        4.7359
At iterate    14  f =      -804.97  |proj g|=        4.7431
At iterate    15  f =      -804.97  |proj g|=        4.7505
At iterate    16  f =      -804.97  |proj g|=        4.7601
At iterate    17  f =      -804.97  |proj g|=        4.7707
At iterate    18  f =      -804.98  |proj g|=        4.7779
At iterate    19  f =         -805  |proj g|=        4.7598
At iterate    20  f =      -805.01  |proj g|=        4.9035
At iterate    21  f =      -805.07  |proj g|=        4.8163
At iterate    22  f =      -805.33  |proj g|=        4.6097
At iterate    23  f =      -806.35  |proj g|=        4.1079
At iterate    24  f =      -809.72  |proj g|=        3.0126
At iterate    25  f =      -811.97  |proj g|=        2.7581
At iterate    26  f =      -834.94  |proj g|=        1.3198
At iterate    27  f =      -838.54  |proj g|=        2.1161
At iterate    28  f =      -843.09  |proj g|=        1.7317
At iterate    29  f =      -843.51  |proj g|=         1.238
At iterate    30  f =      -843.52  |proj g|=        1.3331
At iterate    31  f =      -843.52  |proj g|=        1.3099
At iterate    32  f =      -843.52  |proj g|=        1.3045
At iterate    33  f =      -843.52  |proj g|=        1.3064
At iterate    34  f =      -843.52  |proj g|=        1.3069
At iterate    35  f =      -843.52  |proj g|=        1.3074
At iterate    36  f =      -843.52  |proj g|=        1.3091
At iterate    37  f =      -843.52  |proj g|=        1.3115
At iterate    38  f =      -843.53  |proj g|=        1.3158
At iterate    39  f =      -843.53  |proj g|=         1.322
At iterate    40  f =      -843.53  |proj g|=        1.3302
At iterate    41  f =      -843.53  |proj g|=        1.3371
At iterate    42  f =      -843.55  |proj g|=        1.3318
At iterate    43  f =      -843.57  |proj g|=        1.3023
At iterate    44  f =      -843.58  |proj g|=        1.3286
At iterate    45  f =      -843.62  |proj g|=        1.2767
At iterate    46  f =      -845.58  |proj g|=       0.67244
At iterate    47  f =      -845.64  |proj g|=       0.55349
At iterate    48  f =      -845.64  |proj g|=      0.098436
At iterate    49  f =      -845.64  |proj g|=      0.046205
At iterate    50  f =      -845.64  |proj g|=       0.01223

iterations 50
function evaluations 59
segments explored during Cauchy searches 52
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0122298
final function value -845.639

F = -845.639
final  value -845.638647 
converged
 
INFO  [08:38:36.866] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:38:36.954] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:38:36.961] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:38:42.200] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:38:47.336] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:38:52.632] [mlr3]  Finished benchmark 
INFO  [08:38:52.733] [bbotk] Result of batch 159: 
INFO  [08:38:52.734] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:38:52.734] [bbotk]              6.333631                  6.55992                       0.2679724 
INFO  [08:38:52.734] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:38:52.734] [bbotk]                     2183        1.088 -0.9358917         <NA>   0.9750139 
INFO  [08:38:52.734] [bbotk]                                 uhash 
INFO  [08:38:52.734] [bbotk]  20ab21ba-6739-40a6-ae2f-79df44cb73d5 
DEBUG [08:38:54.086] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.731172e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.731172e-05 0.002087416 
  - best initial criterion value(s) :  804.9375 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -804.94  |proj g|=      0.61644
At iterate     1  f =      -807.49  |proj g|=        3.4618
At iterate     2  f =      -810.88  |proj g|=         2.784
At iterate     3  f =       -812.1  |proj g|=        2.2347
At iterate     4  f =      -812.23  |proj g|=        2.0645
At iterate     5  f =      -812.63  |proj g|=        1.9822
At iterate     6  f =      -813.29  |proj g|=        1.9966
At iterate     7  f =      -813.31  |proj g|=        2.1387
At iterate     8  f =      -813.33  |proj g|=        2.0759
At iterate     9  f =      -813.33  |proj g|=        2.0727
At iterate    10  f =      -813.33  |proj g|=        2.0729
At iterate    11  f =      -813.33  |proj g|=         2.073

iterations 11
function evaluations 16
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.07301
final function value -813.334

F = -813.334
final  value -813.333925 
converged
 
INFO  [08:38:54.090] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:38:54.196] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:38:54.203] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:38:59.791] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:39:06.866] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:39:13.431] [mlr3]  Finished benchmark 
INFO  [08:39:13.543] [bbotk] Result of batch 160: 
INFO  [08:39:13.545] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:39:13.545] [bbotk]               7.13916                 5.107927                       0.4401193 
INFO  [08:39:13.545] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:39:13.545] [bbotk]                     2878        0.915 -0.9554535         <NA>   0.9779167 
INFO  [08:39:13.545] [bbotk]                                 uhash 
INFO  [08:39:13.545] [bbotk]  d5d444b8-0f5d-4005-a968-1ed5f9c726a5 
DEBUG [08:39:15.187] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.728248e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.728248e-05 0.002090343 
  - best initial criterion value(s) :  789.0688 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -789.07  |proj g|=       2.7191
At iterate     1  f =      -800.24  |proj g|=         8.096
At iterate     2  f =      -801.21  |proj g|=        7.4608
At iterate     3  f =      -801.71  |proj g|=        5.7416
At iterate     4  f =      -801.83  |proj g|=        6.4238
At iterate     5  f =      -801.84  |proj g|=        6.3175
At iterate     6  f =      -801.84  |proj g|=        6.3031
At iterate     7  f =      -801.84  |proj g|=        6.2747
At iterate     8  f =      -801.85  |proj g|=        6.2477
At iterate     9  f =      -801.86  |proj g|=        6.2459
At iterate    10  f =      -801.86  |proj g|=         6.313
At iterate    11  f =      -801.87  |proj g|=        6.3872
At iterate    12  f =      -801.87  |proj g|=        6.4019
At iterate    13  f =      -801.87  |proj g|=        6.4027
At iterate    14  f =      -801.87  |proj g|=        6.4032
At iterate    15  f =      -801.87  |proj g|=        6.4063
At iterate    16  f =      -801.87  |proj g|=        6.4098
At iterate    17  f =      -801.87  |proj g|=        6.4166
At iterate    18  f =      -801.87  |proj g|=        6.4256
At iterate    19  f =      -801.87  |proj g|=        6.4349
At iterate    20  f =      -801.87  |proj g|=        6.4476
At iterate    21  f =      -801.88  |proj g|=        6.4466
At iterate    22  f =       -801.9  |proj g|=        6.6341
At iterate    23  f =      -801.93  |proj g|=        6.5665
At iterate    24  f =      -802.19  |proj g|=         6.227
At iterate    25  f =      -802.62  |proj g|=        5.9694
At iterate    26  f =      -803.97  |proj g|=        5.7056
At iterate    27  f =       -806.9  |proj g|=        5.9986
At iterate    28  f =      -807.14  |proj g|=        5.4332
At iterate    29  f =      -812.09  |proj g|=        6.6579
At iterate    30  f =      -816.05  |proj g|=        8.1522
At iterate    31  f =      -816.22  |proj g|=        8.5651
At iterate    32  f =      -816.55  |proj g|=        8.8071
At iterate    33  f =      -816.75  |proj g|=        8.9371
At iterate    34  f =      -816.76  |proj g|=        8.9769
At iterate    35  f =      -816.76  |proj g|=        8.9906
At iterate    36  f =      -816.76  |proj g|=        8.9944
At iterate    37  f =      -816.76  |proj g|=        8.9961

iterations 37
function evaluations 42
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 8.99614
final function value -816.759

F = -816.759
final  value -816.758904 
converged
 
INFO  [08:39:15.192] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:39:15.286] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:39:15.295] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:39:18.501] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:39:21.786] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:39:25.010] [mlr3]  Finished benchmark 
INFO  [08:39:25.131] [bbotk] Result of batch 161: 
INFO  [08:39:25.133] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:39:25.133] [bbotk]              3.526188                 8.801662                       0.1267119 
INFO  [08:39:25.133] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:39:25.133] [bbotk]                     2103        0.915 -0.9574857         <NA>   0.9663534 
INFO  [08:39:25.133] [bbotk]                                 uhash 
INFO  [08:39:25.133] [bbotk]  323b87df-7467-4722-9a37-e5ee705d3df7 
DEBUG [08:39:27.027] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.719229e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.719228e-05 0.002079832 
  - best initial criterion value(s) :  805.6099 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -805.61  |proj g|=       7.6526
At iterate     1  f =      -807.83  |proj g|=        5.9694
At iterate     2  f =      -807.83  |proj g|=        5.8975
At iterate     3  f =      -807.83  |proj g|=        5.9006
At iterate     4  f =      -807.83  |proj g|=        5.9118
At iterate     5  f =      -807.83  |proj g|=        5.9191
At iterate     6  f =      -807.83  |proj g|=        5.9281
At iterate     7  f =      -807.84  |proj g|=         5.944
At iterate     8  f =      -807.84  |proj g|=        6.0071
At iterate     9  f =      -807.86  |proj g|=         5.968
At iterate    10  f =      -807.97  |proj g|=        6.1235
At iterate    11  f =       -808.3  |proj g|=        6.2107
At iterate    12  f =      -809.79  |proj g|=        6.0657
At iterate    13  f =       -812.1  |proj g|=        5.2795
At iterate    14  f =      -817.55  |proj g|=        3.1926
At iterate    15  f =      -817.96  |proj g|=         3.346
At iterate    16  f =       -824.8  |proj g|=        1.5056
At iterate    17  f =      -824.93  |proj g|=        1.6182
At iterate    18  f =      -824.95  |proj g|=        1.6559
At iterate    19  f =      -824.95  |proj g|=        1.6603
At iterate    20  f =      -824.95  |proj g|=        1.6603
At iterate    21  f =      -824.95  |proj g|=        1.6604

iterations 21
function evaluations 28
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.66044
final function value -824.952

F = -824.952
final  value -824.951745 
converged
 
INFO  [08:39:27.031] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:39:27.118] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:39:27.125] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:39:29.901] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:39:32.642] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:39:35.342] [mlr3]  Finished benchmark 
INFO  [08:39:35.442] [bbotk] Result of batch 162: 
INFO  [08:39:35.444] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:39:35.444] [bbotk]              7.563545                 8.507796                       0.1976929 
INFO  [08:39:35.444] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:39:35.444] [bbotk]                     1845        0.993 -0.9524321         <NA>   0.9731797 
INFO  [08:39:35.444] [bbotk]                                 uhash 
INFO  [08:39:35.444] [bbotk]  d94eec60-a1b2-4e7c-a4f3-5ca48f56ef9c 
DEBUG [08:39:37.006] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.71219e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.71219e-05 0.002066625 
  - best initial criterion value(s) :  787.4692 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -787.47  |proj g|=       10.673
At iterate     1  f =      -833.89  |proj g|=        3.7597
At iterate     2  f =      -839.19  |proj g|=         5.353
At iterate     3  f =      -841.52  |proj g|=        4.6787
At iterate     4  f =      -842.93  |proj g|=        3.8472
At iterate     5  f =      -843.12  |proj g|=        3.6634
At iterate     6  f =      -843.23  |proj g|=        3.6342
At iterate     7  f =      -843.34  |proj g|=        3.8276
At iterate     8  f =      -843.35  |proj g|=        3.9015
At iterate     9  f =      -843.35  |proj g|=        3.9076
At iterate    10  f =      -843.35  |proj g|=        3.9072
At iterate    11  f =      -843.35  |proj g|=        3.9123
At iterate    12  f =      -843.35  |proj g|=        3.9121
At iterate    13  f =      -843.36  |proj g|=        3.9029
At iterate    14  f =      -843.37  |proj g|=        3.9529
At iterate    15  f =      -843.38  |proj g|=        3.9268
At iterate    16  f =      -843.44  |proj g|=        4.1698
At iterate    17  f =       -843.6  |proj g|=        3.9174
At iterate    18  f =      -843.94  |proj g|=        3.5425
At iterate    19  f =       -844.8  |proj g|=        2.9056
At iterate    20  f =      -846.86  |proj g|=        1.9773
At iterate    21  f =       -851.7  |proj g|=       0.77364
At iterate    22  f =      -853.73  |proj g|=       0.41439
At iterate    23  f =      -859.84  |proj g|=       0.45433
At iterate    24  f =      -860.34  |proj g|=       0.34005
At iterate    25  f =      -860.44  |proj g|=       0.32873
At iterate    26  f =      -860.45  |proj g|=        0.2657
At iterate    27  f =      -860.45  |proj g|=      0.089712
At iterate    28  f =      -860.45  |proj g|=      0.089347

iterations 28
function evaluations 32
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0893475
final function value -860.448

F = -860.448
final  value -860.447969 
converged
 
INFO  [08:39:37.035] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:39:37.111] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:39:37.118] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:39:42.229] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:39:47.170] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:39:52.337] [mlr3]  Finished benchmark 
INFO  [08:39:52.439] [bbotk] Result of batch 163: 
INFO  [08:39:52.441] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:39:52.441] [bbotk]              8.642791                 2.832196                       0.1465583 
INFO  [08:39:52.441] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:39:52.441] [bbotk]                     3443        0.912 -0.9429765         <NA>   0.9752398 
INFO  [08:39:52.441] [bbotk]                                 uhash 
INFO  [08:39:52.441] [bbotk]  833c158d-2cee-4c60-8022-29151afcae31 
DEBUG [08:39:54.289] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.706709e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.706709e-05 0.002069304 
  - best initial criterion value(s) :  812.2571 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -812.26  |proj g|=       11.356
At iterate     1  f =      -824.53  |proj g|=        11.414
At iterate     2  f =      -841.19  |proj g|=        6.1382
At iterate     3  f =      -844.46  |proj g|=        4.0611
At iterate     4  f =      -845.77  |proj g|=        3.9127
At iterate     5  f =      -845.85  |proj g|=        3.4903
At iterate     6  f =      -845.85  |proj g|=        3.5079
At iterate     7  f =      -845.85  |proj g|=        3.5118
At iterate     8  f =      -845.85  |proj g|=        3.5228
At iterate     9  f =      -845.85  |proj g|=        3.5405
At iterate    10  f =      -845.86  |proj g|=         3.569
At iterate    11  f =      -845.89  |proj g|=        3.6136
At iterate    12  f =      -845.97  |proj g|=        3.6666
At iterate    13  f =      -846.17  |proj g|=        3.6859
At iterate    14  f =      -846.64  |proj g|=         3.539
At iterate    15  f =      -847.52  |proj g|=        3.0081
At iterate    16  f =      -848.53  |proj g|=        1.9404
At iterate    17  f =      -848.95  |proj g|=        1.8665
At iterate    18  f =      -849.15  |proj g|=        1.8659
At iterate    19  f =      -849.34  |proj g|=        1.8658
At iterate    20  f =      -850.23  |proj g|=        1.8647
At iterate    21  f =      -851.96  |proj g|=        1.8624
At iterate    22  f =      -855.43  |proj g|=        1.8565
At iterate    23  f =      -859.09  |proj g|=        1.7653
At iterate    24  f =      -861.81  |proj g|=        1.8406
At iterate    25  f =      -863.22  |proj g|=         1.835
At iterate    26  f =      -863.89  |proj g|=        1.8311
At iterate    27  f =      -864.09  |proj g|=        1.8265
At iterate    28  f =      -864.13  |proj g|=        1.8273
At iterate    29  f =      -864.15  |proj g|=        1.8257
At iterate    30  f =      -864.15  |proj g|=        1.8253
At iterate    31  f =      -864.15  |proj g|=        1.8253
At iterate    32  f =      -864.15  |proj g|=        1.8253

iterations 32
function evaluations 38
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.82531
final function value -864.151

F = -864.151
final  value -864.151052 
converged
 
INFO  [08:39:54.293] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:39:54.379] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:39:54.386] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:39:57.714] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:40:00.713] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:40:03.747] [mlr3]  Finished benchmark 
INFO  [08:40:03.848] [bbotk] Result of batch 164: 
INFO  [08:40:03.850] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:40:03.850] [bbotk]              3.249178                 3.510605                       0.4743243 
INFO  [08:40:03.850] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:40:03.850] [bbotk]                     1881        1.135 -0.9434682         <NA>   0.9721798 
INFO  [08:40:03.850] [bbotk]                                 uhash 
INFO  [08:40:03.850] [bbotk]  fffeedcb-06f6-4a04-84a5-b40d0316a3dd 
DEBUG [08:40:05.349] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.699198e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.699198e-05 0.002056779 
  - best initial criterion value(s) :  773.6582 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -773.66  |proj g|=       3.9027
At iterate     1  f =      -774.32  |proj g|=         4.226
At iterate     2  f =      -788.22  |proj g|=        3.0718
At iterate     3  f =      -792.26  |proj g|=        2.3794
At iterate     4  f =      -792.28  |proj g|=        2.4354
At iterate     5  f =      -792.36  |proj g|=        2.3606
At iterate     6  f =      -792.36  |proj g|=        2.3858
At iterate     7  f =      -792.36  |proj g|=        2.3773
At iterate     8  f =      -792.36  |proj g|=        2.3772

iterations 8
function evaluations 14
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.37716
final function value -792.363

F = -792.363
final  value -792.363012 
converged
 
INFO  [08:40:05.353] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:40:05.442] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:40:05.472] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:40:06.474] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:40:07.507] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:40:08.572] [mlr3]  Finished benchmark 
INFO  [08:40:08.696] [bbotk] Result of batch 165: 
INFO  [08:40:08.698] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:40:08.698] [bbotk]              8.277802                 4.173278                       0.1918333 
INFO  [08:40:08.698] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [08:40:08.698] [bbotk]                      444        1.039 -0.962315         <NA>   0.9619136 
INFO  [08:40:08.698] [bbotk]                                 uhash 
INFO  [08:40:08.698] [bbotk]  45b6a294-99e0-4e84-9e3e-e278d69f8a1f 
DEBUG [08:40:10.402] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.691908e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.691908e-05 0.002040093 
  - best initial criterion value(s) :  824.843 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -824.84  |proj g|=       9.4933
At iterate     1  f =      -832.07  |proj g|=        10.854
At iterate     2  f =      -836.66  |proj g|=        9.4145
At iterate     3  f =      -850.81  |proj g|=        2.6474
At iterate     4  f =      -851.97  |proj g|=        3.6236
At iterate     5  f =      -852.36  |proj g|=        3.4052
At iterate     6  f =      -852.39  |proj g|=        3.3328
At iterate     7  f =      -852.39  |proj g|=        3.3466
At iterate     8  f =      -852.39  |proj g|=        3.3459
At iterate     9  f =      -852.39  |proj g|=        3.3451
At iterate    10  f =      -852.39  |proj g|=        3.3437
At iterate    11  f =      -852.39  |proj g|=        3.3412
At iterate    12  f =      -852.39  |proj g|=         3.337
At iterate    13  f =      -852.39  |proj g|=        3.3309
At iterate    14  f =      -852.39  |proj g|=        3.3236
At iterate    15  f =      -852.39  |proj g|=        3.3193
At iterate    16  f =       -852.4  |proj g|=        3.3314
At iterate    17  f =       -852.4  |proj g|=         3.334
At iterate    18  f =      -852.41  |proj g|=        3.3429
At iterate    19  f =      -852.43  |proj g|=        3.3499
At iterate    20  f =      -852.48  |proj g|=        3.3658
At iterate    21  f =       -852.6  |proj g|=        3.3777
At iterate    22  f =       -852.9  |proj g|=        3.3864
At iterate    23  f =      -853.51  |proj g|=         3.695
At iterate    24  f =      -854.99  |proj g|=        3.7127
At iterate    25  f =       -856.7  |proj g|=        4.1679
At iterate    26  f =      -861.04  |proj g|=        3.5255
At iterate    27  f =       -862.3  |proj g|=        3.3743
At iterate    28  f =      -867.77  |proj g|=        2.5315
At iterate    29  f =      -867.93  |proj g|=        2.7969
At iterate    30  f =      -867.94  |proj g|=        2.7492
At iterate    31  f =      -868.63  |proj g|=        2.8281
At iterate    32  f =      -868.66  |proj g|=         2.888
At iterate    33  f =      -868.66  |proj g|=        2.8731
At iterate    34  f =      -868.66  |proj g|=        2.8658
At iterate    35  f =      -868.66  |proj g|=        2.8659

iterations 35
function evaluations 37
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.86594
final function value -868.659

F = -868.659
final  value -868.659464 
converged
 
INFO  [08:40:10.407] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:40:10.507] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:40:10.515] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:40:13.034] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:40:15.465] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:40:17.944] [mlr3]  Finished benchmark 
INFO  [08:40:18.083] [bbotk] Result of batch 166: 
INFO  [08:40:18.085] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:40:18.085] [bbotk]              3.372151                 4.907111                       0.3967729 
INFO  [08:40:18.085] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:40:18.085] [bbotk]                     1538        0.938 -0.9445271         <NA>   0.9709927 
INFO  [08:40:18.085] [bbotk]                                 uhash 
INFO  [08:40:18.085] [bbotk]  19b25f43-3a0a-4a1c-a7fc-88698583a93a 
DEBUG [08:40:19.888] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.684018e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.684018e-05 0.002027066 
  - best initial criterion value(s) :  781.5705 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -781.57  |proj g|=       10.976
At iterate     1  f =      -784.99  |proj g|=        10.608
At iterate     2  f =      -801.53  |proj g|=        8.3832
At iterate     3  f =      -816.87  |proj g|=        2.7259
At iterate     4  f =      -819.19  |proj g|=        3.1807
At iterate     5  f =      -822.15  |proj g|=        3.5124
At iterate     6  f =      -822.66  |proj g|=        3.2807
At iterate     7  f =      -822.69  |proj g|=        3.1866
At iterate     8  f =      -822.69  |proj g|=        3.1809
At iterate     9  f =      -822.69  |proj g|=        3.1804
At iterate    10  f =      -822.69  |proj g|=        3.1803
At iterate    11  f =      -822.69  |proj g|=          3.18
At iterate    12  f =      -822.69  |proj g|=        3.1796
At iterate    13  f =      -822.69  |proj g|=        3.1787
At iterate    14  f =      -822.69  |proj g|=        3.1775
At iterate    15  f =       -822.7  |proj g|=         3.177
At iterate    16  f =       -822.7  |proj g|=        3.1806
At iterate    17  f =      -822.71  |proj g|=        3.1958
At iterate    18  f =      -822.73  |proj g|=         3.225
At iterate    19  f =      -822.73  |proj g|=        3.2157
At iterate    20  f =      -822.76  |proj g|=        3.2481
At iterate    21  f =      -829.85  |proj g|=        2.1587
At iterate    22  f =      -837.86  |proj g|=       0.67223
At iterate    23  f =      -839.75  |proj g|=       0.25909
At iterate    24  f =      -839.99  |proj g|=       0.26004
At iterate    25  f =       -840.2  |proj g|=       0.72361
At iterate    26  f =      -840.21  |proj g|=        0.7217
At iterate    27  f =      -840.22  |proj g|=       0.72076
At iterate    28  f =      -840.22  |proj g|=        0.7194
At iterate    29  f =      -840.22  |proj g|=       0.71772
At iterate    30  f =      -840.23  |proj g|=       0.52786
At iterate    31  f =      -840.23  |proj g|=        0.5311
At iterate    32  f =      -840.23  |proj g|=        0.5313

iterations 32
function evaluations 38
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.531302
final function value -840.226

F = -840.226
final  value -840.225869 
converged
 
INFO  [08:40:19.893] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:40:19.992] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:40:20.000] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:40:23.567] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:40:27.199] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:40:30.778] [mlr3]  Finished benchmark 
INFO  [08:40:30.914] [bbotk] Result of batch 167: 
INFO  [08:40:30.916] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:40:30.916] [bbotk]              5.397875                 5.255067                       0.3027421 
INFO  [08:40:30.916] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:40:30.916] [bbotk]                     2290         1.09 -0.9551749         <NA>   0.9753416 
INFO  [08:40:30.916] [bbotk]                                 uhash 
INFO  [08:40:30.916] [bbotk]  87eac834-9ec1-4e5f-8da7-4f1fc5fae7ec 
DEBUG [08:40:32.414] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.678825e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.678825e-05 0.002022609 
  - best initial criterion value(s) :  856.5464 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -856.55  |proj g|=       3.2175
At iterate     1  f =      -874.66  |proj g|=        3.4969
At iterate     2  f =      -877.55  |proj g|=        2.8612
At iterate     3  f =      -879.38  |proj g|=        2.4497
At iterate     4  f =      -879.78  |proj g|=        2.6149
At iterate     5  f =      -880.23  |proj g|=        2.6694
At iterate     6  f =      -882.01  |proj g|=        2.7071
At iterate     7  f =      -883.66  |proj g|=         2.564
At iterate     8  f =      -883.74  |proj g|=        2.4374
At iterate     9  f =      -884.24  |proj g|=        2.3615
At iterate    10  f =      -884.28  |proj g|=        2.3381
At iterate    11  f =       -884.6  |proj g|=        2.4175
At iterate    12  f =      -885.47  |proj g|=        2.6759
At iterate    13  f =      -886.27  |proj g|=        3.0145
At iterate    14  f =      -886.38  |proj g|=        2.8787
At iterate    15  f =      -886.74  |proj g|=         3.069
At iterate    16  f =      -886.78  |proj g|=        3.0118
At iterate    17  f =       -886.8  |proj g|=        3.0904
At iterate    18  f =       -886.8  |proj g|=        3.0812
At iterate    19  f =       -886.8  |proj g|=        3.0816

iterations 19
function evaluations 26
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.08155
final function value -886.799

F = -886.799
final  value -886.798582 
converged
 
INFO  [08:40:32.419] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:40:32.509] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:40:32.517] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:40:36.151] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:40:40.051] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:40:44.362] [mlr3]  Finished benchmark 
INFO  [08:40:44.488] [bbotk] Result of batch 168: 
INFO  [08:40:44.490] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:40:44.490] [bbotk]              9.901358                 9.251776                      0.01626497 
INFO  [08:40:44.490] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [08:40:44.490] [bbotk]                     1867        0.931 -0.941624         <NA>   0.9459659 
INFO  [08:40:44.490] [bbotk]                                 uhash 
INFO  [08:40:44.490] [bbotk]  ef8b5355-04b4-48ce-8af7-0ae74965eba9 
DEBUG [08:40:46.092] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.693071e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.693071e-05 0.002030174 
  - best initial criterion value(s) :  808.9761 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -808.98  |proj g|=       11.657
At iterate     1  f =      -823.64  |proj g|=        9.9275
At iterate     2  f =      -836.76  |proj g|=        7.4122
At iterate     3  f =      -845.07  |proj g|=        4.9484
At iterate     4  f =      -850.45  |proj g|=        4.1367
At iterate     5  f =      -853.94  |proj g|=        3.5063
At iterate     6  f =      -856.33  |proj g|=        3.1098
At iterate     7  f =       -856.9  |proj g|=        3.8869
At iterate     8  f =      -858.54  |proj g|=        3.0493
At iterate     9  f =      -859.24  |proj g|=        2.6751
At iterate    10  f =      -859.62  |proj g|=        2.5534
At iterate    11  f =       -859.8  |proj g|=        2.6162
At iterate    12  f =      -859.85  |proj g|=        2.6639
At iterate    13  f =      -859.86  |proj g|=        2.5537
At iterate    14  f =      -859.87  |proj g|=         2.621
At iterate    15  f =      -859.87  |proj g|=         2.636
At iterate    16  f =      -859.94  |proj g|=        2.6867
At iterate    17  f =      -860.63  |proj g|=        2.8555
At iterate    18  f =      -862.35  |proj g|=        3.1999
At iterate    19  f =      -865.36  |proj g|=        4.7267
At iterate    20  f =      -866.52  |proj g|=        4.4648
At iterate    21  f =       -878.1  |proj g|=        2.3699
At iterate    22  f =      -892.16  |proj g|=        1.2391
At iterate    23  f =      -894.33  |proj g|=       0.85175
At iterate    24  f =      -894.42  |proj g|=       0.67757
At iterate    25  f =      -894.43  |proj g|=       0.63482
At iterate    26  f =      -894.43  |proj g|=       0.63965
At iterate    27  f =      -894.43  |proj g|=        0.6393

iterations 27
function evaluations 33
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.639299
final function value -894.427

F = -894.427
final  value -894.426830 
converged
 
INFO  [08:40:46.096] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:40:46.189] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:40:46.196] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:40:50.001] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:40:54.001] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:40:59.306] [mlr3]  Finished benchmark 
INFO  [08:40:59.419] [bbotk] Result of batch 169: 
INFO  [08:40:59.421] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:40:59.421] [bbotk]              9.313594                  5.12265                       0.4726413 
INFO  [08:40:59.421] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:40:59.421] [bbotk]                     1854        0.933 -0.9434806         <NA>   0.9771818 
INFO  [08:40:59.421] [bbotk]                                 uhash 
INFO  [08:40:59.421] [bbotk]  4c34b1cf-c799-4a35-b83b-6ad1df0d3cda 
DEBUG [08:40:59.492] [bbotk]  
INFO  [08:40:59.504] [bbotk] Finished optimizing after 200 evaluation(s) 
INFO  [08:40:59.505] [bbotk] Result: 
INFO  [08:40:59.507] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:40:59.507] [bbotk]              9.216591                 2.401306                       0.4636281 
INFO  [08:40:59.507] [bbotk]  ps_cboost_anneal2.mstop learner_param_vals  x_domain classif.auc 
INFO  [08:40:59.507] [bbotk]                     4278         <list[19]> <list[4]>   0.9791612 
INFO  [08:41:09.587] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2.tuned' on task 'spam' (iter 5/5) 
INFO  [08:41:09.824] [bbotk] Starting to optimize 4 parameter(s) with '<OptimizerInterMBO>' and '<TerminatorEvals> [n_evals=200]' 
DEBUG [08:41:09.895] [bbotk]  
INFO  [08:41:09.902] [bbotk] Evaluating 32 configuration(s) 
INFO  [08:41:12.621] [mlr3]  Running benchmark with 96 resampling iterations 
INFO  [08:41:12.629] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:41:23.665] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:41:25.507] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:41:28.084] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:41:38.574] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:41:46.617] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:41:51.541] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:41:54.076] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:42:04.393] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:42:13.728] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:42:26.683] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:42:37.712] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:42:38.973] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:42:42.083] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:42:48.440] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:42:50.988] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:43:02.128] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:43:02.999] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:43:04.960] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:43:12.020] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:43:18.695] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:43:27.270] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:43:37.264] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:43:39.940] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:43:45.128] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:43:54.162] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:43:56.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:43:58.279] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:44:03.531] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:44:10.031] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:44:10.967] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:44:12.401] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:44:14.844] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:44:17.255] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:44:28.738] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:44:32.982] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:44:38.041] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:44:46.166] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:44:48.625] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:45:00.225] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:45:07.169] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:45:11.676] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:45:13.576] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:45:23.032] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:45:32.137] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:45:37.231] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:45:40.838] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:45:43.724] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:45:53.666] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:45:57.044] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:46:03.241] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:46:08.745] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:46:11.184] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:46:19.479] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:46:23.216] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:46:29.714] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:46:35.918] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:46:40.607] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:46:45.606] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:46:47.162] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:46:50.021] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:46:54.154] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:46:59.666] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:47:07.035] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:47:18.218] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:47:25.044] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:47:32.238] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:47:43.684] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:47:49.076] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:48:00.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:48:04.614] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:48:11.660] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:48:19.082] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:48:30.041] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:48:32.561] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:48:35.936] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:48:41.145] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:48:42.724] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:48:47.698] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:48:52.799] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:48:59.460] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:49:06.683] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:49:15.912] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:49:17.470] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:49:21.464] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:49:34.178] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:49:37.227] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:49:47.306] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:49:55.011] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:50:02.834] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:50:10.874] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:50:17.478] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:50:28.340] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:50:32.714] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:50:45.602] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:50:48.312] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:50:53.682] [mlr3]  Finished benchmark 
INFO  [08:50:56.977] [bbotk] Result of batch 1: 
INFO  [08:50:56.979] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:50:56.979] [bbotk]              3.050434                 6.558666                      0.38083517 
INFO  [08:50:56.979] [bbotk]              5.000799                 4.916522                      0.26718202 
INFO  [08:50:56.979] [bbotk]              6.246932                 8.450404                      0.30159283 
INFO  [08:50:56.979] [bbotk]              3.446836                 3.660809                      0.18410118 
INFO  [08:50:56.979] [bbotk]              7.659943                 5.206991                      0.41183430 
INFO  [08:50:56.979] [bbotk]              4.906970                 6.055770                      0.08426489 
INFO  [08:50:56.979] [bbotk]              5.531788                 6.483234                      0.45928555 
INFO  [08:50:56.979] [bbotk]              6.579098                 3.316453                      0.16899680 
INFO  [08:50:56.979] [bbotk]              6.443999                 3.996970                      0.21090999 
INFO  [08:50:56.979] [bbotk]              8.710547                 7.353447                      0.10050570 
INFO  [08:50:56.979] [bbotk]              4.660330                 4.678327                      0.36913313 
INFO  [08:50:56.979] [bbotk]              2.305486                 6.939133                      0.25036374 
INFO  [08:50:56.979] [bbotk]              6.974033                 7.957716                      0.32606005 
INFO  [08:50:56.979] [bbotk]              2.597172                 7.173216                      0.28214073 
INFO  [08:50:56.979] [bbotk]              2.881245                 9.057623                      0.06338811 
INFO  [08:50:56.979] [bbotk]              5.334284                 2.818901                      0.03810875 
INFO  [08:50:56.979] [bbotk]              7.245441                 2.724526                      0.34151231 
INFO  [08:50:56.979] [bbotk]              9.378711                 8.782053                      0.49295153 
INFO  [08:50:56.979] [bbotk]              5.964647                 8.543203                      0.21965937 
INFO  [08:50:56.979] [bbotk]              9.978018                 5.832453                      0.19258562 
INFO  [08:50:56.979] [bbotk]              8.134658                 3.012926                      0.39690976 
INFO  [08:50:56.979] [bbotk]              8.499265                 9.398248                      0.42859722 
INFO  [08:50:56.979] [bbotk]              8.798469                 5.372406                      0.12498091 
INFO  [08:50:56.979] [bbotk]              4.399094                 5.721503                      0.05016621 
INFO  [08:50:56.979] [bbotk]              3.872151                 4.237967                      0.26152316 
INFO  [08:50:56.979] [bbotk]              7.907476                 8.021870                      0.01306494 
INFO  [08:50:56.979] [bbotk]              4.146068                 7.696949                      0.47412836 
INFO  [08:50:56.979] [bbotk]              7.319096                 2.219189                      0.01857396 
INFO  [08:50:56.979] [bbotk]              9.023775                 9.859678                      0.15306263 
INFO  [08:50:56.979] [bbotk]              3.665234                 2.259186                      0.34868620 
INFO  [08:50:56.979] [bbotk]              9.544419                 4.448098                      0.44715316 
INFO  [08:50:56.979] [bbotk]              2.118372                 9.732961                      0.14021233 
INFO  [08:50:56.979] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:50:56.979] [bbotk]  ps_cboost_anneal2.mstop classif.auc                                uhash 
INFO  [08:50:56.979] [bbotk]                     3247   0.9690171 6a1d5374-97db-4d9a-baaf-fa595f87e810 
INFO  [08:50:56.979] [bbotk]                     1091   0.9684046 f5bf55a7-6db0-4f3f-81d9-a451ebab9ad0 
INFO  [08:50:56.979] [bbotk]                     2140   0.9725706 fed25285-db30-49d3-b7d0-15a063a2903a 
INFO  [08:50:56.979] [bbotk]                     3858   0.9688768 803a4cf4-d479-4de8-80b7-46d0e411bb52 
INFO  [08:50:56.979] [bbotk]                     3401   0.9744665 f8243642-a700-4d46-b17f-a5468180e848 
INFO  [08:50:56.979] [bbotk]                     1381   0.9594219 fff61c0f-5044-43d8-87b0-762d39515973 
INFO  [08:50:56.979] [bbotk]                      497   0.9671094 96deee7b-ab74-40e5-9c66-4be43bfca962 
INFO  [08:50:56.979] [bbotk]                      889   0.9638243 c3d56804-0263-4849-8f7e-3c2774f1dcad 
INFO  [08:50:56.979] [bbotk]                     3715   0.9732990 7bf84d34-cb36-4254-ae18-88ea45577827 
INFO  [08:50:56.979] [bbotk]                     2898   0.9694229 2e17cd4f-b8b3-4aee-a40e-d3641fec0c5d 
INFO  [08:50:56.979] [bbotk]                     2560   0.9733221 d69ba73a-28f3-45d4-a3a6-9c6562c40db1 
INFO  [08:50:56.979] [bbotk]                     1927   0.9547327 0178d3b9-65e6-4f44-a24b-037195893ca7 
INFO  [08:50:56.979] [bbotk]                     3158   0.9740843 901af838-b6d4-4773-98fa-a86ba6d35d61 
INFO  [08:50:56.979] [bbotk]                     4059   0.9648279 ce67f9a4-406e-4310-aab4-f03850c43a62 
INFO  [08:50:56.979] [bbotk]                     4633   0.9578349 e4663d4d-6daa-4e1e-9d48-b2a413003236 
INFO  [08:50:56.979] [bbotk]                     4507   0.9644736 80e5283b-a433-44a4-9f96-d6702c46bc7d 
INFO  [08:50:56.979] [bbotk]                     2345   0.9733458 394173be-d986-412c-a1ac-5b00e9880dd2 
INFO  [08:50:56.979] [bbotk]                     3597   0.9714392 cdc29d54-a8f0-4e48-8b8f-a92c2d0cadbe 
INFO  [08:50:56.979] [bbotk]                      236   0.9494342 ea065362-33cb-43ee-9649-190a1907c11e 
INFO  [08:50:56.979] [bbotk]                      593   0.9615769 e3a3ae87-c624-45f5-8ead-f880a8c8bc11 
INFO  [08:50:56.979] [bbotk]                     4826   0.9729743 e7754f87-aec0-41cf-b6cb-ddcacdb8cc6d 
INFO  [08:50:56.979] [bbotk]                     1457   0.9711221 31ef6599-4919-4c78-87f7-89d8e24fdb13 
INFO  [08:50:56.979] [bbotk]                     4221   0.9706531 0965f9a7-ab8f-4655-994a-59bedee685a7 
INFO  [08:50:56.979] [bbotk]                     2991   0.9610954 137c3051-ec36-4e8d-9509-09b11adedd85 
INFO  [08:50:56.979] [bbotk]                      756   0.9621894 aeb514c6-df84-4455-ab35-1a99ddd75145 
INFO  [08:50:56.979] [bbotk]                     1575   0.9340824 993990d4-09b0-4365-8575-d7b0aa41fe72 
INFO  [08:50:56.979] [bbotk]                     2623   0.9734550 82d8e912-b442-496b-8166-e0c92a42c2b4 
INFO  [08:50:56.979] [bbotk]                     2233   0.9474153 8a7c5d5b-d5c0-4bef-8454-b012c02777f5 
INFO  [08:50:56.979] [bbotk]                     4965   0.9710274 edc4e43d-2f8a-4add-855f-ddb989716b69 
INFO  [08:50:56.979] [bbotk]                     4348   0.9728689 bff5260a-330c-463c-86b2-4c47f2b251f6 
INFO  [08:50:56.979] [bbotk]                     1197   0.9694632 d709c44b-538b-4575-b0f4-0162716c10b4 
INFO  [08:50:56.979] [bbotk]                     1820   0.9483190 353598b5-9ce0-4abf-a19a-a619e0625ebb 
INFO  [08:50:56.979] [bbotk]  ps_cboost_anneal2.mstop classif.auc                                uhash 
DEBUG [08:50:57.751] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.280849e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  9.280849e-06 0.0009625903 
  - best initial criterion value(s) :  111.9891 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -111.99  |proj g|=      0.90782
At iterate     1  f =      -115.27  |proj g|=       0.34522
At iterate     2  f =       -115.8  |proj g|=       0.30255
At iterate     3  f =      -116.51  |proj g|=       0.73345
At iterate     4  f =      -116.95  |proj g|=        0.8342
At iterate     5  f =         -117  |proj g|=       0.28729
At iterate     6  f =      -117.07  |proj g|=       0.21048
At iterate     7  f =      -117.27  |proj g|=       0.78731
At iterate     8  f =      -117.29  |proj g|=       0.14835
At iterate     9  f =      -117.29  |proj g|=       0.14973
At iterate    10  f =      -117.29  |proj g|=       0.14956
At iterate    11  f =      -117.29  |proj g|=       0.14957

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.149565
final function value -117.292

F = -117.292
final  value -117.291934 
converged
 
INFO  [08:50:57.755] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:50:57.872] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:50:57.884] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:51:00.151] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:51:02.039] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:51:03.684] [mlr3]  Finished benchmark 
INFO  [08:51:03.832] [bbotk] Result of batch 2: 
INFO  [08:51:03.834] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:51:03.834] [bbotk]              3.729656                 8.694644                       0.4517033 
INFO  [08:51:03.834] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:51:03.834] [bbotk]                      559        0.499 -0.9681227         <NA>   0.9639974 
INFO  [08:51:03.834] [bbotk]                                 uhash 
INFO  [08:51:03.834] [bbotk]  1f55743e-6883-4aa5-a356-ede5306516c5 
DEBUG [08:51:04.519] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.995149e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  8.995149e-06 0.0009168525 
  - best initial criterion value(s) :  118.9158 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -118.92  |proj g|=      0.89062
At iterate     1  f =      -120.74  |proj g|=       0.80111
At iterate     2  f =      -120.79  |proj g|=       0.39189
At iterate     3  f =       -120.8  |proj g|=       0.37135
At iterate     4  f =       -120.8  |proj g|=       0.35928
At iterate     5  f =       -120.8  |proj g|=       0.36101
At iterate     6  f =       -120.8  |proj g|=       0.36051
At iterate     7  f =       -120.8  |proj g|=       0.36034
At iterate     8  f =       -120.8  |proj g|=       0.35971
At iterate     9  f =       -120.8  |proj g|=       0.35892
At iterate    10  f =       -120.8  |proj g|=       0.35746
At iterate    11  f =       -120.8  |proj g|=       0.35518
At iterate    12  f =       -120.8  |proj g|=       0.35135
At iterate    13  f =       -120.8  |proj g|=       0.34497
At iterate    14  f =       -120.8  |proj g|=       0.33377
At iterate    15  f =      -120.82  |proj g|=        0.3136
At iterate    16  f =      -120.84  |proj g|=       0.28258
At iterate    17  f =      -120.93  |proj g|=       0.25753
At iterate    18  f =      -121.13  |proj g|=       0.21309
At iterate    19  f =      -121.56  |proj g|=       0.15324
At iterate    20  f =      -122.14  |proj g|=       0.81439
At iterate    21  f =       -122.2  |proj g|=       0.81514
At iterate    22  f =      -122.22  |proj g|=       0.81508
At iterate    23  f =      -122.22  |proj g|=       0.81506
At iterate    24  f =      -122.22  |proj g|=       0.81505
At iterate    25  f =      -122.22  |proj g|=         0.815
At iterate    26  f =      -122.22  |proj g|=       0.81474
At iterate    27  f =      -122.23  |proj g|=       0.81408
At iterate    28  f =      -122.25  |proj g|=       0.81216
At iterate    29  f =       -122.3  |proj g|=       0.80729
At iterate    30  f =       -122.4  |proj g|=       0.79588
At iterate    31  f =      -122.58  |proj g|=        0.7745
At iterate    32  f =      -122.81  |proj g|=       0.76742
At iterate    33  f =      -122.85  |proj g|=       0.17817
At iterate    34  f =      -122.85  |proj g|=       0.11999
At iterate    35  f =      -122.85  |proj g|=      0.040381
At iterate    36  f =      -122.85  |proj g|=      0.040365

iterations 36
function evaluations 44
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0403654
final function value -122.854

F = -122.854
final  value -122.853640 
converged
 
INFO  [08:51:04.523] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:51:04.617] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:51:04.625] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:51:15.563] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:51:26.747] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:51:38.560] [mlr3]  Finished benchmark 
INFO  [08:51:38.659] [bbotk] Result of batch 3: 
INFO  [08:51:38.661] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:51:38.661] [bbotk]              4.206592                 3.054504                       0.3289048 
INFO  [08:51:38.661] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:51:38.661] [bbotk]                     4552        0.474 -0.9670303         <NA>   0.9739192 
INFO  [08:51:38.661] [bbotk]                                 uhash 
INFO  [08:51:38.661] [bbotk]  1f89a427-f045-442b-9554-f2e2ed6c7862 
DEBUG [08:51:39.308] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.94843e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  8.94843e-06 0.0009345383 
  - best initial criterion value(s) :  118.0258 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -118.03  |proj g|=      0.93619
At iterate     1  f =      -120.14  |proj g|=       0.75813
At iterate     2  f =      -121.05  |proj g|=       0.82317
At iterate     3  f =      -121.11  |proj g|=        0.8003
At iterate     4  f =      -121.12  |proj g|=       0.79711
At iterate     5  f =      -121.12  |proj g|=       0.79682
At iterate     6  f =      -121.12  |proj g|=       0.79679

iterations 6
function evaluations 12
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.796789
final function value -121.123

F = -121.123
final  value -121.122640 
converged
 
INFO  [08:51:39.312] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:51:39.417] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:51:39.424] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:51:46.669] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:51:54.405] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:52:01.087] [mlr3]  Finished benchmark 
INFO  [08:52:01.186] [bbotk] Result of batch 4: 
INFO  [08:52:01.188] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:52:01.188] [bbotk]              9.373363                  8.78602                       0.4371709 
INFO  [08:52:01.188] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:52:01.188] [bbotk]                     3197        0.471 -0.9704502         <NA>   0.9710859 
INFO  [08:52:01.188] [bbotk]                                 uhash 
INFO  [08:52:01.188] [bbotk]  b89f8b7b-cd9d-4fa5-8ca6-57160a66cc9f 
DEBUG [08:52:01.840] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.777165e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  8.777165e-06 0.0009358647 
  - best initial criterion value(s) :  120.7804 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -120.78  |proj g|=       0.4221
At iterate     1  f =       -122.8  |proj g|=       0.44468
At iterate     2  f =      -122.85  |proj g|=       0.42211
At iterate     3  f =      -122.93  |proj g|=       0.39307
At iterate     4  f =      -123.12  |proj g|=       0.37204
At iterate     5  f =      -123.77  |proj g|=       0.25768
At iterate     6  f =      -124.14  |proj g|=       0.57923
At iterate     7  f =      -124.14  |proj g|=       0.43157
At iterate     8  f =      -124.15  |proj g|=       0.36814
At iterate     9  f =      -124.15  |proj g|=       0.37042
At iterate    10  f =      -124.15  |proj g|=       0.37034
At iterate    11  f =      -124.15  |proj g|=       0.37029
At iterate    12  f =      -124.15  |proj g|=       0.37028

iterations 12
function evaluations 16
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.370285
final function value -124.145

F = -124.145
final  value -124.145419 
converged
 
INFO  [08:52:01.844] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:52:01.931] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:52:01.938] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:52:07.702] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:52:11.570] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:52:16.396] [mlr3]  Finished benchmark 
INFO  [08:52:16.496] [bbotk] Result of batch 5: 
INFO  [08:52:16.498] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:52:16.498] [bbotk]              9.316056                 6.579562                       0.1188854 
INFO  [08:52:16.498] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:52:16.498] [bbotk]                     2085         0.47 -0.9720111         <NA>   0.9680994 
INFO  [08:52:16.498] [bbotk]                                 uhash 
INFO  [08:52:16.498] [bbotk]  f5cfd49e-3593-4175-9fcd-e09e36ad4ca5 
DEBUG [08:52:17.137] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.544079e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  8.544078e-06 0.0009038132 
  - best initial criterion value(s) :  133.7961 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -133.8  |proj g|=      0.18757
At iterate     1  f =      -135.42  |proj g|=       0.84856
At iterate     2  f =      -135.48  |proj g|=       0.84763
At iterate     3  f =      -135.52  |proj g|=       0.84592
At iterate     4  f =      -135.71  |proj g|=        0.8375
At iterate     5  f =      -136.01  |proj g|=       0.80988
At iterate     6  f =      -136.01  |proj g|=       0.80239
At iterate     7  f =      -136.03  |proj g|=       0.48922
At iterate     8  f =      -136.03  |proj g|=       0.48613
At iterate     9  f =      -136.03  |proj g|=       0.48693
At iterate    10  f =      -136.03  |proj g|=       0.48694

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.486945
final function value -136.026

F = -136.026
final  value -136.025690 
converged
 
INFO  [08:52:17.141] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:52:17.245] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:52:17.252] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:52:21.894] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:52:26.480] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:52:33.416] [mlr3]  Finished benchmark 
INFO  [08:52:33.514] [bbotk] Result of batch 6: 
INFO  [08:52:33.516] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:52:33.516] [bbotk]              8.088468                 5.299261                       0.1544269 
INFO  [08:52:33.516] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:52:33.516] [bbotk]                     2091        0.476 -0.9688669         <NA>   0.9699336 
INFO  [08:52:33.516] [bbotk]                                 uhash 
INFO  [08:52:33.516] [bbotk]  ba905a24-d3b9-429b-946d-f4e9bb583cdb 
DEBUG [08:52:34.266] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.356431e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  8.356431e-06 0.0008683145 
  - best initial criterion value(s) :  132.7578 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -132.76  |proj g|=       1.9324
At iterate     1  f =       -133.4  |proj g|=        1.9976
At iterate     2  f =      -133.41  |proj g|=         1.993
At iterate     3  f =      -133.42  |proj g|=          1.98
At iterate     4  f =      -133.44  |proj g|=        1.9612
At iterate     5  f =      -133.49  |proj g|=        1.8949
At iterate     6  f =      -133.55  |proj g|=        1.8052
At iterate     7  f =      -133.58  |proj g|=        1.7377
At iterate     8  f =      -133.59  |proj g|=        1.7419
At iterate     9  f =      -133.59  |proj g|=        1.7465
At iterate    10  f =      -133.59  |proj g|=        1.7467
At iterate    11  f =      -133.59  |proj g|=         1.747
At iterate    12  f =      -133.59  |proj g|=        1.7474
At iterate    13  f =      -133.59  |proj g|=        1.7481
At iterate    14  f =      -133.59  |proj g|=        1.7492
At iterate    15  f =      -133.59  |proj g|=        1.7512
At iterate    16  f =      -133.59  |proj g|=         1.755
At iterate    17  f =      -133.59  |proj g|=        1.7624
At iterate    18  f =      -133.59  |proj g|=        1.7749
At iterate    19  f =      -133.59  |proj g|=        1.7889
At iterate    20  f =      -133.59  |proj g|=        1.7918
At iterate    21  f =       -133.6  |proj g|=        1.8044
At iterate    22  f =      -133.61  |proj g|=        1.8287
At iterate    23  f =      -133.66  |proj g|=        1.8712
At iterate    24  f =      -133.82  |proj g|=        1.9282
At iterate    25  f =      -134.24  |proj g|=        1.9587
At iterate    26  f =      -135.17  |proj g|=        1.8481
At iterate    27  f =      -135.34  |proj g|=        1.7642
At iterate    28  f =      -136.48  |proj g|=        1.3759
At iterate    29  f =      -137.27  |proj g|=        1.0731
At iterate    30  f =      -139.29  |proj g|=       0.69874
At iterate    31  f =      -140.66  |proj g|=       0.79156
At iterate    32  f =      -141.44  |proj g|=       0.52873
At iterate    33  f =      -141.45  |proj g|=       0.77144
At iterate    34  f =      -141.71  |proj g|=       0.77371
At iterate    35  f =      -141.71  |proj g|=        0.6191
At iterate    36  f =      -141.71  |proj g|=       0.61801
At iterate    37  f =      -141.71  |proj g|=       0.61805
At iterate    38  f =      -141.71  |proj g|=       0.61817
At iterate    39  f =      -141.71  |proj g|=       0.61835
At iterate    40  f =      -141.71  |proj g|=       0.61864
At iterate    41  f =      -141.71  |proj g|=       0.61909
At iterate    42  f =      -141.71  |proj g|=       0.61965
At iterate    43  f =      -141.71  |proj g|=       0.62005
At iterate    44  f =      -141.71  |proj g|=       0.77253
At iterate    45  f =      -141.71  |proj g|=       0.77367
At iterate    46  f =      -141.71  |proj g|=       0.77369
At iterate    47  f =      -141.71  |proj g|=       0.77473
At iterate    48  f =      -141.81  |proj g|=       0.78082
At iterate    49  f =      -142.25  |proj g|=       0.78562
At iterate    50  f =      -142.94  |proj g|=       0.76402
At iterate    51  f =      -143.19  |proj g|=       0.22083
At iterate    52  f =       -143.2  |proj g|=       0.73885
At iterate    53  f =      -143.23  |proj g|=       0.18308
At iterate    54  f =      -143.23  |proj g|=       0.16094
At iterate    55  f =      -143.23  |proj g|=       0.14706
At iterate    56  f =      -143.23  |proj g|=       0.10533
At iterate    57  f =      -143.23  |proj g|=      0.031639
At iterate    58  f =      -143.23  |proj g|=       0.06293
At iterate    59  f =      -143.23  |proj g|=     0.0091646
At iterate    60  f =      -143.23  |proj g|=     0.0013577
At iterate    61  f =      -143.23  |proj g|=    0.00033581

iterations 61
function evaluations 74
segments explored during Cauchy searches 63
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.000335811
final function value -143.226

F = -143.226
final  value -143.226307 
converged
 
INFO  [08:52:34.270] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:52:34.358] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:52:34.365] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:52:36.167] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:52:37.894] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:52:39.576] [mlr3]  Finished benchmark 
INFO  [08:52:39.674] [bbotk] Result of batch 7: 
INFO  [08:52:39.676] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:52:39.676] [bbotk]              9.225051                  5.84137                       0.4844177 
INFO  [08:52:39.676] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:52:39.676] [bbotk]                     1000        0.519 -0.9667325         <NA>   0.9706878 
INFO  [08:52:39.676] [bbotk]                                 uhash 
INFO  [08:52:39.676] [bbotk]  0cb2216d-49a6-46b9-bbf3-40f19be258a9 
DEBUG [08:52:40.527] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.194438e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  8.194438e-06 0.0008294046 
  - best initial criterion value(s) :  137.1833 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -137.18  |proj g|=      0.92261
At iterate     1  f =      -144.89  |proj g|=       0.37374
At iterate     2  f =      -145.53  |proj g|=       0.56546
At iterate     3  f =      -146.53  |proj g|=       0.49648
At iterate     4  f =      -146.96  |proj g|=       0.38977
At iterate     5  f =      -147.05  |proj g|=       0.75073
At iterate     6  f =      -147.06  |proj g|=       0.42389
At iterate     7  f =      -147.06  |proj g|=       0.42073
At iterate     8  f =      -147.06  |proj g|=       0.42165
At iterate     9  f =      -147.06  |proj g|=       0.42165

iterations 9
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.421647
final function value -147.059

F = -147.059
final  value -147.059359 
converged
 
INFO  [08:52:40.531] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:52:40.618] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:52:40.625] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:52:43.974] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:52:47.558] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:52:51.218] [mlr3]  Finished benchmark 
INFO  [08:52:51.359] [bbotk] Result of batch 8: 
INFO  [08:52:51.362] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:52:51.362] [bbotk]              6.112798                 5.711164                        0.344983 
INFO  [08:52:51.362] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:52:51.362] [bbotk]                     2377        0.671 -0.9664831         <NA>   0.9734565 
INFO  [08:52:51.362] [bbotk]                                 uhash 
INFO  [08:52:51.362] [bbotk]  6066cad5-e0cb-490a-a422-0f6f8f0ba00d 
DEBUG [08:52:52.023] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.125539e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  8.10694e-06 0.0008125539 
  - best initial criterion value(s) :  145.9101 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -145.91  |proj g|=      0.73677
At iterate     1  f =      -147.13  |proj g|=       0.98087
At iterate     2  f =      -147.16  |proj g|=       0.96978
At iterate     3  f =      -147.23  |proj g|=        0.9365
At iterate     4  f =       -147.3  |proj g|=       0.92004
At iterate     5  f =      -147.65  |proj g|=       0.86136
At iterate     6  f =      -148.01  |proj g|=        0.8479
At iterate     7  f =      -148.17  |proj g|=       0.86581
At iterate     8  f =      -148.18  |proj g|=       0.87786
At iterate     9  f =      -148.19  |proj g|=       0.87154
At iterate    10  f =      -148.19  |proj g|=       0.87161
At iterate    11  f =      -148.19  |proj g|=        0.8716

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.871602
final function value -148.186

F = -148.186
final  value -148.186389 
converged
 
INFO  [08:52:52.028] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:52:52.116] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:52:52.124] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:52:59.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:53:06.878] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:53:14.491] [mlr3]  Finished benchmark 
INFO  [08:53:14.623] [bbotk] Result of batch 9: 
INFO  [08:53:14.625] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:53:14.625] [bbotk]               2.68873                 3.361623                       0.1906598 
INFO  [08:53:14.625] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:53:14.625] [bbotk]                     4693        0.472 -0.9684738         <NA>     0.96421 
INFO  [08:53:14.625] [bbotk]                                 uhash 
INFO  [08:53:14.625] [bbotk]  d94df8ed-ea92-495f-b003-c8796ba354ba 
DEBUG [08:53:15.278] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.925984e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  7.925984e-06 0.0007974284 
  - best initial criterion value(s) :  152.0897 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -152.09  |proj g|=      0.87652
At iterate     1  f =      -153.64  |proj g|=       0.55648
At iterate     2  f =      -154.48  |proj g|=       0.70117
At iterate     3  f =       -156.2  |proj g|=       0.46876
At iterate     4  f =      -156.36  |proj g|=       0.37118
At iterate     5  f =      -156.37  |proj g|=       0.78328
At iterate     6  f =       -156.4  |proj g|=       0.40689
At iterate     7  f =       -156.4  |proj g|=       0.39563
At iterate     8  f =       -156.4  |proj g|=        0.3986
At iterate     9  f =       -156.4  |proj g|=       0.39849
At iterate    10  f =       -156.4  |proj g|=       0.39849

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.398485
final function value -156.4

F = -156.4
final  value -156.400199 
converged
 
INFO  [08:53:15.283] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:53:15.389] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:53:15.397] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:53:21.947] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:53:28.491] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:53:34.782] [mlr3]  Finished benchmark 
INFO  [08:53:34.907] [bbotk] Result of batch 10: 
INFO  [08:53:34.910] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:53:34.910] [bbotk]              4.143478                 8.803066                       0.1676096 
INFO  [08:53:34.910] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:53:34.910] [bbotk]                     4104        0.471 -0.9665695         <NA>   0.9712652 
INFO  [08:53:34.910] [bbotk]                                 uhash 
INFO  [08:53:34.910] [bbotk]  d9888376-940f-42a8-a128-d824af7bc8c2 
DEBUG [08:53:35.565] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.794465e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  7.794465e-06 0.0007987687 
  - best initial criterion value(s) :  151.0881 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -151.09  |proj g|=       1.6304
At iterate     1  f =      -151.12  |proj g|=          2.25
At iterate     2  f =      -151.98  |proj g|=        2.1575
At iterate     3  f =       -152.4  |proj g|=         1.991
At iterate     4  f =      -152.49  |proj g|=        1.9503
At iterate     5  f =      -153.02  |proj g|=        1.7126
At iterate     6  f =      -153.28  |proj g|=        1.6621
At iterate     7  f =      -153.29  |proj g|=        1.7157
At iterate     8  f =       -153.3  |proj g|=        1.6995
At iterate     9  f =       -153.3  |proj g|=        1.6988
At iterate    10  f =       -153.3  |proj g|=        1.6989

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.69885
final function value -153.297

F = -153.297
final  value -153.296850 
converged
 
INFO  [08:53:35.570] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:53:35.667] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:53:35.674] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:53:36.641] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:53:37.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:53:38.778] [mlr3]  Finished benchmark 
INFO  [08:53:38.881] [bbotk] Result of batch 11: 
INFO  [08:53:38.883] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:53:38.883] [bbotk]              8.784155                 3.852118                        0.337161 
INFO  [08:53:38.883] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:53:38.883] [bbotk]                      430        0.475 -0.9674207         <NA>   0.9641258 
INFO  [08:53:38.883] [bbotk]                                 uhash 
INFO  [08:53:38.883] [bbotk]  67fbd2d8-5cc0-42ff-9a40-eb0b8bad6c5b 
DEBUG [08:53:39.541] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.614267e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  7.614267e-06 0.0007660272 
  - best initial criterion value(s) :  153.5449 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -153.54  |proj g|=      0.90695
At iterate     1  f =      -161.48  |proj g|=       0.44902
At iterate     2  f =      -162.16  |proj g|=       0.70187
At iterate     3  f =      -162.58  |proj g|=       0.53854
At iterate     4  f =      -162.71  |proj g|=       0.50473
At iterate     5  f =      -162.88  |proj g|=       0.42473
At iterate     6  f =      -162.95  |proj g|=       0.43574
At iterate     7  f =      -162.96  |proj g|=       0.42732
At iterate     8  f =      -162.96  |proj g|=       0.42954
At iterate     9  f =      -162.96  |proj g|=       0.42944
At iterate    10  f =      -162.96  |proj g|=        0.4294

iterations 10
function evaluations 12
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.429395
final function value -162.957

F = -162.957
final  value -162.956971 
converged
 
INFO  [08:53:39.546] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:53:39.670] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:53:39.677] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:53:41.000] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:53:42.363] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:53:43.688] [mlr3]  Finished benchmark 
INFO  [08:53:43.819] [bbotk] Result of batch 12: 
INFO  [08:53:43.822] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:53:43.822] [bbotk]               3.47412                 2.182683                       0.2629216 
INFO  [08:53:43.822] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:53:43.822] [bbotk]                      652        0.475 -0.9640232         <NA>   0.9577758 
INFO  [08:53:43.822] [bbotk]                                 uhash 
INFO  [08:53:43.822] [bbotk]  209850d1-621d-4a42-9460-33ba8dbac4ac 
DEBUG [08:53:44.514] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.594795e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9597732 9458 
  - variance bounds :  7.594795e-06 0.0007722365 
  - best initial criterion value(s) :  157.7513 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -157.75  |proj g|=      0.91798
At iterate     1  f =      -165.66  |proj g|=        1.4185
At iterate     2  f =      -165.86  |proj g|=        1.2005
At iterate     3  f =      -166.64  |proj g|=       0.83773
At iterate     4  f =      -167.26  |proj g|=       0.88876
At iterate     5  f =      -167.27  |proj g|=        1.1816
At iterate     6  f =      -167.41  |proj g|=        1.0271
At iterate     7  f =      -167.42  |proj g|=       0.99785
At iterate     8  f =      -167.43  |proj g|=        1.0113
At iterate     9  f =      -167.43  |proj g|=        1.0101
At iterate    10  f =      -167.43  |proj g|=        1.0092
At iterate    11  f =      -167.43  |proj g|=        1.0091
At iterate    12  f =      -167.43  |proj g|=        1.0084
At iterate    13  f =      -167.43  |proj g|=        1.0075
At iterate    14  f =      -167.43  |proj g|=        1.0059
At iterate    15  f =      -167.43  |proj g|=         0.997
At iterate    16  f =      -167.43  |proj g|=       0.99847
At iterate    17  f =      -167.43  |proj g|=        1.0005
At iterate    18  f =      -167.43  |proj g|=        1.0043
At iterate    19  f =      -167.45  |proj g|=        1.0065
At iterate    20  f =      -167.48  |proj g|=        1.0021
At iterate    21  f =      -167.57  |proj g|=       0.97267
At iterate    22  f =      -167.79  |proj g|=       0.87014
At iterate    23  f =      -168.25  |proj g|=       0.77117
At iterate    24  f =      -169.03  |proj g|=       0.73392
At iterate    25  f =      -169.31  |proj g|=       0.75153
At iterate    26  f =      -169.61  |proj g|=       0.72081
At iterate    27  f =      -169.72  |proj g|=       0.70504
At iterate    28  f =      -169.73  |proj g|=       0.30114
At iterate    29  f =      -169.73  |proj g|=     0.0096159
At iterate    30  f =      -169.73  |proj g|=      0.009818
At iterate    31  f =      -169.73  |proj g|=     0.0098275

iterations 31
function evaluations 40
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00982752
final function value -169.729

F = -169.729
final  value -169.729153 
converged
 
INFO  [08:53:44.520] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:53:44.616] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:53:44.623] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:53:48.837] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:53:55.503] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:54:01.525] [mlr3]  Finished benchmark 
INFO  [08:54:01.628] [bbotk] Result of batch 13: 
INFO  [08:54:01.630] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:54:01.630] [bbotk]              5.608394                 5.438572                      0.01080575 
INFO  [08:54:01.630] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:54:01.630] [bbotk]                     2757        0.477 -0.9628101         <NA>    0.938749 
INFO  [08:54:01.630] [bbotk]                                 uhash 
INFO  [08:54:01.630] [bbotk]  36c1f28e-722a-4e21-9b5f-e27c04f8ebdb 
DEBUG [08:54:02.300] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.096464e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.808254e-06 0.0009096464 
  - best initial criterion value(s) :  163.5224 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -163.52  |proj g|=      0.63244
At iterate     1  f =      -166.49  |proj g|=       0.88689
At iterate     2  f =      -166.59  |proj g|=       0.88615
At iterate     3  f =      -166.69  |proj g|=        0.8842
At iterate     4  f =      -166.86  |proj g|=       0.88169
At iterate     5  f =      -167.76  |proj g|=       0.85783
At iterate     6  f =      -167.94  |proj g|=       0.84601
At iterate     7  f =      -167.99  |proj g|=         0.668
At iterate     8  f =         -168  |proj g|=       0.13112
At iterate     9  f =         -168  |proj g|=       0.25437
At iterate    10  f =         -168  |proj g|=       0.13151
At iterate    11  f =         -168  |proj g|=       0.13181
At iterate    12  f =         -168  |proj g|=       0.13181

iterations 12
function evaluations 17
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.131814
final function value -168

F = -168
final  value -168.000310 
converged
 
INFO  [08:54:02.304] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:54:02.434] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:54:02.442] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:54:08.855] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:54:13.715] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:54:19.898] [mlr3]  Finished benchmark 
INFO  [08:54:20.021] [bbotk] Result of batch 14: 
INFO  [08:54:20.023] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:54:20.023] [bbotk]              6.292662                  5.95964                       0.1520871 
INFO  [08:54:20.023] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:54:20.023] [bbotk]                     2468        0.483 -0.9656913         <NA>   0.9704674 
INFO  [08:54:20.023] [bbotk]                                 uhash 
INFO  [08:54:20.023] [bbotk]  c04efd69-d902-4026-bab5-d922f49dad30 
DEBUG [08:54:20.809] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.948931e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.639415e-06 0.0008948931 
  - best initial criterion value(s) :  167.328 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -167.33  |proj g|=       0.9113
At iterate     1  f =      -167.66  |proj g|=       0.56468
At iterate     2  f =      -170.46  |proj g|=       0.38106
At iterate     3  f =      -173.12  |proj g|=        0.1679
At iterate     4  f =       -173.3  |proj g|=       0.15908
At iterate     5  f =      -173.37  |proj g|=       0.13879
At iterate     6  f =      -173.37  |proj g|=       0.11977
At iterate     7  f =      -173.37  |proj g|=      0.099155
At iterate     8  f =      -173.37  |proj g|=      0.099172

iterations 8
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.0991719
final function value -173.373

F = -173.373
final  value -173.372920 
converged
 
INFO  [08:54:20.814] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:54:20.946] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:54:20.954] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:54:23.545] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:54:26.688] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:54:29.210] [mlr3]  Finished benchmark 
INFO  [08:54:29.365] [bbotk] Result of batch 15: 
INFO  [08:54:29.367] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:54:29.367] [bbotk]              6.030433                 7.745572                       0.3868106 
INFO  [08:54:29.367] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:54:29.367] [bbotk]                     1197        0.608 -0.9648681         <NA>    0.971325 
INFO  [08:54:29.367] [bbotk]                                 uhash 
INFO  [08:54:29.367] [bbotk]  7db4009d-9d2d-488a-8dc6-c112a82c9eb8 
DEBUG [08:54:30.070] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.825856e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.422857e-06 0.0008825856 
  - best initial criterion value(s) :  171.0708 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -171.07  |proj g|=      0.91222
At iterate     1  f =      -173.94  |proj g|=       0.71712
At iterate     2  f =      -174.32  |proj g|=        1.0312
At iterate     3  f =      -174.47  |proj g|=       0.97493
At iterate     4  f =      -174.51  |proj g|=       0.88594
At iterate     5  f =      -174.52  |proj g|=       0.92313
At iterate     6  f =      -174.52  |proj g|=        0.9176
At iterate     7  f =      -174.52  |proj g|=       0.91679
At iterate     8  f =      -174.52  |proj g|=        0.9167
At iterate     9  f =      -174.52  |proj g|=       0.91698
At iterate    10  f =      -174.52  |proj g|=       0.91685

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.916849
final function value -174.523

F = -174.523
final  value -174.523475 
converged
 
INFO  [08:54:30.075] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:54:30.165] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:54:30.172] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:54:39.139] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:54:46.989] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:54:54.485] [mlr3]  Finished benchmark 
INFO  [08:54:54.596] [bbotk] Result of batch 16: 
INFO  [08:54:54.598] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:54:54.598] [bbotk]              8.810062                 4.427457                       0.4428684 
INFO  [08:54:54.598] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:54:54.598] [bbotk]                     3254         0.52 -0.9667231         <NA>   0.9719085 
INFO  [08:54:54.598] [bbotk]                                 uhash 
INFO  [08:54:54.598] [bbotk]  44bae401-aa3c-453b-9282-cc0467e7c6f2 
DEBUG [08:54:55.308] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.720042e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.493806e-06 0.0008720042 
  - best initial criterion value(s) :  181.0372 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -181.04  |proj g|=      0.88347
At iterate     1  f =      -182.67  |proj g|=       0.22409
At iterate     2  f =      -183.08  |proj g|=       0.42266
At iterate     3  f =      -183.08  |proj g|=       0.17501
At iterate     4  f =      -183.08  |proj g|=       0.17223
At iterate     5  f =      -183.08  |proj g|=       0.17177
At iterate     6  f =      -183.08  |proj g|=       0.17193
At iterate     7  f =      -183.08  |proj g|=       0.17196

iterations 7
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.171961
final function value -183.079

F = -183.079
final  value -183.078633 
converged
 
INFO  [08:54:55.312] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:54:55.403] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:54:55.411] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:55:03.153] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:55:10.017] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:55:15.948] [mlr3]  Finished benchmark 
INFO  [08:55:16.047] [bbotk] Result of batch 17: 
INFO  [08:55:16.049] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:55:16.049] [bbotk]              8.376863                 2.464354                       0.4569418 
INFO  [08:55:16.049] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:55:16.049] [bbotk]                     3022        0.526 -0.9647076         <NA>   0.9723721 
INFO  [08:55:16.049] [bbotk]                                 uhash 
INFO  [08:55:16.049] [bbotk]  c72892f7-30cc-46b6-8b4a-eae1d6a4ef48 
DEBUG [08:55:16.842] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.627692e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.425854e-06 0.0008627692 
  - best initial criterion value(s) :  174.5967 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -174.6  |proj g|=        0.937
At iterate     1  f =      -181.25  |proj g|=       0.71022
At iterate     2  f =      -181.29  |proj g|=        1.2005
At iterate     3  f =      -181.74  |proj g|=        1.0979
At iterate     4  f =      -181.93  |proj g|=       0.97821
At iterate     5  f =      -181.94  |proj g|=       0.95728
At iterate     6  f =      -181.94  |proj g|=       0.96246
At iterate     7  f =      -181.94  |proj g|=         0.963
At iterate     8  f =      -181.94  |proj g|=       0.96263
At iterate     9  f =      -181.94  |proj g|=       0.96233
At iterate    10  f =      -181.94  |proj g|=       0.96241

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.962409
final function value -181.937

F = -181.937
final  value -181.937490 
converged
 
INFO  [08:55:16.846] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:55:16.932] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:55:16.939] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:55:26.424] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:55:37.723] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:55:47.690] [mlr3]  Finished benchmark 
INFO  [08:55:47.808] [bbotk] Result of batch 18: 
INFO  [08:55:47.810] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:55:47.810] [bbotk]              3.661929                 2.734028                       0.0233963 
INFO  [08:55:47.810] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:55:47.810] [bbotk]                     4165        0.574 -0.9681964         <NA>   0.9518792 
INFO  [08:55:47.810] [bbotk]                                 uhash 
INFO  [08:55:47.810] [bbotk]  62cd5ef4-d9a8-4044-8eaa-4e8a40c8cacf 
DEBUG [08:55:48.576] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.844771e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.485668e-06 0.0008844771 
  - best initial criterion value(s) :  176.8326 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -176.83  |proj g|=       2.4818
At iterate     1  f =      -179.41  |proj g|=        3.4361
At iterate     2  f =      -179.62  |proj g|=        3.4301
At iterate     3  f =      -179.63  |proj g|=        3.4291
At iterate     4  f =      -179.63  |proj g|=        3.4268
At iterate     5  f =      -179.63  |proj g|=        3.4255
At iterate     6  f =      -179.63  |proj g|=        3.4241
At iterate     7  f =      -179.63  |proj g|=        3.4241

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.4241
final function value -179.631

F = -179.631
final  value -179.630754 
converged
 
INFO  [08:55:48.580] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:55:48.667] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:55:48.674] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:55:55.943] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:56:02.643] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:56:09.347] [mlr3]  Finished benchmark 
INFO  [08:56:09.446] [bbotk] Result of batch 19: 
INFO  [08:56:09.448] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:56:09.448] [bbotk]              5.780013                 5.533716                       0.3898588 
INFO  [08:56:09.448] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:56:09.448] [bbotk]                     3141        0.577 -0.9681841         <NA>   0.9743906 
INFO  [08:56:09.448] [bbotk]                                 uhash 
INFO  [08:56:09.448] [bbotk]  591dfacb-67ad-4013-8ba9-37bb4024b901 
DEBUG [08:56:10.150] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.82097e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.601181e-06 0.000882097 
  - best initial criterion value(s) :  180.0206 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -180.02  |proj g|=       0.9462
At iterate     1  f =      -191.63  |proj g|=       0.62537
At iterate     2  f =      -192.54  |proj g|=        1.6665
At iterate     3  f =      -192.99  |proj g|=        1.5627
At iterate     4  f =      -193.52  |proj g|=        1.3128
At iterate     5  f =      -193.55  |proj g|=         1.255
At iterate     6  f =      -193.55  |proj g|=        1.2491
At iterate     7  f =      -193.56  |proj g|=        1.2484
At iterate     8  f =      -193.56  |proj g|=        1.2683
At iterate     9  f =      -193.56  |proj g|=        1.2593
At iterate    10  f =      -193.56  |proj g|=        1.2593

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.25929
final function value -193.557

F = -193.557
final  value -193.556762 
converged
 
INFO  [08:56:10.154] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:56:10.257] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:56:10.263] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:56:12.249] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:56:14.418] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:56:16.321] [mlr3]  Finished benchmark 
INFO  [08:56:16.420] [bbotk] Result of batch 20: 
INFO  [08:56:16.422] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:56:16.422] [bbotk]              7.655281                 4.666764                       0.4894984 
INFO  [08:56:16.422] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:56:16.422] [bbotk]                      909        0.515 -0.9666176         <NA>   0.9712947 
INFO  [08:56:16.422] [bbotk]                                 uhash 
INFO  [08:56:16.422] [bbotk]  046a5bb5-df2b-4264-9463-b5395f4ea8c9 
DEBUG [08:56:17.136] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.705573e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.408751e-06 0.0008705573 
  - best initial criterion value(s) :  199.4809 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -199.48  |proj g|=      0.27311
At iterate     1  f =      -201.57  |proj g|=       0.32655
At iterate     2  f =      -201.57  |proj g|=       0.31592
At iterate     3  f =      -201.57  |proj g|=       0.30403
At iterate     4  f =      -201.57  |proj g|=       0.29993
At iterate     5  f =      -201.58  |proj g|=        0.2851
At iterate     6  f =      -201.59  |proj g|=       0.27613
At iterate     7  f =       -201.6  |proj g|=       0.27882
At iterate     8  f =       -201.6  |proj g|=       0.28922
At iterate     9  f =       -201.6  |proj g|=       0.29338
At iterate    10  f =       -201.6  |proj g|=       0.29369
At iterate    11  f =       -201.6  |proj g|=       0.29369

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.293691
final function value -201.6

F = -201.6
final  value -201.599509 
converged
 
INFO  [08:56:17.140] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:56:17.229] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:56:17.236] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:56:26.806] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:56:37.232] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:56:47.714] [mlr3]  Finished benchmark 
INFO  [08:56:47.816] [bbotk] Result of batch 21: 
INFO  [08:56:47.818] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:56:47.818] [bbotk]              2.709194                 2.279421                      0.09918331 
INFO  [08:56:47.818] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:56:47.818] [bbotk]                     4207        0.516 -0.9654015         <NA>   0.9588311 
INFO  [08:56:47.818] [bbotk]                                 uhash 
INFO  [08:56:47.818] [bbotk]  0004ae01-0e33-4a8d-b5fc-072b07d061ec 
DEBUG [08:56:48.529] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.628953e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.218539e-06 0.0008628953 
  - best initial criterion value(s) :  187.5487 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -187.55  |proj g|=       2.6194
At iterate     1  f =      -193.89  |proj g|=        2.4163
At iterate     2  f =      -194.03  |proj g|=        2.5622
At iterate     3  f =      -194.03  |proj g|=        2.5646
At iterate     4  f =      -194.04  |proj g|=        2.5782
At iterate     5  f =      -194.04  |proj g|=        2.5844
At iterate     6  f =      -194.04  |proj g|=         2.587
At iterate     7  f =      -194.04  |proj g|=         2.587

iterations 7
function evaluations 11
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.587
final function value -194.036

F = -194.036
final  value -194.035990 
converged
 
INFO  [08:56:48.534] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:56:48.651] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:56:48.657] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:56:49.818] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:56:51.046] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:56:52.181] [mlr3]  Finished benchmark 
INFO  [08:56:52.280] [bbotk] Result of batch 22: 
INFO  [08:56:52.282] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:56:52.282] [bbotk]              9.019144                 4.463338                      0.09465829 
INFO  [08:56:52.282] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:56:52.282] [bbotk]                      398        0.519 -0.9686397         <NA>   0.9469868 
INFO  [08:56:52.282] [bbotk]                                 uhash 
INFO  [08:56:52.282] [bbotk]  4f76e7c9-75f1-443d-8491-e525e3e4d948 
DEBUG [08:56:53.048] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.123089e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  9.02134e-06 0.0009123089 
  - best initial criterion value(s) :  198.0148 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -198.01  |proj g|=       1.6804
At iterate     1  f =      -198.11  |proj g|=        1.7508
At iterate     2  f =      -198.21  |proj g|=        1.6603
At iterate     3  f =      -198.33  |proj g|=        1.4845
At iterate     4  f =      -198.35  |proj g|=        1.4959
At iterate     5  f =      -198.35  |proj g|=        1.4984
At iterate     6  f =      -198.35  |proj g|=        1.4982
At iterate     7  f =      -198.35  |proj g|=        1.4971
At iterate     8  f =      -198.35  |proj g|=         1.496
At iterate     9  f =      -198.35  |proj g|=        1.4918
At iterate    10  f =      -198.35  |proj g|=         1.486
At iterate    11  f =      -198.35  |proj g|=        1.4894
At iterate    12  f =      -198.35  |proj g|=        1.4776
At iterate    13  f =      -198.36  |proj g|=        1.4537
At iterate    14  f =       -198.4  |proj g|=        1.3907
At iterate    15  f =      -198.57  |proj g|=        1.2494
At iterate    16  f =      -199.18  |proj g|=       0.95107
At iterate    17  f =      -199.19  |proj g|=        0.9233
At iterate    18  f =      -200.74  |proj g|=       0.89136
At iterate    19  f =      -204.05  |proj g|=       0.85582
At iterate    20  f =       -204.9  |proj g|=       0.84201
At iterate    21  f =      -204.93  |proj g|=       0.84002
At iterate    22  f =         -205  |proj g|=       0.83218
At iterate    23  f =         -205  |proj g|=       0.07844
At iterate    24  f =         -205  |proj g|=       0.34025
At iterate    25  f =         -205  |proj g|=      0.023674
At iterate    26  f =         -205  |proj g|=      0.023671

iterations 26
function evaluations 36
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0236713
final function value -205.004

F = -205.004
final  value -205.003882 
converged
 
INFO  [08:56:53.052] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:56:53.163] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:56:53.174] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:57:02.279] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:57:11.463] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:57:20.348] [mlr3]  Finished benchmark 
INFO  [08:57:20.451] [bbotk] Result of batch 23: 
INFO  [08:57:20.453] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:57:20.453] [bbotk]              2.475674                 2.634745                       0.4567965 
INFO  [08:57:20.453] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:57:20.453] [bbotk]                     4101        0.523 -0.9632529         <NA>   0.9668631 
INFO  [08:57:20.453] [bbotk]                                 uhash 
INFO  [08:57:20.453] [bbotk]  c1cc6acc-b654-4af8-be99-b151f9db1e43 
DEBUG [08:57:21.183] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.955263e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.89625e-06 0.0008955263 
  - best initial criterion value(s) :  201.1936 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -201.19  |proj g|=      0.58238
At iterate     1  f =      -201.47  |proj g|=        1.1611
At iterate     2  f =      -201.49  |proj g|=         1.129
At iterate     3  f =      -201.57  |proj g|=       0.93715
At iterate     4  f =      -201.67  |proj g|=       0.82497
At iterate     5  f =      -201.99  |proj g|=       0.69712
At iterate     6  f =      -202.27  |proj g|=        0.9364
At iterate     7  f =      -202.33  |proj g|=        1.1407
At iterate     8  f =      -202.33  |proj g|=        1.1362
At iterate     9  f =      -202.33  |proj g|=         1.138
At iterate    10  f =      -202.33  |proj g|=        1.1381

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.13814
final function value -202.327

F = -202.327
final  value -202.327080 
converged
 
INFO  [08:57:21.187] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:57:21.277] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:57:21.284] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:57:31.596] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:57:41.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:57:55.468] [mlr3]  Finished benchmark 
INFO  [08:57:55.570] [bbotk] Result of batch 24: 
INFO  [08:57:55.572] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:57:55.572] [bbotk]              9.052842                 8.732031                      0.01513383 
INFO  [08:57:55.572] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:57:55.572] [bbotk]                     4468        0.527 -0.9685393         <NA>   0.9548948 
INFO  [08:57:55.572] [bbotk]                                 uhash 
INFO  [08:57:55.572] [bbotk]  323132a5-28cc-4877-80fa-cf354b6f66fe 
DEBUG [08:57:56.319] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.988789e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.888927e-06 0.0008988789 
  - best initial criterion value(s) :  202.4882 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -202.49  |proj g|=       1.1582
At iterate     1  f =      -206.58  |proj g|=        0.9369
At iterate     2  f =      -207.68  |proj g|=       0.86728
At iterate     3  f =      -208.17  |proj g|=        0.5872
At iterate     4  f =      -208.47  |proj g|=       0.84865
At iterate     5  f =      -208.51  |proj g|=       0.84709
At iterate     6  f =      -208.56  |proj g|=       0.84397
At iterate     7  f =      -208.68  |proj g|=       0.83686
At iterate     8  f =      -208.95  |proj g|=       0.74908
At iterate     9  f =      -209.05  |proj g|=       0.82972
At iterate    10  f =      -209.22  |proj g|=       0.87762
At iterate    11  f =      -209.26  |proj g|=       0.91117
At iterate    12  f =      -209.26  |proj g|=       0.92328
At iterate    13  f =      -209.26  |proj g|=       0.92739
At iterate    14  f =      -209.26  |proj g|=       0.92804
At iterate    15  f =      -209.26  |proj g|=         0.928

iterations 15
function evaluations 19
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.928004
final function value -209.258

F = -209.258
final  value -209.258226 
converged
 
INFO  [08:57:56.324] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:57:56.414] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:57:56.421] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:58:03.572] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:58:10.743] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:58:17.432] [mlr3]  Finished benchmark 
INFO  [08:58:17.533] [bbotk] Result of batch 25: 
INFO  [08:58:17.535] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:58:17.535] [bbotk]              5.678044                 7.976646                        0.429516 
INFO  [08:58:17.535] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:58:17.535] [bbotk]                     3448        0.537 -0.9624836         <NA>   0.9748374 
INFO  [08:58:17.535] [bbotk]                                 uhash 
INFO  [08:58:17.535] [bbotk]  694c3696-5690-4836-8640-b47f2fb47fb9 
DEBUG [08:58:18.278] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.992046e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.992046e-06 0.0009036942 
  - best initial criterion value(s) :  204.7045 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -204.7  |proj g|=       2.2421
At iterate     1  f =      -204.76  |proj g|=        2.2274
At iterate     2  f =      -204.83  |proj g|=        2.2149
At iterate     3  f =      -204.84  |proj g|=        2.2203
At iterate     4  f =      -204.84  |proj g|=        2.2193
At iterate     5  f =      -204.84  |proj g|=        2.2192
At iterate     6  f =      -204.84  |proj g|=        2.2192

iterations 6
function evaluations 9
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.21922
final function value -204.84

F = -204.84
final  value -204.839629 
converged
 
INFO  [08:58:18.282] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:58:18.696] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:58:18.707] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:58:20.318] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:58:21.924] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:58:23.643] [mlr3]  Finished benchmark 
INFO  [08:58:23.745] [bbotk] Result of batch 26: 
INFO  [08:58:23.747] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:58:23.747] [bbotk]              9.779932                  5.12228                       0.2605741 
INFO  [08:58:23.747] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:58:23.747] [bbotk]                      648        0.559 -0.9690128         <NA>   0.9654141 
INFO  [08:58:23.747] [bbotk]                                 uhash 
INFO  [08:58:23.747] [bbotk]  a126bdaf-7a2f-41dd-a2a6-5877460edc01 
DEBUG [08:58:24.509] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.831482e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.824631e-06 0.0008831482 
  - best initial criterion value(s) :  217.1319 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -217.13  |proj g|=      0.50835
At iterate     1  f =      -217.65  |proj g|=       0.64502
At iterate     2  f =      -217.66  |proj g|=       0.63716
At iterate     3  f =      -217.66  |proj g|=       0.63288
At iterate     4  f =      -217.66  |proj g|=       0.63011
At iterate     5  f =      -217.67  |proj g|=        0.6216
At iterate     6  f =      -217.68  |proj g|=       0.61077
At iterate     7  f =       -217.7  |proj g|=       0.59767
At iterate     8  f =      -217.71  |proj g|=       0.59966
At iterate     9  f =      -217.71  |proj g|=       0.82012
At iterate    10  f =      -217.71  |proj g|=       0.81976
At iterate    11  f =      -217.71  |proj g|=       0.81966
At iterate    12  f =      -217.71  |proj g|=       0.81966

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.819657
final function value -217.714

F = -217.714
final  value -217.714138 
converged
 
INFO  [08:58:24.514] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:58:24.606] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:58:24.614] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:58:30.378] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:58:36.898] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:58:42.811] [mlr3]  Finished benchmark 
INFO  [08:58:42.913] [bbotk] Result of batch 27: 
INFO  [08:58:42.915] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:58:42.915] [bbotk]              6.204289                 7.796098                       0.4932943 
INFO  [08:58:42.915] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:58:42.915] [bbotk]                     2650        0.558 -0.9664294         <NA>   0.9746641 
INFO  [08:58:42.915] [bbotk]                                 uhash 
INFO  [08:58:42.915] [bbotk]  8b9786c2-0ef8-4ee0-89a6-b53fbf7ee134 
DEBUG [08:58:43.646] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.826134e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.964977 9458 
  - variance bounds :  8.789816e-06 0.0008826134 
  - best initial criterion value(s) :  223.6637 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -223.66  |proj g|=      0.15405
At iterate     1  f =      -224.92  |proj g|=        0.8507
At iterate     2  f =      -224.93  |proj g|=       0.82612
At iterate     3  f =      -224.94  |proj g|=       0.82486
At iterate     4  f =      -224.96  |proj g|=         0.823
At iterate     5  f =      -225.03  |proj g|=       0.81636
At iterate     6  f =      -225.15  |proj g|=       0.51831
At iterate     7  f =      -225.32  |proj g|=       0.52896
At iterate     8  f =      -225.38  |proj g|=        0.6143
At iterate     9  f =      -225.39  |proj g|=       0.66947
At iterate    10  f =      -225.39  |proj g|=       0.68279
At iterate    11  f =      -225.39  |proj g|=       0.68361
At iterate    12  f =      -225.39  |proj g|=       0.68362

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.683624
final function value -225.386

F = -225.386
final  value -225.385750 
converged
 
INFO  [08:58:43.650] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:58:43.741] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:58:43.749] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:58:46.571] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:58:50.754] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:58:54.141] [mlr3]  Finished benchmark 
INFO  [08:58:54.245] [bbotk] Result of batch 28: 
INFO  [08:58:54.247] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:58:54.247] [bbotk]              6.260693                 9.519692                       0.1744609 
INFO  [08:58:54.247] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:58:54.247] [bbotk]                     1342        0.537 -0.9648146         <NA>   0.9676735 
INFO  [08:58:54.247] [bbotk]                                 uhash 
INFO  [08:58:54.247] [bbotk]  3ab01946-bfbf-4489-8105-38303d786e96 
DEBUG [08:58:55.012] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.681892e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.964977 9458 
  - variance bounds :  8.582848e-06 0.0008681892 
  - best initial criterion value(s) :  205.9946 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -205.99  |proj g|=       1.1356
At iterate     1  f =       -215.5  |proj g|=        1.5462
At iterate     2  f =      -215.63  |proj g|=        1.5348
At iterate     3  f =      -215.82  |proj g|=        1.4694
At iterate     4  f =      -215.86  |proj g|=        1.4859
At iterate     5  f =      -215.94  |proj g|=        1.4689
At iterate     6  f =      -216.44  |proj g|=         1.239
At iterate     7  f =      -216.53  |proj g|=        1.1717
At iterate     8  f =      -216.54  |proj g|=        1.1692
At iterate     9  f =      -216.54  |proj g|=        1.1702
At iterate    10  f =      -216.54  |proj g|=        1.1699
At iterate    11  f =      -216.54  |proj g|=        1.1699

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.16994
final function value -216.537

F = -216.537
final  value -216.536517 
converged
 
INFO  [08:58:55.016] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:58:55.146] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:58:55.154] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:58:57.596] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:59:00.774] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:59:03.464] [mlr3]  Finished benchmark 
INFO  [08:59:03.567] [bbotk] Result of batch 29: 
INFO  [08:59:03.569] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:59:03.569] [bbotk]              4.974739                 4.380571                       0.1062948 
INFO  [08:59:03.569] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:59:03.569] [bbotk]                     1031        0.569 -0.9693783         <NA>   0.9587677 
INFO  [08:59:03.569] [bbotk]                                 uhash 
INFO  [08:59:03.569] [bbotk]  f6a0128d-11aa-4853-bdb3-e1ba18aa4b6e 
DEBUG [08:59:04.308] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.611334e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.964977 9458 
  - variance bounds :  8.535603e-06 0.0008611333 
  - best initial criterion value(s) :  228.4922 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -228.49  |proj g|=       0.8883
At iterate     1  f =      -230.26  |proj g|=       0.83458
At iterate     2  f =      -231.19  |proj g|=        1.0377
At iterate     3  f =      -231.28  |proj g|=         1.013
At iterate     4  f =      -231.29  |proj g|=        1.0072
At iterate     5  f =      -231.29  |proj g|=        1.0072
At iterate     6  f =      -231.29  |proj g|=        1.0072

iterations 6
function evaluations 10
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.00719
final function value -231.285

F = -231.285
final  value -231.285303 
converged
 
INFO  [08:59:04.312] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:59:04.404] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:59:04.435] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:59:15.384] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:59:25.785] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:59:33.140] [mlr3]  Finished benchmark 
INFO  [08:59:33.280] [bbotk] Result of batch 30: 
INFO  [08:59:33.283] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:59:33.283] [bbotk]              5.416464                 4.417359                       0.2885662 
INFO  [08:59:33.283] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:59:33.283] [bbotk]                     4407        0.549 -0.9634776         <NA>    0.974472 
INFO  [08:59:33.283] [bbotk]                                 uhash 
INFO  [08:59:33.283] [bbotk]  daca6c96-b839-4633-b213-74e8325e3ab7 
DEBUG [08:59:34.265] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.601728e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.964977 9458 
  - variance bounds :  8.601728e-06 0.0008670534 
  - best initial criterion value(s) :  233.2068 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -233.21  |proj g|=        2.406
At iterate     1  f =      -233.71  |proj g|=        2.8201
At iterate     2  f =      -233.72  |proj g|=        2.7875
At iterate     3  f =      -233.77  |proj g|=         2.697
At iterate     4  f =      -233.83  |proj g|=        2.5957
At iterate     5  f =      -234.03  |proj g|=        2.3111
At iterate     6  f =      -234.33  |proj g|=        1.9578
At iterate     7  f =       -234.5  |proj g|=        1.8252
At iterate     8  f =      -234.54  |proj g|=        1.9792
At iterate     9  f =      -234.54  |proj g|=        1.9814
At iterate    10  f =      -234.54  |proj g|=        1.9819
At iterate    11  f =      -234.54  |proj g|=        1.9821
At iterate    12  f =      -234.54  |proj g|=        1.9826
At iterate    13  f =      -234.54  |proj g|=        1.9834
At iterate    14  f =      -234.54  |proj g|=        1.9847
At iterate    15  f =      -234.54  |proj g|=         1.987
At iterate    16  f =      -234.54  |proj g|=        1.9911
At iterate    17  f =      -234.54  |proj g|=        1.9976
At iterate    18  f =      -234.54  |proj g|=        2.0047
At iterate    19  f =      -234.54  |proj g|=         2.004
At iterate    20  f =      -234.54  |proj g|=         2.002
At iterate    21  f =      -234.54  |proj g|=         1.989
At iterate    22  f =      -234.54  |proj g|=        1.9726
At iterate    23  f =      -234.55  |proj g|=        1.9396
At iterate    24  f =      -234.56  |proj g|=         1.885
At iterate    25  f =       -234.6  |proj g|=        1.7911
At iterate    26  f =      -234.69  |proj g|=        1.6243
At iterate    27  f =      -234.94  |proj g|=        1.3311
At iterate    28  f =      -235.04  |proj g|=        1.1194
At iterate    29  f =       -235.7  |proj g|=       0.88789
At iterate    30  f =       -237.3  |proj g|=       0.87905
At iterate    31  f =      -238.41  |proj g|=       0.86342
At iterate    32  f =      -239.15  |proj g|=       0.84004
At iterate    33  f =      -239.44  |proj g|=       0.14595
At iterate    34  f =      -239.49  |proj g|=       0.81501
At iterate    35  f =      -239.57  |proj g|=       0.80372
At iterate    36  f =      -239.57  |proj g|=        0.1666
At iterate    37  f =      -239.57  |proj g|=        0.1662
At iterate    38  f =      -239.57  |proj g|=       0.16623

iterations 38
function evaluations 43
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.166226
final function value -239.57

F = -239.57
final  value -239.570374 
converged
 
INFO  [08:59:34.270] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:59:34.582] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:59:34.591] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:59:37.114] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:59:39.679] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:59:42.641] [mlr3]  Finished benchmark 
INFO  [08:59:42.758] [bbotk] Result of batch 31: 
INFO  [08:59:42.760] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:59:42.760] [bbotk]              3.248555                 4.301086                       0.2876883 
INFO  [08:59:42.760] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:59:42.760] [bbotk]                     1474        0.742 -0.9629851         <NA>   0.9648029 
INFO  [08:59:42.760] [bbotk]                                 uhash 
INFO  [08:59:42.760] [bbotk]  fd7236cf-3c11-4ad1-a649-876391df90d7 
DEBUG [08:59:43.530] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.461695e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.964977 9458 
  - variance bounds :  8.461695e-06 0.0008477168 
  - best initial criterion value(s) :  239.6969 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -239.7  |proj g|=      0.23933
At iterate     1  f =      -240.75  |proj g|=        1.3814
At iterate     2  f =      -242.25  |proj g|=         1.142
At iterate     3  f =      -242.88  |proj g|=       0.87586
At iterate     4  f =      -242.93  |proj g|=        0.8402
At iterate     5  f =      -242.94  |proj g|=       0.84003
At iterate     6  f =      -243.02  |proj g|=       0.84276
At iterate     7  f =      -243.17  |proj g|=       0.93241
At iterate     8  f =      -243.46  |proj g|=        1.0337
At iterate     9  f =      -243.69  |proj g|=         1.034
At iterate    10  f =      -243.73  |proj g|=       0.99568
At iterate    11  f =      -243.75  |proj g|=       0.93388
At iterate    12  f =      -243.75  |proj g|=       0.90784
At iterate    13  f =      -243.75  |proj g|=       0.91052
At iterate    14  f =      -243.75  |proj g|=       0.91049

iterations 14
function evaluations 17
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.910486
final function value -243.754

F = -243.754
final  value -243.753544 
converged
 
INFO  [08:59:43.534] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:59:43.619] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:59:43.626] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [08:59:46.955] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:59:50.533] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:59:53.834] [mlr3]  Finished benchmark 
INFO  [08:59:53.931] [bbotk] Result of batch 32: 
INFO  [08:59:53.933] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [08:59:53.933] [bbotk]              2.077107                 5.924013                       0.1255595 
INFO  [08:59:53.933] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [08:59:53.933] [bbotk]                     2108        0.571 -0.9631874         <NA>   0.9486348 
INFO  [08:59:53.933] [bbotk]                                 uhash 
INFO  [08:59:53.933] [bbotk]  5b8dfda0-3947-4275-b567-184acc8bbe9c 
DEBUG [08:59:54.701] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.780419e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80182 15.35399 0.964977 9458 
  - variance bounds :  8.707705e-06 0.0008780419 
  - best initial criterion value(s) :  242.0299 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -242.03  |proj g|=       2.5674
At iterate     1  f =      -243.17  |proj g|=        3.0877
At iterate     2  f =      -243.69  |proj g|=        2.7172
At iterate     3  f =      -244.23  |proj g|=        2.1853
At iterate     4  f =      -244.27  |proj g|=        1.9386
At iterate     5  f =       -244.3  |proj g|=        2.0695
At iterate     6  f =       -244.3  |proj g|=        2.0485
At iterate     7  f =       -244.3  |proj g|=        2.0497
At iterate     8  f =       -244.3  |proj g|=        2.0467
At iterate     9  f =       -244.3  |proj g|=         2.043
At iterate    10  f =       -244.3  |proj g|=        2.0371
At iterate    11  f =       -244.3  |proj g|=        2.0223
At iterate    12  f =      -244.31  |proj g|=        2.0012
At iterate    13  f =      -244.31  |proj g|=        1.9632
At iterate    14  f =      -244.33  |proj g|=        1.9156
At iterate    15  f =      -244.34  |proj g|=        1.6893
At iterate    16  f =       -244.4  |proj g|=        1.7594
At iterate    17  f =      -244.61  |proj g|=        1.8327
At iterate    18  f =      -245.18  |proj g|=        1.8272
At iterate    19  f =       -246.4  |proj g|=        1.5946
At iterate    20  f =      -248.71  |proj g|=        1.1055
At iterate    21  f =      -249.91  |proj g|=       0.35739
At iterate    22  f =       -250.1  |proj g|=       0.35531
At iterate    23  f =      -250.33  |proj g|=       0.31573
At iterate    24  f =      -250.46  |proj g|=       0.75508
At iterate    25  f =       -250.5  |proj g|=       0.20272
At iterate    26  f =      -250.51  |proj g|=        0.1873
At iterate    27  f =      -250.51  |proj g|=       0.18549
At iterate    28  f =      -250.51  |proj g|=       0.18527
At iterate    29  f =      -250.51  |proj g|=       0.18558
At iterate    30  f =      -250.51  |proj g|=       0.18547

iterations 30
function evaluations 42
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.185465
final function value -250.506

F = -250.506
final  value -250.505621 
converged
 
INFO  [08:59:54.705] [bbotk] Evaluating 1 configuration(s) 
INFO  [08:59:54.806] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [08:59:54.812] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [08:59:57.090] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [08:59:59.319] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:00:01.616] [mlr3]  Finished benchmark 
INFO  [09:00:01.715] [bbotk] Result of batch 33: 
INFO  [09:00:01.716] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:00:01.716] [bbotk]              9.982777                 3.986169                       0.4310392 
INFO  [09:00:01.716] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:00:01.716] [bbotk]                     1372        0.529 -0.9601325         <NA>    0.968949 
INFO  [09:00:01.716] [bbotk]                                 uhash 
INFO  [09:00:01.716] [bbotk]  a9a86436-90a7-4408-a789-5db44b511b36 
DEBUG [09:00:02.500] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.661846e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.509058e-06 0.0008661846 
  - best initial criterion value(s) :  236.1154 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -236.12  |proj g|=      0.62135
At iterate     1  f =      -236.78  |proj g|=       0.79888
At iterate     2  f =      -236.82  |proj g|=       0.66369
At iterate     3  f =      -236.83  |proj g|=       0.65993
At iterate     4  f =      -236.83  |proj g|=       0.66008
At iterate     5  f =      -236.84  |proj g|=       0.65791
At iterate     6  f =      -236.86  |proj g|=       0.80519
At iterate     7  f =      -236.87  |proj g|=       0.80938
At iterate     8  f =      -236.87  |proj g|=       0.81074
At iterate     9  f =      -236.87  |proj g|=       0.81036
At iterate    10  f =      -236.87  |proj g|=       0.81026
At iterate    11  f =      -236.87  |proj g|=       0.81025
At iterate    12  f =      -236.87  |proj g|=       0.81014
At iterate    13  f =      -236.87  |proj g|=       0.81001
At iterate    14  f =      -236.87  |proj g|=       0.80979
At iterate    15  f =      -236.87  |proj g|=       0.80937
At iterate    16  f =      -236.87  |proj g|=       0.80878
At iterate    17  f =      -236.88  |proj g|=       0.63419
At iterate    18  f =      -236.88  |proj g|=       0.63084
At iterate    19  f =      -236.88  |proj g|=       0.63403
At iterate    20  f =      -236.91  |proj g|=       0.63912
At iterate    21  f =      -236.96  |proj g|=       0.63904
At iterate    22  f =      -237.09  |proj g|=       0.62233
At iterate    23  f =      -237.33  |proj g|=       0.57264
At iterate    24  f =      -237.49  |proj g|=       0.78913
At iterate    25  f =      -237.95  |proj g|=       0.49453
At iterate    26  f =      -238.48  |proj g|=       0.49099
At iterate    27  f =      -238.67  |proj g|=       0.44154
At iterate    28  f =      -238.85  |proj g|=       0.37453
At iterate    29  f =      -238.88  |proj g|=       0.41391
At iterate    30  f =      -238.89  |proj g|=       0.37335
At iterate    31  f =      -238.89  |proj g|=       0.37635
At iterate    32  f =      -238.89  |proj g|=       0.37618

iterations 32
function evaluations 40
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.376182
final function value -238.892

F = -238.892
final  value -238.891971 
converged
 
INFO  [09:00:02.504] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:00:02.590] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:00:02.597] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:00:04.280] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:00:06.209] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:00:08.067] [mlr3]  Finished benchmark 
INFO  [09:00:08.184] [bbotk] Result of batch 34: 
INFO  [09:00:08.187] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:00:08.187] [bbotk]              5.569574                 8.055411                       0.4906857 
INFO  [09:00:08.187] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [09:00:08.187] [bbotk]                     1077        0.539 -0.969669         <NA>   0.9716707 
INFO  [09:00:08.187] [bbotk]                                 uhash 
INFO  [09:00:08.187] [bbotk]  2c6233cf-7664-4958-b07c-ec5cd481849d 
DEBUG [09:00:09.003] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.58782e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.366931e-06 0.000858782 
  - best initial criterion value(s) :  250.0928 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -250.09  |proj g|=       0.7961
At iterate     1  f =      -252.46  |proj g|=        1.3926
At iterate     2  f =      -253.89  |proj g|=        1.1893
At iterate     3  f =      -254.62  |proj g|=        1.0995
At iterate     4  f =      -254.67  |proj g|=        1.0516
At iterate     5  f =      -254.68  |proj g|=        1.0656
At iterate     6  f =      -254.68  |proj g|=        1.0694
At iterate     7  f =      -254.73  |proj g|=         1.104
At iterate     8  f =       -254.8  |proj g|=        1.1447
At iterate     9  f =      -254.87  |proj g|=        1.1806
At iterate    10  f =      -254.89  |proj g|=        1.1704
At iterate    11  f =       -254.9  |proj g|=        1.1624
At iterate    12  f =       -254.9  |proj g|=         1.162
At iterate    13  f =       -254.9  |proj g|=         1.162

iterations 13
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.16201
final function value -254.895

F = -254.895
final  value -254.895358 
converged
 
INFO  [09:00:09.007] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:00:09.093] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:00:09.100] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:00:11.872] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:00:14.648] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:00:17.459] [mlr3]  Finished benchmark 
INFO  [09:00:17.560] [bbotk] Result of batch 35: 
INFO  [09:00:17.562] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:00:17.562] [bbotk]              6.751362                 4.166252                      0.02621438 
INFO  [09:00:17.562] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:00:17.562] [bbotk]                     1784        0.596 -0.9635762         <NA>   0.9488574 
INFO  [09:00:17.562] [bbotk]                                 uhash 
INFO  [09:00:17.562] [bbotk]  ea24536e-3efa-4406-98e6-1202fc22a778 
DEBUG [09:00:18.306] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.873079e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.643896e-06 0.0008873079 
  - best initial criterion value(s) :  257.0439 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -257.04  |proj g|=      0.58644
At iterate     1  f =      -257.23  |proj g|=       0.84491
At iterate     2  f =      -257.23  |proj g|=       0.84481
At iterate     3  f =      -257.23  |proj g|=       0.84481
At iterate     4  f =      -257.23  |proj g|=       0.84484
At iterate     5  f =      -257.23  |proj g|=       0.84505
At iterate     6  f =      -257.23  |proj g|=       0.84557
At iterate     7  f =      -257.24  |proj g|=       0.84679
At iterate     8  f =      -257.24  |proj g|=       0.84841
At iterate     9  f =      -257.24  |proj g|=       0.84921
At iterate    10  f =      -257.24  |proj g|=       0.84925
At iterate    11  f =      -257.24  |proj g|=       0.84927

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.849265
final function value -257.239

F = -257.239
final  value -257.239389 
converged
 
INFO  [09:00:18.310] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:00:18.442] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:00:18.450] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:00:23.188] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:00:27.900] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:00:32.357] [mlr3]  Finished benchmark 
INFO  [09:00:32.456] [bbotk] Result of batch 36: 
INFO  [09:00:32.458] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:00:32.458] [bbotk]              9.481556                 5.675065                        0.375144 
INFO  [09:00:32.458] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:00:32.458] [bbotk]                     3097        0.547 -0.9664013         <NA>   0.9713556 
INFO  [09:00:32.458] [bbotk]                                 uhash 
INFO  [09:00:32.458] [bbotk]  342ef7aa-f77b-48bb-a098-b54dfdb8042b 
DEBUG [09:00:33.227] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.795133e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.568136e-06 0.0008795133 
  - best initial criterion value(s) :  245.3451 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -245.35  |proj g|=       2.5654
At iterate     1  f =      -263.46  |proj g|=         1.129
At iterate     2  f =      -264.22  |proj g|=        1.1159
At iterate     3  f =      -264.99  |proj g|=        1.0329
At iterate     4  f =      -265.12  |proj g|=        1.0704
At iterate     5  f =      -265.13  |proj g|=        1.0669
At iterate     6  f =      -265.14  |proj g|=         1.068
At iterate     7  f =      -265.16  |proj g|=          1.08
At iterate     8  f =      -265.18  |proj g|=        1.1159
At iterate     9  f =      -265.18  |proj g|=        1.1095
At iterate    10  f =      -265.18  |proj g|=        1.1087
At iterate    11  f =      -265.18  |proj g|=        1.1087

iterations 11
function evaluations 13
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.10873
final function value -265.184

F = -265.184
final  value -265.183871 
converged
 
INFO  [09:00:33.231] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:00:33.334] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:00:33.341] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:00:36.321] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:00:39.248] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:00:44.894] [mlr3]  Finished benchmark 
INFO  [09:00:45.034] [bbotk] Result of batch 37: 
INFO  [09:00:45.036] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:00:45.036] [bbotk]              8.437227                 4.543379                      0.06609324 
INFO  [09:00:45.036] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:00:45.036] [bbotk]                     1769        0.546 -0.9600165         <NA>   0.9618347 
INFO  [09:00:45.036] [bbotk]                                 uhash 
INFO  [09:00:45.036] [bbotk]  1a6ce3ee-c7ff-42a2-a426-b3d69705fd7d 
DEBUG [09:00:45.805] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.681472e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.467893e-06 0.0008681472 
  - best initial criterion value(s) :  253.2819 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -253.28  |proj g|=       0.2261
At iterate     1  f =       -254.5  |proj g|=       0.30748
At iterate     2  f =      -254.52  |proj g|=        0.3021
At iterate     3  f =      -254.66  |proj g|=       0.26999
At iterate     4  f =       -254.8  |proj g|=       0.25348
At iterate     5  f =      -255.28  |proj g|=       0.20658
At iterate     6  f =      -255.51  |proj g|=        0.2253
At iterate     7  f =      -255.53  |proj g|=       0.23871
At iterate     8  f =      -255.53  |proj g|=       0.31995
At iterate     9  f =      -255.53  |proj g|=       0.27018
At iterate    10  f =      -255.53  |proj g|=       0.27004

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.270043
final function value -255.534

F = -255.534
final  value -255.534220 
converged
 
INFO  [09:00:45.809] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:00:45.895] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:00:45.902] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:00:49.225] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:00:52.247] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:00:55.076] [mlr3]  Finished benchmark 
INFO  [09:00:55.200] [bbotk] Result of batch 38: 
INFO  [09:00:55.202] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:00:55.202] [bbotk]              8.006394                 4.213109                       0.4645745 
INFO  [09:00:55.202] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [09:00:55.202] [bbotk]                      948         0.56 -0.969161         <NA>   0.9712773 
INFO  [09:00:55.202] [bbotk]                                 uhash 
INFO  [09:00:55.202] [bbotk]  b908335f-909f-4a15-9c8f-7ba13f9ce711 
DEBUG [09:00:55.951] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.606554e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.324925e-06 0.0008606554 
  - best initial criterion value(s) :  267.346 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -267.35  |proj g|=       3.9578
At iterate     1  f =      -267.49  |proj g|=        3.6591
At iterate     2  f =      -267.68  |proj g|=        3.5823
At iterate     3  f =      -267.89  |proj g|=         3.342
At iterate     4  f =      -267.91  |proj g|=        3.3315
At iterate     5  f =      -267.91  |proj g|=         3.339
At iterate     6  f =      -267.91  |proj g|=         3.341
At iterate     7  f =      -267.91  |proj g|=        3.3413

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.34125
final function value -267.909

F = -267.909
final  value -267.909186 
converged
 
INFO  [09:00:55.956] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:00:56.052] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:00:56.059] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:01:01.826] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:01:08.348] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:01:14.153] [mlr3]  Finished benchmark 
INFO  [09:01:14.256] [bbotk] Result of batch 39: 
INFO  [09:01:14.258] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:01:14.258] [bbotk]              5.149098                 9.190973                       0.2490879 
INFO  [09:01:14.258] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:01:14.258] [bbotk]                     2755        0.557 -0.9660522         <NA>   0.9725064 
INFO  [09:01:14.258] [bbotk]                                 uhash 
INFO  [09:01:14.258] [bbotk]  e1c94abb-d7fc-4c33-9665-643f1c0a2a74 
DEBUG [09:01:15.039] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.555361e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.246357e-06 0.0008555361 
  - best initial criterion value(s) :  241.9336 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -241.93  |proj g|=      0.81855
At iterate     1  f =      -254.84  |proj g|=       0.68438
At iterate     2  f =      -255.55  |proj g|=       0.65598
At iterate     3  f =      -257.84  |proj g|=       0.50873
At iterate     4  f =      -258.74  |proj g|=       0.39172
At iterate     5  f =      -260.83  |proj g|=       0.38279
At iterate     6  f =      -262.15  |proj g|=       0.44408
At iterate     7  f =       -262.2  |proj g|=       0.78582
At iterate     8  f =      -262.22  |proj g|=       0.79118
At iterate     9  f =      -262.22  |proj g|=       0.37475
At iterate    10  f =      -262.22  |proj g|=       0.54579
At iterate    11  f =      -262.22  |proj g|=       0.54581

iterations 11
function evaluations 16
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.545812
final function value -262.218

F = -262.218
final  value -262.218095 
converged
 
INFO  [09:01:15.044] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:01:15.166] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:01:15.173] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:01:21.786] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:01:28.984] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:01:35.752] [mlr3]  Finished benchmark 
INFO  [09:01:35.856] [bbotk] Result of batch 40: 
INFO  [09:01:35.858] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:01:35.858] [bbotk]              8.039971                 5.876608                       0.1250327 
INFO  [09:01:35.858] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:01:35.858] [bbotk]                     2697        0.562 -0.9697296         <NA>   0.9701291 
INFO  [09:01:35.858] [bbotk]                                 uhash 
INFO  [09:01:35.858] [bbotk]  eb9d80cd-f14b-491c-ad86-485f09a28f4c 
DEBUG [09:01:36.699] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.464188e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.176241e-06 0.0008464188 
  - best initial criterion value(s) :  269.4641 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -269.46  |proj g|=       2.4337
At iterate     1  f =       -270.1  |proj g|=        2.4864
At iterate     2  f =      -273.05  |proj g|=        2.5557
At iterate     3  f =      -277.04  |proj g|=        2.4754
At iterate     4  f =      -277.43  |proj g|=        2.4049
At iterate     5  f =      -277.52  |proj g|=        2.3447
At iterate     6  f =      -277.71  |proj g|=        2.1532
At iterate     7  f =      -277.76  |proj g|=        2.0998
At iterate     8  f =      -277.76  |proj g|=        2.1049
At iterate     9  f =      -277.76  |proj g|=        2.1045
At iterate    10  f =      -277.78  |proj g|=         2.086
At iterate    11  f =       -278.1  |proj g|=        1.8986
At iterate    12  f =      -278.65  |proj g|=        1.6675
At iterate    13  f =      -280.44  |proj g|=        1.1606
At iterate    14  f =      -282.55  |proj g|=       0.85812
At iterate    15  f =      -282.96  |proj g|=        1.0369
At iterate    16  f =       -283.2  |proj g|=         1.177
At iterate    17  f =      -283.25  |proj g|=        1.2748
At iterate    18  f =      -283.36  |proj g|=        1.2369
At iterate    19  f =      -283.37  |proj g|=        1.1824
At iterate    20  f =      -283.37  |proj g|=        1.1943
At iterate    21  f =      -283.37  |proj g|=        1.2002
At iterate    22  f =      -283.37  |proj g|=        1.2003
At iterate    23  f =      -283.37  |proj g|=        1.2003

iterations 23
function evaluations 34
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.20031
final function value -283.368

F = -283.368
final  value -283.367732 
converged
 
INFO  [09:01:36.704] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:01:36.827] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:01:36.834] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:01:47.363] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:01:59.679] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:02:11.075] [mlr3]  Finished benchmark 
INFO  [09:02:11.178] [bbotk] Result of batch 41: 
INFO  [09:02:11.180] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:02:11.180] [bbotk]              8.582778                 6.016805                       0.2612926 
INFO  [09:02:11.180] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:02:11.180] [bbotk]                     4609        0.587 -0.9644142         <NA>   0.9723234 
INFO  [09:02:11.180] [bbotk]                                 uhash 
INFO  [09:02:11.180] [bbotk]  5365c732-42b6-4a21-a220-fda395dd0e30 
DEBUG [09:02:12.059] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.409635e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.14606e-06 0.0008409635 
  - best initial criterion value(s) :  287.9573 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -287.96  |proj g|=      0.43203
At iterate     1  f =      -290.94  |proj g|=       0.84698
At iterate     2  f =      -290.96  |proj g|=       0.84647
At iterate     3  f =      -291.04  |proj g|=       0.84349
At iterate     4  f =      -291.14  |proj g|=        0.8401
At iterate     5  f =      -291.47  |proj g|=       0.82737
At iterate     6  f =      -291.87  |proj g|=       0.73083
At iterate     7  f =      -292.21  |proj g|=        0.9873
At iterate     8  f =      -292.24  |proj g|=        1.0189
At iterate     9  f =      -292.24  |proj g|=        1.0463
At iterate    10  f =      -292.25  |proj g|=        1.0399
At iterate    11  f =      -292.25  |proj g|=        1.0396
At iterate    12  f =      -292.25  |proj g|=        1.0394
At iterate    13  f =      -292.25  |proj g|=        1.0389
At iterate    14  f =      -292.25  |proj g|=        1.0381
At iterate    15  f =      -292.25  |proj g|=        1.0368
At iterate    16  f =      -292.25  |proj g|=        1.0346
At iterate    17  f =      -292.25  |proj g|=        1.0316
At iterate    18  f =      -292.25  |proj g|=         1.028
At iterate    19  f =      -292.25  |proj g|=         1.027
At iterate    20  f =      -292.25  |proj g|=        1.0429
At iterate    21  f =      -292.25  |proj g|=        1.0353
At iterate    22  f =      -292.25  |proj g|=        1.0338
At iterate    23  f =      -292.25  |proj g|=        1.0319
At iterate    24  f =      -292.25  |proj g|=        1.0268
At iterate    25  f =      -292.25  |proj g|=        1.0216
At iterate    26  f =      -292.25  |proj g|=        1.0148
At iterate    27  f =      -292.26  |proj g|=       0.98537
At iterate    28  f =      -292.27  |proj g|=       0.98342
At iterate    29  f =      -292.34  |proj g|=       0.98072
At iterate    30  f =      -292.48  |proj g|=       0.98909
At iterate    31  f =      -292.92  |proj g|=         1.042
At iterate    32  f =      -293.16  |proj g|=        1.1139
At iterate    33  f =      -293.18  |proj g|=        1.0577
At iterate    34  f =       -293.4  |proj g|=        1.1626
At iterate    35  f =      -293.41  |proj g|=        1.1805
At iterate    36  f =      -293.41  |proj g|=         1.187
At iterate    37  f =      -293.41  |proj g|=         1.188
At iterate    38  f =      -293.41  |proj g|=        1.1882

iterations 38
function evaluations 49
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.18819
final function value -293.408

F = -293.408
final  value -293.407736 
converged
 
INFO  [09:02:12.064] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:02:12.185] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:02:12.196] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:02:19.425] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:02:25.973] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:02:32.166] [mlr3]  Finished benchmark 
INFO  [09:02:32.268] [bbotk] Result of batch 42: 
INFO  [09:02:32.270] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:02:32.270] [bbotk]              9.917549                 4.544062                        0.492369 
INFO  [09:02:32.270] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:02:32.270] [bbotk]                     2670        0.583 -0.9611734         <NA>   0.9701993 
INFO  [09:02:32.270] [bbotk]                                 uhash 
INFO  [09:02:32.270] [bbotk]  8f64da05-d86f-4711-b399-9b7d2fd52167 
DEBUG [09:02:33.054] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.321875e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.036498e-06 0.0008321875 
  - best initial criterion value(s) :  249.9506 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -249.95  |proj g|=       0.9584
At iterate     1  f =      -274.27  |proj g|=        3.6323
At iterate     2  f =      -296.64  |proj g|=        1.1052
At iterate     3  f =      -296.83  |proj g|=        1.1198
At iterate     4  f =         -297  |proj g|=        1.3302
At iterate     5  f =      -297.43  |proj g|=        1.2838
At iterate     6  f =       -297.5  |proj g|=         1.244
At iterate     7  f =      -297.51  |proj g|=        1.2561
At iterate     8  f =      -297.51  |proj g|=        1.2575
At iterate     9  f =      -297.51  |proj g|=        1.2574
At iterate    10  f =      -297.51  |proj g|=        1.2578
At iterate    11  f =      -297.51  |proj g|=        1.2578

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.25779
final function value -297.507

F = -297.507
final  value -297.506635 
converged
 
INFO  [09:02:33.059] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:02:33.187] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:02:33.198] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:02:36.579] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:02:39.621] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:02:43.105] [mlr3]  Finished benchmark 
INFO  [09:02:43.208] [bbotk] Result of batch 43: 
INFO  [09:02:43.210] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:02:43.210] [bbotk]                7.1692                 7.886977                       0.1785786 
INFO  [09:02:43.210] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:02:43.210] [bbotk]                     1438        0.572 -0.9563466         <NA>    0.968568 
INFO  [09:02:43.210] [bbotk]                                 uhash 
INFO  [09:02:43.210] [bbotk]  56f23fe7-29b7-4964-9d7e-8795eab4b57c 
DEBUG [09:02:44.007] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.21932e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  7.929509e-06 0.000821932 
  - best initial criterion value(s) :  290.5961 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -290.6  |proj g|=      0.89916
At iterate     1  f =      -295.72  |proj g|=       0.35456
At iterate     2  f =      -296.72  |proj g|=       0.81124
At iterate     3  f =      -296.82  |proj g|=       0.81075
At iterate     4  f =      -296.86  |proj g|=        0.5985
At iterate     5  f =      -296.86  |proj g|=       0.61989
At iterate     6  f =      -296.86  |proj g|=       0.62022
At iterate     7  f =      -296.86  |proj g|=       0.62088
At iterate     8  f =      -296.86  |proj g|=        0.6209

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.620898
final function value -296.859

F = -296.859
final  value -296.858668 
converged
 
INFO  [09:02:44.011] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:02:44.143] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:02:44.151] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:02:50.067] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:02:54.780] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:02:59.445] [mlr3]  Finished benchmark 
INFO  [09:02:59.549] [bbotk] Result of batch 44: 
INFO  [09:02:59.551] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:02:59.551] [bbotk]              4.914034                 5.683415                       0.4704302 
INFO  [09:02:59.551] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:02:59.551] [bbotk]                     2235        0.586 -0.9651575         <NA>   0.9737754 
INFO  [09:02:59.551] [bbotk]                                 uhash 
INFO  [09:02:59.551] [bbotk]  11525f0b-bf5f-40a0-acc4-05766bcb2a32 
DEBUG [09:03:00.629] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.195254e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  7.901703e-06 0.0008195254 
  - best initial criterion value(s) :  291.7247 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -291.72  |proj g|=       5.4043
At iterate     1  f =      -294.31  |proj g|=        4.4902
At iterate     2  f =      -294.95  |proj g|=         4.435
At iterate     3  f =      -295.84  |proj g|=        3.8372
At iterate     4  f =      -295.96  |proj g|=        3.6852
At iterate     5  f =         -296  |proj g|=        3.6671
At iterate     6  f =         -296  |proj g|=        3.6943
At iterate     7  f =         -296  |proj g|=        3.7128
At iterate     8  f =         -296  |proj g|=        3.7149
At iterate     9  f =         -296  |proj g|=        3.7149
At iterate    10  f =         -296  |proj g|=        3.7148
At iterate    11  f =         -296  |proj g|=        3.7144
At iterate    12  f =         -296  |proj g|=        3.7134
At iterate    13  f =         -296  |proj g|=        3.7124
At iterate    14  f =         -296  |proj g|=        3.7083
At iterate    15  f =      -296.01  |proj g|=        3.6991
At iterate    16  f =      -296.01  |proj g|=        3.7015
At iterate    17  f =      -296.01  |proj g|=        3.6858
At iterate    18  f =      -296.03  |proj g|=        3.6518
At iterate    19  f =      -296.05  |proj g|=          3.56
At iterate    20  f =      -296.07  |proj g|=        3.6331
At iterate    21  f =      -296.15  |proj g|=        3.4874
At iterate    22  f =      -298.61  |proj g|=        2.9723
At iterate    23  f =      -304.18  |proj g|=        1.2534
At iterate    24  f =      -306.79  |proj g|=        1.1561
At iterate    25  f =      -307.86  |proj g|=        1.1368
At iterate    26  f =      -307.91  |proj g|=        1.1768
At iterate    27  f =      -308.44  |proj g|=        1.1506
At iterate    28  f =      -308.51  |proj g|=        1.1512
At iterate    29  f =      -308.52  |proj g|=         1.153
At iterate    30  f =      -308.52  |proj g|=        1.1555
At iterate    31  f =      -308.52  |proj g|=        1.1566
At iterate    32  f =      -308.52  |proj g|=        1.1568
At iterate    33  f =      -308.52  |proj g|=        1.1568

iterations 33
function evaluations 42
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.15676
final function value -308.519

F = -308.519
final  value -308.519357 
converged
 
INFO  [09:03:00.631] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:03:00.712] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:03:00.719] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:03:08.619] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:03:16.931] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:03:25.179] [mlr3]  Finished benchmark 
INFO  [09:03:25.298] [bbotk] Result of batch 45: 
INFO  [09:03:25.300] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:03:25.300] [bbotk]              4.454856                 6.786498                       0.1172826 
INFO  [09:03:25.300] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:03:25.300] [bbotk]                     3536        0.613 -0.9585486         <NA>   0.9695751 
INFO  [09:03:25.300] [bbotk]                                 uhash 
INFO  [09:03:25.300] [bbotk]  abb62c9d-4516-4423-a8a2-2ac87c3ed1d6 
DEBUG [09:03:26.146] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.104685e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  7.85539e-06 0.0008104685 
  - best initial criterion value(s) :  291.1592 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -291.16  |proj g|=        1.154
At iterate     1  f =      -297.39  |proj g|=        1.9583
At iterate     2  f =      -297.59  |proj g|=        2.0875
At iterate     3  f =      -301.19  |proj g|=         1.874
At iterate     4  f =      -302.17  |proj g|=        1.6705
At iterate     5  f =      -302.88  |proj g|=        1.7172
At iterate     6  f =       -302.9  |proj g|=        1.7805
At iterate     7  f =      -302.92  |proj g|=        1.7601
At iterate     8  f =      -302.92  |proj g|=        1.7577
At iterate     9  f =      -305.19  |proj g|=        1.4806
At iterate    10  f =      -309.69  |proj g|=       0.78378
At iterate    11  f =      -310.15  |proj g|=        0.7103
At iterate    12  f =      -310.71  |proj g|=       0.34752
At iterate    13  f =      -310.78  |proj g|=       0.55448
At iterate    14  f =      -310.78  |proj g|=       0.34478
At iterate    15  f =      -310.78  |proj g|=       0.34866
At iterate    16  f =      -310.78  |proj g|=       0.34861

iterations 16
function evaluations 29
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.348613
final function value -310.776

F = -310.776
final  value -310.776141 
converged
 
INFO  [09:03:26.150] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:03:26.244] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:03:26.251] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:03:37.283] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:03:45.833] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:03:54.145] [mlr3]  Finished benchmark 
INFO  [09:03:54.314] [bbotk] Result of batch 46: 
INFO  [09:03:54.318] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:03:54.318] [bbotk]              6.154457                 4.024338                        0.376388 
INFO  [09:03:54.318] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:03:54.318] [bbotk]                     4999        0.599 -0.9635674         <NA>   0.9753932 
INFO  [09:03:54.318] [bbotk]                                 uhash 
INFO  [09:03:54.318] [bbotk]  ca41097e-da92-4c6d-805a-33c9a2b4e97b 
DEBUG [09:03:55.145] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.116203e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9526 
  - variance bounds :  7.910353e-06 0.0008116203 
  - best initial criterion value(s) :  294.9278 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -294.93  |proj g|=       2.8831
At iterate     1  f =      -296.99  |proj g|=        3.3656
At iterate     2  f =      -300.91  |proj g|=        3.9629
At iterate     3  f =      -301.06  |proj g|=        3.9535
At iterate     4  f =      -301.48  |proj g|=        3.8124
At iterate     5  f =      -301.48  |proj g|=        3.7847
At iterate     6  f =      -301.48  |proj g|=        3.7965
At iterate     7  f =      -301.48  |proj g|=        3.7956
At iterate     8  f =      -301.48  |proj g|=        3.7955

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.79551
final function value -301.484

F = -301.484
final  value -301.484275 
converged
 
INFO  [09:03:55.151] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:03:55.291] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:03:55.300] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:04:02.950] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:04:10.229] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:04:17.423] [mlr3]  Finished benchmark 
INFO  [09:04:18.056] [bbotk] Result of batch 47: 
INFO  [09:04:18.058] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:04:18.058] [bbotk]              5.401928                 5.238549                     0.003892507 
INFO  [09:04:18.058] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:04:18.058] [bbotk]                     4455        0.596 -0.9619104         <NA>   0.9254663 
INFO  [09:04:18.058] [bbotk]                                 uhash 
INFO  [09:04:18.058] [bbotk]  eca819fd-6dd3-422f-81ef-33afa3a3e15b 
DEBUG [09:04:18.997] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.011496e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.011496e-05 0.001021351 
  - best initial criterion value(s) :  291.1743 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -291.17  |proj g|=      0.14737
At iterate     1  f =       -295.5  |proj g|=        1.7045
At iterate     2  f =      -295.55  |proj g|=        1.6362
At iterate     3  f =      -295.58  |proj g|=        1.5279
At iterate     4  f =      -295.64  |proj g|=        1.4569
At iterate     5  f =      -295.89  |proj g|=        1.0988
At iterate     6  f =      -296.04  |proj g|=        1.0489
At iterate     7  f =      -296.07  |proj g|=        1.1482
At iterate     8  f =      -296.07  |proj g|=        1.1269
At iterate     9  f =      -296.07  |proj g|=        1.1273
At iterate    10  f =      -296.07  |proj g|=         1.127

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.12704
final function value -296.07

F = -296.07
final  value -296.069968 
converged
 
INFO  [09:04:19.002] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:04:19.088] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:04:19.094] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:04:23.173] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:04:27.250] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:04:31.372] [mlr3]  Finished benchmark 
INFO  [09:04:31.488] [bbotk] Result of batch 48: 
INFO  [09:04:31.490] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:04:31.490] [bbotk]              3.585351                 3.666285                       0.1914349 
INFO  [09:04:31.490] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:04:31.490] [bbotk]                     2546        0.701 -0.9679345         <NA>    0.967789 
INFO  [09:04:31.490] [bbotk]                                 uhash 
INFO  [09:04:31.490] [bbotk]  e397ca47-7214-4e84-bcb5-8bd98197b3b7 
DEBUG [09:04:32.472] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.992152e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.992151e-06 0.001010001 
  - best initial criterion value(s) :  272.2244 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -272.22  |proj g|=       2.8359
At iterate     1  f =      -286.51  |proj g|=         2.688
At iterate     2  f =      -288.36  |proj g|=        2.3923
At iterate     3  f =      -291.14  |proj g|=        1.5993
At iterate     4  f =      -291.46  |proj g|=        1.3432
At iterate     5  f =      -291.83  |proj g|=        1.2176
At iterate     6  f =      -292.37  |proj g|=        1.1683
At iterate     7  f =      -293.29  |proj g|=        1.1331
At iterate     8  f =       -294.1  |proj g|=        1.2189
At iterate     9  f =      -295.25  |proj g|=        1.5698
At iterate    10  f =      -295.28  |proj g|=        1.7338
At iterate    11  f =      -295.29  |proj g|=        1.6924
At iterate    12  f =      -295.29  |proj g|=        1.6826
At iterate    13  f =      -295.29  |proj g|=        1.6856
At iterate    14  f =      -295.29  |proj g|=        1.6854
At iterate    15  f =      -295.29  |proj g|=        1.6852
At iterate    16  f =      -295.29  |proj g|=        1.6844
At iterate    17  f =      -295.29  |proj g|=        1.6853
At iterate    18  f =      -295.29  |proj g|=        1.6841
At iterate    19  f =      -295.29  |proj g|=         1.687
At iterate    20  f =      -295.29  |proj g|=        1.6832
At iterate    21  f =      -295.29  |proj g|=        1.6763
At iterate    22  f =       -295.3  |proj g|=        1.6597
At iterate    23  f =      -295.32  |proj g|=        1.6216
At iterate    24  f =      -295.36  |proj g|=         1.546
At iterate    25  f =      -295.47  |proj g|=        1.2983
At iterate    26  f =      -295.72  |proj g|=        1.0529
At iterate    27  f =      -296.31  |proj g|=       0.25395
At iterate    28  f =       -297.2  |proj g|=       0.91328
At iterate    29  f =      -297.67  |proj g|=       0.25068
At iterate    30  f =      -297.89  |proj g|=       0.22734
At iterate    31  f =      -297.96  |proj g|=       0.22615
At iterate    32  f =      -297.98  |proj g|=       0.22499
At iterate    33  f =      -297.98  |proj g|=       0.22294
At iterate    34  f =      -297.98  |proj g|=       0.22151
At iterate    35  f =      -297.98  |proj g|=       0.22215
At iterate    36  f =      -297.98  |proj g|=       0.22239
At iterate    37  f =      -297.98  |proj g|=       0.22244
At iterate    38  f =      -297.98  |proj g|=       0.22278
At iterate    39  f =      -297.98  |proj g|=       0.22277
At iterate    40  f =      -297.98  |proj g|=       0.22673
At iterate    41  f =      -297.98  |proj g|=        0.2246
At iterate    42  f =      -297.98  |proj g|=       0.23041
At iterate    43  f =      -297.99  |proj g|=       0.24244
At iterate    44  f =         -298  |proj g|=       0.75882
At iterate    45  f =      -298.01  |proj g|=       0.89235
At iterate    46  f =      -298.15  |proj g|=       0.89494
At iterate    47  f =      -298.17  |proj g|=       0.89568
At iterate    48  f =      -298.36  |proj g|=       0.90193
At iterate    49  f =      -298.36  |proj g|=       0.25972
At iterate    50  f =      -298.36  |proj g|=       0.90229
At iterate    51  f =      -298.36  |proj g|=        0.9023
At iterate    52  f =      -298.36  |proj g|=       0.39881
At iterate    53  f =      -298.36  |proj g|=      0.011054
At iterate    54  f =      -298.36  |proj g|=     0.0054006
At iterate    55  f =      -298.36  |proj g|=     0.0054005

iterations 55
function evaluations 75
segments explored during Cauchy searches 57
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00540054
final function value -298.359

F = -298.359
final  value -298.359400 
converged
 
INFO  [09:04:32.476] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:04:32.561] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:04:32.568] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:04:35.990] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:04:39.513] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:04:43.098] [mlr3]  Finished benchmark 
INFO  [09:04:43.197] [bbotk] Result of batch 49: 
INFO  [09:04:43.199] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:04:43.199] [bbotk]              8.615666                 9.251496                        0.100415 
INFO  [09:04:43.199] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:04:43.199] [bbotk]                     2253        0.625 -0.9682064         <NA>   0.9678969 
INFO  [09:04:43.199] [bbotk]                                 uhash 
INFO  [09:04:43.199] [bbotk]  ccdb1298-0cf2-48ac-a9c8-5815724652b7 
DEBUG [09:04:44.330] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.872918e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.872918e-06 0.001004799 
  - best initial criterion value(s) :  290.8535 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -290.85  |proj g|=       1.1264
At iterate     1  f =      -299.33  |proj g|=        2.2738
At iterate     2  f =      -299.65  |proj g|=        2.2044
At iterate     3  f =      -299.92  |proj g|=        1.9393
At iterate     4  f =      -299.98  |proj g|=        2.0361
At iterate     5  f =      -299.99  |proj g|=        2.0281
At iterate     6  f =      -300.13  |proj g|=        1.9619
At iterate     7  f =      -300.32  |proj g|=        1.9179
At iterate     8  f =      -300.77  |proj g|=        1.9085
At iterate     9  f =      -301.14  |proj g|=        2.0507
At iterate    10  f =      -301.27  |proj g|=        2.1962
At iterate    11  f =      -301.29  |proj g|=        2.2762
At iterate    12  f =       -301.3  |proj g|=        2.2987
At iterate    13  f =       -301.3  |proj g|=        2.3013
At iterate    14  f =       -301.3  |proj g|=        2.3013

iterations 14
function evaluations 17
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.3013
final function value -301.295

F = -301.295
final  value -301.295285 
converged
 
INFO  [09:04:44.334] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:04:44.421] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:04:44.428] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:04:46.414] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:04:48.735] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:04:52.479] [mlr3]  Finished benchmark 
INFO  [09:04:52.595] [bbotk] Result of batch 50: 
INFO  [09:04:52.597] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:04:52.597] [bbotk]              8.911222                  2.37409                       0.4848802 
INFO  [09:04:52.597] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:04:52.597] [bbotk]                     1198        0.624 -0.9646571         <NA>   0.9704722 
INFO  [09:04:52.597] [bbotk]                                 uhash 
INFO  [09:04:52.597] [bbotk]  f7a934da-f7ad-452e-b2d7-eca03285abdb 
DEBUG [09:04:53.439] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.779798e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.779798e-06 0.0009932916 
  - best initial criterion value(s) :  297.9204 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -297.92  |proj g|=       2.5207
At iterate     1  f =      -304.46  |proj g|=       0.91744
At iterate     2  f =      -304.59  |proj g|=       0.93058
At iterate     3  f =      -304.72  |proj g|=        1.0874
At iterate     4  f =      -305.56  |proj g|=        1.1556
At iterate     5  f =      -307.57  |proj g|=       0.96403
At iterate     6  f =      -308.37  |proj g|=       0.85683
At iterate     7  f =      -308.62  |proj g|=       0.84381
At iterate     8  f =      -308.69  |proj g|=       0.83707
At iterate     9  f =      -308.72  |proj g|=       0.83731
At iterate    10  f =      -308.72  |proj g|=       0.83452
At iterate    11  f =      -308.72  |proj g|=       0.83471
At iterate    12  f =      -308.72  |proj g|=       0.83479
At iterate    13  f =      -308.72  |proj g|=        0.8349
At iterate    14  f =      -308.72  |proj g|=        0.8351
At iterate    15  f =      -308.72  |proj g|=       0.83545
At iterate    16  f =      -308.72  |proj g|=       0.83585
At iterate    17  f =      -308.72  |proj g|=       0.83652
At iterate    18  f =      -308.73  |proj g|=       0.83779
At iterate    19  f =      -308.73  |proj g|=       0.83945
At iterate    20  f =      -308.75  |proj g|=       0.84002
At iterate    21  f =      -308.83  |proj g|=       0.84649
At iterate    22  f =      -309.27  |proj g|=       0.86657
At iterate    23  f =      -309.82  |proj g|=       0.89255
At iterate    24  f =      -309.85  |proj g|=       0.88401
At iterate    25  f =      -310.38  |proj g|=       0.85839
At iterate    26  f =      -310.52  |proj g|=       0.86175
At iterate    27  f =      -310.53  |proj g|=       0.36097
At iterate    28  f =      -310.53  |proj g|=       0.36178
At iterate    29  f =      -310.53  |proj g|=       0.36083
At iterate    30  f =      -310.53  |proj g|=        0.3608
At iterate    31  f =      -310.53  |proj g|=       0.36051

iterations 31
function evaluations 37
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.360512
final function value -310.531

F = -310.531
final  value -310.530758 
converged
 
INFO  [09:04:53.443] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:04:53.530] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:04:53.537] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:05:04.044] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:05:16.305] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:05:27.185] [mlr3]  Finished benchmark 
INFO  [09:05:27.303] [bbotk] Result of batch 51: 
INFO  [09:05:27.305] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:05:27.305] [bbotk]              8.168047                 3.776342                       0.2924682 
INFO  [09:05:27.305] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:05:27.305] [bbotk]                     4935        0.574 -0.9655811         <NA>   0.9729957 
INFO  [09:05:27.305] [bbotk]                                 uhash 
INFO  [09:05:27.305] [bbotk]  dac68e5d-fa27-41bb-b651-06c730607df9 
DEBUG [09:05:28.093] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.726126e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.726125e-06 0.000984615 
  - best initial criterion value(s) :  311.9652 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -311.97  |proj g|=       1.2454
At iterate     1  f =      -314.46  |proj g|=        0.4877
At iterate     2  f =      -315.07  |proj g|=       0.87032
At iterate     3  f =      -315.77  |proj g|=       0.84188
At iterate     4  f =       -315.8  |proj g|=       0.47517
At iterate     5  f =       -315.8  |proj g|=       0.47287
At iterate     6  f =       -315.8  |proj g|=       0.47237
At iterate     7  f =       -315.8  |proj g|=        0.4729
At iterate     8  f =       -315.8  |proj g|=       0.47299

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.472993
final function value -315.797

F = -315.797
final  value -315.796680 
converged
 
INFO  [09:05:28.097] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:05:28.184] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:05:28.191] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:05:30.314] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:05:32.065] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:05:34.418] [mlr3]  Finished benchmark 
INFO  [09:05:34.535] [bbotk] Result of batch 52: 
INFO  [09:05:34.536] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:05:34.536] [bbotk]              5.445909                  6.98222                       0.2009769 
INFO  [09:05:34.536] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:05:34.536] [bbotk]                      810        0.578 -0.9640594         <NA>   0.9639881 
INFO  [09:05:34.536] [bbotk]                                 uhash 
INFO  [09:05:34.536] [bbotk]  acbac68b-116d-42d8-8b42-200442e00fea 
DEBUG [09:05:35.415] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.610924e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.610924e-06 0.000966483 
  - best initial criterion value(s) :  294.2485 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -294.25  |proj g|=       2.5008
At iterate     1  f =       -301.5  |proj g|=        4.6442
At iterate     2  f =      -301.59  |proj g|=        4.5234
At iterate     3  f =       -301.7  |proj g|=         4.204
At iterate     4  f =      -301.93  |proj g|=        4.0852
At iterate     5  f =       -303.2  |proj g|=        3.7901
At iterate     6  f =       -303.7  |proj g|=        3.8204
At iterate     7  f =      -303.97  |proj g|=        3.7755
At iterate     8  f =      -303.98  |proj g|=        3.7932
At iterate     9  f =      -303.98  |proj g|=         3.784
At iterate    10  f =      -303.98  |proj g|=        3.7863
At iterate    11  f =      -303.98  |proj g|=        3.7863
At iterate    12  f =      -303.98  |proj g|=        3.7857
At iterate    13  f =      -303.98  |proj g|=        3.7855
At iterate    14  f =      -303.98  |proj g|=        3.7848
At iterate    15  f =      -303.98  |proj g|=        3.7838
At iterate    16  f =      -303.98  |proj g|=         3.782
At iterate    17  f =      -303.98  |proj g|=        3.7792
At iterate    18  f =      -303.98  |proj g|=        3.7744
At iterate    19  f =      -303.98  |proj g|=        3.7664
At iterate    20  f =      -303.98  |proj g|=        3.7538
At iterate    21  f =      -303.98  |proj g|=        3.7408
At iterate    22  f =      -303.98  |proj g|=        3.7339
At iterate    23  f =      -303.98  |proj g|=        3.7224
At iterate    24  f =      -304.01  |proj g|=        3.7083
At iterate    25  f =      -304.13  |proj g|=        3.6405
At iterate    26  f =      -304.34  |proj g|=        3.7212
At iterate    27  f =      -305.07  |proj g|=        4.6271
At iterate    28  f =      -305.09  |proj g|=         4.582
At iterate    29  f =      -305.14  |proj g|=          4.95
At iterate    30  f =      -305.14  |proj g|=        4.9846
At iterate    31  f =      -305.14  |proj g|=        4.9723
At iterate    32  f =      -305.14  |proj g|=         4.972

iterations 32
function evaluations 43
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.97196
final function value -305.143

F = -305.143
final  value -305.143297 
converged
 
INFO  [09:05:35.419] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:05:35.506] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:05:35.513] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:05:47.346] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:05:59.251] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:06:10.830] [mlr3]  Finished benchmark 
INFO  [09:06:10.932] [bbotk] Result of batch 53: 
INFO  [09:06:10.933] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:06:10.933] [bbotk]              4.686224                 2.888134                       0.4497752 
INFO  [09:06:10.933] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [09:06:10.933] [bbotk]                     4557        0.598 -0.970225         <NA>   0.9749428 
INFO  [09:06:10.933] [bbotk]                                 uhash 
INFO  [09:06:10.933] [bbotk]  37846927-409e-4ed0-a313-764c03a69c0b 
DEBUG [09:06:11.741] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.597932e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.597932e-06 0.0009716523 
  - best initial criterion value(s) :  302.534 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -302.53  |proj g|=       7.0236
At iterate     1  f =      -302.73  |proj g|=        5.6296
At iterate     2  f =      -306.89  |proj g|=        4.9163
At iterate     3  f =      -311.63  |proj g|=        3.0672
At iterate     4  f =      -315.38  |proj g|=       0.57092
At iterate     5  f =      -316.61  |proj g|=       0.90548
At iterate     6  f =      -316.63  |proj g|=       0.90766
At iterate     7  f =      -316.63  |proj g|=       0.90735
At iterate     8  f =      -316.63  |proj g|=       0.90732
At iterate     9  f =      -316.63  |proj g|=       0.90732

iterations 9
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.90732
final function value -316.634

F = -316.634
final  value -316.633592 
converged
 
INFO  [09:06:11.746] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:06:11.869] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:06:11.877] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:06:22.703] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:06:32.140] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:06:41.213] [mlr3]  Finished benchmark 
INFO  [09:06:41.315] [bbotk] Result of batch 54: 
INFO  [09:06:41.317] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:06:41.317] [bbotk]              2.286899                 3.829066                       0.1951304 
INFO  [09:06:41.317] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:06:41.317] [bbotk]                     4198        0.601 -0.9688354         <NA>   0.9593282 
INFO  [09:06:41.317] [bbotk]                                 uhash 
INFO  [09:06:41.317] [bbotk]  6ad1db7c-c8cf-47ac-977c-52a978d40177 
DEBUG [09:06:42.141] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.53235e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.53235e-06 0.000957064 
  - best initial criterion value(s) :  307.2672 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -307.27  |proj g|=       1.8238
At iterate     1  f =      -312.69  |proj g|=        1.2022
At iterate     2  f =      -314.64  |proj g|=       0.97632
At iterate     3  f =      -315.88  |proj g|=       0.85356
At iterate     4  f =      -315.99  |proj g|=       0.84985
At iterate     5  f =      -316.01  |proj g|=       0.85045
At iterate     6  f =      -316.05  |proj g|=       0.84845
At iterate     7  f =      -316.11  |proj g|=       0.84271
At iterate     8  f =      -316.16  |proj g|=       0.83523
At iterate     9  f =      -316.16  |proj g|=       0.83361
At iterate    10  f =      -316.16  |proj g|=       0.83353
At iterate    11  f =      -316.16  |proj g|=       0.83356
At iterate    12  f =      -316.16  |proj g|=       0.83357

iterations 12
function evaluations 16
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.833572
final function value -316.163

F = -316.163
final  value -316.162870 
converged
 
INFO  [09:06:42.145] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:06:42.237] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:06:42.244] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:06:46.720] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:06:55.541] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:07:02.879] [mlr3]  Finished benchmark 
INFO  [09:07:02.985] [bbotk] Result of batch 55: 
INFO  [09:07:02.987] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:07:02.987] [bbotk]              3.904158                 9.552648                       0.3527277 
INFO  [09:07:02.987] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:07:02.987] [bbotk]                     1781        0.599 -0.9676642         <NA>   0.9703753 
INFO  [09:07:02.987] [bbotk]                                 uhash 
INFO  [09:07:02.987] [bbotk]  9033f003-a6ea-46b6-9dc6-ea13f06f1467 
DEBUG [09:07:03.812] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.445784e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.445784e-06 0.0009530378 
  - best initial criterion value(s) :  303.9732 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -303.97  |proj g|=       4.0231
At iterate     1  f =      -306.41  |proj g|=        3.0328
At iterate     2  f =      -310.29  |proj g|=        4.1437
At iterate     3  f =      -313.23  |proj g|=         3.126
At iterate     4  f =      -313.38  |proj g|=        2.5265
At iterate     5  f =       -313.8  |proj g|=        2.2535
At iterate     6  f =      -313.84  |proj g|=        2.2299
At iterate     7  f =      -313.84  |proj g|=        2.2504
At iterate     8  f =      -313.84  |proj g|=        2.2601
At iterate     9  f =      -313.84  |proj g|=        2.2615
At iterate    10  f =      -313.84  |proj g|=        2.2622

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.26223
final function value -313.844

F = -313.844
final  value -313.844444 
converged
 
INFO  [09:07:03.817] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:07:03.906] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:07:03.913] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:07:08.490] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:07:12.926] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:07:18.067] [mlr3]  Finished benchmark 
INFO  [09:07:18.173] [bbotk] Result of batch 56: 
INFO  [09:07:18.175] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:07:18.175] [bbotk]              2.623916                  7.87812                      0.09643512 
INFO  [09:07:18.175] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [09:07:18.175] [bbotk]                     2282        0.604 -0.966782         <NA>   0.9495015 
INFO  [09:07:18.175] [bbotk]                                 uhash 
INFO  [09:07:18.175] [bbotk]  f45f5292-7c5f-44df-a86c-cb04467c602b 
DEBUG [09:07:19.049] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.639024e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.624704e-06 0.0009639024 
  - best initial criterion value(s) :  323.4794 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -323.48  |proj g|=       1.2406
At iterate     1  f =      -327.65  |proj g|=       0.41019
At iterate     2  f =      -328.44  |proj g|=       0.86237
At iterate     3  f =      -328.48  |proj g|=       0.86293
At iterate     4  f =      -328.49  |proj g|=       0.57897
At iterate     5  f =      -328.49  |proj g|=       0.58342
At iterate     6  f =      -328.49  |proj g|=       0.58399
At iterate     7  f =      -328.49  |proj g|=       0.58467
At iterate     8  f =      -328.49  |proj g|=        0.5855
At iterate     9  f =      -328.49  |proj g|=       0.58898
At iterate    10  f =      -328.49  |proj g|=       0.59415
At iterate    11  f =      -328.49  |proj g|=       0.86439
At iterate    12  f =      -328.49  |proj g|=       0.86499
At iterate    13  f =       -328.5  |proj g|=       0.86619
At iterate    14  f =      -328.51  |proj g|=        0.8686
At iterate    15  f =      -328.55  |proj g|=       0.87297
At iterate    16  f =      -328.62  |proj g|=       0.87817
At iterate    17  f =      -328.77  |proj g|=       0.88775
At iterate    18  f =      -328.85  |proj g|=       0.89725
At iterate    19  f =      -329.39  |proj g|=       0.89367
At iterate    20  f =      -330.84  |proj g|=       0.36812
At iterate    21  f =      -331.75  |proj g|=       0.25461
At iterate    22  f =      -331.77  |proj g|=       0.15948
At iterate    23  f =      -331.77  |proj g|=       0.14377
At iterate    24  f =      -331.77  |proj g|=       0.14292
At iterate    25  f =      -331.77  |proj g|=       0.14285

iterations 25
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.142855
final function value -331.774

F = -331.774
final  value -331.774334 
converged
 
INFO  [09:07:19.053] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:07:19.141] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:07:19.148] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:07:22.920] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:07:27.570] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:07:33.485] [mlr3]  Finished benchmark 
INFO  [09:07:33.632] [bbotk] Result of batch 57: 
INFO  [09:07:33.635] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:07:33.635] [bbotk]              7.409657                 7.769982                       0.1744317 
INFO  [09:07:33.635] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:07:33.635] [bbotk]                     1690         0.61 -0.9678778         <NA>   0.9694902 
INFO  [09:07:33.635] [bbotk]                                 uhash 
INFO  [09:07:33.635] [bbotk]  56c02a2e-a36a-4474-85cf-c9863615d70d 
DEBUG [09:07:34.509] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.545846e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.545846e-06 0.0009584654 
  - best initial criterion value(s) :  283.9914 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -283.99  |proj g|=       2.0548
At iterate     1  f =      -287.58  |proj g|=        12.115
At iterate     2  f =      -287.64  |proj g|=        11.402
At iterate     3  f =      -287.72  |proj g|=         10.26
At iterate     4  f =       -287.8  |proj g|=        9.6954
At iterate     5  f =      -288.14  |proj g|=        7.4403
At iterate     6  f =      -288.58  |proj g|=        7.0723
At iterate     7  f =       -289.7  |proj g|=        9.1432
At iterate     8  f =      -290.01  |proj g|=        13.902
At iterate     9  f =      -290.07  |proj g|=        12.806
At iterate    10  f =      -290.07  |proj g|=        12.784
At iterate    11  f =      -290.07  |proj g|=        12.691
At iterate    12  f =      -290.07  |proj g|=        12.733
At iterate    13  f =      -290.07  |proj g|=        12.727
At iterate    14  f =      -290.07  |proj g|=        12.726

iterations 14
function evaluations 18
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 12.7262
final function value -290.068

F = -290.068
final  value -290.067870 
converged
 
INFO  [09:07:34.513] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:07:34.606] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:07:34.613] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:07:41.040] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:07:45.788] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:07:50.682] [mlr3]  Finished benchmark 
INFO  [09:07:50.974] [bbotk] Result of batch 58: 
INFO  [09:07:50.977] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:07:50.977] [bbotk]              3.405472                 8.745993                       0.4858849 
INFO  [09:07:50.977] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:07:50.977] [bbotk]                     3059        0.635 -0.9744338         <NA>   0.9719359 
INFO  [09:07:50.977] [bbotk]                                 uhash 
INFO  [09:07:50.977] [bbotk]  615b4466-c70d-402a-80d1-b60f155551d3 
DEBUG [09:07:52.103] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.482509e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.482509e-06 0.0009501934 
  - best initial criterion value(s) :  320.3651 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -320.37  |proj g|=       4.0474
At iterate     1  f =      -325.87  |proj g|=         5.716
At iterate     2  f =       -327.7  |proj g|=        5.7664
At iterate     3  f =      -331.01  |proj g|=        4.7528
At iterate     4  f =      -331.22  |proj g|=        4.1459
At iterate     5  f =      -331.52  |proj g|=        3.8996
At iterate     6  f =      -331.57  |proj g|=        3.6933
At iterate     7  f =      -331.57  |proj g|=        3.6967
At iterate     8  f =      -331.57  |proj g|=        3.7126
At iterate     9  f =      -331.57  |proj g|=        3.7424
At iterate    10  f =      -331.58  |proj g|=        3.7468
At iterate    11  f =       -331.6  |proj g|=        3.8143
At iterate    12  f =      -331.69  |proj g|=        3.9384
At iterate    13  f =      -331.88  |proj g|=        3.7451
At iterate    14  f =      -332.44  |proj g|=        4.0849
At iterate    15  f =      -334.09  |proj g|=        4.2969
At iterate    16  f =      -338.27  |proj g|=        3.7387
At iterate    17  f =      -342.29  |proj g|=        2.3324
At iterate    18  f =      -342.31  |proj g|=        2.3399
At iterate    19  f =      -343.43  |proj g|=        2.4021
At iterate    20  f =      -344.74  |proj g|=         1.763
At iterate    21  f =      -346.05  |proj g|=        1.9486
At iterate    22  f =      -347.33  |proj g|=        1.9376
At iterate    23  f =      -348.27  |proj g|=        2.1444
At iterate    24  f =      -348.28  |proj g|=        2.0485
At iterate    25  f =      -348.28  |proj g|=        2.0836
At iterate    26  f =      -348.29  |proj g|=         2.069
At iterate    27  f =      -348.29  |proj g|=        2.0686

iterations 27
function evaluations 33
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.06862
final function value -348.286

F = -348.286
final  value -348.285582 
converged
 
INFO  [09:07:52.108] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:07:52.211] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:07:52.221] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:07:58.044] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:08:03.876] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:08:09.764] [mlr3]  Finished benchmark 
INFO  [09:08:09.909] [bbotk] Result of batch 59: 
INFO  [09:08:09.912] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:08:09.912] [bbotk]              8.151778                 5.537242                      0.04966219 
INFO  [09:08:09.912] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:08:09.912] [bbotk]                     3616        0.809 -0.9673754         <NA>   0.9661074 
INFO  [09:08:09.912] [bbotk]                                 uhash 
INFO  [09:08:09.912] [bbotk]  84014ac7-616d-4893-a704-bc405d6c4e21 
DEBUG [09:08:10.914] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.376178e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.376178e-06 0.0009412892 
  - best initial criterion value(s) :  322.2696 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -322.27  |proj g|=       3.0653
At iterate     1  f =      -329.23  |proj g|=        2.3619
At iterate     2  f =      -345.17  |proj g|=        1.4112
At iterate     3  f =      -354.77  |proj g|=        1.3792
At iterate     4  f =      -357.58  |proj g|=        1.1295
At iterate     5  f =      -357.77  |proj g|=       0.96046
At iterate     6  f =      -357.83  |proj g|=       0.94648
At iterate     7  f =      -357.96  |proj g|=         0.774
At iterate     8  f =      -357.96  |proj g|=       0.77353
At iterate     9  f =      -357.96  |proj g|=       0.77209
At iterate    10  f =      -357.96  |proj g|=       0.77229
At iterate    11  f =      -357.96  |proj g|=       0.77231
At iterate    12  f =      -357.96  |proj g|=       0.77238
At iterate    13  f =      -357.96  |proj g|=       0.77249
At iterate    14  f =      -357.96  |proj g|=        0.7727
At iterate    15  f =      -357.96  |proj g|=       0.77287
At iterate    16  f =      -357.96  |proj g|=       0.77315
At iterate    17  f =      -357.96  |proj g|=       0.77418
At iterate    18  f =      -357.97  |proj g|=       0.77545
At iterate    19  f =      -357.98  |proj g|=       0.77741
At iterate    20  f =      -358.01  |proj g|=       0.78064
At iterate    21  f =      -358.02  |proj g|=       0.55893
At iterate    22  f =      -358.11  |proj g|=       0.78333
At iterate    23  f =      -358.53  |proj g|=       0.78391
At iterate    24  f =       -359.5  |proj g|=       0.76683
At iterate    25  f =      -359.94  |proj g|=       0.75012
At iterate    26  f =      -360.14  |proj g|=       0.73491
At iterate    27  f =      -360.14  |proj g|=        0.3589
At iterate    28  f =      -360.14  |proj g|=       0.35893

iterations 28
function evaluations 36
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.358934
final function value -360.143

F = -360.143
final  value -360.142944 
converged
 
INFO  [09:08:10.919] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:08:11.023] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:08:11.031] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:08:16.348] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:08:21.567] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:08:26.855] [mlr3]  Finished benchmark 
INFO  [09:08:26.977] [bbotk] Result of batch 60: 
INFO  [09:08:26.979] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:08:26.979] [bbotk]               9.33094                 5.501091                        0.139392 
INFO  [09:08:26.979] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:08:26.979] [bbotk]                     3258        0.679 -0.9547195         <NA>   0.9703802 
INFO  [09:08:26.979] [bbotk]                                 uhash 
INFO  [09:08:26.979] [bbotk]  bcee97d2-475d-4731-adcf-c012a483ec0a 
DEBUG [09:08:27.871] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.29634e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.29634e-06 0.0009334522 
  - best initial criterion value(s) :  327.815 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -327.82  |proj g|=       2.5566
At iterate     1  f =      -344.72  |proj g|=       0.82975
At iterate     2  f =         -346  |proj g|=       0.82409
At iterate     3  f =      -347.45  |proj g|=       0.17546
At iterate     4  f =       -347.7  |proj g|=       0.18114
At iterate     5  f =      -347.88  |proj g|=       0.15452
At iterate     6  f =      -348.41  |proj g|=       0.19895
At iterate     7  f =      -348.84  |proj g|=       0.86595
At iterate     8  f =      -348.88  |proj g|=       0.86566
At iterate     9  f =      -348.88  |proj g|=       0.86453
At iterate    10  f =      -348.88  |proj g|=       0.86483
At iterate    11  f =      -348.88  |proj g|=       0.86482

iterations 11
function evaluations 16
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.864825
final function value -348.881

F = -348.881
final  value -348.880645 
converged
 
INFO  [09:08:27.875] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:08:28.022] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:08:28.030] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:08:35.951] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:08:44.005] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:08:52.145] [mlr3]  Finished benchmark 
INFO  [09:08:52.307] [bbotk] Result of batch 61: 
INFO  [09:08:52.309] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:08:52.309] [bbotk]               7.61897                 3.881913                       0.1242131 
INFO  [09:08:52.309] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:08:52.309] [bbotk]                     4933        0.656 -0.9673092         <NA>   0.9724693 
INFO  [09:08:52.309] [bbotk]                                 uhash 
INFO  [09:08:52.309] [bbotk]  aed6b598-a691-4334-b700-62c7a52bf0ab 
DEBUG [09:08:53.520] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.243616e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.243616e-06 0.0009250892 
  - best initial criterion value(s) :  350.2866 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -350.29  |proj g|=       1.4578
At iterate     1  f =      -351.17  |proj g|=        2.6805
At iterate     2  f =      -352.07  |proj g|=        3.4839
At iterate     3  f =      -352.12  |proj g|=        3.3421
At iterate     4  f =      -352.15  |proj g|=         2.951
At iterate     5  f =      -352.16  |proj g|=        3.0717
At iterate     6  f =      -352.16  |proj g|=        3.0546
At iterate     7  f =      -352.16  |proj g|=        3.0534
At iterate     8  f =      -352.16  |proj g|=         3.054
At iterate     9  f =      -352.16  |proj g|=        3.0528
At iterate    10  f =      -352.16  |proj g|=        3.0479
At iterate    11  f =      -352.16  |proj g|=        3.0377
At iterate    12  f =      -352.16  |proj g|=        3.0219
At iterate    13  f =      -352.16  |proj g|=        2.9959
At iterate    14  f =      -352.16  |proj g|=        2.9522
At iterate    15  f =      -352.17  |proj g|=        2.9328
At iterate    16  f =      -352.18  |proj g|=        2.8549
At iterate    17  f =      -352.22  |proj g|=        2.6983
At iterate    18  f =      -352.36  |proj g|=         2.401
At iterate    19  f =      -352.74  |proj g|=        1.9183
At iterate    20  f =      -353.96  |proj g|=        1.3716
At iterate    21  f =      -357.31  |proj g|=       0.99266
At iterate    22  f =      -362.05  |proj g|=       0.88017
At iterate    23  f =      -363.47  |proj g|=        1.3087
At iterate    24  f =         -366  |proj g|=       0.71177
At iterate    25  f =      -367.09  |proj g|=       0.84551
At iterate    26  f =      -368.23  |proj g|=       0.15617
At iterate    27  f =      -368.56  |proj g|=        0.8127
At iterate    28  f =      -368.63  |proj g|=       0.80521
At iterate    29  f =      -368.64  |proj g|=       0.62738
At iterate    30  f =      -368.64  |proj g|=       0.65786
At iterate    31  f =      -368.64  |proj g|=       0.63418
At iterate    32  f =      -368.64  |proj g|=       0.63842
At iterate    33  f =      -368.65  |proj g|=       0.66596
At iterate    34  f =      -368.68  |proj g|=       0.69434
At iterate    35  f =      -368.76  |proj g|=       0.72238
At iterate    36  f =      -368.76  |proj g|=        0.7336
At iterate    37  f =      -368.92  |proj g|=       0.72186
At iterate    38  f =      -369.21  |proj g|=       0.62654
At iterate    39  f =      -369.61  |proj g|=       0.45452
At iterate    40  f =      -369.92  |proj g|=       0.34482
At iterate    41  f =      -370.33  |proj g|=       0.24314
At iterate    42  f =      -370.35  |proj g|=       0.24287
At iterate    43  f =      -370.36  |proj g|=       0.24255
At iterate    44  f =      -370.38  |proj g|=       0.23647
At iterate    45  f =      -370.38  |proj g|=       0.26356
At iterate    46  f =      -370.38  |proj g|=     0.0035082
At iterate    47  f =      -370.38  |proj g|=    0.00086682

iterations 47
function evaluations 60
segments explored during Cauchy searches 50
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000866819
final function value -370.38

F = -370.38
final  value -370.380164 
converged
 
INFO  [09:08:53.524] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:08:53.620] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:08:53.628] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:09:04.449] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:09:12.642] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:09:22.351] [mlr3]  Finished benchmark 
INFO  [09:09:22.450] [bbotk] Result of batch 62: 
INFO  [09:09:22.452] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:09:22.452] [bbotk]              6.509348                 7.895184                      0.09736864 
INFO  [09:09:22.452] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:09:22.452] [bbotk]                     3964        0.633 -0.9564538         <NA>   0.9706459 
INFO  [09:09:22.452] [bbotk]                                 uhash 
INFO  [09:09:22.452] [bbotk]  9d30b8e4-3424-4cde-97f1-910f74a28ce9 
DEBUG [09:09:23.297] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.168405e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.168405e-06 0.0009199357 
  - best initial criterion value(s) :  346.719 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -346.72  |proj g|=       1.0642
At iterate     1  f =      -350.81  |proj g|=        3.8193
At iterate     2  f =      -353.78  |proj g|=        3.6513
At iterate     3  f =      -356.61  |proj g|=        3.1253
At iterate     4  f =      -356.71  |proj g|=        2.8889
At iterate     5  f =      -356.78  |proj g|=          2.98
At iterate     6  f =      -356.87  |proj g|=        3.0508
At iterate     7  f =      -357.19  |proj g|=         3.255
At iterate     8  f =      -357.53  |proj g|=        3.4654
At iterate     9  f =      -357.75  |proj g|=        3.5077
At iterate    10  f =      -357.76  |proj g|=        3.5061
At iterate    11  f =      -357.76  |proj g|=        3.5025
At iterate    12  f =      -357.76  |proj g|=        3.5012
At iterate    13  f =      -357.76  |proj g|=        3.5009

iterations 13
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.50091
final function value -357.76

F = -357.76
final  value -357.760454 
converged
 
INFO  [09:09:23.301] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:09:23.387] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:09:23.394] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:09:31.156] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:09:37.855] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:09:44.797] [mlr3]  Finished benchmark 
INFO  [09:09:44.913] [bbotk] Result of batch 63: 
INFO  [09:09:44.915] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:09:44.915] [bbotk]              5.298439                 9.687109                       0.1452407 
INFO  [09:09:44.915] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:09:44.915] [bbotk]                     3282        0.616 -0.9631587         <NA>   0.9712135 
INFO  [09:09:44.915] [bbotk]                                 uhash 
INFO  [09:09:44.915] [bbotk]  9431cdf2-9e12-4c45-93f4-05de8e194ade 
DEBUG [09:09:45.844] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.100413e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.100413e-06 0.0009162215 
  - best initial criterion value(s) :  322.2295 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -322.23  |proj g|=       7.1201
At iterate     1  f =      -345.51  |proj g|=        7.3089
At iterate     2  f =      -345.77  |proj g|=        7.3994
At iterate     3  f =      -345.88  |proj g|=        7.2043
At iterate     4  f =      -346.05  |proj g|=        6.5955
At iterate     5  f =      -346.09  |proj g|=        6.3426
At iterate     6  f =       -346.1  |proj g|=        6.2051
At iterate     7  f =       -346.1  |proj g|=         6.188
At iterate     8  f =       -346.1  |proj g|=        6.1925
At iterate     9  f =       -346.1  |proj g|=        6.1942
At iterate    10  f =       -346.1  |proj g|=        6.1951
At iterate    11  f =       -346.1  |proj g|=        6.1983
At iterate    12  f =       -346.1  |proj g|=        6.2023
At iterate    13  f =       -346.1  |proj g|=        6.2096
At iterate    14  f =       -346.1  |proj g|=        6.2216
At iterate    15  f =       -346.1  |proj g|=        6.2443
At iterate    16  f =      -346.11  |proj g|=        6.2844
At iterate    17  f =      -346.11  |proj g|=        6.3438
At iterate    18  f =      -346.11  |proj g|=        6.4245
At iterate    19  f =      -346.12  |proj g|=        6.4696
At iterate    20  f =      -346.23  |proj g|=        6.8023
At iterate    21  f =      -346.25  |proj g|=         6.868
At iterate    22  f =      -346.49  |proj g|=        7.1068
At iterate    23  f =      -347.91  |proj g|=        6.8846
At iterate    24  f =      -352.36  |proj g|=        4.8917
At iterate    25  f =      -359.31  |proj g|=        2.6218
At iterate    26  f =      -363.32  |proj g|=         2.283
At iterate    27  f =      -365.15  |proj g|=       0.91947
At iterate    28  f =      -367.42  |proj g|=        2.2485
At iterate    29  f =      -369.34  |proj g|=        1.8009
At iterate    30  f =      -369.89  |proj g|=        1.3061
At iterate    31  f =      -369.97  |proj g|=       0.85241
At iterate    32  f =         -370  |proj g|=       0.98618
At iterate    33  f =      -370.01  |proj g|=       0.96851
At iterate    34  f =      -370.01  |proj g|=       0.95907
At iterate    35  f =      -370.01  |proj g|=       0.95902

iterations 35
function evaluations 42
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.959018
final function value -370.007

F = -370.007
final  value -370.006954 
converged
 
INFO  [09:09:45.848] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:09:45.935] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:09:45.942] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:09:58.856] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:10:08.374] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:10:18.338] [mlr3]  Finished benchmark 
INFO  [09:10:18.438] [bbotk] Result of batch 64: 
INFO  [09:10:18.440] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:10:18.440] [bbotk]              3.320778                 9.426714                       0.1260427 
INFO  [09:10:18.440] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:10:18.440] [bbotk]                     4176        0.623 -0.9674452         <NA>   0.9665573 
INFO  [09:10:18.440] [bbotk]                                 uhash 
INFO  [09:10:18.440] [bbotk]  193c6c2b-24df-4a5a-9d3b-65a1a1c1a8e3 
DEBUG [09:10:19.407] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.004044e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.004044e-06 0.0009050995 
  - best initial criterion value(s) :  354.1594 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -354.16  |proj g|=        5.262
At iterate     1  f =      -355.74  |proj g|=        6.0389
At iterate     2  f =      -359.76  |proj g|=        3.9933
At iterate     3  f =      -363.31  |proj g|=        3.8583
At iterate     4  f =      -366.17  |proj g|=        2.7849
At iterate     5  f =      -366.42  |proj g|=        2.6127
At iterate     6  f =      -366.43  |proj g|=        2.6556
At iterate     7  f =      -366.43  |proj g|=        2.6466
At iterate     8  f =      -366.43  |proj g|=        2.6464
At iterate     9  f =      -366.43  |proj g|=        2.6467
At iterate    10  f =      -366.43  |proj g|=        2.6472
At iterate    11  f =      -366.43  |proj g|=        2.6484
At iterate    12  f =      -366.43  |proj g|=        2.6499
At iterate    13  f =      -366.44  |proj g|=        2.6523
At iterate    14  f =      -366.47  |proj g|=        2.6479
At iterate    15  f =      -366.51  |proj g|=        2.6933
At iterate    16  f =      -366.59  |proj g|=         2.669
At iterate    17  f =      -367.72  |proj g|=        2.5046
At iterate    18  f =      -371.31  |proj g|=         2.037
At iterate    19  f =      -375.51  |proj g|=         1.177
At iterate    20  f =      -376.59  |proj g|=        1.0094
At iterate    21  f =      -376.82  |proj g|=        1.3444
At iterate    22  f =      -376.98  |proj g|=        1.2042
At iterate    23  f =      -377.01  |proj g|=         1.086
At iterate    24  f =      -377.01  |proj g|=        1.1086
At iterate    25  f =      -377.01  |proj g|=        1.1059
At iterate    26  f =      -377.05  |proj g|=        1.1409
At iterate    27  f =      -377.08  |proj g|=        1.2093
At iterate    28  f =      -377.08  |proj g|=        1.2212
At iterate    29  f =      -377.14  |proj g|=        1.3086
At iterate    30  f =      -377.26  |proj g|=        1.4025
At iterate    31  f =      -377.55  |proj g|=        1.5165
At iterate    32  f =      -378.11  |proj g|=        1.5369
At iterate    33  f =      -378.56  |proj g|=        1.4713
At iterate    34  f =      -378.75  |proj g|=        1.2304
At iterate    35  f =      -378.78  |proj g|=        1.0462
At iterate    36  f =       -378.8  |proj g|=        1.1379
At iterate    37  f =       -378.8  |proj g|=        1.1305
At iterate    38  f =       -378.8  |proj g|=        1.1289
At iterate    39  f =       -378.8  |proj g|=         1.129

iterations 39
function evaluations 45
segments explored during Cauchy searches 41
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.129
final function value -378.804

F = -378.804
final  value -378.804064 
converged
 
INFO  [09:10:19.412] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:10:19.496] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:10:19.503] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:10:24.112] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:10:28.049] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:10:31.716] [mlr3]  Finished benchmark 
INFO  [09:10:31.816] [bbotk] Result of batch 65: 
INFO  [09:10:31.818] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:10:31.818] [bbotk]              9.134569                 9.154869                       0.4816643 
INFO  [09:10:31.818] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:10:31.818] [bbotk]                     1718        0.642 -0.9573342         <NA>   0.9709593 
INFO  [09:10:31.818] [bbotk]                                 uhash 
INFO  [09:10:31.818] [bbotk]  93930f45-56f3-4b15-8ee6-7e5583f6ca0d 
DEBUG [09:10:32.801] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.935772e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  8.935772e-06 0.000899181 
  - best initial criterion value(s) :  358.3866 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -358.39  |proj g|=       3.1676
At iterate     1  f =      -363.69  |proj g|=        4.2698
At iterate     2  f =      -363.86  |proj g|=        4.2152
At iterate     3  f =      -364.05  |proj g|=        4.0507
At iterate     4  f =      -364.43  |proj g|=        3.9549
At iterate     5  f =      -365.29  |proj g|=        3.1176
At iterate     6  f =      -365.45  |proj g|=        3.4048
At iterate     7  f =      -365.46  |proj g|=        3.3507
At iterate     8  f =      -365.46  |proj g|=        3.3455
At iterate     9  f =      -365.46  |proj g|=        3.3442
At iterate    10  f =      -365.46  |proj g|=        3.3427
At iterate    11  f =      -365.46  |proj g|=        3.3388
At iterate    12  f =      -365.46  |proj g|=        3.3256
At iterate    13  f =      -365.47  |proj g|=        3.3079
At iterate    14  f =      -365.48  |proj g|=        3.2732
At iterate    15  f =      -365.52  |proj g|=        3.2269
At iterate    16  f =      -365.55  |proj g|=        2.9931
At iterate    17  f =      -365.71  |proj g|=        3.0294
At iterate    18  f =      -366.04  |proj g|=        3.0516
At iterate    19  f =      -367.43  |proj g|=         2.971
At iterate    20  f =      -370.57  |proj g|=        2.6056
At iterate    21  f =      -378.58  |proj g|=        2.4533
At iterate    22  f =      -385.37  |proj g|=        1.6107
At iterate    23  f =      -385.39  |proj g|=        1.5919
At iterate    24  f =      -385.48  |proj g|=        1.4596
At iterate    25  f =       -385.9  |proj g|=        1.1695
At iterate    26  f =      -386.62  |proj g|=       0.55392
At iterate    27  f =      -387.17  |proj g|=        0.6008
At iterate    28  f =      -387.17  |proj g|=       0.64096
At iterate    29  f =      -387.17  |proj g|=        0.6307
At iterate    30  f =      -387.17  |proj g|=       0.63245
At iterate    31  f =      -387.17  |proj g|=       0.63492
At iterate    32  f =      -387.17  |proj g|=       0.83146
At iterate    33  f =      -387.18  |proj g|=       0.83137
At iterate    34  f =      -387.19  |proj g|=       0.83094
At iterate    35  f =      -387.23  |proj g|=       0.82959
At iterate    36  f =      -387.33  |proj g|=       0.82571
At iterate    37  f =      -387.56  |proj g|=       0.81576
At iterate    38  f =      -388.05  |proj g|=       0.79401
At iterate    39  f =      -388.27  |proj g|=       0.77976
At iterate    40  f =      -388.31  |proj g|=       0.77919
At iterate    41  f =      -388.32  |proj g|=       0.19715
At iterate    42  f =      -388.32  |proj g|=       0.19693
At iterate    43  f =      -388.32  |proj g|=       0.19661
At iterate    44  f =      -388.32  |proj g|=       0.19617
At iterate    45  f =      -388.32  |proj g|=       0.19506
At iterate    46  f =      -388.32  |proj g|=       0.15931
At iterate    47  f =      -388.32  |proj g|=       0.60809
At iterate    48  f =      -388.32  |proj g|=       0.51212
At iterate    49  f =      -388.32  |proj g|=      0.091544
At iterate    50  f =      -388.32  |proj g|=     0.0035138
At iterate    51  f =      -388.32  |proj g|=     0.0019783

iterations 51
function evaluations 58
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00197832
final function value -388.325

F = -388.325
final  value -388.324778 
converged
 
INFO  [09:10:32.805] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:10:32.891] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:10:32.898] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:10:45.163] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:10:57.944] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:11:08.234] [mlr3]  Finished benchmark 
INFO  [09:11:08.335] [bbotk] Result of batch 66: 
INFO  [09:11:08.337] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:11:08.337] [bbotk]              9.576726                 3.900087                       0.1708675 
INFO  [09:11:08.337] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:11:08.337] [bbotk]                     4777        0.625 -0.9600022         <NA>   0.9704874 
INFO  [09:11:08.337] [bbotk]                                 uhash 
INFO  [09:11:08.337] [bbotk]  7815ad6a-ffb2-41b8-adf5-36a6f35723e8 
DEBUG [09:11:09.215] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.863754e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  8.863754e-06 0.0008881491 
  - best initial criterion value(s) :  371.6122 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -371.61  |proj g|=      0.19084
At iterate     1  f =      -381.17  |proj g|=        4.3066
At iterate     2  f =      -382.61  |proj g|=        4.0242
At iterate     3  f =      -383.26  |proj g|=        2.8293
At iterate     4  f =      -383.64  |proj g|=        3.4761
At iterate     5  f =      -383.68  |proj g|=        3.3523
At iterate     6  f =      -383.69  |proj g|=        3.3034
At iterate     7  f =       -383.7  |proj g|=        3.2383
At iterate     8  f =      -383.73  |proj g|=        3.0961
At iterate     9  f =      -383.76  |proj g|=        2.9973
At iterate    10  f =      -383.76  |proj g|=        3.1071
At iterate    11  f =      -383.77  |proj g|=        3.0181
At iterate    12  f =      -383.77  |proj g|=        3.0196
At iterate    13  f =      -383.77  |proj g|=        3.0196

iterations 13
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.01955
final function value -383.769

F = -383.769
final  value -383.769077 
converged
 
INFO  [09:11:09.219] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:11:09.305] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:11:09.312] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:11:16.478] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:11:24.943] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:11:31.813] [mlr3]  Finished benchmark 
INFO  [09:11:31.938] [bbotk] Result of batch 67: 
INFO  [09:11:31.940] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:11:31.940] [bbotk]              8.969751                 5.738962                      0.03647303 
INFO  [09:11:31.940] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:11:31.940] [bbotk]                     3279        0.635 -0.9674725         <NA>   0.9621795 
INFO  [09:11:31.940] [bbotk]                                 uhash 
INFO  [09:11:31.940] [bbotk]  b28b3a15-f2bd-4a79-9dfb-ac2a1530c1e1 
DEBUG [09:11:32.948] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.787378e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  8.787378e-06 0.0008807587 
  - best initial criterion value(s) :  349.6026 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -349.6  |proj g|=       9.8044
At iterate     1  f =      -366.64  |proj g|=        1.9062
At iterate     2  f =      -371.14  |proj g|=        3.0077
At iterate     3  f =      -371.73  |proj g|=        2.8437
At iterate     4  f =      -371.91  |proj g|=        2.6011
At iterate     5  f =      -371.92  |proj g|=        2.6457
At iterate     6  f =      -371.92  |proj g|=        2.6386
At iterate     7  f =      -371.92  |proj g|=        2.6385

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.63849
final function value -371.918

F = -371.918
final  value -371.918341 
converged
 
INFO  [09:11:32.952] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:11:33.039] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:11:33.046] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:11:39.335] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:11:45.794] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:11:50.098] [mlr3]  Finished benchmark 
INFO  [09:11:50.590] [bbotk] Result of batch 68: 
INFO  [09:11:50.593] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:11:50.593] [bbotk]              4.254093                 2.770409                       0.2556582 
INFO  [09:11:50.593] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:11:50.593] [bbotk]                     2881        0.777 -0.9679925         <NA>   0.9718194 
INFO  [09:11:50.593] [bbotk]                                 uhash 
INFO  [09:11:50.593] [bbotk]  a4bd5e30-5a60-4dd2-9512-30d1859c9b2e 
DEBUG [09:11:51.676] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.732215e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  8.732215e-06 0.0008770258 
  - best initial criterion value(s) :  354.7747 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -354.77  |proj g|=       8.8294
At iterate     1  f =      -367.93  |proj g|=        7.8382
At iterate     2  f =       -370.9  |proj g|=        7.2101
At iterate     3  f =      -371.15  |proj g|=         6.792
At iterate     4  f =      -371.24  |proj g|=        6.3724
At iterate     5  f =      -371.24  |proj g|=        6.3104
At iterate     6  f =      -371.25  |proj g|=        6.2694
At iterate     7  f =      -371.25  |proj g|=        6.2643
At iterate     8  f =      -371.25  |proj g|=        6.2699
At iterate     9  f =      -371.25  |proj g|=        6.2712
At iterate    10  f =      -371.25  |proj g|=        6.2753
At iterate    11  f =      -371.25  |proj g|=        6.2815
At iterate    12  f =      -371.25  |proj g|=        6.2917
At iterate    13  f =      -371.25  |proj g|=        6.3095
At iterate    14  f =      -371.25  |proj g|=        6.3418
At iterate    15  f =      -371.25  |proj g|=        6.4007
At iterate    16  f =      -371.26  |proj g|=        6.4868
At iterate    17  f =      -371.27  |proj g|=        6.5975
At iterate    18  f =      -371.29  |proj g|=        6.6176
At iterate    19  f =       -371.4  |proj g|=         6.664
At iterate    20  f =      -371.58  |proj g|=        6.6129
At iterate    21  f =      -372.41  |proj g|=         6.077
At iterate    22  f =      -374.22  |proj g|=        4.8945
At iterate    23  f =       -379.8  |proj g|=        2.2491
At iterate    24  f =      -381.37  |proj g|=        0.6089
At iterate    25  f =      -382.39  |proj g|=       0.46216
At iterate    26  f =      -384.15  |proj g|=       0.84773
At iterate    27  f =      -384.47  |proj g|=       0.84858
At iterate    28  f =      -384.61  |proj g|=       0.86122
At iterate    29  f =      -385.34  |proj g|=       0.86839
At iterate    30  f =      -386.38  |proj g|=       0.88937
At iterate    31  f =      -386.59  |proj g|=       0.55462
At iterate    32  f =       -386.6  |proj g|=       0.57728
At iterate    33  f =       -386.6  |proj g|=       0.57533
At iterate    34  f =       -386.6  |proj g|=       0.57609
At iterate    35  f =       -386.6  |proj g|=        0.5761

iterations 35
function evaluations 41
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.576098
final function value -386.597

F = -386.597
final  value -386.596557 
converged
 
INFO  [09:11:51.683] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:11:51.785] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:11:51.792] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:11:56.584] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:12:01.405] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:12:06.155] [mlr3]  Finished benchmark 
INFO  [09:12:06.258] [bbotk] Result of batch 69: 
INFO  [09:12:06.260] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:12:06.260] [bbotk]              2.121848                 6.842269                      0.01850611 
INFO  [09:12:06.260] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:12:06.260] [bbotk]                     2915         0.74 -0.9672487         <NA>   0.9201024 
INFO  [09:12:06.260] [bbotk]                                 uhash 
INFO  [09:12:06.260] [bbotk]  e8fe684d-6063-4fd8-b25f-1f129b16da78 
DEBUG [09:12:07.277] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.075371e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.044423e-05 0.001075371 
  - best initial criterion value(s) :  370.5825 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -370.58  |proj g|=       13.794
At iterate     1  f =      -379.21  |proj g|=        9.5757
At iterate     2  f =      -382.39  |proj g|=        8.7089
At iterate     3  f =      -384.36  |proj g|=        6.9859
At iterate     4  f =      -385.97  |proj g|=        6.0366
At iterate     5  f =      -386.47  |proj g|=        5.1639
At iterate     6  f =      -386.67  |proj g|=        4.7727
At iterate     7  f =       -386.7  |proj g|=        5.1014
At iterate     8  f =      -386.77  |proj g|=        4.6794
At iterate     9  f =      -386.77  |proj g|=        4.6439
At iterate    10  f =      -386.77  |proj g|=        4.6347
At iterate    11  f =      -386.77  |proj g|=         4.607
At iterate    12  f =      -386.78  |proj g|=        4.5745
At iterate    13  f =      -386.79  |proj g|=        4.4811
At iterate    14  f =      -386.79  |proj g|=        4.5192
At iterate    15  f =      -386.82  |proj g|=         4.388
At iterate    16  f =       -386.9  |proj g|=         4.151
At iterate    17  f =      -387.08  |proj g|=        3.8383
At iterate    18  f =      -387.65  |proj g|=        3.3721
At iterate    19  f =      -389.36  |proj g|=        2.6755
At iterate    20  f =       -389.7  |proj g|=        2.3617
At iterate    21  f =      -394.35  |proj g|=        1.5807
At iterate    22  f =      -399.21  |proj g|=       0.77808
At iterate    23  f =       -404.3  |proj g|=       0.70581
At iterate    24  f =      -404.64  |proj g|=       0.26573
At iterate    25  f =      -404.68  |proj g|=       0.25842
At iterate    26  f =      -404.69  |proj g|=       0.25483
At iterate    27  f =       -404.7  |proj g|=       0.72944
At iterate    28  f =       -404.7  |proj g|=      0.090838
At iterate    29  f =       -404.7  |proj g|=      0.090418
At iterate    30  f =       -404.7  |proj g|=      0.090424

iterations 30
function evaluations 37
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.090424
final function value -404.698

F = -404.698
final  value -404.697782 
converged
 
INFO  [09:12:07.281] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:12:07.474] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:12:07.481] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:12:09.109] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:12:10.849] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:12:12.633] [mlr3]  Finished benchmark 
INFO  [09:12:12.737] [bbotk] Result of batch 70: 
INFO  [09:12:12.739] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:12:12.739] [bbotk]              9.054762                 3.664553                       0.2905245 
INFO  [09:12:12.739] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:12:12.739] [bbotk]                      951        0.683 -0.9549843         <NA>    0.969059 
INFO  [09:12:12.739] [bbotk]                                 uhash 
INFO  [09:12:12.739] [bbotk]  abfc749c-1db7-463d-aed2-e42fd66f0740 
DEBUG [09:12:13.698] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.06582e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.035849e-05 0.00106582 
  - best initial criterion value(s) :  362.6362 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -362.64  |proj g|=       14.247
At iterate     1  f =      -368.27  |proj g|=        4.8489
At iterate     2  f =      -385.24  |proj g|=        2.3339
At iterate     3  f =      -388.71  |proj g|=       0.98207
At iterate     4  f =      -388.74  |proj g|=       0.89623
At iterate     5  f =      -388.74  |proj g|=       0.90241
At iterate     6  f =      -388.75  |proj g|=       0.97328
At iterate     7  f =      -388.75  |proj g|=        1.0309
At iterate     8  f =      -388.76  |proj g|=        1.0988
At iterate     9  f =      -388.79  |proj g|=        1.2276
At iterate    10  f =       -388.8  |proj g|=        1.2012
At iterate    11  f =      -388.87  |proj g|=        1.3976
At iterate    12  f =      -389.06  |proj g|=        1.6975
At iterate    13  f =      -389.52  |proj g|=        2.0354
At iterate    14  f =      -390.52  |proj g|=        2.1722
At iterate    15  f =      -392.21  |proj g|=        1.6003
At iterate    16  f =      -392.37  |proj g|=        1.6701
At iterate    17  f =      -393.42  |proj g|=       0.94948
At iterate    18  f =      -393.75  |proj g|=       0.54126
At iterate    19  f =      -394.01  |proj g|=       0.30634
At iterate    20  f =      -394.04  |proj g|=       0.32281
At iterate    21  f =      -394.06  |proj g|=       0.69174
At iterate    22  f =      -394.06  |proj g|=       0.26937
At iterate    23  f =      -394.06  |proj g|=       0.29662
At iterate    24  f =      -394.06  |proj g|=       0.29742
At iterate    25  f =      -394.06  |proj g|=       0.29751

iterations 25
function evaluations 34
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.297509
final function value -394.063

F = -394.063
final  value -394.063375 
converged
 
INFO  [09:12:13.702] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:12:13.835] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:12:13.842] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:12:15.216] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:12:16.581] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:12:17.904] [mlr3]  Finished benchmark 
INFO  [09:12:18.007] [bbotk] Result of batch 71: 
INFO  [09:12:18.009] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:12:18.009] [bbotk]              5.133312                 6.303354                       0.2204178 
INFO  [09:12:18.009] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:12:18.009] [bbotk]                      622         0.65 -0.9636297         <NA>   0.9616114 
INFO  [09:12:18.009] [bbotk]                                 uhash 
INFO  [09:12:18.009] [bbotk]  b385a6bb-3e3d-4816-b58c-3bd8a4bbfc9f 
DEBUG [09:12:19.208] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.056834e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.027171e-05 0.001056834 
  - best initial criterion value(s) :  378.7609 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -378.76  |proj g|=       3.8277
At iterate     1  f =      -389.44  |proj g|=        5.4365
At iterate     2  f =      -390.93  |proj g|=        5.4469
At iterate     3  f =      -394.62  |proj g|=        4.6936
At iterate     4  f =      -395.48  |proj g|=         4.077
At iterate     5  f =      -396.89  |proj g|=        2.7846
At iterate     6  f =      -397.04  |proj g|=        2.6539
At iterate     7  f =      -397.07  |proj g|=        2.6852
At iterate     8  f =      -397.07  |proj g|=         2.665
At iterate     9  f =      -397.07  |proj g|=        2.6697
At iterate    10  f =      -397.07  |proj g|=        2.6708
At iterate    11  f =      -397.07  |proj g|=        2.6777
At iterate    12  f =      -397.07  |proj g|=        2.6863
At iterate    13  f =      -397.08  |proj g|=        2.7004
At iterate    14  f =      -397.08  |proj g|=        2.7211
At iterate    15  f =      -397.08  |proj g|=        2.7562
At iterate    16  f =       -397.1  |proj g|=        2.8176
At iterate    17  f =      -397.14  |proj g|=        2.9268
At iterate    18  f =      -397.22  |proj g|=        3.0989
At iterate    19  f =      -397.33  |proj g|=        3.2789
At iterate    20  f =       -397.4  |proj g|=        3.3549
At iterate    21  f =      -397.46  |proj g|=        3.3443
At iterate    22  f =       -397.5  |proj g|=        3.2961
At iterate    23  f =      -397.58  |proj g|=        3.2115
At iterate    24  f =      -397.79  |proj g|=        3.0378
At iterate    25  f =      -398.36  |proj g|=        2.7094
At iterate    26  f =      -399.68  |proj g|=        2.1058
At iterate    27  f =      -401.51  |proj g|=        1.7863
At iterate    28  f =      -402.19  |proj g|=        2.4708
At iterate    29  f =      -403.05  |proj g|=        2.3425
At iterate    30  f =      -403.59  |proj g|=        2.3687
At iterate    31  f =      -405.61  |proj g|=        2.5064
At iterate    32  f =      -406.97  |proj g|=        2.6697
At iterate    33  f =       -407.2  |proj g|=        2.7533
At iterate    34  f =      -407.22  |proj g|=        2.9037
At iterate    35  f =      -407.26  |proj g|=        2.8912
At iterate    36  f =      -407.26  |proj g|=        2.8979
At iterate    37  f =      -407.26  |proj g|=         2.898
At iterate    38  f =      -407.26  |proj g|=           2.9
At iterate    39  f =      -407.26  |proj g|=        2.9003

iterations 39
function evaluations 50
segments explored during Cauchy searches 41
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.90026
final function value -407.26

F = -407.26
final  value -407.260380 
converged
 
INFO  [09:12:19.212] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:12:19.339] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:12:19.346] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:12:26.288] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:12:33.271] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:12:40.444] [mlr3]  Finished benchmark 
INFO  [09:12:40.566] [bbotk] Result of batch 72: 
INFO  [09:12:40.567] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:12:40.567] [bbotk]              9.610731                  7.84469                     0.007702672 
INFO  [09:12:40.567] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:12:40.567] [bbotk]                     4346        0.818 -0.9566361         <NA>   0.9440525 
INFO  [09:12:40.567] [bbotk]                                 uhash 
INFO  [09:12:40.567] [bbotk]  6e1788a8-1232-43fb-887f-ca114113b988 
DEBUG [09:12:41.627] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.091424e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.06251e-05 0.001091424 
  - best initial criterion value(s) :  376.3134 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -376.31  |proj g|=       7.5389
At iterate     1  f =      -389.23  |proj g|=        7.0918
At iterate     2  f =      -396.44  |proj g|=        5.4266
At iterate     3  f =      -398.15  |proj g|=        4.0657
At iterate     4  f =      -399.58  |proj g|=        2.7202
At iterate     5  f =      -399.61  |proj g|=        2.5752
At iterate     6  f =      -399.61  |proj g|=          2.56
At iterate     7  f =      -399.61  |proj g|=        2.5664
At iterate     8  f =      -399.61  |proj g|=        2.5719
At iterate     9  f =      -399.61  |proj g|=        2.5852
At iterate    10  f =      -399.61  |proj g|=        2.6098
At iterate    11  f =      -399.62  |proj g|=        2.6462
At iterate    12  f =      -399.63  |proj g|=        2.7053
At iterate    13  f =      -399.65  |proj g|=        2.8045
At iterate    14  f =      -399.72  |proj g|=        2.9764
At iterate    15  f =      -399.86  |proj g|=        3.2456
At iterate    16  f =      -400.13  |proj g|=        3.5819
At iterate    17  f =       -400.6  |proj g|=        3.9753
At iterate    18  f =      -401.51  |proj g|=        4.2899
At iterate    19  f =      -402.45  |proj g|=        4.3967
At iterate    20  f =      -406.24  |proj g|=        3.7445
At iterate    21  f =      -408.17  |proj g|=        1.9667
At iterate    22  f =       -413.7  |proj g|=        1.0446
At iterate    23  f =      -415.53  |proj g|=       0.70502
At iterate    24  f =      -416.78  |proj g|=       0.98217
At iterate    25  f =      -416.91  |proj g|=       0.99847
At iterate    26  f =      -416.95  |proj g|=        1.0742
At iterate    27  f =      -416.99  |proj g|=        1.1753
At iterate    28  f =      -416.99  |proj g|=        1.1951
At iterate    29  f =      -416.99  |proj g|=        1.1986
At iterate    30  f =      -416.99  |proj g|=        1.1987

iterations 30
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.19869
final function value -416.991

F = -416.991
final  value -416.991403 
converged
 
INFO  [09:12:41.631] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:12:41.722] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:12:41.730] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:12:49.789] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:12:57.893] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:13:10.438] [mlr3]  Finished benchmark 
INFO  [09:13:10.557] [bbotk] Result of batch 73: 
INFO  [09:13:10.559] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:13:10.559] [bbotk]              3.680677                 9.014448                       0.3903903 
INFO  [09:13:10.559] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:13:10.559] [bbotk]                     4898        0.725 -0.9534544         <NA>   0.9734028 
INFO  [09:13:10.559] [bbotk]                                 uhash 
INFO  [09:13:10.559] [bbotk]  66a0b064-b2d6-4389-b6db-3b58ed098acf 
DEBUG [09:13:11.568] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.087046e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.050539e-05 0.001087046 
  - best initial criterion value(s) :  379.6118 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -379.61  |proj g|=       3.7496
At iterate     1  f =      -395.08  |proj g|=        6.3414
At iterate     2  f =      -396.91  |proj g|=        6.3736
At iterate     3  f =      -399.18  |proj g|=        5.9666
At iterate     4  f =       -399.2  |proj g|=        5.9249
At iterate     5  f =      -399.21  |proj g|=        5.9766
At iterate     6  f =      -399.23  |proj g|=        6.1047
At iterate     7  f =      -399.23  |proj g|=        6.2228
At iterate     8  f =      -399.24  |proj g|=         6.249
At iterate     9  f =      -399.24  |proj g|=        6.2536
At iterate    10  f =      -399.24  |proj g|=        6.2722
At iterate    11  f =      -399.24  |proj g|=        6.3025
At iterate    12  f =      -399.25  |proj g|=        6.3357
At iterate    13  f =      -399.26  |proj g|=        6.4392
At iterate    14  f =      -399.28  |proj g|=        6.3075
At iterate    15  f =      -399.36  |proj g|=        6.4141
At iterate    16  f =      -402.51  |proj g|=        6.1465
At iterate    17  f =      -414.29  |proj g|=         2.724
At iterate    18  f =      -414.31  |proj g|=        2.7074
At iterate    19  f =      -414.73  |proj g|=        2.2112
At iterate    20  f =      -414.75  |proj g|=         2.333
At iterate    21  f =      -414.75  |proj g|=        2.2902
At iterate    22  f =      -414.75  |proj g|=        2.2899
At iterate    23  f =      -414.75  |proj g|=        2.2804
At iterate    24  f =      -414.75  |proj g|=        2.2642
At iterate    25  f =      -414.77  |proj g|=        2.2322
At iterate    26  f =      -414.77  |proj g|=        2.2763
At iterate    27  f =      -414.86  |proj g|=        2.2716
At iterate    28  f =      -415.08  |proj g|=        2.3021
At iterate    29  f =      -415.73  |proj g|=        2.3224
At iterate    30  f =      -416.68  |proj g|=        2.3785
At iterate    31  f =      -417.85  |proj g|=         2.464
At iterate    32  f =      -417.87  |proj g|=        2.3763
At iterate    33  f =      -419.04  |proj g|=        2.4686
At iterate    34  f =      -419.34  |proj g|=        2.5492
At iterate    35  f =      -419.34  |proj g|=        2.5572
At iterate    36  f =      -419.34  |proj g|=        2.5593
At iterate    37  f =      -419.34  |proj g|=        2.5598

iterations 37
function evaluations 50
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.55984
final function value -419.339

F = -419.339
final  value -419.338752 
converged
 
INFO  [09:13:11.572] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:13:11.663] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:13:11.671] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:13:15.736] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:13:22.471] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:13:27.973] [mlr3]  Finished benchmark 
INFO  [09:13:28.101] [bbotk] Result of batch 74: 
INFO  [09:13:28.103] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:13:28.103] [bbotk]               2.63214                 9.023641                       0.4129896 
INFO  [09:13:28.103] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:13:28.103] [bbotk]                     1950         0.65 -0.9524973         <NA>   0.9630769 
INFO  [09:13:28.103] [bbotk]                                 uhash 
INFO  [09:13:28.103] [bbotk]  2506bf62-d987-4a8d-a256-cbf3719250f7 
DEBUG [09:13:29.058] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.077124e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.051813e-05 0.001077124 
  - best initial criterion value(s) :  389.0393 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -389.04  |proj g|=       5.9082
At iterate     1  f =      -404.07  |proj g|=        6.0976
At iterate     2  f =      -405.07  |proj g|=         6.136
At iterate     3  f =      -407.66  |proj g|=        5.1193
At iterate     4  f =       -407.9  |proj g|=        3.9025
At iterate     5  f =      -408.19  |proj g|=        4.0988
At iterate     6  f =      -408.21  |proj g|=        3.9501
At iterate     7  f =      -408.21  |proj g|=        3.9216
At iterate     8  f =      -408.22  |proj g|=        3.8353
At iterate     9  f =      -408.23  |proj g|=        3.7497
At iterate    10  f =      -408.28  |proj g|=        3.5739
At iterate    11  f =       -408.4  |proj g|=        3.3106
At iterate    12  f =      -408.43  |proj g|=        3.1922
At iterate    13  f =      -408.72  |proj g|=        2.8627
At iterate    14  f =      -411.58  |proj g|=        2.0255
At iterate    15  f =         -421  |proj g|=       0.86874
At iterate    16  f =      -421.93  |proj g|=       0.92348
At iterate    17  f =      -422.16  |proj g|=        1.0484
At iterate    18  f =       -422.2  |proj g|=        1.1763
At iterate    19  f =       -422.2  |proj g|=         1.207
At iterate    20  f =       -422.2  |proj g|=        1.2181
At iterate    21  f =       -422.2  |proj g|=        1.2099
At iterate    22  f =       -422.2  |proj g|=        1.2074
At iterate    23  f =       -422.2  |proj g|=        1.2073

iterations 23
function evaluations 28
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.20732
final function value -422.204

F = -422.204
final  value -422.203705 
converged
 
INFO  [09:13:29.063] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:13:29.177] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:13:29.184] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:13:32.902] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:13:37.501] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:13:41.383] [mlr3]  Finished benchmark 
INFO  [09:13:41.481] [bbotk] Result of batch 75: 
INFO  [09:13:41.483] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:13:41.483] [bbotk]              7.938781                  5.57551                       0.2993981 
INFO  [09:13:41.483] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:13:41.483] [bbotk]                     1615        0.664 -0.9575956         <NA>   0.9715701 
INFO  [09:13:41.483] [bbotk]                                 uhash 
INFO  [09:13:41.483] [bbotk]  8e078f17-c858-4c79-9ddc-8797d4a91a87 
DEBUG [09:13:42.485] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.070439e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.042017e-05 0.001070439 
  - best initial criterion value(s) :  392.7314 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -392.73  |proj g|=       2.7661
At iterate     1  f =      -396.35  |proj g|=        4.3273
At iterate     2  f =      -396.79  |proj g|=        3.8587
At iterate     3  f =      -397.03  |proj g|=        3.9174
At iterate     4  f =      -397.12  |proj g|=        3.7857
At iterate     5  f =      -397.13  |proj g|=        3.8378
At iterate     6  f =      -397.14  |proj g|=        3.8278
At iterate     7  f =      -397.14  |proj g|=        3.8279
At iterate     8  f =      -397.14  |proj g|=        3.8279
At iterate     9  f =      -397.14  |proj g|=         3.828
At iterate    10  f =      -397.14  |proj g|=         3.828
At iterate    11  f =      -397.14  |proj g|=        3.8279
At iterate    12  f =      -397.14  |proj g|=        3.8281
At iterate    13  f =      -397.14  |proj g|=        3.8176
At iterate    14  f =      -397.14  |proj g|=        3.8312
At iterate    15  f =      -397.14  |proj g|=        3.8223
At iterate    16  f =      -397.18  |proj g|=        3.7461
At iterate    17  f =      -397.25  |proj g|=        3.6299
At iterate    18  f =      -397.49  |proj g|=        3.3123
At iterate    19  f =      -398.04  |proj g|=        2.7032
At iterate    20  f =      -399.13  |proj g|=        1.5326
At iterate    21  f =      -400.96  |proj g|=       0.86722
At iterate    22  f =      -401.74  |proj g|=       0.85273
At iterate    23  f =      -401.86  |proj g|=       0.84828
At iterate    24  f =      -401.86  |proj g|=       0.84667
At iterate    25  f =      -401.87  |proj g|=        0.8455
At iterate    26  f =      -401.87  |proj g|=       0.84489
At iterate    27  f =      -401.87  |proj g|=       0.55903
At iterate    28  f =      -401.87  |proj g|=       0.55675
At iterate    29  f =      -401.87  |proj g|=       0.55574
At iterate    30  f =      -401.87  |proj g|=       0.55575

iterations 30
function evaluations 38
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.555747
final function value -401.867

F = -401.867
final  value -401.866915 
converged
 
INFO  [09:13:42.489] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:13:42.593] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:13:42.600] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:13:46.860] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:13:52.378] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:13:58.828] [mlr3]  Finished benchmark 
INFO  [09:13:58.963] [bbotk] Result of batch 76: 
INFO  [09:13:58.965] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:13:58.965] [bbotk]              8.289682                 9.659146                       0.1635048 
INFO  [09:13:58.965] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:13:58.965] [bbotk]                     1982        0.675 -0.9662621         <NA>   0.9699282 
INFO  [09:13:58.965] [bbotk]                                 uhash 
INFO  [09:13:58.965] [bbotk]  81dfd092-4ff8-495b-a246-d1713383eff6 
DEBUG [09:13:59.884] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.062195e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.036312e-05 0.001062195 
  - best initial criterion value(s) :  409.5986 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -409.6  |proj g|=       2.0606
At iterate     1  f =      -413.08  |proj g|=        2.1813
At iterate     2  f =      -415.85  |proj g|=         4.269
At iterate     3  f =      -418.97  |proj g|=        3.4717
At iterate     4  f =      -419.74  |proj g|=        3.1579
At iterate     5  f =      -420.84  |proj g|=        3.3911
At iterate     6  f =      -420.91  |proj g|=        3.7149
At iterate     7  f =      -420.97  |proj g|=        3.5865
At iterate     8  f =      -420.97  |proj g|=        3.5649
At iterate     9  f =      -420.97  |proj g|=        3.5672
At iterate    10  f =      -420.97  |proj g|=        3.5678

iterations 10
function evaluations 17
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.56782
final function value -420.969

F = -420.969
final  value -420.968614 
converged
 
INFO  [09:13:59.888] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:13:59.976] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:13:59.983] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:14:02.066] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:14:04.099] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:14:06.936] [mlr3]  Finished benchmark 
INFO  [09:14:07.035] [bbotk] Result of batch 77: 
INFO  [09:14:07.037] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:14:07.037] [bbotk]              9.792858                 4.637302                        0.171412 
INFO  [09:14:07.037] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [09:14:07.037] [bbotk]                      794        0.679  -0.96019         <NA>   0.9633105 
INFO  [09:14:07.037] [bbotk]                                 uhash 
INFO  [09:14:07.037] [bbotk]  499375e9-19ed-476f-a332-f3514abb97d1 
DEBUG [09:14:07.962] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.052718e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.0274e-05 0.001052718 
  - best initial criterion value(s) :  390.1229 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -390.12  |proj g|=       5.8051
At iterate     1  f =      -418.55  |proj g|=        2.5118
At iterate     2  f =      -432.84  |proj g|=        1.0256
At iterate     3  f =      -436.49  |proj g|=       0.91382
At iterate     4  f =      -436.66  |proj g|=       0.83897
At iterate     5  f =         -437  |proj g|=       0.20568
At iterate     6  f =      -437.16  |proj g|=        0.7668
At iterate     7  f =      -437.18  |proj g|=       0.77022
At iterate     8  f =      -437.18  |proj g|=       0.77097
At iterate     9  f =      -437.18  |proj g|=       0.77092
At iterate    10  f =      -437.18  |proj g|=       0.77092

iterations 10
function evaluations 12
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.770915
final function value -437.183

F = -437.183
final  value -437.182577 
converged
 
INFO  [09:14:07.964] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:14:08.059] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:14:08.066] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:14:17.732] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:14:28.008] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:14:37.202] [mlr3]  Finished benchmark 
INFO  [09:14:37.300] [bbotk] Result of batch 78: 
INFO  [09:14:37.302] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:14:37.302] [bbotk]              2.063984                 6.578666                      0.05533505 
INFO  [09:14:37.302] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:14:37.302] [bbotk]                     4159         0.67 -0.9568709         <NA>   0.9466142 
INFO  [09:14:37.302] [bbotk]                                 uhash 
INFO  [09:14:37.302] [bbotk]  bbf6197b-a0b9-4706-a051-70fef11d741b 
DEBUG [09:14:38.431] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.075676e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.047714e-05 0.001075676 
  - best initial criterion value(s) :  421.1044 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -421.1  |proj g|=       3.1548
At iterate     1  f =      -421.25  |proj g|=       0.33156
At iterate     2  f =      -426.62  |proj g|=        3.0997
At iterate     3  f =      -433.62  |proj g|=        2.3369
At iterate     4  f =      -434.55  |proj g|=         2.205
At iterate     5  f =      -436.08  |proj g|=        1.6595
At iterate     6  f =      -436.14  |proj g|=         1.529
At iterate     7  f =      -436.16  |proj g|=        1.7326
At iterate     8  f =      -436.19  |proj g|=        1.6083
At iterate     9  f =      -436.19  |proj g|=        1.6152
At iterate    10  f =      -436.19  |proj g|=        1.6149

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.61494
final function value -436.189

F = -436.189
final  value -436.189056 
converged
 
INFO  [09:14:38.436] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:14:38.523] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:14:38.530] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:14:39.758] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:14:41.759] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:14:43.084] [mlr3]  Finished benchmark 
INFO  [09:14:43.183] [bbotk] Result of batch 79: 
INFO  [09:14:43.185] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:14:43.185] [bbotk]              8.451888                  4.74871                       0.2377236 
INFO  [09:14:43.185] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:14:43.185] [bbotk]                      480        0.842 -0.9590512         <NA>    0.961616 
INFO  [09:14:43.185] [bbotk]                                 uhash 
INFO  [09:14:43.185] [bbotk]  ab6647d7-0d92-4885-86b4-ba5e8f7eaaf1 
DEBUG [09:14:44.133] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.067056e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.038754e-05 0.001067056 
  - best initial criterion value(s) :  420.3157 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -420.32  |proj g|=       1.2573
At iterate     1  f =      -424.06  |proj g|=        3.1229
At iterate     2  f =      -426.74  |proj g|=         4.307
At iterate     3  f =      -426.89  |proj g|=        4.4147
At iterate     4  f =         -427  |proj g|=         4.597
At iterate     5  f =      -427.02  |proj g|=        4.6889
At iterate     6  f =      -427.02  |proj g|=         4.754
At iterate     7  f =      -427.03  |proj g|=        4.7747
At iterate     8  f =      -427.03  |proj g|=        4.7755
At iterate     9  f =      -427.03  |proj g|=         4.775

iterations 9
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.775
final function value -427.026

F = -427.026
final  value -427.026015 
converged
 
INFO  [09:14:44.137] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:14:44.225] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:14:44.232] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:14:49.140] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:14:54.669] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:15:00.361] [mlr3]  Finished benchmark 
INFO  [09:15:00.480] [bbotk] Result of batch 80: 
INFO  [09:15:00.482] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:15:00.482] [bbotk]               4.65647                 7.150371                      0.03596921 
INFO  [09:15:00.482] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:15:00.482] [bbotk]                     2194        0.698 -0.9618552         <NA>   0.9534445 
INFO  [09:15:00.482] [bbotk]                                 uhash 
INFO  [09:15:00.482] [bbotk]  8b2cc145-91c6-4495-92f5-df7058e4075a 
DEBUG [09:15:01.425] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.069992e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.040981e-05 0.001069992 
  - best initial criterion value(s) :  418.8627 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -418.86  |proj g|=      0.96994
At iterate     1  f =      -435.36  |proj g|=       0.50077
At iterate     2  f =      -438.04  |proj g|=        2.5615
At iterate     3  f =      -438.79  |proj g|=        2.3324
At iterate     4  f =      -439.62  |proj g|=         1.754
At iterate     5  f =      -439.63  |proj g|=        1.5643
At iterate     6  f =      -439.64  |proj g|=         1.634
At iterate     7  f =      -439.64  |proj g|=        1.6305
At iterate     8  f =      -439.64  |proj g|=        1.6155
At iterate     9  f =      -439.64  |proj g|=        1.6153

iterations 9
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.61532
final function value -439.639

F = -439.639
final  value -439.639386 
converged
 
INFO  [09:15:01.429] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:15:01.515] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:15:01.522] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:15:05.134] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:15:08.912] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:15:13.005] [mlr3]  Finished benchmark 
INFO  [09:15:13.109] [bbotk] Result of batch 81: 
INFO  [09:15:13.112] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:15:13.112] [bbotk]              8.063556                 7.463161                       0.4920062 
INFO  [09:15:13.112] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:15:13.112] [bbotk]                     1603        0.709 -0.9620708         <NA>   0.9721628 
INFO  [09:15:13.112] [bbotk]                                 uhash 
INFO  [09:15:13.112] [bbotk]  53642986-2362-4013-8ce2-612c5c1bd420 
DEBUG [09:15:14.302] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.064704e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.033097e-05 0.001064704 
  - best initial criterion value(s) :  430.9295 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -430.93  |proj g|=       4.8927
At iterate     1  f =      -433.25  |proj g|=        4.8395
At iterate     2  f =       -433.6  |proj g|=        5.2378
At iterate     3  f =      -433.61  |proj g|=        5.1901
At iterate     4  f =      -433.62  |proj g|=        5.1812
At iterate     5  f =      -433.62  |proj g|=        5.1837
At iterate     6  f =      -433.63  |proj g|=        5.1949
At iterate     7  f =      -433.63  |proj g|=         5.204
At iterate     8  f =      -433.66  |proj g|=        5.2079
At iterate     9  f =      -433.73  |proj g|=        5.1805
At iterate    10  f =       -433.9  |proj g|=        5.0838
At iterate    11  f =      -434.23  |proj g|=        4.8193
At iterate    12  f =      -434.77  |proj g|=        4.3189
At iterate    13  f =      -434.79  |proj g|=        4.3496
At iterate    14  f =      -435.55  |proj g|=        3.6913
At iterate    15  f =      -440.49  |proj g|=        2.4691
At iterate    16  f =      -443.16  |proj g|=        1.7067
At iterate    17  f =      -445.22  |proj g|=        1.0721
At iterate    18  f =      -446.32  |proj g|=       0.74622
At iterate    19  f =      -446.55  |proj g|=       0.70176
At iterate    20  f =      -446.59  |proj g|=       0.90753
At iterate    21  f =      -446.63  |proj g|=       0.89768
At iterate    22  f =      -446.64  |proj g|=        0.9054
At iterate    23  f =      -446.64  |proj g|=       0.91174
At iterate    24  f =      -446.64  |proj g|=       0.91202

iterations 24
function evaluations 33
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.912021
final function value -446.635

F = -446.635
final  value -446.635334 
converged
 
INFO  [09:15:14.306] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:15:14.428] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:15:14.435] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:15:28.992] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:15:40.111] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:15:52.216] [mlr3]  Finished benchmark 
INFO  [09:15:52.318] [bbotk] Result of batch 82: 
INFO  [09:15:52.320] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:15:52.320] [bbotk]              3.751332                 7.195503                       0.3912887 
INFO  [09:15:52.320] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:15:52.320] [bbotk]                     4973        0.665 -0.9615105         <NA>   0.9736381 
INFO  [09:15:52.320] [bbotk]                                 uhash 
INFO  [09:15:52.320] [bbotk]  a120ac05-584b-4f27-a804-d5e45eecb321 
DEBUG [09:15:53.376] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.061434e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.031636e-05 0.001061434 
  - best initial criterion value(s) :  428.4694 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -428.47  |proj g|=       3.8062
At iterate     1  f =      -447.39  |proj g|=        2.6707
At iterate     2  f =      -450.09  |proj g|=        2.4364
At iterate     3  f =      -452.77  |proj g|=        1.3425
At iterate     4  f =      -453.62  |proj g|=        1.7843
At iterate     5  f =      -455.43  |proj g|=        1.8944
At iterate     6  f =      -459.16  |proj g|=        1.7757
At iterate     7  f =      -459.81  |proj g|=        2.3573
At iterate     8  f =      -460.81  |proj g|=        1.9956
At iterate     9  f =      -460.85  |proj g|=        1.8999
At iterate    10  f =      -460.86  |proj g|=        1.8889
At iterate    11  f =      -460.86  |proj g|=         1.882
At iterate    12  f =      -460.86  |proj g|=        1.8832
At iterate    13  f =      -460.86  |proj g|=        1.8829
At iterate    14  f =      -460.86  |proj g|=        1.8877
At iterate    15  f =      -460.89  |proj g|=        1.8939
At iterate    16  f =      -460.94  |proj g|=        1.9581
At iterate    17  f =      -461.05  |proj g|=        1.9213
At iterate    18  f =      -461.49  |proj g|=        1.9493
At iterate    19  f =      -462.23  |proj g|=        1.7684
At iterate    20  f =      -463.68  |proj g|=        1.4683
At iterate    21  f =      -463.69  |proj g|=        1.4364
At iterate    22  f =      -463.69  |proj g|=        1.4372
At iterate    23  f =      -463.69  |proj g|=        1.4367
At iterate    24  f =      -463.69  |proj g|=        1.4371
At iterate    25  f =      -463.69  |proj g|=        1.4361
At iterate    26  f =      -463.69  |proj g|=        1.4313
At iterate    27  f =      -463.69  |proj g|=        1.4243
At iterate    28  f =      -463.69  |proj g|=        1.4147
At iterate    29  f =       -463.7  |proj g|=        1.4055
At iterate    30  f =       -463.7  |proj g|=        1.4061
At iterate    31  f =      -463.72  |proj g|=        1.4465
At iterate    32  f =      -463.72  |proj g|=        1.4563
At iterate    33  f =      -463.72  |proj g|=        1.4573
At iterate    34  f =      -463.72  |proj g|=        1.4573

iterations 34
function evaluations 39
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.45728
final function value -463.716

F = -463.716
final  value -463.716373 
converged
 
INFO  [09:15:53.381] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:15:53.496] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:15:53.507] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:15:55.391] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:15:57.232] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:15:58.997] [mlr3]  Finished benchmark 
INFO  [09:15:59.100] [bbotk] Result of batch 83: 
INFO  [09:15:59.102] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:15:59.102] [bbotk]              2.744088                 9.533778                       0.2365775 
INFO  [09:15:59.102] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:15:59.102] [bbotk]                     1027         0.69 -0.9488231         <NA>   0.9532681 
INFO  [09:15:59.102] [bbotk]                                 uhash 
INFO  [09:15:59.102] [bbotk]  6330a8e4-d1c8-4646-8525-de820cceb264 
DEBUG [09:16:00.237] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.064778e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.033427e-05 0.001064778 
  - best initial criterion value(s) :  423.2969 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -423.3  |proj g|=       14.005
At iterate     1  f =       -429.5  |proj g|=        4.6872
At iterate     2  f =      -448.02  |proj g|=        1.8281
At iterate     3  f =      -448.04  |proj g|=        1.7182
At iterate     4  f =      -448.04  |proj g|=        1.6968
At iterate     5  f =      -448.04  |proj g|=         1.646
At iterate     6  f =      -448.04  |proj g|=        1.6409
At iterate     7  f =      -448.04  |proj g|=        1.6367
At iterate     8  f =      -448.04  |proj g|=        1.6345
At iterate     9  f =      -448.04  |proj g|=        1.6269
At iterate    10  f =      -448.05  |proj g|=        1.6014
At iterate    11  f =      -448.07  |proj g|=          1.55
At iterate    12  f =      -448.12  |proj g|=         1.441
At iterate    13  f =      -448.23  |proj g|=          1.24
At iterate    14  f =      -448.47  |proj g|=       0.99483
At iterate    15  f =      -448.97  |proj g|=        0.9093
At iterate    16  f =       -449.8  |proj g|=       0.90534
At iterate    17  f =      -451.37  |proj g|=       0.89824
At iterate    18  f =      -451.87  |proj g|=       0.89763
At iterate    19  f =      -456.98  |proj g|=        1.2101
At iterate    20  f =      -459.77  |proj g|=       0.85353
At iterate    21  f =      -461.54  |proj g|=       0.82495
At iterate    22  f =      -462.01  |proj g|=        0.2327
At iterate    23  f =      -462.18  |proj g|=       0.17977
At iterate    24  f =      -462.24  |proj g|=       0.80073
At iterate    25  f =      -462.29  |proj g|=       0.48516
At iterate    26  f =      -462.29  |proj g|=       0.23154
At iterate    27  f =      -462.29  |proj g|=       0.23395
At iterate    28  f =      -462.29  |proj g|=       0.23433
At iterate    29  f =      -462.29  |proj g|=       0.23436

iterations 29
function evaluations 41
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.234363
final function value -462.289

F = -462.289
final  value -462.289011 
converged
 
INFO  [09:16:00.241] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:16:00.332] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:16:00.339] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:16:06.151] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:16:11.902] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:16:17.362] [mlr3]  Finished benchmark 
INFO  [09:16:17.464] [bbotk] Result of batch 84: 
INFO  [09:16:17.466] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:16:17.466] [bbotk]              3.124335                 2.459364                      0.05902401 
INFO  [09:16:17.466] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:16:17.466] [bbotk]                     3657        0.742 -0.9572206         <NA>   0.9572693 
INFO  [09:16:17.466] [bbotk]                                 uhash 
INFO  [09:16:17.466] [bbotk]  e6e074a0-81bf-4b25-b2eb-cc59e5775666 
DEBUG [09:16:18.413] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.060924e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.033278e-05 0.001060924 
  - best initial criterion value(s) :  442.6515 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -442.65  |proj g|=       4.7505
At iterate     1  f =      -445.58  |proj g|=        2.3636
At iterate     2  f =      -468.08  |proj g|=        1.2555
At iterate     3  f =      -468.53  |proj g|=        1.1321
At iterate     4  f =       -468.8  |proj g|=        0.9293
At iterate     5  f =      -468.96  |proj g|=       0.74646
At iterate     6  f =      -469.12  |proj g|=       0.51108
At iterate     7  f =      -469.15  |proj g|=       0.78167
At iterate     8  f =      -469.15  |proj g|=       0.78121
At iterate     9  f =      -469.15  |proj g|=       0.78124

iterations 9
function evaluations 12
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.781241
final function value -469.15

F = -469.15
final  value -469.149942 
converged
 
INFO  [09:16:18.417] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:16:18.508] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:16:18.537] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:16:24.437] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:16:30.685] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:16:36.974] [mlr3]  Finished benchmark 
INFO  [09:16:37.125] [bbotk] Result of batch 85: 
INFO  [09:16:37.127] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:16:37.127] [bbotk]              5.059231                 3.772018                       0.3873378 
INFO  [09:16:37.127] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:16:37.127] [bbotk]                     3920        0.686 -0.9558734         <NA>   0.9746917 
INFO  [09:16:37.127] [bbotk]                                 uhash 
INFO  [09:16:37.127] [bbotk]  cd2b2ae8-750b-46ff-8efe-cafc3ee4cb3f 
DEBUG [09:16:38.071] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.059558e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.033082e-05 0.001059558 
  - best initial criterion value(s) :  436.9411 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -436.94  |proj g|=        6.149
At iterate     1  f =      -446.92  |proj g|=        1.4377
At iterate     2  f =      -466.62  |proj g|=        2.4845
At iterate     3  f =      -469.07  |proj g|=        2.3219
At iterate     4  f =      -469.42  |proj g|=        2.2489
At iterate     5  f =      -470.48  |proj g|=        1.1976
At iterate     6  f =      -470.64  |proj g|=        1.4134
At iterate     7  f =      -470.65  |proj g|=        1.3421
At iterate     8  f =      -470.65  |proj g|=        1.3306
At iterate     9  f =      -470.65  |proj g|=        1.3305
At iterate    10  f =      -470.65  |proj g|=        1.3305

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.33046
final function value -470.648

F = -470.648
final  value -470.648222 
converged
 
INFO  [09:16:38.075] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:16:38.165] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:16:38.172] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:16:41.981] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:16:45.990] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:16:50.082] [mlr3]  Finished benchmark 
INFO  [09:16:50.204] [bbotk] Result of batch 86: 
INFO  [09:16:50.206] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:16:50.206] [bbotk]              3.951106                 5.645053                        0.214084 
INFO  [09:16:50.206] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:16:50.206] [bbotk]                     2647        0.684 -0.9584722         <NA>   0.9700621 
INFO  [09:16:50.206] [bbotk]                                 uhash 
INFO  [09:16:50.206] [bbotk]  1669b58a-356e-437f-ac1f-b6bbe8e4324f 
DEBUG [09:16:51.439] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.052423e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.025121e-05 0.001052423 
  - best initial criterion value(s) :  424.2303 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -424.23  |proj g|=       12.097
At iterate     1  f =      -442.11  |proj g|=        7.5625
At iterate     2  f =         -447  |proj g|=        8.2315
At iterate     3  f =      -449.13  |proj g|=        7.3472
At iterate     4  f =      -452.54  |proj g|=        4.1204
At iterate     5  f =      -452.72  |proj g|=        4.4398
At iterate     6  f =       -452.9  |proj g|=        4.7156
At iterate     7  f =      -452.99  |proj g|=        4.6768
At iterate     8  f =      -453.04  |proj g|=        4.4522
At iterate     9  f =      -453.05  |proj g|=        4.4981
At iterate    10  f =      -453.05  |proj g|=        4.4617
At iterate    11  f =      -463.67  |proj g|=        3.2682
At iterate    12  f =      -468.73  |proj g|=        2.9361
At iterate    13  f =      -474.21  |proj g|=        2.4143
At iterate    14  f =      -475.66  |proj g|=        2.1236
At iterate    15  f =      -475.99  |proj g|=        2.4197
At iterate    16  f =      -476.09  |proj g|=        2.2796
At iterate    17  f =      -476.11  |proj g|=        2.1988
At iterate    18  f =      -476.11  |proj g|=        2.2093
At iterate    19  f =      -476.11  |proj g|=        2.2074
At iterate    20  f =      -476.11  |proj g|=        2.2115
At iterate    21  f =      -476.22  |proj g|=         2.203
At iterate    22  f =      -476.33  |proj g|=        2.1808
At iterate    23  f =      -476.33  |proj g|=        2.1792
At iterate    24  f =      -476.33  |proj g|=        2.1802
At iterate    25  f =      -476.33  |proj g|=        2.1793
At iterate    26  f =      -476.33  |proj g|=        2.1802
At iterate    27  f =      -476.33  |proj g|=        2.1795
At iterate    28  f =      -476.33  |proj g|=        2.1742
At iterate    29  f =      -476.34  |proj g|=        2.1642
At iterate    30  f =      -476.34  |proj g|=        2.1416
At iterate    31  f =      -476.35  |proj g|=        2.1131
At iterate    32  f =      -476.37  |proj g|=          2.08
At iterate    33  f =       -476.4  |proj g|=        2.0724
At iterate    34  f =      -476.42  |proj g|=        2.1598
At iterate    35  f =      -476.42  |proj g|=        2.1465
At iterate    36  f =      -476.42  |proj g|=        2.1456
At iterate    37  f =      -476.42  |proj g|=        2.1453
At iterate    38  f =      -476.42  |proj g|=         2.145
At iterate    39  f =      -476.42  |proj g|=        2.1444
At iterate    40  f =      -476.42  |proj g|=        2.1436
At iterate    41  f =      -476.42  |proj g|=        2.1425
At iterate    42  f =      -476.42  |proj g|=        2.1414
At iterate    43  f =      -476.42  |proj g|=        2.1404
At iterate    44  f =      -476.42  |proj g|=        2.1396
At iterate    45  f =      -476.43  |proj g|=        2.1377
At iterate    46  f =      -476.43  |proj g|=         2.161
At iterate    47  f =      -476.43  |proj g|=        2.1435
At iterate    48  f =      -476.45  |proj g|=        2.1101
At iterate    49  f =      -476.51  |proj g|=        2.0237
At iterate    50  f =      -476.65  |proj g|=        1.8778
At iterate    51  f =      -476.99  |proj g|=        1.5976
At iterate    52  f =       -477.7  |proj g|=        1.1711
At iterate    53  f =      -478.87  |proj g|=       0.71171
At iterate    54  f =      -478.95  |proj g|=         0.537
At iterate    55  f =       -480.7  |proj g|=       0.28857
At iterate    56  f =      -483.01  |proj g|=       0.24293
At iterate    57  f =      -483.01  |proj g|=       0.25692
At iterate    58  f =      -483.01  |proj g|=      0.041629
At iterate    59  f =      -483.01  |proj g|=      0.022134
At iterate    60  f =      -483.01  |proj g|=       0.02189

iterations 60
function evaluations 71
segments explored during Cauchy searches 62
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0218899
final function value -483.007

F = -483.007
final  value -483.006680 
converged
 
INFO  [09:16:51.444] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:16:51.534] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:16:51.542] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:16:56.437] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:17:01.367] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:17:09.576] [mlr3]  Finished benchmark 
INFO  [09:17:09.681] [bbotk] Result of batch 87: 
INFO  [09:17:09.683] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:17:09.683] [bbotk]              5.374789                 4.946771                       0.1257115 
INFO  [09:17:09.683] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:17:09.683] [bbotk]                     3135        0.726 -0.9518592         <NA>   0.9703651 
INFO  [09:17:09.683] [bbotk]                                 uhash 
INFO  [09:17:09.683] [bbotk]  f3fc6db1-e0ff-4719-90b4-200c4df767d6 
DEBUG [09:17:10.814] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.045631e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.014854e-05 0.001045631 
  - best initial criterion value(s) :  432.6756 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -432.68  |proj g|=       13.336
At iterate     1  f =      -447.04  |proj g|=        6.6507
At iterate     2  f =      -452.96  |proj g|=        5.2358
At iterate     3  f =      -457.83  |proj g|=        3.5191
At iterate     4  f =      -458.51  |proj g|=         3.005
At iterate     5  f =      -458.98  |proj g|=        2.5117
At iterate     6  f =      -459.09  |proj g|=        2.4495
At iterate     7  f =      -459.09  |proj g|=        2.4463
At iterate     8  f =      -459.09  |proj g|=        2.4442
At iterate     9  f =      -459.09  |proj g|=        2.4376
At iterate    10  f =      -459.09  |proj g|=        2.4285
At iterate    11  f =       -459.1  |proj g|=        2.4108
At iterate    12  f =       -459.1  |proj g|=        2.3798
At iterate    13  f =      -459.12  |proj g|=        2.3216
At iterate    14  f =      -459.16  |proj g|=        2.2214
At iterate    15  f =      -459.23  |proj g|=         2.093
At iterate    16  f =      -459.23  |proj g|=        2.1472
At iterate    17  f =      -459.27  |proj g|=        2.0292
At iterate    18  f =      -459.55  |proj g|=        1.7692
At iterate    19  f =      -460.39  |proj g|=        1.4755
At iterate    20  f =       -464.5  |proj g|=       0.91265
At iterate    21  f =      -469.92  |proj g|=       0.90456
At iterate    22  f =      -470.08  |proj g|=       0.90254
At iterate    23  f =      -472.21  |proj g|=        0.8945
At iterate    24  f =      -477.35  |proj g|=          1.15
At iterate    25  f =      -479.26  |proj g|=        1.7006
At iterate    26  f =      -480.11  |proj g|=        2.0973
At iterate    27  f =      -480.32  |proj g|=        2.3201
At iterate    28  f =      -480.39  |proj g|=        2.5163
At iterate    29  f =      -480.43  |proj g|=        2.6155
At iterate    30  f =      -480.43  |proj g|=        2.6539
At iterate    31  f =      -480.43  |proj g|=        2.6597
At iterate    32  f =      -480.43  |proj g|=          2.66

iterations 32
function evaluations 40
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.66
final function value -480.43

F = -480.43
final  value -480.430481 
converged
 
INFO  [09:17:10.819] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:17:10.912] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:17:10.920] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:17:19.388] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:17:25.716] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:17:32.023] [mlr3]  Finished benchmark 
INFO  [09:17:32.131] [bbotk] Result of batch 88: 
INFO  [09:17:32.134] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:17:32.134] [bbotk]              7.407039                 9.156517                       0.2270711 
INFO  [09:17:32.134] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:17:32.134] [bbotk]                     2835        0.731 -0.9584924         <NA>    0.972662 
INFO  [09:17:32.134] [bbotk]                                 uhash 
INFO  [09:17:32.134] [bbotk]  84477fcc-0674-4ce4-8368-2205f097d952 
DEBUG [09:17:33.360] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.041311e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.012062e-05 0.001041311 
  - best initial criterion value(s) :  450.4953 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -450.5  |proj g|=       6.1855
At iterate     1  f =      -467.36  |proj g|=        2.2601
At iterate     2  f =      -471.97  |proj g|=        2.0391
At iterate     3  f =      -478.33  |proj g|=        1.1758
At iterate     4  f =      -479.05  |proj g|=        1.3073
At iterate     5  f =      -483.46  |proj g|=        1.5018
At iterate     6  f =      -486.58  |proj g|=        1.2268
At iterate     7  f =      -487.76  |proj g|=        1.1202
At iterate     8  f =      -488.21  |proj g|=        0.9439
At iterate     9  f =      -488.31  |proj g|=        1.0765
At iterate    10  f =      -488.32  |proj g|=        1.1101
At iterate    11  f =      -488.32  |proj g|=        1.1143
At iterate    12  f =      -488.33  |proj g|=         1.124
At iterate    13  f =      -488.33  |proj g|=        1.1191
At iterate    14  f =      -488.75  |proj g|=        1.0958
At iterate    15  f =      -489.51  |proj g|=        1.0911
At iterate    16  f =      -489.56  |proj g|=        1.1098
At iterate    17  f =      -489.57  |proj g|=        1.1249
At iterate    18  f =      -489.57  |proj g|=        1.1297
At iterate    19  f =      -489.57  |proj g|=         1.131
At iterate    20  f =      -489.57  |proj g|=        1.1309

iterations 20
function evaluations 28
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.13095
final function value -489.568

F = -489.568
final  value -489.567936 
converged
 
INFO  [09:17:33.364] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:17:33.897] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:17:33.904] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:17:34.987] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:17:36.012] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:17:36.964] [mlr3]  Finished benchmark 
INFO  [09:17:37.063] [bbotk] Result of batch 89: 
INFO  [09:17:37.064] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:17:37.064] [bbotk]              9.744848                 6.608469                      0.03864298 
INFO  [09:17:37.064] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:17:37.064] [bbotk]                      229        0.893 -0.9529024         <NA>   0.9146231 
INFO  [09:17:37.064] [bbotk]                                 uhash 
INFO  [09:17:37.064] [bbotk]  a20519a3-4e23-4855-87c2-423099739b31 
DEBUG [09:17:38.023] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.247181e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.247181e-05 0.001316395 
  - best initial criterion value(s) :  466.5164 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -466.52  |proj g|=       3.1039
At iterate     1  f =      -469.33  |proj g|=        2.4347
At iterate     2  f =      -470.94  |proj g|=        3.3023
At iterate     3  f =       -471.1  |proj g|=        3.4086
At iterate     4  f =      -471.16  |proj g|=        3.4951
At iterate     5  f =      -471.16  |proj g|=        3.5205
At iterate     6  f =      -471.16  |proj g|=        3.5266
At iterate     7  f =      -471.16  |proj g|=        3.5279
At iterate     8  f =      -471.16  |proj g|=        3.5283

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.52828
final function value -471.162

F = -471.162
final  value -471.161655 
converged
 
INFO  [09:17:38.027] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:17:38.115] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:17:38.122] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:17:48.093] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:17:58.607] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:18:10.411] [mlr3]  Finished benchmark 
INFO  [09:18:10.530] [bbotk] Result of batch 90: 
INFO  [09:18:10.532] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:18:10.532] [bbotk]              7.997839                 2.381905                       0.3186981 
INFO  [09:18:10.532] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:18:10.532] [bbotk]                     4160         0.71 -0.9607819         <NA>   0.9740372 
INFO  [09:18:10.532] [bbotk]                                 uhash 
INFO  [09:18:10.532] [bbotk]  7209d221-3376-4507-91a8-c92beca28a44 
DEBUG [09:18:11.513] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.243614e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.243614e-05 0.001313555 
  - best initial criterion value(s) :  426.9768 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -426.98  |proj g|=       3.6509
At iterate     1  f =      -466.27  |proj g|=        1.2462
At iterate     2  f =       -468.9  |proj g|=        2.5427
At iterate     3  f =       -475.4  |proj g|=        2.0685
At iterate     4  f =         -477  |proj g|=        1.3427
At iterate     5  f =       -480.3  |proj g|=        1.2033
At iterate     6  f =      -482.14  |proj g|=       0.80909
At iterate     7  f =      -482.22  |proj g|=       0.31563
At iterate     8  f =      -482.22  |proj g|=       0.81479
At iterate     9  f =      -482.22  |proj g|=        0.4515
At iterate    10  f =      -482.22  |proj g|=       0.56971

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.569706
final function value -482.219

F = -482.219
final  value -482.219372 
converged
 
INFO  [09:18:11.517] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:18:11.604] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:18:11.611] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:18:15.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:18:18.940] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:18:22.418] [mlr3]  Finished benchmark 
INFO  [09:18:22.518] [bbotk] Result of batch 91: 
INFO  [09:18:22.519] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:18:22.519] [bbotk]              5.097732                 5.751896                       0.1803997 
INFO  [09:18:22.519] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [09:18:22.519] [bbotk]                     1490        0.713 -0.958053         <NA>   0.9679412 
INFO  [09:18:22.519] [bbotk]                                 uhash 
INFO  [09:18:22.519] [bbotk]  897758d3-dded-4cd3-8bac-86bc97d88ebe 
DEBUG [09:18:23.590] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.234034e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.234034e-05 0.001301773 
  - best initial criterion value(s) :  433.3572 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -433.36  |proj g|=        4.515
At iterate     1  f =      -459.42  |proj g|=        7.0763
At iterate     2  f =       -461.4  |proj g|=        7.1394
At iterate     3  f =       -468.7  |proj g|=        5.9647
At iterate     4  f =       -470.1  |proj g|=        4.3809
At iterate     5  f =      -471.66  |proj g|=        4.4997
At iterate     6  f =      -472.51  |proj g|=        3.7849
At iterate     7  f =      -472.56  |proj g|=        3.5526
At iterate     8  f =      -472.56  |proj g|=        3.5901
At iterate     9  f =      -472.56  |proj g|=        3.5874
At iterate    10  f =      -472.56  |proj g|=        3.5853
At iterate    11  f =      -472.56  |proj g|=        3.5807
At iterate    12  f =      -472.56  |proj g|=        3.5732
At iterate    13  f =      -472.56  |proj g|=        3.5612
At iterate    14  f =      -472.56  |proj g|=        3.5411
At iterate    15  f =      -472.56  |proj g|=        3.5131
At iterate    16  f =      -472.57  |proj g|=        3.4683
At iterate    17  f =      -472.59  |proj g|=         3.413
At iterate    18  f =      -472.63  |proj g|=        3.2327
At iterate    19  f =      -472.72  |proj g|=        3.1617
At iterate    20  f =      -473.27  |proj g|=        2.8179
At iterate    21  f =      -474.34  |proj g|=        2.3216
At iterate    22  f =      -475.67  |proj g|=        1.7911
At iterate    23  f =      -476.32  |proj g|=        1.6532
At iterate    24  f =      -476.34  |proj g|=        1.6146
At iterate    25  f =      -476.62  |proj g|=        1.6483
At iterate    26  f =      -476.67  |proj g|=        1.6198
At iterate    27  f =      -476.73  |proj g|=        1.5967
At iterate    28  f =      -476.73  |proj g|=        1.5943
At iterate    29  f =      -476.73  |proj g|=        1.5946
At iterate    30  f =      -476.73  |proj g|=        1.5951

iterations 30
function evaluations 37
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.59508
final function value -476.734

F = -476.734
final  value -476.734294 
converged
 
INFO  [09:18:23.594] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:18:23.697] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:18:23.704] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:18:27.231] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:18:30.503] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:18:33.734] [mlr3]  Finished benchmark 
INFO  [09:18:33.862] [bbotk] Result of batch 92: 
INFO  [09:18:33.865] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:18:33.865] [bbotk]              4.479351                 9.043192                      0.08634107 
INFO  [09:18:33.865] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:18:33.865] [bbotk]                     1564        0.724 -0.9618937         <NA>   0.9600703 
INFO  [09:18:33.865] [bbotk]                                 uhash 
INFO  [09:18:33.865] [bbotk]  4f51b9fa-04bf-49fa-9b00-70e35394911a 
DEBUG [09:18:34.936] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.225933e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.225933e-05 0.001291463 
  - best initial criterion value(s) :  429.902 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -429.9  |proj g|=       5.3204
At iterate     1  f =      -445.82  |proj g|=        8.9586
At iterate     2  f =      -446.22  |proj g|=        8.8981
At iterate     3  f =      -447.08  |proj g|=        7.5923
At iterate     4  f =      -447.34  |proj g|=        7.7108
At iterate     5  f =      -447.48  |proj g|=        7.3746
At iterate     6  f =      -447.52  |proj g|=        7.1373
At iterate     7  f =      -447.56  |proj g|=        6.9225
At iterate     8  f =      -447.57  |proj g|=        6.8815
At iterate     9  f =      -447.75  |proj g|=        6.6245
At iterate    10  f =      -448.86  |proj g|=        6.1368
At iterate    11  f =      -453.69  |proj g|=         4.629
At iterate    12  f =      -456.69  |proj g|=        2.9852
At iterate    13  f =      -464.94  |proj g|=        2.2869
At iterate    14  f =      -471.57  |proj g|=        2.9331
At iterate    15  f =      -476.33  |proj g|=        3.9583
At iterate    16  f =      -480.55  |proj g|=         2.324
At iterate    17  f =      -481.75  |proj g|=        2.3956
At iterate    18  f =      -482.45  |proj g|=        2.9463
At iterate    19  f =      -483.03  |proj g|=         2.938
At iterate    20  f =      -483.18  |proj g|=        3.3702
At iterate    21  f =      -483.22  |proj g|=        3.3088
At iterate    22  f =      -483.22  |proj g|=        3.3231
At iterate    23  f =      -483.22  |proj g|=        3.3362
At iterate    24  f =      -483.22  |proj g|=        3.3408
At iterate    25  f =      -483.22  |proj g|=        3.3407

iterations 25
function evaluations 30
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.34075
final function value -483.222

F = -483.222
final  value -483.221956 
converged
 
INFO  [09:18:34.940] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:18:35.027] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:18:35.034] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:18:40.962] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:18:45.740] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:18:50.922] [mlr3]  Finished benchmark 
INFO  [09:18:51.022] [bbotk] Result of batch 93: 
INFO  [09:18:51.024] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:18:51.024] [bbotk]              6.346433                  8.67941                      0.06616352 
INFO  [09:18:51.024] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:18:51.024] [bbotk]                     2451        0.723 -0.9557302         <NA>     0.96465 
INFO  [09:18:51.024] [bbotk]                                 uhash 
INFO  [09:18:51.024] [bbotk]  d7b6686f-286b-43d7-8303-d0684f3cb377 
DEBUG [09:18:52.271] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.215976e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.215976e-05 0.001283491 
  - best initial criterion value(s) :  412.8026 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -412.8  |proj g|=       2.8592
At iterate     1  f =      -463.92  |proj g|=        2.3553
At iterate     2  f =      -471.76  |proj g|=        7.9388
At iterate     3  f =       -474.1  |proj g|=        7.2552
At iterate     4  f =      -474.74  |proj g|=         6.363
At iterate     5  f =      -474.94  |proj g|=        6.3696
At iterate     6  f =      -476.35  |proj g|=        5.3042
At iterate     7  f =      -476.39  |proj g|=        4.7004
At iterate     8  f =      -476.46  |proj g|=        5.2167
At iterate     9  f =      -476.47  |proj g|=        5.1272
At iterate    10  f =      -476.47  |proj g|=         5.105
At iterate    11  f =      -476.47  |proj g|=        5.1007
At iterate    12  f =      -476.47  |proj g|=        5.0893
At iterate    13  f =      -476.47  |proj g|=        5.0744
At iterate    14  f =      -476.47  |proj g|=        5.0472
At iterate    15  f =      -476.47  |proj g|=        5.0031
At iterate    16  f =      -476.48  |proj g|=        4.9311
At iterate    17  f =       -476.5  |proj g|=         4.827
At iterate    18  f =      -476.54  |proj g|=        4.7282
At iterate    19  f =      -476.55  |proj g|=        4.6473
At iterate    20  f =      -476.61  |proj g|=        4.5413
At iterate    21  f =      -489.38  |proj g|=        1.7523
At iterate    22  f =      -492.04  |proj g|=         2.421
At iterate    23  f =      -492.94  |proj g|=        3.2113
At iterate    24  f =      -492.95  |proj g|=        3.1879
At iterate    25  f =      -492.99  |proj g|=        3.1276
At iterate    26  f =      -493.01  |proj g|=        3.0479
At iterate    27  f =      -493.01  |proj g|=        3.0464
At iterate    28  f =      -493.01  |proj g|=        3.0492
At iterate    29  f =      -493.01  |proj g|=        3.0518
At iterate    30  f =      -493.01  |proj g|=        3.0535
At iterate    31  f =      -493.01  |proj g|=        3.0539
At iterate    32  f =      -493.01  |proj g|=        3.0548
At iterate    33  f =      -493.01  |proj g|=        3.0555
At iterate    34  f =      -493.01  |proj g|=         3.056
At iterate    35  f =      -493.01  |proj g|=        3.0555
At iterate    36  f =      -493.01  |proj g|=        3.0539
At iterate    37  f =      -493.01  |proj g|=        3.0519
At iterate    38  f =      -493.01  |proj g|=        3.0509
At iterate    39  f =      -493.01  |proj g|=        3.0506
At iterate    40  f =      -493.01  |proj g|=        3.0503
At iterate    41  f =      -493.01  |proj g|=        3.0503
At iterate    42  f =      -493.01  |proj g|=        3.0507
At iterate    43  f =      -493.01  |proj g|=        3.0518
At iterate    44  f =      -493.01  |proj g|=        3.0548
At iterate    45  f =      -493.01  |proj g|=        3.0572
At iterate    46  f =      -493.01  |proj g|=        3.0591
At iterate    47  f =      -493.01  |proj g|=        3.0594
At iterate    48  f =      -493.01  |proj g|=        3.0591
At iterate    49  f =      -494.59  |proj g|=         2.476
At iterate    50  f =      -499.84  |proj g|=        1.1008
At iterate    51  f =      -502.68  |proj g|=       0.83987
At iterate    52  f =      -503.63  |proj g|=       0.74936
At iterate    53  f =      -503.68  |proj g|=       0.74679
At iterate    54  f =       -503.7  |proj g|=       0.23598
At iterate    55  f =       -503.7  |proj g|=       0.23599
At iterate    56  f =      -503.71  |proj g|=       0.23534
At iterate    57  f =      -503.71  |proj g|=       0.23496
At iterate    58  f =      -503.71  |proj g|=      0.020068
At iterate    59  f =      -503.71  |proj g|=     0.0028533

iterations 59
function evaluations 67
segments explored during Cauchy searches 61
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00285334
final function value -503.708

F = -503.708
final  value -503.708335 
converged
 
INFO  [09:18:52.275] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:18:52.387] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:18:52.395] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:18:59.190] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:19:10.300] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:19:16.673] [mlr3]  Finished benchmark 
INFO  [09:19:16.775] [bbotk] Result of batch 94: 
INFO  [09:19:16.777] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:19:16.777] [bbotk]              9.187959                 6.406377                       0.4126648 
INFO  [09:19:16.777] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [09:19:16.777] [bbotk]                     3012        0.716 -0.942548         <NA>    0.971079 
INFO  [09:19:16.777] [bbotk]                                 uhash 
INFO  [09:19:16.777] [bbotk]  0f28c2f5-92ee-4ce4-8e9a-580e41860e35 
DEBUG [09:19:17.937] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.209122e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.209122e-05 0.001277646 
  - best initial criterion value(s) :  457.9529 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -457.95  |proj g|=       5.0963
At iterate     1  f =      -476.73  |proj g|=        3.2123
At iterate     2  f =      -477.65  |proj g|=         3.086
At iterate     3  f =         -479  |proj g|=        2.7151
At iterate     4  f =      -479.15  |proj g|=         2.519
At iterate     5  f =      -479.44  |proj g|=        2.6512
At iterate     6  f =      -480.28  |proj g|=        2.7962
At iterate     7  f =      -482.01  |proj g|=        2.9303
At iterate     8  f =      -482.86  |proj g|=        2.7821
At iterate     9  f =      -482.92  |proj g|=        2.7536
At iterate    10  f =      -482.93  |proj g|=        2.7718
At iterate    11  f =      -482.93  |proj g|=        2.8186
At iterate    12  f =      -482.93  |proj g|=        2.8003
At iterate    13  f =      -482.93  |proj g|=        2.7999
At iterate    14  f =      -482.93  |proj g|=        2.7992
At iterate    15  f =      -482.93  |proj g|=        2.7979
At iterate    16  f =      -482.93  |proj g|=        2.7961
At iterate    17  f =      -482.93  |proj g|=        2.7935
At iterate    18  f =      -482.94  |proj g|=        2.7896
At iterate    19  f =      -482.94  |proj g|=        2.7858
At iterate    20  f =      -482.94  |proj g|=        2.7782
At iterate    21  f =      -482.95  |proj g|=         2.784
At iterate    22  f =      -482.96  |proj g|=        2.7534
At iterate    23  f =      -482.98  |proj g|=        2.7584
At iterate    24  f =       -484.4  |proj g|=        2.7434
At iterate    25  f =      -486.02  |proj g|=        2.6078
At iterate    26  f =      -486.05  |proj g|=        2.6818
At iterate    27  f =      -486.08  |proj g|=        2.6161
At iterate    28  f =      -486.08  |proj g|=         2.624
At iterate    29  f =      -486.08  |proj g|=         2.618
At iterate    30  f =      -486.08  |proj g|=        2.6205
At iterate    31  f =      -486.08  |proj g|=        2.6205

iterations 31
function evaluations 40
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.62055
final function value -486.079

F = -486.079
final  value -486.079194 
converged
 
INFO  [09:19:17.942] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:19:18.028] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:19:18.035] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:19:21.903] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:19:25.487] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:19:30.742] [mlr3]  Finished benchmark 
INFO  [09:19:30.843] [bbotk] Result of batch 95: 
INFO  [09:19:30.845] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:19:30.845] [bbotk]              4.278869                  2.29211                       0.1391721 
INFO  [09:19:30.845] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:19:30.845] [bbotk]                     1726        0.737 -0.9620905         <NA>   0.9657266 
INFO  [09:19:30.845] [bbotk]                                 uhash 
INFO  [09:19:30.845] [bbotk]  95a42a66-3b0f-4650-a785-1a4dbc0a81bb 
DEBUG [09:19:32.289] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.199485e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.199485e-05 0.001268278 
  - best initial criterion value(s) :  457.3999 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -457.4  |proj g|=       3.8164
At iterate     1  f =      -472.12  |proj g|=        2.7636
At iterate     2  f =       -472.4  |proj g|=        2.5161
At iterate     3  f =      -473.17  |proj g|=         2.191
At iterate     4  f =      -473.77  |proj g|=        2.1417
At iterate     5  f =      -479.55  |proj g|=        1.7485
At iterate     6  f =      -487.34  |proj g|=        1.3753
At iterate     7  f =         -490  |proj g|=        3.4334
At iterate     8  f =      -497.22  |proj g|=        3.4925
At iterate     9  f =      -497.77  |proj g|=        3.5639
At iterate    10  f =      -497.92  |proj g|=        3.6781
At iterate    11  f =      -497.96  |proj g|=        3.7803
At iterate    12  f =      -497.99  |proj g|=         3.907
At iterate    13  f =         -498  |proj g|=        3.9705
At iterate    14  f =         -498  |proj g|=        3.9783
At iterate    15  f =         -498  |proj g|=        3.9798
At iterate    16  f =         -498  |proj g|=        3.9887
At iterate    17  f =         -498  |proj g|=        3.9993
At iterate    18  f =      -498.01  |proj g|=        4.0184
At iterate    19  f =      -498.01  |proj g|=        4.0467
At iterate    20  f =      -498.02  |proj g|=        4.0868
At iterate    21  f =      -498.04  |proj g|=        4.1644
At iterate    22  f =       -498.1  |proj g|=        4.2209
At iterate    23  f =      -498.11  |proj g|=        4.2988
At iterate    24  f =      -498.24  |proj g|=        4.3135
At iterate    25  f =      -498.71  |proj g|=        4.0989
At iterate    26  f =      -499.06  |proj g|=        3.6528
At iterate    27  f =      -499.07  |proj g|=        3.5458
At iterate    28  f =      -499.07  |proj g|=        3.5561
At iterate    29  f =      -499.07  |proj g|=        3.5546
At iterate    30  f =      -499.07  |proj g|=         3.554
At iterate    31  f =      -499.07  |proj g|=        3.5487
At iterate    32  f =      -499.08  |proj g|=        3.5348
At iterate    33  f =      -499.08  |proj g|=        3.5135
At iterate    34  f =      -499.09  |proj g|=        3.4768
At iterate    35  f =       -499.1  |proj g|=        3.4173
At iterate    36  f =      -499.11  |proj g|=        3.4304
At iterate    37  f =      -499.13  |proj g|=        3.3953
At iterate    38  f =      -499.14  |proj g|=        3.4204
At iterate    39  f =      -499.14  |proj g|=         3.456
At iterate    40  f =      -499.14  |proj g|=        3.4593
At iterate    41  f =      -499.15  |proj g|=        3.4504
At iterate    42  f =      -499.17  |proj g|=        3.4198
At iterate    43  f =      -499.23  |proj g|=        3.3785
At iterate    44  f =      -499.38  |proj g|=        3.2787
At iterate    45  f =      -499.75  |proj g|=        3.1752
At iterate    46  f =      -500.47  |proj g|=        2.9356
At iterate    47  f =      -501.88  |proj g|=        2.5305
At iterate    48  f =      -503.18  |proj g|=        2.7582
At iterate    49  f =      -504.61  |proj g|=        2.5985
At iterate    50  f =      -507.67  |proj g|=           2.1
At iterate    51  f =      -507.74  |proj g|=        2.1881
At iterate    52  f =      -507.76  |proj g|=        2.2882
At iterate    53  f =      -510.77  |proj g|=        1.6746
At iterate    54  f =      -515.33  |proj g|=       0.74429
At iterate    55  f =      -515.84  |proj g|=       0.24374
At iterate    56  f =      -515.85  |proj g|=       0.24045
At iterate    57  f =      -515.85  |proj g|=       0.10392
At iterate    58  f =      -515.85  |proj g|=       0.10345
At iterate    59  f =      -515.85  |proj g|=       0.55418
At iterate    60  f =      -515.85  |proj g|=       0.73898
At iterate    61  f =      -515.85  |proj g|=       0.73933
At iterate    62  f =      -515.86  |proj g|=       0.73971
At iterate    63  f =      -515.86  |proj g|=       0.73998
At iterate    64  f =      -515.87  |proj g|=       0.73963
At iterate    65  f =      -515.87  |proj g|=       0.73845
At iterate    66  f =      -515.87  |proj g|=       0.73728
At iterate    67  f =      -515.87  |proj g|=      0.064875
At iterate    68  f =      -515.87  |proj g|=     0.0079014
At iterate    69  f =      -515.87  |proj g|=     0.0022732

iterations 69
function evaluations 80
segments explored during Cauchy searches 72
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00227316
final function value -515.873

F = -515.873
final  value -515.873397 
converged
 
INFO  [09:19:32.293] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:19:32.379] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:19:32.387] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:19:34.301] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:19:36.871] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:19:38.560] [mlr3]  Finished benchmark 
INFO  [09:19:38.663] [bbotk] Result of batch 96: 
INFO  [09:19:38.665] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:19:38.665] [bbotk]              8.324284                 3.777619                        0.135615 
INFO  [09:19:38.665] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:19:38.665] [bbotk]                      708        0.708 -0.9420956         <NA>   0.9595977 
INFO  [09:19:38.665] [bbotk]                                 uhash 
INFO  [09:19:38.665] [bbotk]  7d4a5f5c-848f-43f0-8ef9-6529991f6eb5 
DEBUG [09:19:39.902] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.192313e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.192313e-05 0.001262813 
  - best initial criterion value(s) :  468.1949 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -468.19  |proj g|=       5.9691
At iterate     1  f =      -487.36  |proj g|=        2.3293
At iterate     2  f =      -495.01  |proj g|=        6.0898
At iterate     3  f =      -495.28  |proj g|=        5.7094
At iterate     4  f =      -495.32  |proj g|=        5.5208
At iterate     5  f =      -495.32  |proj g|=        5.5262
At iterate     6  f =      -495.32  |proj g|=        5.5342
At iterate     7  f =      -495.32  |proj g|=        5.5271
At iterate     8  f =      -495.32  |proj g|=        5.5201
At iterate     9  f =      -495.32  |proj g|=         5.512
At iterate    10  f =      -495.32  |proj g|=        5.4972
At iterate    11  f =      -495.33  |proj g|=        5.4734
At iterate    12  f =      -495.35  |proj g|=        5.4398
At iterate    13  f =      -495.39  |proj g|=        5.4075
At iterate    14  f =      -495.48  |proj g|=        5.4091
At iterate    15  f =      -495.62  |proj g|=        5.0901
At iterate    16  f =      -496.01  |proj g|=        5.0073
At iterate    17  f =      -497.85  |proj g|=        2.7954
At iterate    18  f =      -504.71  |proj g|=        2.3269
At iterate    19  f =      -508.51  |proj g|=        2.3937
At iterate    20  f =      -509.92  |proj g|=        2.8204
At iterate    21  f =      -510.04  |proj g|=        2.9488
At iterate    22  f =      -510.38  |proj g|=         3.169
At iterate    23  f =      -510.48  |proj g|=        2.8612
At iterate    24  f =      -510.56  |proj g|=        2.9808
At iterate    25  f =      -510.56  |proj g|=        2.9858
At iterate    26  f =      -510.57  |proj g|=        3.0212
At iterate    27  f =      -510.57  |proj g|=         3.019
At iterate    28  f =      -510.57  |proj g|=        3.0201
At iterate    29  f =      -510.57  |proj g|=        3.0205
At iterate    30  f =      -510.57  |proj g|=        3.0223
At iterate    31  f =      -510.57  |proj g|=        3.0246
At iterate    32  f =      -510.57  |proj g|=        3.0329
At iterate    33  f =      -510.57  |proj g|=         3.032
At iterate    34  f =      -510.57  |proj g|=        3.0308
At iterate    35  f =      -510.57  |proj g|=        3.0337
At iterate    36  f =      -510.57  |proj g|=        3.0106
At iterate    37  f =      -510.57  |proj g|=         2.994
At iterate    38  f =      -510.57  |proj g|=        2.9998
At iterate    39  f =      -510.58  |proj g|=        2.9785
At iterate    40  f =      -510.58  |proj g|=        2.9597
At iterate    41  f =      -510.63  |proj g|=        2.8908
At iterate    42  f =      -510.72  |proj g|=        2.8025
At iterate    43  f =       -510.9  |proj g|=        2.7094
At iterate    44  f =      -511.13  |proj g|=        2.0852
At iterate    45  f =       -512.1  |proj g|=        2.0007
At iterate    46  f =      -514.45  |proj g|=        1.6084
At iterate    47  f =      -518.57  |proj g|=       0.83773
At iterate    48  f =      -521.93  |proj g|=       0.74767
At iterate    49  f =      -522.38  |proj g|=       0.24624
At iterate    50  f =      -522.43  |proj g|=       0.72785
At iterate    51  f =       -522.5  |proj g|=       0.25024
At iterate    52  f =       -522.5  |proj g|=      0.048404
At iterate    53  f =       -522.5  |proj g|=     0.0013539

iterations 53
function evaluations 64
segments explored during Cauchy searches 57
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0013539
final function value -522.499

F = -522.499
final  value -522.499287 
converged
 
INFO  [09:19:39.906] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:19:40.035] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:19:40.043] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:19:49.726] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:19:57.466] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:20:04.493] [mlr3]  Finished benchmark 
INFO  [09:20:04.595] [bbotk] Result of batch 97: 
INFO  [09:20:04.597] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:20:04.597] [bbotk]              9.310445                 2.741847                       0.1998146 
INFO  [09:20:04.597] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:20:04.597] [bbotk]                     4335        0.724 -0.9431165         <NA>   0.9708809 
INFO  [09:20:04.597] [bbotk]                                 uhash 
INFO  [09:20:04.597] [bbotk]  4edcdb70-a21a-4fdf-a805-53b2e5d7ec54 
DEBUG [09:20:05.913] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.185613e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.185613e-05 0.001258645 
  - best initial criterion value(s) :  491.3245 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -491.32  |proj g|=       1.6917
At iterate     1  f =      -494.84  |proj g|=        4.0013
At iterate     2  f =      -495.37  |proj g|=        3.7353
At iterate     3  f =      -495.54  |proj g|=        3.3134
At iterate     4  f =      -495.56  |proj g|=        3.4453
At iterate     5  f =      -495.56  |proj g|=        3.4288
At iterate     6  f =      -495.56  |proj g|=        3.4245
At iterate     7  f =      -495.56  |proj g|=        3.4032
At iterate     8  f =      -495.56  |proj g|=        3.3746
At iterate     9  f =      -495.57  |proj g|=        3.3324
At iterate    10  f =      -495.57  |proj g|=        3.3085
At iterate    11  f =      -495.57  |proj g|=        3.3145
At iterate    12  f =      -495.57  |proj g|=        3.3217
At iterate    13  f =      -495.57  |proj g|=         3.323
At iterate    14  f =      -495.57  |proj g|=        3.3235
At iterate    15  f =      -495.57  |proj g|=        3.3273
At iterate    16  f =      -495.57  |proj g|=        3.3315
At iterate    17  f =      -495.57  |proj g|=        3.3393
At iterate    18  f =      -495.57  |proj g|=        3.3513
At iterate    19  f =      -495.57  |proj g|=        3.3716
At iterate    20  f =      -495.58  |proj g|=        3.4012
At iterate    21  f =      -495.58  |proj g|=        3.4428
At iterate    22  f =      -495.59  |proj g|=        3.4969
At iterate    23  f =      -495.62  |proj g|=        3.6118
At iterate    24  f =      -495.68  |proj g|=        3.6636
At iterate    25  f =      -495.77  |proj g|=        3.8878
At iterate    26  f =      -496.08  |proj g|=        3.8515
At iterate    27  f =      -497.05  |proj g|=        3.4708
At iterate    28  f =       -498.4  |proj g|=           2.7
At iterate    29  f =      -500.21  |proj g|=        1.6562
At iterate    30  f =      -502.16  |proj g|=       0.67569
At iterate    31  f =      -502.21  |proj g|=       0.54049
At iterate    32  f =      -503.23  |proj g|=       0.70779
At iterate    33  f =      -503.32  |proj g|=       0.79082
At iterate    34  f =      -503.33  |proj g|=       0.78913
At iterate    35  f =      -503.33  |proj g|=       0.79588
At iterate    36  f =      -503.33  |proj g|=        0.7954
At iterate    37  f =      -503.33  |proj g|=       0.79541

iterations 37
function evaluations 45
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.795406
final function value -503.332

F = -503.332
final  value -503.332147 
converged
 
INFO  [09:20:05.918] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:20:06.159] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:20:06.166] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:20:09.273] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:20:12.483] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:20:15.543] [mlr3]  Finished benchmark 
INFO  [09:20:15.648] [bbotk] Result of batch 98: 
INFO  [09:20:15.650] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:20:15.650] [bbotk]               4.42583                 8.439385                      0.04720236 
INFO  [09:20:15.650] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:20:15.650] [bbotk]                     1928        0.846 -0.9610364         <NA>   0.9547638 
INFO  [09:20:15.650] [bbotk]                                 uhash 
INFO  [09:20:15.650] [bbotk]  fc430a11-ad41-46da-aa1d-c14cfbb3e55b 
DEBUG [09:20:16.769] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.18457e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.18457e-05 0.001255504 
  - best initial criterion value(s) :  484.9532 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -484.95  |proj g|=       5.2715
At iterate     1  f =      -503.09  |proj g|=        2.9868
At iterate     2  f =      -512.82  |proj g|=        4.6337
At iterate     3  f =      -513.26  |proj g|=        4.4378
At iterate     4  f =      -513.63  |proj g|=        4.0646
At iterate     5  f =      -513.64  |proj g|=        4.0213
At iterate     6  f =      -513.65  |proj g|=        4.0175
At iterate     7  f =      -513.65  |proj g|=        4.0401
At iterate     8  f =      -513.65  |proj g|=        4.0594
At iterate     9  f =      -513.65  |proj g|=        4.0597
At iterate    10  f =      -513.65  |proj g|=        4.0602
At iterate    11  f =      -513.65  |proj g|=         4.061
At iterate    12  f =      -513.65  |proj g|=        4.0621
At iterate    13  f =      -513.65  |proj g|=        4.0635
At iterate    14  f =      -513.65  |proj g|=        4.0645
At iterate    15  f =      -513.65  |proj g|=         4.064
At iterate    16  f =      -513.65  |proj g|=        4.0621
At iterate    17  f =      -513.66  |proj g|=        4.0508
At iterate    18  f =      -513.66  |proj g|=        4.0621
At iterate    19  f =      -513.66  |proj g|=        4.0453
At iterate    20  f =      -522.79  |proj g|=        1.4795
At iterate    21  f =      -524.12  |proj g|=        1.3163
At iterate    22  f =      -525.01  |proj g|=        1.4233
At iterate    23  f =       -525.9  |proj g|=        1.5735
At iterate    24  f =      -525.91  |proj g|=        1.4862
At iterate    25  f =      -525.92  |proj g|=        1.4882
At iterate    26  f =      -525.92  |proj g|=        1.4883

iterations 26
function evaluations 33
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.48826
final function value -525.925

F = -525.925
final  value -525.924966 
converged
 
INFO  [09:20:16.802] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:20:16.902] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:20:16.909] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:20:18.499] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:20:20.214] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:20:21.908] [mlr3]  Finished benchmark 
INFO  [09:20:22.043] [bbotk] Result of batch 99: 
INFO  [09:20:22.046] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:20:22.046] [bbotk]              3.146699                 2.946876                       0.4622421 
INFO  [09:20:22.046] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:20:22.046] [bbotk]                      867        0.734 -0.9564511         <NA>   0.9637053 
INFO  [09:20:22.046] [bbotk]                                 uhash 
INFO  [09:20:22.046] [bbotk]  f2407016-0a54-4cf3-bff6-dbda90e977f4 
DEBUG [09:20:23.272] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.175513e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.175513e-05 0.001246829 
  - best initial criterion value(s) :  469.4463 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -469.45  |proj g|=       11.401
At iterate     1  f =       -505.7  |proj g|=        3.4484
At iterate     2  f =      -506.09  |proj g|=        4.1977
At iterate     3  f =      -508.22  |proj g|=        4.7881
At iterate     4  f =      -508.25  |proj g|=        5.2086
At iterate     5  f =      -508.27  |proj g|=        5.1403
At iterate     6  f =      -508.27  |proj g|=        5.0558
At iterate     7  f =      -508.27  |proj g|=        5.0987
At iterate     8  f =      -508.27  |proj g|=        5.0986
At iterate     9  f =      -508.27  |proj g|=         5.098
At iterate    10  f =      -508.27  |proj g|=        5.0968
At iterate    11  f =      -508.28  |proj g|=        5.0956
At iterate    12  f =      -508.28  |proj g|=        5.0921
At iterate    13  f =       -508.3  |proj g|=        5.0925
At iterate    14  f =      -508.33  |proj g|=        5.1104
At iterate    15  f =      -508.42  |proj g|=        5.1754
At iterate    16  f =      -508.61  |proj g|=        5.2365
At iterate    17  f =      -509.07  |proj g|=        5.2998
At iterate    18  f =      -509.11  |proj g|=        5.0987
At iterate    19  f =      -510.17  |proj g|=        4.7963
At iterate    20  f =      -517.45  |proj g|=        3.2744
At iterate    21  f =      -519.25  |proj g|=        3.5681
At iterate    22  f =      -520.02  |proj g|=        3.5302
At iterate    23  f =      -520.76  |proj g|=        3.2464
At iterate    24  f =      -521.27  |proj g|=        3.2923
At iterate    25  f =      -521.45  |proj g|=        3.7904
At iterate    26  f =      -521.46  |proj g|=        3.7922
At iterate    27  f =      -521.47  |proj g|=        3.7894
At iterate    28  f =      -521.47  |proj g|=        3.7904
At iterate    29  f =      -521.47  |proj g|=        3.7906

iterations 29
function evaluations 35
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.7906
final function value -521.465

F = -521.465
final  value -521.465186 
converged
 
INFO  [09:20:23.277] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:20:23.375] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:20:23.382] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:20:25.973] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:20:28.843] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:20:31.425] [mlr3]  Finished benchmark 
INFO  [09:20:31.535] [bbotk] Result of batch 100: 
INFO  [09:20:31.537] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:20:31.537] [bbotk]              3.774722                  5.17572                       0.4130594 
INFO  [09:20:31.537] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:20:31.537] [bbotk]                     1620        0.784 -0.9605473         <NA>   0.9701633 
INFO  [09:20:31.537] [bbotk]                                 uhash 
INFO  [09:20:31.537] [bbotk]  96665fff-dd8c-45a5-a043-78ebfa7041dc 
DEBUG [09:20:32.823] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.168528e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.168528e-05 0.001234738 
  - best initial criterion value(s) :  490.4122 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -490.41  |proj g|=       5.8059
At iterate     1  f =      -508.66  |proj g|=        6.6968
At iterate     2  f =      -516.12  |proj g|=        5.7283
At iterate     3  f =      -526.15  |proj g|=        3.1777
At iterate     4  f =      -526.94  |proj g|=        1.7207
At iterate     5  f =      -527.81  |proj g|=        2.1098
At iterate     6  f =      -530.25  |proj g|=        2.2297
At iterate     7  f =      -534.56  |proj g|=        1.5085
At iterate     8  f =      -534.57  |proj g|=        2.0812
At iterate     9  f =      -537.03  |proj g|=        1.0996
At iterate    10  f =      -537.48  |proj g|=       0.74181
At iterate    11  f =      -537.58  |proj g|=       0.70078
At iterate    12  f =      -537.68  |proj g|=       0.72689
At iterate    13  f =      -537.71  |proj g|=       0.77163
At iterate    14  f =      -537.71  |proj g|=       0.78587
At iterate    15  f =      -537.71  |proj g|=         0.785
At iterate    16  f =      -537.71  |proj g|=       0.78822
At iterate    17  f =      -537.71  |proj g|=       0.78995
At iterate    18  f =      -537.72  |proj g|=       0.78964
At iterate    19  f =      -537.72  |proj g|=       0.78494
At iterate    20  f =      -537.74  |proj g|=       0.77938
At iterate    21  f =      -537.79  |proj g|=       0.75435
At iterate    22  f =       -537.8  |proj g|=        0.8069
At iterate    23  f =       -537.9  |proj g|=        0.7963
At iterate    24  f =      -539.22  |proj g|=       0.83012
At iterate    25  f =      -539.84  |proj g|=       0.78851
At iterate    26  f =      -541.26  |proj g|=       0.73923
At iterate    27  f =      -541.38  |proj g|=       0.73923
At iterate    28  f =      -541.39  |proj g|=       0.73923
At iterate    29  f =      -541.39  |proj g|=       0.73923
At iterate    30  f =      -541.39  |proj g|=       0.73919
At iterate    31  f =      -541.39  |proj g|=       0.73919
At iterate    32  f =      -541.39  |proj g|=        0.7383
At iterate    33  f =      -541.43  |proj g|=       0.68845
At iterate    34  f =      -541.44  |proj g|=       0.68801
At iterate    35  f =      -541.44  |proj g|=       0.68785
At iterate    36  f =      -541.44  |proj g|=       0.68785
At iterate    37  f =      -541.44  |proj g|=       0.68785
At iterate    38  f =      -541.44  |proj g|=       0.68785

iterations 38
function evaluations 46
segments explored during Cauchy searches 41
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.687853
final function value -541.443

F = -541.443
final  value -541.443082 
converged
 
INFO  [09:20:32.827] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:20:32.917] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:20:32.925] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:20:34.071] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:20:35.336] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:20:36.665] [mlr3]  Finished benchmark 
INFO  [09:20:36.799] [bbotk] Result of batch 101: 
INFO  [09:20:36.801] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:20:36.801] [bbotk]              7.158305                 2.087699                      0.09236835 
INFO  [09:20:36.801] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:20:36.801] [bbotk]                      514        0.839 -0.9460194         <NA>   0.9497903 
INFO  [09:20:36.801] [bbotk]                                 uhash 
INFO  [09:20:36.801] [bbotk]  a4010e2f-ad34-4edf-9c43-d8278b6fb99e 
DEBUG [09:20:38.161] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.17716e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.17716e-05 0.001251082 
  - best initial criterion value(s) :  485.3997 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -485.4  |proj g|=       11.685
At iterate     1  f =      -503.79  |proj g|=        6.8955
At iterate     2  f =      -506.39  |proj g|=         5.517
At iterate     3  f =      -509.27  |proj g|=        2.4552
At iterate     4  f =      -509.44  |proj g|=        2.7407
At iterate     5  f =      -509.47  |proj g|=        2.6251
At iterate     6  f =      -509.48  |proj g|=        2.6133
At iterate     7  f =      -509.48  |proj g|=        2.6254
At iterate     8  f =      -509.48  |proj g|=        2.6208
At iterate     9  f =      -509.48  |proj g|=        2.6182
At iterate    10  f =      -509.48  |proj g|=        2.6126
At iterate    11  f =      -509.48  |proj g|=        2.6041
At iterate    12  f =      -509.49  |proj g|=        2.5889
At iterate    13  f =       -509.5  |proj g|=        2.5652
At iterate    14  f =      -509.54  |proj g|=        2.5273
At iterate    15  f =      -509.63  |proj g|=        2.4746
At iterate    16  f =      -509.83  |proj g|=        2.4197
At iterate    17  f =      -510.27  |proj g|=        2.4175
At iterate    18  f =       -510.7  |proj g|=        2.5293
At iterate    19  f =      -510.84  |proj g|=        2.5859
At iterate    20  f =      -511.21  |proj g|=        2.6549
At iterate    21  f =       -512.3  |proj g|=        2.7333
At iterate    22  f =      -515.19  |proj g|=        3.1185
At iterate    23  f =      -524.88  |proj g|=        3.0425
At iterate    24  f =      -527.81  |proj g|=        3.1142
At iterate    25  f =      -535.34  |proj g|=        2.7981
At iterate    26  f =      -538.57  |proj g|=         2.225
At iterate    27  f =      -538.98  |proj g|=        2.0204
At iterate    28  f =      -539.13  |proj g|=        1.7954
At iterate    29  f =      -539.13  |proj g|=        1.7805
At iterate    30  f =      -539.13  |proj g|=          1.78

iterations 30
function evaluations 32
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.78002
final function value -539.133

F = -539.133
final  value -539.132722 
converged
 
INFO  [09:20:38.166] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:20:38.310] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:20:38.318] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:20:39.561] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:20:40.865] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:20:42.749] [mlr3]  Finished benchmark 
INFO  [09:20:42.872] [bbotk] Result of batch 102: 
INFO  [09:20:42.874] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:20:42.874] [bbotk]              5.461873                 5.019471                      0.05743076 
INFO  [09:20:42.874] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:20:42.874] [bbotk]                      577        0.803 -0.9435834         <NA>   0.9403414 
INFO  [09:20:42.874] [bbotk]                                 uhash 
INFO  [09:20:42.874] [bbotk]  7b352603-2e8b-4da0-9229-50fae01a9d6e 
DEBUG [09:20:44.133] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.213575e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.213575e-05 0.001303237 
  - best initial criterion value(s) :  496.3684 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -496.37  |proj g|=       2.6882
At iterate     1  f =       -516.3  |proj g|=       0.20684
At iterate     2  f =      -533.96  |proj g|=        4.8633
At iterate     3  f =      -534.74  |proj g|=        4.8047
At iterate     4  f =      -536.42  |proj g|=        4.5013
At iterate     5  f =      -536.67  |proj g|=        4.4522
At iterate     6  f =      -536.77  |proj g|=        4.8752
At iterate     7  f =      -536.79  |proj g|=         4.755
At iterate     8  f =      -536.79  |proj g|=        4.7272
At iterate     9  f =      -536.79  |proj g|=        4.7275
At iterate    10  f =      -536.79  |proj g|=        4.7308
At iterate    11  f =      -536.79  |proj g|=        4.7343
At iterate    12  f =      -536.79  |proj g|=        4.7448
At iterate    13  f =       -536.8  |proj g|=        4.7575
At iterate    14  f =       -536.8  |proj g|=        4.7739
At iterate    15  f =      -536.82  |proj g|=        4.7983
At iterate    16  f =      -536.86  |proj g|=        4.7813
At iterate    17  f =      -536.86  |proj g|=        4.8885
At iterate    18  f =      -536.95  |proj g|=        4.8234
At iterate    19  f =      -539.08  |proj g|=        4.1036
At iterate    20  f =      -544.19  |proj g|=        2.8336
At iterate    21  f =      -544.41  |proj g|=        2.8097
At iterate    22  f =      -544.46  |proj g|=        2.5762
At iterate    23  f =      -544.47  |proj g|=        2.5891
At iterate    24  f =      -544.47  |proj g|=        2.5892
At iterate    25  f =      -544.47  |proj g|=        2.5951
At iterate    26  f =      -544.47  |proj g|=        2.6079
At iterate    27  f =      -544.48  |proj g|=         2.628
At iterate    28  f =       -544.5  |proj g|=        2.6415
At iterate    29  f =      -544.56  |proj g|=        2.6946
At iterate    30  f =       -544.7  |proj g|=        2.7043
At iterate    31  f =      -545.13  |proj g|=         2.593
At iterate    32  f =      -546.03  |proj g|=        2.3579
At iterate    33  f =      -548.26  |proj g|=        1.5138
At iterate    34  f =       -550.3  |proj g|=        1.4034
At iterate    35  f =       -551.9  |proj g|=       0.63774
At iterate    36  f =      -552.54  |proj g|=       0.42839
At iterate    37  f =      -552.68  |proj g|=       0.30803
At iterate    38  f =      -552.92  |proj g|=       0.27006
At iterate    39  f =      -552.92  |proj g|=       0.26827
At iterate    40  f =      -552.92  |proj g|=     0.0046045
At iterate    41  f =      -552.92  |proj g|=    0.00045253

iterations 41
function evaluations 49
segments explored during Cauchy searches 45
BFGS updates skipped 0
active bounds at final generalized Cauchy point 3
norm of the final projected gradient 0.000452533
final function value -552.923

F = -552.923
final  value -552.923229 
converged
 
INFO  [09:20:44.137] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:20:44.223] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:20:44.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:20:46.756] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:20:49.374] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:20:52.115] [mlr3]  Finished benchmark 
INFO  [09:20:52.213] [bbotk] Result of batch 103: 
INFO  [09:20:52.215] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:20:52.215] [bbotk]              2.302823                  8.62279                       0.2430573 
INFO  [09:20:52.215] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:20:52.215] [bbotk]                     1578        0.772 -0.9433848         <NA>   0.9521032 
INFO  [09:20:52.215] [bbotk]                                 uhash 
INFO  [09:20:52.215] [bbotk]  9bb4b474-6124-4c24-a878-b65fe0adb0b5 
DEBUG [09:20:53.455] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.216314e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.216314e-05 0.001305614 
  - best initial criterion value(s) :  517.6047 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -517.6  |proj g|=       6.4901
At iterate     1  f =      -520.73  |proj g|=        4.8657
At iterate     2  f =      -523.74  |proj g|=        5.0099
At iterate     3  f =      -524.83  |proj g|=        4.7697
At iterate     4  f =      -525.32  |proj g|=        4.6326
At iterate     5  f =      -525.47  |proj g|=        4.6194
At iterate     6  f =      -525.51  |proj g|=        4.6627
At iterate     7  f =      -525.51  |proj g|=        4.7427
At iterate     8  f =      -525.51  |proj g|=        4.7213
At iterate     9  f =      -525.51  |proj g|=        4.7239
At iterate    10  f =      -525.52  |proj g|=        4.7345
At iterate    11  f =      -525.52  |proj g|=        4.7485
At iterate    12  f =      -525.52  |proj g|=        4.7716
At iterate    13  f =      -525.53  |proj g|=        4.8282
At iterate    14  f =      -525.55  |proj g|=        4.8409
At iterate    15  f =       -525.6  |proj g|=        4.9984
At iterate    16  f =      -526.07  |proj g|=        5.1797
At iterate    17  f =      -527.49  |proj g|=        5.0956
At iterate    18  f =      -531.84  |proj g|=        4.1693
At iterate    19  f =      -539.62  |proj g|=        3.0295
At iterate    20  f =      -545.93  |proj g|=       0.80569
At iterate    21  f =      -549.66  |proj g|=        1.2714
At iterate    22  f =      -550.64  |proj g|=        1.1988
At iterate    23  f =      -551.07  |proj g|=        1.0815
At iterate    24  f =      -551.17  |proj g|=       0.94923
At iterate    25  f =      -551.17  |proj g|=       0.94498
At iterate    26  f =      -551.17  |proj g|=       0.94548
At iterate    27  f =      -551.17  |proj g|=       0.94511
At iterate    28  f =      -551.17  |proj g|=       0.94531

iterations 28
function evaluations 33
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.945311
final function value -551.173

F = -551.173
final  value -551.172869 
converged
 
INFO  [09:20:53.459] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:20:53.548] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:20:53.572] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:20:56.514] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:20:59.738] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:21:02.866] [mlr3]  Finished benchmark 
INFO  [09:21:02.992] [bbotk] Result of batch 104: 
INFO  [09:21:02.993] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:21:02.993] [bbotk]              2.390969                 9.837377                        0.242106 
INFO  [09:21:02.993] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:21:02.993] [bbotk]                     1955        0.814 -0.9493571         <NA>   0.9554238 
INFO  [09:21:02.993] [bbotk]                                 uhash 
INFO  [09:21:02.993] [bbotk]  948d6eb8-fc11-48e7-8330-e2815a58025c 
DEBUG [09:21:04.515] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.213498e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.213498e-05 0.001301916 
  - best initial criterion value(s) :  476.3851 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -476.39  |proj g|=       4.2371
At iterate     1  f =      -527.46  |proj g|=        2.9482
At iterate     2  f =      -529.62  |proj g|=        3.8428
At iterate     3  f =      -547.05  |proj g|=         3.283
At iterate     4  f =      -551.36  |proj g|=        2.0269
At iterate     5  f =      -551.43  |proj g|=        2.1174
At iterate     6  f =      -551.56  |proj g|=        2.1435
At iterate     7  f =      -551.88  |proj g|=        1.9642
At iterate     8  f =      -551.95  |proj g|=        1.7838
At iterate     9  f =      -551.96  |proj g|=        1.7363
At iterate    10  f =      -551.96  |proj g|=        1.7432
At iterate    11  f =      -551.96  |proj g|=        1.7421
At iterate    12  f =      -551.96  |proj g|=        1.7415
At iterate    13  f =      -551.96  |proj g|=        1.7406
At iterate    14  f =      -551.96  |proj g|=        1.7392
At iterate    15  f =      -551.96  |proj g|=        1.7375
At iterate    16  f =      -551.96  |proj g|=        1.7362
At iterate    17  f =      -551.96  |proj g|=         1.735
At iterate    18  f =      -551.96  |proj g|=        1.7332
At iterate    19  f =      -551.96  |proj g|=        1.7335
At iterate    20  f =      -551.96  |proj g|=        1.7041
At iterate    21  f =      -551.97  |proj g|=        1.7192
At iterate    22  f =         -552  |proj g|=        1.7669
At iterate    23  f =      -552.06  |proj g|=        1.8238
At iterate    24  f =      -552.23  |proj g|=        1.9256
At iterate    25  f =       -552.6  |proj g|=        2.0653
At iterate    26  f =      -553.41  |proj g|=        2.2606
At iterate    27  f =      -554.66  |proj g|=        2.3542
At iterate    28  f =      -555.27  |proj g|=        2.3851
At iterate    29  f =      -555.58  |proj g|=        2.0911
At iterate    30  f =      -555.59  |proj g|=        2.0596
At iterate    31  f =       -555.6  |proj g|=        2.0593
At iterate    32  f =       -555.6  |proj g|=        2.0606
At iterate    33  f =       -555.6  |proj g|=        2.0588
At iterate    34  f =       -555.6  |proj g|=        2.0562
At iterate    35  f =       -555.6  |proj g|=        2.0511
At iterate    36  f =       -555.6  |proj g|=        2.0434
At iterate    37  f =       -555.6  |proj g|=        2.0302
At iterate    38  f =       -555.6  |proj g|=        2.0087
At iterate    39  f =      -555.61  |proj g|=        1.9731
At iterate    40  f =      -555.64  |proj g|=        1.9167
At iterate    41  f =      -555.69  |proj g|=        1.8442
At iterate    42  f =      -555.77  |proj g|=        1.8145
At iterate    43  f =      -555.78  |proj g|=        1.8663
At iterate    44  f =      -555.78  |proj g|=        1.8899
At iterate    45  f =      -555.78  |proj g|=        1.8997
At iterate    46  f =      -555.79  |proj g|=        1.9242
At iterate    47  f =       -555.8  |proj g|=        1.9605
At iterate    48  f =      -555.83  |proj g|=         2.013
At iterate    49  f =      -556.33  |proj g|=        1.8222
At iterate    50  f =      -556.79  |proj g|=        1.7288
At iterate    51  f =      -556.82  |proj g|=        1.7752
At iterate    52  f =      -556.85  |proj g|=        1.8849
At iterate    53  f =      -558.99  |proj g|=        1.5039
At iterate    54  f =      -563.17  |proj g|=       0.73337
At iterate    55  f =      -563.19  |proj g|=       0.73214
At iterate    56  f =      -563.28  |proj g|=       0.54853
At iterate    57  f =      -563.28  |proj g|=      0.013602
At iterate    58  f =      -563.28  |proj g|=     0.0080425

iterations 58
function evaluations 73
segments explored during Cauchy searches 62
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0080425
final function value -563.278

F = -563.278
final  value -563.277707 
converged
 
INFO  [09:21:04.519] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:21:04.604] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:21:04.611] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:21:13.561] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:21:23.985] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:21:34.145] [mlr3]  Finished benchmark 
INFO  [09:21:34.246] [bbotk] Result of batch 105: 
INFO  [09:21:34.248] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:21:34.248] [bbotk]              3.428399                 8.398865                       0.3186632 
INFO  [09:21:34.248] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:21:34.248] [bbotk]                     4554        0.826 -0.9426289         <NA>    0.971922 
INFO  [09:21:34.248] [bbotk]                                 uhash 
INFO  [09:21:34.248] [bbotk]  9c5a2eff-cb88-42a4-997c-fb3c0e6a1182 
DEBUG [09:21:35.794] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.208506e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.208506e-05 0.001299274 
  - best initial criterion value(s) :  488.2761 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -488.28  |proj g|=       9.1522
At iterate     1  f =       -535.3  |proj g|=        8.2338
At iterate     2  f =      -536.78  |proj g|=        7.4973
At iterate     3  f =      -540.68  |proj g|=        3.6986
At iterate     4  f =      -540.94  |proj g|=        4.0015
At iterate     5  f =      -540.97  |proj g|=        3.8789
At iterate     6  f =      -540.97  |proj g|=        3.8478
At iterate     7  f =      -540.97  |proj g|=        3.8555
At iterate     8  f =      -540.97  |proj g|=        3.8704
At iterate     9  f =      -540.98  |proj g|=        3.9041
At iterate    10  f =      -540.98  |proj g|=        3.9551
At iterate    11  f =         -541  |proj g|=        4.0406
At iterate    12  f =      -541.03  |proj g|=        4.1643
At iterate    13  f =      -541.09  |proj g|=        4.3219
At iterate    14  f =      -541.12  |proj g|=        4.5105
At iterate    15  f =      -541.27  |proj g|=        4.6205
At iterate    16  f =      -541.99  |proj g|=        4.8119
At iterate    17  f =      -543.91  |proj g|=        4.6612
At iterate    18  f =      -548.26  |proj g|=        3.4512
At iterate    19  f =      -552.08  |proj g|=        2.0727
At iterate    20  f =      -552.59  |proj g|=        2.6229
At iterate    21  f =      -555.05  |proj g|=        1.8984
At iterate    22  f =      -556.45  |proj g|=        1.8324
At iterate    23  f =      -558.31  |proj g|=        2.4244
At iterate    24  f =      -558.46  |proj g|=        2.3371
At iterate    25  f =      -558.49  |proj g|=        2.3778
At iterate    26  f =       -558.5  |proj g|=        2.4191
At iterate    27  f =       -558.5  |proj g|=        2.4257
At iterate    28  f =       -558.5  |proj g|=        2.4226
At iterate    29  f =       -558.5  |proj g|=        2.4274
At iterate    30  f =       -558.5  |proj g|=        2.4336
At iterate    31  f =      -558.51  |proj g|=        2.4506
At iterate    32  f =      -558.52  |proj g|=         2.455
At iterate    33  f =      -558.53  |proj g|=        2.4982
At iterate    34  f =      -558.54  |proj g|=         2.476
At iterate    35  f =      -558.56  |proj g|=        2.4386
At iterate    36  f =      -558.61  |proj g|=        2.3172
At iterate    37  f =      -558.65  |proj g|=        2.2243
At iterate    38  f =       -558.7  |proj g|=        2.1606
At iterate    39  f =      -558.77  |proj g|=        2.1129
At iterate    40  f =       -558.8  |proj g|=        2.1357
At iterate    41  f =      -558.84  |proj g|=        2.1902
At iterate    42  f =      -558.86  |proj g|=        2.2687
At iterate    43  f =      -558.87  |proj g|=        2.3001
At iterate    44  f =      -558.91  |proj g|=        2.3315
At iterate    45  f =      -558.94  |proj g|=        2.3499
At iterate    46  f =      -558.95  |proj g|=        2.3054
At iterate    47  f =      -558.97  |proj g|=        2.2952
At iterate    48  f =       -559.1  |proj g|=        2.2681
At iterate    49  f =      -559.36  |proj g|=        2.1524
At iterate    50  f =      -559.76  |proj g|=        2.1193
At iterate    51  f =      -559.79  |proj g|=        2.2539
At iterate    52  f =      -560.89  |proj g|=        2.0575
At iterate    53  f =      -567.14  |proj g|=       0.75244
At iterate    54  f =      -567.76  |proj g|=       0.73909
At iterate    55  f =      -567.84  |proj g|=       0.73614
At iterate    56  f =      -567.94  |proj g|=        0.7273
At iterate    57  f =      -567.94  |proj g|=         0.069
At iterate    58  f =      -567.94  |proj g|=      0.069092

iterations 58
function evaluations 70
segments explored during Cauchy searches 60
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0690919
final function value -567.938

F = -567.938
final  value -567.937798 
converged
 
INFO  [09:21:35.796] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:21:35.894] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:21:35.901] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:21:46.899] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:21:56.361] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:22:05.775] [mlr3]  Finished benchmark 
INFO  [09:22:05.875] [bbotk] Result of batch 106: 
INFO  [09:22:05.877] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:22:05.877] [bbotk]              3.948615                 6.059631                        0.147851 
INFO  [09:22:05.877] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [09:22:05.877] [bbotk]                     4288        0.948 -0.942092         <NA>   0.9704921 
INFO  [09:22:05.877] [bbotk]                                 uhash 
INFO  [09:22:05.877] [bbotk]  feef4214-5dbd-4529-80f4-88091dfd1ab5 
DEBUG [09:22:06.985] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.202151e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.202151e-05 0.001293935 
  - best initial criterion value(s) :  492.3134 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -492.31  |proj g|=        8.197
At iterate     1  f =      -505.27  |proj g|=        3.1944
At iterate     2  f =      -532.99  |proj g|=        1.8145
At iterate     3  f =      -534.51  |proj g|=         2.159
At iterate     4  f =      -534.62  |proj g|=        2.2013
At iterate     5  f =      -536.01  |proj g|=        2.4007
At iterate     6  f =      -536.37  |proj g|=        2.2258
At iterate     7  f =       -536.5  |proj g|=        2.0281
At iterate     8  f =      -536.51  |proj g|=        1.9875
At iterate     9  f =      -536.51  |proj g|=        1.9821
At iterate    10  f =      -536.51  |proj g|=        2.0008
At iterate    11  f =      -536.51  |proj g|=        1.9909
At iterate    12  f =      -537.02  |proj g|=        1.7857
At iterate    13  f =      -538.92  |proj g|=        1.6504
At iterate    14  f =      -542.07  |proj g|=        1.8718
At iterate    15  f =      -544.38  |proj g|=        1.8225
At iterate    16  f =      -545.24  |proj g|=        1.6552
At iterate    17  f =      -545.43  |proj g|=        1.4645
At iterate    18  f =      -545.44  |proj g|=        1.4076
At iterate    19  f =      -545.44  |proj g|=        1.4103
At iterate    20  f =      -545.44  |proj g|=        1.4103

iterations 20
function evaluations 29
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.41026
final function value -545.438

F = -545.438
final  value -545.437751 
converged
 
INFO  [09:22:06.989] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:22:07.078] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:22:07.103] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:22:13.113] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:22:17.946] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:22:23.051] [mlr3]  Finished benchmark 
INFO  [09:22:23.151] [bbotk] Result of batch 107: 
INFO  [09:22:23.153] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:22:23.153] [bbotk]               7.09784                 4.165084                       0.1497652 
INFO  [09:22:23.153] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:22:23.153] [bbotk]                     2503        0.754 -0.9566293         <NA>   0.9706517 
INFO  [09:22:23.153] [bbotk]                                 uhash 
INFO  [09:22:23.153] [bbotk]  d7513adf-302b-42c5-a82f-98a7feb7b2c8 
DEBUG [09:22:24.236] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.195989e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.195989e-05 0.001288276 
  - best initial criterion value(s) :  533.965 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -533.96  |proj g|=      0.70835
At iterate     1  f =      -552.05  |proj g|=         5.804
At iterate     2  f =      -552.59  |proj g|=        5.5587
At iterate     3  f =      -553.09  |proj g|=        4.5664
At iterate     4  f =      -553.19  |proj g|=         4.931
At iterate     5  f =       -553.2  |proj g|=        4.8774
At iterate     6  f =      -553.21  |proj g|=        4.8414
At iterate     7  f =      -553.23  |proj g|=        4.7789
At iterate     8  f =      -553.29  |proj g|=        4.7141
At iterate     9  f =      -553.38  |proj g|=        4.7001
At iterate    10  f =      -553.46  |proj g|=        5.1206
At iterate    11  f =      -553.48  |proj g|=        4.9789
At iterate    12  f =      -553.49  |proj g|=        4.9533
At iterate    13  f =      -553.49  |proj g|=        4.9544
At iterate    14  f =      -553.49  |proj g|=        4.9548

iterations 14
function evaluations 18
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.95484
final function value -553.485

F = -553.485
final  value -553.485472 
converged
 
INFO  [09:22:24.240] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:22:24.326] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:22:24.333] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:22:31.302] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:22:38.351] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:22:44.772] [mlr3]  Finished benchmark 
INFO  [09:22:44.910] [bbotk] Result of batch 108: 
INFO  [09:22:44.912] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:22:44.912] [bbotk]              8.549474                  8.17796                       0.1328697 
INFO  [09:22:44.912] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:22:44.912] [bbotk]                     3287        0.762 -0.9610956         <NA>   0.9710313 
INFO  [09:22:44.912] [bbotk]                                 uhash 
INFO  [09:22:44.912] [bbotk]  4ecf5c2c-3cf9-446e-a594-4deeef11c896 
DEBUG [09:22:46.108] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.190216e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.190216e-05 0.001281512 
  - best initial criterion value(s) :  542.4429 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -542.44  |proj g|=       5.3834
At iterate     1  f =      -558.12  |proj g|=        1.3442
At iterate     2  f =      -560.58  |proj g|=        1.1594
At iterate     3  f =      -562.06  |proj g|=        2.0961
At iterate     4  f =      -562.44  |proj g|=        1.6429
At iterate     5  f =      -562.76  |proj g|=        1.7368
At iterate     6  f =      -563.32  |proj g|=        1.6884
At iterate     7  f =      -563.76  |proj g|=         1.227
At iterate     8  f =      -563.81  |proj g|=        1.2678
At iterate     9  f =      -563.81  |proj g|=        1.2745
At iterate    10  f =      -563.81  |proj g|=        1.2735
At iterate    11  f =      -563.81  |proj g|=        1.2714
At iterate    12  f =      -563.81  |proj g|=        1.2671
At iterate    13  f =      -563.81  |proj g|=        1.2628
At iterate    14  f =      -563.81  |proj g|=        1.2608
At iterate    15  f =      -563.81  |proj g|=        1.2444
At iterate    16  f =      -563.81  |proj g|=        1.2569
At iterate    17  f =      -563.81  |proj g|=        1.2665
At iterate    18  f =      -563.81  |proj g|=        1.2613
At iterate    19  f =      -563.81  |proj g|=        1.2663
At iterate    20  f =      -563.95  |proj g|=        1.2344
At iterate    21  f =      -566.32  |proj g|=       0.91664
At iterate    22  f =      -567.08  |proj g|=       0.75772
At iterate    23  f =       -567.1  |proj g|=        0.8149
At iterate    24  f =      -567.11  |proj g|=       0.82118
At iterate    25  f =      -567.11  |proj g|=       0.82606
At iterate    26  f =      -567.11  |proj g|=       0.82523
At iterate    27  f =      -567.11  |proj g|=       0.82521

iterations 27
function evaluations 38
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.825214
final function value -567.109

F = -567.109
final  value -567.109026 
converged
 
INFO  [09:22:46.112] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:22:46.200] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:22:46.207] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:22:49.539] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:22:53.470] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:22:57.613] [mlr3]  Finished benchmark 
INFO  [09:22:57.744] [bbotk] Result of batch 109: 
INFO  [09:22:57.747] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:22:57.747] [bbotk]              2.869071                 7.743487                       0.4697092 
INFO  [09:22:57.747] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:22:57.747] [bbotk]                     1509        0.759 -0.9571949         <NA>    0.964446 
INFO  [09:22:57.747] [bbotk]                                 uhash 
INFO  [09:22:57.747] [bbotk]  dee40cd6-1884-4b43-8802-8c371a85c8f8 
DEBUG [09:22:58.795] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.181659e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.181659e-05 0.001271772 
  - best initial criterion value(s) :  542.3417 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -542.34  |proj g|=       5.6987
At iterate     1  f =      -560.39  |proj g|=        2.4899
At iterate     2  f =      -579.56  |proj g|=         2.439
At iterate     3  f =      -582.62  |proj g|=        1.4427
At iterate     4  f =      -582.76  |proj g|=        1.6165
At iterate     5  f =      -582.76  |proj g|=        1.6494
At iterate     6  f =      -582.76  |proj g|=        1.6462
At iterate     7  f =      -582.76  |proj g|=         1.642
At iterate     8  f =      -582.76  |proj g|=        1.6421

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.64214
final function value -582.762

F = -582.762
final  value -582.761695 
converged
 
INFO  [09:22:58.800] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:22:58.892] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:22:58.899] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:23:08.115] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:23:17.220] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:23:26.552] [mlr3]  Finished benchmark 
INFO  [09:23:26.656] [bbotk] Result of batch 110: 
INFO  [09:23:26.658] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:23:26.658] [bbotk]              6.554627                 6.948203                       0.1802185 
INFO  [09:23:26.658] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:23:26.658] [bbotk]                     3787        0.765 -0.9501666         <NA>    0.972794 
INFO  [09:23:26.658] [bbotk]                                 uhash 
INFO  [09:23:26.658] [bbotk]  ed2f4fbd-3a7b-4e04-bb79-ea43fd797cab 
DEBUG [09:23:27.748] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.177826e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.177826e-05 0.001270021 
  - best initial criterion value(s) :  535.8038 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -535.8  |proj g|=      0.92477
At iterate     1  f =      -536.16  |proj g|=        1.4068
At iterate     2  f =      -541.06  |proj g|=        1.1442
At iterate     3  f =      -541.42  |proj g|=        1.4065
At iterate     4  f =      -541.42  |proj g|=        1.4121
At iterate     5  f =      -541.42  |proj g|=        1.4115
At iterate     6  f =      -541.42  |proj g|=        1.4113

iterations 6
function evaluations 14
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.41134
final function value -541.425

F = -541.425
final  value -541.424567 
converged
 
INFO  [09:23:27.752] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:23:27.876] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:23:27.883] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:23:31.857] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:23:35.051] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:23:38.737] [mlr3]  Finished benchmark 
INFO  [09:23:38.884] [bbotk] Result of batch 111: 
INFO  [09:23:38.886] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:23:38.886] [bbotk]              7.505799                 9.479473                      0.05925582 
INFO  [09:23:38.886] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:23:38.886] [bbotk]                     1588        0.788 -0.9653306         <NA>   0.9589822 
INFO  [09:23:38.886] [bbotk]                                 uhash 
INFO  [09:23:38.886] [bbotk]  ae22b9d6-a522-4218-b7a4-83ec0e3992f0 
DEBUG [09:23:40.415] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.171849e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.171849e-05 0.001263292 
  - best initial criterion value(s) :  557.0143 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -557.01  |proj g|=       1.2153
At iterate     1  f =      -561.82  |proj g|=        5.9041
At iterate     2  f =      -565.31  |proj g|=        5.4838
At iterate     3  f =       -568.3  |proj g|=        4.4838
At iterate     4  f =      -568.55  |proj g|=        3.9083
At iterate     5  f =      -568.83  |proj g|=        4.0102
At iterate     6  f =      -570.02  |proj g|=        3.9653
At iterate     7  f =      -570.34  |proj g|=        3.5851
At iterate     8  f =      -570.39  |proj g|=        3.3825
At iterate     9  f =      -570.39  |proj g|=        3.4242
At iterate    10  f =      -570.39  |proj g|=          3.42
At iterate    11  f =      -570.39  |proj g|=        3.4194
At iterate    12  f =      -570.39  |proj g|=        3.4183
At iterate    13  f =      -570.39  |proj g|=        3.4161
At iterate    14  f =      -570.39  |proj g|=        3.4133
At iterate    15  f =      -570.39  |proj g|=        3.4082
At iterate    16  f =      -570.39  |proj g|=        3.4002
At iterate    17  f =      -570.39  |proj g|=        3.3867
At iterate    18  f =      -570.39  |proj g|=        3.3635
At iterate    19  f =       -570.4  |proj g|=        3.3225
At iterate    20  f =      -570.42  |proj g|=        3.2474
At iterate    21  f =      -570.48  |proj g|=        3.1054
At iterate    22  f =      -570.64  |proj g|=        2.8306
At iterate    23  f =      -571.06  |proj g|=        2.5282
At iterate    24  f =      -571.95  |proj g|=        2.5139
At iterate    25  f =      -573.04  |proj g|=        2.8947
At iterate    26  f =      -573.19  |proj g|=        3.0747
At iterate    27  f =      -573.21  |proj g|=        3.1379
At iterate    28  f =      -573.21  |proj g|=        3.1472
At iterate    29  f =      -573.21  |proj g|=        3.1475
At iterate    30  f =      -573.21  |proj g|=        3.1524
At iterate    31  f =      -573.21  |proj g|=        3.1541
At iterate    32  f =      -573.21  |proj g|=        3.1586
At iterate    33  f =      -573.22  |proj g|=        3.1704
At iterate    34  f =      -573.25  |proj g|=        3.1715
At iterate    35  f =      -573.28  |proj g|=        3.3174
At iterate    36  f =      -573.38  |proj g|=        3.2516
At iterate    37  f =      -573.73  |proj g|=        3.0769
At iterate    38  f =      -574.37  |proj g|=        2.8916
At iterate    39  f =      -575.67  |proj g|=        2.6812
At iterate    40  f =      -577.05  |proj g|=        2.6548
At iterate    41  f =      -577.23  |proj g|=        2.4532
At iterate    42  f =      -578.18  |proj g|=        2.5753
At iterate    43  f =      -578.82  |proj g|=        2.8835
At iterate    44  f =      -578.92  |proj g|=        2.9717
At iterate    45  f =      -578.94  |proj g|=        3.0268
At iterate    46  f =      -578.94  |proj g|=        3.0479
At iterate    47  f =      -578.94  |proj g|=        3.0548
At iterate    48  f =      -578.94  |proj g|=        3.0534
At iterate    49  f =      -578.94  |proj g|=        3.0534
At iterate    50  f =      -578.94  |proj g|=        3.0534

iterations 50
function evaluations 56
segments explored during Cauchy searches 52
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.05344
final function value -578.94

F = -578.94
final  value -578.940274 
converged
 
INFO  [09:23:40.420] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:23:40.508] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:23:40.515] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:23:48.390] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:23:57.517] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:24:04.039] [mlr3]  Finished benchmark 
INFO  [09:24:04.188] [bbotk] Result of batch 112: 
INFO  [09:24:04.190] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:24:04.190] [bbotk]              4.001699                 3.495765                        0.406777 
INFO  [09:24:04.190] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [09:24:04.190] [bbotk]                     3516        0.956 -0.955774         <NA>   0.9734689 
INFO  [09:24:04.190] [bbotk]                                 uhash 
INFO  [09:24:04.190] [bbotk]  954d4666-236e-49a4-ab22-bff4a0b29836 
DEBUG [09:24:05.520] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.168913e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.168913e-05 0.001262574 
  - best initial criterion value(s) :  539.2374 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -539.24  |proj g|=       3.6957
At iterate     1  f =      -566.53  |proj g|=         2.724
At iterate     2  f =      -583.12  |proj g|=        6.9768
At iterate     3  f =      -583.21  |proj g|=        7.0679
At iterate     4  f =      -583.28  |proj g|=        7.0106
At iterate     5  f =       -583.5  |proj g|=        6.3119
At iterate     6  f =       -583.5  |proj g|=        6.4217
At iterate     7  f =       -583.5  |proj g|=        6.3983
At iterate     8  f =       -583.5  |proj g|=         6.397
At iterate     9  f =       -583.5  |proj g|=        6.3954
At iterate    10  f =       -583.5  |proj g|=        6.3928
At iterate    11  f =       -583.5  |proj g|=        6.3887
At iterate    12  f =       -583.5  |proj g|=        6.3822
At iterate    13  f =       -583.5  |proj g|=        6.3723
At iterate    14  f =       -583.5  |proj g|=        6.3578
At iterate    15  f =      -583.51  |proj g|=        6.3395
At iterate    16  f =      -583.51  |proj g|=        6.3257
At iterate    17  f =      -583.52  |proj g|=        6.3444
At iterate    18  f =      -583.53  |proj g|=        6.4724
At iterate    19  f =      -583.53  |proj g|=        6.4827
At iterate    20  f =      -583.58  |proj g|=         6.504
At iterate    21  f =      -584.24  |proj g|=        6.4987
At iterate    22  f =      -585.56  |proj g|=        6.1298
At iterate    23  f =      -588.38  |proj g|=        5.0166
At iterate    24  f =      -588.78  |proj g|=        5.4753
At iterate    25  f =      -592.18  |proj g|=        3.7558
At iterate    26  f =      -592.67  |proj g|=         3.421
At iterate    27  f =      -593.29  |proj g|=        3.0347
At iterate    28  f =      -595.99  |proj g|=         1.551
At iterate    29  f =      -598.46  |proj g|=       0.75474
At iterate    30  f =      -603.32  |proj g|=       0.69793
At iterate    31  f =      -604.93  |proj g|=        1.1405
At iterate    32  f =      -605.01  |proj g|=        1.2283
At iterate    33  f =      -605.03  |proj g|=        1.3065
At iterate    34  f =      -605.03  |proj g|=        1.3046
At iterate    35  f =      -605.03  |proj g|=        1.3049
At iterate    36  f =      -605.03  |proj g|=        1.3054
At iterate    37  f =      -605.03  |proj g|=        1.3067
At iterate    38  f =      -605.03  |proj g|=        1.3085
At iterate    39  f =      -605.03  |proj g|=        1.3116
At iterate    40  f =      -605.03  |proj g|=        1.3164
At iterate    41  f =      -605.03  |proj g|=         1.324
At iterate    42  f =      -605.04  |proj g|=        1.3358
At iterate    43  f =      -605.04  |proj g|=        1.3539
At iterate    44  f =      -605.06  |proj g|=        1.3806
At iterate    45  f =      -606.89  |proj g|=       0.72634
At iterate    46  f =      -607.07  |proj g|=       0.71933
At iterate    47  f =      -607.11  |proj g|=       0.71694
At iterate    48  f =      -607.15  |proj g|=       0.26139
At iterate    49  f =      -607.15  |proj g|=     0.0038596
At iterate    50  f =      -607.15  |proj g|=      0.001108

iterations 50
function evaluations 62
segments explored during Cauchy searches 52
BFGS updates skipped 0
active bounds at final generalized Cauchy point 3
norm of the final projected gradient 0.00110803
final function value -607.146

F = -607.146
final  value -607.146253 
converged
 
INFO  [09:24:05.524] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:24:05.614] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:24:05.621] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:24:08.533] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:24:11.339] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:24:14.517] [mlr3]  Finished benchmark 
INFO  [09:24:14.622] [bbotk] Result of batch 113: 
INFO  [09:24:14.624] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:24:14.624] [bbotk]              7.682753                 4.426857                       0.4342599 
INFO  [09:24:14.624] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:24:14.624] [bbotk]                     1776        0.764 -0.9412504         <NA>   0.9731558 
INFO  [09:24:14.624] [bbotk]                                 uhash 
INFO  [09:24:14.624] [bbotk]  c921dc25-8722-40b1-ae1e-ec6668062418 
DEBUG [09:24:15.897] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.165574e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.165574e-05 0.001258726 
  - best initial criterion value(s) :  545.4479 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -545.45  |proj g|=       3.5622
At iterate     1  f =      -551.91  |proj g|=        1.3744
At iterate     2  f =      -552.22  |proj g|=        1.4849
At iterate     3  f =      -552.36  |proj g|=        1.7425
At iterate     4  f =      -552.38  |proj g|=        1.7079
At iterate     5  f =      -552.48  |proj g|=        1.6097
At iterate     6  f =      -552.68  |proj g|=         1.485
At iterate     7  f =      -553.03  |proj g|=        1.3741
At iterate     8  f =      -553.36  |proj g|=        1.3801
At iterate     9  f =      -553.46  |proj g|=        1.4434
At iterate    10  f =      -553.48  |proj g|=        1.4998
At iterate    11  f =      -553.48  |proj g|=        1.5289
At iterate    12  f =      -553.48  |proj g|=        1.5305
At iterate    13  f =      -553.48  |proj g|=        1.5272
At iterate    14  f =      -553.49  |proj g|=        1.5111
At iterate    15  f =       -553.5  |proj g|=        1.4874
At iterate    16  f =      -553.52  |proj g|=        1.4464
At iterate    17  f =      -553.58  |proj g|=        1.3785
At iterate    18  f =      -553.73  |proj g|=        1.3422
At iterate    19  f =      -554.08  |proj g|=        1.4832
At iterate    20  f =      -554.83  |proj g|=        1.6031
At iterate    21  f =      -555.28  |proj g|=        1.3984
At iterate    22  f =      -555.61  |proj g|=        1.4022
At iterate    23  f =      -555.85  |proj g|=         1.371
At iterate    24  f =      -557.31  |proj g|=        1.3769
At iterate    25  f =      -557.34  |proj g|=        1.4665
At iterate    26  f =      -557.41  |proj g|=         1.411
At iterate    27  f =      -557.41  |proj g|=        1.3971
At iterate    28  f =      -557.41  |proj g|=        1.3979
At iterate    29  f =      -557.41  |proj g|=        1.3975
At iterate    30  f =      -557.41  |proj g|=        1.3975

iterations 30
function evaluations 35
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.39745
final function value -557.414

F = -557.414
final  value -557.413537 
converged
 
INFO  [09:24:15.901] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:24:16.017] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:24:16.029] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:24:24.231] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:24:32.704] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:24:41.247] [mlr3]  Finished benchmark 
INFO  [09:24:41.352] [bbotk] Result of batch 114: 
INFO  [09:24:41.354] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:24:41.354] [bbotk]              6.006146                 6.367724                       0.2174397 
INFO  [09:24:41.354] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:24:41.354] [bbotk]                     5000        0.819 -0.9644108         <NA>   0.9740978 
INFO  [09:24:41.354] [bbotk]                                 uhash 
INFO  [09:24:41.354] [bbotk]  93107bfc-de4d-4ccc-a6e9-9ad36ba2d1f2 
DEBUG [09:24:42.738] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.163354e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.163354e-05 0.001256471 
  - best initial criterion value(s) :  577.722 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -577.72  |proj g|=       1.7724
At iterate     1  f =      -583.74  |proj g|=        5.5453
At iterate     2  f =      -586.28  |proj g|=        5.1813
At iterate     3  f =      -587.65  |proj g|=        4.6602
At iterate     4  f =      -587.75  |proj g|=        4.3451
At iterate     5  f =      -587.77  |proj g|=        4.4418
At iterate     6  f =      -587.78  |proj g|=        4.4108
At iterate     7  f =       -587.8  |proj g|=        4.3312
At iterate     8  f =       -587.8  |proj g|=        4.3395
At iterate     9  f =       -587.8  |proj g|=        4.3428
At iterate    10  f =       -587.8  |proj g|=        4.3431
At iterate    11  f =       -587.8  |proj g|=         4.345
At iterate    12  f =       -587.8  |proj g|=        4.3472
At iterate    13  f =       -587.8  |proj g|=        4.3513
At iterate    14  f =       -587.8  |proj g|=        4.3578
At iterate    15  f =       -587.8  |proj g|=        4.3686
At iterate    16  f =       -587.8  |proj g|=        4.3863
At iterate    17  f =      -587.81  |proj g|=        4.4134
At iterate    18  f =      -587.82  |proj g|=        4.4471
At iterate    19  f =      -587.84  |proj g|=        4.4598
At iterate    20  f =      -587.85  |proj g|=        4.3997
At iterate    21  f =      -587.85  |proj g|=        4.4068
At iterate    22  f =      -587.85  |proj g|=        4.4082
At iterate    23  f =      -587.85  |proj g|=        4.4131
At iterate    24  f =      -587.85  |proj g|=        4.4195
At iterate    25  f =      -587.85  |proj g|=         4.427
At iterate    26  f =      -587.85  |proj g|=        4.4554
At iterate    27  f =      -587.86  |proj g|=        4.4633
At iterate    28  f =      -590.88  |proj g|=        3.7633
At iterate    29  f =       -601.4  |proj g|=        2.8721
At iterate    30  f =      -606.71  |proj g|=        2.7005
At iterate    31  f =      -609.18  |proj g|=        2.6756
At iterate    32  f =      -609.25  |proj g|=        2.4702
At iterate    33  f =      -609.29  |proj g|=        2.4354
At iterate    34  f =      -609.32  |proj g|=        2.4622
At iterate    35  f =      -609.32  |proj g|=        2.4623
At iterate    36  f =      -609.32  |proj g|=         2.462

iterations 36
function evaluations 42
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.46203
final function value -609.316

F = -609.316
final  value -609.315993 
converged
 
INFO  [09:24:42.742] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:24:43.357] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:24:43.364] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:24:46.344] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:24:49.436] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:24:52.576] [mlr3]  Finished benchmark 
INFO  [09:24:52.688] [bbotk] Result of batch 115: 
INFO  [09:24:52.691] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:24:52.691] [bbotk]              6.546848                 3.389425                      0.04191001 
INFO  [09:24:52.691] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:24:52.691] [bbotk]                     1926        0.897 -0.9533102         <NA>   0.9561961 
INFO  [09:24:52.691] [bbotk]                                 uhash 
INFO  [09:24:52.691] [bbotk]  31ffbe2d-5279-42fe-968c-7632d888a038 
DEBUG [09:24:53.965] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.160559e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.160559e-05 0.001256325 
  - best initial criterion value(s) :  549.6665 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -549.67  |proj g|=       3.0086
At iterate     1  f =      -555.45  |proj g|=        10.043
At iterate     2  f =       -588.3  |proj g|=        5.6523
At iterate     3  f =      -589.23  |proj g|=        5.1092
At iterate     4  f =      -594.66  |proj g|=         3.714
At iterate     5  f =      -598.16  |proj g|=        3.9206
At iterate     6  f =      -599.28  |proj g|=        3.0429
At iterate     7  f =      -599.58  |proj g|=        2.7721
At iterate     8  f =      -599.71  |proj g|=         3.424
At iterate     9  f =      -599.91  |proj g|=        2.9644
At iterate    10  f =      -599.93  |proj g|=        2.8932
At iterate    11  f =      -599.94  |proj g|=        2.8935
At iterate    12  f =      -599.97  |proj g|=        2.9172
At iterate    13  f =         -600  |proj g|=        2.9382
At iterate    14  f =      -600.08  |proj g|=        2.9149
At iterate    15  f =      -600.28  |proj g|=         2.734
At iterate    16  f =      -600.42  |proj g|=        3.0732
At iterate    17  f =      -600.93  |proj g|=         2.707
At iterate    18  f =      -602.17  |proj g|=        2.2442
At iterate    19  f =      -609.21  |proj g|=        1.4869
At iterate    20  f =      -615.02  |proj g|=        1.4493
At iterate    21  f =         -617  |proj g|=       0.69219
At iterate    22  f =      -617.27  |proj g|=       0.74256
At iterate    23  f =      -617.27  |proj g|=        0.7604
At iterate    24  f =      -617.27  |proj g|=       0.75968
At iterate    25  f =      -617.27  |proj g|=       0.75979
At iterate    26  f =      -617.27  |proj g|=       0.75976

iterations 26
function evaluations 39
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.759761
final function value -617.269

F = -617.269
final  value -617.269222 
converged
 
INFO  [09:24:53.969] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:24:54.066] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:24:54.074] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:24:57.821] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:25:01.618] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:25:05.632] [mlr3]  Finished benchmark 
INFO  [09:25:05.755] [bbotk] Result of batch 116: 
INFO  [09:25:05.756] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:25:05.756] [bbotk]               5.80898                 3.718239                        0.213808 
INFO  [09:25:05.756] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:25:05.756] [bbotk]                     2453        0.793 -0.9507901         <NA>   0.9717467 
INFO  [09:25:05.756] [bbotk]                                 uhash 
INFO  [09:25:05.756] [bbotk]  226b8bef-53ad-4560-8902-526a3adef971 
DEBUG [09:25:07.234] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.155824e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.155824e-05 0.00125157 
  - best initial criterion value(s) :  573.3831 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -573.38  |proj g|=       4.5891
At iterate     1  f =      -589.58  |proj g|=        3.0166
At iterate     2  f =      -590.65  |proj g|=        4.0928
At iterate     3  f =      -590.79  |proj g|=        3.9237
At iterate     4  f =      -590.83  |proj g|=        3.7717
At iterate     5  f =      -590.83  |proj g|=        3.7755
At iterate     6  f =      -590.84  |proj g|=        3.7863
At iterate     7  f =      -590.84  |proj g|=        3.7871
At iterate     8  f =      -590.84  |proj g|=        3.7874

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.78736
final function value -590.836

F = -590.836
final  value -590.835917 
converged
 
INFO  [09:25:07.236] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:25:07.322] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:25:07.330] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:25:09.276] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:25:11.160] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:25:14.516] [mlr3]  Finished benchmark 
INFO  [09:25:14.617] [bbotk] Result of batch 117: 
INFO  [09:25:14.618] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:25:14.618] [bbotk]              6.366998                 6.053317                       0.4178509 
INFO  [09:25:14.618] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:25:14.618] [bbotk]                     1104        1.146 -0.9613419         <NA>   0.9713742 
INFO  [09:25:14.618] [bbotk]                                 uhash 
INFO  [09:25:14.618] [bbotk]  7dfc298f-4b9d-406f-a644-c0a48810aed9 
DEBUG [09:25:15.970] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.150777e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.150777e-05 0.00124291 
  - best initial criterion value(s) :  591.4768 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -591.48  |proj g|=       7.5935
At iterate     1  f =       -600.3  |proj g|=        4.2512
At iterate     2  f =      -600.42  |proj g|=        4.6679
At iterate     3  f =      -601.11  |proj g|=        4.9497
At iterate     4  f =      -612.52  |proj g|=        2.0061
At iterate     5  f =       -616.2  |proj g|=        1.3073
At iterate     6  f =      -618.28  |proj g|=        1.0822
At iterate     7  f =      -619.02  |proj g|=        1.1548
At iterate     8  f =      -619.03  |proj g|=        1.1026
At iterate     9  f =       -619.1  |proj g|=        1.0734
At iterate    10  f =       -619.1  |proj g|=        1.0672
At iterate    11  f =       -619.1  |proj g|=        1.0669
At iterate    12  f =       -619.1  |proj g|=        1.0673
At iterate    13  f =       -619.1  |proj g|=        1.0678
At iterate    14  f =       -619.1  |proj g|=        1.0679
At iterate    15  f =       -619.1  |proj g|=        1.0688
At iterate    16  f =       -619.1  |proj g|=         1.069
At iterate    17  f =       -619.1  |proj g|=        1.0695
At iterate    18  f =      -619.11  |proj g|=        1.0649
At iterate    19  f =      -619.11  |proj g|=        1.0673
At iterate    20  f =      -619.12  |proj g|=        1.0718
At iterate    21  f =      -619.12  |proj g|=        1.0587
At iterate    22  f =      -619.16  |proj g|=        1.0711
At iterate    23  f =      -619.23  |proj g|=        1.0779
At iterate    24  f =      -619.42  |proj g|=        1.0699
At iterate    25  f =      -619.84  |proj g|=        1.0199
At iterate    26  f =      -620.46  |proj g|=       0.78202
At iterate    27  f =      -620.48  |proj g|=       0.76559
At iterate    28  f =      -620.89  |proj g|=       0.76034
At iterate    29  f =       -621.4  |proj g|=        0.2715
At iterate    30  f =      -621.42  |proj g|=        0.2337
At iterate    31  f =      -621.49  |proj g|=       0.23391
At iterate    32  f =      -621.59  |proj g|=       0.23115
At iterate    33  f =      -621.61  |proj g|=       0.23003
At iterate    34  f =      -621.81  |proj g|=       0.21873
At iterate    35  f =      -621.98  |proj g|=       0.20355
At iterate    36  f =      -622.01  |proj g|=       0.77984
At iterate    37  f =      -622.01  |proj g|=       0.19975
At iterate    38  f =      -622.01  |proj g|=       0.12645
At iterate    39  f =      -622.01  |proj g|=     0.0084787
At iterate    40  f =      -622.01  |proj g|=     0.0084787

iterations 40
function evaluations 54
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00847866
final function value -622.008

F = -622.008
final  value -622.007900 
converged
 
INFO  [09:25:15.974] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:25:16.079] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:25:16.086] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:25:21.162] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:25:25.927] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:25:30.084] [mlr3]  Finished benchmark 
INFO  [09:25:30.184] [bbotk] Result of batch 118: 
INFO  [09:25:30.186] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:25:30.186] [bbotk]              7.568012                 8.075979                       0.2635393 
INFO  [09:25:30.186] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:25:30.186] [bbotk]                     2096        0.773 -0.9526957         <NA>   0.9720504 
INFO  [09:25:30.186] [bbotk]                                 uhash 
INFO  [09:25:30.186] [bbotk]  f3d1bb7d-61d4-4f10-8ff7-d912a9c00006 
DEBUG [09:25:31.409] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.146373e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.146373e-05 0.001242905 
  - best initial criterion value(s) :  565.3206 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -565.32  |proj g|=       3.0733
At iterate     1  f =         -575  |proj g|=        9.2041
At iterate     2  f =      -582.68  |proj g|=        8.5629
At iterate     3  f =      -593.92  |proj g|=        6.4615
At iterate     4  f =      -594.64  |proj g|=        5.7205
At iterate     5  f =      -594.65  |proj g|=        5.6072
At iterate     6  f =      -594.68  |proj g|=        5.5838
At iterate     7  f =      -594.72  |proj g|=        5.4647
At iterate     8  f =      -594.73  |proj g|=        5.4661
At iterate     9  f =      -594.73  |proj g|=        5.4701
At iterate    10  f =      -594.73  |proj g|=        5.4729
At iterate    11  f =      -594.74  |proj g|=        5.4516
At iterate    12  f =      -594.74  |proj g|=        5.5231
At iterate    13  f =      -594.77  |proj g|=        5.4809
At iterate    14  f =      -606.98  |proj g|=         3.986
At iterate    15  f =      -616.11  |proj g|=        2.0119
At iterate    16  f =      -621.19  |proj g|=        0.6657
At iterate    17  f =       -622.2  |proj g|=       0.79889
At iterate    18  f =      -622.22  |proj g|=       0.79947
At iterate    19  f =      -622.22  |proj g|=       0.46752
At iterate    20  f =      -622.22  |proj g|=        0.1741
At iterate    21  f =      -622.22  |proj g|=       0.17421

iterations 21
function evaluations 28
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.174213
final function value -622.223

F = -622.223
final  value -622.223409 
converged
 
INFO  [09:25:31.413] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:25:31.502] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:25:31.526] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:25:32.799] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:25:34.199] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:25:35.889] [mlr3]  Finished benchmark 
INFO  [09:25:36.025] [bbotk] Result of batch 119: 
INFO  [09:25:36.027] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:25:36.027] [bbotk]               2.14211                 4.370862                         0.27961 
INFO  [09:25:36.027] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:25:36.027] [bbotk]                      434        0.804 -0.9550923         <NA>   0.9364179 
INFO  [09:25:36.027] [bbotk]                                 uhash 
INFO  [09:25:36.027] [bbotk]  7a625f6d-0104-4719-91b9-5a77c3ea1c7b 
DEBUG [09:25:37.262] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.193181e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.193181e-05 0.001307125 
  - best initial criterion value(s) :  556.8482 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -556.85  |proj g|=       13.114
At iterate     1  f =      -566.15  |proj g|=        8.9732
At iterate     2  f =      -584.05  |proj g|=        6.7906
At iterate     3  f =      -595.47  |proj g|=        4.5667
At iterate     4  f =      -597.19  |proj g|=         3.723
At iterate     5  f =      -598.89  |proj g|=        3.3879
At iterate     6  f =      -599.39  |proj g|=        3.1316
At iterate     7  f =      -599.39  |proj g|=        3.1438
At iterate     8  f =      -599.39  |proj g|=        3.1515
At iterate     9  f =      -599.39  |proj g|=        3.1645
At iterate    10  f =       -599.4  |proj g|=        3.1725
At iterate    11  f =      -599.41  |proj g|=        3.2159
At iterate    12  f =      -599.44  |proj g|=        3.2367
At iterate    13  f =      -599.79  |proj g|=        3.3694
At iterate    14  f =      -600.46  |proj g|=        3.4842
At iterate    15  f =      -602.38  |proj g|=        3.5548
At iterate    16  f =      -607.03  |proj g|=        3.8664
At iterate    17  f =       -618.3  |proj g|=        2.7975
At iterate    18  f =      -626.23  |proj g|=        1.9634
At iterate    19  f =       -627.3  |proj g|=         1.649
At iterate    20  f =      -627.64  |proj g|=        1.4259
At iterate    21  f =      -628.14  |proj g|=        1.0031
At iterate    22  f =      -628.55  |proj g|=       0.57257
At iterate    23  f =      -628.76  |proj g|=       0.57778
At iterate    24  f =      -628.77  |proj g|=       0.65221
At iterate    25  f =      -628.77  |proj g|=       0.63463
At iterate    26  f =      -628.77  |proj g|=       0.63409

iterations 26
function evaluations 30
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.634092
final function value -628.766

F = -628.766
final  value -628.765727 
converged
 
INFO  [09:25:37.266] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:25:37.352] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:25:37.359] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:25:38.503] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:25:40.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:25:41.430] [mlr3]  Finished benchmark 
INFO  [09:25:41.533] [bbotk] Result of batch 120: 
INFO  [09:25:41.535] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:25:41.535] [bbotk]              9.323488                 8.704347                       0.4171815 
INFO  [09:25:41.535] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:25:41.535] [bbotk]                      455         0.81 -0.9521374         <NA>   0.9663907 
INFO  [09:25:41.535] [bbotk]                                 uhash 
INFO  [09:25:41.535] [bbotk]  40ec5fa5-876b-4742-8a98-cc56101f96f2 
DEBUG [09:25:43.021] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.18539e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.18539e-05 0.001293276 
  - best initial criterion value(s) :  542.2894 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -542.29  |proj g|=       3.2524
At iterate     1  f =       -570.5  |proj g|=        13.485
At iterate     2  f =      -580.23  |proj g|=        13.316
At iterate     3  f =      -597.26  |proj g|=        12.945
At iterate     4  f =       -599.5  |proj g|=        10.788
At iterate     5  f =      -602.92  |proj g|=        9.9582
At iterate     6  f =      -613.37  |proj g|=        5.2573
At iterate     7  f =      -617.04  |proj g|=        4.1231
At iterate     8  f =      -619.93  |proj g|=         3.569
At iterate     9  f =      -621.06  |proj g|=        4.2816
At iterate    10  f =      -621.83  |proj g|=        5.1519
At iterate    11  f =      -621.91  |proj g|=        5.4449
At iterate    12  f =      -621.91  |proj g|=        5.5294
At iterate    13  f =      -621.91  |proj g|=        5.5376
At iterate    14  f =      -621.91  |proj g|=        5.5394
At iterate    15  f =      -621.91  |proj g|=        5.5483
At iterate    16  f =      -621.91  |proj g|=        5.5591
At iterate    17  f =      -621.91  |proj g|=        5.5786
At iterate    18  f =      -621.91  |proj g|=        5.6086
At iterate    19  f =      -621.92  |proj g|=        5.6572
At iterate    20  f =      -621.94  |proj g|=         5.734
At iterate    21  f =      -621.98  |proj g|=        5.8548
At iterate    22  f =       -622.1  |proj g|=         6.035
At iterate    23  f =      -622.38  |proj g|=        6.2727
At iterate    24  f =      -623.03  |proj g|=        6.4912
At iterate    25  f =      -624.31  |proj g|=        6.2939
At iterate    26  f =      -624.94  |proj g|=        5.6241
At iterate    27  f =      -625.11  |proj g|=        5.0928
At iterate    28  f =      -625.13  |proj g|=        5.3182
At iterate    29  f =      -625.13  |proj g|=        5.2801
At iterate    30  f =      -625.13  |proj g|=        5.2748
At iterate    31  f =      -625.13  |proj g|=        5.2755

iterations 31
function evaluations 35
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 5.27554
final function value -625.132

F = -625.132
final  value -625.131727 
converged
 
INFO  [09:25:43.025] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:25:43.224] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:25:43.232] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:25:52.381] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:26:01.324] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:26:12.108] [mlr3]  Finished benchmark 
INFO  [09:26:12.210] [bbotk] Result of batch 121: 
INFO  [09:26:12.212] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:26:12.212] [bbotk]              3.942942                 8.150065                       0.2088504 
INFO  [09:26:12.212] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:26:12.212] [bbotk]                     3832        1.026 -0.9534454         <NA>   0.9714675 
INFO  [09:26:12.212] [bbotk]                                 uhash 
INFO  [09:26:12.212] [bbotk]  386d5a6e-bca0-45cf-b4fd-97125fb72fd7 
DEBUG [09:26:13.510] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.180438e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.180438e-05 0.001291301 
  - best initial criterion value(s) :  604.3362 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -604.34  |proj g|=       0.7761
At iterate     1  f =      -617.97  |proj g|=        4.7822
At iterate     2  f =      -618.24  |proj g|=        4.5398
At iterate     3  f =      -618.43  |proj g|=        4.0215
At iterate     4  f =      -618.45  |proj g|=        4.0982
At iterate     5  f =       -618.5  |proj g|=        4.2138
At iterate     6  f =      -618.64  |proj g|=        4.4064
At iterate     7  f =      -618.87  |proj g|=        4.5843
At iterate     8  f =      -619.13  |proj g|=        4.6022
At iterate     9  f =      -619.23  |proj g|=         4.499
At iterate    10  f =      -619.26  |proj g|=        4.3905
At iterate    11  f =      -619.26  |proj g|=        4.3342
At iterate    12  f =      -619.26  |proj g|=        4.3284
At iterate    13  f =      -619.26  |proj g|=        4.3296
At iterate    14  f =      -619.26  |proj g|=        4.3294
At iterate    15  f =      -619.26  |proj g|=        4.3282
At iterate    16  f =      -619.26  |proj g|=        4.3267
At iterate    17  f =      -619.26  |proj g|=        4.3249
At iterate    18  f =      -619.26  |proj g|=        4.3256
At iterate    19  f =      -619.26  |proj g|=        4.3134
At iterate    20  f =      -619.26  |proj g|=        4.3136
At iterate    21  f =      -619.27  |proj g|=        4.3125
At iterate    22  f =       -619.3  |proj g|=        4.3001
At iterate    23  f =      -619.39  |proj g|=        4.2503
At iterate    24  f =      -619.65  |proj g|=        4.0926
At iterate    25  f =      -619.88  |proj g|=        3.0036
At iterate    26  f =      -620.88  |proj g|=        3.1518
At iterate    27  f =      -623.47  |proj g|=        2.6801
At iterate    28  f =      -628.13  |proj g|=        1.2606
At iterate    29  f =      -628.67  |proj g|=        1.1981
At iterate    30  f =      -630.03  |proj g|=       0.77001
At iterate    31  f =      -630.52  |proj g|=       0.76497
At iterate    32  f =      -630.59  |proj g|=       0.69177
At iterate    33  f =       -630.6  |proj g|=       0.61879
At iterate    34  f =       -630.6  |proj g|=       0.58366
At iterate    35  f =       -630.6  |proj g|=       0.57974
At iterate    36  f =       -630.6  |proj g|=       0.58072
At iterate    37  f =       -630.6  |proj g|=        0.5808

iterations 37
function evaluations 42
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.580804
final function value -630.6

F = -630.6
final  value -630.599812 
converged
 
INFO  [09:26:13.515] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:26:13.638] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:26:13.645] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:26:23.352] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:26:30.937] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:26:39.431] [mlr3]  Finished benchmark 
INFO  [09:26:39.536] [bbotk] Result of batch 122: 
INFO  [09:26:39.538] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:26:39.538] [bbotk]              3.128537                 5.507683                       0.3183089 
INFO  [09:26:39.538] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:26:39.538] [bbotk]                     3458        0.793 -0.9528289         <NA>   0.9689697 
INFO  [09:26:39.538] [bbotk]                                 uhash 
INFO  [09:26:39.538] [bbotk]  18176c04-c778-4b93-86a1-f3be39eb2754 
DEBUG [09:26:40.876] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.173769e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.173769e-05 0.001283928 
  - best initial criterion value(s) :  575.8235 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -575.82  |proj g|=       12.853
At iterate     1  f =      -599.14  |proj g|=        8.2311
At iterate     2  f =      -603.81  |proj g|=        6.8263
At iterate     3  f =      -604.47  |proj g|=        5.6793
At iterate     4  f =      -604.61  |proj g|=        5.1246
At iterate     5  f =      -604.64  |proj g|=        5.0181
At iterate     6  f =      -604.65  |proj g|=         5.017
At iterate     7  f =      -604.65  |proj g|=        5.0483
At iterate     8  f =      -604.65  |proj g|=         5.057
At iterate     9  f =      -604.65  |proj g|=        5.0587
At iterate    10  f =      -604.65  |proj g|=        5.0693
At iterate    11  f =      -604.65  |proj g|=        5.0799
At iterate    12  f =      -604.65  |proj g|=         5.097
At iterate    13  f =      -604.65  |proj g|=        5.1196
At iterate    14  f =      -604.66  |proj g|=        5.1518
At iterate    15  f =      -604.68  |proj g|=        5.1929
At iterate    16  f =      -604.73  |proj g|=        5.2365
At iterate    17  f =      -604.87  |proj g|=        5.2454
At iterate    18  f =      -605.22  |proj g|=        5.1076
At iterate    19  f =      -606.06  |proj g|=        4.5709
At iterate    20  f =      -607.86  |proj g|=        3.6623
At iterate    21  f =      -609.19  |proj g|=        2.7636
At iterate    22  f =      -609.32  |proj g|=        2.9697
At iterate    23  f =      -609.34  |proj g|=        2.9867
At iterate    24  f =      -609.84  |proj g|=        3.3349
At iterate    25  f =      -610.95  |proj g|=        3.6275
At iterate    26  f =       -614.4  |proj g|=        4.1192
At iterate    27  f =      -617.95  |proj g|=        3.9756
At iterate    28  f =      -623.12  |proj g|=        3.0026
At iterate    29  f =      -625.21  |proj g|=        1.2513
At iterate    30  f =      -625.65  |proj g|=        1.3248
At iterate    31  f =      -626.06  |proj g|=        1.5831
At iterate    32  f =      -626.85  |proj g|=        1.2942
At iterate    33  f =      -629.68  |proj g|=       0.88275
At iterate    34  f =      -629.72  |proj g|=        1.0394
At iterate    35  f =      -629.73  |proj g|=        1.1174
At iterate    36  f =      -629.73  |proj g|=        1.1238
At iterate    37  f =      -629.73  |proj g|=        1.1239

iterations 37
function evaluations 42
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.12393
final function value -629.733

F = -629.733
final  value -629.732564 
converged
 
INFO  [09:26:40.880] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:26:41.005] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:26:41.013] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:26:49.670] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:26:58.065] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:27:06.148] [mlr3]  Finished benchmark 
INFO  [09:27:06.293] [bbotk] Result of batch 123: 
INFO  [09:27:06.295] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:27:06.295] [bbotk]               4.83969                 4.079796                      0.03861018 
INFO  [09:27:06.295] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [09:27:06.295] [bbotk]                     3573        0.802 -0.957327         <NA>   0.9611537 
INFO  [09:27:06.295] [bbotk]                                 uhash 
INFO  [09:27:06.295] [bbotk]  0b957f05-8204-4f25-818a-7c3123053712 
DEBUG [09:27:07.467] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.167009e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.167009e-05 0.001277286 
  - best initial criterion value(s) :  577.7916 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -577.79  |proj g|=       7.5972
At iterate     1  f =       -625.5  |proj g|=        4.3706
At iterate     2  f =      -629.22  |proj g|=        4.6199
At iterate     3  f =      -633.93  |proj g|=         4.629
At iterate     4  f =         -636  |proj g|=        3.5762
At iterate     5  f =      -637.47  |proj g|=        1.4643
At iterate     6  f =      -637.67  |proj g|=        2.9908
At iterate     7  f =      -637.93  |proj g|=        2.5556
At iterate     8  f =      -637.95  |proj g|=        2.3008
At iterate     9  f =      -637.96  |proj g|=        2.3719
At iterate    10  f =      -637.96  |proj g|=        2.3676
At iterate    11  f =      -637.96  |proj g|=        2.3675

iterations 11
function evaluations 14
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.36749
final function value -637.958

F = -637.958
final  value -637.958234 
converged
 
INFO  [09:27:07.474] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:27:07.561] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:27:07.569] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:27:20.498] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:27:32.504] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:27:41.649] [mlr3]  Finished benchmark 
INFO  [09:27:41.795] [bbotk] Result of batch 124: 
INFO  [09:27:41.796] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:27:41.796] [bbotk]              3.267925                 8.140316                       0.3193929 
INFO  [09:27:41.796] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:27:41.796] [bbotk]                     4883         0.84 -0.9573301         <NA>   0.9714663 
INFO  [09:27:41.796] [bbotk]                                 uhash 
INFO  [09:27:41.796] [bbotk]  9c3a06ad-b176-46b2-9c44-b69d8afe3beb 
DEBUG [09:27:43.075] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.162232e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.162232e-05 0.00127024 
  - best initial criterion value(s) :  580.5881 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -580.59  |proj g|=       1.9407
At iterate     1  f =      -597.22  |proj g|=        8.1668
At iterate     2  f =      -597.46  |proj g|=        8.0015
At iterate     3  f =      -598.36  |proj g|=        6.9183
At iterate     4  f =      -601.17  |proj g|=        6.3909
At iterate     5  f =      -606.18  |proj g|=        5.3929
At iterate     6  f =      -606.34  |proj g|=         5.501
At iterate     7  f =      -606.35  |proj g|=        5.5623
At iterate     8  f =      -606.35  |proj g|=        5.5471
At iterate     9  f =      -606.35  |proj g|=        5.5337
At iterate    10  f =      -606.38  |proj g|=        5.4862
At iterate    11  f =      -606.44  |proj g|=        5.4349
At iterate    12  f =       -606.6  |proj g|=        5.3682
At iterate    13  f =      -606.99  |proj g|=        5.3274
At iterate    14  f =      -607.84  |proj g|=         5.449
At iterate    15  f =      -609.08  |proj g|=        5.9837
At iterate    16  f =      -610.08  |proj g|=        6.9606
At iterate    17  f =      -610.16  |proj g|=        7.1975
At iterate    18  f =      -610.17  |proj g|=        7.3293
At iterate    19  f =      -610.17  |proj g|=         7.336
At iterate    20  f =      -610.18  |proj g|=        7.3262
At iterate    21  f =      -610.18  |proj g|=        7.3009
At iterate    22  f =      -610.18  |proj g|=        7.2933
At iterate    23  f =      -610.18  |proj g|=         7.294
At iterate    24  f =      -610.18  |proj g|=        7.2954

iterations 24
function evaluations 31
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 7.29538
final function value -610.182

F = -610.182
final  value -610.182196 
converged
 
INFO  [09:27:43.079] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:27:43.168] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:27:43.175] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:27:45.516] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:27:47.921] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:27:50.320] [mlr3]  Finished benchmark 
INFO  [09:27:50.445] [bbotk] Result of batch 125: 
INFO  [09:27:50.447] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:27:50.447] [bbotk]              3.721259                 2.805706                      0.06291445 
INFO  [09:27:50.447] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:27:50.447] [bbotk]                     1400        0.817 -0.9615516         <NA>   0.9508693 
INFO  [09:27:50.447] [bbotk]                                 uhash 
INFO  [09:27:50.447] [bbotk]  1f29ff2c-1786-4c0a-830f-54259b40c694 
DEBUG [09:27:52.014] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.167387e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.167387e-05 0.001276892 
  - best initial criterion value(s) :  559.4198 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -559.42  |proj g|=       4.2128
At iterate     1  f =       -561.4  |proj g|=        8.0837
At iterate     2  f =      -569.64  |proj g|=          7.03
At iterate     3  f =      -578.41  |proj g|=        4.6628
At iterate     4  f =      -578.91  |proj g|=        3.9733
At iterate     5  f =      -579.13  |proj g|=        3.9223
At iterate     6  f =      -579.99  |proj g|=        4.0344
At iterate     7  f =      -580.61  |proj g|=        4.7433
At iterate     8  f =      -580.92  |proj g|=        5.3989
At iterate     9  f =      -580.95  |proj g|=        5.3028
At iterate    10  f =      -580.95  |proj g|=        5.2947
At iterate    11  f =      -580.95  |proj g|=        5.2939
At iterate    12  f =      -580.95  |proj g|=        5.2973
At iterate    13  f =      -580.95  |proj g|=        5.3092
At iterate    14  f =      -580.95  |proj g|=        5.3167
At iterate    15  f =      -580.95  |proj g|=        5.3347
At iterate    16  f =      -580.96  |proj g|=        5.3647
At iterate    17  f =      -580.96  |proj g|=        5.4137
At iterate    18  f =      -580.97  |proj g|=        5.4824
At iterate    19  f =      -581.01  |proj g|=        5.5785
At iterate    20  f =      -581.02  |proj g|=        5.6909
At iterate    21  f =      -581.11  |proj g|=        5.7733
At iterate    22  f =      -582.39  |proj g|=        5.7597
At iterate    23  f =       -585.2  |proj g|=        5.2716
At iterate    24  f =      -592.36  |proj g|=        2.1262
At iterate    25  f =      -599.31  |proj g|=       0.71714
At iterate    26  f =       -600.6  |proj g|=        0.6595
At iterate    27  f =      -600.65  |proj g|=       0.70314
At iterate    28  f =      -601.41  |proj g|=       0.85319
At iterate    29  f =      -601.48  |proj g|=       0.86741
At iterate    30  f =      -601.48  |proj g|=       0.90148
At iterate    31  f =      -601.48  |proj g|=       0.89731
At iterate    32  f =      -601.48  |proj g|=       0.89651
At iterate    33  f =      -601.48  |proj g|=       0.89602

iterations 33
function evaluations 45
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.896017
final function value -601.482

F = -601.482
final  value -601.482189 
converged
 
INFO  [09:27:52.019] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:27:52.121] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:27:52.130] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:27:59.122] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:28:05.448] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:28:11.903] [mlr3]  Finished benchmark 
INFO  [09:28:12.076] [bbotk] Result of batch 126: 
INFO  [09:28:12.078] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:28:12.078] [bbotk]              3.406926                 4.765123                       0.1776756 
INFO  [09:28:12.078] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:28:12.078] [bbotk]                     3895        1.008 -0.9632114         <NA>   0.9685006 
INFO  [09:28:12.078] [bbotk]                                 uhash 
INFO  [09:28:12.078] [bbotk]  9aa8f46e-e0d0-4f05-93f6-f4ea3730662b 
DEBUG [09:28:13.562] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.160763e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.160763e-05 0.001270465 
  - best initial criterion value(s) :  608.9359 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -608.94  |proj g|=       6.5552
At iterate     1  f =      -634.45  |proj g|=        3.2008
At iterate     2  f =      -649.84  |proj g|=        8.0058
At iterate     3  f =      -650.91  |proj g|=        7.6697
At iterate     4  f =      -652.66  |proj g|=        6.5928
At iterate     5  f =      -652.97  |proj g|=        6.2244
At iterate     6  f =      -653.23  |proj g|=        6.1582
At iterate     7  f =      -653.42  |proj g|=        6.3307
At iterate     8  f =      -653.47  |proj g|=        6.5364
At iterate     9  f =      -653.47  |proj g|=        6.5278
At iterate    10  f =      -653.47  |proj g|=         6.553
At iterate    11  f =      -653.47  |proj g|=        6.5386
At iterate    12  f =      -653.47  |proj g|=        6.5342
At iterate    13  f =      -653.47  |proj g|=        6.5198
At iterate    14  f =      -653.48  |proj g|=        6.4963
At iterate    15  f =      -653.48  |proj g|=        6.4581
At iterate    16  f =      -653.48  |proj g|=        6.3953
At iterate    17  f =       -653.5  |proj g|=        6.2935
At iterate    18  f =      -653.54  |proj g|=        6.1409
At iterate    19  f =      -653.62  |proj g|=        5.9212
At iterate    20  f =      -653.81  |proj g|=        5.5828
At iterate    21  f =      -654.22  |proj g|=        5.2107
At iterate    22  f =      -654.33  |proj g|=        4.6614
At iterate    23  f =      -655.16  |proj g|=        4.2534
At iterate    24  f =      -658.89  |proj g|=         3.249
At iterate    25  f =      -670.01  |proj g|=        2.5423
At iterate    26  f =      -671.01  |proj g|=        2.4421
At iterate    27  f =      -671.59  |proj g|=        1.3927
At iterate    28  f =      -671.81  |proj g|=        1.7927
At iterate    29  f =      -671.85  |proj g|=        1.6619
At iterate    30  f =      -671.85  |proj g|=        1.6521
At iterate    31  f =      -671.85  |proj g|=        1.6484
At iterate    32  f =      -671.85  |proj g|=        1.6502
At iterate    33  f =      -671.85  |proj g|=        1.6521
At iterate    34  f =      -671.85  |proj g|=        1.6564
At iterate    35  f =      -671.85  |proj g|=        1.6613
At iterate    36  f =      -671.85  |proj g|=        1.6704
At iterate    37  f =      -671.85  |proj g|=        1.6839
At iterate    38  f =      -671.85  |proj g|=        1.7051
At iterate    39  f =      -671.86  |proj g|=        1.7333
At iterate    40  f =      -671.87  |proj g|=        1.7564
At iterate    41  f =      -671.88  |proj g|=        1.8405
At iterate    42  f =      -671.91  |proj g|=         1.817
At iterate    43  f =      -672.02  |proj g|=        1.7194
At iterate    44  f =       -672.2  |proj g|=        1.5819
At iterate    45  f =      -672.63  |proj g|=        1.2749
At iterate    46  f =      -673.32  |proj g|=       0.86833
At iterate    47  f =      -673.69  |proj g|=       0.32249
At iterate    48  f =      -674.75  |proj g|=       0.27733
At iterate    49  f =      -675.42  |proj g|=       0.26824
At iterate    50  f =      -675.53  |proj g|=       0.26862
At iterate    51  f =      -675.56  |proj g|=      0.077129
At iterate    52  f =      -675.56  |proj g|=      0.019604
At iterate    53  f =      -675.56  |proj g|=      0.066838
At iterate    54  f =      -675.56  |proj g|=       0.14554
At iterate    55  f =      -675.56  |proj g|=      0.066372
At iterate    56  f =      -675.56  |proj g|=     0.0026047

iterations 56
function evaluations 64
segments explored during Cauchy searches 59
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0026047
final function value -675.558

F = -675.558
final  value -675.558148 
converged
 
INFO  [09:28:13.566] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:28:13.654] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:28:13.661] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:28:15.824] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:28:18.100] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:28:20.353] [mlr3]  Finished benchmark 
INFO  [09:28:20.453] [bbotk] Result of batch 127: 
INFO  [09:28:20.455] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:28:20.455] [bbotk]              9.236118                 3.118109                       0.1869664 
INFO  [09:28:20.455] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:28:20.455] [bbotk]                     1305          0.8 -0.9431969         <NA>    0.968053 
INFO  [09:28:20.455] [bbotk]                                 uhash 
INFO  [09:28:20.455] [bbotk]  da369b58-6ddd-449a-9aaf-cfcb7465d98d 
DEBUG [09:28:21.800] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.154018e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.154018e-05 0.001260951 
  - best initial criterion value(s) :  621.1586 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -621.16  |proj g|=       7.1227
At iterate     1  f =      -630.08  |proj g|=        6.5441
At iterate     2  f =      -638.36  |proj g|=        6.3038
At iterate     3  f =      -648.46  |proj g|=        5.0116
At iterate     4  f =      -648.95  |proj g|=        4.6836
At iterate     5  f =      -649.93  |proj g|=        4.7054
At iterate     6  f =      -650.53  |proj g|=        5.2612
At iterate     7  f =      -653.69  |proj g|=        5.2984
At iterate     8  f =      -654.13  |proj g|=        5.4309
At iterate     9  f =      -654.24  |proj g|=        5.5658
At iterate    10  f =      -654.28  |proj g|=        5.6738
At iterate    11  f =      -654.29  |proj g|=        5.7348
At iterate    12  f =      -654.29  |proj g|=        5.7517
At iterate    13  f =      -654.29  |proj g|=        5.7642
At iterate    14  f =      -654.29  |proj g|=        5.7948
At iterate    15  f =       -654.3  |proj g|=        5.8331
At iterate    16  f =      -654.33  |proj g|=        5.8978
At iterate    17  f =      -654.39  |proj g|=        5.9846
At iterate    18  f =      -654.53  |proj g|=        6.0779
At iterate    19  f =      -654.74  |proj g|=        6.0406
At iterate    20  f =       -654.8  |proj g|=        5.9086
At iterate    21  f =      -654.81  |proj g|=        5.8705
At iterate    22  f =      -654.81  |proj g|=         5.847
At iterate    23  f =      -654.82  |proj g|=        5.8091
At iterate    24  f =      -654.84  |proj g|=        5.7502
At iterate    25  f =      -654.87  |proj g|=        5.6766
At iterate    26  f =      -654.94  |proj g|=        5.5974
At iterate    27  f =       -655.1  |proj g|=        5.2519
At iterate    28  f =      -655.41  |proj g|=        5.1607
At iterate    29  f =      -655.76  |proj g|=        4.7599
At iterate    30  f =      -656.66  |proj g|=        4.8522
At iterate    31  f =      -656.74  |proj g|=        4.9617
At iterate    32  f =      -656.74  |proj g|=        4.9555
At iterate    33  f =      -656.74  |proj g|=        4.9598
At iterate    34  f =      -656.74  |proj g|=        4.9569
At iterate    35  f =      -656.74  |proj g|=        4.9568

iterations 35
function evaluations 41
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.95676
final function value -656.739

F = -656.739
final  value -656.738847 
converged
 
INFO  [09:28:21.804] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:28:21.909] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:28:21.916] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:28:24.562] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:28:27.362] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:28:30.153] [mlr3]  Finished benchmark 
INFO  [09:28:30.253] [bbotk] Result of batch 128: 
INFO  [09:28:30.255] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:28:30.255] [bbotk]              4.584693                  9.58101                         0.28722 
INFO  [09:28:30.255] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:28:30.255] [bbotk]                     1741        0.818 -0.9524145         <NA>    0.970677 
INFO  [09:28:30.255] [bbotk]                                 uhash 
INFO  [09:28:30.255] [bbotk]  f3411b79-62d1-48ba-96bb-7be62ac20481 
DEBUG [09:28:31.523] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.148833e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.148833e-05 0.001256754 
  - best initial criterion value(s) :  628.2553 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -628.26  |proj g|=       1.9766
At iterate     1  f =      -638.12  |proj g|=         3.069
At iterate     2  f =      -638.47  |proj g|=        2.8512
At iterate     3  f =      -638.97  |proj g|=        2.2708
At iterate     4  f =         -639  |proj g|=        1.9598
At iterate     5  f =      -639.01  |proj g|=        2.0646
At iterate     6  f =      -639.01  |proj g|=        2.0563
At iterate     7  f =      -639.01  |proj g|=        2.0559

iterations 7
function evaluations 11
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.05594
final function value -639.009

F = -639.009
final  value -639.008657 
converged
 
INFO  [09:28:31.527] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:28:31.615] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:28:31.622] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:28:35.564] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:28:39.674] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:28:43.747] [mlr3]  Finished benchmark 
INFO  [09:28:43.868] [bbotk] Result of batch 129: 
INFO  [09:28:43.870] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:28:43.870] [bbotk]              7.288737                 2.170416                       0.2037974 
INFO  [09:28:43.870] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:28:43.870] [bbotk]                     2573        0.932 -0.9610669         <NA>   0.9718838 
INFO  [09:28:43.870] [bbotk]                                 uhash 
INFO  [09:28:43.870] [bbotk]  28f40322-46bc-4033-a4c5-68e8eeda2c12 
DEBUG [09:28:45.216] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.144648e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.144648e-05 0.001255877 
  - best initial criterion value(s) :  636.6659 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -636.67  |proj g|=       3.9875
At iterate     1  f =      -665.84  |proj g|=       0.94349
At iterate     2  f =      -672.97  |proj g|=        2.3318
At iterate     3  f =      -676.96  |proj g|=       0.79195
At iterate     4  f =      -678.09  |proj g|=        1.2404
At iterate     5  f =      -678.13  |proj g|=        1.4448
At iterate     6  f =      -678.15  |proj g|=        1.3928
At iterate     7  f =      -678.15  |proj g|=        1.3672
At iterate     8  f =      -678.16  |proj g|=         1.383
At iterate     9  f =      -678.16  |proj g|=        1.3807
At iterate    10  f =      -678.16  |proj g|=        1.3809

iterations 10
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.38085
final function value -678.156

F = -678.156
final  value -678.155770 
converged
 
INFO  [09:28:45.220] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:28:45.307] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:28:45.313] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:28:50.869] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:28:58.769] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:29:05.745] [mlr3]  Finished benchmark 
INFO  [09:29:05.867] [bbotk] Result of batch 130: 
INFO  [09:29:05.869] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:29:05.869] [bbotk]              7.497188                 2.619104                       0.2499633 
INFO  [09:29:05.869] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:29:05.869] [bbotk]                     3458        0.981 -0.9522581         <NA>   0.9734939 
INFO  [09:29:05.869] [bbotk]                                 uhash 
INFO  [09:29:05.869] [bbotk]  bd78254d-831b-4eec-8ab5-4fe1a1153a63 
DEBUG [09:29:07.252] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.142025e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.142025e-05 0.001254149 
  - best initial criterion value(s) :  638.2208 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -638.22  |proj g|=        13.24
At iterate     1  f =      -668.48  |proj g|=        2.5357
At iterate     2  f =      -670.85  |proj g|=        5.4025
At iterate     3  f =      -671.27  |proj g|=        4.8729
At iterate     4  f =      -671.35  |proj g|=        4.4947
At iterate     5  f =      -671.36  |proj g|=        4.5675
At iterate     6  f =      -671.37  |proj g|=        4.6689
At iterate     7  f =      -671.37  |proj g|=        4.6979
At iterate     8  f =      -671.37  |proj g|=        4.6917
At iterate     9  f =      -671.37  |proj g|=        4.6835
At iterate    10  f =      -671.37  |proj g|=        4.6758
At iterate    11  f =      -671.37  |proj g|=        4.6603
At iterate    12  f =      -671.38  |proj g|=        4.6361
At iterate    13  f =      -671.38  |proj g|=        4.5967
At iterate    14  f =       -671.4  |proj g|=        4.5368
At iterate    15  f =      -671.45  |proj g|=        4.4503
At iterate    16  f =      -671.56  |proj g|=        4.3488
At iterate    17  f =      -671.82  |proj g|=        4.3068
At iterate    18  f =      -672.32  |proj g|=        4.5605
At iterate    19  f =      -672.63  |proj g|=        5.7031
At iterate    20  f =      -672.69  |proj g|=        5.3672
At iterate    21  f =      -672.74  |proj g|=        5.2618
At iterate    22  f =      -672.89  |proj g|=        5.0453
At iterate    23  f =      -673.54  |proj g|=        4.3399
At iterate    24  f =      -675.04  |proj g|=        3.3146
At iterate    25  f =      -679.98  |proj g|=        1.4134
At iterate    26  f =      -685.11  |proj g|=        1.3266
At iterate    27  f =      -687.09  |proj g|=        1.1098
At iterate    28  f =      -687.77  |proj g|=        1.5342
At iterate    29  f =      -688.84  |proj g|=        1.3687
At iterate    30  f =      -689.13  |proj g|=         1.335
At iterate    31  f =      -689.13  |proj g|=        1.3528
At iterate    32  f =      -689.21  |proj g|=        1.3624
At iterate    33  f =      -689.24  |proj g|=        1.3885
At iterate    34  f =      -689.25  |proj g|=        1.4194
At iterate    35  f =      -689.25  |proj g|=        1.4171
At iterate    36  f =      -689.25  |proj g|=        1.4176

iterations 36
function evaluations 42
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.41762
final function value -689.25

F = -689.25
final  value -689.250425 
converged
 
INFO  [09:29:07.256] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:29:07.345] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:29:07.352] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:29:09.379] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:29:11.339] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:29:14.330] [mlr3]  Finished benchmark 
INFO  [09:29:14.433] [bbotk] Result of batch 131: 
INFO  [09:29:14.435] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:29:14.435] [bbotk]              4.019059                 3.237391                      0.05967796 
INFO  [09:29:14.435] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:29:14.435] [bbotk]                      668        0.826 -0.9469782         <NA>    0.938718 
INFO  [09:29:14.435] [bbotk]                                 uhash 
INFO  [09:29:14.435] [bbotk]  c7db3969-170c-4a0a-a612-a273e875901d 
DEBUG [09:29:15.945] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.177589e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.177589e-05 0.001301658 
  - best initial criterion value(s) :  630.9732 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -630.97  |proj g|=       12.846
At iterate     1  f =      -654.28  |proj g|=        6.3284
At iterate     2  f =      -655.98  |proj g|=        6.1245
At iterate     3  f =      -656.88  |proj g|=        5.1048
At iterate     4  f =      -657.08  |proj g|=        4.8214
At iterate     5  f =      -657.12  |proj g|=        4.7731
At iterate     6  f =      -657.12  |proj g|=        4.7933
At iterate     7  f =      -657.12  |proj g|=        4.8109
At iterate     8  f =      -657.12  |proj g|=        4.8125
At iterate     9  f =      -657.12  |proj g|=        4.8151
At iterate    10  f =      -657.12  |proj g|=        4.8193
At iterate    11  f =      -657.12  |proj g|=         4.826
At iterate    12  f =      -657.12  |proj g|=        4.8367
At iterate    13  f =      -657.13  |proj g|=        4.8536
At iterate    14  f =      -657.13  |proj g|=        4.8798
At iterate    15  f =      -657.14  |proj g|=        4.9193
At iterate    16  f =      -657.16  |proj g|=        4.9736
At iterate    17  f =      -657.23  |proj g|=         5.033
At iterate    18  f =       -657.4  |proj g|=        5.0472
At iterate    19  f =      -657.86  |proj g|=        4.8551
At iterate    20  f =      -658.95  |proj g|=        4.0853
At iterate    21  f =      -660.02  |proj g|=        3.0027
At iterate    22  f =      -660.52  |proj g|=         2.286
At iterate    23  f =      -660.52  |proj g|=        2.2409
At iterate    24  f =      -660.53  |proj g|=        2.2159
At iterate    25  f =      -660.53  |proj g|=        2.2058
At iterate    26  f =      -660.54  |proj g|=        2.1802
At iterate    27  f =      -660.55  |proj g|=        2.1422
At iterate    28  f =       -660.6  |proj g|=        2.0715
At iterate    29  f =      -660.74  |proj g|=        1.9683
At iterate    30  f =      -661.09  |proj g|=        1.8161
At iterate    31  f =      -661.96  |proj g|=        1.6483
At iterate    32  f =      -664.04  |proj g|=        1.6699
At iterate    33  f =      -666.62  |proj g|=         2.801
At iterate    34  f =      -666.75  |proj g|=        2.8069
At iterate    35  f =      -669.39  |proj g|=        1.3004
At iterate    36  f =      -672.06  |proj g|=        1.6032
At iterate    37  f =      -673.28  |proj g|=        1.8737
At iterate    38  f =      -673.63  |proj g|=        1.7431
At iterate    39  f =       -673.7  |proj g|=         1.911
At iterate    40  f =      -673.76  |proj g|=        1.8478
At iterate    41  f =      -673.76  |proj g|=        1.8455
At iterate    42  f =      -673.76  |proj g|=          1.84
At iterate    43  f =      -673.76  |proj g|=        1.8459
At iterate    44  f =      -673.76  |proj g|=        1.8465

iterations 44
function evaluations 52
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.84653
final function value -673.764

F = -673.764
final  value -673.764095 
converged
 
INFO  [09:29:15.949] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:29:16.037] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:29:16.044] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:29:17.141] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:29:18.606] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:29:19.704] [mlr3]  Finished benchmark 
INFO  [09:29:19.806] [bbotk] Result of batch 132: 
INFO  [09:29:19.808] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:29:19.808] [bbotk]                4.7893                  5.92538                       0.1783016 
INFO  [09:29:19.808] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:29:19.808] [bbotk]                      224        0.861 -0.9526534         <NA>   0.9428935 
INFO  [09:29:19.808] [bbotk]                                 uhash 
INFO  [09:29:19.808] [bbotk]  8fb1e419-f225-4a8f-90d0-59db85456f18 
DEBUG [09:29:20.997] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.199878e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.199878e-05 0.001336561 
  - best initial criterion value(s) :  661.0672 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -661.07  |proj g|=       1.7343
At iterate     1  f =      -664.08  |proj g|=        3.3834
At iterate     2  f =      -664.09  |proj g|=        3.3453
At iterate     3  f =       -664.2  |proj g|=        3.0821
At iterate     4  f =       -664.3  |proj g|=         2.907
At iterate     5  f =      -664.57  |proj g|=        2.5298
At iterate     6  f =      -664.68  |proj g|=        2.5638
At iterate     7  f =      -664.69  |proj g|=        2.6085
At iterate     8  f =      -664.69  |proj g|=        2.6127
At iterate     9  f =      -664.69  |proj g|=        2.6129

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.61286
final function value -664.69

F = -664.69
final  value -664.689982 
converged
 
INFO  [09:29:21.001] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:29:21.089] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:29:21.097] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:29:26.136] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:29:32.179] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:29:38.286] [mlr3]  Finished benchmark 
INFO  [09:29:38.427] [bbotk] Result of batch 133: 
INFO  [09:29:38.429] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:29:38.429] [bbotk]              3.011233                  9.45173                       0.3175595 
INFO  [09:29:38.429] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:29:38.429] [bbotk]                     2418         0.85 -0.9591158         <NA>   0.9662281 
INFO  [09:29:38.429] [bbotk]                                 uhash 
INFO  [09:29:38.429] [bbotk]  92defb7b-10eb-4e1a-8335-7b63e06cad5b 
DEBUG [09:29:39.885] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.192657e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.192657e-05 0.001330793 
  - best initial criterion value(s) :  631.998 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -632  |proj g|=       7.3537
At iterate     1  f =      -664.63  |proj g|=        9.1913
At iterate     2  f =      -666.68  |proj g|=        9.1057
At iterate     3  f =       -668.3  |proj g|=         8.183
At iterate     4  f =      -668.75  |proj g|=         8.678
At iterate     5  f =      -668.79  |proj g|=         8.594
At iterate     6  f =      -668.79  |proj g|=        8.5816
At iterate     7  f =       -668.8  |proj g|=        8.5947
At iterate     8  f =      -668.83  |proj g|=        8.4391
At iterate     9  f =      -670.19  |proj g|=        8.4038
At iterate    10  f =       -674.6  |proj g|=        7.4434
At iterate    11  f =      -679.82  |proj g|=        5.6246
At iterate    12  f =      -680.63  |proj g|=        4.7802
At iterate    13  f =       -681.3  |proj g|=        4.9862
At iterate    14  f =      -681.32  |proj g|=        5.0849
At iterate    15  f =      -681.32  |proj g|=        4.9991
At iterate    16  f =      -681.32  |proj g|=        4.9993
At iterate    17  f =      -681.32  |proj g|=        4.9997

iterations 17
function evaluations 24
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.99973
final function value -681.323

F = -681.323
final  value -681.322503 
converged
 
INFO  [09:29:39.890] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:29:39.979] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:29:39.987] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:29:50.978] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:30:01.250] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:30:11.899] [mlr3]  Finished benchmark 
INFO  [09:30:12.043] [bbotk] Result of batch 134: 
INFO  [09:30:12.045] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:30:12.045] [bbotk]              3.715901                 4.718512                       0.1997076 
INFO  [09:30:12.045] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:30:12.045] [bbotk]                     4542        1.019 -0.9520217         <NA>   0.9713027 
INFO  [09:30:12.045] [bbotk]                                 uhash 
INFO  [09:30:12.045] [bbotk]  7a170f3b-8fa8-44f9-b876-1f55a9276386 
DEBUG [09:30:13.373] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.188013e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.188013e-05 0.001327557 
  - best initial criterion value(s) :  625.7241 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -625.72  |proj g|=       7.5995
At iterate     1  f =      -673.42  |proj g|=        5.2066
At iterate     2  f =      -674.25  |proj g|=        6.3522
At iterate     3  f =      -674.27  |proj g|=        6.2808
At iterate     4  f =       -674.3  |proj g|=        6.1972
At iterate     5  f =       -674.3  |proj g|=        6.2044
At iterate     6  f =       -674.3  |proj g|=        6.2135
At iterate     7  f =       -674.3  |proj g|=        6.2168
At iterate     8  f =       -674.3  |proj g|=         6.224
At iterate     9  f =       -674.3  |proj g|=        6.2323
At iterate    10  f =      -674.31  |proj g|=        6.2373
At iterate    11  f =      -674.32  |proj g|=        6.2212
At iterate    12  f =      -674.35  |proj g|=        6.1353
At iterate    13  f =      -674.36  |proj g|=        6.2191
At iterate    14  f =      -674.42  |proj g|=        6.0885
At iterate    15  f =      -674.92  |proj g|=        5.7771
At iterate    16  f =      -679.44  |proj g|=        4.1892
At iterate    17  f =      -689.86  |proj g|=        2.5685
At iterate    18  f =      -696.61  |proj g|=        3.1491
At iterate    19  f =      -700.94  |proj g|=          2.16
At iterate    20  f =      -711.59  |proj g|=        1.8104
At iterate    21  f =         -713  |proj g|=        1.2359
At iterate    22  f =      -713.01  |proj g|=        1.2359
At iterate    23  f =      -713.11  |proj g|=        1.2359
At iterate    24  f =      -713.11  |proj g|=        1.2359

iterations 24
function evaluations 31
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.2359
final function value -713.114

F = -713.114
final  value -713.114346 
converged
 
INFO  [09:30:13.377] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:30:13.468] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:30:13.475] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:30:26.277] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:30:37.118] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:30:47.760] [mlr3]  Finished benchmark 
INFO  [09:30:47.865] [bbotk] Result of batch 135: 
INFO  [09:30:47.866] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:30:47.866] [bbotk]              2.854888                 8.208306                       0.2894927 
INFO  [09:30:47.866] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:30:47.866] [bbotk]                     4570        0.851 -0.9411795         <NA>   0.9678343 
INFO  [09:30:47.866] [bbotk]                                 uhash 
INFO  [09:30:47.866] [bbotk]  d46ec9b7-52aa-4b4f-a398-8df35ef9644a 
DEBUG [09:30:49.310] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.181383e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.181383e-05 0.001319234 
  - best initial criterion value(s) :  627.4637 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -627.46  |proj g|=       7.2033
At iterate     1  f =         -665  |proj g|=        11.336
At iterate     2  f =      -667.78  |proj g|=        10.469
At iterate     3  f =      -680.74  |proj g|=        5.9114
At iterate     4  f =      -685.86  |proj g|=        4.0941
At iterate     5  f =      -686.17  |proj g|=        3.7914
At iterate     6  f =      -686.17  |proj g|=        3.7805
At iterate     7  f =      -686.17  |proj g|=        3.7818
At iterate     8  f =      -686.17  |proj g|=        3.7829
At iterate     9  f =      -686.17  |proj g|=        3.7891
At iterate    10  f =      -686.17  |proj g|=        3.7942
At iterate    11  f =      -686.17  |proj g|=        3.8051
At iterate    12  f =      -686.18  |proj g|=        3.8224
At iterate    13  f =      -686.18  |proj g|=        3.8508
At iterate    14  f =       -686.2  |proj g|=        3.8943
At iterate    15  f =      -686.24  |proj g|=        3.9524
At iterate    16  f =       -686.3  |proj g|=        4.0031
At iterate    17  f =      -686.33  |proj g|=        4.1226
At iterate    18  f =      -686.47  |proj g|=        4.1423
At iterate    19  f =      -687.05  |proj g|=        4.1965
At iterate    20  f =      -688.33  |proj g|=        4.2941
At iterate    21  f =      -690.44  |proj g|=        4.3998
At iterate    22  f =      -691.61  |proj g|=        4.4193
At iterate    23  f =      -691.61  |proj g|=        4.6382
At iterate    24  f =      -691.92  |proj g|=        4.5412
At iterate    25  f =         -692  |proj g|=        4.5169
At iterate    26  f =         -692  |proj g|=        4.5287
At iterate    27  f =         -692  |proj g|=         4.535
At iterate    28  f =         -692  |proj g|=        4.5372
At iterate    29  f =         -692  |proj g|=        4.5376
At iterate    30  f =         -692  |proj g|=        4.5385

iterations 30
function evaluations 40
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.53848
final function value -692.002

F = -692.002
final  value -692.002015 
converged
 
INFO  [09:30:49.314] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:30:49.450] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:30:49.458] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:30:51.024] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:30:52.340] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:30:53.977] [mlr3]  Finished benchmark 
INFO  [09:30:54.083] [bbotk] Result of batch 136: 
INFO  [09:30:54.084] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:30:54.084] [bbotk]              8.520588                 9.320553                      0.03598605 
INFO  [09:30:54.084] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:30:54.084] [bbotk]                      526        0.849 -0.9524074         <NA>   0.9326211 
INFO  [09:30:54.084] [bbotk]                                 uhash 
INFO  [09:30:54.084] [bbotk]  3c9e220e-03e5-4ae9-ae0b-7183c6fee04a 
DEBUG [09:30:55.471] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.23618e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.23618e-05 0.001397529 
  - best initial criterion value(s) :  672.105 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -672.1  |proj g|=       5.8046
At iterate     1  f =      -681.19  |proj g|=        8.1313
At iterate     2  f =      -682.56  |proj g|=        8.0087
At iterate     3  f =      -683.41  |proj g|=        6.9994
At iterate     4  f =      -683.78  |proj g|=        7.3361
At iterate     5  f =      -683.91  |proj g|=        7.1717
At iterate     6  f =      -684.27  |proj g|=        6.3499
At iterate     7  f =      -684.28  |proj g|=        6.3634
At iterate     8  f =      -684.28  |proj g|=         6.362
At iterate     9  f =      -684.28  |proj g|=        6.3617
At iterate    10  f =      -684.28  |proj g|=        6.3602
At iterate    11  f =      -684.28  |proj g|=        6.3582
At iterate    12  f =      -684.29  |proj g|=        6.3537
At iterate    13  f =       -684.3  |proj g|=        6.3427
At iterate    14  f =      -684.32  |proj g|=        6.3057
At iterate    15  f =      -684.36  |proj g|=        6.2254
At iterate    16  f =      -684.47  |proj g|=        6.0772
At iterate    17  f =      -684.73  |proj g|=        5.7848
At iterate    18  f =      -684.74  |proj g|=        5.8776
At iterate    19  f =      -685.72  |proj g|=        5.3552
At iterate    20  f =      -687.52  |proj g|=        4.2923
At iterate    21  f =      -690.58  |proj g|=        3.4183
At iterate    22  f =      -699.96  |proj g|=        3.8255
At iterate    23  f =      -703.71  |proj g|=        4.9422
At iterate    24  f =      -703.75  |proj g|=        4.7075
At iterate    25  f =      -704.76  |proj g|=        5.5915
At iterate    26  f =      -704.97  |proj g|=        5.8439
At iterate    27  f =      -704.98  |proj g|=         5.895
At iterate    28  f =      -704.98  |proj g|=        5.9107
At iterate    29  f =      -704.98  |proj g|=        5.9123
At iterate    30  f =      -704.98  |proj g|=        5.9126

iterations 30
function evaluations 33
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 5.9126
final function value -704.981

F = -704.981
final  value -704.980664 
converged
 
INFO  [09:30:55.475] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:30:55.606] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:30:55.614] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:30:58.253] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:31:01.091] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:31:03.969] [mlr3]  Finished benchmark 
INFO  [09:31:04.121] [bbotk] Result of batch 137: 
INFO  [09:31:04.123] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:31:04.123] [bbotk]              8.961981                  7.94121                       0.4253839 
INFO  [09:31:04.123] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:31:04.123] [bbotk]                     1076        0.865 -0.9536835         <NA>   0.9710855 
INFO  [09:31:04.123] [bbotk]                                 uhash 
INFO  [09:31:04.123] [bbotk]  330c8b58-3a4e-4956-b028-99bd660f1c24 
DEBUG [09:31:05.825] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.231294e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.231294e-05 0.001387263 
  - best initial criterion value(s) :  665.4451 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -665.45  |proj g|=       3.9856
At iterate     1  f =      -694.86  |proj g|=        10.034
At iterate     2  f =      -700.23  |proj g|=        8.7807
At iterate     3  f =      -705.55  |proj g|=        4.4092
At iterate     4  f =      -707.02  |proj g|=        5.6277
At iterate     5  f =      -708.17  |proj g|=        5.7588
At iterate     6  f =      -714.36  |proj g|=        4.9237
At iterate     7  f =      -715.52  |proj g|=        4.6993
At iterate     8  f =      -715.55  |proj g|=        4.8795
At iterate     9  f =      -715.55  |proj g|=        4.8785
At iterate    10  f =      -715.55  |proj g|=        4.8734
At iterate    11  f =      -715.55  |proj g|=        4.8665
At iterate    12  f =      -715.55  |proj g|=        4.8543
At iterate    13  f =      -715.55  |proj g|=         4.835
At iterate    14  f =      -715.55  |proj g|=        4.8029
At iterate    15  f =      -715.56  |proj g|=        4.7502
At iterate    16  f =      -715.59  |proj g|=        4.6623
At iterate    17  f =      -715.65  |proj g|=        4.5236
At iterate    18  f =      -715.79  |proj g|=        4.3419
At iterate    19  f =      -716.03  |proj g|=        4.2459
At iterate    20  f =       -716.1  |proj g|=          4.88
At iterate    21  f =      -716.19  |proj g|=        4.5849
At iterate    22  f =      -716.19  |proj g|=        4.5486
At iterate    23  f =      -716.19  |proj g|=         4.554
At iterate    24  f =      -716.19  |proj g|=        4.5538
At iterate    25  f =      -716.19  |proj g|=        4.5477
At iterate    26  f =      -716.19  |proj g|=        4.5197
At iterate    27  f =      -716.21  |proj g|=        4.4554
At iterate    28  f =      -716.26  |proj g|=        4.3554
At iterate    29  f =      -716.38  |proj g|=        4.2221
At iterate    30  f =      -716.41  |proj g|=        4.0308
At iterate    31  f =       -716.7  |proj g|=        3.8275
At iterate    32  f =      -726.67  |proj g|=       0.75055
At iterate    33  f =      -730.07  |proj g|=       0.29866
At iterate    34  f =      -730.55  |proj g|=       0.70532
At iterate    35  f =      -730.67  |proj g|=       0.28003
At iterate    36  f =      -730.79  |proj g|=       0.69458
At iterate    37  f =      -730.93  |proj g|=       0.68468
At iterate    38  f =      -730.95  |proj g|=       0.51295
At iterate    39  f =      -730.95  |proj g|=     0.0052643
At iterate    40  f =      -730.95  |proj g|=     0.0061496
At iterate    41  f =      -730.95  |proj g|=     0.0022654

iterations 41
function evaluations 51
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00226542
final function value -730.95

F = -730.95
final  value -730.949510 
converged
 
INFO  [09:31:05.829] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:31:05.921] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:31:05.928] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:31:11.581] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:31:16.152] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:31:19.183] [mlr3]  Finished benchmark 
INFO  [09:31:19.284] [bbotk] Result of batch 138: 
INFO  [09:31:19.286] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:31:19.286] [bbotk]              5.893008                 3.718813                       0.2504589 
INFO  [09:31:19.286] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:31:19.286] [bbotk]                     1855        0.847 -0.9396971         <NA>   0.9712833 
INFO  [09:31:19.286] [bbotk]                                 uhash 
INFO  [09:31:19.286] [bbotk]  1af245de-3275-4424-8ab0-b0c77abe2959 
DEBUG [09:31:20.959] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.22659e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.22659e-05 0.001380459 
  - best initial criterion value(s) :  656.3398 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -656.34  |proj g|=       7.7322
At iterate     1  f =      -673.66  |proj g|=        6.8161
At iterate     2  f =      -683.46  |proj g|=         6.531
At iterate     3  f =      -697.44  |proj g|=        5.1879
At iterate     4  f =      -699.34  |proj g|=        4.2513
At iterate     5  f =      -701.43  |proj g|=        4.3433
At iterate     6  f =      -710.23  |proj g|=        3.9341
At iterate     7  f =      -713.23  |proj g|=        3.8237
At iterate     8  f =      -715.31  |proj g|=        3.7209
At iterate     9  f =      -716.26  |proj g|=        3.8606
At iterate    10  f =      -716.74  |proj g|=        4.4414
At iterate    11  f =      -716.75  |proj g|=        4.4811
At iterate    12  f =      -716.75  |proj g|=        4.4904
At iterate    13  f =      -716.75  |proj g|=        4.4678
At iterate    14  f =      -716.75  |proj g|=         4.479
At iterate    15  f =      -717.01  |proj g|=        4.5018
At iterate    16  f =      -718.11  |proj g|=        4.2982
At iterate    17  f =      -718.18  |proj g|=        4.2199
At iterate    18  f =      -718.18  |proj g|=         4.206
At iterate    19  f =      -718.18  |proj g|=        4.2072
At iterate    20  f =      -718.18  |proj g|=        4.2086
At iterate    21  f =      -718.18  |proj g|=         4.209
At iterate    22  f =      -718.18  |proj g|=         4.223
At iterate    23  f =      -718.18  |proj g|=        4.2181
At iterate    24  f =      -718.19  |proj g|=        4.1981
At iterate    25  f =      -718.19  |proj g|=        4.1713
At iterate    26  f =       -718.2  |proj g|=        4.1247
At iterate    27  f =      -718.24  |proj g|=        4.0516
At iterate    28  f =      -718.32  |proj g|=        3.8794
At iterate    29  f =      -718.52  |proj g|=        3.6554
At iterate    30  f =      -719.02  |proj g|=        3.1574
At iterate    31  f =      -720.13  |proj g|=        2.5713
At iterate    32  f =      -720.35  |proj g|=        2.0898
At iterate    33  f =      -722.35  |proj g|=        1.5092
At iterate    34  f =      -730.34  |proj g|=        1.7989
At iterate    35  f =      -734.67  |proj g|=       0.70861
At iterate    36  f =      -735.36  |proj g|=       0.68059
At iterate    37  f =      -735.45  |proj g|=       0.68289
At iterate    38  f =      -735.48  |proj g|=       0.28945
At iterate    39  f =      -735.48  |proj g|=       0.14613
At iterate    40  f =      -735.48  |proj g|=      0.094437
At iterate    41  f =      -735.48  |proj g|=      0.094269

iterations 41
function evaluations 52
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0942692
final function value -735.484

F = -735.484
final  value -735.484237 
converged
 
INFO  [09:31:20.964] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:31:21.071] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:31:21.078] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:31:25.265] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:31:29.502] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:31:33.705] [mlr3]  Finished benchmark 
INFO  [09:31:33.824] [bbotk] Result of batch 139: 
INFO  [09:31:33.826] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:31:33.826] [bbotk]               7.85564                 8.359898                      0.07113578 
INFO  [09:31:33.826] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [09:31:33.826] [bbotk]                     2635        0.957 -0.940997         <NA>   0.9664381 
INFO  [09:31:33.826] [bbotk]                                 uhash 
INFO  [09:31:33.826] [bbotk]  5dd31a67-75bd-4145-9594-1d739cf3bb2d 
DEBUG [09:31:35.196] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.219518e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.219518e-05 0.001375058 
  - best initial criterion value(s) :  661.3934 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -661.39  |proj g|=       10.559
At iterate     1  f =      -681.32  |proj g|=         9.274
At iterate     2  f =      -685.83  |proj g|=         7.837
At iterate     3  f =      -701.76  |proj g|=       0.86724
At iterate     4  f =      -701.84  |proj g|=         1.486
At iterate     5  f =      -701.99  |proj g|=        1.0757
At iterate     6  f =      -701.99  |proj g|=        1.0514
At iterate     7  f =      -701.99  |proj g|=        1.0553
At iterate     8  f =      -701.99  |proj g|=        1.0551
At iterate     9  f =      -701.99  |proj g|=        1.0538
At iterate    10  f =      -701.99  |proj g|=        1.0523
At iterate    11  f =      -701.99  |proj g|=        1.0497
At iterate    12  f =      -701.99  |proj g|=        1.0459
At iterate    13  f =      -701.99  |proj g|=          1.04
At iterate    14  f =         -702  |proj g|=        1.0313
At iterate    15  f =         -702  |proj g|=        1.0558
At iterate    16  f =      -702.01  |proj g|=        1.0208
At iterate    17  f =      -702.03  |proj g|=        1.0665
At iterate    18  f =      -702.28  |proj g|=        1.0183
At iterate    19  f =      -702.74  |proj g|=        1.0839
At iterate    20  f =      -703.25  |proj g|=       0.95296
At iterate    21  f =      -703.28  |proj g|=        0.9641
At iterate    22  f =      -703.28  |proj g|=       0.98756
At iterate    23  f =      -703.28  |proj g|=       0.98644
At iterate    24  f =      -703.28  |proj g|=         0.987
At iterate    25  f =      -703.28  |proj g|=       0.98707

iterations 25
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.987074
final function value -703.285

F = -703.285
final  value -703.284632 
converged
 
INFO  [09:31:35.201] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:31:35.287] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:31:35.294] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:31:41.970] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:31:48.720] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:31:55.320] [mlr3]  Finished benchmark 
INFO  [09:31:55.421] [bbotk] Result of batch 140: 
INFO  [09:31:55.423] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:31:55.423] [bbotk]              8.222632                 3.599676                        0.468425 
INFO  [09:31:55.423] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:31:55.423] [bbotk]                     4178        0.856 -0.9562395         <NA>   0.9726252 
INFO  [09:31:55.423] [bbotk]                                 uhash 
INFO  [09:31:55.423] [bbotk]  9ef5a966-a8e2-48e6-b93f-a3bbbbfe77b5 
DEBUG [09:31:57.207] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.216043e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.216043e-05 0.001372294 
  - best initial criterion value(s) :  681.8033 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -681.8  |proj g|=       8.0798
At iterate     1  f =      -702.82  |proj g|=        4.1426
At iterate     2  f =      -704.79  |proj g|=        7.2042
At iterate     3  f =      -706.24  |proj g|=         5.835
At iterate     4  f =      -706.29  |proj g|=        5.8192
At iterate     5  f =      -706.44  |proj g|=        5.8569
At iterate     6  f =      -706.46  |proj g|=        5.9602
At iterate     7  f =      -706.47  |proj g|=        5.9718
At iterate     8  f =      -706.47  |proj g|=        5.9736
At iterate     9  f =      -706.47  |proj g|=        5.9758
At iterate    10  f =      -706.47  |proj g|=        5.9788
At iterate    11  f =      -706.47  |proj g|=        5.9842
At iterate    12  f =      -706.47  |proj g|=        5.9941
At iterate    13  f =      -706.48  |proj g|=        6.0041
At iterate    14  f =       -706.5  |proj g|=        6.0766
At iterate    15  f =      -706.51  |proj g|=        5.9947
At iterate    16  f =      -706.56  |proj g|=        6.0379
At iterate    17  f =      -707.07  |proj g|=        6.1167
At iterate    18  f =      -708.66  |proj g|=        5.8662
At iterate    19  f =      -712.59  |proj g|=        4.8215
At iterate    20  f =      -719.51  |proj g|=        4.9201
At iterate    21  f =      -719.65  |proj g|=         4.583
At iterate    22  f =      -726.72  |proj g|=         4.875
At iterate    23  f =      -727.58  |proj g|=        5.0144
At iterate    24  f =      -731.46  |proj g|=        5.1139
At iterate    25  f =      -731.72  |proj g|=        4.8468
At iterate    26  f =      -731.74  |proj g|=        4.8667
At iterate    27  f =      -731.74  |proj g|=        4.8292
At iterate    28  f =      -731.74  |proj g|=         4.836
At iterate    29  f =      -731.74  |proj g|=        4.8358
At iterate    30  f =      -731.74  |proj g|=        4.8351
At iterate    31  f =      -731.74  |proj g|=        4.8342
At iterate    32  f =      -731.74  |proj g|=        4.8326
At iterate    33  f =      -731.74  |proj g|=        4.8316
At iterate    34  f =      -731.74  |proj g|=        4.8247
At iterate    35  f =      -731.74  |proj g|=        4.8273
At iterate    36  f =      -731.74  |proj g|=        4.8035
At iterate    37  f =      -731.75  |proj g|=        4.8075
At iterate    38  f =      -731.79  |proj g|=        4.8059
At iterate    39  f =      -732.44  |proj g|=        4.6366
At iterate    40  f =      -734.81  |proj g|=         3.757
At iterate    41  f =      -738.12  |proj g|=        2.4143
At iterate    42  f =       -738.3  |proj g|=        2.8737
At iterate    43  f =      -741.54  |proj g|=         1.692
At iterate    44  f =      -745.73  |proj g|=       0.81543
At iterate    45  f =      -746.47  |proj g|=       0.70285
At iterate    46  f =      -746.65  |proj g|=       0.68595
At iterate    47  f =      -746.65  |proj g|=      0.092915
At iterate    48  f =      -746.65  |proj g|=      0.045709
At iterate    49  f =      -746.65  |proj g|=      0.032181

iterations 49
function evaluations 59
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0321814
final function value -746.654

F = -746.654
final  value -746.653610 
converged
 
INFO  [09:31:57.212] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:31:57.332] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:31:57.340] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:31:58.707] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:32:00.064] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:32:01.413] [mlr3]  Finished benchmark 
INFO  [09:32:01.513] [bbotk] Result of batch 141: 
INFO  [09:32:01.515] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:32:01.515] [bbotk]              8.421978                 9.740284                       0.4859691 
INFO  [09:32:01.515] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:32:01.515] [bbotk]                      726        1.037 -0.9406252         <NA>   0.9703704 
INFO  [09:32:01.515] [bbotk]                                 uhash 
INFO  [09:32:01.515] [bbotk]  1d5e37a9-db57-4575-b18e-abce27afd55b 
DEBUG [09:32:02.715] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.210788e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.210788e-05 0.001361947 
  - best initial criterion value(s) :  645.5974 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -645.6  |proj g|=       10.471
At iterate     1  f =      -672.45  |proj g|=        9.1619
At iterate     2  f =      -718.43  |proj g|=        4.8015
At iterate     3  f =      -719.35  |proj g|=        3.1029
At iterate     4  f =      -720.63  |proj g|=        3.6559
At iterate     5  f =      -722.33  |proj g|=        3.7362
At iterate     6  f =      -726.34  |proj g|=        3.0984
At iterate     7  f =      -728.36  |proj g|=         2.126
At iterate     8  f =       -729.2  |proj g|=        2.4087
At iterate     9  f =       -729.2  |proj g|=        2.4355
At iterate    10  f =       -729.2  |proj g|=        2.4449
At iterate    11  f =       -729.2  |proj g|=        2.4451

iterations 11
function evaluations 14
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.44505
final function value -729.203

F = -729.203
final  value -729.202591 
converged
 
INFO  [09:32:02.719] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:32:02.806] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:32:02.827] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:32:04.878] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:32:07.131] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:32:09.157] [mlr3]  Finished benchmark 
INFO  [09:32:09.255] [bbotk] Result of batch 142: 
INFO  [09:32:09.257] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:32:09.257] [bbotk]              6.566913                 6.796309                       0.2697492 
INFO  [09:32:09.257] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:32:09.257] [bbotk]                     1354        0.849 -0.9474942         <NA>   0.9704378 
INFO  [09:32:09.257] [bbotk]                                 uhash 
INFO  [09:32:09.257] [bbotk]  15d7ce24-5c57-4cbf-b6c5-e7969779d487 
DEBUG [09:32:10.796] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.205618e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.205618e-05 0.001352516 
  - best initial criterion value(s) :  690.9342 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -690.93  |proj g|=       2.1428
At iterate     1  f =      -713.13  |proj g|=        11.547
At iterate     2  f =      -717.98  |proj g|=        11.447
At iterate     3  f =      -722.86  |proj g|=        8.9311
At iterate     4  f =      -722.92  |proj g|=        8.5739
At iterate     5  f =      -723.14  |proj g|=        8.5422
At iterate     6  f =       -723.7  |proj g|=        8.2452
At iterate     7  f =      -723.77  |proj g|=        8.2201
At iterate     8  f =      -723.78  |proj g|=        8.2483
At iterate     9  f =      -723.78  |proj g|=        8.2683
At iterate    10  f =      -723.78  |proj g|=        8.2734
At iterate    11  f =      -723.78  |proj g|=        8.2746
At iterate    12  f =      -723.78  |proj g|=        8.2783
At iterate    13  f =      -723.78  |proj g|=        8.2823
At iterate    14  f =      -723.78  |proj g|=        8.2873
At iterate    15  f =      -723.78  |proj g|=        8.2886
At iterate    16  f =      -723.78  |proj g|=        8.2787
At iterate    17  f =      -723.79  |proj g|=        8.2899
At iterate    18  f =       -723.8  |proj g|=        8.2605
At iterate    19  f =      -723.83  |proj g|=        8.3191
At iterate    20  f =      -723.88  |proj g|=        8.1896
At iterate    21  f =      -724.12  |proj g|=        8.1004
At iterate    22  f =      -724.51  |proj g|=        7.6825
At iterate    23  f =      -725.88  |proj g|=        6.5033
At iterate    24  f =       -727.8  |proj g|=        5.3715
At iterate    25  f =      -731.77  |proj g|=        4.1953
At iterate    26  f =      -734.43  |proj g|=         3.447
At iterate    27  f =         -738  |proj g|=        3.8073
At iterate    28  f =      -739.36  |proj g|=        4.6526
At iterate    29  f =      -739.36  |proj g|=        4.6122
At iterate    30  f =      -739.36  |proj g|=        4.6122

iterations 30
function evaluations 38
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 4.61217
final function value -739.363

F = -739.363
final  value -739.362750 
converged
 
INFO  [09:32:10.801] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:32:10.890] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:32:10.896] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:32:16.657] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:32:22.350] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:32:32.190] [mlr3]  Finished benchmark 
INFO  [09:32:32.291] [bbotk] Result of batch 143: 
INFO  [09:32:32.293] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:32:32.293] [bbotk]              5.491012                 6.918112                       0.2876125 
INFO  [09:32:32.293] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:32:32.293] [bbotk]                     3395         0.91 -0.9536939         <NA>   0.9737932 
INFO  [09:32:32.293] [bbotk]                                 uhash 
INFO  [09:32:32.293] [bbotk]  0cda2483-64d0-4327-93a9-61db234505f9 
DEBUG [09:32:33.728] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.203313e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.203313e-05 0.001351066 
  - best initial criterion value(s) :  671.6677 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -671.67  |proj g|=       8.8032
At iterate     1  f =      -694.53  |proj g|=        8.4637
At iterate     2  f =      -698.96  |proj g|=         8.658
At iterate     3  f =      -707.31  |proj g|=        7.6697
At iterate     4  f =      -707.71  |proj g|=        7.2708
At iterate     5  f =      -707.77  |proj g|=        7.0928
At iterate     6  f =      -707.85  |proj g|=        6.7634
At iterate     7  f =      -707.89  |proj g|=        6.7842
At iterate     8  f =      -708.06  |proj g|=         6.826
At iterate     9  f =      -708.52  |proj g|=        6.8733
At iterate    10  f =      -709.65  |proj g|=        6.8921
At iterate    11  f =      -712.27  |proj g|=        6.7471
At iterate    12  f =      -716.95  |proj g|=         6.148
At iterate    13  f =      -723.69  |proj g|=        4.4773
At iterate    14  f =      -728.67  |proj g|=        3.4006
At iterate    15  f =      -729.46  |proj g|=        2.3176
At iterate    16  f =      -730.34  |proj g|=        3.8203
At iterate    17  f =      -731.53  |proj g|=        2.9493
At iterate    18  f =      -734.69  |proj g|=        2.8274
At iterate    19  f =      -735.67  |proj g|=         2.747
At iterate    20  f =      -735.88  |proj g|=        2.7593
At iterate    21  f =       -735.9  |proj g|=        2.6743
At iterate    22  f =      -735.92  |proj g|=        2.7956
At iterate    23  f =      -735.92  |proj g|=        2.7825
At iterate    24  f =      -735.92  |proj g|=        2.7854
At iterate    25  f =      -735.92  |proj g|=        2.7873
At iterate    26  f =      -735.92  |proj g|=        2.7873

iterations 26
function evaluations 34
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.78731
final function value -735.92

F = -735.92
final  value -735.919938 
converged
 
INFO  [09:32:33.732] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:32:33.908] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:32:33.915] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:32:39.200] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:32:45.985] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:32:52.652] [mlr3]  Finished benchmark 
INFO  [09:32:52.753] [bbotk] Result of batch 144: 
INFO  [09:32:52.754] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:32:52.754] [bbotk]              5.824004                 6.020664                       0.1897738 
INFO  [09:32:52.754] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:32:52.754] [bbotk]                     2196        0.869 -0.9537106         <NA>   0.9707643 
INFO  [09:32:52.754] [bbotk]                                 uhash 
INFO  [09:32:52.754] [bbotk]  6724b791-ebe0-4b34-9553-f9c75716ec73 
DEBUG [09:32:54.344] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.198405e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.198405e-05 0.001350748 
  - best initial criterion value(s) :  731.7553 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -731.76  |proj g|=       1.7171
At iterate     1  f =       -732.8  |proj g|=        2.5537
At iterate     2  f =      -732.86  |proj g|=        2.3642
At iterate     3  f =      -732.86  |proj g|=        2.3164
At iterate     4  f =      -732.86  |proj g|=        2.3064
At iterate     5  f =      -732.86  |proj g|=        2.3093
At iterate     6  f =      -732.86  |proj g|=        2.3133
At iterate     7  f =      -732.86  |proj g|=        2.3232
At iterate     8  f =      -732.86  |proj g|=        2.3364
At iterate     9  f =      -732.87  |proj g|=         2.358
At iterate    10  f =      -732.87  |proj g|=        2.3881
At iterate    11  f =      -732.89  |proj g|=        2.4246
At iterate    12  f =      -732.92  |proj g|=        2.4771
At iterate    13  f =      -733.01  |proj g|=        2.4614
At iterate    14  f =      -733.05  |proj g|=        2.6423
At iterate    15  f =      -733.21  |proj g|=        2.5458
At iterate    16  f =      -733.87  |proj g|=        2.1521
At iterate    17  f =      -735.03  |proj g|=        1.5214
At iterate    18  f =      -737.49  |proj g|=       0.62422
At iterate    19  f =      -740.39  |proj g|=       0.45494
At iterate    20  f =      -740.43  |proj g|=       0.57639
At iterate    21  f =      -740.48  |proj g|=        0.4266
At iterate    22  f =      -740.48  |proj g|=       0.42565
At iterate    23  f =      -740.48  |proj g|=       0.42564

iterations 23
function evaluations 32
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.425636
final function value -740.478

F = -740.478
final  value -740.478383 
converged
 
INFO  [09:32:54.348] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:32:54.464] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:32:54.474] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:32:57.511] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:33:00.421] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:33:03.186] [mlr3]  Finished benchmark 
INFO  [09:33:03.288] [bbotk] Result of batch 145: 
INFO  [09:33:03.290] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:33:03.290] [bbotk]              4.514023                  6.60315                       0.2772589 
INFO  [09:33:03.290] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:33:03.290] [bbotk]                     1252        0.882 -0.9519272         <NA>   0.9687354 
INFO  [09:33:03.290] [bbotk]                                 uhash 
INFO  [09:33:03.290] [bbotk]  822e9e50-47ea-4935-b4ef-646e311eb4fb 
DEBUG [09:33:04.948] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.192406e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.192406e-05 0.001341255 
  - best initial criterion value(s) :  674.0382 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -674.04  |proj g|=       12.078
At iterate     1  f =      -711.17  |proj g|=        8.4709
At iterate     2  f =      -722.34  |proj g|=        6.1134
At iterate     3  f =      -725.52  |proj g|=        4.1612
At iterate     4  f =      -727.35  |proj g|=        3.5167
At iterate     5  f =      -728.67  |proj g|=        2.8769
At iterate     6  f =      -728.69  |proj g|=        2.7286
At iterate     7  f =      -728.69  |proj g|=        2.7676
At iterate     8  f =      -728.69  |proj g|=        2.7669
At iterate     9  f =      -728.69  |proj g|=        2.7648
At iterate    10  f =      -728.69  |proj g|=        2.7601
At iterate    11  f =      -728.69  |proj g|=        2.7502
At iterate    12  f =       -728.7  |proj g|=        2.7342
At iterate    13  f =       -728.7  |proj g|=        2.7053
At iterate    14  f =      -728.72  |proj g|=         2.654
At iterate    15  f =      -728.77  |proj g|=        2.5616
At iterate    16  f =      -728.88  |proj g|=        2.4069
At iterate    17  f =      -729.11  |proj g|=        2.2075
At iterate    18  f =      -729.47  |proj g|=        2.1321
At iterate    19  f =      -729.53  |proj g|=        2.1685
At iterate    20  f =      -729.53  |proj g|=        2.1943
At iterate    21  f =      -729.55  |proj g|=         2.232
At iterate    22  f =       -729.6  |proj g|=        2.2833
At iterate    23  f =      -729.75  |proj g|=        2.3641
At iterate    24  f =      -730.09  |proj g|=        2.4515
At iterate    25  f =      -730.91  |proj g|=        2.5218
At iterate    26  f =      -732.55  |proj g|=        2.5196
At iterate    27  f =      -733.39  |proj g|=        2.4755
At iterate    28  f =      -734.29  |proj g|=        2.3439
At iterate    29  f =      -737.75  |proj g|=         1.089
At iterate    30  f =      -738.13  |proj g|=         1.995
At iterate    31  f =      -738.22  |proj g|=        2.0439
At iterate    32  f =      -738.23  |proj g|=        2.0215
At iterate    33  f =      -738.23  |proj g|=        2.0373
At iterate    34  f =      -738.23  |proj g|=        2.0368
At iterate    35  f =      -738.23  |proj g|=         2.037

iterations 35
function evaluations 41
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.03696
final function value -738.23

F = -738.23
final  value -738.229909 
converged
 
INFO  [09:33:04.950] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:33:05.028] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:33:05.035] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:33:11.537] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:33:19.355] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:33:27.510] [mlr3]  Finished benchmark 
INFO  [09:33:27.614] [bbotk] Result of batch 146: 
INFO  [09:33:27.616] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:33:27.616] [bbotk]              4.369829                 6.273721                       0.2683027 
INFO  [09:33:27.616] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:33:27.616] [bbotk]                     3052        1.045 -0.9569489         <NA>   0.9724893 
INFO  [09:33:27.616] [bbotk]                                 uhash 
INFO  [09:33:27.616] [bbotk]  f65b4c2f-a1e0-43f1-9c0b-abc65bdc237b 
DEBUG [09:33:29.130] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.188892e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.188892e-05 0.001339763 
  - best initial criterion value(s) :  718.5808 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -718.58  |proj g|=        3.808
At iterate     1  f =      -744.73  |proj g|=        2.1994
At iterate     2  f =      -752.44  |proj g|=        4.9412
At iterate     3  f =      -752.93  |proj g|=        4.6853
At iterate     4  f =      -753.07  |proj g|=        4.1554
At iterate     5  f =      -753.12  |proj g|=        4.4236
At iterate     6  f =      -753.12  |proj g|=        4.3786
At iterate     7  f =      -753.12  |proj g|=        4.3725
At iterate     8  f =      -753.12  |proj g|=         4.373
At iterate     9  f =      -753.12  |proj g|=         4.376
At iterate    10  f =      -753.12  |proj g|=        4.3787
At iterate    11  f =      -753.12  |proj g|=        4.3862
At iterate    12  f =      -753.12  |proj g|=        4.3962
At iterate    13  f =      -753.12  |proj g|=        4.4128
At iterate    14  f =      -753.13  |proj g|=         4.435
At iterate    15  f =      -753.13  |proj g|=        4.4639
At iterate    16  f =      -753.15  |proj g|=        4.5132
At iterate    17  f =      -753.19  |proj g|=         4.531
At iterate    18  f =      -753.22  |proj g|=        4.7271
At iterate    19  f =      -753.32  |proj g|=        4.7242
At iterate    20  f =      -753.93  |proj g|=        4.7242
At iterate    21  f =      -754.89  |proj g|=        4.7528
At iterate    22  f =      -756.87  |proj g|=        4.9155
At iterate    23  f =      -759.87  |proj g|=         5.461
At iterate    24  f =      -760.05  |proj g|=        5.0769
At iterate    25  f =      -762.46  |proj g|=        6.0447
At iterate    26  f =      -762.68  |proj g|=        5.7935
At iterate    27  f =       -762.7  |proj g|=        6.0016
At iterate    28  f =       -762.7  |proj g|=        5.9583
At iterate    29  f =       -762.7  |proj g|=        5.9549
At iterate    30  f =       -762.7  |proj g|=        5.9551

iterations 30
function evaluations 39
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 5.95515
final function value -762.704

F = -762.704
final  value -762.703563 
converged
 
INFO  [09:33:29.135] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:33:29.260] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:33:29.268] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:33:36.548] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:33:42.961] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:33:50.006] [mlr3]  Finished benchmark 
INFO  [09:33:50.111] [bbotk] Result of batch 147: 
INFO  [09:33:50.113] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:33:50.113] [bbotk]              3.037637                 2.648883                       0.1042076 
INFO  [09:33:50.113] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [09:33:50.113] [bbotk]                     3060        0.892 -0.951463         <NA>    0.960688 
INFO  [09:33:50.113] [bbotk]                                 uhash 
INFO  [09:33:50.113] [bbotk]  5f5cccec-79a7-4cfe-add7-535e5bf54d77 
DEBUG [09:33:51.762] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.183188e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.183188e-05 0.001333122 
  - best initial criterion value(s) :  700.7421 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -700.74  |proj g|=       8.4034
At iterate     1  f =      -751.93  |proj g|=       0.96452
At iterate     2  f =      -761.12  |proj g|=        2.2554
At iterate     3  f =      -768.95  |proj g|=        3.5152
At iterate     4  f =      -769.02  |proj g|=        3.6054
At iterate     5  f =      -769.07  |proj g|=        3.5757
At iterate     6  f =      -769.07  |proj g|=        3.5763
At iterate     7  f =      -769.07  |proj g|=        3.5652
At iterate     8  f =      -769.07  |proj g|=        3.5673
At iterate     9  f =      -769.07  |proj g|=        3.5688
At iterate    10  f =      -769.07  |proj g|=        3.5719
At iterate    11  f =      -769.07  |proj g|=        3.5765
At iterate    12  f =      -769.07  |proj g|=        3.5842
At iterate    13  f =      -769.07  |proj g|=        3.5962
At iterate    14  f =      -769.07  |proj g|=        3.6152
At iterate    15  f =      -769.07  |proj g|=        3.6418
At iterate    16  f =      -769.08  |proj g|=        3.6749
At iterate    17  f =      -769.09  |proj g|=        3.7137
At iterate    18  f =      -769.11  |proj g|=        3.8559
At iterate    19  f =      -769.15  |proj g|=        3.8451
At iterate    20  f =      -769.39  |proj g|=        3.7559
At iterate    21  f =      -769.85  |proj g|=        3.5434
At iterate    22  f =      -770.81  |proj g|=        3.0426
At iterate    23  f =      -772.23  |proj g|=        2.2733
At iterate    24  f =      -774.08  |proj g|=        1.1829
At iterate    25  f =      -776.96  |proj g|=       0.94318
At iterate    26  f =      -779.01  |proj g|=        1.1252
At iterate    27  f =      -779.18  |proj g|=        1.2111
At iterate    28  f =      -779.94  |proj g|=        1.5172
At iterate    29  f =      -780.01  |proj g|=         1.519
At iterate    30  f =      -780.03  |proj g|=        1.5131
At iterate    31  f =      -780.03  |proj g|=         1.508
At iterate    32  f =      -780.03  |proj g|=        1.5075
At iterate    33  f =      -780.03  |proj g|=        1.5076

iterations 33
function evaluations 37
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.50759
final function value -780.034

F = -780.034
final  value -780.033894 
converged
 
INFO  [09:33:51.766] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:33:51.886] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:33:51.897] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:33:56.449] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:34:03.127] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:34:07.657] [mlr3]  Finished benchmark 
INFO  [09:34:07.762] [bbotk] Result of batch 148: 
INFO  [09:34:07.764] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:34:07.764] [bbotk]              5.332193                 9.001603                       0.1127794 
INFO  [09:34:07.764] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [09:34:07.764] [bbotk]                     2252        0.885 -0.940421         <NA>   0.9677923 
INFO  [09:34:07.764] [bbotk]                                 uhash 
INFO  [09:34:07.764] [bbotk]  8c94df42-d0d2-49ee-9621-aa9659b3fe17 
DEBUG [09:34:09.282] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.177005e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.177005e-05 0.001329519 
  - best initial criterion value(s) :  650.2182 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -650.22  |proj g|=       11.829
At iterate     1  f =      -663.53  |proj g|=        6.5836
At iterate     2  f =      -689.08  |proj g|=        9.0099
At iterate     3  f =      -702.77  |proj g|=         8.461
At iterate     4  f =      -709.93  |proj g|=         5.926
At iterate     5  f =      -714.33  |proj g|=        3.3223
At iterate     6  f =      -714.55  |proj g|=        3.2159
At iterate     7  f =      -714.74  |proj g|=        2.8652
At iterate     8  f =      -714.75  |proj g|=        2.9239
At iterate     9  f =      -714.75  |proj g|=        2.9182
At iterate    10  f =      -714.75  |proj g|=        2.9177
At iterate    11  f =      -714.75  |proj g|=        2.9139
At iterate    12  f =      -714.75  |proj g|=        2.9095
At iterate    13  f =      -714.75  |proj g|=        2.9011
At iterate    14  f =      -714.75  |proj g|=        2.8877
At iterate    15  f =      -714.75  |proj g|=        2.8641
At iterate    16  f =      -714.76  |proj g|=        2.8253
At iterate    17  f =      -714.78  |proj g|=        2.7716
At iterate    18  f =       -714.8  |proj g|=         2.713
At iterate    19  f =      -714.83  |proj g|=        2.6938
At iterate    20  f =      -714.86  |proj g|=        2.6666
At iterate    21  f =      -715.11  |proj g|=        2.4875
At iterate    22  f =      -715.52  |proj g|=        2.3092
At iterate    23  f =      -716.73  |proj g|=        1.9318
At iterate    24  f =      -718.47  |proj g|=        1.5758
At iterate    25  f =      -719.38  |proj g|=        2.0698
At iterate    26  f =      -720.23  |proj g|=        2.4153
At iterate    27  f =      -720.31  |proj g|=        2.6393
At iterate    28  f =      -720.49  |proj g|=        2.1159
At iterate    29  f =       -720.5  |proj g|=        2.2179
At iterate    30  f =       -720.5  |proj g|=        2.2603
At iterate    31  f =       -720.5  |proj g|=        2.2639
At iterate    32  f =       -720.5  |proj g|=        2.2643

iterations 32
function evaluations 40
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.26433
final function value -720.499

F = -720.499
final  value -720.499265 
converged
 
INFO  [09:34:09.287] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:34:09.404] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:34:09.416] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:34:18.351] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:34:30.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:34:38.675] [mlr3]  Finished benchmark 
INFO  [09:34:38.825] [bbotk] Result of batch 149: 
INFO  [09:34:38.827] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:34:38.827] [bbotk]              6.697811                 2.518233                       0.3720328 
INFO  [09:34:38.827] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:34:38.827] [bbotk]                     4123        0.883 -0.9616413         <NA>   0.9750327 
INFO  [09:34:38.827] [bbotk]                                 uhash 
INFO  [09:34:38.827] [bbotk]  91ff9675-1654-4ed3-b766-43fa3da3026c 
DEBUG [09:34:40.319] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.176103e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.176102e-05 0.00133058 
  - best initial criterion value(s) :  701.7355 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -701.74  |proj g|=       6.4336
At iterate     1  f =      -719.54  |proj g|=        1.7271
At iterate     2  f =       -719.7  |proj g|=        1.6564
At iterate     3  f =       -719.8  |proj g|=        1.9599
At iterate     4  f =       -719.8  |proj g|=        1.9285
At iterate     5  f =      -719.81  |proj g|=        1.8978
At iterate     6  f =      -719.83  |proj g|=        1.8403
At iterate     7  f =      -719.86  |proj g|=        1.7914
At iterate     8  f =       -719.9  |proj g|=        1.7909
At iterate     9  f =      -719.91  |proj g|=        1.8373
At iterate    10  f =      -719.91  |proj g|=        1.8738
At iterate    11  f =      -719.91  |proj g|=        1.8846
At iterate    12  f =      -719.91  |proj g|=        1.8864
At iterate    13  f =      -719.92  |proj g|=        1.8941
At iterate    14  f =      -719.92  |proj g|=        1.9052
At iterate    15  f =      -719.92  |proj g|=        1.9224
At iterate    16  f =      -719.93  |proj g|=        1.9474
At iterate    17  f =      -719.94  |proj g|=        1.9791
At iterate    18  f =      -719.99  |proj g|=        1.9999
At iterate    19  f =      -720.08  |proj g|=         2.009
At iterate    20  f =      -720.31  |proj g|=        1.8838
At iterate    21  f =      -720.34  |proj g|=        2.0034
At iterate    22  f =      -720.82  |proj g|=        1.7432
At iterate    23  f =      -721.82  |proj g|=        1.6139
At iterate    24  f =      -723.07  |proj g|=         1.107
At iterate    25  f =      -723.16  |proj g|=        1.1771
At iterate    26  f =      -723.17  |proj g|=        1.1826
At iterate    27  f =      -723.17  |proj g|=        1.1787
At iterate    28  f =      -723.17  |proj g|=        1.1784
At iterate    29  f =      -723.17  |proj g|=        1.1783

iterations 29
function evaluations 35
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.17834
final function value -723.174

F = -723.174
final  value -723.173554 
converged
 
INFO  [09:34:40.323] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:34:40.415] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:34:40.422] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:34:44.343] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:34:48.179] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:34:51.689] [mlr3]  Finished benchmark 
INFO  [09:34:51.805] [bbotk] Result of batch 150: 
INFO  [09:34:51.807] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:34:51.807] [bbotk]              7.835925                 7.797354                       0.1350365 
INFO  [09:34:51.807] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:34:51.807] [bbotk]                     1926        0.903 -0.9606578         <NA>   0.9686768 
INFO  [09:34:51.807] [bbotk]                                 uhash 
INFO  [09:34:51.807] [bbotk]  308860a0-9615-4af0-b99d-732271c21dcf 
DEBUG [09:34:53.781] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.170322e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.170322e-05 0.001326634 
  - best initial criterion value(s) :  724.1112 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -724.11  |proj g|=       11.446
At iterate     1  f =      -730.79  |proj g|=        6.9541
At iterate     2  f =      -732.23  |proj g|=        6.8842
At iterate     3  f =      -733.05  |proj g|=        6.1559
At iterate     4  f =      -733.27  |proj g|=        5.8229
At iterate     5  f =      -733.32  |proj g|=        5.7561
At iterate     6  f =      -733.33  |proj g|=         5.781
At iterate     7  f =      -733.33  |proj g|=        5.8116
At iterate     8  f =      -733.33  |proj g|=        5.8132
At iterate     9  f =      -733.33  |proj g|=        5.8145
At iterate    10  f =      -733.33  |proj g|=        5.8172
At iterate    11  f =      -733.33  |proj g|=         5.821
At iterate    12  f =      -733.33  |proj g|=        5.8271
At iterate    13  f =      -733.33  |proj g|=        5.8358
At iterate    14  f =      -733.33  |proj g|=        5.8472
At iterate    15  f =      -733.33  |proj g|=        5.8581
At iterate    16  f =      -733.34  |proj g|=        5.8551
At iterate    17  f =      -733.35  |proj g|=        5.8018
At iterate    18  f =      -733.37  |proj g|=        5.6371
At iterate    19  f =      -733.37  |proj g|=        5.5086
At iterate    20  f =      -733.38  |proj g|=        5.4975
At iterate    21  f =      -733.38  |proj g|=        5.4983
At iterate    22  f =      -733.38  |proj g|=        5.4979
At iterate    23  f =      -733.38  |proj g|=        5.4971
At iterate    24  f =      -733.38  |proj g|=        5.4958
At iterate    25  f =      -733.38  |proj g|=        5.4929
At iterate    26  f =      -733.38  |proj g|=        5.4915
At iterate    27  f =      -733.38  |proj g|=        5.5009
At iterate    28  f =      -733.39  |proj g|=        5.5346
At iterate    29  f =      -733.42  |proj g|=        5.6046
At iterate    30  f =      -733.48  |proj g|=        5.7142
At iterate    31  f =      -733.63  |proj g|=        5.9646
At iterate    32  f =      -733.66  |proj g|=          5.79
At iterate    33  f =      -734.04  |proj g|=        5.9739
At iterate    34  f =      -737.67  |proj g|=        5.0992
At iterate    35  f =      -742.52  |proj g|=        2.5561
At iterate    36  f =      -746.09  |proj g|=        1.1219
At iterate    37  f =      -746.75  |proj g|=        1.1238
At iterate    38  f =      -746.79  |proj g|=        1.1874
At iterate    39  f =       -746.9  |proj g|=        1.2063
At iterate    40  f =       -746.9  |proj g|=        1.2148
At iterate    41  f =       -746.9  |proj g|=        1.2134
At iterate    42  f =       -746.9  |proj g|=        1.2163
At iterate    43  f =       -746.9  |proj g|=        1.2161

iterations 43
function evaluations 51
segments explored during Cauchy searches 45
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.21611
final function value -746.904

F = -746.904
final  value -746.904321 
converged
 
INFO  [09:34:53.785] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:34:53.870] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:34:53.877] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:34:57.088] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:35:00.339] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:35:03.633] [mlr3]  Finished benchmark 
INFO  [09:35:03.733] [bbotk] Result of batch 151: 
INFO  [09:35:03.735] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:35:03.735] [bbotk]              6.040253                 7.726511                       0.4825786 
INFO  [09:35:03.735] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:35:03.735] [bbotk]                     2050        0.877 -0.9575158         <NA>   0.9738722 
INFO  [09:35:03.735] [bbotk]                                 uhash 
INFO  [09:35:03.735] [bbotk]  a23ca846-dd3b-400b-b84d-d69bf628cf38 
DEBUG [09:35:05.282] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.168178e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.168178e-05 0.001325519 
  - best initial criterion value(s) :  695.7543 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -695.75  |proj g|=       14.066
At iterate     1  f =      -705.39  |proj g|=        9.0122
At iterate     2  f =      -746.48  |proj g|=         4.791
At iterate     3  f =      -747.47  |proj g|=        4.2729
At iterate     4  f =      -748.75  |proj g|=         2.111
At iterate     5  f =      -748.76  |proj g|=        2.0691
At iterate     6  f =      -748.76  |proj g|=        2.0768
At iterate     7  f =      -748.76  |proj g|=         2.076
At iterate     8  f =      -748.76  |proj g|=         2.074
At iterate     9  f =      -748.76  |proj g|=        2.0703
At iterate    10  f =      -748.76  |proj g|=        2.0647
At iterate    11  f =      -748.76  |proj g|=        2.0568
At iterate    12  f =      -748.76  |proj g|=        2.0483
At iterate    13  f =      -748.77  |proj g|=        2.1206
At iterate    14  f =      -748.77  |proj g|=        2.1842
At iterate    15  f =      -748.78  |proj g|=        2.2815
At iterate    16  f =       -748.8  |proj g|=        2.4003
At iterate    17  f =      -748.84  |proj g|=        2.5876
At iterate    18  f =      -748.95  |proj g|=        2.8577
At iterate    19  f =      -749.21  |proj g|=        3.2251
At iterate    20  f =      -749.82  |proj g|=        3.5898
At iterate    21  f =      -750.25  |proj g|=        3.6015
At iterate    22  f =      -751.85  |proj g|=        3.5092
At iterate    23  f =      -754.13  |proj g|=        2.5439
At iterate    24  f =      -755.55  |proj g|=        1.5622
At iterate    25  f =      -756.21  |proj g|=        1.5607
At iterate    26  f =       -756.3  |proj g|=        1.6341
At iterate    27  f =       -756.3  |proj g|=        1.6477
At iterate    28  f =       -756.3  |proj g|=        1.6126
At iterate    29  f =      -756.31  |proj g|=        1.6021
At iterate    30  f =      -756.31  |proj g|=        1.6015
At iterate    31  f =      -756.31  |proj g|=        1.6015

iterations 31
function evaluations 40
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.60152
final function value -756.305

F = -756.305
final  value -756.305147 
converged
 
INFO  [09:35:05.287] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:35:05.392] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:35:05.399] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:35:12.719] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:35:19.984] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:35:27.065] [mlr3]  Finished benchmark 
INFO  [09:35:27.177] [bbotk] Result of batch 152: 
INFO  [09:35:27.180] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:35:27.180] [bbotk]              7.887333                 3.847428                       0.3008466 
INFO  [09:35:27.180] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:35:27.180] [bbotk]                     4446        0.906 -0.9571071         <NA>   0.9742537 
INFO  [09:35:27.180] [bbotk]                                 uhash 
INFO  [09:35:27.180] [bbotk]  b14cd96c-1c0b-4041-bee4-9c8eb797fc88 
DEBUG [09:35:28.810] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.166385e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.166385e-05 0.001325797 
  - best initial criterion value(s) :  686.019 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -686.02  |proj g|=       6.0526
At iterate     1  f =       -709.6  |proj g|=        11.396
At iterate     2  f =      -724.55  |proj g|=        10.956
At iterate     3  f =      -744.71  |proj g|=        8.8151
At iterate     4  f =      -746.08  |proj g|=        7.4094
At iterate     5  f =      -749.15  |proj g|=           6.1
At iterate     6  f =      -749.53  |proj g|=        6.7137
At iterate     7  f =      -752.46  |proj g|=        4.4553
At iterate     8  f =      -752.93  |proj g|=        3.8447
At iterate     9  f =      -755.04  |proj g|=        3.7364
At iterate    10  f =      -768.96  |proj g|=        3.6706
At iterate    11  f =      -774.68  |proj g|=        2.7648
At iterate    12  f =      -778.24  |proj g|=        1.1967
At iterate    13  f =      -784.59  |proj g|=        1.3368
At iterate    14  f =      -785.76  |proj g|=        1.3236
At iterate    15  f =      -785.84  |proj g|=         1.695
At iterate    16  f =      -786.19  |proj g|=        1.4518
At iterate    17  f =      -786.29  |proj g|=        1.3324
At iterate    18  f =      -786.29  |proj g|=        1.3405
At iterate    19  f =      -786.29  |proj g|=        1.3427
At iterate    20  f =      -786.29  |proj g|=        1.3427

iterations 20
function evaluations 30
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.34274
final function value -786.287

F = -786.287
final  value -786.287100 
converged
 
INFO  [09:35:28.815] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:35:28.913] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:35:28.921] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:35:29.669] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:35:30.378] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:35:31.156] [mlr3]  Finished benchmark 
INFO  [09:35:31.299] [bbotk] Result of batch 153: 
INFO  [09:35:31.301] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:35:31.301] [bbotk]              7.715846                  3.60012                      0.04713336 
INFO  [09:35:31.301] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:35:31.301] [bbotk]                      228        0.994 -0.9470747         <NA>   0.9184379 
INFO  [09:35:31.301] [bbotk]                                 uhash 
INFO  [09:35:31.301] [bbotk]  17aba12e-81fb-4e8b-81fa-0273301f936d 
DEBUG [09:35:33.444] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.278361e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.278361e-05 0.001489481 
  - best initial criterion value(s) :  644.7346 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -644.73  |proj g|=       15.256
At iterate     1  f =       -704.9  |proj g|=        13.859
At iterate     2  f =       -752.5  |proj g|=        10.102
At iterate     3  f =       -756.8  |proj g|=        8.2769
At iterate     4  f =      -765.97  |proj g|=        4.2932
At iterate     5  f =      -769.22  |proj g|=        2.7772
At iterate     6  f =      -771.56  |proj g|=        2.0086
At iterate     7  f =      -775.49  |proj g|=        6.0803
At iterate     8  f =      -778.33  |proj g|=        4.2611
At iterate     9  f =      -779.97  |proj g|=        3.3749
At iterate    10  f =      -780.14  |proj g|=         3.742
At iterate    11  f =      -780.18  |proj g|=        4.1069
At iterate    12  f =      -780.23  |proj g|=        3.9199
At iterate    13  f =      -780.44  |proj g|=        3.5789
At iterate    14  f =      -781.22  |proj g|=        2.7635
At iterate    15  f =      -783.01  |proj g|=        1.7276
At iterate    16  f =      -788.11  |proj g|=       0.59867
At iterate    17  f =      -804.32  |proj g|=        1.4693
At iterate    18  f =      -806.07  |proj g|=        1.9196
At iterate    19  f =      -807.12  |proj g|=        2.5364
At iterate    20  f =      -807.15  |proj g|=        2.5365
At iterate    21  f =      -807.17  |proj g|=        2.5169
At iterate    22  f =      -807.17  |proj g|=        2.5244
At iterate    23  f =      -807.17  |proj g|=        2.5313
At iterate    24  f =      -807.17  |proj g|=        2.5318
At iterate    25  f =      -807.17  |proj g|=        2.5314
At iterate    26  f =      -807.17  |proj g|=          2.53
At iterate    27  f =      -807.18  |proj g|=        2.5275
At iterate    28  f =      -807.18  |proj g|=        2.5233
At iterate    29  f =      -807.18  |proj g|=        2.5318
At iterate    30  f =      -807.19  |proj g|=        2.5263
At iterate    31  f =      -807.21  |proj g|=        2.4961
At iterate    32  f =      -807.25  |proj g|=        2.4658
At iterate    33  f =      -807.38  |proj g|=        2.3506
At iterate    34  f =      -807.74  |proj g|=        2.1054
At iterate    35  f =      -808.52  |proj g|=          1.58
At iterate    36  f =       -810.6  |proj g|=       0.34042
At iterate    37  f =      -811.63  |proj g|=       0.32884
At iterate    38  f =      -812.85  |proj g|=       0.68596
At iterate    39  f =      -812.87  |proj g|=       0.29518
At iterate    40  f =      -812.87  |proj g|=       0.29432
At iterate    41  f =      -812.87  |proj g|=       0.10634
At iterate    42  f =      -812.87  |proj g|=     0.0066421
At iterate    43  f =      -812.87  |proj g|=    0.00033184

iterations 43
function evaluations 55
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000331835
final function value -812.871

F = -812.871
final  value -812.871437 
converged
 
INFO  [09:35:33.448] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:35:33.543] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:35:33.551] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:35:39.731] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:35:45.681] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:35:51.637] [mlr3]  Finished benchmark 
INFO  [09:35:51.761] [bbotk] Result of batch 154: 
INFO  [09:35:51.763] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:35:51.763] [bbotk]              8.632721                 8.850417                       0.3620154 
INFO  [09:35:51.763] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:35:51.763] [bbotk]                     3913        1.001 -0.9352505         <NA>   0.9719435 
INFO  [09:35:51.763] [bbotk]                                 uhash 
INFO  [09:35:51.763] [bbotk]  22659df2-de32-4113-9628-e8684e460973 
DEBUG [09:35:53.090] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.274133e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.274133e-05 0.001486815 
  - best initial criterion value(s) :  644.5129 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -644.51  |proj g|=        4.437
At iterate     1  f =      -664.04  |proj g|=        3.2832
At iterate     2  f =      -664.32  |proj g|=        3.0499
At iterate     3  f =       -664.7  |proj g|=        3.2185
At iterate     4  f =      -664.84  |proj g|=        3.5709
At iterate     5  f =      -664.89  |proj g|=        3.4607
At iterate     6  f =      -664.89  |proj g|=        3.4663
At iterate     7  f =      -664.89  |proj g|=        3.4723
At iterate     8  f =      -664.89  |proj g|=        3.4709
At iterate     9  f =      -664.89  |proj g|=        3.4706

iterations 9
function evaluations 15
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.47062
final function value -664.891

F = -664.891
final  value -664.891040 
converged
 
INFO  [09:35:53.094] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:35:53.182] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:35:53.189] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:35:56.908] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:36:00.954] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:36:05.041] [mlr3]  Finished benchmark 
INFO  [09:36:05.162] [bbotk] Result of batch 155: 
INFO  [09:36:05.164] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:36:05.164] [bbotk]              4.939408                 8.415922                       0.3391324 
INFO  [09:36:05.164] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [09:36:05.164] [bbotk]                     2487        0.893 -0.969462         <NA>   0.9731434 
INFO  [09:36:05.164] [bbotk]                                 uhash 
INFO  [09:36:05.164] [bbotk]  fcae09aa-19e3-4f2f-8eee-d57ac17e647d 
DEBUG [09:36:06.857] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.270911e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.270911e-05 0.001487428 
  - best initial criterion value(s) :  731.4499 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -731.45  |proj g|=       3.7965
At iterate     1  f =       -772.4  |proj g|=        9.8793
At iterate     2  f =      -773.26  |proj g|=        9.4111
At iterate     3  f =      -774.82  |proj g|=        7.1086
At iterate     4  f =      -775.23  |proj g|=         7.484
At iterate     5  f =      -776.64  |proj g|=        7.7631
At iterate     6  f =      -780.85  |proj g|=         7.292
At iterate     7  f =      -788.32  |proj g|=        5.0317
At iterate     8  f =      -792.07  |proj g|=        2.7905
At iterate     9  f =      -792.22  |proj g|=        2.4135
At iterate    10  f =      -792.79  |proj g|=        2.6043
At iterate    11  f =      -792.95  |proj g|=        2.6422
At iterate    12  f =         -793  |proj g|=        2.6475
At iterate    13  f =         -793  |proj g|=        2.6554
At iterate    14  f =      -793.01  |proj g|=        2.6565
At iterate    15  f =      -793.01  |proj g|=         2.657
At iterate    16  f =      -793.01  |proj g|=         2.658
At iterate    17  f =      -793.01  |proj g|=        2.6599
At iterate    18  f =      -793.01  |proj g|=        2.6607
At iterate    19  f =      -793.02  |proj g|=        2.6587
At iterate    20  f =      -793.05  |proj g|=         2.631
At iterate    21  f =      -793.09  |proj g|=        2.7174
At iterate    22  f =      -793.19  |proj g|=        2.6354
At iterate    23  f =      -793.22  |proj g|=        2.8166
At iterate    24  f =      -793.63  |proj g|=        2.5099
At iterate    25  f =      -794.72  |proj g|=        2.1135
At iterate    26  f =      -796.74  |proj g|=        1.8521
At iterate    27  f =      -808.28  |proj g|=        1.5732
At iterate    28  f =      -813.07  |proj g|=        1.0336
At iterate    29  f =       -814.2  |proj g|=       0.72215
At iterate    30  f =       -814.5  |proj g|=       0.73935
At iterate    31  f =      -814.51  |proj g|=       0.24065
At iterate    32  f =      -814.52  |proj g|=       0.13254
At iterate    33  f =      -814.52  |proj g|=       0.13051
At iterate    34  f =      -814.52  |proj g|=       0.13068

iterations 34
function evaluations 42
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.130681
final function value -814.519

F = -814.519
final  value -814.519060 
converged
 
INFO  [09:36:06.859] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:36:06.956] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:36:06.966] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:36:09.184] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:36:10.977] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:36:12.709] [mlr3]  Finished benchmark 
INFO  [09:36:12.822] [bbotk] Result of batch 156: 
INFO  [09:36:12.824] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:36:12.824] [bbotk]              6.373408                 9.754198                       0.2910247 
INFO  [09:36:12.824] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:36:12.824] [bbotk]                      736        0.934 -0.9441549         <NA>   0.9671587 
INFO  [09:36:12.824] [bbotk]                                 uhash 
INFO  [09:36:12.824] [bbotk]  866fe302-8945-4d70-82a1-5c16c090cfc4 
DEBUG [09:36:14.380] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.264343e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.264343e-05 0.001473522 
  - best initial criterion value(s) :  762.3297 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -762.33  |proj g|=      0.61289
At iterate     1  f =      -776.69  |proj g|=        5.4877
At iterate     2  f =      -777.08  |proj g|=        5.2082
At iterate     3  f =      -777.31  |proj g|=        4.6101
At iterate     4  f =      -777.32  |proj g|=        4.7409
At iterate     5  f =      -777.32  |proj g|=        4.7269
At iterate     6  f =      -777.32  |proj g|=        4.7258
At iterate     7  f =      -777.32  |proj g|=        4.7184
At iterate     8  f =      -777.32  |proj g|=        4.7151
At iterate     9  f =      -777.32  |proj g|=        4.7197
At iterate    10  f =      -777.32  |proj g|=        4.7427
At iterate    11  f =      -777.32  |proj g|=        4.7386
At iterate    12  f =      -777.32  |proj g|=        4.7385

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.73851
final function value -777.324

F = -777.324
final  value -777.323504 
converged
 
INFO  [09:36:14.384] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:36:14.473] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:36:14.480] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:36:17.519] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:36:21.676] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:36:24.577] [mlr3]  Finished benchmark 
INFO  [09:36:24.714] [bbotk] Result of batch 157: 
INFO  [09:36:24.715] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:36:24.715] [bbotk]              9.865834                 5.414376                       0.2073196 
INFO  [09:36:24.715] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:36:24.715] [bbotk]                     1262        0.901 -0.9583918         <NA>   0.9680668 
INFO  [09:36:24.715] [bbotk]                                 uhash 
INFO  [09:36:24.715] [bbotk]  c90c0079-55a8-42f5-9c1f-d0af3252dc8c 
DEBUG [09:36:26.429] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.2581e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.2581e-05 0.001464173 
  - best initial criterion value(s) :  737.7952 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -737.8  |proj g|=       10.234
At iterate     1  f =      -787.48  |proj g|=        4.3444
At iterate     2  f =      -793.23  |proj g|=        4.0937
At iterate     3  f =      -801.65  |proj g|=        2.8248
At iterate     4  f =      -803.82  |proj g|=        3.1326
At iterate     5  f =      -809.09  |proj g|=        3.3709
At iterate     6  f =      -815.05  |proj g|=        3.3659
At iterate     7  f =      -815.26  |proj g|=        3.6523
At iterate     8  f =      -815.28  |proj g|=        3.6022
At iterate     9  f =      -815.28  |proj g|=        3.5935
At iterate    10  f =      -815.28  |proj g|=        3.5983
At iterate    11  f =      -815.28  |proj g|=        3.5938
At iterate    12  f =      -815.56  |proj g|=         3.472
At iterate    13  f =      -816.63  |proj g|=        3.2552
At iterate    14  f =      -819.36  |proj g|=        2.9106
At iterate    15  f =      -822.16  |proj g|=        2.7316
At iterate    16  f =       -823.7  |proj g|=        2.7274
At iterate    17  f =      -824.38  |proj g|=        2.8401
At iterate    18  f =       -824.6  |proj g|=         2.991
At iterate    19  f =      -824.64  |proj g|=        3.0568
At iterate    20  f =      -824.64  |proj g|=        3.0691
At iterate    21  f =      -824.64  |proj g|=        3.0723
At iterate    22  f =      -824.64  |proj g|=        3.0725
At iterate    23  f =      -824.64  |proj g|=        3.0726
At iterate    24  f =      -824.64  |proj g|=        3.0731
At iterate    25  f =      -824.64  |proj g|=        3.0732
At iterate    26  f =      -824.64  |proj g|=        3.0723
At iterate    27  f =      -824.64  |proj g|=        3.0725
At iterate    28  f =      -824.64  |proj g|=        3.0648
At iterate    29  f =      -824.64  |proj g|=        3.0672
At iterate    30  f =      -824.65  |proj g|=        3.0692
At iterate    31  f =      -824.69  |proj g|=        3.0728
At iterate    32  f =      -824.79  |proj g|=        3.0672
At iterate    33  f =      -825.16  |proj g|=        3.0231
At iterate    34  f =      -825.93  |proj g|=        3.1324
At iterate    35  f =      -827.51  |proj g|=        2.1012
At iterate    36  f =      -828.93  |proj g|=        1.5871
At iterate    37  f =      -832.99  |proj g|=       0.74436
At iterate    38  f =      -834.58  |proj g|=       0.28132
At iterate    39  f =      -834.61  |proj g|=       0.28538
At iterate    40  f =      -834.62  |proj g|=       0.28894
At iterate    41  f =      -834.62  |proj g|=       0.28905
At iterate    42  f =      -834.62  |proj g|=      0.021552
At iterate    43  f =      -834.62  |proj g|=    0.00063432

iterations 43
function evaluations 54
segments explored during Cauchy searches 45
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000634318
final function value -834.624

F = -834.624
final  value -834.623546 
converged
 
INFO  [09:36:26.433] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:36:26.521] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:36:26.528] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:36:36.391] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:36:44.605] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:36:51.903] [mlr3]  Finished benchmark 
INFO  [09:36:52.040] [bbotk] Result of batch 158: 
INFO  [09:36:52.042] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:36:52.042] [bbotk]              7.754705                 6.145047                       0.1866232 
INFO  [09:36:52.042] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:36:52.042] [bbotk]                     3352        0.901 -0.9358576         <NA>   0.9725334 
INFO  [09:36:52.042] [bbotk]                                 uhash 
INFO  [09:36:52.042] [bbotk]  8ffd30f4-c2a3-4979-8f65-90b803ca60a9 
DEBUG [09:36:53.751] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.254443e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.254443e-05 0.001463257 
  - best initial criterion value(s) :  745.2264 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -745.23  |proj g|=        12.12
At iterate     1  f =       -776.4  |proj g|=        2.5403
At iterate     2  f =      -780.21  |proj g|=        3.4633
At iterate     3  f =      -780.68  |proj g|=        3.2469
At iterate     4  f =      -780.83  |proj g|=         2.943
At iterate     5  f =      -780.84  |proj g|=        2.9927
At iterate     6  f =      -780.84  |proj g|=        2.9839
At iterate     7  f =      -780.84  |proj g|=        2.9824
At iterate     8  f =      -780.84  |proj g|=        2.9788
At iterate     9  f =      -780.84  |proj g|=         2.971
At iterate    10  f =      -780.85  |proj g|=        2.9592
At iterate    11  f =      -780.85  |proj g|=        2.9322
At iterate    12  f =      -780.86  |proj g|=        2.9068
At iterate    13  f =      -780.87  |proj g|=        2.8534
At iterate    14  f =       -780.9  |proj g|=        2.8299
At iterate    15  f =       -781.2  |proj g|=        2.6856
At iterate    16  f =      -781.76  |proj g|=        2.4974
At iterate    17  f =      -783.77  |proj g|=         2.103
At iterate    18  f =       -788.9  |proj g|=        1.0411
At iterate    19  f =      -789.78  |proj g|=        1.0354
At iterate    20  f =      -790.86  |proj g|=       0.86716
At iterate    21  f =      -793.62  |proj g|=       0.85498
At iterate    22  f =      -796.58  |proj g|=        0.8293
At iterate    23  f =      -796.99  |proj g|=       0.81827
At iterate    24  f =      -797.06  |proj g|=       0.88436
At iterate    25  f =      -797.07  |proj g|=       0.95667
At iterate    26  f =      -797.07  |proj g|=        0.9915
At iterate    27  f =      -797.07  |proj g|=       0.98561
At iterate    28  f =      -797.07  |proj g|=       0.98567

iterations 28
function evaluations 33
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.985673
final function value -797.069

F = -797.069
final  value -797.068647 
converged
 
INFO  [09:36:53.755] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:36:53.844] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:36:53.851] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:36:55.672] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:36:58.268] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:37:00.510] [mlr3]  Finished benchmark 
INFO  [09:37:00.626] [bbotk] Result of batch 159: 
INFO  [09:37:00.628] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:37:00.628] [bbotk]              9.944041                 2.195744                       0.1073923 
INFO  [09:37:00.628] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:37:00.628] [bbotk]                      983          1.1 -0.9561577         <NA>   0.9607924 
INFO  [09:37:00.628] [bbotk]                                 uhash 
INFO  [09:37:00.628] [bbotk]  87a2122e-9a5d-4d65-a9e5-2c0b5e9ca965 
DEBUG [09:37:01.954] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.248737e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.248737e-05 0.001455545 
  - best initial criterion value(s) :  718.1397 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -718.14  |proj g|=       10.729
At iterate     1  f =      -800.71  |proj g|=         2.381
At iterate     2  f =      -812.13  |proj g|=        3.0673
At iterate     3  f =       -813.9  |proj g|=        2.7722
At iterate     4  f =      -815.71  |proj g|=          1.85
At iterate     5  f =      -816.34  |proj g|=        1.1492
At iterate     6  f =      -816.34  |proj g|=        1.1291
At iterate     7  f =      -816.34  |proj g|=        1.1256
At iterate     8  f =      -816.34  |proj g|=        1.1293
At iterate     9  f =      -816.34  |proj g|=        1.1282

iterations 9
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.12819
final function value -816.344

F = -816.344
final  value -816.343768 
converged
 
INFO  [09:37:01.958] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:37:02.050] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:37:02.057] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:37:07.587] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:37:13.829] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:37:21.428] [mlr3]  Finished benchmark 
INFO  [09:37:21.532] [bbotk] Result of batch 160: 
INFO  [09:37:21.534] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:37:21.534] [bbotk]              9.755663                 4.667105                       0.1224291 
INFO  [09:37:21.534] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:37:21.534] [bbotk]                     2529        0.906 -0.9535579         <NA>   0.9688602 
INFO  [09:37:21.534] [bbotk]                                 uhash 
INFO  [09:37:21.534] [bbotk]  9efa0bf9-ecf0-40ad-a579-3a3278e89b7e 
DEBUG [09:37:23.220] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.242954e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.242954e-05 0.001450182 
  - best initial criterion value(s) :  777.7398 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -777.74  |proj g|=       6.9798
At iterate     1  f =      -803.16  |proj g|=        4.0019
At iterate     2  f =      -805.08  |proj g|=        4.9952
At iterate     3  f =       -806.7  |proj g|=        5.9083
At iterate     4  f =      -808.38  |proj g|=        6.1068
At iterate     5  f =      -808.54  |proj g|=           5.5
At iterate     6  f =      -808.56  |proj g|=        5.6026
At iterate     7  f =      -808.57  |proj g|=        5.6414
At iterate     8  f =      -808.57  |proj g|=        5.6259
At iterate     9  f =      -808.57  |proj g|=        5.6271
At iterate    10  f =      -808.57  |proj g|=        5.6277
At iterate    11  f =      -808.57  |proj g|=        5.6295
At iterate    12  f =      -808.57  |proj g|=        5.6319
At iterate    13  f =      -808.57  |proj g|=        5.6359
At iterate    14  f =      -808.57  |proj g|=        5.6421
At iterate    15  f =      -808.57  |proj g|=        5.6521
At iterate    16  f =      -808.58  |proj g|=        5.6681
At iterate    17  f =      -808.58  |proj g|=        5.6946
At iterate    18  f =      -808.59  |proj g|=        5.7378
At iterate    19  f =      -808.61  |proj g|=        5.8045
At iterate    20  f =      -808.67  |proj g|=        5.8885
At iterate    21  f =      -808.75  |proj g|=        5.9273
At iterate    22  f =      -808.79  |proj g|=        5.7925
At iterate    23  f =       -808.8  |proj g|=        5.8088
At iterate    24  f =      -809.34  |proj g|=        5.5602
At iterate    25  f =      -812.57  |proj g|=        3.8935
At iterate    26  f =      -813.87  |proj g|=        4.0509
At iterate    27  f =      -814.09  |proj g|=        3.7899
At iterate    28  f =      -814.21  |proj g|=        4.2063
At iterate    29  f =      -814.22  |proj g|=        4.1843
At iterate    30  f =      -814.22  |proj g|=        4.2183
At iterate    31  f =      -814.22  |proj g|=        4.2165
At iterate    32  f =      -814.22  |proj g|=        4.2165

iterations 32
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.21647
final function value -814.219

F = -814.219
final  value -814.219383 
converged
 
INFO  [09:37:23.224] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:37:23.315] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:37:23.322] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:37:35.525] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:37:45.961] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:37:56.510] [mlr3]  Finished benchmark 
INFO  [09:37:56.617] [bbotk] Result of batch 161: 
INFO  [09:37:56.619] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:37:56.619] [bbotk]              5.290135                  8.83443                       0.3615143 
INFO  [09:37:56.619] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:37:56.619] [bbotk]                     4523        0.965 -0.9547499         <NA>   0.9749382 
INFO  [09:37:56.619] [bbotk]                                 uhash 
INFO  [09:37:56.619] [bbotk]  17d8d0fa-0a97-4a2c-80b2-49b56afa8721 
DEBUG [09:37:58.359] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.241592e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.241592e-05 0.001449749 
  - best initial criterion value(s) :  774.3559 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -774.36  |proj g|=       3.6397
At iterate     1  f =      -785.96  |proj g|=       0.82134
At iterate     2  f =      -786.11  |proj g|=       0.82064
At iterate     3  f =      -786.17  |proj g|=       0.37476
At iterate     4  f =      -786.17  |proj g|=        0.3749
At iterate     5  f =      -786.17  |proj g|=       0.37503
At iterate     6  f =      -786.18  |proj g|=         0.376
At iterate     7  f =      -786.19  |proj g|=       0.37753
At iterate     8  f =       -786.2  |proj g|=       0.37983
At iterate     9  f =       -786.2  |proj g|=       0.38071
At iterate    10  f =       -786.2  |proj g|=       0.38056
At iterate    11  f =       -786.2  |proj g|=       0.38052
At iterate    12  f =       -786.2  |proj g|=        0.3805
At iterate    13  f =       -786.2  |proj g|=       0.38049
At iterate    14  f =       -786.2  |proj g|=       0.38041
At iterate    15  f =       -786.2  |proj g|=       0.38021
At iterate    16  f =       -786.2  |proj g|=       0.37987
At iterate    17  f =       -786.2  |proj g|=        0.3791
At iterate    18  f =       -786.2  |proj g|=       0.37732
At iterate    19  f =       -786.2  |proj g|=       0.37673
At iterate    20  f =      -786.21  |proj g|=       0.37356
At iterate    21  f =      -786.21  |proj g|=        0.3689
At iterate    22  f =      -786.22  |proj g|=       0.36554
At iterate    23  f =      -786.22  |proj g|=       0.36529
At iterate    24  f =      -786.22  |proj g|=       0.36665
At iterate    25  f =      -786.22  |proj g|=       0.36646
At iterate    26  f =      -786.22  |proj g|=       0.36647

iterations 26
function evaluations 36
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.366465
final function value -786.22

F = -786.22
final  value -786.219708 
converged
 
INFO  [09:37:58.363] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:37:58.476] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:37:58.487] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:38:10.005] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:38:21.449] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:38:34.230] [mlr3]  Finished benchmark 
INFO  [09:38:34.336] [bbotk] Result of batch 162: 
INFO  [09:38:34.338] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:38:34.338] [bbotk]              4.154616                 2.837957                       0.4527721 
INFO  [09:38:34.338] [bbotk]  ps_cboost_anneal2.mstop propose.time crit.vals errors.model classif.auc 
INFO  [09:38:34.338] [bbotk]                     4966        1.063 -0.959495         <NA>   0.9745497 
INFO  [09:38:34.338] [bbotk]                                 uhash 
INFO  [09:38:34.338] [bbotk]  05b74c7b-ec17-4f29-873b-4e25639c9965 
DEBUG [09:38:35.984] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.2398e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.2398e-05 0.001448302 
  - best initial criterion value(s) :  741.1708 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -741.17  |proj g|=       11.532
At iterate     1  f =      -743.21  |proj g|=         1.809
At iterate     2  f =      -776.11  |proj g|=        3.1021
At iterate     3  f =      -791.06  |proj g|=        5.3751
At iterate     4  f =      -800.69  |proj g|=        5.1248
At iterate     5  f =      -814.87  |proj g|=        5.0287
At iterate     6  f =      -815.01  |proj g|=        5.2422
At iterate     7  f =      -815.02  |proj g|=        5.4344
At iterate     8  f =      -815.03  |proj g|=        5.3513
At iterate     9  f =      -815.03  |proj g|=         5.313
At iterate    10  f =      -815.03  |proj g|=        5.2731
At iterate    11  f =      -815.04  |proj g|=        5.1975
At iterate    12  f =      -815.07  |proj g|=        5.0739
At iterate    13  f =      -815.13  |proj g|=        4.8656
At iterate    14  f =      -815.29  |proj g|=        4.5327
At iterate    15  f =      -815.67  |proj g|=          3.99
At iterate    16  f =      -816.55  |proj g|=        3.2518
At iterate    17  f =      -816.75  |proj g|=        2.8269
At iterate    18  f =      -818.47  |proj g|=        2.1155
At iterate    19  f =      -826.64  |proj g|=        2.7115
At iterate    20  f =      -827.49  |proj g|=        3.3585
At iterate    21  f =      -828.37  |proj g|=        3.4807
At iterate    22  f =      -828.59  |proj g|=        3.9499
At iterate    23  f =      -828.61  |proj g|=        3.8492
At iterate    24  f =      -828.66  |proj g|=        3.8593
At iterate    25  f =      -828.66  |proj g|=        3.9499
At iterate    26  f =      -828.66  |proj g|=        3.9478
At iterate    27  f =      -828.66  |proj g|=        3.9475

iterations 27
function evaluations 36
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.94751
final function value -828.659

F = -828.659
final  value -828.659031 
converged
 
INFO  [09:38:35.988] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:38:36.125] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:38:36.133] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:38:46.791] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:38:59.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:39:10.682] [mlr3]  Finished benchmark 
INFO  [09:39:10.832] [bbotk] Result of batch 163: 
INFO  [09:39:10.834] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:39:10.834] [bbotk]              8.495425                  9.10003                       0.1683384 
INFO  [09:39:10.834] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:39:10.834] [bbotk]                     4812        0.946 -0.9554292         <NA>   0.9715383 
INFO  [09:39:10.834] [bbotk]                                 uhash 
INFO  [09:39:10.834] [bbotk]  deaedec8-3f63-41b2-9296-212b05cea275 
DEBUG [09:39:12.400] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.235513e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.235513e-05 0.001442163 
  - best initial criterion value(s) :  804.9428 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -804.94  |proj g|=        4.234
At iterate     1  f =      -823.31  |proj g|=        5.6024
At iterate     2  f =      -830.98  |proj g|=        4.7995
At iterate     3  f =      -838.74  |proj g|=         2.855
At iterate     4  f =         -839  |proj g|=        2.1997
At iterate     5  f =      -839.17  |proj g|=        2.3682
At iterate     6  f =      -839.63  |proj g|=        2.5835
At iterate     7  f =      -840.65  |proj g|=        2.6736
At iterate     8  f =      -841.74  |proj g|=         2.375
At iterate     9  f =      -841.95  |proj g|=         2.001
At iterate    10  f =      -841.95  |proj g|=        2.0209
At iterate    11  f =      -841.96  |proj g|=        2.0542
At iterate    12  f =      -841.96  |proj g|=        2.0552
At iterate    13  f =      -841.96  |proj g|=        2.0554
At iterate    14  f =      -841.96  |proj g|=        2.0573
At iterate    15  f =      -841.96  |proj g|=        2.0598
At iterate    16  f =      -841.97  |proj g|=        2.0639
At iterate    17  f =      -841.97  |proj g|=        2.0672
At iterate    18  f =      -841.98  |proj g|=        2.0626
At iterate    19  f =      -842.01  |proj g|=        2.0782
At iterate    20  f =      -842.08  |proj g|=        2.0201
At iterate    21  f =      -842.09  |proj g|=        2.1138
At iterate    22  f =      -842.25  |proj g|=         1.992
At iterate    23  f =      -843.55  |proj g|=        1.6489
At iterate    24  f =      -848.68  |proj g|=       0.98103
At iterate    25  f =      -850.57  |proj g|=       0.58164
At iterate    26  f =      -850.58  |proj g|=       0.58164
At iterate    27  f =      -850.58  |proj g|=       0.58164
At iterate    28  f =      -850.58  |proj g|=       0.58164

iterations 28
function evaluations 32
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.581636
final function value -850.579

F = -850.579
final  value -850.579019 
converged
 
INFO  [09:39:12.404] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:39:12.495] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:39:12.503] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:39:21.544] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:39:28.606] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:39:35.793] [mlr3]  Finished benchmark 
INFO  [09:39:35.917] [bbotk] Result of batch 164: 
INFO  [09:39:35.919] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:39:35.919] [bbotk]              7.526782                 5.301493                       0.2151685 
INFO  [09:39:35.919] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:39:35.919] [bbotk]                     4677        0.938 -0.9439956         <NA>   0.9738674 
INFO  [09:39:35.919] [bbotk]                                 uhash 
INFO  [09:39:35.919] [bbotk]  fe4ee3c4-fbfd-495d-bb23-b384350bc52f 
DEBUG [09:39:37.611] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.233057e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.233057e-05 0.001442077 
  - best initial criterion value(s) :  759.0491 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -759.05  |proj g|=       7.6635
At iterate     1  f =       -836.2  |proj g|=        2.2332
At iterate     2  f =      -845.08  |proj g|=        4.1567
At iterate     3  f =      -854.56  |proj g|=        4.1065
At iterate     4  f =      -858.28  |proj g|=        2.1411
At iterate     5  f =      -859.34  |proj g|=        3.1244
At iterate     6  f =       -859.7  |proj g|=        2.9747
At iterate     7  f =      -860.49  |proj g|=        2.5244
At iterate     8  f =      -860.96  |proj g|=        2.7515
At iterate     9  f =      -861.19  |proj g|=        3.0111
At iterate    10  f =      -861.22  |proj g|=        3.0095
At iterate    11  f =      -861.22  |proj g|=        2.9938
At iterate    12  f =      -861.22  |proj g|=        2.9968
At iterate    13  f =      -861.22  |proj g|=        2.9965

iterations 13
function evaluations 15
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.99652
final function value -861.217

F = -861.217
final  value -861.217265 
converged
 
INFO  [09:39:37.615] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:39:37.785] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:39:37.794] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:39:43.134] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:39:47.772] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:39:52.612] [mlr3]  Finished benchmark 
INFO  [09:39:52.761] [bbotk] Result of batch 165: 
INFO  [09:39:52.764] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:39:52.764] [bbotk]              7.536519                 9.581283                       0.3000786 
INFO  [09:39:52.764] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:39:52.764] [bbotk]                     3042        1.085 -0.9420599         <NA>   0.9736385 
INFO  [09:39:52.764] [bbotk]                                 uhash 
INFO  [09:39:52.764] [bbotk]  0e83e84e-2fe6-40af-83a8-daac530ec63c 
DEBUG [09:39:54.521] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.230386e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.230386e-05 0.00144025 
  - best initial criterion value(s) :  771.9342 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -771.93  |proj g|=       9.6753
At iterate     1  f =      -802.27  |proj g|=        3.4709
At iterate     2  f =      -803.02  |proj g|=        3.3373
At iterate     3  f =      -803.81  |proj g|=        3.2857
At iterate     4  f =      -803.93  |proj g|=        2.9758
At iterate     5  f =      -804.57  |proj g|=        3.0277
At iterate     6  f =      -805.53  |proj g|=        3.0705
At iterate     7  f =      -805.69  |proj g|=        3.3624
At iterate     8  f =       -805.8  |proj g|=        3.2742
At iterate     9  f =      -805.85  |proj g|=        3.2403
At iterate    10  f =      -806.03  |proj g|=         3.195
At iterate    11  f =      -806.62  |proj g|=        3.1166
At iterate    12  f =      -806.64  |proj g|=        3.1643
At iterate    13  f =      -806.64  |proj g|=         3.191
At iterate    14  f =      -806.64  |proj g|=        3.1956
At iterate    15  f =      -806.64  |proj g|=         3.191
At iterate    16  f =      -806.64  |proj g|=         3.194
At iterate    17  f =      -806.65  |proj g|=        3.2022
At iterate    18  f =      -806.66  |proj g|=        3.2317
At iterate    19  f =      -806.69  |proj g|=        3.2776
At iterate    20  f =      -806.78  |proj g|=         3.351
At iterate    21  f =      -806.99  |proj g|=        3.4615
At iterate    22  f =      -807.49  |proj g|=         3.615
At iterate    23  f =      -808.57  |proj g|=         3.779
At iterate    24  f =      -810.81  |proj g|=        3.7654
At iterate    25  f =       -812.5  |proj g|=        2.9098
At iterate    26  f =      -813.57  |proj g|=        2.9977
At iterate    27  f =      -813.63  |proj g|=        2.8657
At iterate    28  f =      -813.63  |proj g|=        2.8566
At iterate    29  f =      -813.63  |proj g|=        2.8574
At iterate    30  f =      -813.63  |proj g|=        2.8578

iterations 30
function evaluations 37
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.85777
final function value -813.631

F = -813.631
final  value -813.631213 
converged
 
INFO  [09:39:54.526] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:39:54.636] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:39:54.644] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:39:56.116] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:39:57.617] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:39:59.162] [mlr3]  Finished benchmark 
INFO  [09:39:59.287] [bbotk] Result of batch 166: 
INFO  [09:39:59.289] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:39:59.289] [bbotk]               3.39539                 5.897439                       0.4870768 
INFO  [09:39:59.289] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:39:59.289] [bbotk]                      734        1.043 -0.9537291         <NA>   0.9648662 
INFO  [09:39:59.289] [bbotk]                                 uhash 
INFO  [09:39:59.289] [bbotk]  25b44350-3cb4-4fbe-9816-8b2f86e93b13 
DEBUG [09:40:00.861] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.224115e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.224115e-05 0.001429746 
  - best initial criterion value(s) :  695.5996 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -695.6  |proj g|=       12.615
At iterate     1  f =      -806.52  |proj g|=        3.8445
At iterate     2  f =      -813.39  |proj g|=        8.7207
At iterate     3  f =      -815.91  |proj g|=        7.6321
At iterate     4  f =      -820.71  |proj g|=        5.0944
At iterate     5  f =      -822.64  |proj g|=        4.3418
At iterate     6  f =      -824.45  |proj g|=         5.204
At iterate     7  f =      -824.61  |proj g|=        5.8715
At iterate     8  f =      -824.61  |proj g|=        5.9116
At iterate     9  f =      -824.61  |proj g|=        5.9198
At iterate    10  f =      -824.61  |proj g|=        5.9679
At iterate    11  f =      -824.62  |proj g|=        6.0239
At iterate    12  f =      -824.63  |proj g|=        6.1269
At iterate    13  f =      -824.67  |proj g|=        6.2833
At iterate    14  f =      -824.76  |proj g|=        6.5342
At iterate    15  f =         -825  |proj g|=        6.9102
At iterate    16  f =      -825.61  |proj g|=        7.4595
At iterate    17  f =      -834.84  |proj g|=        5.6918
At iterate    18  f =      -865.72  |proj g|=        5.0696
At iterate    19  f =      -868.64  |proj g|=        4.3101
At iterate    20  f =      -868.83  |proj g|=        4.1284
At iterate    21  f =      -868.91  |proj g|=         3.943
At iterate    22  f =      -868.92  |proj g|=        4.0348
At iterate    23  f =      -868.92  |proj g|=        4.0211
At iterate    24  f =      -868.92  |proj g|=        4.0203

iterations 24
function evaluations 31
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 4.02034
final function value -868.916

F = -868.916
final  value -868.916010 
converged
 
INFO  [09:40:00.865] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:40:00.961] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:40:00.969] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:40:06.047] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:40:11.206] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:40:16.347] [mlr3]  Finished benchmark 
INFO  [09:40:16.509] [bbotk] Result of batch 167: 
INFO  [09:40:16.511] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:40:16.511] [bbotk]               5.56736                 3.028999                     0.009260946 
INFO  [09:40:16.511] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:40:16.511] [bbotk]                     3172        0.937 -0.9428738         <NA>   0.9383971 
INFO  [09:40:16.511] [bbotk]                                 uhash 
INFO  [09:40:16.511] [bbotk]  c337821d-2346-4979-9845-716692a5ddff 
DEBUG [09:40:18.292] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.254236e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.254236e-05 0.001449783 
  - best initial criterion value(s) :  742.9868 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -742.99  |proj g|=       3.6103
At iterate     1  f =      -772.03  |proj g|=        13.174
At iterate     2  f =      -784.33  |proj g|=        12.992
At iterate     3  f =      -803.26  |proj g|=        12.741
At iterate     4  f =      -804.62  |proj g|=        12.682
At iterate     5  f =      -804.85  |proj g|=        12.642
At iterate     6  f =      -806.39  |proj g|=        12.248
At iterate     7  f =         -807  |proj g|=        11.048
At iterate     8  f =      -807.15  |proj g|=        11.476
At iterate     9  f =      -807.18  |proj g|=        11.769
At iterate    10  f =      -807.19  |proj g|=        11.804
At iterate    11  f =      -807.19  |proj g|=        11.807
At iterate    12  f =      -807.19  |proj g|=         11.82
At iterate    13  f =      -807.19  |proj g|=        11.835
At iterate    14  f =      -807.19  |proj g|=        11.864
At iterate    15  f =      -807.19  |proj g|=        11.907
At iterate    16  f =       -807.2  |proj g|=        11.979
At iterate    17  f =      -807.21  |proj g|=        11.994
At iterate    18  f =      -807.26  |proj g|=        11.994
At iterate    19  f =      -807.39  |proj g|=        11.993
At iterate    20  f =      -807.74  |proj g|=        11.993
At iterate    21  f =      -808.62  |proj g|=        11.992
At iterate    22  f =       -810.7  |proj g|=        11.988
At iterate    23  f =       -815.2  |proj g|=        11.981
At iterate    24  f =      -821.69  |proj g|=        11.973
At iterate    25  f =      -825.81  |proj g|=        11.802
At iterate    26  f =      -827.31  |proj g|=         11.11
At iterate    27  f =      -827.32  |proj g|=        11.153
At iterate    28  f =      -827.32  |proj g|=        11.153

iterations 28
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 11.1535
final function value -827.316

F = -827.316
final  value -827.315703 
converged
 
INFO  [09:40:18.297] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:40:18.406] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:40:18.415] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:40:25.015] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:40:37.669] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:40:47.175] [mlr3]  Finished benchmark 
INFO  [09:40:47.578] [bbotk] Result of batch 168: 
INFO  [09:40:47.580] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:40:47.580] [bbotk]              7.929427                 7.322675                       0.4520539 
INFO  [09:40:47.580] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:40:47.580] [bbotk]                     4006        0.927 -0.9607766         <NA>   0.9744697 
INFO  [09:40:47.580] [bbotk]                                 uhash 
INFO  [09:40:47.580] [bbotk]  003df470-5127-4dcd-b528-efdaaf800693 
DEBUG [09:40:48.957] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.252328e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.252328e-05 0.001448335 
  - best initial criterion value(s) :  834.7789 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -834.78  |proj g|=      0.95598
At iterate     1  f =      -846.87  |proj g|=        4.5392
At iterate     2  f =       -849.2  |proj g|=        4.1279
At iterate     3  f =      -850.17  |proj g|=        3.1408
At iterate     4  f =      -850.49  |proj g|=         3.563
At iterate     5  f =      -850.56  |proj g|=        3.5173
At iterate     6  f =      -850.92  |proj g|=        3.3058
At iterate     7  f =      -851.21  |proj g|=        3.3059
At iterate     8  f =      -851.57  |proj g|=        3.5417
At iterate     9  f =      -851.59  |proj g|=         3.574
At iterate    10  f =      -851.59  |proj g|=        3.5724
At iterate    11  f =      -851.59  |proj g|=         3.572

iterations 11
function evaluations 13
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.57204
final function value -851.588

F = -851.588
final  value -851.587989 
converged
 
INFO  [09:40:48.961] [bbotk] Evaluating 1 configuration(s) 
INFO  [09:40:49.108] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [09:40:49.116] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 2/3) 
INFO  [09:40:51.042] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 3/3) 
INFO  [09:40:52.928] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal2' on task 'spam' (iter 1/3) 
INFO  [09:40:54.940] [mlr3]  Finished benchmark 
INFO  [09:40:55.066] [bbotk] Result of batch 169: 
INFO  [09:40:55.068] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:40:55.068] [bbotk]              7.578746                 5.107626                       0.1932903 
INFO  [09:40:55.068] [bbotk]  ps_cboost_anneal2.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [09:40:55.068] [bbotk]                      608        0.942 -0.9551248         <NA>   0.9615898 
INFO  [09:40:55.068] [bbotk]                                 uhash 
INFO  [09:40:55.068] [bbotk]  5cce2460-ad56-4fec-9075-2d3a65bcd274 
DEBUG [09:40:55.137] [bbotk]  
INFO  [09:40:55.151] [bbotk] Finished optimizing after 200 evaluation(s) 
INFO  [09:40:55.153] [bbotk] Result: 
INFO  [09:40:55.155] [bbotk]  ps_cboost_anneal2.df ps_cboost_anneal2.df_cat ps_cboost_anneal2.learning_rate 
INFO  [09:40:55.155] [bbotk]              6.154457                 4.024338                        0.376388 
INFO  [09:40:55.155] [bbotk]  ps_cboost_anneal2.mstop learner_param_vals  x_domain classif.auc 
INFO  [09:40:55.155] [bbotk]                     4999         <list[19]> <list[4]>   0.9753932 
INFO  [09:41:07.328] [mlr3]  Finished benchmark 

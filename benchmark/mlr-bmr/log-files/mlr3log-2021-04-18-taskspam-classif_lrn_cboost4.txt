INFO  [21:58:38.056] [mlr3]  Running benchmark with 5 resampling iterations 
INFO  [21:58:38.165] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1.tuned' on task 'spam' (iter 4/5) 
INFO  [21:58:38.273] [bbotk] Starting to optimize 4 parameter(s) with '<OptimizerInterMBO>' and '<TerminatorEvals> [n_evals=200]' 
DEBUG [21:58:39.196] [bbotk]  
INFO  [21:58:39.216] [bbotk] Evaluating 32 configuration(s) 
INFO  [21:58:40.473] [mlr3]  Running benchmark with 96 resampling iterations 
INFO  [21:58:40.481] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [21:58:51.567] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [21:58:58.132] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [21:59:02.405] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [21:59:08.452] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [21:59:10.933] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [21:59:24.979] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [21:59:33.376] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [21:59:43.141] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [21:59:46.309] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [21:59:56.369] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:00:07.357] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:00:08.892] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:00:18.665] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:00:28.658] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:00:42.432] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:00:55.349] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:01:04.622] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:01:07.321] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:01:20.616] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:01:29.733] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:01:31.397] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:01:36.979] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:01:42.557] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:01:47.598] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:01:55.812] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:01:58.975] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:02:09.610] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:02:13.280] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:02:19.808] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:02:33.535] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:02:42.165] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:02:46.905] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:02:54.932] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:02:58.306] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:03:03.891] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:03:15.652] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:03:26.985] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:03:35.189] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:03:37.739] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:03:50.464] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:04:00.004] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:04:10.033] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:04:12.772] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:04:17.598] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:04:18.896] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:04:25.034] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:04:27.279] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:04:30.875] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:04:43.001] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:04:54.578] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:05:03.799] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:05:08.011] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:05:12.412] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:05:22.839] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:05:30.837] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:05:32.051] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:05:39.780] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:05:43.534] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:05:45.888] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:05:46.915] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:05:50.680] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:05:52.916] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:06:04.054] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:06:07.089] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:06:12.787] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:06:23.134] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:06:24.265] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:06:25.272] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:06:32.969] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:06:38.325] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:06:47.236] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:06:50.773] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:06:55.700] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:07:00.255] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:07:06.229] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:07:10.265] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:07:19.069] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:07:28.276] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:07:33.964] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:07:37.345] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:07:49.112] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:07:55.273] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:08:06.923] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:08:14.693] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:08:25.492] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:08:29.969] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:08:31.931] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:08:44.108] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:08:56.121] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:09:02.925] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:09:09.585] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:09:11.834] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:09:20.685] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:09:25.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:09:28.625] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:09:40.060] [mlr3]  Finished benchmark 
INFO  [22:09:41.647] [bbotk] Result of batch 1: 
INFO  [22:09:41.651] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:09:41.651] [bbotk]              4.152874                 8.959057                     0.168180978 
INFO  [22:09:41.651] [bbotk]              4.819695                 6.618220                     0.085913133 
INFO  [22:09:41.651] [bbotk]              5.552188                 8.444031                     0.462831400 
INFO  [22:09:41.651] [bbotk]              6.493104                 6.784911                     0.293487833 
INFO  [22:09:41.651] [bbotk]              7.344239                 5.031688                     0.392523442 
INFO  [22:09:41.651] [bbotk]              4.696148                 4.013402                     0.326326890 
INFO  [22:09:41.651] [bbotk]              8.536073                 3.530680                     0.377190753 
INFO  [22:09:41.651] [bbotk]              3.106622                 7.311592                     0.099607948 
INFO  [22:09:41.651] [bbotk]              9.083282                 8.669608                     0.238282478 
INFO  [22:09:41.651] [bbotk]              7.162224                 7.021630                     0.416587132 
INFO  [22:09:41.651] [bbotk]              5.986315                 3.403962                     0.234176299 
INFO  [22:09:41.651] [bbotk]              2.800148                 9.843598                     0.436498176 
INFO  [22:09:41.651] [bbotk]              9.350186                 5.480585                     0.141810995 
INFO  [22:09:41.651] [bbotk]              6.863931                 5.741304                     0.193337259 
INFO  [22:09:41.651] [bbotk]              8.310616                 8.077128                     0.019601991 
INFO  [22:09:41.651] [bbotk]              5.183952                 3.080761                     0.128141096 
INFO  [22:09:41.651] [bbotk]              6.724025                 4.741754                     0.471906857 
INFO  [22:09:41.651] [bbotk]              3.676510                 5.858597                     0.208586580 
INFO  [22:09:41.651] [bbotk]              5.495065                 9.141424                     0.184020680 
INFO  [22:09:41.651] [bbotk]              6.061086                 4.826894                     0.114884249 
INFO  [22:09:41.651] [bbotk]              8.068744                 2.683896                     0.304687116 
INFO  [22:09:41.651] [bbotk]              2.050413                 3.790852                     0.055034365 
INFO  [22:09:41.651] [bbotk]              2.695118                 4.340108                     0.443071272 
INFO  [22:09:41.651] [bbotk]              9.973115                 6.200862                     0.251814492 
INFO  [22:09:41.651] [bbotk]              3.386641                 6.343807                     0.270232046 
INFO  [22:09:41.651] [bbotk]              2.410865                 2.426261                     0.337928873 
INFO  [22:09:41.651] [bbotk]              9.604876                 9.290427                     0.033996118 
INFO  [22:09:41.651] [bbotk]              8.925028                 2.759242                     0.008841257 
INFO  [22:09:41.651] [bbotk]              7.637683                 7.576833                     0.365019013 
INFO  [22:09:41.651] [bbotk]              3.789919                 7.779337                     0.484604679 
INFO  [22:09:41.651] [bbotk]              7.963314                 2.034819                     0.349922121 
INFO  [22:09:41.651] [bbotk]              4.287181                 9.502664                     0.064141008 
INFO  [22:09:41.651] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:09:41.651] [bbotk]  ps_cboost_anneal1.mstop classif.auc                                uhash 
INFO  [22:09:41.651] [bbotk]                     1228   0.9647190 e3121b03-d6c8-4695-b6ad-681d8bff5599 
INFO  [22:09:41.651] [bbotk]                     3893   0.9700801 7accff5c-ba56-42c3-9229-834f4a2c91ed 
INFO  [22:09:41.651] [bbotk]                     2440   0.9757956 c9052da2-4b9f-4450-aed5-362dd4722448 
INFO  [22:09:41.651] [bbotk]                     1615   0.9729496 ed5cc0d1-9659-497d-86a9-20f52561a3a3 
INFO  [22:09:41.651] [bbotk]                     3671   0.9769034 4a43b9ee-b9f3-4a4c-870d-b05cbe0f827e 
INFO  [22:09:41.651] [bbotk]                     4397   0.9759575 3f7fcda7-7394-4e07-a95c-b00a6cd311cb 
INFO  [22:09:41.651] [bbotk]                     2113   0.9752498 1edfd8ec-507f-409e-b12b-ee31001537c5 
INFO  [22:09:41.651] [bbotk]                     3977   0.9650469 f7eb9bce-0dde-4866-92bd-63d88b907688 
INFO  [22:09:41.651] [bbotk]                     1021   0.9697173 3f074eb4-5120-42bd-bcd8-c76370ff3bef 
INFO  [22:09:41.651] [bbotk]                     1985   0.9751816 587d172b-3aae-447c-85d6-1fd46625db18 
INFO  [22:09:41.651] [bbotk]                      689   0.9658988 8a5bf35e-7103-4c58-bd63-ffdb28017e35 
INFO  [22:09:41.651] [bbotk]                     3557   0.9704780 484d75f2-7427-4bba-a928-e5ed8ed4dbed 
INFO  [22:09:41.651] [bbotk]                     2764   0.9725083 349b6c46-a55f-4cab-a307-1ccc4b190ffa 
INFO  [22:09:41.651] [bbotk]                     4996   0.9751581 a8cd1e07-c94c-4f7a-b60a-10b2a7024ed0 
INFO  [22:09:41.651] [bbotk]                     3338   0.9570421 6aee4061-a291-48e4-aa8d-b58ddad6b36c 
INFO  [22:09:41.651] [bbotk]                     4425   0.9733852 dd5ccb14-e867-4e47-b66d-6c53a090608e 
INFO  [22:09:41.651] [bbotk]                     2190   0.9753517 043d0588-e37d-4ad2-8e7d-b052618384ef 
INFO  [22:09:41.651] [bbotk]                      913   0.9619744 6376a9ff-aaee-4781-a6dd-b6e588550006 
INFO  [22:09:41.651] [bbotk]                     1525   0.9697249 ec184c6c-8ee0-44c9-b9b6-591d86292a85 
INFO  [22:09:41.651] [bbotk]                     2573   0.9703714 a473ed8c-b8fb-45a7-b4d8-ee3e9d1df0ff 
INFO  [22:09:41.651] [bbotk]                     4229   0.9768018 1a04e737-b3bf-4cbc-bfae-c56150bcb91b 
INFO  [22:09:41.651] [bbotk]                     2601   0.9386686 355ae40f-9bbf-42b9-a781-fa86e179c689 
INFO  [22:09:41.651] [bbotk]                      373   0.9500346 2d445bb8-2199-468e-a1a1-d5c0e0844b91 
INFO  [22:09:41.651] [bbotk]                     1308   0.9716644 bba9e5b8-f0c3-4be9-bd9d-847b02b98715 
INFO  [22:09:41.651] [bbotk]                     4644   0.9731571 a6ff0584-04c2-411a-bdff-94051e2892af 
INFO  [22:09:41.651] [bbotk]                     2966   0.9639273 459f8e14-b0ba-4c8f-8097-48bb64611dbe 
INFO  [22:09:41.651] [bbotk]                      549   0.9340172 544bc09b-6661-46c5-a057-4a55a757c30d 
INFO  [22:09:41.651] [bbotk]                     3051   0.9436675 d2df2d78-e3e1-4800-8f33-18664d8b2383 
INFO  [22:09:41.651] [bbotk]                     4781   0.9774119 3d4b4d09-a901-4709-a441-b96c6ab5fdd6 
INFO  [22:09:41.651] [bbotk]                     1800   0.9730733 67d63adf-18b7-4b7d-a0d8-5d4699c34948 
INFO  [22:09:41.651] [bbotk]                      273   0.9611737 82a35b7e-67f1-4b70-bc0a-4b197afd8d54 
INFO  [22:09:41.651] [bbotk]                     3444   0.9657988 f5a2e135-febc-4723-88ba-99f1e8286c92 
INFO  [22:09:41.651] [bbotk]  ps_cboost_anneal1.mstop classif.auc                                uhash 
DEBUG [22:09:43.193] [bbotk]  
DEBUG [22:09:43.196] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.253059e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.253059e-05 0.001299455 
  - best initial criterion value(s) :  107.9161 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -107.92  |proj g|=      0.55407
At iterate     1  f =      -113.61  |proj g|=        1.0765
At iterate     2  f =      -113.96  |proj g|=        1.0134
At iterate     3  f =      -114.78  |proj g|=       0.82429
At iterate     4  f =         -115  |proj g|=       0.76063
At iterate     5  f =      -115.43  |proj g|=       0.72712
At iterate     6  f =      -115.57  |proj g|=       0.81275
At iterate     7  f =      -115.58  |proj g|=       0.78104
At iterate     8  f =      -115.58  |proj g|=       0.78327
At iterate     9  f =      -115.58  |proj g|=       0.78393
At iterate    10  f =      -115.58  |proj g|=       0.78366
At iterate    11  f =      -115.58  |proj g|=       0.78364

iterations 11
function evaluations 16
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.783645
final function value -115.584

F = -115.584
final  value -115.584087 
converged
 
INFO  [22:09:43.200] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:09:43.255] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:09:43.262] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:09:49.211] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:09:56.051] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:10:02.672] [mlr3]  Finished benchmark 
INFO  [22:10:02.742] [bbotk] Result of batch 2: 
INFO  [22:10:02.744] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:10:02.744] [bbotk]              8.471689                  8.99554                       0.4734656 
INFO  [22:10:02.744] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:10:02.744] [bbotk]                     2311        0.498 -0.9641148         <NA>   0.9762672 
INFO  [22:10:02.744] [bbotk]                                 uhash 
INFO  [22:10:02.744] [bbotk]  22263f8b-acb8-4ed9-b5ff-f86224206b5d 
DEBUG [22:10:03.542] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.240121e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.240121e-05 0.001286738 
  - best initial criterion value(s) :  122.3353 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -122.34  |proj g|=       1.0043
At iterate     1  f =      -122.37  |proj g|=        1.0558
At iterate     2  f =      -122.49  |proj g|=        1.0347
At iterate     3  f =      -122.55  |proj g|=       0.99882
At iterate     4  f =      -122.56  |proj g|=        1.0126
At iterate     5  f =      -122.56  |proj g|=        1.0103
At iterate     6  f =      -122.56  |proj g|=        1.0102
At iterate     7  f =      -122.56  |proj g|=        1.0102

iterations 7
function evaluations 13
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.01015
final function value -122.557

F = -122.557
final  value -122.556742 
converged
 
INFO  [22:10:03.546] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:10:03.623] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:10:03.630] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:10:05.224] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:10:06.763] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:10:08.385] [mlr3]  Finished benchmark 
INFO  [22:10:08.455] [bbotk] Result of batch 3: 
INFO  [22:10:08.457] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:10:08.457] [bbotk]              3.635566                 2.939693                       0.3567618 
INFO  [22:10:08.457] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:10:08.457] [bbotk]                      477        0.486 -0.9644349         <NA>    0.960664 
INFO  [22:10:08.457] [bbotk]                                 uhash 
INFO  [22:10:08.457] [bbotk]  d7d68d27-4c36-43d7-abae-1907fdced4c9 
DEBUG [22:10:09.136] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.215288e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.215288e-05 0.001274159 
  - best initial criterion value(s) :  119.6393 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -119.64  |proj g|=      0.85181
At iterate     1  f =      -120.85  |proj g|=        1.1581
At iterate     2  f =      -121.77  |proj g|=        1.0505
At iterate     3  f =      -121.81  |proj g|=        1.0915
At iterate     4  f =      -121.82  |proj g|=        1.0851
At iterate     5  f =      -121.82  |proj g|=        1.0837
At iterate     6  f =      -121.82  |proj g|=        1.0852
At iterate     7  f =      -121.82  |proj g|=        1.0867
At iterate     8  f =      -121.82  |proj g|=        1.0866

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.08663
final function value -121.818

F = -121.818
final  value -121.818459 
converged
 
INFO  [22:10:09.140] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:10:09.220] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:10:09.227] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:10:18.957] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:10:24.840] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:10:31.950] [mlr3]  Finished benchmark 
INFO  [22:10:32.040] [bbotk] Result of batch 4: 
INFO  [22:10:32.042] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:10:32.042] [bbotk]              3.707933                 9.282808                       0.1829142 
INFO  [22:10:32.042] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:10:32.042] [bbotk]                     2373        0.492 -0.9651201         <NA>   0.9692803 
INFO  [22:10:32.042] [bbotk]                                 uhash 
INFO  [22:10:32.042] [bbotk]  093c1341-31b4-4856-b3b6-98b37f200899 
DEBUG [22:10:32.892] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.180961e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.180961e-05 0.001237036 
  - best initial criterion value(s) :  124.0692 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -124.07  |proj g|=      0.87191
At iterate     1  f =      -127.24  |proj g|=       0.51304
At iterate     2  f =      -127.56  |proj g|=       0.72248
At iterate     3  f =      -127.88  |proj g|=       0.72839
At iterate     4  f =      -128.08  |proj g|=       0.73692
At iterate     5  f =      -128.08  |proj g|=       0.38994
At iterate     6  f =      -128.08  |proj g|=       0.39131
At iterate     7  f =      -128.08  |proj g|=       0.39177
At iterate     8  f =      -128.08  |proj g|=       0.39201
At iterate     9  f =      -128.08  |proj g|=       0.39198
At iterate    10  f =      -128.08  |proj g|=       0.39197

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.391973
final function value -128.083

F = -128.083
final  value -128.082577 
converged
 
INFO  [22:10:32.897] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:10:32.957] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:10:32.964] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:10:41.294] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:10:50.650] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:10:59.816] [mlr3]  Finished benchmark 
INFO  [22:10:59.888] [bbotk] Result of batch 5: 
INFO  [22:10:59.890] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:10:59.890] [bbotk]              5.380889                 9.822874                       0.3450262 
INFO  [22:10:59.890] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:10:59.890] [bbotk]                     3214        0.661 -0.9663606         <NA>   0.9756419 
INFO  [22:10:59.890] [bbotk]                                 uhash 
INFO  [22:10:59.890] [bbotk]  293010f1-79f5-4a42-abb9-ef00a3c345c8 
DEBUG [22:11:00.541] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.167406e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.167406e-05 0.001267015 
  - best initial criterion value(s) :  126.4404 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -126.44  |proj g|=       1.2763
At iterate     1  f =       -126.6  |proj g|=        1.2322
At iterate     2  f =      -126.78  |proj g|=        1.2567
At iterate     3  f =      -126.79  |proj g|=        1.2553
At iterate     4  f =      -126.79  |proj g|=        1.2553
At iterate     5  f =      -126.79  |proj g|=        1.2555
At iterate     6  f =      -126.79  |proj g|=        1.2556

iterations 6
function evaluations 9
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.25558
final function value -126.788

F = -126.788
final  value -126.787867 
converged
 
INFO  [22:11:00.545] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:11:00.602] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:11:00.609] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:11:14.378] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:11:26.612] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:11:40.153] [mlr3]  Finished benchmark 
INFO  [22:11:40.223] [bbotk] Result of batch 6: 
INFO  [22:11:40.225] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:11:40.225] [bbotk]              4.009185                 6.248174                      0.07845961 
INFO  [22:11:40.225] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:11:40.225] [bbotk]                     4789        0.474 -0.9685343         <NA>   0.9692949 
INFO  [22:11:40.225] [bbotk]                                 uhash 
INFO  [22:11:40.225] [bbotk]  5907d351-6917-4b5e-90d3-780572090b6d 
DEBUG [22:11:40.884] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.135996e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.135996e-05 0.00120909 
  - best initial criterion value(s) :  130.5577 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -130.56  |proj g|=        1.065
At iterate     1  f =      -133.44  |proj g|=        1.4675
At iterate     2  f =      -133.99  |proj g|=         1.391
At iterate     3  f =      -134.38  |proj g|=         1.255
At iterate     4  f =       -134.4  |proj g|=        1.1839
At iterate     5  f =       -134.4  |proj g|=        1.2035
At iterate     6  f =      -134.41  |proj g|=         1.206
At iterate     7  f =      -134.42  |proj g|=        1.2062
At iterate     8  f =      -134.43  |proj g|=        1.1904
At iterate     9  f =      -134.43  |proj g|=        1.1807
At iterate    10  f =      -134.43  |proj g|=        1.1804
At iterate    11  f =      -134.43  |proj g|=        1.1804

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.18044
final function value -134.431

F = -134.431
final  value -134.431014 
converged
 
INFO  [22:11:40.888] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:11:40.945] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:11:40.953] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:11:53.652] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:12:07.532] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:12:20.789] [mlr3]  Finished benchmark 
INFO  [22:12:20.861] [bbotk] Result of batch 7: 
INFO  [22:12:20.863] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:12:20.863] [bbotk]              9.298708                 4.331201                      0.08033476 
INFO  [22:12:20.863] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [22:12:20.863] [bbotk]                     4599        0.472 -0.964062         <NA>   0.9721635 
INFO  [22:12:20.863] [bbotk]                                 uhash 
INFO  [22:12:20.863] [bbotk]  f4092ab9-7f42-466d-a461-262df5ad3fed 
DEBUG [22:12:21.528] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.111249e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.111249e-05 0.00120717 
  - best initial criterion value(s) :  129.8915 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -129.89  |proj g|=       1.2773
At iterate     1  f =      -138.72  |proj g|=       0.77961
At iterate     2  f =      -139.29  |proj g|=       0.76094
At iterate     3  f =      -140.47  |proj g|=       0.66883
At iterate     4  f =       -140.6  |proj g|=       0.63425
At iterate     5  f =      -140.74  |proj g|=       0.62305
At iterate     6  f =      -141.05  |proj g|=       0.61353
At iterate     7  f =      -141.14  |proj g|=       0.75009
At iterate     8  f =      -141.21  |proj g|=       0.62808
At iterate     9  f =      -141.21  |proj g|=       0.62352
At iterate    10  f =      -141.21  |proj g|=       0.62243
At iterate    11  f =      -141.21  |proj g|=       0.62238
At iterate    12  f =      -141.21  |proj g|=       0.62246
At iterate    13  f =      -141.21  |proj g|=       0.62245

iterations 13
function evaluations 20
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.622449
final function value -141.214

F = -141.214
final  value -141.213751 
converged
 
INFO  [22:12:21.532] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:12:21.590] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:12:21.597] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:12:33.311] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:12:44.468] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:12:55.707] [mlr3]  Finished benchmark 
INFO  [22:12:55.789] [bbotk] Result of batch 8: 
INFO  [22:12:55.791] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:12:55.791] [bbotk]              8.054318                 7.683593                        0.292585 
INFO  [22:12:55.791] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:12:55.791] [bbotk]                     4264        0.473 -0.9659037         <NA>   0.9767425 
INFO  [22:12:55.791] [bbotk]                                 uhash 
INFO  [22:12:55.791] [bbotk]  b5a05489-c290-474c-89c1-33a8c2666f07 
DEBUG [22:12:56.539] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.103759e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.103759e-05 0.00121576 
  - best initial criterion value(s) :  141.6199 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -141.62  |proj g|=      0.80106
At iterate     1  f =      -142.36  |proj g|=       0.96251
At iterate     2  f =      -143.73  |proj g|=       0.93209
At iterate     3  f =      -144.92  |proj g|=       0.83336
At iterate     4  f =      -144.96  |proj g|=        0.8104
At iterate     5  f =      -144.96  |proj g|=       0.80697
At iterate     6  f =      -144.96  |proj g|=        0.8053
At iterate     7  f =      -144.96  |proj g|=       0.80073
At iterate     8  f =      -144.96  |proj g|=       0.79988
At iterate     9  f =      -144.97  |proj g|=       0.80229
At iterate    10  f =      -144.97  |proj g|=       0.80285
At iterate    11  f =      -144.97  |proj g|=       0.80291

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.802908
final function value -144.966

F = -144.966
final  value -144.965909 
converged
 
INFO  [22:12:56.543] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:12:56.599] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:12:56.606] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:13:08.592] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:13:18.535] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:13:27.754] [mlr3]  Finished benchmark 
INFO  [22:13:27.836] [bbotk] Result of batch 9: 
INFO  [22:13:27.838] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:13:27.838] [bbotk]              7.906805                 7.830098                       0.2035971 
INFO  [22:13:27.838] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:13:27.838] [bbotk]                     3732        0.562 -0.9659253         <NA>   0.9751221 
INFO  [22:13:27.838] [bbotk]                                 uhash 
INFO  [22:13:27.838] [bbotk]  a7b8e2b8-5f5e-443b-ade3-1a12924c0fef 
DEBUG [22:13:28.700] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.088979e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.088979e-05 0.001197256 
  - best initial criterion value(s) :  149.5068 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -149.51  |proj g|=       0.7088
At iterate     1  f =      -149.92  |proj g|=        0.7818
At iterate     2  f =      -149.92  |proj g|=       0.77826
At iterate     3  f =      -149.92  |proj g|=       0.77544
At iterate     4  f =      -149.93  |proj g|=       0.77365
At iterate     5  f =      -149.95  |proj g|=       0.77321
At iterate     6  f =      -149.98  |proj g|=       0.77837
At iterate     7  f =      -150.01  |proj g|=       0.79846
At iterate     8  f =      -150.01  |proj g|=       0.80034
At iterate     9  f =      -150.01  |proj g|=       0.80092
At iterate    10  f =      -150.01  |proj g|=       0.80101
At iterate    11  f =      -150.01  |proj g|=       0.80148
At iterate    12  f =      -150.01  |proj g|=       0.80192
At iterate    13  f =      -150.01  |proj g|=       0.80227
At iterate    14  f =      -150.01  |proj g|=       0.80366
At iterate    15  f =      -150.02  |proj g|=       0.80377
At iterate    16  f =      -150.02  |proj g|=       0.80368
At iterate    17  f =      -150.03  |proj g|=       0.80204
At iterate    18  f =      -150.08  |proj g|=        0.7917
At iterate    19  f =      -150.22  |proj g|=       0.75769
At iterate    20  f =      -150.29  |proj g|=       0.70057
At iterate    21  f =      -150.59  |proj g|=       0.64686
At iterate    22  f =      -151.18  |proj g|=       0.53898
At iterate    23  f =      -151.93  |proj g|=       0.41204
At iterate    24  f =      -152.42  |proj g|=       0.49309
At iterate    25  f =      -152.51  |proj g|=       0.48961
At iterate    26  f =       -152.8  |proj g|=       0.43826
At iterate    27  f =      -152.86  |proj g|=       0.70631
At iterate    28  f =      -152.91  |proj g|=       0.51475
At iterate    29  f =      -152.91  |proj g|=       0.50388
At iterate    30  f =      -152.91  |proj g|=       0.50608
At iterate    31  f =      -152.91  |proj g|=       0.50615
At iterate    32  f =      -152.91  |proj g|=       0.50605

iterations 32
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.506048
final function value -152.913

F = -152.913
final  value -152.912855 
converged
 
INFO  [22:13:28.704] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:13:28.759] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:13:28.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:13:34.636] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:13:38.673] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:13:43.332] [mlr3]  Finished benchmark 
INFO  [22:13:43.400] [bbotk] Result of batch 10: 
INFO  [22:13:43.402] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:13:43.402] [bbotk]              9.126417                 4.035766                        0.351168 
INFO  [22:13:43.402] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:13:43.402] [bbotk]                     1541        0.627 -0.9658866         <NA>   0.9740912 
INFO  [22:13:43.402] [bbotk]                                 uhash 
INFO  [22:13:43.402] [bbotk]  4511f74a-e218-4720-8f98-3152693cdbe6 
DEBUG [22:13:44.272] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.070948e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.070948e-05 0.001157132 
  - best initial criterion value(s) :  151.7543 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -151.75  |proj g|=      0.83983
At iterate     1  f =       -153.5  |proj g|=       0.95153
At iterate     2  f =      -154.22  |proj g|=       0.86706
At iterate     3  f =      -156.02  |proj g|=       0.81495
At iterate     4  f =      -159.55  |proj g|=       0.40059
At iterate     5  f =      -159.69  |proj g|=       0.37331
At iterate     6  f =      -159.84  |proj g|=       0.33076
At iterate     7  f =      -159.85  |proj g|=       0.63194
At iterate     8  f =      -159.85  |proj g|=       0.22165
At iterate     9  f =      -159.85  |proj g|=       0.22228
At iterate    10  f =      -159.85  |proj g|=       0.22217
At iterate    11  f =      -159.85  |proj g|=       0.22217

iterations 11
function evaluations 17
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.222167
final function value -159.853

F = -159.853
final  value -159.852573 
converged
 
INFO  [22:13:44.276] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:13:44.332] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:13:44.339] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:13:53.609] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:14:01.446] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:14:10.912] [mlr3]  Finished benchmark 
INFO  [22:14:10.996] [bbotk] Result of batch 11: 
INFO  [22:14:10.999] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:14:10.999] [bbotk]              9.928964                 5.073277                       0.1337915 
INFO  [22:14:10.999] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:14:10.999] [bbotk]                     3044        0.632 -0.9626158         <NA>   0.9727783 
INFO  [22:14:10.999] [bbotk]                                 uhash 
INFO  [22:14:10.999] [bbotk]  689a74f9-2e4c-4f7a-8303-fb6c2ebe0ebb 
DEBUG [22:14:11.709] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.050035e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.050035e-05 0.001140672 
  - best initial criterion value(s) :  155.9451 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -155.95  |proj g|=      0.35789
At iterate     1  f =      -157.27  |proj g|=        2.0829
At iterate     2  f =      -158.67  |proj g|=        1.9344
At iterate     3  f =      -160.25  |proj g|=        1.4336
At iterate     4  f =      -160.26  |proj g|=        1.3479
At iterate     5  f =      -160.27  |proj g|=        1.3858
At iterate     6  f =      -160.29  |proj g|=        1.4113
At iterate     7  f =      -160.32  |proj g|=        1.4435
At iterate     8  f =      -160.33  |proj g|=        1.4356
At iterate     9  f =      -160.33  |proj g|=        1.4151
At iterate    10  f =      -160.33  |proj g|=        1.4113
At iterate    11  f =      -160.33  |proj g|=        1.4112
At iterate    12  f =      -160.33  |proj g|=        1.4109
At iterate    13  f =      -160.33  |proj g|=        1.4104
At iterate    14  f =      -160.33  |proj g|=        1.4093
At iterate    15  f =      -160.33  |proj g|=        1.4078
At iterate    16  f =      -160.33  |proj g|=        1.4051
At iterate    17  f =      -160.33  |proj g|=        1.4008
At iterate    18  f =      -160.33  |proj g|=        1.3942
At iterate    19  f =      -160.34  |proj g|=        1.3848
At iterate    20  f =      -160.34  |proj g|=        1.3759
At iterate    21  f =      -160.35  |proj g|=        1.3807
At iterate    22  f =      -160.36  |proj g|=        1.3986
At iterate    23  f =      -160.36  |proj g|=        1.4123
At iterate    24  f =      -160.36  |proj g|=        1.4186
At iterate    25  f =      -160.36  |proj g|=         1.424
At iterate    26  f =      -160.37  |proj g|=         1.434
At iterate    27  f =      -160.37  |proj g|=        1.4477
At iterate    28  f =      -160.39  |proj g|=        1.4653
At iterate    29  f =      -160.44  |proj g|=        1.4804
At iterate    30  f =      -160.58  |proj g|=        1.4701
At iterate    31  f =      -160.92  |proj g|=        1.3675
At iterate    32  f =      -161.61  |proj g|=        1.0147
At iterate    33  f =      -161.94  |proj g|=       0.71049
At iterate    34  f =      -162.02  |proj g|=       0.58469
At iterate    35  f =      -162.08  |proj g|=       0.51342
At iterate    36  f =      -162.18  |proj g|=       0.47305
At iterate    37  f =      -162.44  |proj g|=       0.43846
At iterate    38  f =      -163.17  |proj g|=       0.37541
At iterate    39  f =      -164.68  |proj g|=       0.73727
At iterate    40  f =      -165.28  |proj g|=       0.28169
At iterate    41  f =      -165.42  |proj g|=       0.27455
At iterate    42  f =      -165.43  |proj g|=       0.14108
At iterate    43  f =      -165.44  |proj g|=       0.15024
At iterate    44  f =      -165.44  |proj g|=       0.15172
At iterate    45  f =      -165.44  |proj g|=       0.15141
At iterate    46  f =      -165.44  |proj g|=       0.15263

iterations 46
function evaluations 51
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.152629
final function value -165.437

F = -165.437
final  value -165.437222 
converged
 
INFO  [22:14:11.714] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:14:11.772] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:14:11.779] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:14:21.562] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:14:31.430] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:14:42.674] [mlr3]  Finished benchmark 
INFO  [22:14:42.744] [bbotk] Result of batch 12: 
INFO  [22:14:42.746] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:14:42.746] [bbotk]              2.464472                 2.800858                       0.3641473 
INFO  [22:14:42.746] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [22:14:42.746] [bbotk]                     3812        0.489 -0.963703         <NA>   0.9663694 
INFO  [22:14:42.746] [bbotk]                                 uhash 
INFO  [22:14:42.746] [bbotk]  8041bec1-658c-4bb9-b849-f4f34e91664c 
DEBUG [22:14:43.456] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.025825e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.025825e-05 0.001137572 
  - best initial criterion value(s) :  157.7236 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -157.72  |proj g|=       2.7953
At iterate     1  f =       -159.3  |proj g|=        2.2756
At iterate     2  f =       -160.3  |proj g|=        2.4073
At iterate     3  f =      -160.35  |proj g|=        2.3323
At iterate     4  f =      -160.37  |proj g|=        2.2482
At iterate     5  f =      -160.37  |proj g|=        2.2471
At iterate     6  f =      -160.37  |proj g|=        2.2467
At iterate     7  f =      -160.37  |proj g|=        2.2468

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.24676
final function value -160.373

F = -160.373
final  value -160.372887 
converged
 
INFO  [22:14:43.460] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:14:43.518] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:14:43.525] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:14:45.255] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:14:47.702] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:14:49.415] [mlr3]  Finished benchmark 
INFO  [22:14:49.484] [bbotk] Result of batch 13: 
INFO  [22:14:49.486] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:14:49.486] [bbotk]              3.849245                 5.029328                      0.02724298 
INFO  [22:14:49.486] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:14:49.486] [bbotk]                      573        0.521 -0.9679813         <NA>   0.9166627 
INFO  [22:14:49.486] [bbotk]                                 uhash 
INFO  [22:14:49.486] [bbotk]  7fe8ea00-e2ed-4e88-a445-ca54724e05a6 
DEBUG [22:14:50.214] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.604922e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.604922e-05 0.001946038 
  - best initial criterion value(s) :  161.904 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -161.9  |proj g|=      0.85073
At iterate     1  f =      -169.44  |proj g|=       0.73696
At iterate     2  f =      -169.74  |proj g|=       0.89804
At iterate     3  f =      -170.09  |proj g|=       0.83213
At iterate     4  f =      -170.24  |proj g|=       0.75586
At iterate     5  f =      -170.25  |proj g|=       0.73495
At iterate     6  f =      -170.25  |proj g|=       0.73915
At iterate     7  f =      -170.25  |proj g|=       0.74097
At iterate     8  f =      -170.25  |proj g|=       0.74082
At iterate     9  f =      -170.25  |proj g|=       0.74075

iterations 9
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.740754
final function value -170.252

F = -170.252
final  value -170.252463 
converged
 
INFO  [22:14:50.218] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:14:50.277] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:14:50.284] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:14:53.179] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:14:56.593] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:14:59.610] [mlr3]  Finished benchmark 
INFO  [22:14:59.679] [bbotk] Result of batch 14: 
INFO  [22:14:59.681] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:14:59.681] [bbotk]              3.273313                 2.907062                       0.0441811 
INFO  [22:14:59.681] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:14:59.681] [bbotk]                     1153        0.538 -0.9639191         <NA>   0.9402628 
INFO  [22:14:59.681] [bbotk]                                 uhash 
INFO  [22:14:59.681] [bbotk]  06fa4bce-2e0a-47b3-af5e-3ad2fc01184a 
DEBUG [22:15:00.372] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.727299e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.727299e-05 0.002072545 
  - best initial criterion value(s) :  162.9296 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -162.93  |proj g|=      0.38636
At iterate     1  f =         -163  |proj g|=       0.43379
At iterate     2  f =      -163.55  |proj g|=        0.4003
At iterate     3  f =      -164.05  |proj g|=        0.3136
At iterate     4  f =      -164.06  |proj g|=       0.69373
At iterate     5  f =      -164.06  |proj g|=       0.50968
At iterate     6  f =      -164.06  |proj g|=       0.55005
At iterate     7  f =      -164.06  |proj g|=        0.5522
At iterate     8  f =      -164.06  |proj g|=       0.55117

iterations 8
function evaluations 14
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.551171
final function value -164.059

F = -164.059
final  value -164.059487 
converged
 
INFO  [22:15:00.376] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:15:00.432] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:15:00.440] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:15:03.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:15:08.090] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:15:11.108] [mlr3]  Finished benchmark 
INFO  [22:15:11.209] [bbotk] Result of batch 15: 
INFO  [22:15:11.211] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:15:11.211] [bbotk]              2.720777                 4.554217                       0.1940739 
INFO  [22:15:11.211] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:15:11.211] [bbotk]                     1120        0.504 -0.9669771         <NA>   0.9540077 
INFO  [22:15:11.211] [bbotk]                                 uhash 
INFO  [22:15:11.211] [bbotk]  1f41118e-4a5a-4700-9caa-f182ca709fa7 
DEBUG [22:15:11.903] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.722327e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.722327e-05 0.002056205 
  - best initial criterion value(s) :  164.2118 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -164.21  |proj g|=      0.74767
At iterate     1  f =      -164.47  |proj g|=       0.70994
At iterate     2  f =      -164.82  |proj g|=       0.69083
At iterate     3  f =      -165.18  |proj g|=       0.64299
At iterate     4  f =      -165.23  |proj g|=       0.54778
At iterate     5  f =      -165.24  |proj g|=       0.60531
At iterate     6  f =      -165.24  |proj g|=       0.37761
At iterate     7  f =      -165.24  |proj g|=       0.37365
At iterate     8  f =      -165.24  |proj g|=       0.37378
At iterate     9  f =      -165.24  |proj g|=       0.37379

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.373794
final function value -165.243

F = -165.243
final  value -165.243150 
converged
 
INFO  [22:15:11.907] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:15:11.963] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:15:11.970] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:15:22.270] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:15:31.467] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:15:44.686] [mlr3]  Finished benchmark 
INFO  [22:15:44.757] [bbotk] Result of batch 16: 
INFO  [22:15:44.759] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:15:44.759] [bbotk]              5.586653                 9.553373                       0.2024118 
INFO  [22:15:44.759] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:15:44.759] [bbotk]                     3522        0.502 -0.9664845         <NA>    0.974508 
INFO  [22:15:44.759] [bbotk]                                 uhash 
INFO  [22:15:44.759] [bbotk]  ec5c47ce-b3ca-47a6-a572-8a2c57017e6a 
DEBUG [22:15:45.507] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.699799e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.699799e-05 0.002047853 
  - best initial criterion value(s) :  165.2333 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -165.23  |proj g|=       1.3132
At iterate     1  f =      -167.31  |proj g|=        2.5399
At iterate     2  f =      -167.36  |proj g|=        2.4775
At iterate     3  f =      -167.41  |proj g|=        2.3536
At iterate     4  f =      -167.44  |proj g|=        2.3219
At iterate     5  f =      -167.81  |proj g|=        1.9984
At iterate     6  f =      -168.16  |proj g|=        1.8788
At iterate     7  f =      -168.28  |proj g|=        1.9375
At iterate     8  f =      -168.32  |proj g|=        2.0259
At iterate     9  f =      -168.32  |proj g|=        1.9873
At iterate    10  f =      -168.32  |proj g|=        1.9865
At iterate    11  f =      -168.32  |proj g|=        1.9866
At iterate    12  f =      -168.32  |proj g|=        1.9866
At iterate    13  f =      -168.32  |proj g|=        1.9867
At iterate    14  f =      -168.32  |proj g|=        1.9867
At iterate    15  f =      -168.32  |proj g|=        1.9868
At iterate    16  f =      -168.32  |proj g|=        1.9875
At iterate    17  f =      -168.32  |proj g|=        1.9875
At iterate    18  f =      -168.32  |proj g|=        1.9908
At iterate    19  f =      -168.32  |proj g|=        1.9846
At iterate    20  f =      -168.32  |proj g|=        1.9889
At iterate    21  f =      -168.34  |proj g|=        1.9903
At iterate    22  f =      -169.36  |proj g|=        1.5109
At iterate    23  f =      -170.81  |proj g|=        0.7541
At iterate    24  f =      -171.49  |proj g|=       0.39155
At iterate    25  f =      -171.49  |proj g|=       0.70218
At iterate    26  f =      -171.85  |proj g|=       0.68412
At iterate    27  f =      -171.99  |proj g|=       0.66688
At iterate    28  f =      -172.07  |proj g|=       0.51644
At iterate    29  f =       -172.1  |proj g|=        0.5385
At iterate    30  f =      -172.11  |proj g|=       0.57267
At iterate    31  f =      -172.12  |proj g|=       0.59217
At iterate    32  f =      -172.12  |proj g|=       0.59138
At iterate    33  f =      -172.12  |proj g|=       0.59431
At iterate    34  f =      -172.12  |proj g|=       0.59425
At iterate    35  f =      -172.12  |proj g|=       0.59426

iterations 35
function evaluations 42
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.594264
final function value -172.118

F = -172.118
final  value -172.117883 
converged
 
INFO  [22:15:45.512] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:15:45.571] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:15:45.579] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:15:52.042] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:15:58.614] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:16:04.154] [mlr3]  Finished benchmark 
INFO  [22:16:04.222] [bbotk] Result of batch 17: 
INFO  [22:16:04.224] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:16:04.224] [bbotk]              2.126466                 5.692124                       0.2990415 
INFO  [22:16:04.224] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:16:04.224] [bbotk]                     2198        0.527 -0.9664936         <NA>   0.9573904 
INFO  [22:16:04.224] [bbotk]                                 uhash 
INFO  [22:16:04.224] [bbotk]  74e3afa4-86e2-49ab-997c-ee77856e2a75 
DEBUG [22:16:04.990] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.680222e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.680222e-05 0.002022328 
  - best initial criterion value(s) :  169.9161 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -169.92  |proj g|=       1.7022
At iterate     1  f =      -170.61  |proj g|=        1.4993
At iterate     2  f =       -170.9  |proj g|=        1.3404
At iterate     3  f =      -171.03  |proj g|=        1.2325
At iterate     4  f =      -171.04  |proj g|=        1.2274
At iterate     5  f =      -171.05  |proj g|=        1.2289
At iterate     6  f =      -171.05  |proj g|=        1.2282
At iterate     7  f =      -171.05  |proj g|=        1.2286
At iterate     8  f =      -171.05  |proj g|=        1.2284
At iterate     9  f =      -171.05  |proj g|=        1.2269
At iterate    10  f =      -171.05  |proj g|=         1.225
At iterate    11  f =      -171.05  |proj g|=        1.2214
At iterate    12  f =      -171.05  |proj g|=        1.2157
At iterate    13  f =      -171.05  |proj g|=         1.206
At iterate    14  f =      -171.05  |proj g|=        1.1898
At iterate    15  f =      -171.06  |proj g|=        1.1618
At iterate    16  f =       -171.1  |proj g|=        1.1144
At iterate    17  f =      -171.18  |proj g|=        1.0413
At iterate    18  f =      -171.35  |proj g|=       0.96424
At iterate    19  f =       -171.6  |proj g|=       0.99375
At iterate    20  f =      -171.68  |proj g|=        1.0207
At iterate    21  f =      -171.71  |proj g|=        1.0503
At iterate    22  f =      -171.73  |proj g|=        1.0734
At iterate    23  f =      -171.75  |proj g|=        1.0875
At iterate    24  f =      -171.78  |proj g|=        1.1057
At iterate    25  f =      -171.83  |proj g|=        1.1024
At iterate    26  f =      -171.93  |proj g|=        1.0953
At iterate    27  f =      -172.15  |proj g|=       0.95667
At iterate    28  f =       -172.5  |proj g|=       0.76188
At iterate    29  f =      -172.73  |proj g|=       0.68027
At iterate    30  f =      -173.27  |proj g|=        0.7051
At iterate    31  f =      -174.14  |proj g|=       0.55299
At iterate    32  f =      -175.32  |proj g|=       0.38483
At iterate    33  f =      -175.58  |proj g|=       0.54159
At iterate    34  f =      -176.04  |proj g|=       0.43078
At iterate    35  f =       -176.1  |proj g|=       0.36049
At iterate    36  f =      -176.15  |proj g|=       0.45003
At iterate    37  f =      -176.16  |proj g|=       0.15084
At iterate    38  f =      -176.16  |proj g|=       0.15639
At iterate    39  f =      -176.16  |proj g|=       0.15688
At iterate    40  f =      -176.16  |proj g|=       0.15684

iterations 40
function evaluations 48
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.156837
final function value -176.158

F = -176.158
final  value -176.157548 
converged
 
INFO  [22:16:04.995] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:16:05.051] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:16:05.058] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:16:17.806] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:16:28.420] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:16:40.532] [mlr3]  Finished benchmark 
INFO  [22:16:40.599] [bbotk] Result of batch 18: 
INFO  [22:16:40.601] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:16:40.601] [bbotk]              3.848113                 5.671214                       0.1178292 
INFO  [22:16:40.601] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:16:40.601] [bbotk]                     3891         0.53 -0.9650187         <NA>   0.9699754 
INFO  [22:16:40.601] [bbotk]                                 uhash 
INFO  [22:16:40.601] [bbotk]  9ccb5bad-a026-45d2-9939-e8866fd88844 
DEBUG [22:16:41.289] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.648239e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9515268 9446 
  - variance bounds :  1.648239e-05 0.002007744 
  - best initial criterion value(s) :  172.3042 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -172.3  |proj g|=        1.087
At iterate     1  f =      -175.51  |proj g|=       0.88597
At iterate     2  f =      -176.23  |proj g|=        1.3008
At iterate     3  f =      -176.47  |proj g|=        1.1935
At iterate     4  f =      -176.56  |proj g|=        1.0426
At iterate     5  f =      -176.59  |proj g|=        1.1023
At iterate     6  f =      -176.59  |proj g|=         1.094
At iterate     7  f =      -176.59  |proj g|=        1.0915
At iterate     8  f =      -176.59  |proj g|=        1.0913
At iterate     9  f =      -176.59  |proj g|=        1.0923
At iterate    10  f =      -176.59  |proj g|=        1.0929
At iterate    11  f =      -176.59  |proj g|=         1.093

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.09296
final function value -176.592

F = -176.592
final  value -176.591647 
converged
 
INFO  [22:16:41.293] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:16:41.351] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:16:41.358] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:16:44.252] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:16:47.405] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:16:50.755] [mlr3]  Finished benchmark 
INFO  [22:16:50.836] [bbotk] Result of batch 19: 
INFO  [22:16:50.838] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:16:50.838] [bbotk]              4.260011                 4.907764                       0.4977725 
INFO  [22:16:50.838] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [22:16:50.838] [bbotk]                     1153        0.513 -0.968052         <NA>   0.9721745 
INFO  [22:16:50.838] [bbotk]                                 uhash 
INFO  [22:16:50.838] [bbotk]  880eb963-4fb5-481c-86ed-983954f78b5c 
DEBUG [22:16:51.593] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.621725e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.621725e-05 0.001935771 
  - best initial criterion value(s) :  177.271 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -177.27  |proj g|=       2.9457
At iterate     1  f =      -178.08  |proj g|=        2.5159
At iterate     2  f =      -178.66  |proj g|=        2.7052
At iterate     3  f =      -178.92  |proj g|=        2.6908
At iterate     4  f =      -179.12  |proj g|=         2.628
At iterate     5  f =      -179.26  |proj g|=        2.5534
At iterate     6  f =      -179.34  |proj g|=        2.5025
At iterate     7  f =      -179.35  |proj g|=        2.5321
At iterate     8  f =      -179.35  |proj g|=        2.4871
At iterate     9  f =      -179.35  |proj g|=        2.4953
At iterate    10  f =      -179.35  |proj g|=        2.4954
At iterate    11  f =      -179.35  |proj g|=        2.4969
At iterate    12  f =      -179.35  |proj g|=        2.4985
At iterate    13  f =      -179.36  |proj g|=        2.4907
At iterate    14  f =      -179.36  |proj g|=        2.5022
At iterate    15  f =      -179.36  |proj g|=        2.4907
At iterate    16  f =      -179.45  |proj g|=        2.4441
At iterate    17  f =      -182.16  |proj g|=        1.5995
At iterate    18  f =      -184.99  |proj g|=        0.7665
At iterate    19  f =      -186.75  |proj g|=       0.50623
At iterate    20  f =      -187.92  |proj g|=       0.62218
At iterate    21  f =      -187.97  |proj g|=       0.61694
At iterate    22  f =      -188.01  |proj g|=        0.6028
At iterate    23  f =      -188.26  |proj g|=       0.47783
At iterate    24  f =      -188.27  |proj g|=      0.033869
At iterate    25  f =      -188.27  |proj g|=      0.044794
At iterate    26  f =      -188.27  |proj g|=      0.019605
At iterate    27  f =      -188.27  |proj g|=       0.01953
At iterate    28  f =      -188.27  |proj g|=      0.019543

iterations 28
function evaluations 36
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0195428
final function value -188.274

F = -188.274
final  value -188.273630 
converged
 
INFO  [22:16:51.597] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:16:51.652] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:16:51.658] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:17:00.786] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:17:11.499] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:17:20.161] [mlr3]  Finished benchmark 
INFO  [22:17:20.229] [bbotk] Result of batch 20: 
INFO  [22:17:20.231] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:17:20.231] [bbotk]              8.888722                 6.157772                       0.2420968 
INFO  [22:17:20.231] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:17:20.231] [bbotk]                     3386        0.527 -0.9639007         <NA>   0.9755708 
INFO  [22:17:20.231] [bbotk]                                 uhash 
INFO  [22:17:20.231] [bbotk]  7aad6c77-3872-4681-a47b-8bf79d0b5d93 
DEBUG [22:17:20.994] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.606049e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.606049e-05 0.001946643 
  - best initial criterion value(s) :  181.9065 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -181.91  |proj g|=      0.81711
At iterate     1  f =      -183.79  |proj g|=        2.0755
At iterate     2  f =      -184.67  |proj g|=         1.942
At iterate     3  f =       -185.4  |proj g|=        1.6211
At iterate     4  f =      -185.53  |proj g|=        1.5177
At iterate     5  f =      -186.02  |proj g|=        1.1842
At iterate     6  f =       -186.5  |proj g|=        1.0232
At iterate     7  f =      -186.55  |proj g|=        1.0507
At iterate     8  f =      -186.55  |proj g|=        1.0287
At iterate     9  f =      -186.55  |proj g|=        1.0271
At iterate    10  f =      -186.55  |proj g|=        1.0275
At iterate    11  f =      -186.55  |proj g|=        1.0279
At iterate    12  f =      -186.55  |proj g|=        1.0292
At iterate    13  f =      -186.55  |proj g|=         1.031
At iterate    14  f =      -186.55  |proj g|=         1.034
At iterate    15  f =      -186.56  |proj g|=        1.0387
At iterate    16  f =      -186.56  |proj g|=        1.0458
At iterate    17  f =      -186.56  |proj g|=        1.0559
At iterate    18  f =      -186.56  |proj g|=        1.0688
At iterate    19  f =      -186.56  |proj g|=        1.0786
At iterate    20  f =      -186.57  |proj g|=        1.0905
At iterate    21  f =      -186.66  |proj g|=        1.0841
At iterate    22  f =      -187.81  |proj g|=       0.75757
At iterate    23  f =       -188.8  |proj g|=       0.49069
At iterate    24  f =      -189.47  |proj g|=       0.64944
At iterate    25  f =      -190.24  |proj g|=       0.41553
At iterate    26  f =      -190.39  |proj g|=       0.54628
At iterate    27  f =      -190.42  |proj g|=        0.3092
At iterate    28  f =      -190.43  |proj g|=       0.28614
At iterate    29  f =      -190.43  |proj g|=       0.28757
At iterate    30  f =      -190.43  |proj g|=       0.28758
At iterate    31  f =      -190.43  |proj g|=       0.28755

iterations 31
function evaluations 36
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.287553
final function value -190.425

F = -190.425
final  value -190.425442 
converged
 
INFO  [22:17:20.998] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:17:21.055] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:17:21.062] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:17:25.835] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:17:30.012] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:17:34.847] [mlr3]  Finished benchmark 
INFO  [22:17:34.916] [bbotk] Result of batch 21: 
INFO  [22:17:34.918] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:17:34.918] [bbotk]              2.121966                 5.968024                       0.1697684 
INFO  [22:17:34.918] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:17:34.918] [bbotk]                     1636        0.543 -0.9643592         <NA>   0.9500611 
INFO  [22:17:34.918] [bbotk]                                 uhash 
INFO  [22:17:34.918] [bbotk]  2d0321c2-d765-4e2d-847c-7650720e26e3 
DEBUG [22:17:35.659] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.626571e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.626571e-05 0.001958183 
  - best initial criterion value(s) :  188.7843 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -188.78  |proj g|=      0.79109
At iterate     1  f =      -190.34  |proj g|=       0.72439
At iterate     2  f =      -190.64  |proj g|=       0.72573
At iterate     3  f =       -191.1  |proj g|=       0.72255
At iterate     4  f =      -191.25  |proj g|=       0.70798
At iterate     5  f =      -191.41  |proj g|=       0.68136
At iterate     6  f =      -191.45  |proj g|=       0.67008
At iterate     7  f =       -191.5  |proj g|=       0.64748
At iterate     8  f =       -191.5  |proj g|=       0.36954
At iterate     9  f =       -191.5  |proj g|=       0.36962
At iterate    10  f =       -191.5  |proj g|=       0.36963

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.369628
final function value -191.5

F = -191.5
final  value -191.499938 
converged
 
INFO  [22:17:35.664] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:17:35.721] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:17:35.728] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:17:41.039] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:17:46.731] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:17:52.643] [mlr3]  Finished benchmark 
INFO  [22:17:52.713] [bbotk] Result of batch 22: 
INFO  [22:17:52.715] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:17:52.715] [bbotk]              3.797631                 3.512038                      0.04401039 
INFO  [22:17:52.715] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [22:17:52.715] [bbotk]                     2141        0.547 -0.966272         <NA>   0.9552937 
INFO  [22:17:52.715] [bbotk]                                 uhash 
INFO  [22:17:52.715] [bbotk]  bc2be7b3-e2b5-429c-8df1-6fa66a787731 
DEBUG [22:17:53.661] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.617696e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.617696e-05 0.001965563 
  - best initial criterion value(s) :  184.1082 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -184.11  |proj g|=       2.5807
At iterate     1  f =      -186.28  |proj g|=        1.1527
At iterate     2  f =      -188.41  |proj g|=         1.105
At iterate     3  f =      -191.18  |proj g|=       0.89148
At iterate     4  f =      -191.37  |proj g|=       0.90507
At iterate     5  f =      -192.34  |proj g|=        0.9297
At iterate     6  f =      -193.58  |proj g|=        1.0488
At iterate     7  f =      -193.81  |proj g|=        1.1021
At iterate     8  f =      -193.85  |proj g|=        1.1274
At iterate     9  f =      -193.85  |proj g|=        1.1368
At iterate    10  f =      -193.85  |proj g|=        1.1403
At iterate    11  f =      -193.85  |proj g|=        1.1398
At iterate    12  f =      -193.85  |proj g|=        1.1395
At iterate    13  f =      -193.85  |proj g|=        1.1382
At iterate    14  f =      -193.85  |proj g|=        1.1364
At iterate    15  f =      -193.85  |proj g|=         1.133
At iterate    16  f =      -193.85  |proj g|=        1.1272
At iterate    17  f =      -193.86  |proj g|=        1.1173
At iterate    18  f =      -193.87  |proj g|=        1.1002
At iterate    19  f =      -193.92  |proj g|=        1.0702
At iterate    20  f =      -194.03  |proj g|=        1.0175
At iterate    21  f =       -194.3  |proj g|=       0.92957
At iterate    22  f =      -194.83  |proj g|=       0.81862
At iterate    23  f =      -195.35  |proj g|=       0.84444
At iterate    24  f =      -195.42  |proj g|=       0.93028
At iterate    25  f =      -195.42  |proj g|=       0.92377
At iterate    26  f =      -195.42  |proj g|=       0.92228
At iterate    27  f =      -195.42  |proj g|=       0.91889
At iterate    28  f =      -195.42  |proj g|=       0.91461
At iterate    29  f =      -195.43  |proj g|=        0.9068
At iterate    30  f =      -195.44  |proj g|=       0.90348
At iterate    31  f =      -195.45  |proj g|=       0.90611
At iterate    32  f =      -195.47  |proj g|=       0.92684
At iterate    33  f =      -195.48  |proj g|=       0.94045
At iterate    34  f =      -195.48  |proj g|=       0.95071
At iterate    35  f =      -195.48  |proj g|=       0.95133
At iterate    36  f =      -195.48  |proj g|=       0.95134

iterations 36
function evaluations 43
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.951339
final function value -195.477

F = -195.477
final  value -195.476657 
converged
 
INFO  [22:17:53.665] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:17:53.726] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:17:53.734] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:17:56.376] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:17:58.869] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:18:00.741] [mlr3]  Finished benchmark 
INFO  [22:18:00.810] [bbotk] Result of batch 23: 
INFO  [22:18:00.812] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:18:00.812] [bbotk]              4.311038                 5.006709                       0.2838396 
INFO  [22:18:00.812] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:18:00.812] [bbotk]                      700        0.707 -0.9644665         <NA>   0.9647613 
INFO  [22:18:00.812] [bbotk]                                 uhash 
INFO  [22:18:00.812] [bbotk]  18ceaa2d-a7f5-434c-88bd-7cea9755e137 
DEBUG [22:18:01.514] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.587451e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.587451e-05 0.001888462 
  - best initial criterion value(s) :  188.9182 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -188.92  |proj g|=       2.2602
At iterate     1  f =      -192.24  |proj g|=         1.286
At iterate     2  f =      -194.19  |proj g|=         2.036
At iterate     3  f =      -194.34  |proj g|=        1.9586
At iterate     4  f =      -194.49  |proj g|=        1.7614
At iterate     5  f =      -194.53  |proj g|=         1.827
At iterate     6  f =      -194.53  |proj g|=        1.8238
At iterate     7  f =      -194.53  |proj g|=        1.8219
At iterate     8  f =      -194.53  |proj g|=        1.8221

iterations 8
function evaluations 10
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.82207
final function value -194.535

F = -194.535
final  value -194.534990 
converged
 
INFO  [22:18:01.518] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:18:01.576] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:18:01.583] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:18:14.035] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:18:26.804] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:18:39.567] [mlr3]  Finished benchmark 
INFO  [22:18:39.637] [bbotk] Result of batch 24: 
INFO  [22:18:39.639] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:18:39.639] [bbotk]              6.236425                 8.250717                       0.4850933 
INFO  [22:18:39.639] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:18:39.639] [bbotk]                     4404        0.509 -0.9668299         <NA>   0.9770897 
INFO  [22:18:39.639] [bbotk]                                 uhash 
INFO  [22:18:39.639] [bbotk]  459006a6-bb36-42ec-af3f-77dd9a7ea725 
DEBUG [22:18:40.347] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.580565e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.580565e-05 0.00189992 
  - best initial criterion value(s) :  190.0961 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -190.1  |proj g|=        2.728
At iterate     1  f =         -198  |proj g|=       0.68901
At iterate     2  f =      -204.03  |proj g|=       0.58734
At iterate     3  f =      -204.03  |proj g|=       0.58738
At iterate     4  f =      -204.03  |proj g|=       0.58624
At iterate     5  f =      -204.04  |proj g|=       0.58155
At iterate     6  f =      -204.04  |proj g|=       0.57632
At iterate     7  f =      -204.04  |proj g|=       0.57631
At iterate     8  f =      -204.04  |proj g|=       0.57328
At iterate     9  f =      -204.04  |proj g|=       0.57319
At iterate    10  f =      -204.04  |proj g|=       0.57316

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.573162
final function value -204.043

F = -204.043
final  value -204.043024 
converged
 
INFO  [22:18:40.352] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:18:40.410] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:18:40.417] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:18:51.177] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:19:01.933] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:19:13.021] [mlr3]  Finished benchmark 
INFO  [22:19:13.091] [bbotk] Result of batch 25: 
INFO  [22:19:13.093] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:19:13.093] [bbotk]              7.065953                 9.442858                       0.4578454 
INFO  [22:19:13.093] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:19:13.093] [bbotk]                     3690        0.516 -0.9651253         <NA>   0.9772037 
INFO  [22:19:13.093] [bbotk]                                 uhash 
INFO  [22:19:13.093] [bbotk]  de08f181-3a9c-440c-a29f-53d95ab63e92 
DEBUG [22:19:13.787] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.573588e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.573588e-05 0.001910079 
  - best initial criterion value(s) :  200.2908 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -200.29  |proj g|=      0.99635
At iterate     1  f =      -201.72  |proj g|=       0.75261
At iterate     2  f =      -201.79  |proj g|=       0.77816
At iterate     3  f =      -201.79  |proj g|=       0.78241
At iterate     4  f =      -201.79  |proj g|=       0.78031
At iterate     5  f =      -201.79  |proj g|=       0.78027

iterations 5
function evaluations 8
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.780274
final function value -201.792

F = -201.792
final  value -201.792068 
converged
 
INFO  [22:19:13.791] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:19:13.848] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:19:13.855] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:19:26.864] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:19:40.553] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:19:53.696] [mlr3]  Finished benchmark 
INFO  [22:19:53.765] [bbotk] Result of batch 26: 
INFO  [22:19:53.767] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:19:53.767] [bbotk]              9.605915                 7.795481                       0.1606644 
INFO  [22:19:53.767] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:19:53.767] [bbotk]                     4859        0.505 -0.9680264         <NA>   0.9756363 
INFO  [22:19:53.767] [bbotk]                                 uhash 
INFO  [22:19:53.767] [bbotk]  5cc6f5fb-b4c0-4000-95fb-2758a36037eb 
DEBUG [22:19:54.536] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.560578e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.560578e-05 0.001914307 
  - best initial criterion value(s) :  203.621 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -203.62  |proj g|=      0.81821
At iterate     1  f =      -208.82  |proj g|=       0.68487
At iterate     2  f =      -208.94  |proj g|=       0.65749
At iterate     3  f =         -209  |proj g|=       0.65126
At iterate     4  f =      -209.01  |proj g|=       0.42922
At iterate     5  f =      -209.01  |proj g|=       0.43067
At iterate     6  f =      -209.01  |proj g|=       0.43126
At iterate     7  f =      -209.01  |proj g|=       0.43127

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.431274
final function value -209.014

F = -209.014
final  value -209.013649 
converged
 
INFO  [22:19:54.540] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:19:54.597] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:19:54.604] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:20:02.127] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:20:10.500] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:20:17.425] [mlr3]  Finished benchmark 
INFO  [22:20:17.494] [bbotk] Result of batch 27: 
INFO  [22:20:17.495] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:20:17.495] [bbotk]              6.455009                 5.752921                      0.06745166 
INFO  [22:20:17.495] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:20:17.495] [bbotk]                     2803        0.568 -0.9670116         <NA>   0.9673313 
INFO  [22:20:17.495] [bbotk]                                 uhash 
INFO  [22:20:17.495] [bbotk]  d1d10024-78ca-4146-9979-7f53740fae39 
DEBUG [22:20:18.399] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.533312e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.533312e-05 0.001887403 
  - best initial criterion value(s) :  206.0907 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -206.09  |proj g|=       1.7559
At iterate     1  f =      -212.89  |proj g|=       0.70615
At iterate     2  f =      -213.22  |proj g|=       0.70348
At iterate     3  f =      -213.48  |proj g|=       0.69292
At iterate     4  f =       -213.6  |proj g|=       0.69675
At iterate     5  f =      -213.61  |proj g|=       0.69559
At iterate     6  f =      -213.63  |proj g|=       0.69393
At iterate     7  f =      -213.66  |proj g|=       0.68926
At iterate     8  f =      -213.76  |proj g|=       0.67616
At iterate     9  f =      -213.93  |proj g|=       0.65035
At iterate    10  f =      -214.15  |proj g|=       0.47769
At iterate    11  f =       -214.2  |proj g|=       0.50466
At iterate    12  f =       -214.2  |proj g|=       0.51637
At iterate    13  f =       -214.2  |proj g|=       0.51874
At iterate    14  f =       -214.2  |proj g|=       0.51888
At iterate    15  f =       -214.2  |proj g|=       0.51888

iterations 15
function evaluations 18
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.518877
final function value -214.203

F = -214.203
final  value -214.203278 
converged
 
INFO  [22:20:18.403] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:20:18.460] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:20:18.467] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:20:22.904] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:20:27.315] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:20:31.652] [mlr3]  Finished benchmark 
INFO  [22:20:31.721] [bbotk] Result of batch 28: 
INFO  [22:20:31.723] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:20:31.723] [bbotk]              4.894359                 4.202327                       0.2629322 
INFO  [22:20:31.723] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:20:31.723] [bbotk]                     2293        0.648 -0.9656353         <NA>   0.9733825 
INFO  [22:20:31.723] [bbotk]                                 uhash 
INFO  [22:20:31.723] [bbotk]  7066bcfe-0fb9-4ead-91df-12adfa96fc56 
DEBUG [22:20:32.458] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.514815e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.514815e-05 0.001865035 
  - best initial criterion value(s) :  215.4665 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -215.47  |proj g|=      0.81846
At iterate     1  f =       -220.6  |proj g|=       0.69554
At iterate     2  f =      -222.13  |proj g|=       0.83407
At iterate     3  f =      -222.29  |proj g|=       0.85327
At iterate     4  f =      -222.33  |proj g|=       0.86283
At iterate     5  f =      -222.34  |proj g|=        0.8629
At iterate     6  f =      -222.34  |proj g|=       0.86259
At iterate     7  f =      -222.34  |proj g|=       0.86236

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.862364
final function value -222.335

F = -222.335
final  value -222.335268 
converged
 
INFO  [22:20:32.462] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:20:32.521] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:20:32.529] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:20:37.498] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:20:42.556] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:20:47.409] [mlr3]  Finished benchmark 
INFO  [22:20:47.478] [bbotk] Result of batch 29: 
INFO  [22:20:47.480] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:20:47.480] [bbotk]              9.010043                 3.550083                       0.2229186 
INFO  [22:20:47.480] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:20:47.480] [bbotk]                     2537         0.55 -0.9627404         <NA>   0.9742163 
INFO  [22:20:47.480] [bbotk]                                 uhash 
INFO  [22:20:47.480] [bbotk]  3f262de3-e3f1-40f4-bad8-9c77d744d78f 
DEBUG [22:20:48.213] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.49867e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.49867e-05 0.001864987 
  - best initial criterion value(s) :  212.2983 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -212.3  |proj g|=       2.8783
At iterate     1  f =      -212.56  |proj g|=        2.9907
At iterate     2  f =      -213.58  |proj g|=        2.7117
At iterate     3  f =      -217.17  |proj g|=        1.2785
At iterate     4  f =      -217.94  |proj g|=       0.84762
At iterate     5  f =      -218.09  |proj g|=        1.0683
At iterate     6  f =       -218.1  |proj g|=       0.98266
At iterate     7  f =       -218.1  |proj g|=       0.99215
At iterate     8  f =       -218.1  |proj g|=       0.99174
At iterate     9  f =       -218.1  |proj g|=       0.99158

iterations 9
function evaluations 15
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.991583
final function value -218.101

F = -218.101
final  value -218.101270 
converged
 
INFO  [22:20:48.217] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:20:48.274] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:20:48.281] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:20:55.404] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:21:02.421] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:21:09.278] [mlr3]  Finished benchmark 
INFO  [22:21:09.381] [bbotk] Result of batch 30: 
INFO  [22:21:09.384] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:21:09.384] [bbotk]              6.589633                 3.527603                       0.3857315 
INFO  [22:21:09.384] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:21:09.384] [bbotk]                     3720        0.531 -0.9678211         <NA>   0.9761777 
INFO  [22:21:09.384] [bbotk]                                 uhash 
INFO  [22:21:09.384] [bbotk]  4fe2ccff-3f9d-4cab-9a16-3f5c71e3581e 
DEBUG [22:21:10.223] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.488169e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.488169e-05 0.001862403 
  - best initial criterion value(s) :  221.2971 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -221.3  |proj g|=       3.4163
At iterate     1  f =      -222.25  |proj g|=        3.8433
At iterate     2  f =         -223  |proj g|=        3.7704
At iterate     3  f =      -223.44  |proj g|=        3.5231
At iterate     4  f =       -223.6  |proj g|=        3.2586
At iterate     5  f =      -223.83  |proj g|=        2.8793
At iterate     6  f =         -224  |proj g|=        2.5033
At iterate     7  f =         -224  |proj g|=        2.5251
At iterate     8  f =         -224  |proj g|=        2.5264
At iterate     9  f =         -224  |proj g|=        2.5273
At iterate    10  f =         -224  |proj g|=         2.529
At iterate    11  f =         -224  |proj g|=        2.5316
At iterate    12  f =         -224  |proj g|=        2.5359
At iterate    13  f =         -224  |proj g|=        2.5425
At iterate    14  f =         -224  |proj g|=        2.5536
At iterate    15  f =         -224  |proj g|=        2.5725
At iterate    16  f =      -224.01  |proj g|=         2.606
At iterate    17  f =      -224.03  |proj g|=        2.6669
At iterate    18  f =      -224.08  |proj g|=        2.7755
At iterate    19  f =      -224.19  |proj g|=        2.9438
At iterate    20  f =      -224.36  |proj g|=         3.093
At iterate    21  f =      -224.42  |proj g|=         3.074
At iterate    22  f =      -224.42  |proj g|=        3.0676
At iterate    23  f =      -224.42  |proj g|=        3.0624
At iterate    24  f =      -224.42  |proj g|=         3.043
At iterate    25  f =      -224.43  |proj g|=        3.0132
At iterate    26  f =      -224.44  |proj g|=        2.9523
At iterate    27  f =      -224.47  |proj g|=        2.8435
At iterate    28  f =      -224.52  |proj g|=        2.6835
At iterate    29  f =      -224.61  |proj g|=        2.5602
At iterate    30  f =      -224.66  |proj g|=        2.5442
At iterate    31  f =      -224.68  |proj g|=        2.5672
At iterate    32  f =      -224.73  |proj g|=        2.6003
At iterate    33  f =      -224.85  |proj g|=        2.5928
At iterate    34  f =      -225.18  |proj g|=        2.4984
At iterate    35  f =      -225.89  |proj g|=        2.2225
At iterate    36  f =      -227.45  |proj g|=        1.5617
At iterate    37  f =      -228.81  |proj g|=       0.68899
At iterate    38  f =         -231  |proj g|=        1.0891
At iterate    39  f =      -231.27  |proj g|=        1.1014
At iterate    40  f =      -231.32  |proj g|=        1.1213
At iterate    41  f =      -231.34  |proj g|=        1.1389
At iterate    42  f =      -231.47  |proj g|=        1.1747
At iterate    43  f =       -231.6  |proj g|=        1.1997
At iterate    44  f =       -231.6  |proj g|=        1.1839
At iterate    45  f =      -231.61  |proj g|=         1.189
At iterate    46  f =      -231.61  |proj g|=        1.1865
At iterate    47  f =      -231.61  |proj g|=        1.1851
At iterate    48  f =      -231.61  |proj g|=        1.1849
At iterate    49  f =      -231.61  |proj g|=        1.1848
At iterate    50  f =      -231.61  |proj g|=        1.1848
At iterate    51  f =      -231.61  |proj g|=        1.1841
At iterate    52  f =      -231.61  |proj g|=        1.1861
At iterate    53  f =      -231.61  |proj g|=        1.1851
At iterate    54  f =      -231.61  |proj g|=        1.1822
At iterate    55  f =      -231.61  |proj g|=        1.1806
At iterate    56  f =      -231.69  |proj g|=        1.1573
At iterate    57  f =      -232.18  |proj g|=        1.0119
At iterate    58  f =      -232.18  |proj g|=       0.99099
At iterate    59  f =      -233.06  |proj g|=       0.78595
At iterate    60  f =      -234.66  |proj g|=       0.62138
At iterate    61  f =      -235.04  |proj g|=       0.64623
At iterate    62  f =      -235.39  |proj g|=       0.63115
At iterate    63  f =      -235.77  |proj g|=       0.59718
At iterate    64  f =      -235.87  |proj g|=        0.5645
At iterate    65  f =      -235.92  |proj g|=       0.57259
At iterate    66  f =      -235.92  |proj g|=       0.57275
At iterate    67  f =      -235.92  |proj g|=        0.5727
At iterate    68  f =      -235.92  |proj g|=       0.57237
At iterate    69  f =      -235.92  |proj g|=       0.57096
At iterate    70  f =      -235.93  |proj g|=       0.56751
At iterate    71  f =      -235.94  |proj g|=       0.55935
At iterate    72  f =      -235.96  |proj g|=       0.54463
At iterate    73  f =      -236.03  |proj g|=       0.07522
At iterate    74  f =      -236.05  |proj g|=       0.46566
At iterate    75  f =      -236.05  |proj g|=       0.46545
At iterate    76  f =      -236.05  |proj g|=     0.0075158
At iterate    77  f =      -236.05  |proj g|=     0.0011812
At iterate    78  f =      -236.05  |proj g|=     0.0006664

iterations 78
function evaluations 88
segments explored during Cauchy searches 80
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0006664
final function value -236.05

F = -236.05
final  value -236.050195 
converged
 
INFO  [22:21:10.227] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:21:10.287] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:21:10.295] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:21:14.733] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:21:19.075] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:21:23.202] [mlr3]  Finished benchmark 
INFO  [22:21:23.463] [bbotk] Result of batch 31: 
INFO  [22:21:23.468] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:21:23.468] [bbotk]              8.014087                 4.891383                       0.2911558 
INFO  [22:21:23.468] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:21:23.468] [bbotk]                     2259        0.539 -0.9533278         <NA>   0.9745528 
INFO  [22:21:23.468] [bbotk]                                 uhash 
INFO  [22:21:23.468] [bbotk]  66a5258e-c057-41b1-a6f3-8455f22ed2f6 
DEBUG [22:21:24.397] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.473133e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.473133e-05 0.001843489 
  - best initial criterion value(s) :  230.4379 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -230.44  |proj g|=       1.3036
At iterate     1  f =      -231.55  |proj g|=        1.5946
At iterate     2  f =      -231.56  |proj g|=        1.5855
At iterate     3  f =      -231.56  |proj g|=        1.5792
At iterate     4  f =      -231.56  |proj g|=        1.5778
At iterate     5  f =      -231.57  |proj g|=        1.5835
At iterate     6  f =      -231.59  |proj g|=        1.6054
At iterate     7  f =       -231.6  |proj g|=        1.6464
At iterate     8  f =       -231.6  |proj g|=        1.6536
At iterate     9  f =       -231.6  |proj g|=        1.6538
At iterate    10  f =       -231.6  |proj g|=        1.6539
At iterate    11  f =       -231.6  |proj g|=        1.6541
At iterate    12  f =       -231.6  |proj g|=        1.6546
At iterate    13  f =       -231.6  |proj g|=         1.654
At iterate    14  f =       -231.6  |proj g|=        1.6543
At iterate    15  f =       -231.6  |proj g|=        1.6557
At iterate    16  f =       -231.6  |proj g|=        1.6588
At iterate    17  f =      -231.61  |proj g|=        1.6588
At iterate    18  f =      -231.62  |proj g|=        1.6619
At iterate    19  f =      -231.65  |proj g|=        1.6741
At iterate    20  f =      -231.66  |proj g|=        1.6454
At iterate    21  f =      -231.73  |proj g|=        1.6508
At iterate    22  f =      -232.49  |proj g|=        1.5126
At iterate    23  f =       -234.7  |proj g|=       0.97265
At iterate    24  f =      -235.38  |proj g|=       0.98396
At iterate    25  f =      -235.61  |proj g|=        1.0683
At iterate    26  f =      -235.61  |proj g|=        1.0393
At iterate    27  f =      -235.63  |proj g|=        1.0221
At iterate    28  f =      -235.63  |proj g|=        1.0155
At iterate    29  f =      -235.63  |proj g|=        1.0103
At iterate    30  f =      -235.63  |proj g|=        1.0097
At iterate    31  f =      -235.63  |proj g|=        1.0097

iterations 31
function evaluations 39
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.00966
final function value -235.627

F = -235.627
final  value -235.626532 
converged
 
INFO  [22:21:24.401] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:21:24.481] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:21:24.489] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:21:29.018] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:21:33.585] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:21:39.115] [mlr3]  Finished benchmark 
INFO  [22:21:39.183] [bbotk] Result of batch 32: 
INFO  [22:21:39.185] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:21:39.185] [bbotk]              6.423639                 3.133694                         0.26561 
INFO  [22:21:39.185] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:21:39.185] [bbotk]                     1421        0.663 -0.9635632         <NA>   0.9718202 
INFO  [22:21:39.185] [bbotk]                                 uhash 
INFO  [22:21:39.185] [bbotk]  a07cdf30-1100-40ac-b8c5-3b9b23d05634 
DEBUG [22:21:39.961] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.452973e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.452973e-05 0.001794516 
  - best initial criterion value(s) :  221.5253 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -221.53  |proj g|=       1.0323
At iterate     1  f =      -234.87  |proj g|=        2.2127
At iterate     2  f =      -235.59  |proj g|=        2.0918
At iterate     3  f =      -237.23  |proj g|=        1.5199
At iterate     4  f =       -237.6  |proj g|=        1.1457
At iterate     5  f =      -238.34  |proj g|=        1.0244
At iterate     6  f =       -238.9  |proj g|=        1.0703
At iterate     7  f =      -238.93  |proj g|=        0.9734
At iterate     8  f =      -238.93  |proj g|=       0.97634
At iterate     9  f =      -238.93  |proj g|=       0.97392
At iterate    10  f =      -238.93  |proj g|=       0.97421

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.974209
final function value -238.929

F = -238.929
final  value -238.929384 
converged
 
INFO  [22:21:39.966] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:21:40.024] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:21:40.031] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:21:41.529] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:21:43.157] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:21:44.926] [mlr3]  Finished benchmark 
INFO  [22:21:44.994] [bbotk] Result of batch 33: 
INFO  [22:21:44.996] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:21:44.996] [bbotk]              5.159304                 9.813425                       0.2463851 
INFO  [22:21:44.996] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:21:44.996] [bbotk]                      476        0.547 -0.9639598         <NA>   0.9616353 
INFO  [22:21:44.996] [bbotk]                                 uhash 
INFO  [22:21:44.996] [bbotk]  98cecbb8-ffb7-4441-9e84-ca915f0fb6ff 
DEBUG [22:21:45.783] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.434633e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.434633e-05 0.001760346 
  - best initial criterion value(s) :  229.3808 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -229.38  |proj g|=       3.8074
At iterate     1  f =      -233.15  |proj g|=        3.0074
At iterate     2  f =      -233.26  |proj g|=        2.7719
At iterate     3  f =      -233.31  |proj g|=        2.8898
At iterate     4  f =      -233.32  |proj g|=        2.8909
At iterate     5  f =      -233.32  |proj g|=        2.9067
At iterate     6  f =      -233.32  |proj g|=        2.9107
At iterate     7  f =      -233.32  |proj g|=        2.9109
At iterate     8  f =      -233.32  |proj g|=        2.9117
At iterate     9  f =      -233.32  |proj g|=        2.9146
At iterate    10  f =      -233.32  |proj g|=        2.9182
At iterate    11  f =      -233.32  |proj g|=        2.9244
At iterate    12  f =      -233.32  |proj g|=        2.9202
At iterate    13  f =      -233.33  |proj g|=        2.9343
At iterate    14  f =      -233.33  |proj g|=        2.9475
At iterate    15  f =      -233.36  |proj g|=        2.9682
At iterate    16  f =      -233.41  |proj g|=        2.9778
At iterate    17  f =      -233.54  |proj g|=        2.9491
At iterate    18  f =      -233.83  |proj g|=        2.8109
At iterate    19  f =      -234.46  |proj g|=         2.453
At iterate    20  f =       -235.6  |proj g|=        1.8341
At iterate    21  f =      -236.85  |proj g|=        1.1806
At iterate    22  f =      -237.15  |proj g|=       0.91795
At iterate    23  f =      -238.45  |proj g|=       0.71763
At iterate    24  f =      -239.59  |proj g|=       0.75193
At iterate    25  f =      -239.61  |proj g|=       0.73868
At iterate    26  f =      -239.62  |proj g|=       0.72297
At iterate    27  f =      -239.62  |proj g|=       0.72246
At iterate    28  f =      -239.62  |proj g|=        0.7221
At iterate    29  f =      -239.62  |proj g|=       0.72175
At iterate    30  f =      -239.62  |proj g|=       0.72175

iterations 30
function evaluations 35
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.721755
final function value -239.618

F = -239.618
final  value -239.618242 
converged
 
INFO  [22:21:45.788] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:21:45.846] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:21:45.853] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:21:55.841] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:22:07.976] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:22:20.303] [mlr3]  Finished benchmark 
INFO  [22:22:20.392] [bbotk] Result of batch 34: 
INFO  [22:22:20.393] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:22:20.393] [bbotk]              6.192534                 9.229502                       0.3847479 
INFO  [22:22:20.393] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:22:20.393] [bbotk]                     3892        0.556 -0.9665059         <NA>   0.9763933 
INFO  [22:22:20.393] [bbotk]                                 uhash 
INFO  [22:22:20.393] [bbotk]  a32c168b-dbf4-47df-bbe8-aabf3516ac02 
DEBUG [22:22:21.158] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.425655e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.425655e-05 0.001758705 
  - best initial criterion value(s) :  239.9391 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -239.94  |proj g|=        1.734
At iterate     1  f =      -245.08  |proj g|=        0.6471
At iterate     2  f =      -245.13  |proj g|=       0.64557
At iterate     3  f =      -245.16  |proj g|=       0.64304
At iterate     4  f =      -245.16  |proj g|=       0.64328
At iterate     5  f =      -245.16  |proj g|=       0.64303
At iterate     6  f =      -245.16  |proj g|=       0.64208
At iterate     7  f =      -245.16  |proj g|=       0.64054
At iterate     8  f =      -245.16  |proj g|=       0.63988
At iterate     9  f =      -245.16  |proj g|=       0.63983
At iterate    10  f =      -245.16  |proj g|=       0.63981

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.639813
final function value -245.158

F = -245.158
final  value -245.158292 
converged
 
INFO  [22:22:21.162] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:22:21.221] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:22:21.228] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:22:33.320] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:22:48.719] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:23:02.114] [mlr3]  Finished benchmark 
INFO  [22:23:02.185] [bbotk] Result of batch 35: 
INFO  [22:23:02.187] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:23:02.187] [bbotk]              8.036883                 5.227056                       0.4751861 
INFO  [22:23:02.187] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:23:02.187] [bbotk]                     4788        0.558 -0.9662597         <NA>   0.9777041 
INFO  [22:23:02.187] [bbotk]                                 uhash 
INFO  [22:23:02.187] [bbotk]  1d679706-f0f1-4e74-a3b3-ed1622cda203 
DEBUG [22:23:02.980] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.420468e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.420468e-05 0.001759081 
  - best initial criterion value(s) :  249.2269 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -249.23  |proj g|=      0.72962
At iterate     1  f =      -249.65  |proj g|=        0.6976
At iterate     2  f =      -250.08  |proj g|=       0.68696
At iterate     3  f =      -250.81  |proj g|=        0.6376
At iterate     4  f =      -250.94  |proj g|=       0.61441
At iterate     5  f =      -250.98  |proj g|=       0.51242
At iterate     6  f =      -250.98  |proj g|=        0.5146
At iterate     7  f =      -250.98  |proj g|=       0.51494
At iterate     8  f =      -250.98  |proj g|=       0.51496

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.514964
final function value -250.978

F = -250.978
final  value -250.977631 
converged
 
INFO  [22:23:02.984] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:23:03.042] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:23:03.049] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:23:09.432] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:23:16.452] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:23:22.649] [mlr3]  Finished benchmark 
INFO  [22:23:22.721] [bbotk] Result of batch 36: 
INFO  [22:23:22.723] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:23:22.723] [bbotk]               2.64994                 6.216846                       0.0785962 
INFO  [22:23:22.723] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:23:22.723] [bbotk]                     2165        0.581 -0.9656867         <NA>   0.9497056 
INFO  [22:23:22.723] [bbotk]                                 uhash 
INFO  [22:23:22.723] [bbotk]  72fb5549-0a42-4b39-bd57-bd2f57200dff 
DEBUG [22:23:23.662] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.445414e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.445414e-05 0.001790382 
  - best initial criterion value(s) :  250.1344 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -250.13  |proj g|=       2.6613
At iterate     1  f =         -252  |proj g|=        3.2294
At iterate     2  f =      -252.78  |proj g|=        2.9446
At iterate     3  f =      -254.52  |proj g|=         2.133
At iterate     4  f =      -255.72  |proj g|=       0.78362
At iterate     5  f =      -256.02  |proj g|=        1.3273
At iterate     6  f =      -256.03  |proj g|=        1.2679
At iterate     7  f =      -256.03  |proj g|=        1.2366
At iterate     8  f =      -256.03  |proj g|=        1.2397
At iterate     9  f =      -256.03  |proj g|=        1.2396

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.23964
final function value -256.034

F = -256.034
final  value -256.033817 
converged
 
INFO  [22:23:23.667] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:23:23.756] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:23:23.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:23:35.562] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:23:50.057] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:24:02.390] [mlr3]  Finished benchmark 
INFO  [22:24:02.458] [bbotk] Result of batch 37: 
INFO  [22:24:02.460] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:24:02.460] [bbotk]              6.533393                 4.340649                        0.321948 
INFO  [22:24:02.460] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:24:02.460] [bbotk]                     4333        0.546 -0.9649417         <NA>   0.9761121 
INFO  [22:24:02.460] [bbotk]                                 uhash 
INFO  [22:24:02.460] [bbotk]  8c3bbccb-7c88-4c82-9907-dc766b3d0a2b 
DEBUG [22:24:03.275] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.435819e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.435819e-05 0.001778023 
  - best initial criterion value(s) :  242.2714 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -242.27  |proj g|=       5.4431
At iterate     1  f =      -243.25  |proj g|=        5.3292
At iterate     2  f =      -244.69  |proj g|=        5.2236
At iterate     3  f =      -247.35  |proj g|=        4.8354
At iterate     4  f =      -248.41  |proj g|=        4.4583
At iterate     5  f =      -249.92  |proj g|=          3.85
At iterate     6  f =      -250.11  |proj g|=        3.6329
At iterate     7  f =      -250.15  |proj g|=        3.5354
At iterate     8  f =      -250.16  |proj g|=        3.5076
At iterate     9  f =      -250.16  |proj g|=        3.5051
At iterate    10  f =      -250.16  |proj g|=        3.4997
At iterate    11  f =      -250.17  |proj g|=        3.4749
At iterate    12  f =      -250.22  |proj g|=        3.3834
At iterate    13  f =      -250.36  |proj g|=        3.2165
At iterate    14  f =       -250.7  |proj g|=        2.9398
At iterate    15  f =      -251.45  |proj g|=        2.5155
At iterate    16  f =      -251.46  |proj g|=        2.5358
At iterate    17  f =      -252.84  |proj g|=        1.9813
At iterate    18  f =      -257.95  |proj g|=        1.6275
At iterate    19  f =      -260.34  |proj g|=        1.1239
At iterate    20  f =      -262.48  |proj g|=         1.499
At iterate    21  f =      -264.11  |proj g|=        1.3508
At iterate    22  f =      -264.36  |proj g|=       0.90236
At iterate    23  f =      -264.39  |proj g|=        1.0242
At iterate    24  f =      -264.39  |proj g|=       0.99903
At iterate    25  f =      -264.39  |proj g|=       0.99973
At iterate    26  f =      -264.39  |proj g|=       0.99979

iterations 26
function evaluations 38
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.999788
final function value -264.391

F = -264.391
final  value -264.391119 
converged
 
INFO  [22:24:03.279] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:24:03.335] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:24:03.342] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:24:07.627] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:24:12.091] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:24:17.658] [mlr3]  Finished benchmark 
INFO  [22:24:17.726] [bbotk] Result of batch 38: 
INFO  [22:24:17.729] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:24:17.729] [bbotk]               6.75529                 8.840634                       0.2552616 
INFO  [22:24:17.729] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:24:17.729] [bbotk]                     1640        0.558 -0.9641253         <NA>   0.9723265 
INFO  [22:24:17.729] [bbotk]                                 uhash 
INFO  [22:24:17.729] [bbotk]  6bc8c5f5-2e5d-42e6-8b40-ee99ed8fcaa1 
DEBUG [22:24:18.549] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.418484e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.418484e-05 0.001747935 
  - best initial criterion value(s) :  249.8708 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -249.87  |proj g|=      0.86358
At iterate     1  f =      -255.14  |proj g|=        3.2875
At iterate     2  f =      -257.49  |proj g|=        3.7399
At iterate     3  f =      -260.59  |proj g|=        4.0503
At iterate     4  f =      -264.96  |proj g|=        3.3438
At iterate     5  f =      -265.71  |proj g|=        2.9829
At iterate     6  f =      -265.78  |proj g|=        2.8243
At iterate     7  f =      -265.79  |proj g|=        2.8241
At iterate     8  f =      -265.79  |proj g|=        2.8175
At iterate     9  f =      -265.79  |proj g|=        2.8185
At iterate    10  f =      -265.79  |proj g|=        2.8189
At iterate    11  f =      -265.79  |proj g|=        2.8199
At iterate    12  f =      -265.79  |proj g|=        2.8217
At iterate    13  f =      -265.79  |proj g|=        2.8244
At iterate    14  f =      -265.79  |proj g|=        2.8288
At iterate    15  f =      -265.79  |proj g|=        2.8356
At iterate    16  f =      -265.79  |proj g|=        2.8462
At iterate    17  f =      -265.79  |proj g|=        2.8626
At iterate    18  f =       -265.8  |proj g|=        2.8874
At iterate    19  f =      -265.83  |proj g|=        2.9221
At iterate    20  f =      -265.92  |proj g|=        2.9616
At iterate    21  f =      -266.14  |proj g|=        2.9765
At iterate    22  f =      -266.75  |proj g|=        2.8601
At iterate    23  f =      -268.42  |proj g|=        2.2675
At iterate    24  f =      -269.56  |proj g|=        1.5689
At iterate    25  f =      -269.71  |proj g|=        1.3375
At iterate    26  f =      -269.74  |proj g|=         1.275
At iterate    27  f =      -269.75  |proj g|=        1.2703
At iterate    28  f =      -269.75  |proj g|=        1.2803
At iterate    29  f =      -269.75  |proj g|=        1.3006
At iterate    30  f =      -269.76  |proj g|=        1.3352
At iterate    31  f =      -269.78  |proj g|=        1.3926
At iterate    32  f =      -269.84  |proj g|=        1.4752
At iterate    33  f =      -269.98  |proj g|=        1.5889
At iterate    34  f =      -270.32  |proj g|=        1.7026
At iterate    35  f =      -271.01  |proj g|=        1.6298
At iterate    36  f =      -271.52  |proj g|=        1.3948
At iterate    37  f =      -273.21  |proj g|=         1.121
At iterate    38  f =      -275.41  |proj g|=       0.83767
At iterate    39  f =      -276.17  |proj g|=       0.56888
At iterate    40  f =      -276.35  |proj g|=       0.44186
At iterate    41  f =      -276.36  |proj g|=       0.44186
At iterate    42  f =      -276.36  |proj g|=       0.44186
At iterate    43  f =      -276.36  |proj g|=       0.44185

iterations 43
function evaluations 52
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.441855
final function value -276.365

F = -276.365
final  value -276.364673 
converged
 
INFO  [22:24:18.554] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:24:18.609] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:24:18.617] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:24:26.226] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:24:34.586] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:24:42.873] [mlr3]  Finished benchmark 
INFO  [22:24:42.957] [bbotk] Result of batch 39: 
INFO  [22:24:42.959] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:24:42.959] [bbotk]              3.207952                 3.193903                        0.154196 
INFO  [22:24:42.959] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:24:42.959] [bbotk]                     2828        0.549 -0.9502875         <NA>   0.9665232 
INFO  [22:24:42.959] [bbotk]                                 uhash 
INFO  [22:24:42.959] [bbotk]  df739767-d674-4e29-8067-da7f01bde210 
DEBUG [22:24:43.801] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.398011e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.398011e-05 0.001725165 
  - best initial criterion value(s) :  263.2599 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -263.26  |proj g|=       5.0497
At iterate     1  f =      -265.48  |proj g|=        5.3716
At iterate     2  f =      -266.12  |proj g|=        4.8156
At iterate     3  f =      -266.83  |proj g|=        3.5917
At iterate     4  f =      -267.25  |proj g|=        3.1526
At iterate     5  f =      -267.35  |proj g|=        2.9355
At iterate     6  f =      -267.35  |proj g|=        2.9484
At iterate     7  f =      -267.35  |proj g|=          2.95
At iterate     8  f =      -267.35  |proj g|=        2.9506
At iterate     9  f =      -267.35  |proj g|=        2.9528
At iterate    10  f =      -267.35  |proj g|=        2.9556
At iterate    11  f =      -267.35  |proj g|=        2.9607
At iterate    12  f =      -267.35  |proj g|=        2.9689
At iterate    13  f =      -267.35  |proj g|=        2.9828
At iterate    14  f =      -267.36  |proj g|=        3.0064
At iterate    15  f =      -267.37  |proj g|=        3.0476
At iterate    16  f =       -267.4  |proj g|=        3.1206
At iterate    17  f =      -267.47  |proj g|=        3.2508
At iterate    18  f =      -267.67  |proj g|=        3.4765
At iterate    19  f =      -268.08  |proj g|=        3.8199
At iterate    20  f =      -268.92  |proj g|=        4.1391
At iterate    21  f =      -269.34  |proj g|=        4.0906
At iterate    22  f =      -269.35  |proj g|=        4.1647
At iterate    23  f =      -269.35  |proj g|=        4.1941
At iterate    24  f =      -269.35  |proj g|=        4.1953
At iterate    25  f =      -269.35  |proj g|=        4.2053
At iterate    26  f =      -269.35  |proj g|=         4.213
At iterate    27  f =      -269.36  |proj g|=        4.2646
At iterate    28  f =      -269.36  |proj g|=         4.258
At iterate    29  f =      -269.41  |proj g|=        4.2568
At iterate    30  f =      -269.74  |proj g|=        4.1597
At iterate    31  f =      -270.49  |proj g|=        3.8018
At iterate    32  f =      -271.88  |proj g|=        3.0136
At iterate    33  f =      -273.65  |proj g|=        1.8187
At iterate    34  f =      -274.08  |proj g|=        1.7206
At iterate    35  f =      -275.71  |proj g|=        1.2166
At iterate    36  f =      -277.59  |proj g|=       0.56992
At iterate    37  f =      -278.35  |proj g|=       0.64428
At iterate    38  f =      -278.89  |proj g|=       0.68471
At iterate    39  f =      -279.06  |proj g|=       0.63636
At iterate    40  f =      -279.17  |proj g|=       0.69164
At iterate    41  f =      -279.19  |proj g|=       0.70983
At iterate    42  f =      -279.19  |proj g|=        0.7161
At iterate    43  f =      -279.19  |proj g|=       0.71701
At iterate    44  f =      -279.19  |proj g|=       0.71708

iterations 44
function evaluations 51
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.71708
final function value -279.191

F = -279.191
final  value -279.191254 
converged
 
INFO  [22:24:43.805] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:24:43.863] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:24:43.870] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:24:46.276] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:24:48.924] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:24:51.585] [mlr3]  Finished benchmark 
INFO  [22:24:51.839] [bbotk] Result of batch 40: 
INFO  [22:24:51.841] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:24:51.841] [bbotk]              4.174998                 7.125338                       0.1055547 
INFO  [22:24:51.841] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [22:24:51.841] [bbotk]                      860        0.589 -0.957167         <NA>   0.9565634 
INFO  [22:24:51.841] [bbotk]                                 uhash 
INFO  [22:24:51.841] [bbotk]  158cb959-fc6c-42d2-a4a0-efefa2eb3c35 
DEBUG [22:24:52.711] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.394223e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.394223e-05 0.001719754 
  - best initial criterion value(s) :  249.3938 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -249.39  |proj g|=         7.93
At iterate     1  f =       -260.6  |proj g|=        5.2185
At iterate     2  f =       -264.1  |proj g|=         4.799
At iterate     3  f =      -266.39  |proj g|=        3.6245
At iterate     4  f =      -267.84  |proj g|=        2.2982
At iterate     5  f =      -267.99  |proj g|=        2.0019
At iterate     6  f =      -268.08  |proj g|=        1.8716
At iterate     7  f =      -268.24  |proj g|=        2.0515
At iterate     8  f =      -268.25  |proj g|=        1.9698
At iterate     9  f =      -268.25  |proj g|=        1.9573
At iterate    10  f =      -268.25  |proj g|=        1.9556
At iterate    11  f =      -268.25  |proj g|=        1.9526
At iterate    12  f =      -268.25  |proj g|=        1.9503
At iterate    13  f =      -268.26  |proj g|=         1.935
At iterate    14  f =      -268.27  |proj g|=         1.917
At iterate    15  f =      -268.29  |proj g|=         1.862
At iterate    16  f =      -268.34  |proj g|=        1.7712
At iterate    17  f =      -268.44  |proj g|=        1.5754
At iterate    18  f =      -268.44  |proj g|=        1.6854
At iterate    19  f =      -268.65  |proj g|=        1.4095
At iterate    20  f =       -269.1  |proj g|=        1.0705
At iterate    21  f =      -270.44  |proj g|=       0.86021
At iterate    22  f =      -272.67  |proj g|=        0.7062
At iterate    23  f =      -273.28  |proj g|=       0.94182
At iterate    24  f =      -273.46  |proj g|=       0.83627
At iterate    25  f =      -273.52  |proj g|=       0.82697
At iterate    26  f =      -273.55  |proj g|=       0.81822
At iterate    27  f =      -273.55  |proj g|=        0.8286
At iterate    28  f =      -273.55  |proj g|=       0.83155
At iterate    29  f =      -273.55  |proj g|=       0.83142
At iterate    30  f =      -273.55  |proj g|=       0.83157
At iterate    31  f =      -273.55  |proj g|=       0.83132
At iterate    32  f =      -273.55  |proj g|=       0.83079
At iterate    33  f =      -273.55  |proj g|=       0.83166
At iterate    34  f =      -273.55  |proj g|=       0.83012
At iterate    35  f =      -273.55  |proj g|=       0.82801
At iterate    36  f =      -273.55  |proj g|=       0.82426
At iterate    37  f =      -273.55  |proj g|=        0.8185
At iterate    38  f =      -273.56  |proj g|=       0.80602
At iterate    39  f =      -273.56  |proj g|=       0.81359
At iterate    40  f =      -273.57  |proj g|=       0.80178
At iterate    41  f =       -273.6  |proj g|=       0.78778
At iterate    42  f =      -273.65  |proj g|=       0.78262
At iterate    43  f =      -273.72  |proj g|=       0.77476
At iterate    44  f =      -273.72  |proj g|=       0.75909
At iterate    45  f =      -273.83  |proj g|=       0.74051
At iterate    46  f =      -273.83  |proj g|=       0.75082
At iterate    47  f =      -274.08  |proj g|=       0.68728
At iterate    48  f =      -274.99  |proj g|=       0.54829
At iterate    49  f =      -275.95  |proj g|=       0.68516
At iterate    50  f =      -275.97  |proj g|=       0.46305
At iterate    51  f =      -276.47  |proj g|=        0.4649
At iterate    52  f =      -276.65  |proj g|=       0.59772
At iterate    53  f =      -276.71  |proj g|=       0.59755
At iterate    54  f =      -276.73  |proj g|=      0.052458
At iterate    55  f =      -276.73  |proj g|=     0.0044754
At iterate    56  f =      -276.73  |proj g|=     0.0031582

iterations 56
function evaluations 68
segments explored during Cauchy searches 58
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00315816
final function value -276.728

F = -276.728
final  value -276.727625 
converged
 
INFO  [22:24:52.715] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:24:52.773] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:24:52.780] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:25:03.761] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:25:14.587] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:25:26.110] [mlr3]  Finished benchmark 
INFO  [22:25:26.179] [bbotk] Result of batch 41: 
INFO  [22:25:26.181] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:25:26.181] [bbotk]              4.349335                 6.151719                       0.3219447 
INFO  [22:25:26.181] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:25:26.181] [bbotk]                     3926        0.569 -0.9594135         <NA>   0.9752652 
INFO  [22:25:26.181] [bbotk]                                 uhash 
INFO  [22:25:26.181] [bbotk]  805f3e0f-509a-4719-8e71-59f9e0ad83da 
DEBUG [22:25:27.023] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.383774e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.383774e-05 0.001716657 
  - best initial criterion value(s) :  260.7106 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -260.71  |proj g|=       4.2491
At iterate     1  f =      -261.72  |proj g|=        3.6584
At iterate     2  f =      -262.25  |proj g|=        3.5879
At iterate     3  f =      -262.51  |proj g|=        3.4395
At iterate     4  f =      -262.56  |proj g|=        3.3783
At iterate     5  f =      -262.57  |proj g|=        3.3606
At iterate     6  f =      -262.57  |proj g|=          3.36
At iterate     7  f =      -262.57  |proj g|=         3.362
At iterate     8  f =      -262.57  |proj g|=        3.3618
At iterate     9  f =      -262.57  |proj g|=         3.361
At iterate    10  f =      -262.57  |proj g|=        3.3588
At iterate    11  f =      -262.57  |proj g|=        3.3557
At iterate    12  f =      -262.57  |proj g|=        3.3502
At iterate    13  f =      -262.57  |proj g|=        3.3413
At iterate    14  f =      -262.57  |proj g|=        3.3262
At iterate    15  f =      -262.57  |proj g|=        3.3031
At iterate    16  f =      -262.58  |proj g|=        3.2651
At iterate    17  f =      -262.59  |proj g|=        3.1721
At iterate    18  f =      -262.62  |proj g|=         3.158
At iterate    19  f =      -262.74  |proj g|=        3.0826
At iterate    20  f =      -262.99  |proj g|=        2.9163
At iterate    21  f =      -263.53  |proj g|=        2.5824
At iterate    22  f =      -264.42  |proj g|=        2.0401
At iterate    23  f =      -264.48  |proj g|=        2.0673
At iterate    24  f =      -265.87  |proj g|=        1.9874
At iterate    25  f =      -270.01  |proj g|=        1.6564
At iterate    26  f =      -272.02  |proj g|=       0.96671
At iterate    27  f =      -275.54  |proj g|=       0.81156
At iterate    28  f =      -276.23  |proj g|=       0.83577
At iterate    29  f =      -276.53  |proj g|=       0.66892
At iterate    30  f =      -276.54  |proj g|=       0.51445
At iterate    31  f =      -276.54  |proj g|=       0.55852
At iterate    32  f =      -276.54  |proj g|=       0.55282
At iterate    33  f =      -276.54  |proj g|=       0.55357
At iterate    34  f =      -276.54  |proj g|=       0.55359

iterations 34
function evaluations 39
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.553587
final function value -276.542

F = -276.542
final  value -276.541760 
converged
 
INFO  [22:25:27.028] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:25:27.082] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:25:27.089] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:25:37.604] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:25:51.635] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:26:02.316] [mlr3]  Finished benchmark 
INFO  [22:26:02.386] [bbotk] Result of batch 42: 
INFO  [22:26:02.388] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:26:02.388] [bbotk]              5.730619                 7.980496                       0.1036907 
INFO  [22:26:02.388] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:26:02.388] [bbotk]                     4086        0.574 -0.9638229         <NA>   0.9721826 
INFO  [22:26:02.388] [bbotk]                                 uhash 
INFO  [22:26:02.388] [bbotk]  fb6fa486-be8b-4197-a80e-9531d5eb2c4c 
DEBUG [22:26:03.336] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.367895e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.367895e-05 0.001707429 
  - best initial criterion value(s) :  276.8605 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -276.86  |proj g|=      0.86024
At iterate     1  f =         -278  |proj g|=        2.7373
At iterate     2  f =      -280.28  |proj g|=        2.5113
At iterate     3  f =      -282.51  |proj g|=         1.712
At iterate     4  f =       -282.7  |proj g|=        1.4977
At iterate     5  f =       -282.9  |proj g|=        1.1307
At iterate     6  f =      -282.98  |proj g|=         1.351
At iterate     7  f =      -282.98  |proj g|=        1.2985
At iterate     8  f =      -282.98  |proj g|=        1.2929
At iterate     9  f =      -282.98  |proj g|=        1.2921
At iterate    10  f =      -282.98  |proj g|=        1.2926

iterations 10
function evaluations 13
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.29259
final function value -282.984

F = -282.984
final  value -282.983689 
converged
 
INFO  [22:26:03.341] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:26:03.397] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:26:03.404] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:26:16.508] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:26:28.670] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:26:41.771] [mlr3]  Finished benchmark 
INFO  [22:26:41.841] [bbotk] Result of batch 43: 
INFO  [22:26:41.843] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:26:41.843] [bbotk]              9.739895                 5.716943                       0.4384364 
INFO  [22:26:41.843] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:26:41.843] [bbotk]                     4432         0.56 -0.9622171         <NA>   0.9769202 
INFO  [22:26:41.843] [bbotk]                                 uhash 
INFO  [22:26:41.843] [bbotk]  705c4714-44d4-48c0-a357-298ebed00372 
DEBUG [22:26:42.756] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.361631e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.361631e-05 0.001710269 
  - best initial criterion value(s) :  269.7974 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -269.8  |proj g|=      0.89187
At iterate     1  f =      -270.94  |proj g|=        4.4297
At iterate     2  f =      -272.37  |proj g|=        3.8587
At iterate     3  f =      -274.96  |proj g|=        3.1958
At iterate     4  f =       -278.6  |proj g|=        2.9169
At iterate     5  f =      -283.28  |proj g|=        2.9869
At iterate     6  f =      -285.43  |proj g|=        3.0446
At iterate     7  f =      -285.68  |proj g|=        2.8014
At iterate     8  f =      -285.75  |proj g|=        2.9079
At iterate     9  f =      -285.75  |proj g|=        2.8973
At iterate    10  f =      -285.75  |proj g|=         2.899
At iterate    11  f =      -285.75  |proj g|=        2.8993
At iterate    12  f =      -285.75  |proj g|=        2.9001
At iterate    13  f =      -285.75  |proj g|=        2.9016
At iterate    14  f =      -285.75  |proj g|=        2.9071
At iterate    15  f =      -285.75  |proj g|=        2.9016
At iterate    16  f =      -285.75  |proj g|=        2.9081
At iterate    17  f =      -285.75  |proj g|=         2.925
At iterate    18  f =      -285.76  |proj g|=        2.9486
At iterate    19  f =      -285.79  |proj g|=         2.987
At iterate    20  f =      -285.88  |proj g|=        3.0291
At iterate    21  f =      -285.89  |proj g|=        3.0852
At iterate    22  f =      -286.08  |proj g|=         3.066
At iterate    23  f =      -286.57  |proj g|=        2.8965
At iterate    24  f =      -287.84  |proj g|=        2.3351
At iterate    25  f =      -290.14  |proj g|=        1.3864
At iterate    26  f =      -292.99  |proj g|=       0.81502
At iterate    27  f =      -293.02  |proj g|=       0.76708
At iterate    28  f =      -294.14  |proj g|=       0.89046
At iterate    29  f =      -294.29  |proj g|=       0.86041
At iterate    30  f =      -294.31  |proj g|=       0.86595
At iterate    31  f =      -294.31  |proj g|=       0.87097
At iterate    32  f =      -294.31  |proj g|=       0.87096
At iterate    33  f =      -294.31  |proj g|=       0.87102
At iterate    34  f =      -294.31  |proj g|=       0.86916
At iterate    35  f =      -294.31  |proj g|=       0.86962
At iterate    36  f =      -294.31  |proj g|=       0.86979
At iterate    37  f =      -294.31  |proj g|=       0.87168
At iterate    38  f =      -294.32  |proj g|=       0.87334
At iterate    39  f =      -294.33  |proj g|=       0.87501
At iterate    40  f =      -294.34  |proj g|=       0.87446
At iterate    41  f =      -294.39  |proj g|=       0.86496
At iterate    42  f =      -294.49  |proj g|=       0.86959
At iterate    43  f =      -294.69  |proj g|=       0.76485
At iterate    44  f =      -294.96  |proj g|=       0.59516
At iterate    45  f =      -295.16  |proj g|=        0.6034
At iterate    46  f =      -295.21  |proj g|=       0.60359
At iterate    47  f =      -295.73  |proj g|=       0.55123
At iterate    48  f =      -296.25  |proj g|=       0.45719
At iterate    49  f =      -296.26  |proj g|=       0.53816
At iterate    50  f =      -296.27  |proj g|=       0.53482
At iterate    51  f =      -296.27  |proj g|=       0.53245
At iterate    52  f =      -296.27  |proj g|=       0.53322
At iterate    53  f =      -296.27  |proj g|=       0.53399
At iterate    54  f =      -296.28  |proj g|=       0.54248
At iterate    55  f =      -296.32  |proj g|=       0.55263
At iterate    56  f =      -296.45  |proj g|=       0.56959
At iterate    57  f =      -296.52  |proj g|=       0.56582
At iterate    58  f =      -296.54  |proj g|=       0.54533
At iterate    59  f =      -296.54  |proj g|=       0.49306
At iterate    60  f =      -296.54  |proj g|=      0.028776
At iterate    61  f =      -296.54  |proj g|=      0.024948

iterations 61
function evaluations 82
segments explored during Cauchy searches 63
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0249479
final function value -296.536

F = -296.536
final  value -296.536284 
converged
 
INFO  [22:26:42.761] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:26:42.818] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:26:42.825] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:26:53.064] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:27:03.363] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:27:14.530] [mlr3]  Finished benchmark 
INFO  [22:27:14.600] [bbotk] Result of batch 44: 
INFO  [22:27:14.602] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:27:14.602] [bbotk]              6.948564                 6.939342                       0.4093143 
INFO  [22:27:14.602] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:27:14.602] [bbotk]                     3818        0.581 -0.9545954         <NA>   0.9763711 
INFO  [22:27:14.602] [bbotk]                                 uhash 
INFO  [22:27:14.602] [bbotk]  a3585f1d-35e6-42e7-bff0-368c468b7e88 
DEBUG [22:27:15.495] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.353861e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.353861e-05 0.001710881 
  - best initial criterion value(s) :  283.1623 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -283.16  |proj g|=        1.563
At iterate     1  f =      -284.96  |proj g|=        2.5383
At iterate     2  f =      -287.58  |proj g|=        2.3121
At iterate     3  f =      -290.38  |proj g|=        1.5637
At iterate     4  f =      -290.53  |proj g|=        1.4271
At iterate     5  f =      -290.76  |proj g|=        1.4269
At iterate     6  f =      -290.83  |proj g|=        1.5422
At iterate     7  f =      -290.83  |proj g|=        1.5173
At iterate     8  f =      -290.83  |proj g|=        1.5177
At iterate     9  f =      -290.83  |proj g|=        1.5195
At iterate    10  f =      -290.83  |proj g|=        1.5187
At iterate    11  f =      -290.83  |proj g|=        1.5179
At iterate    12  f =      -290.83  |proj g|=        1.5164
At iterate    13  f =      -290.83  |proj g|=        1.5142
At iterate    14  f =      -290.83  |proj g|=        1.5103
At iterate    15  f =      -290.83  |proj g|=         1.504
At iterate    16  f =      -290.84  |proj g|=        1.4934
At iterate    17  f =      -290.84  |proj g|=         1.475
At iterate    18  f =      -290.85  |proj g|=        1.4423
At iterate    19  f =      -290.88  |proj g|=        1.3853
At iterate    20  f =      -290.94  |proj g|=        1.2997
At iterate    21  f =      -291.03  |proj g|=        1.2278
At iterate    22  f =      -291.09  |proj g|=        1.4113
At iterate    23  f =      -291.09  |proj g|=        1.4276
At iterate    24  f =       -291.1  |proj g|=        1.4346
At iterate    25  f =      -291.12  |proj g|=        1.4855
At iterate    26  f =      -291.19  |proj g|=        1.6019
At iterate    27  f =      -291.44  |proj g|=         1.837
At iterate    28  f =      -291.49  |proj g|=        1.7633
At iterate    29  f =      -291.94  |proj g|=        2.0804
At iterate    30  f =      -292.55  |proj g|=        2.3182
At iterate    31  f =      -292.87  |proj g|=        2.2133
At iterate    32  f =      -292.88  |proj g|=        2.1395
At iterate    33  f =      -292.89  |proj g|=        2.1578
At iterate    34  f =      -292.89  |proj g|=        2.1585
At iterate    35  f =      -292.89  |proj g|=        2.1629
At iterate    36  f =      -292.89  |proj g|=        2.1639
At iterate    37  f =      -292.89  |proj g|=        2.1644

iterations 37
function evaluations 43
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.16439
final function value -292.886

F = -292.886
final  value -292.885763 
converged
 
INFO  [22:27:15.499] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:27:15.588] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:27:15.596] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:27:22.757] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:27:32.162] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:27:38.031] [mlr3]  Finished benchmark 
INFO  [22:27:38.100] [bbotk] Result of batch 45: 
INFO  [22:27:38.102] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:27:38.102] [bbotk]              4.325891                 8.739813                      0.02179853 
INFO  [22:27:38.102] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:27:38.102] [bbotk]                     2301        0.578 -0.9624668         <NA>   0.9492788 
INFO  [22:27:38.102] [bbotk]                                 uhash 
INFO  [22:27:38.102] [bbotk]  d2c1adc8-f801-4f5e-9eb5-828292674bf8 
DEBUG [22:27:38.920] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.379789e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.379789e-05 0.001728012 
  - best initial criterion value(s) :  283.6054 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -283.61  |proj g|=      0.34346
At iterate     1  f =      -283.66  |proj g|=       0.34099
At iterate     2  f =      -283.88  |proj g|=        0.3245
At iterate     3  f =      -284.12  |proj g|=       0.73853
At iterate     4  f =      -284.24  |proj g|=       0.27577
At iterate     5  f =      -284.25  |proj g|=       0.28209
At iterate     6  f =      -284.25  |proj g|=       0.43388
At iterate     7  f =      -284.25  |proj g|=       0.40434
At iterate     8  f =      -284.25  |proj g|=        0.3833
At iterate     9  f =      -284.25  |proj g|=       0.38429

iterations 9
function evaluations 16
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.384292
final function value -284.252

F = -284.252
final  value -284.251771 
converged
 
INFO  [22:27:38.925] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:27:38.983] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:27:38.990] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:27:50.253] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:27:59.909] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:28:12.116] [mlr3]  Finished benchmark 
INFO  [22:28:12.186] [bbotk] Result of batch 46: 
INFO  [22:28:12.188] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:28:12.188] [bbotk]              6.734048                 4.441135                       0.1757973 
INFO  [22:28:12.188] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:28:12.188] [bbotk]                     3832        0.606 -0.9681268         <NA>   0.9744791 
INFO  [22:28:12.188] [bbotk]                                 uhash 
INFO  [22:28:12.188] [bbotk]  2ac6efc8-5a3c-44da-a792-53fd2a01dbbf 
DEBUG [22:28:12.990] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.368289e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.368289e-05 0.001722389 
  - best initial criterion value(s) :  285.432 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -285.43  |proj g|=        4.401
At iterate     1  f =      -289.85  |proj g|=        2.8457
At iterate     2  f =      -295.95  |proj g|=         2.487
At iterate     3  f =      -305.27  |proj g|=        1.6967
At iterate     4  f =      -307.56  |proj g|=        1.2703
At iterate     5  f =      -307.64  |proj g|=         1.076
At iterate     6  f =       -307.7  |proj g|=        1.1729
At iterate     7  f =       -307.7  |proj g|=        1.1619
At iterate     8  f =       -307.7  |proj g|=        1.1561
At iterate     9  f =       -307.7  |proj g|=        1.1562

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.15618
final function value -307.701

F = -307.701
final  value -307.701435 
converged
 
INFO  [22:28:12.994] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:28:13.052] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:28:13.059] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:28:19.594] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:28:26.700] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:28:33.667] [mlr3]  Finished benchmark 
INFO  [22:28:33.736] [bbotk] Result of batch 47: 
INFO  [22:28:33.738] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:28:33.738] [bbotk]              5.688093                 9.276144                       0.4262953 
INFO  [22:28:33.738] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [22:28:33.738] [bbotk]                     2457        0.593 -0.956151         <NA>   0.9756251 
INFO  [22:28:33.738] [bbotk]                                 uhash 
INFO  [22:28:33.738] [bbotk]  d98608f3-1605-491a-b513-ad93a896a68b 
DEBUG [22:28:34.755] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.359164e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.359164e-05 0.00170873 
  - best initial criterion value(s) :  291.0108 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -291.01  |proj g|=       1.6889
At iterate     1  f =      -298.43  |proj g|=        1.6002
At iterate     2  f =      -299.91  |proj g|=         1.145
At iterate     3  f =      -302.43  |proj g|=       0.85996
At iterate     4  f =      -306.15  |proj g|=       0.65669
At iterate     5  f =      -309.44  |proj g|=       0.80145
At iterate     6  f =      -309.61  |proj g|=       0.88403
At iterate     7  f =      -310.21  |proj g|=        0.8263
At iterate     8  f =      -310.28  |proj g|=       0.77258
At iterate     9  f =      -310.34  |proj g|=       0.81899
At iterate    10  f =      -310.34  |proj g|=       0.80208
At iterate    11  f =      -310.34  |proj g|=       0.80369
At iterate    12  f =      -310.34  |proj g|=        0.8039
At iterate    13  f =      -310.34  |proj g|=       0.80396
At iterate    14  f =      -310.34  |proj g|=       0.80419
At iterate    15  f =      -310.34  |proj g|=       0.80453
At iterate    16  f =      -310.34  |proj g|=       0.80458
At iterate    17  f =      -310.34  |proj g|=       0.80624
At iterate    18  f =      -310.34  |proj g|=       0.80616
At iterate    19  f =      -310.34  |proj g|=       0.80585
At iterate    20  f =      -310.35  |proj g|=       0.80517
At iterate    21  f =      -310.35  |proj g|=       0.80333
At iterate    22  f =      -310.37  |proj g|=       0.79882
At iterate    23  f =      -310.41  |proj g|=       0.78884
At iterate    24  f =      -310.51  |proj g|=       0.77164
At iterate    25  f =      -310.51  |proj g|=       0.75327
At iterate    26  f =      -310.73  |proj g|=       0.71316
At iterate    27  f =      -311.39  |proj g|=       0.58432
At iterate    28  f =       -311.4  |proj g|=       0.57045
At iterate    29  f =       -311.4  |proj g|=       0.57235
At iterate    30  f =       -311.4  |proj g|=        0.5722
At iterate    31  f =       -311.4  |proj g|=       0.57224

iterations 31
function evaluations 42
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.572243
final function value -311.402

F = -311.402
final  value -311.401648 
converged
 
INFO  [22:28:34.759] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:28:34.829] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:28:34.836] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:28:46.125] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:28:57.047] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:29:06.674] [mlr3]  Finished benchmark 
INFO  [22:29:06.757] [bbotk] Result of batch 48: 
INFO  [22:29:06.759] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:29:06.759] [bbotk]              5.825662                 2.442166                       0.1807336 
INFO  [22:29:06.759] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:29:06.759] [bbotk]                     3631        0.765 -0.9595111         <NA>    0.974317 
INFO  [22:29:06.759] [bbotk]                                 uhash 
INFO  [22:29:06.759] [bbotk]  2b4d3423-dc76-42b5-9bf7-c1b68b60a344 
DEBUG [22:29:07.604] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.347589e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.347589e-05 0.001708435 
  - best initial criterion value(s) :  288.2605 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -288.26  |proj g|=       4.1919
At iterate     1  f =      -290.04  |proj g|=        5.4649
At iterate     2  f =         -294  |proj g|=        4.6694
At iterate     3  f =      -296.33  |proj g|=         3.721
At iterate     4  f =      -300.55  |proj g|=        2.9178
At iterate     5  f =      -302.11  |proj g|=        2.8838
At iterate     6  f =      -302.14  |proj g|=        2.7852
At iterate     7  f =      -302.14  |proj g|=        2.8214
At iterate     8  f =      -302.14  |proj g|=        2.8203
At iterate     9  f =      -302.14  |proj g|=        2.8194
At iterate    10  f =      -302.14  |proj g|=        2.8177
At iterate    11  f =      -302.14  |proj g|=        2.8152
At iterate    12  f =      -302.14  |proj g|=        2.8102
At iterate    13  f =      -302.14  |proj g|=         2.808
At iterate    14  f =      -302.15  |proj g|=        2.8008
At iterate    15  f =      -302.15  |proj g|=        2.7884
At iterate    16  f =      -302.18  |proj g|=        2.7647
At iterate    17  f =      -302.31  |proj g|=        2.6977
At iterate    18  f =      -302.33  |proj g|=        2.7548
At iterate    19  f =       -302.7  |proj g|=        2.5727
At iterate    20  f =      -303.57  |proj g|=         2.272
At iterate    21  f =      -305.86  |proj g|=        1.7587
At iterate    22  f =      -310.58  |proj g|=         1.121
At iterate    23  f =         -316  |proj g|=        1.1421
At iterate    24  f =      -316.82  |proj g|=       0.77106
At iterate    25  f =      -318.05  |proj g|=       0.71606
At iterate    26  f =       -318.8  |proj g|=       0.74568
At iterate    27  f =      -320.33  |proj g|=        0.6538
At iterate    28  f =      -320.92  |proj g|=       0.44548
At iterate    29  f =      -321.21  |proj g|=       0.40689
At iterate    30  f =       -321.3  |proj g|=        0.4179
At iterate    31  f =      -321.31  |proj g|=        0.1379
At iterate    32  f =      -321.31  |proj g|=      0.034923
At iterate    33  f =      -321.31  |proj g|=      0.034184
At iterate    34  f =      -321.31  |proj g|=      0.034176

iterations 34
function evaluations 43
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0341757
final function value -321.306

F = -321.306
final  value -321.305987 
converged
 
INFO  [22:29:07.608] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:29:07.662] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:29:07.668] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:29:17.280] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:29:28.724] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:29:38.643] [mlr3]  Finished benchmark 
INFO  [22:29:38.713] [bbotk] Result of batch 49: 
INFO  [22:29:38.715] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:29:38.715] [bbotk]              5.309148                 6.449847                       0.3152909 
INFO  [22:29:38.715] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:29:38.715] [bbotk]                     3629        0.577 -0.9550403         <NA>   0.9757272 
INFO  [22:29:38.715] [bbotk]                                 uhash 
INFO  [22:29:38.715] [bbotk]  5925d18e-dff8-4f03-8b99-ce48770363f9 
DEBUG [22:29:39.550] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.338777e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.338777e-05 0.001711106 
  - best initial criterion value(s) :  296.9708 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -296.97  |proj g|=       4.6867
At iterate     1  f =      -299.85  |proj g|=        5.5783
At iterate     2  f =      -303.78  |proj g|=        3.8654
At iterate     3  f =      -306.18  |proj g|=        3.8401
At iterate     4  f =      -309.03  |proj g|=        2.6881
At iterate     5  f =      -309.25  |proj g|=         2.394
At iterate     6  f =      -309.34  |proj g|=        2.5637
At iterate     7  f =      -309.35  |proj g|=        2.5374
At iterate     8  f =      -309.35  |proj g|=        2.5337
At iterate     9  f =      -309.35  |proj g|=         2.534
At iterate    10  f =      -309.35  |proj g|=        2.5346
At iterate    11  f =      -309.35  |proj g|=        2.5354
At iterate    12  f =      -309.35  |proj g|=        2.5368
At iterate    13  f =      -309.35  |proj g|=         2.539
At iterate    14  f =      -309.35  |proj g|=        2.5423
At iterate    15  f =      -309.35  |proj g|=        2.5466
At iterate    16  f =      -309.36  |proj g|=        2.5512
At iterate    17  f =      -309.36  |proj g|=        2.5578
At iterate    18  f =      -309.38  |proj g|=        2.5557
At iterate    19  f =      -309.38  |proj g|=        2.5824
At iterate    20  f =      -309.41  |proj g|=        2.5744
At iterate    21  f =      -309.54  |proj g|=        2.5543
At iterate    22  f =      -309.98  |proj g|=        2.5185
At iterate    23  f =      -311.22  |proj g|=        2.4526
At iterate    24  f =      -313.64  |proj g|=        2.3142
At iterate    25  f =       -313.9  |proj g|=        2.5256
At iterate    26  f =      -316.18  |proj g|=        2.1676
At iterate    27  f =      -317.05  |proj g|=        1.9759
At iterate    28  f =      -317.94  |proj g|=        1.9952
At iterate    29  f =      -318.26  |proj g|=        2.0947
At iterate    30  f =      -318.37  |proj g|=        2.0477
At iterate    31  f =      -318.43  |proj g|=        2.1402
At iterate    32  f =      -318.47  |proj g|=        2.0909
At iterate    33  f =      -318.47  |proj g|=        2.0886
At iterate    34  f =      -318.47  |proj g|=        2.0913
At iterate    35  f =      -318.47  |proj g|=        2.0922
At iterate    36  f =      -318.47  |proj g|=        2.0923

iterations 36
function evaluations 42
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.09235
final function value -318.471

F = -318.471
final  value -318.471117 
converged
 
INFO  [22:29:39.554] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:29:39.613] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:29:39.621] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:29:49.966] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:29:59.512] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:30:09.866] [mlr3]  Finished benchmark 
INFO  [22:30:09.937] [bbotk] Result of batch 50: 
INFO  [22:30:09.939] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:30:09.939] [bbotk]               9.55525                 2.649367                       0.2112195 
INFO  [22:30:09.939] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:30:09.939] [bbotk]                     3612        0.583 -0.9556311         <NA>   0.9755873 
INFO  [22:30:09.939] [bbotk]                                 uhash 
INFO  [22:30:09.939] [bbotk]  26da1009-99cb-41ee-8b87-6f7456c06a74 
DEBUG [22:30:10.750] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.32971e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.32971e-05 0.001705103 
  - best initial criterion value(s) :  315.9284 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -315.93  |proj g|=       1.3326
At iterate     1  f =      -316.03  |proj g|=        1.5126
At iterate     2  f =      -316.24  |proj g|=        1.3538
At iterate     3  f =      -316.54  |proj g|=       0.94076
At iterate     4  f =      -316.58  |proj g|=       0.98087
At iterate     5  f =      -316.58  |proj g|=       0.94821
At iterate     6  f =      -316.58  |proj g|=       0.94789
At iterate     7  f =      -316.58  |proj g|=       0.94792

iterations 7
function evaluations 12
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.94792
final function value -316.585

F = -316.585
final  value -316.584589 
converged
 
INFO  [22:30:10.754] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:30:10.811] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:30:10.818] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:30:22.332] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:30:36.217] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:30:48.810] [mlr3]  Finished benchmark 
INFO  [22:30:48.901] [bbotk] Result of batch 51: 
INFO  [22:30:48.903] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:30:48.903] [bbotk]                7.1771                 4.754874                       0.3146963 
INFO  [22:30:48.903] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:30:48.903] [bbotk]                     4548        0.594 -0.9643884         <NA>   0.9768521 
INFO  [22:30:48.903] [bbotk]                                 uhash 
INFO  [22:30:48.903] [bbotk]  1d75b4e0-52fb-4580-bd13-e236bf8f74ea 
DEBUG [22:30:49.885] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.323278e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.323278e-05 0.001712303 
  - best initial criterion value(s) :  292.78 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -292.78  |proj g|=       11.001
At iterate     1  f =      -305.21  |proj g|=        6.6711
At iterate     2  f =      -311.66  |proj g|=         4.467
At iterate     3  f =      -315.48  |proj g|=        2.1351
At iterate     4  f =      -316.11  |proj g|=        2.3783
At iterate     5  f =      -316.17  |proj g|=        2.2564
At iterate     6  f =      -316.18  |proj g|=        2.2207
At iterate     7  f =      -316.18  |proj g|=        2.2244
At iterate     8  f =      -316.18  |proj g|=        2.2263
At iterate     9  f =      -316.18  |proj g|=        2.2303
At iterate    10  f =      -316.18  |proj g|=        2.2354
At iterate    11  f =      -316.19  |proj g|=        2.2366
At iterate    12  f =      -316.21  |proj g|=         2.223
At iterate    13  f =      -316.25  |proj g|=        2.1701
At iterate    14  f =       -316.3  |proj g|=         2.053
At iterate    15  f =      -316.35  |proj g|=        1.9709
At iterate    16  f =      -316.41  |proj g|=        1.8144
At iterate    17  f =      -316.52  |proj g|=        1.7876
At iterate    18  f =      -317.15  |proj g|=        1.9144
At iterate    19  f =      -318.99  |proj g|=        2.2222
At iterate    20  f =      -323.04  |proj g|=        2.7741
At iterate    21  f =       -326.6  |proj g|=        2.7159
At iterate    22  f =      -328.01  |proj g|=        3.4953
At iterate    23  f =      -328.31  |proj g|=        3.5335
At iterate    24  f =      -328.47  |proj g|=        3.6119
At iterate    25  f =      -328.49  |proj g|=        3.6531
At iterate    26  f =      -328.49  |proj g|=        3.6784
At iterate    27  f =      -328.49  |proj g|=        3.6879
At iterate    28  f =      -328.49  |proj g|=        3.6893
At iterate    29  f =      -328.49  |proj g|=        3.6892

iterations 29
function evaluations 34
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 3.68923
final function value -328.488

F = -328.488
final  value -328.488271 
converged
 
INFO  [22:30:49.890] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:30:49.948] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:30:49.956] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:30:55.654] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:31:01.635] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:31:07.564] [mlr3]  Finished benchmark 
INFO  [22:31:07.633] [bbotk] Result of batch 52: 
INFO  [22:31:07.635] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:31:07.635] [bbotk]              6.522559                  2.10797                       0.2449991 
INFO  [22:31:07.635] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:31:07.635] [bbotk]                     2163        0.709 -0.9611902         <NA>   0.9735326 
INFO  [22:31:07.635] [bbotk]                                 uhash 
INFO  [22:31:07.635] [bbotk]  31286a52-708d-4ec1-b631-c5fc9559f0d8 
DEBUG [22:31:08.622] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.310944e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.310944e-05 0.001689895 
  - best initial criterion value(s) :  323.3604 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -323.36  |proj g|=       1.3561
At iterate     1  f =      -323.71  |proj g|=        1.1852
At iterate     2  f =      -323.72  |proj g|=        1.2269
At iterate     3  f =      -323.72  |proj g|=        1.2441
At iterate     4  f =      -323.72  |proj g|=        1.2492
At iterate     5  f =      -323.72  |proj g|=        1.2483
At iterate     6  f =      -323.72  |proj g|=        1.2489
At iterate     7  f =      -323.72  |proj g|=        1.2549
At iterate     8  f =      -323.73  |proj g|=        1.2623
At iterate     9  f =      -323.76  |proj g|=        1.2668
At iterate    10  f =      -323.82  |proj g|=         1.244
At iterate    11  f =      -323.82  |proj g|=        1.2482
At iterate    12  f =      -323.96  |proj g|=        1.1511
At iterate    13  f =      -324.25  |proj g|=       0.91398
At iterate    14  f =      -324.43  |proj g|=       0.78731
At iterate    15  f =      -324.71  |proj g|=       0.70533
At iterate    16  f =      -324.81  |proj g|=       0.73108
At iterate    17  f =      -324.81  |proj g|=       0.73076
At iterate    18  f =      -324.82  |proj g|=        0.5615
At iterate    19  f =      -324.82  |proj g|=        0.5512
At iterate    20  f =      -324.82  |proj g|=       0.55038
At iterate    21  f =      -324.82  |proj g|=       0.55037

iterations 21
function evaluations 34
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.550374
final function value -324.824

F = -324.824
final  value -324.824160 
converged
 
INFO  [22:31:08.626] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:31:08.686] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:31:08.693] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:31:13.383] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:31:18.014] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:31:22.857] [mlr3]  Finished benchmark 
INFO  [22:31:22.926] [bbotk] Result of batch 53: 
INFO  [22:31:22.928] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:31:22.928] [bbotk]              2.899477                 5.374839                      0.05315208 
INFO  [22:31:22.928] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:31:22.928] [bbotk]                     1675        0.714 -0.9655992         <NA>   0.9446114 
INFO  [22:31:22.928] [bbotk]                                 uhash 
INFO  [22:31:22.928] [bbotk]  5eeca93e-4f8b-4b1a-9091-2bb8e6a767ed 
DEBUG [22:31:24.096] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.36017e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.36017e-05 0.001744043 
  - best initial criterion value(s) :  333.1853 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -333.19  |proj g|=        2.889
At iterate     1  f =      -337.01  |proj g|=       0.98252
At iterate     2  f =      -339.79  |proj g|=        1.0076
At iterate     3  f =      -341.86  |proj g|=        1.0173
At iterate     4  f =      -342.33  |proj g|=       0.94873
At iterate     5  f =      -343.74  |proj g|=       0.96086
At iterate     6  f =      -345.26  |proj g|=        1.0169
At iterate     7  f =      -345.69  |proj g|=        1.0375
At iterate     8  f =      -345.84  |proj g|=        1.0596
At iterate     9  f =      -345.86  |proj g|=        1.0756
At iterate    10  f =      -345.87  |proj g|=        1.0845
At iterate    11  f =      -345.87  |proj g|=        1.0867
At iterate    12  f =      -345.87  |proj g|=         1.087
At iterate    13  f =      -345.87  |proj g|=        1.0871
At iterate    14  f =      -345.87  |proj g|=        1.0873
At iterate    15  f =      -345.87  |proj g|=        1.0875
At iterate    16  f =      -345.87  |proj g|=        1.0877
At iterate    17  f =      -345.87  |proj g|=        1.0883
At iterate    18  f =      -345.87  |proj g|=        1.0885
At iterate    19  f =      -345.87  |proj g|=        1.0887
At iterate    20  f =      -345.88  |proj g|=        1.0881
At iterate    21  f =       -345.9  |proj g|=        1.0815
At iterate    22  f =      -345.96  |proj g|=         1.056
At iterate    23  f =      -345.96  |proj g|=        1.0543
At iterate    24  f =      -345.99  |proj g|=        1.0331
At iterate    25  f =      -345.99  |proj g|=        1.0283
At iterate    26  f =      -345.99  |proj g|=        1.0295
At iterate    27  f =      -345.99  |proj g|=        1.0298
At iterate    28  f =      -345.99  |proj g|=          1.03
At iterate    29  f =      -345.99  |proj g|=        1.0312
At iterate    30  f =      -345.99  |proj g|=        1.0316
At iterate    31  f =      -345.99  |proj g|=        1.0322
At iterate    32  f =      -345.99  |proj g|=        1.0331
At iterate    33  f =         -346  |proj g|=        1.0344
At iterate    34  f =         -346  |proj g|=         1.036
At iterate    35  f =      -346.01  |proj g|=        1.0386
At iterate    36  f =      -346.04  |proj g|=        1.0238
At iterate    37  f =       -346.1  |proj g|=         1.029
At iterate    38  f =      -346.13  |proj g|=       0.98188
At iterate    39  f =      -346.27  |proj g|=       0.94147
At iterate    40  f =      -346.53  |proj g|=       0.52244
At iterate    41  f =       -346.7  |proj g|=       0.48395
At iterate    42  f =      -346.72  |proj g|=       0.48866
At iterate    43  f =      -346.72  |proj g|=       0.48744
At iterate    44  f =      -346.72  |proj g|=       0.48701
At iterate    45  f =      -346.72  |proj g|=       0.48672
At iterate    46  f =      -346.72  |proj g|=       0.48655
At iterate    47  f =      -346.72  |proj g|=       0.48647
At iterate    48  f =      -346.72  |proj g|=        0.4863
At iterate    49  f =      -346.72  |proj g|=       0.48594
At iterate    50  f =      -346.72  |proj g|=       0.48522
At iterate    51  f =      -346.72  |proj g|=        0.4838
At iterate    52  f =      -346.73  |proj g|=       0.48087
At iterate    53  f =      -346.74  |proj g|=       0.47617
At iterate    54  f =      -346.74  |proj g|=       0.47549
At iterate    55  f =      -346.76  |proj g|=       0.46761
At iterate    56  f =      -347.19  |proj g|=       0.41223
At iterate    57  f =      -347.28  |proj g|=        0.5967
At iterate    58  f =      -347.29  |proj g|=       0.06144
At iterate    59  f =      -347.29  |proj g|=      0.094952
At iterate    60  f =      -347.29  |proj g|=      0.040634
At iterate    61  f =      -347.29  |proj g|=      0.001338
At iterate    62  f =      -347.29  |proj g|=      0.001338

iterations 62
function evaluations 73
segments explored during Cauchy searches 64
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00133799
final function value -347.295

F = -347.295
final  value -347.294642 
converged
 
INFO  [22:31:24.100] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:31:24.156] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:31:24.163] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:31:32.310] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:31:40.742] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:31:49.211] [mlr3]  Finished benchmark 
INFO  [22:31:49.281] [bbotk] Result of batch 54: 
INFO  [22:31:49.283] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:31:49.283] [bbotk]              4.779159                 4.442299                       0.1054285 
INFO  [22:31:49.283] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [22:31:49.283] [bbotk]                     2931        0.759 -0.954316         <NA>   0.9695407 
INFO  [22:31:49.283] [bbotk]                                 uhash 
INFO  [22:31:49.283] [bbotk]  e9c3b9de-5311-4edf-a45e-aad19cf56b06 
DEBUG [22:31:50.350] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.344375e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.344375e-05 0.001727142 
  - best initial criterion value(s) :  331.6516 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -331.65  |proj g|=      0.99715
At iterate     1  f =      -332.52  |proj g|=         2.579
At iterate     2  f =      -336.66  |proj g|=        2.1785
At iterate     3  f =      -337.74  |proj g|=        1.6708
At iterate     4  f =      -337.88  |proj g|=        1.7376
At iterate     5  f =      -338.01  |proj g|=        1.9381
At iterate     6  f =      -338.02  |proj g|=        1.9527
At iterate     7  f =      -338.02  |proj g|=        1.9628
At iterate     8  f =      -338.02  |proj g|=        1.9635
At iterate     9  f =      -338.02  |proj g|=        1.9636

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.96362
final function value -338.017

F = -338.017
final  value -338.017398 
converged
 
INFO  [22:31:50.354] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:31:50.410] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:31:50.418] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:31:59.747] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:32:12.291] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:32:21.334] [mlr3]  Finished benchmark 
INFO  [22:32:21.403] [bbotk] Result of batch 55: 
INFO  [22:32:21.405] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:32:21.405] [bbotk]               9.45567                  9.61629                       0.3958253 
INFO  [22:32:21.405] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [22:32:21.405] [bbotk]                     3482        0.782 -0.963811         <NA>   0.9770128 
INFO  [22:32:21.405] [bbotk]                                 uhash 
INFO  [22:32:21.405] [bbotk]  82457e00-5bff-4b67-a8cc-29272a2ed6cc 
DEBUG [22:32:22.444] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.338589e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.338589e-05 0.00172569 
  - best initial criterion value(s) :  341.7956 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -341.8  |proj g|=       1.2543
At iterate     1  f =      -343.05  |proj g|=        3.6568
At iterate     2  f =      -347.59  |proj g|=        2.4139
At iterate     3  f =       -347.8  |proj g|=        2.0353
At iterate     4  f =      -347.95  |proj g|=        2.0348
At iterate     5  f =      -347.95  |proj g|=        2.0524
At iterate     6  f =      -347.95  |proj g|=        2.0483
At iterate     7  f =      -347.95  |proj g|=        2.0483

iterations 7
function evaluations 11
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.04834
final function value -347.948

F = -347.948
final  value -347.948004 
converged
 
INFO  [22:32:22.449] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:32:22.505] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:32:22.512] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:32:25.431] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:32:29.886] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:32:32.494] [mlr3]  Finished benchmark 
INFO  [22:32:32.564] [bbotk] Result of batch 56: 
INFO  [22:32:32.566] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:32:32.566] [bbotk]              4.893937                 2.602725                       0.3224199 
INFO  [22:32:32.566] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:32:32.566] [bbotk]                      960        0.809 -0.9606332         <NA>   0.9697214 
INFO  [22:32:32.566] [bbotk]                                 uhash 
INFO  [22:32:32.566] [bbotk]  6e9adc8f-2525-478e-971e-a6e3c1a0bd36 
DEBUG [22:32:33.456] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.323434e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.323434e-05 0.001690069 
  - best initial criterion value(s) :  334.1906 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -334.19  |proj g|=        10.03
At iterate     1  f =      -348.42  |proj g|=       0.79916
At iterate     2  f =      -350.08  |proj g|=        1.0006
At iterate     3  f =      -350.78  |proj g|=        1.3122
At iterate     4  f =       -350.8  |proj g|=        1.3923
At iterate     5  f =       -350.8  |proj g|=        1.3729
At iterate     6  f =       -350.8  |proj g|=        1.3588
At iterate     7  f =       -350.8  |proj g|=        1.3573
At iterate     8  f =       -350.8  |proj g|=        1.3522
At iterate     9  f =      -350.81  |proj g|=        1.3338
At iterate    10  f =      -350.81  |proj g|=        1.3096
At iterate    11  f =      -350.81  |proj g|=        1.2614
At iterate    12  f =      -350.82  |proj g|=        1.2103
At iterate    13  f =      -350.84  |proj g|=        1.1288
At iterate    14  f =      -350.89  |proj g|=        1.0123
At iterate    15  f =      -351.05  |proj g|=       0.93522
At iterate    16  f =      -351.43  |proj g|=       0.91866
At iterate    17  f =      -352.29  |proj g|=       0.90432
At iterate    18  f =      -353.47  |proj g|=       0.90772
At iterate    19  f =       -353.8  |proj g|=       0.98947
At iterate    20  f =      -354.28  |proj g|=       0.96575
At iterate    21  f =       -355.3  |proj g|=       0.98585
At iterate    22  f =      -355.45  |proj g|=       0.98378
At iterate    23  f =      -355.49  |proj g|=        1.0085
At iterate    24  f =      -355.51  |proj g|=        1.0087
At iterate    25  f =      -355.51  |proj g|=        1.0091
At iterate    26  f =      -355.52  |proj g|=        1.0143
At iterate    27  f =      -355.52  |proj g|=        1.0149
At iterate    28  f =      -355.52  |proj g|=         1.015

iterations 28
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.01502
final function value -355.517

F = -355.517
final  value -355.517403 
converged
 
INFO  [22:32:33.460] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:32:33.516] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:32:33.523] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:32:40.710] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:32:48.104] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:32:54.563] [mlr3]  Finished benchmark 
INFO  [22:32:54.633] [bbotk] Result of batch 57: 
INFO  [22:32:54.635] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:32:54.635] [bbotk]              3.666036                 6.828636                       0.2096104 
INFO  [22:32:54.635] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:32:54.635] [bbotk]                     2572        0.622 -0.9593313         <NA>   0.9703302 
INFO  [22:32:54.635] [bbotk]                                 uhash 
INFO  [22:32:54.635] [bbotk]  2984cf02-014d-46a0-8239-1e4e61e3440f 
DEBUG [22:32:55.476] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.308918e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.308918e-05 0.001674779 
  - best initial criterion value(s) :  341.1488 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -341.15  |proj g|=       1.4546
At iterate     1  f =       -341.9  |proj g|=        2.8529
At iterate     2  f =       -343.6  |proj g|=        2.6243
At iterate     3  f =      -344.76  |proj g|=        2.2386
At iterate     4  f =      -345.16  |proj g|=        2.1436
At iterate     5  f =      -347.17  |proj g|=        1.8408
At iterate     6  f =      -348.46  |proj g|=        2.2233
At iterate     7  f =      -348.46  |proj g|=        2.2127
At iterate     8  f =      -348.46  |proj g|=        2.2129
At iterate     9  f =      -348.46  |proj g|=        2.2124
At iterate    10  f =      -348.46  |proj g|=        2.2123

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.21228
final function value -348.462

F = -348.462
final  value -348.462159 
converged
 
INFO  [22:32:55.502] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:32:55.548] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:32:55.555] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:33:06.566] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:33:16.971] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:33:28.519] [mlr3]  Finished benchmark 
INFO  [22:33:28.589] [bbotk] Result of batch 58: 
INFO  [22:33:28.591] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:33:28.591] [bbotk]              2.840182                 9.842803                       0.3032247 
INFO  [22:33:28.591] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:33:28.591] [bbotk]                     3753         0.62 -0.9634422         <NA>   0.9691035 
INFO  [22:33:28.591] [bbotk]                                 uhash 
INFO  [22:33:28.591] [bbotk]  3a48cf5f-4ade-45b9-acee-088d4aa462e7 
DEBUG [22:33:29.540] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.294211e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.294211e-05 0.001660794 
  - best initial criterion value(s) :  335.86 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -335.86  |proj g|=       5.7598
At iterate     1  f =      -350.48  |proj g|=        1.7974
At iterate     2  f =      -354.89  |proj g|=        3.1621
At iterate     3  f =      -355.41  |proj g|=        3.6743
At iterate     4  f =      -356.02  |proj g|=        4.0574
At iterate     5  f =      -356.63  |proj g|=        4.1864
At iterate     6  f =      -356.63  |proj g|=        4.1717
At iterate     7  f =      -356.67  |proj g|=        4.0908
At iterate     8  f =      -356.99  |proj g|=        3.8721
At iterate     9  f =         -359  |proj g|=        2.7919
At iterate    10  f =      -362.45  |proj g|=        1.6901
At iterate    11  f =         -369  |proj g|=       0.92187
At iterate    12  f =      -371.73  |proj g|=        1.3218
At iterate    13  f =      -372.65  |proj g|=         1.265
At iterate    14  f =      -372.82  |proj g|=        1.1972
At iterate    15  f =      -373.08  |proj g|=         1.299
At iterate    16  f =       -373.1  |proj g|=        1.3273
At iterate    17  f =       -373.1  |proj g|=        1.3335
At iterate    18  f =       -373.1  |proj g|=        1.3339
At iterate    19  f =       -373.1  |proj g|=        1.3336
At iterate    20  f =       -373.1  |proj g|=        1.3332
At iterate    21  f =       -373.1  |proj g|=         1.332
At iterate    22  f =       -373.1  |proj g|=        1.3304
At iterate    23  f =       -373.1  |proj g|=        1.3276
At iterate    24  f =       -373.1  |proj g|=         1.323
At iterate    25  f =       -373.1  |proj g|=        1.3159
At iterate    26  f =      -373.11  |proj g|=        1.3065
At iterate    27  f =      -373.12  |proj g|=        1.3006
At iterate    28  f =      -373.13  |proj g|=        1.3206
At iterate    29  f =      -373.13  |proj g|=        1.3151
At iterate    30  f =      -373.13  |proj g|=         1.315
At iterate    31  f =      -373.13  |proj g|=        1.3149
At iterate    32  f =      -373.13  |proj g|=        1.3148
At iterate    33  f =      -373.13  |proj g|=        1.3147
At iterate    34  f =      -373.13  |proj g|=        1.3124
At iterate    35  f =      -373.13  |proj g|=        1.3136
At iterate    36  f =      -373.13  |proj g|=        1.3147
At iterate    37  f =      -373.13  |proj g|=        1.3189
At iterate    38  f =      -373.14  |proj g|=        1.3237
At iterate    39  f =      -373.15  |proj g|=        1.3307
At iterate    40  f =      -373.19  |proj g|=        1.3364
At iterate    41  f =      -373.27  |proj g|=        1.2667
At iterate    42  f =      -373.45  |proj g|=       0.94016
At iterate    43  f =      -373.66  |proj g|=       0.64608
At iterate    44  f =      -374.44  |proj g|=       0.45632
At iterate    45  f =      -374.92  |proj g|=       0.50241
At iterate    46  f =      -374.96  |proj g|=      0.040537
At iterate    47  f =      -374.96  |proj g|=      0.016762
At iterate    48  f =      -374.96  |proj g|=       0.01434
At iterate    49  f =      -374.96  |proj g|=      0.014374

iterations 49
function evaluations 58
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0143738
final function value -374.963

F = -374.963
final  value -374.963083 
converged
 
INFO  [22:33:29.544] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:33:29.601] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:33:29.608] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:33:42.763] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:33:55.677] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:34:07.352] [mlr3]  Finished benchmark 
INFO  [22:34:07.420] [bbotk] Result of batch 59: 
INFO  [22:34:07.422] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:34:07.422] [bbotk]              2.485621                  9.73579                      0.07242238 
INFO  [22:34:07.422] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:34:07.422] [bbotk]                     4711        0.612 -0.9491631         <NA>    0.956313 
INFO  [22:34:07.422] [bbotk]                                 uhash 
INFO  [22:34:07.422] [bbotk]  c56d3111-daeb-4e90-9784-6448edd3b5be 
DEBUG [22:34:08.257] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.294579e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.8454 15.61756 0.9778625 9446 
  - variance bounds :  1.294579e-05 0.001648633 
  - best initial criterion value(s) :  339.0567 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -339.06  |proj g|=       5.4599
At iterate     1  f =      -341.81  |proj g|=        4.5022
At iterate     2  f =      -346.04  |proj g|=        3.9771
At iterate     3  f =       -354.9  |proj g|=        2.8177
At iterate     4  f =       -357.7  |proj g|=        1.7446
At iterate     5  f =      -365.63  |proj g|=        1.8091
At iterate     6  f =      -366.85  |proj g|=        2.3164
At iterate     7  f =      -366.95  |proj g|=        2.3268
At iterate     8  f =      -366.95  |proj g|=        2.3001
At iterate     9  f =      -366.95  |proj g|=        2.3027
At iterate    10  f =      -366.95  |proj g|=        2.3027

iterations 10
function evaluations 16
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.30271
final function value -366.952

F = -366.952
final  value -366.952159 
converged
 
INFO  [22:34:08.261] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:34:08.318] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:34:08.325] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:34:11.617] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:34:14.880] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:34:18.143] [mlr3]  Finished benchmark 
INFO  [22:34:18.227] [bbotk] Result of batch 60: 
INFO  [22:34:18.230] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:34:18.230] [bbotk]              2.000079                 9.153194                       0.3778514 
INFO  [22:34:18.230] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:34:18.230] [bbotk]                     1614        0.605 -0.9556209         <NA>   0.9555864 
INFO  [22:34:18.230] [bbotk]                                 uhash 
INFO  [22:34:18.230] [bbotk]  a596236a-d7e5-4615-a145-b9dd8724e538 
DEBUG [22:34:19.178] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.296501e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.61756 0.9778625 9446 
  - variance bounds :  1.296501e-05 0.001647745 
  - best initial criterion value(s) :  354.0837 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -354.08  |proj g|=       3.0874
At iterate     1  f =      -358.99  |proj g|=        2.4184
At iterate     2  f =       -359.1  |proj g|=        2.6261
At iterate     3  f =      -359.12  |proj g|=        2.6337
At iterate     4  f =      -359.13  |proj g|=        2.6329
At iterate     5  f =      -359.13  |proj g|=        2.6327
At iterate     6  f =      -359.13  |proj g|=        2.6327
At iterate     7  f =      -359.13  |proj g|=        2.6328
At iterate     8  f =      -359.13  |proj g|=        2.6305
At iterate     9  f =      -359.13  |proj g|=        2.6314
At iterate    10  f =      -359.13  |proj g|=        2.6319
At iterate    11  f =      -359.13  |proj g|=        2.6309
At iterate    12  f =      -359.14  |proj g|=        2.6316
At iterate    13  f =      -359.15  |proj g|=        2.6321
At iterate    14  f =      -359.15  |proj g|=        2.6278
At iterate    15  f =      -359.18  |proj g|=        2.6196
At iterate    16  f =       -361.3  |proj g|=        1.8466
At iterate    17  f =      -365.52  |proj g|=        1.2567
At iterate    18  f =      -366.53  |proj g|=        1.0816
At iterate    19  f =      -366.88  |proj g|=        1.0048
At iterate    20  f =      -366.91  |proj g|=        1.0583
At iterate    21  f =      -366.98  |proj g|=        1.0045
At iterate    22  f =      -366.99  |proj g|=       0.98118
At iterate    23  f =      -366.99  |proj g|=       0.97647
At iterate    24  f =      -366.99  |proj g|=       0.97765
At iterate    25  f =      -366.99  |proj g|=       0.97847
At iterate    26  f =      -366.99  |proj g|=       0.97853

iterations 26
function evaluations 33
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.97853
final function value -366.994

F = -366.994
final  value -366.993910 
converged
 
INFO  [22:34:19.182] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:34:19.246] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:34:19.255] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:34:27.100] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:34:34.982] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:34:43.211] [mlr3]  Finished benchmark 
INFO  [22:34:43.282] [bbotk] Result of batch 61: 
INFO  [22:34:43.284] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:34:43.284] [bbotk]              8.450557                 2.384316                      0.02314944 
INFO  [22:34:43.284] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:34:43.284] [bbotk]                     4159        0.622 -0.9598091         <NA>   0.9614364 
INFO  [22:34:43.284] [bbotk]                                 uhash 
INFO  [22:34:43.284] [bbotk]  10795278-8a6b-4b15-b099-e58ef45958fa 
DEBUG [22:34:44.155] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.286429e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.61756 0.9778625 9446 
  - variance bounds :  1.286429e-05 0.001630748 
  - best initial criterion value(s) :  367.2225 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -367.22  |proj g|=       2.3679
At iterate     1  f =      -374.05  |proj g|=        1.9693
At iterate     2  f =      -376.51  |proj g|=        1.5927
At iterate     3  f =      -378.59  |proj g|=        1.3684
At iterate     4  f =      -378.61  |proj g|=        1.3302
At iterate     5  f =      -378.62  |proj g|=        1.3419
At iterate     6  f =      -378.63  |proj g|=        1.3473
At iterate     7  f =      -378.65  |proj g|=        1.3601
At iterate     8  f =      -378.68  |proj g|=        1.3652
At iterate     9  f =       -378.7  |proj g|=        1.3551
At iterate    10  f =      -378.71  |proj g|=        1.3488
At iterate    11  f =      -378.71  |proj g|=        1.3472
At iterate    12  f =      -378.71  |proj g|=        1.3469
At iterate    13  f =      -378.71  |proj g|=         1.347

iterations 13
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.34695
final function value -378.706

F = -378.706
final  value -378.705569 
converged
 
INFO  [22:34:44.159] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:34:44.244] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:34:44.252] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:34:46.286] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:34:48.464] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:34:50.618] [mlr3]  Finished benchmark 
INFO  [22:34:50.781] [bbotk] Result of batch 62: 
INFO  [22:34:50.783] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:34:50.783] [bbotk]              8.471373                 9.915361                       0.3115008 
INFO  [22:34:50.783] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:34:50.783] [bbotk]                      981        0.632 -0.9592959         <NA>   0.9709451 
INFO  [22:34:50.783] [bbotk]                                 uhash 
INFO  [22:34:50.783] [bbotk]  13b3abdd-36d1-47c2-85eb-94debdf9682e 
DEBUG [22:34:52.153] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.273674e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.273674e-05 0.001598831 
  - best initial criterion value(s) :  339.755 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -339.75  |proj g|=       7.9799
At iterate     1  f =      -373.94  |proj g|=        1.6787
At iterate     2  f =      -376.11  |proj g|=        1.6681
At iterate     3  f =      -378.86  |proj g|=        2.3368
At iterate     4  f =      -380.12  |proj g|=        1.5915
At iterate     5  f =      -380.33  |proj g|=        1.5745
At iterate     6  f =      -380.67  |proj g|=        1.5813
At iterate     7  f =      -381.31  |proj g|=        1.6388
At iterate     8  f =       -382.3  |proj g|=        1.7559
At iterate     9  f =      -382.49  |proj g|=        1.7395
At iterate    10  f =      -382.49  |proj g|=        1.7325
At iterate    11  f =      -382.49  |proj g|=        1.7282
At iterate    12  f =       -382.5  |proj g|=        1.7323
At iterate    13  f =       -382.5  |proj g|=        1.7302
At iterate    14  f =       -382.5  |proj g|=         1.728
At iterate    15  f =       -382.5  |proj g|=        1.7299
At iterate    16  f =      -383.84  |proj g|=        1.6912
At iterate    17  f =      -385.06  |proj g|=        1.6025
At iterate    18  f =       -385.3  |proj g|=        1.5606
At iterate    19  f =      -385.34  |proj g|=        1.5442
At iterate    20  f =      -385.34  |proj g|=        1.5434
At iterate    21  f =      -385.34  |proj g|=        1.5466
At iterate    22  f =      -385.34  |proj g|=        1.5463
At iterate    23  f =      -385.34  |proj g|=        1.5463
At iterate    24  f =      -385.34  |proj g|=        1.5463
At iterate    25  f =      -385.34  |proj g|=        1.5462
At iterate    26  f =      -385.34  |proj g|=        1.5461
At iterate    27  f =      -385.34  |proj g|=        1.5454
At iterate    28  f =      -385.34  |proj g|=        1.5496
At iterate    29  f =      -385.34  |proj g|=        1.5471
At iterate    30  f =      -385.35  |proj g|=        1.5403
At iterate    31  f =      -385.36  |proj g|=        1.5302
At iterate    32  f =      -385.41  |proj g|=        1.5051
At iterate    33  f =      -385.63  |proj g|=        1.4397
At iterate    34  f =      -385.75  |proj g|=        1.3151
At iterate    35  f =      -386.36  |proj g|=        1.2082
At iterate    36  f =      -387.56  |proj g|=       0.60626
At iterate    37  f =      -388.17  |proj g|=       0.56709
At iterate    38  f =      -388.92  |proj g|=       0.56585
At iterate    39  f =      -389.11  |proj g|=       0.45701
At iterate    40  f =      -389.12  |proj g|=       0.50325
At iterate    41  f =      -389.13  |proj g|=       0.45343
At iterate    42  f =      -389.13  |proj g|=       0.45722
At iterate    43  f =      -389.13  |proj g|=        0.4574

iterations 43
function evaluations 55
segments explored during Cauchy searches 45
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.457395
final function value -389.127

F = -389.127
final  value -389.127110 
converged
 
INFO  [22:34:52.158] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:34:52.215] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:34:52.222] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:34:57.944] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:35:03.644] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:35:09.345] [mlr3]  Finished benchmark 
INFO  [22:35:09.416] [bbotk] Result of batch 63: 
INFO  [22:35:09.417] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:35:09.417] [bbotk]              6.702378                 4.709435                       0.2795442 
INFO  [22:35:09.417] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:35:09.417] [bbotk]                     2953        0.982 -0.9542386         <NA>   0.9748946 
INFO  [22:35:09.417] [bbotk]                                 uhash 
INFO  [22:35:09.417] [bbotk]  0547f1c9-f2ed-4f54-b377-2795ee427919 
DEBUG [22:35:10.266] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.265634e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.265634e-05 0.001592422 
  - best initial criterion value(s) :  377.3998 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -377.4  |proj g|=       2.0346
At iterate     1  f =      -391.67  |proj g|=        1.7535
At iterate     2  f =      -392.08  |proj g|=        1.7302
At iterate     3  f =      -392.91  |proj g|=        1.2447
At iterate     4  f =         -393  |proj g|=        1.1881
At iterate     5  f =         -393  |proj g|=        1.1921
At iterate     6  f =         -393  |proj g|=        1.1897
At iterate     7  f =         -393  |proj g|=        1.1911
At iterate     8  f =         -393  |proj g|=        1.1908
At iterate     9  f =         -393  |proj g|=        1.1908

iterations 9
function evaluations 15
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.1908
final function value -393

F = -393
final  value -392.999935 
converged
 
INFO  [22:35:10.270] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:35:10.330] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:35:10.338] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:35:16.581] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:35:22.497] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:35:28.996] [mlr3]  Finished benchmark 
INFO  [22:35:29.066] [bbotk] Result of batch 64: 
INFO  [22:35:29.068] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:35:29.068] [bbotk]              9.723509                 8.891292                       0.1623257 
INFO  [22:35:29.068] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:35:29.068] [bbotk]                     3097        0.612 -0.9581034         <NA>   0.9738208 
INFO  [22:35:29.068] [bbotk]                                 uhash 
INFO  [22:35:29.068] [bbotk]  638614ae-d18c-4bac-ac09-d32a99abf155 
DEBUG [22:35:30.065] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.256139e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.256139e-05 0.001583465 
  - best initial criterion value(s) :  360.9372 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -360.94  |proj g|=       7.7667
At iterate     1  f =      -361.29  |proj g|=        6.7527
At iterate     2  f =      -372.13  |proj g|=        5.9513
At iterate     3  f =      -375.11  |proj g|=        4.0288
At iterate     4  f =      -380.83  |proj g|=        1.3093
At iterate     5  f =      -380.89  |proj g|=       0.94924
At iterate     6  f =       -380.9  |proj g|=        0.9973
At iterate     7  f =       -380.9  |proj g|=       0.98688
At iterate     8  f =       -380.9  |proj g|=       0.98613

iterations 8
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.986132
final function value -380.905

F = -380.905
final  value -380.904727 
converged
 
INFO  [22:35:30.069] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:35:30.140] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:35:30.147] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:35:37.573] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:35:46.231] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:35:55.806] [mlr3]  Finished benchmark 
INFO  [22:35:55.887] [bbotk] Result of batch 65: 
INFO  [22:35:55.889] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:35:55.889] [bbotk]              4.507128                  4.15478                       0.2273431 
INFO  [22:35:55.889] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:35:55.889] [bbotk]                     3163        0.737 -0.9644319         <NA>   0.9736454 
INFO  [22:35:55.889] [bbotk]                                 uhash 
INFO  [22:35:55.889] [bbotk]  e0801df1-01b2-43a3-b4d7-01bcf5d85b39 
DEBUG [22:35:56.753] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.246542e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.246542e-05 0.001580719 
  - best initial criterion value(s) :  390.6565 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -390.66  |proj g|=       1.4734
At iterate     1  f =      -391.53  |proj g|=        1.3108
At iterate     2  f =       -392.5  |proj g|=        1.3663
At iterate     3  f =      -392.68  |proj g|=         1.365
At iterate     4  f =      -392.71  |proj g|=        1.3672
At iterate     5  f =      -392.71  |proj g|=        1.3696
At iterate     6  f =      -392.71  |proj g|=        1.3707
At iterate     7  f =      -392.71  |proj g|=        1.3711
At iterate     8  f =      -392.71  |proj g|=        1.3712

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.37118
final function value -392.708

F = -392.708
final  value -392.707967 
converged
 
INFO  [22:35:56.757] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:35:56.813] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:35:56.820] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:36:07.517] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:36:17.184] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:36:26.513] [mlr3]  Finished benchmark 
INFO  [22:36:26.583] [bbotk] Result of batch 66: 
INFO  [22:36:26.585] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:36:26.585] [bbotk]              7.559236                 4.054129                       0.1111206 
INFO  [22:36:26.585] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:36:26.585] [bbotk]                     3591        0.638 -0.9610147         <NA>   0.9722201 
INFO  [22:36:26.585] [bbotk]                                 uhash 
INFO  [22:36:26.585] [bbotk]  b4c1861b-aeed-4cc5-8935-e6027c7f46cb 
DEBUG [22:36:27.547] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.235565e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.235565e-05 0.001572725 
  - best initial criterion value(s) :  379.3325 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -379.33  |proj g|=       2.1692
At iterate     1  f =      -384.65  |proj g|=        1.6694
At iterate     2  f =      -389.37  |proj g|=        1.3076
At iterate     3  f =      -390.08  |proj g|=           1.1
At iterate     4  f =       -390.4  |proj g|=        1.0724
At iterate     5  f =      -390.65  |proj g|=        1.1475
At iterate     6  f =      -390.71  |proj g|=        1.1239
At iterate     7  f =      -390.71  |proj g|=        1.1249
At iterate     8  f =      -390.71  |proj g|=        1.1263
At iterate     9  f =      -390.71  |proj g|=         1.126
At iterate    10  f =      -390.71  |proj g|=        1.1258
At iterate    11  f =      -390.71  |proj g|=        1.1256
At iterate    12  f =      -390.71  |proj g|=        1.1249
At iterate    13  f =      -390.71  |proj g|=         1.124
At iterate    14  f =      -390.71  |proj g|=        1.1224
At iterate    15  f =      -390.71  |proj g|=        1.1202
At iterate    16  f =      -390.71  |proj g|=        1.1171
At iterate    17  f =      -390.71  |proj g|=         1.114
At iterate    18  f =      -390.72  |proj g|=        1.1079
At iterate    19  f =      -390.73  |proj g|=        1.1071
At iterate    20  f =      -390.74  |proj g|=        1.0831
At iterate    21  f =      -390.77  |proj g|=        1.0841
At iterate    22  f =      -390.93  |proj g|=        1.0803
At iterate    23  f =      -391.25  |proj g|=        1.0657
At iterate    24  f =      -391.93  |proj g|=        1.0265
At iterate    25  f =      -392.87  |proj g|=       0.96637
At iterate    26  f =      -394.27  |proj g|=       0.98867
At iterate    27  f =      -394.84  |proj g|=        1.2096
At iterate    28  f =      -395.16  |proj g|=       0.80331
At iterate    29  f =      -395.23  |proj g|=       0.69105
At iterate    30  f =      -395.25  |proj g|=       0.54213
At iterate    31  f =      -395.25  |proj g|=       0.52119
At iterate    32  f =      -395.25  |proj g|=       0.52423
At iterate    33  f =      -395.25  |proj g|=       0.52418

iterations 33
function evaluations 41
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.524176
final function value -395.247

F = -395.247
final  value -395.246513 
converged
 
INFO  [22:36:27.551] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:36:27.608] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:36:27.615] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:36:40.018] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:36:52.069] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:37:04.097] [mlr3]  Finished benchmark 
INFO  [22:37:04.168] [bbotk] Result of batch 67: 
INFO  [22:37:04.170] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:37:04.170] [bbotk]              9.710642                 7.395955                       0.2596031 
INFO  [22:37:04.170] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:37:04.170] [bbotk]                     4316        0.651 -0.9621657         <NA>   0.9765056 
INFO  [22:37:04.170] [bbotk]                                 uhash 
INFO  [22:37:04.170] [bbotk]  cb539018-1dee-47d0-ab51-0d2a999940bc 
DEBUG [22:37:05.114] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.230469e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.230469e-05 0.00157527 
  - best initial criterion value(s) :  375.4101 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -375.41  |proj g|=       6.4099
At iterate     1  f =      -384.17  |proj g|=        3.9372
At iterate     2  f =      -384.28  |proj g|=        3.8703
At iterate     3  f =      -384.36  |proj g|=        3.6055
At iterate     4  f =      -384.36  |proj g|=        3.6229
At iterate     5  f =      -384.36  |proj g|=        3.5797
At iterate     6  f =      -384.36  |proj g|=        3.5749
At iterate     7  f =      -384.39  |proj g|=        3.5269
At iterate     8  f =       -384.6  |proj g|=         3.241
At iterate     9  f =      -385.09  |proj g|=        2.7973
At iterate    10  f =      -385.18  |proj g|=        2.5175
At iterate    11  f =      -386.34  |proj g|=        1.9001
At iterate    12  f =      -388.41  |proj g|=        1.1209
At iterate    13  f =      -391.07  |proj g|=        1.1598
At iterate    14  f =      -391.96  |proj g|=        1.1622
At iterate    15  f =      -392.11  |proj g|=        1.1152
At iterate    16  f =      -392.15  |proj g|=        1.0802
At iterate    17  f =      -392.16  |proj g|=        1.0953
At iterate    18  f =      -392.16  |proj g|=         1.103
At iterate    19  f =      -392.17  |proj g|=        1.1095
At iterate    20  f =      -392.17  |proj g|=        1.1088
At iterate    21  f =      -392.17  |proj g|=        1.1089
At iterate    22  f =      -392.17  |proj g|=        1.1089
At iterate    23  f =      -392.17  |proj g|=        1.1087

iterations 23
function evaluations 30
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.10866
final function value -392.165

F = -392.165
final  value -392.165265 
converged
 
INFO  [22:37:05.118] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:37:05.175] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:37:05.183] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:37:08.438] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:37:11.777] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:37:14.870] [mlr3]  Finished benchmark 
INFO  [22:37:14.937] [bbotk] Result of batch 68: 
INFO  [22:37:14.939] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:37:14.939] [bbotk]              7.635892                 9.160866                       0.4120057 
INFO  [22:37:14.939] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:37:14.939] [bbotk]                     1121        0.661 -0.9632097         <NA>    0.972918 
INFO  [22:37:14.939] [bbotk]                                 uhash 
INFO  [22:37:14.939] [bbotk]  386f0726-041b-41d3-a6b9-357629ffee1e 
DEBUG [22:37:16.104] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.220415e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.220415e-05 0.001547201 
  - best initial criterion value(s) :  382.8498 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -382.85  |proj g|=       7.6492
At iterate     1  f =      -384.77  |proj g|=          6.99
At iterate     2  f =      -387.12  |proj g|=        6.5254
At iterate     3  f =      -391.45  |proj g|=        5.0756
At iterate     4  f =      -394.32  |proj g|=         3.961
At iterate     5  f =      -394.97  |proj g|=        3.3547
At iterate     6  f =      -395.68  |proj g|=         3.487
At iterate     7  f =       -395.7  |proj g|=        3.4146
At iterate     8  f =       -395.7  |proj g|=        3.4131
At iterate     9  f =       -395.7  |proj g|=        3.4134
At iterate    10  f =       -395.7  |proj g|=        3.4135
At iterate    11  f =       -395.7  |proj g|=        3.4138
At iterate    12  f =       -395.7  |proj g|=        3.4142
At iterate    13  f =       -395.7  |proj g|=        3.4148
At iterate    14  f =       -395.7  |proj g|=        3.4159
At iterate    15  f =       -395.7  |proj g|=        3.4191
At iterate    16  f =      -395.71  |proj g|=         3.428
At iterate    17  f =      -395.72  |proj g|=        3.4485
At iterate    18  f =      -395.73  |proj g|=        3.4718
At iterate    19  f =      -395.78  |proj g|=        3.5385
At iterate    20  f =      -395.83  |proj g|=        3.5574
At iterate    21  f =      -395.97  |proj g|=         3.595
At iterate    22  f =      -396.95  |proj g|=        3.5912
At iterate    23  f =       -397.1  |proj g|=        3.7571
At iterate    24  f =      -398.99  |proj g|=         3.439
At iterate    25  f =      -402.07  |proj g|=         2.633
At iterate    26  f =      -405.02  |proj g|=        1.8728
At iterate    27  f =      -408.37  |proj g|=        1.2589
At iterate    28  f =      -412.04  |proj g|=        1.4146
At iterate    29  f =       -412.3  |proj g|=        1.6798
At iterate    30  f =      -412.97  |proj g|=        1.5402
At iterate    31  f =      -414.21  |proj g|=       0.84912
At iterate    32  f =      -414.24  |proj g|=       0.78828
At iterate    33  f =      -414.25  |proj g|=       0.81107
At iterate    34  f =      -414.25  |proj g|=       0.80739
At iterate    35  f =      -414.25  |proj g|=       0.80811

iterations 35
function evaluations 42
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.808111
final function value -414.247

F = -414.247
final  value -414.247210 
converged
 
INFO  [22:37:16.109] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:37:16.162] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:37:16.169] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:37:30.109] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:37:47.659] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:38:01.311] [mlr3]  Finished benchmark 
INFO  [22:38:01.381] [bbotk] Result of batch 69: 
INFO  [22:38:01.383] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:38:01.383] [bbotk]              3.110574                  5.65238                       0.2647504 
INFO  [22:38:01.383] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:38:01.383] [bbotk]                     4956        0.631 -0.9597197         <NA>   0.9718628 
INFO  [22:38:01.383] [bbotk]                                 uhash 
INFO  [22:38:01.383] [bbotk]  66af4801-94d6-4b7d-a950-6a63f3f88e8b 
DEBUG [22:38:02.318] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.209587e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.209587e-05 0.001533596 
  - best initial criterion value(s) :  401.8205 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -401.82  |proj g|=       4.5734
At iterate     1  f =      -409.54  |proj g|=        1.9786
At iterate     2  f =      -412.85  |proj g|=        1.9122
At iterate     3  f =      -416.06  |proj g|=        1.6914
At iterate     4  f =      -416.15  |proj g|=        1.6163
At iterate     5  f =      -416.21  |proj g|=        1.6383
At iterate     6  f =      -416.34  |proj g|=        1.6707
At iterate     7  f =       -416.6  |proj g|=        1.7104
At iterate     8  f =      -416.84  |proj g|=        1.7263
At iterate     9  f =      -416.88  |proj g|=         1.685
At iterate    10  f =      -416.93  |proj g|=        1.6911
At iterate    11  f =      -416.93  |proj g|=        1.6907
At iterate    12  f =      -416.93  |proj g|=        1.6909
At iterate    13  f =      -416.94  |proj g|=        1.6924
At iterate    14  f =      -417.07  |proj g|=        1.6948
At iterate    15  f =      -417.12  |proj g|=        1.6369
At iterate    16  f =      -417.41  |proj g|=        1.6406
At iterate    17  f =      -417.92  |proj g|=        1.6085
At iterate    18  f =      -418.25  |proj g|=        1.5466
At iterate    19  f =      -418.46  |proj g|=        1.4717
At iterate    20  f =      -418.49  |proj g|=        1.4785
At iterate    21  f =      -418.49  |proj g|=        1.4819
At iterate    22  f =      -418.49  |proj g|=        1.4843
At iterate    23  f =      -418.49  |proj g|=        1.4839
At iterate    24  f =      -418.49  |proj g|=         1.484

iterations 24
function evaluations 32
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.484
final function value -418.489

F = -418.489
final  value -418.488989 
converged
 
INFO  [22:38:02.323] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:38:02.379] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:38:02.386] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:38:04.797] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:38:07.134] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:38:09.612] [mlr3]  Finished benchmark 
INFO  [22:38:09.697] [bbotk] Result of batch 70: 
INFO  [22:38:09.699] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:38:09.699] [bbotk]              8.256745                  6.83636                       0.3948994 
INFO  [22:38:09.699] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:38:09.699] [bbotk]                      912        0.644 -0.9584971         <NA>    0.971784 
INFO  [22:38:09.699] [bbotk]                                 uhash 
INFO  [22:38:09.699] [bbotk]  5b02fc8e-c5da-47b9-85d3-40e01410d9de 
DEBUG [22:38:10.767] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.198887e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.198887e-05 0.001506903 
  - best initial criterion value(s) :  401.6708 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -401.67  |proj g|=       5.4406
At iterate     1  f =      -403.14  |proj g|=        5.9846
At iterate     2  f =      -404.81  |proj g|=        5.5419
At iterate     3  f =      -408.66  |proj g|=        3.6986
At iterate     4  f =      -411.43  |proj g|=        2.7194
At iterate     5  f =       -412.1  |proj g|=        3.0042
At iterate     6  f =      -412.52  |proj g|=        2.9369
At iterate     7  f =      -412.53  |proj g|=          2.92
At iterate     8  f =      -412.53  |proj g|=        2.9217
At iterate     9  f =      -412.53  |proj g|=        2.9216
At iterate    10  f =      -412.53  |proj g|=        2.9213
At iterate    11  f =      -412.53  |proj g|=        2.9207
At iterate    12  f =      -412.53  |proj g|=        2.9197
At iterate    13  f =      -412.53  |proj g|=        2.9182
At iterate    14  f =      -412.53  |proj g|=        2.9165
At iterate    15  f =      -412.54  |proj g|=         2.911
At iterate    16  f =      -412.55  |proj g|=        2.9074
At iterate    17  f =      -412.58  |proj g|=        2.8813
At iterate    18  f =      -412.66  |proj g|=        2.8737
At iterate    19  f =      -413.01  |proj g|=        2.7048
At iterate    20  f =      -413.79  |proj g|=        2.7062
At iterate    21  f =      -415.98  |proj g|=        2.5808
At iterate    22  f =      -419.07  |proj g|=        2.2999
At iterate    23  f =      -421.35  |proj g|=        2.0608
At iterate    24  f =      -422.28  |proj g|=         1.852
At iterate    25  f =      -422.35  |proj g|=         1.877
At iterate    26  f =      -422.74  |proj g|=        1.8431
At iterate    27  f =      -422.82  |proj g|=        1.7892
At iterate    28  f =      -422.84  |proj g|=        1.7849
At iterate    29  f =      -422.84  |proj g|=        1.8037
At iterate    30  f =      -422.84  |proj g|=        1.7941
At iterate    31  f =      -422.84  |proj g|=        1.7938
At iterate    32  f =      -422.84  |proj g|=        1.7936
At iterate    33  f =      -422.84  |proj g|=        1.7917
At iterate    34  f =      -422.84  |proj g|=        1.7907
At iterate    35  f =      -422.84  |proj g|=        1.7898
At iterate    36  f =      -422.84  |proj g|=        1.7875
At iterate    37  f =      -422.85  |proj g|=        1.7813
At iterate    38  f =      -422.86  |proj g|=        1.7719
At iterate    39  f =      -422.86  |proj g|=        1.7561
At iterate    40  f =      -422.89  |proj g|=        1.7426
At iterate    41  f =      -422.94  |proj g|=        1.7128
At iterate    42  f =      -423.05  |proj g|=        1.6711
At iterate    43  f =       -423.3  |proj g|=        1.5306
At iterate    44  f =      -424.74  |proj g|=         1.414
At iterate    45  f =      -426.16  |proj g|=       0.57642
At iterate    46  f =      -429.28  |proj g|=       0.46176
At iterate    47  f =      -429.77  |proj g|=       0.65507
At iterate    48  f =      -430.03  |proj g|=       0.37536
At iterate    49  f =      -430.05  |proj g|=       0.37094
At iterate    50  f =      -430.05  |proj g|=       0.36317
At iterate    51  f =      -430.05  |proj g|=       0.36355
At iterate    52  f =      -430.05  |proj g|=        0.1863
At iterate    53  f =      -430.05  |proj g|=       0.24398
At iterate    54  f =      -430.05  |proj g|=      0.023587
At iterate    55  f =      -430.05  |proj g|=     0.0037155

iterations 55
function evaluations 67
segments explored during Cauchy searches 57
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00371552
final function value -430.053

F = -430.053
final  value -430.052840 
converged
 
INFO  [22:38:10.771] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:38:10.827] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:38:10.834] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:38:16.666] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:38:23.160] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:38:28.776] [mlr3]  Finished benchmark 
INFO  [22:38:28.845] [bbotk] Result of batch 71: 
INFO  [22:38:28.847] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:38:28.847] [bbotk]              6.195335                 9.567694                       0.4245838 
INFO  [22:38:28.847] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:38:28.847] [bbotk]                     2196         0.65 -0.9568992         <NA>    0.975188 
INFO  [22:38:28.847] [bbotk]                                 uhash 
INFO  [22:38:28.847] [bbotk]  e6f058fd-26ef-41f6-a3d5-ae7b364512f3 
DEBUG [22:38:29.841] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.191988e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.191988e-05 0.001494716 
  - best initial criterion value(s) :  400.7363 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -400.74  |proj g|=       4.5548
At iterate     1  f =      -402.57  |proj g|=        2.7404
At iterate     2  f =      -412.01  |proj g|=        3.5859
At iterate     3  f =      -415.59  |proj g|=        3.3053
At iterate     4  f =      -415.95  |proj g|=        3.3787
At iterate     5  f =      -415.98  |proj g|=        3.2641
At iterate     6  f =      -415.98  |proj g|=         3.266
At iterate     7  f =      -415.98  |proj g|=        3.2654
At iterate     8  f =      -415.98  |proj g|=        3.2653
At iterate     9  f =      -415.98  |proj g|=        3.2646
At iterate    10  f =      -415.98  |proj g|=        3.2637
At iterate    11  f =      -415.98  |proj g|=        3.2621
At iterate    12  f =      -415.98  |proj g|=        3.2585
At iterate    13  f =      -415.98  |proj g|=        3.2498
At iterate    14  f =      -415.99  |proj g|=        3.2442
At iterate    15  f =      -416.01  |proj g|=        3.2014
At iterate    16  f =      -416.01  |proj g|=         3.249
At iterate    17  f =      -416.05  |proj g|=        3.1798
At iterate    18  f =      -416.21  |proj g|=        3.0303
At iterate    19  f =      -416.72  |proj g|=        2.7387
At iterate    20  f =      -418.43  |proj g|=        2.2178
At iterate    21  f =      -423.14  |proj g|=        1.5082
At iterate    22  f =      -423.35  |proj g|=        1.3904
At iterate    23  f =       -429.4  |proj g|=        1.8875
At iterate    24  f =      -429.97  |proj g|=        2.3988
At iterate    25  f =       -430.1  |proj g|=        1.5852
At iterate    26  f =      -430.19  |proj g|=        1.5655
At iterate    27  f =      -430.21  |proj g|=         1.678
At iterate    28  f =      -430.21  |proj g|=        1.6637
At iterate    29  f =      -430.21  |proj g|=        1.6599
At iterate    30  f =      -430.21  |proj g|=        1.6596

iterations 30
function evaluations 41
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.65964
final function value -430.211

F = -430.211
final  value -430.211484 
converged
 
INFO  [22:38:29.845] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:38:29.903] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:38:29.910] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:38:41.218] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:38:52.416] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:39:04.114] [mlr3]  Finished benchmark 
INFO  [22:39:04.186] [bbotk] Result of batch 72: 
INFO  [22:39:04.188] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:39:04.188] [bbotk]              6.624457                 8.731073                       0.1146085 
INFO  [22:39:04.188] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:39:04.188] [bbotk]                     3765        0.657 -0.9604485         <NA>   0.9724368 
INFO  [22:39:04.188] [bbotk]                                 uhash 
INFO  [22:39:04.188] [bbotk]  5f0440f8-5374-4a4a-b123-0d7a46c38e2b 
DEBUG [22:39:05.234] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.182098e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.182098e-05 0.0014877 
  - best initial criterion value(s) :  405.6422 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -405.64  |proj g|=       5.7139
At iterate     1  f =      -411.73  |proj g|=        3.4585
At iterate     2  f =      -413.41  |proj g|=        2.8178
At iterate     3  f =      -413.74  |proj g|=        2.7186
At iterate     4  f =      -414.05  |proj g|=        2.7521
At iterate     5  f =      -414.63  |proj g|=        2.9435
At iterate     6  f =      -415.03  |proj g|=        3.5609
At iterate     7  f =      -415.04  |proj g|=        3.4646
At iterate     8  f =      -415.04  |proj g|=        3.4719
At iterate     9  f =      -415.04  |proj g|=        3.4842
At iterate    10  f =      -415.05  |proj g|=        3.4655
At iterate    11  f =      -415.06  |proj g|=        3.4264
At iterate    12  f =       -415.1  |proj g|=        3.3489
At iterate    13  f =      -415.19  |proj g|=        3.2287
At iterate    14  f =      -415.46  |proj g|=        2.9966
At iterate    15  f =      -416.15  |proj g|=        2.5872
At iterate    16  f =      -417.71  |proj g|=        1.9496
At iterate    17  f =      -420.05  |proj g|=        1.3649
At iterate    18  f =      -422.68  |proj g|=        1.7318
At iterate    19  f =      -423.62  |proj g|=        1.2543
At iterate    20  f =      -424.57  |proj g|=        1.3676
At iterate    21  f =      -424.75  |proj g|=        1.3605
At iterate    22  f =       -432.8  |proj g|=        1.4206
At iterate    23  f =      -437.49  |proj g|=        1.4159
At iterate    24  f =         -441  |proj g|=       0.68383
At iterate    25  f =      -442.39  |proj g|=       0.65851
At iterate    26  f =         -443  |proj g|=       0.59453
At iterate    27  f =      -443.06  |proj g|=         0.594
At iterate    28  f =      -443.06  |proj g|=       0.24526
At iterate    29  f =      -443.06  |proj g|=       0.18692
At iterate    30  f =      -443.06  |proj g|=       0.18724

iterations 30
function evaluations 39
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.187241
final function value -443.063

F = -443.063
final  value -443.062930 
converged
 
INFO  [22:39:05.238] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:39:05.295] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:39:05.302] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:39:14.330] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:39:21.198] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:39:27.659] [mlr3]  Finished benchmark 
INFO  [22:39:27.845] [bbotk] Result of batch 73: 
INFO  [22:39:27.847] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:39:27.847] [bbotk]              8.252142                 3.924746                       0.3793343 
INFO  [22:39:27.847] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:39:27.847] [bbotk]                     2538        0.701 -0.9552772         <NA>   0.9759276 
INFO  [22:39:27.847] [bbotk]                                 uhash 
INFO  [22:39:27.847] [bbotk]  73bc90c4-ec13-45f1-97fb-dd12e83be9a2 
DEBUG [22:39:29.022] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.176395e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.176395e-05 0.001479361 
  - best initial criterion value(s) :  415.3174 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -415.32  |proj g|=       2.0145
At iterate     1  f =      -416.08  |proj g|=        2.3347
At iterate     2  f =       -418.3  |proj g|=        2.0903
At iterate     3  f =      -420.28  |proj g|=        1.9502
At iterate     4  f =      -420.66  |proj g|=        2.0561
At iterate     5  f =      -420.82  |proj g|=        2.0482
At iterate     6  f =      -420.83  |proj g|=        2.0379
At iterate     7  f =      -420.83  |proj g|=        2.0405
At iterate     8  f =      -420.83  |proj g|=        2.0396
At iterate     9  f =      -420.83  |proj g|=        2.0395
At iterate    10  f =      -420.83  |proj g|=        2.0391
At iterate    11  f =      -420.83  |proj g|=        2.0385
At iterate    12  f =      -420.83  |proj g|=        2.0375
At iterate    13  f =      -420.83  |proj g|=        2.0358
At iterate    14  f =      -420.83  |proj g|=        2.0333
At iterate    15  f =      -420.83  |proj g|=          2.03
At iterate    16  f =      -420.83  |proj g|=        2.0271
At iterate    17  f =      -420.84  |proj g|=        2.0279
At iterate    18  f =      -420.84  |proj g|=        2.0237
At iterate    19  f =      -420.85  |proj g|=        2.0235
At iterate    20  f =       -428.1  |proj g|=        1.5098
At iterate    21  f =      -428.64  |proj g|=        1.3065
At iterate    22  f =      -428.89  |proj g|=        1.0928
At iterate    23  f =         -429  |proj g|=       0.95004
At iterate    24  f =      -429.04  |proj g|=       0.86145
At iterate    25  f =      -429.04  |proj g|=       0.84291
At iterate    26  f =      -429.04  |proj g|=        0.8416
At iterate    27  f =      -429.04  |proj g|=       0.84154

iterations 27
function evaluations 37
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.841537
final function value -429.038

F = -429.038
final  value -429.038067 
converged
 
INFO  [22:39:29.026] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:39:29.085] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:39:29.092] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:39:42.069] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:39:53.969] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:40:06.572] [mlr3]  Finished benchmark 
INFO  [22:40:06.672] [bbotk] Result of batch 74: 
INFO  [22:40:06.674] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:40:06.674] [bbotk]               7.69269                 7.093738                       0.2105928 
INFO  [22:40:06.674] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:40:06.674] [bbotk]                     4401        0.846 -0.9604181         <NA>   0.9756359 
INFO  [22:40:06.674] [bbotk]                                 uhash 
INFO  [22:40:06.674] [bbotk]  8aab0c69-3875-400d-84d6-350af595d1ef 
DEBUG [22:40:07.611] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.170275e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.170275e-05 0.001479648 
  - best initial criterion value(s) :  399.6176 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -399.62  |proj g|=       5.8532
At iterate     1  f =      -408.99  |proj g|=        1.1198
At iterate     2  f =      -414.19  |proj g|=        3.4601
At iterate     3  f =      -414.37  |proj g|=        3.2695
At iterate     4  f =      -414.48  |proj g|=         3.147
At iterate     5  f =      -414.54  |proj g|=        3.1932
At iterate     6  f =      -414.58  |proj g|=          3.39
At iterate     7  f =      -414.58  |proj g|=        3.3986
At iterate     8  f =      -414.58  |proj g|=        3.3965
At iterate     9  f =      -414.58  |proj g|=        3.3965

iterations 9
function evaluations 11
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.39654
final function value -414.584

F = -414.584
final  value -414.584222 
converged
 
INFO  [22:40:07.616] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:40:07.674] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:40:07.682] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:40:20.399] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:40:33.696] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:40:47.252] [mlr3]  Finished benchmark 
INFO  [22:40:47.323] [bbotk] Result of batch 75: 
INFO  [22:40:47.325] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:40:47.325] [bbotk]              4.117816                 7.940697                       0.3110782 
INFO  [22:40:47.325] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:40:47.325] [bbotk]                     4518        0.674 -0.9649953         <NA>    0.975243 
INFO  [22:40:47.325] [bbotk]                                 uhash 
INFO  [22:40:47.325] [bbotk]  7d8203e0-667f-4ee6-820c-9667cb9c8929 
DEBUG [22:40:48.301] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.163647e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.163647e-05 0.001479601 
  - best initial criterion value(s) :  434.6531 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -434.65  |proj g|=       5.2395
At iterate     1  f =      -438.92  |proj g|=         6.806
At iterate     2  f =      -441.38  |proj g|=        6.7532
At iterate     3  f =      -447.17  |proj g|=        5.0499
At iterate     4  f =      -448.51  |proj g|=        3.6129
At iterate     5  f =       -449.3  |proj g|=        2.4774
At iterate     6  f =      -449.34  |proj g|=         2.665
At iterate     7  f =      -449.34  |proj g|=         2.645
At iterate     8  f =      -449.35  |proj g|=        2.6529
At iterate     9  f =      -449.38  |proj g|=        2.7105
At iterate    10  f =      -449.44  |proj g|=        2.7865
At iterate    11  f =      -449.61  |proj g|=        2.8683
At iterate    12  f =      -450.03  |proj g|=        2.9121
At iterate    13  f =      -451.02  |proj g|=        2.7595
At iterate    14  f =      -453.35  |proj g|=        2.0054
At iterate    15  f =      -455.68  |proj g|=        1.2739
At iterate    16  f =      -457.28  |proj g|=        1.4952
At iterate    17  f =       -457.3  |proj g|=        1.4957
At iterate    18  f =      -457.39  |proj g|=        1.4867
At iterate    19  f =      -457.42  |proj g|=        1.4632
At iterate    20  f =      -457.43  |proj g|=        1.4428
At iterate    21  f =      -457.43  |proj g|=        1.4414
At iterate    22  f =      -457.43  |proj g|=        1.4414

iterations 22
function evaluations 27
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.44141
final function value -457.435

F = -457.435
final  value -457.434866 
converged
 
INFO  [22:40:48.305] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:40:48.360] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:40:48.368] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:41:02.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:41:16.682] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:41:30.583] [mlr3]  Finished benchmark 
INFO  [22:41:30.651] [bbotk] Result of batch 76: 
INFO  [22:41:30.653] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:41:30.653] [bbotk]              6.549645                 6.660308                       0.3075287 
INFO  [22:41:30.653] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:41:30.653] [bbotk]                     4951         0.67 -0.9559123         <NA>    0.976338 
INFO  [22:41:30.653] [bbotk]                                 uhash 
INFO  [22:41:30.653] [bbotk]  31bf5cda-28f9-4650-8bdb-47f75f4fc0d1 
DEBUG [22:41:31.556] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.158576e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.76108 0.9778625 9446 
  - variance bounds :  1.158576e-05 0.001479386 
  - best initial criterion value(s) :  428.565 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -428.57  |proj g|=       2.8822
At iterate     1  f =      -430.66  |proj g|=        1.7965
At iterate     2  f =      -445.07  |proj g|=        2.1458
At iterate     3  f =      -445.12  |proj g|=        2.1778
At iterate     4  f =       -445.2  |proj g|=         2.249
At iterate     5  f =      -445.22  |proj g|=        2.2428
At iterate     6  f =      -445.23  |proj g|=        2.2129
At iterate     7  f =      -445.23  |proj g|=        2.2139
At iterate     8  f =      -445.23  |proj g|=        2.2137
At iterate     9  f =      -445.23  |proj g|=        2.2137

iterations 9
function evaluations 11
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.21369
final function value -445.232

F = -445.232
final  value -445.231964 
converged
 
INFO  [22:41:31.560] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:41:31.615] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:41:31.622] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:41:38.758] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:41:45.002] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:41:50.228] [mlr3]  Finished benchmark 
INFO  [22:41:50.296] [bbotk] Result of batch 77: 
INFO  [22:41:50.298] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:41:50.298] [bbotk]              7.584189                 9.951049                       0.2656233 
INFO  [22:41:50.298] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:41:50.298] [bbotk]                     2140        0.661 -0.9606391         <NA>   0.9738912 
INFO  [22:41:50.298] [bbotk]                                 uhash 
INFO  [22:41:50.298] [bbotk]  69fc74b4-32ed-456f-993e-1cbde592b690 
DEBUG [22:41:51.213] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.150477e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.150477e-05 0.001464011 
  - best initial criterion value(s) :  436.0109 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -436.01  |proj g|=      0.90973
At iterate     1  f =      -439.78  |proj g|=        1.1743
At iterate     2  f =      -440.24  |proj g|=       0.78678
At iterate     3  f =      -440.29  |proj g|=       0.78296
At iterate     4  f =       -440.3  |proj g|=       0.77978
At iterate     5  f =       -440.3  |proj g|=       0.77946
At iterate     6  f =       -440.3  |proj g|=       0.77944

iterations 6
function evaluations 9
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.779439
final function value -440.302

F = -440.302
final  value -440.301546 
converged
 
INFO  [22:41:51.217] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:41:51.274] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:41:51.280] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:41:54.769] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:41:59.440] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:42:03.440] [mlr3]  Finished benchmark 
INFO  [22:42:03.510] [bbotk] Result of batch 78: 
INFO  [22:42:03.512] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:42:03.512] [bbotk]              8.217674                 3.612304                     0.008937733 
INFO  [22:42:03.512] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:42:03.512] [bbotk]                     1335        0.677 -0.9631769         <NA>   0.9268662 
INFO  [22:42:03.512] [bbotk]                                 uhash 
INFO  [22:42:03.512] [bbotk]  dd2e9b56-fe33-48d5-95c3-a419eaf9653a 
DEBUG [22:42:04.627] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.298948e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.298948e-05 0.001643336 
  - best initial criterion value(s) :  458.2602 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -458.26  |proj g|=      0.55034
At iterate     1  f =      -458.46  |proj g|=        2.3175
At iterate     2  f =       -460.7  |proj g|=        1.7479
At iterate     3  f =      -461.37  |proj g|=        1.2692
At iterate     4  f =      -461.43  |proj g|=        1.0387
At iterate     5  f =      -461.57  |proj g|=        1.0555
At iterate     6  f =      -461.99  |proj g|=       0.71198
At iterate     7  f =         -462  |proj g|=       0.56225
At iterate     8  f =         -462  |proj g|=       0.68365
At iterate     9  f =         -462  |proj g|=       0.68412
At iterate    10  f =         -462  |proj g|=       0.68404
At iterate    11  f =         -462  |proj g|=       0.68404

iterations 11
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.684043
final function value -462.004

F = -462.004
final  value -462.003851 
converged
 
INFO  [22:42:04.632] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:42:04.707] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:42:04.714] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:42:15.999] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:42:25.267] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:42:35.392] [mlr3]  Finished benchmark 
INFO  [22:42:35.461] [bbotk] Result of batch 79: 
INFO  [22:42:35.463] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:42:35.463] [bbotk]              9.797504                 6.617684                       0.0863161 
INFO  [22:42:35.463] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:42:35.463] [bbotk]                     3487        0.858 -0.9606351         <NA>   0.9710814 
INFO  [22:42:35.463] [bbotk]                                 uhash 
INFO  [22:42:35.463] [bbotk]  636f3002-63b3-4c5a-b3d3-8ce4fd41c9a0 
DEBUG [22:42:36.447] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.287823e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.287823e-05 0.001634655 
  - best initial criterion value(s) :  425.9154 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -425.92  |proj g|=       1.3806
At iterate     1  f =       -447.4  |proj g|=        7.2698
At iterate     2  f =      -449.41  |proj g|=        7.1754
At iterate     3  f =      -454.71  |proj g|=        6.0045
At iterate     4  f =      -455.07  |proj g|=        5.5199
At iterate     5  f =      -455.38  |proj g|=        5.2841
At iterate     6  f =      -455.85  |proj g|=        4.5503
At iterate     7  f =       -455.9  |proj g|=        4.7651
At iterate     8  f =      -455.91  |proj g|=        4.7251
At iterate     9  f =      -455.91  |proj g|=        4.7263
At iterate    10  f =      -455.91  |proj g|=        4.7275
At iterate    11  f =      -455.92  |proj g|=        4.7242
At iterate    12  f =      -455.94  |proj g|=        4.7135
At iterate    13  f =      -455.99  |proj g|=        4.6884
At iterate    14  f =      -456.12  |proj g|=        4.5949
At iterate    15  f =      -456.43  |proj g|=        4.3532
At iterate    16  f =      -457.17  |proj g|=        3.8955
At iterate    17  f =      -458.96  |proj g|=        3.6376
At iterate    18  f =      -462.23  |proj g|=        3.9634
At iterate    19  f =      -467.11  |proj g|=        3.7787
At iterate    20  f =      -469.22  |proj g|=        3.7326
At iterate    21  f =       -470.2  |proj g|=        3.3464
At iterate    22  f =      -470.46  |proj g|=        3.3166
At iterate    23  f =       -470.5  |proj g|=        3.2574
At iterate    24  f =       -470.5  |proj g|=        3.2541
At iterate    25  f =       -470.5  |proj g|=        3.2577
At iterate    26  f =       -470.5  |proj g|=        3.2571
At iterate    27  f =       -470.5  |proj g|=        3.2572
At iterate    28  f =       -470.5  |proj g|=        3.2569

iterations 28
function evaluations 35
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.25687
final function value -470.504

F = -470.504
final  value -470.503984 
converged
 
INFO  [22:42:36.451] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:42:36.508] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:42:36.515] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:42:44.471] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:42:49.852] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:42:55.243] [mlr3]  Finished benchmark 
INFO  [22:42:55.313] [bbotk] Result of batch 80: 
INFO  [22:42:55.315] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:42:55.315] [bbotk]              4.417012                 9.058009                       0.1284078 
INFO  [22:42:55.315] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:42:55.315] [bbotk]                     2180        0.662 -0.9542257         <NA>    0.968141 
INFO  [22:42:55.315] [bbotk]                                 uhash 
INFO  [22:42:55.315] [bbotk]  dd232535-67f3-4fe5-a5d8-3a436c612f69 
DEBUG [22:42:56.364] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.276115e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.276115e-05 0.001616453 
  - best initial criterion value(s) :  456.0679 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -456.07  |proj g|=       4.2852
At iterate     1  f =      -456.16  |proj g|=        3.4075
At iterate     2  f =      -461.46  |proj g|=        3.2948
At iterate     3  f =      -467.06  |proj g|=        2.7948
At iterate     4  f =      -467.13  |proj g|=        2.7198
At iterate     5  f =      -467.17  |proj g|=        2.7192
At iterate     6  f =      -467.28  |proj g|=         2.754
At iterate     7  f =      -467.28  |proj g|=        2.7623
At iterate     8  f =      -467.28  |proj g|=        2.7636
At iterate     9  f =      -467.28  |proj g|=        2.7638
At iterate    10  f =      -467.28  |proj g|=        2.7647
At iterate    11  f =      -467.29  |proj g|=        2.7665
At iterate    12  f =      -467.29  |proj g|=        2.7682
At iterate    13  f =      -467.29  |proj g|=        2.7722
At iterate    14  f =      -467.29  |proj g|=        2.7773
At iterate    15  f =      -467.29  |proj g|=        2.7852
At iterate    16  f =       -467.3  |proj g|=        2.7933
At iterate    17  f =      -467.32  |proj g|=        2.8236
At iterate    18  f =      -467.36  |proj g|=        2.8271
At iterate    19  f =      -467.44  |proj g|=         2.941
At iterate    20  f =      -467.75  |proj g|=        2.8536
At iterate    21  f =      -468.22  |proj g|=        2.6823
At iterate    22  f =      -468.87  |proj g|=        2.4054
At iterate    23  f =      -469.36  |proj g|=        2.2351
At iterate    24  f =      -469.42  |proj g|=        2.3608
At iterate    25  f =      -469.54  |proj g|=         2.282
At iterate    26  f =      -469.59  |proj g|=        2.2236
At iterate    27  f =      -469.61  |proj g|=        2.2351
At iterate    28  f =      -469.62  |proj g|=        2.2458
At iterate    29  f =      -469.62  |proj g|=        2.2446
At iterate    30  f =      -469.62  |proj g|=        2.2463
At iterate    31  f =      -469.62  |proj g|=        2.2473
At iterate    32  f =      -469.62  |proj g|=        2.2502
At iterate    33  f =      -469.62  |proj g|=        2.2502

iterations 33
function evaluations 40
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.25021
final function value -469.619

F = -469.619
final  value -469.618672 
converged
 
INFO  [22:42:56.368] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:42:56.426] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:42:56.433] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:43:00.098] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:43:03.668] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:43:06.831] [mlr3]  Finished benchmark 
INFO  [22:43:06.905] [bbotk] Result of batch 81: 
INFO  [22:43:06.907] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:43:06.907] [bbotk]              8.332804                 6.336363                       0.3143135 
INFO  [22:43:06.907] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:43:06.907] [bbotk]                     1127        0.698 -0.9593983         <NA>   0.9717043 
INFO  [22:43:06.907] [bbotk]                                 uhash 
INFO  [22:43:06.907] [bbotk]  15995d74-9b3c-4c5e-9f00-40c8258ec9da 
DEBUG [22:43:07.897] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.265742e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.265742e-05 0.001591121 
  - best initial criterion value(s) :  453.0266 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -453.03  |proj g|=       6.2991
At iterate     1  f =      -464.49  |proj g|=         3.325
At iterate     2  f =      -468.43  |proj g|=        3.2316
At iterate     3  f =       -473.3  |proj g|=        2.8452
At iterate     4  f =      -473.52  |proj g|=        2.7186
At iterate     5  f =       -473.6  |proj g|=        2.7076
At iterate     6  f =      -473.78  |proj g|=        2.7271
At iterate     7  f =      -473.78  |proj g|=         2.749
At iterate     8  f =      -473.78  |proj g|=        2.7492
At iterate     9  f =      -473.79  |proj g|=        2.7476
At iterate    10  f =      -473.81  |proj g|=        2.7375
At iterate    11  f =      -473.85  |proj g|=        2.7248
At iterate    12  f =      -473.98  |proj g|=        2.6893
At iterate    13  f =      -474.27  |proj g|=        2.6738
At iterate    14  f =      -474.38  |proj g|=        2.5477
At iterate    15  f =      -474.98  |proj g|=        2.4935
At iterate    16  f =      -477.21  |proj g|=        2.2805
At iterate    17  f =      -477.78  |proj g|=        2.2006
At iterate    18  f =      -477.87  |proj g|=        2.2984
At iterate    19  f =      -477.88  |proj g|=        2.2746
At iterate    20  f =      -477.88  |proj g|=        2.2795
At iterate    21  f =      -477.88  |proj g|=        2.2793

iterations 21
function evaluations 29
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.27929
final function value -477.878

F = -477.878
final  value -477.877724 
converged
 
INFO  [22:43:07.901] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:43:07.956] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:43:07.963] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:43:15.518] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:43:23.664] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:43:32.038] [mlr3]  Finished benchmark 
INFO  [22:43:32.106] [bbotk] Result of batch 82: 
INFO  [22:43:32.108] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:43:32.108] [bbotk]              6.874088                 9.050013                       0.3686737 
INFO  [22:43:32.108] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [22:43:32.108] [bbotk]                     3020        0.683 -0.958249         <NA>   0.9755929 
INFO  [22:43:32.108] [bbotk]                                 uhash 
INFO  [22:43:32.108] [bbotk]  9f036d9e-76e2-4238-94f1-84f80e14756b 
DEBUG [22:43:33.269] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.259291e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.259291e-05 0.001586854 
  - best initial criterion value(s) :  440.3535 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -440.35  |proj g|=       4.9741
At iterate     1  f =      -457.94  |proj g|=        4.1029
At iterate     2  f =      -467.16  |proj g|=        4.8363
At iterate     3  f =      -470.48  |proj g|=        4.4965
At iterate     4  f =      -473.63  |proj g|=        4.0804
At iterate     5  f =      -473.92  |proj g|=        3.9008
At iterate     6  f =      -473.93  |proj g|=        3.6865
At iterate     7  f =      -473.94  |proj g|=        3.7705
At iterate     8  f =      -473.94  |proj g|=        3.7758
At iterate     9  f =      -473.94  |proj g|=        3.7984
At iterate    10  f =      -473.95  |proj g|=        3.8255
At iterate    11  f =      -473.97  |proj g|=        3.8721
At iterate    12  f =      -474.01  |proj g|=        3.9378
At iterate    13  f =      -474.11  |proj g|=        4.0293
At iterate    14  f =      -474.36  |proj g|=         4.123
At iterate    15  f =      -474.89  |proj g|=        4.1434
At iterate    16  f =      -475.93  |proj g|=        3.9458
At iterate    17  f =      -477.81  |proj g|=        3.1583
At iterate    18  f =      -480.63  |proj g|=        3.3362
At iterate    19  f =       -483.5  |proj g|=        4.2796
At iterate    20  f =      -483.96  |proj g|=        5.1359
At iterate    21  f =      -483.99  |proj g|=        5.0062
At iterate    22  f =      -483.99  |proj g|=        5.0043
At iterate    23  f =      -483.99  |proj g|=        5.0035
At iterate    24  f =      -483.99  |proj g|=         5.004
At iterate    25  f =      -483.99  |proj g|=        5.0012
At iterate    26  f =      -483.99  |proj g|=         4.992
At iterate    27  f =      -483.99  |proj g|=        4.9855
At iterate    28  f =      -483.99  |proj g|=        4.9771
At iterate    29  f =      -483.99  |proj g|=        4.9758
At iterate    30  f =      -483.99  |proj g|=        4.9754
At iterate    31  f =      -483.99  |proj g|=        4.9748
At iterate    32  f =      -483.99  |proj g|=         4.974
At iterate    33  f =      -483.99  |proj g|=        4.9732
At iterate    34  f =      -483.99  |proj g|=        4.9731
At iterate    35  f =      -483.99  |proj g|=         4.976
At iterate    36  f =      -483.99  |proj g|=        4.9856
At iterate    37  f =      -483.99  |proj g|=         4.982
At iterate    38  f =      -483.99  |proj g|=        5.0015
At iterate    39  f =         -484  |proj g|=        5.0811
At iterate    40  f =      -484.01  |proj g|=        5.1423
At iterate    41  f =      -484.02  |proj g|=        5.1845
At iterate    42  f =      -484.02  |proj g|=        5.1813
At iterate    43  f =      -484.02  |proj g|=        5.1756
At iterate    44  f =      -484.02  |proj g|=        5.1565
At iterate    45  f =      -484.02  |proj g|=         5.127
At iterate    46  f =      -484.03  |proj g|=        5.0915
At iterate    47  f =      -484.05  |proj g|=        5.0264
At iterate    48  f =      -484.11  |proj g|=        4.9318
At iterate    49  f =      -484.11  |proj g|=        4.8824
At iterate    50  f =      -484.24  |proj g|=        4.7592
At iterate    51  f =      -484.41  |proj g|=        5.4019
At iterate    52  f =      -484.76  |proj g|=        5.2085
At iterate    53  f =      -488.09  |proj g|=        3.5839
At iterate    54  f =      -491.65  |proj g|=        2.3457
At iterate    55  f =      -497.93  |proj g|=        1.2305
At iterate    56  f =      -500.71  |proj g|=       0.55134
At iterate    57  f =      -502.42  |proj g|=        0.5064
At iterate    58  f =       -502.8  |proj g|=          0.47
At iterate    59  f =         -503  |proj g|=       0.52588
At iterate    60  f =       -503.1  |proj g|=       0.41677
At iterate    61  f =      -503.13  |proj g|=       0.56109
At iterate    62  f =      -503.14  |proj g|=       0.42965
At iterate    63  f =      -503.14  |proj g|=      0.017941
At iterate    64  f =      -503.14  |proj g|=      0.031755

iterations 64
function evaluations 73
segments explored during Cauchy searches 67
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0317546
final function value -503.145

F = -503.145
final  value -503.144884 
converged
 
INFO  [22:43:33.274] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:43:33.330] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:43:33.337] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:43:47.699] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:43:59.020] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:44:12.680] [mlr3]  Finished benchmark 
INFO  [22:44:12.751] [bbotk] Result of batch 83: 
INFO  [22:44:12.753] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:44:12.753] [bbotk]              8.065062                 9.076748                       0.3837494 
INFO  [22:44:12.753] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:44:12.753] [bbotk]                     4482        0.684 -0.9496455         <NA>   0.9774182 
INFO  [22:44:12.753] [bbotk]                                 uhash 
INFO  [22:44:12.753] [bbotk]  dd24885d-c0d6-4c2a-96ec-7d8ac0a6a63e 
DEBUG [22:44:13.829] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.255513e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.255513e-05 0.001591084 
  - best initial criterion value(s) :  447.1775 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -447.18  |proj g|=       5.3777
At iterate     1  f =      -457.82  |proj g|=        7.0979
At iterate     2  f =      -466.15  |proj g|=        5.9001
At iterate     3  f =      -470.59  |proj g|=        3.9544
At iterate     4  f =      -478.47  |proj g|=        1.8352
At iterate     5  f =       -478.6  |proj g|=        1.7798
At iterate     6  f =       -478.6  |proj g|=        1.7669
At iterate     7  f =       -478.6  |proj g|=          1.77
At iterate     8  f =       -478.6  |proj g|=        1.7699
At iterate     9  f =       -478.6  |proj g|=        1.7695
At iterate    10  f =      -478.61  |proj g|=        1.7674
At iterate    11  f =      -478.61  |proj g|=        1.7647
At iterate    12  f =      -478.61  |proj g|=        1.7599
At iterate    13  f =      -478.62  |proj g|=        1.7531
At iterate    14  f =      -478.64  |proj g|=        1.7439
At iterate    15  f =      -478.68  |proj g|=        1.7362
At iterate    16  f =      -478.77  |proj g|=        1.7357
At iterate    17  f =      -478.82  |proj g|=        1.6806
At iterate    18  f =      -479.02  |proj g|=        1.6988
At iterate    19  f =      -479.41  |proj g|=        1.7168
At iterate    20  f =      -479.66  |proj g|=        1.7278
At iterate    21  f =      -479.77  |proj g|=        1.7421
At iterate    22  f =      -479.78  |proj g|=        1.7512
At iterate    23  f =      -479.78  |proj g|=        1.7537
At iterate    24  f =      -479.78  |proj g|=        1.7534
At iterate    25  f =      -479.78  |proj g|=        1.7541
At iterate    26  f =      -479.78  |proj g|=        1.7539
At iterate    27  f =      -479.78  |proj g|=        1.7539

iterations 27
function evaluations 38
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.75389
final function value -479.776

F = -479.776
final  value -479.776476 
converged
 
INFO  [22:44:13.833] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:44:13.911] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:44:13.923] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:44:25.272] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:44:36.307] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:44:47.724] [mlr3]  Finished benchmark 
INFO  [22:44:47.791] [bbotk] Result of batch 84: 
INFO  [22:44:47.793] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:44:47.793] [bbotk]              3.469127                 7.227701                       0.4384169 
INFO  [22:44:47.793] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:44:47.793] [bbotk]                     3846          0.7 -0.9604769         <NA>   0.9746359 
INFO  [22:44:47.793] [bbotk]                                 uhash 
INFO  [22:44:47.793] [bbotk]  de6f4086-703f-44e1-94f8-3c228e58181e 
DEBUG [22:44:49.095] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.247952e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.247952e-05 0.001587608 
  - best initial criterion value(s) :  483.1417 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -483.14  |proj g|=       10.609
At iterate     1  f =      -483.77  |proj g|=        8.7833
At iterate     2  f =      -489.73  |proj g|=        7.3459
At iterate     3  f =      -493.92  |proj g|=        4.6505
At iterate     4  f =      -495.53  |proj g|=         3.462
At iterate     5  f =      -495.95  |proj g|=        2.1402
At iterate     6  f =      -495.97  |proj g|=        2.3478
At iterate     7  f =      -495.98  |proj g|=        2.3172
At iterate     8  f =      -495.98  |proj g|=        2.3143
At iterate     9  f =      -495.98  |proj g|=        2.3136
At iterate    10  f =      -495.98  |proj g|=        2.3096
At iterate    11  f =      -495.98  |proj g|=        2.3045
At iterate    12  f =      -495.98  |proj g|=        2.2938
At iterate    13  f =      -495.98  |proj g|=         2.275
At iterate    14  f =      -495.98  |proj g|=        2.2389
At iterate    15  f =      -495.99  |proj g|=        2.1711
At iterate    16  f =         -496  |proj g|=        2.0475
At iterate    17  f =      -496.04  |proj g|=        1.8597
At iterate    18  f =       -496.1  |proj g|=        1.7165
At iterate    19  f =      -496.11  |proj g|=        1.7188
At iterate    20  f =      -496.12  |proj g|=        1.7397
At iterate    21  f =      -496.12  |proj g|=        1.7732
At iterate    22  f =      -496.14  |proj g|=        1.8127
At iterate    23  f =       -496.2  |proj g|=        1.8497
At iterate    24  f =      -496.33  |proj g|=        1.8594
At iterate    25  f =      -496.64  |proj g|=        1.7347
At iterate    26  f =      -497.29  |proj g|=        1.2996
At iterate    27  f =      -498.45  |proj g|=       0.79882
At iterate    28  f =      -498.66  |proj g|=        0.7969
At iterate    29  f =      -498.74  |proj g|=       0.79602
At iterate    30  f =      -498.87  |proj g|=       0.89188
At iterate    31  f =      -499.22  |proj g|=        1.2136
At iterate    32  f =      -499.95  |proj g|=        1.5753
At iterate    33  f =      -501.39  |proj g|=        1.8247
At iterate    34  f =      -503.87  |proj g|=         1.733
At iterate    35  f =      -504.06  |proj g|=         1.816
At iterate    36  f =      -505.62  |proj g|=        1.4932
At iterate    37  f =      -505.85  |proj g|=        1.3225
At iterate    38  f =      -507.21  |proj g|=       0.65411
At iterate    39  f =      -507.46  |proj g|=       0.40299
At iterate    40  f =      -507.57  |proj g|=       0.36846
At iterate    41  f =      -507.58  |proj g|=       0.36506
At iterate    42  f =      -507.58  |proj g|=        0.3531
At iterate    43  f =      -507.58  |proj g|=       0.35282
At iterate    44  f =      -507.58  |proj g|=       0.35277
At iterate    45  f =      -507.58  |proj g|=       0.35282

iterations 45
function evaluations 51
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.35282
final function value -507.584

F = -507.584
final  value -507.584280 
converged
 
INFO  [22:44:49.099] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:44:49.157] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:44:49.163] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:44:57.087] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:45:04.374] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:45:11.068] [mlr3]  Finished benchmark 
INFO  [22:45:11.136] [bbotk] Result of batch 85: 
INFO  [22:45:11.137] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:45:11.137] [bbotk]              8.119499                  9.72976                       0.1808103 
INFO  [22:45:11.137] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:45:11.137] [bbotk]                     2482        0.717 -0.9550441         <NA>   0.9728669 
INFO  [22:45:11.137] [bbotk]                                 uhash 
INFO  [22:45:11.137] [bbotk]  f85bdff8-a0d5-4ecc-86eb-64494966f8fc 
DEBUG [22:45:12.192] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.238828e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.238828e-05 0.001572357 
  - best initial criterion value(s) :  467.9856 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -467.99  |proj g|=       5.8978
At iterate     1  f =         -494  |proj g|=        3.8007
At iterate     2  f =      -497.15  |proj g|=        3.7384
At iterate     3  f =      -501.15  |proj g|=        3.4957
At iterate     4  f =      -501.74  |proj g|=         3.242
At iterate     5  f =      -501.95  |proj g|=        3.3162
At iterate     6  f =      -502.32  |proj g|=         3.384
At iterate     7  f =      -503.22  |proj g|=        3.4695
At iterate     8  f =      -503.91  |proj g|=        3.4675
At iterate     9  f =      -503.96  |proj g|=        3.3909
At iterate    10  f =      -504.02  |proj g|=        3.4156
At iterate    11  f =      -504.03  |proj g|=        3.4233
At iterate    12  f =      -504.03  |proj g|=        3.4256
At iterate    13  f =      -504.03  |proj g|=         3.426
At iterate    14  f =      -504.03  |proj g|=        3.4263
At iterate    15  f =      -504.03  |proj g|=        3.4269
At iterate    16  f =      -504.03  |proj g|=        3.4276
At iterate    17  f =      -504.03  |proj g|=        3.4289
At iterate    18  f =      -504.03  |proj g|=        3.4307
At iterate    19  f =      -504.03  |proj g|=        3.4328
At iterate    20  f =      -504.03  |proj g|=        3.4342
At iterate    21  f =      -504.03  |proj g|=        3.4367
At iterate    22  f =      -504.03  |proj g|=        3.4315
At iterate    23  f =      -504.04  |proj g|=        3.4547
At iterate    24  f =      -504.05  |proj g|=        3.4363
At iterate    25  f =      -504.08  |proj g|=        3.3801
At iterate    26  f =      -504.14  |proj g|=        3.3057
At iterate    27  f =      -504.24  |proj g|=        3.2068
At iterate    28  f =      -504.32  |proj g|=        3.1626
At iterate    29  f =      -504.34  |proj g|=        3.1852
At iterate    30  f =      -504.34  |proj g|=        3.2086
At iterate    31  f =      -504.34  |proj g|=        3.2133
At iterate    32  f =      -504.34  |proj g|=        3.2189
At iterate    33  f =      -504.35  |proj g|=        3.2221
At iterate    34  f =      -504.35  |proj g|=        3.2166
At iterate    35  f =      -504.35  |proj g|=        3.2086
At iterate    36  f =      -504.35  |proj g|=        3.2122
At iterate    37  f =      -504.35  |proj g|=        3.2122

iterations 37
function evaluations 42
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.21223
final function value -504.347

F = -504.347
final  value -504.346622 
converged
 
INFO  [22:45:12.196] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:45:12.252] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:45:12.259] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:45:23.345] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:45:34.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:45:46.672] [mlr3]  Finished benchmark 
INFO  [22:45:46.739] [bbotk] Result of batch 86: 
INFO  [22:45:46.741] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:45:46.741] [bbotk]              5.843348                 3.434063                       0.4914546 
INFO  [22:45:46.741] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:45:46.741] [bbotk]                     4233        0.689 -0.9545324         <NA>   0.9770848 
INFO  [22:45:46.741] [bbotk]                                 uhash 
INFO  [22:45:46.741] [bbotk]  b1e6881b-5b1d-47e4-acd9-829842d15a2d 
DEBUG [22:45:47.690] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.234553e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9778625 9446 
  - variance bounds :  1.234553e-05 0.001574831 
  - best initial criterion value(s) :  492.4326 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -492.43  |proj g|=       2.8616
At iterate     1  f =      -492.78  |proj g|=        1.7807
At iterate     2  f =      -497.07  |proj g|=        1.5782
At iterate     3  f =      -499.69  |proj g|=        1.3006
At iterate     4  f =      -499.73  |proj g|=        1.1836
At iterate     5  f =      -499.78  |proj g|=        1.2372
At iterate     6  f =      -499.78  |proj g|=        1.2341
At iterate     7  f =       -499.8  |proj g|=        1.2172
At iterate     8  f =      -499.81  |proj g|=        1.2095
At iterate     9  f =      -499.83  |proj g|=         1.214
At iterate    10  f =      -499.84  |proj g|=        1.2291
At iterate    11  f =      -499.84  |proj g|=         1.231
At iterate    12  f =      -499.84  |proj g|=        1.2311

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.23108
final function value -499.84

F = -499.84
final  value -499.840354 
converged
 
INFO  [22:45:47.694] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:45:47.751] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:45:47.758] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:45:55.982] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:46:05.734] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:46:14.570] [mlr3]  Finished benchmark 
INFO  [22:46:14.658] [bbotk] Result of batch 87: 
INFO  [22:46:14.660] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:46:14.660] [bbotk]              2.605726                 9.025001                       0.4999184 
INFO  [22:46:14.660] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:46:14.660] [bbotk]                     2957        0.686 -0.9596486         <NA>   0.9682201 
INFO  [22:46:14.660] [bbotk]                                 uhash 
INFO  [22:46:14.660] [bbotk]  71c147d2-94d1-4ee5-9ab2-7c5d8f245f26 
DEBUG [22:46:15.797] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.224008e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.224008e-05 0.001566175 
  - best initial criterion value(s) :  517.1327 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -517.13  |proj g|=      0.27213
At iterate     1  f =      -519.79  |proj g|=        1.4071
At iterate     2  f =      -519.84  |proj g|=        1.3589
At iterate     3  f =      -519.99  |proj g|=        1.3317
At iterate     4  f =      -520.17  |proj g|=        1.4449
At iterate     5  f =      -520.35  |proj g|=        2.0845
At iterate     6  f =      -520.39  |proj g|=        1.9769
At iterate     7  f =      -520.39  |proj g|=        1.9466
At iterate     8  f =      -520.39  |proj g|=        1.9486
At iterate     9  f =      -520.39  |proj g|=        1.9488

iterations 9
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.94882
final function value -520.392

F = -520.392
final  value -520.392292 
converged
 
INFO  [22:46:15.801] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:46:15.859] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:46:15.866] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:46:17.951] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:46:20.469] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:46:23.424] [mlr3]  Finished benchmark 
INFO  [22:46:23.493] [bbotk] Result of batch 88: 
INFO  [22:46:23.495] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:46:23.495] [bbotk]               6.75642                 2.762599                       0.2268347 
INFO  [22:46:23.495] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:46:23.495] [bbotk]                      816        0.872 -0.9579795         <NA>   0.9673061 
INFO  [22:46:23.495] [bbotk]                                 uhash 
INFO  [22:46:23.495] [bbotk]  5bf480d3-6b30-4fd2-908a-ca2b911769ed 
DEBUG [22:46:24.583] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.213755e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.213755e-05 0.00154144 
  - best initial criterion value(s) :  507.6759 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -507.68  |proj g|=       2.7995
At iterate     1  f =      -513.05  |proj g|=        5.0294
At iterate     2  f =      -514.61  |proj g|=        4.2514
At iterate     3  f =      -515.08  |proj g|=        4.0483
At iterate     4  f =      -515.49  |proj g|=        3.9215
At iterate     5  f =      -515.69  |proj g|=        3.8947
At iterate     6  f =      -515.72  |proj g|=        4.0398
At iterate     7  f =      -515.72  |proj g|=        3.9901
At iterate     8  f =      -515.72  |proj g|=        3.9894
At iterate     9  f =      -515.72  |proj g|=        3.9808
At iterate    10  f =      -515.73  |proj g|=        3.9729
At iterate    11  f =      -515.73  |proj g|=        3.9349
At iterate    12  f =      -515.75  |proj g|=        3.8873
At iterate    13  f =      -515.79  |proj g|=        3.7934
At iterate    14  f =      -515.91  |proj g|=        3.6351
At iterate    15  f =      -516.22  |proj g|=        3.3424
At iterate    16  f =      -517.02  |proj g|=        2.8283
At iterate    17  f =      -518.59  |proj g|=        2.1122
At iterate    18  f =      -520.86  |proj g|=        1.7438
At iterate    19  f =      -522.21  |proj g|=        1.6714
At iterate    20  f =      -523.12  |proj g|=        1.6732
At iterate    21  f =       -523.6  |proj g|=        1.6793
At iterate    22  f =      -523.83  |proj g|=        1.5932
At iterate    23  f =      -523.85  |proj g|=        1.7085
At iterate    24  f =      -523.91  |proj g|=        1.6077
At iterate    25  f =      -523.99  |proj g|=        1.5761
At iterate    26  f =      -524.44  |proj g|=        1.4657
At iterate    27  f =      -525.16  |proj g|=        1.6318
At iterate    28  f =       -527.4  |proj g|=        1.9621
At iterate    29  f =       -530.3  |proj g|=        1.8153
At iterate    30  f =      -533.16  |proj g|=        1.0317
At iterate    31  f =      -533.83  |proj g|=       0.64572
At iterate    32  f =      -534.11  |proj g|=       0.58619
At iterate    33  f =      -534.18  |proj g|=       0.44378
At iterate    34  f =      -534.19  |proj g|=       0.38184
At iterate    35  f =      -534.19  |proj g|=       0.39148
At iterate    36  f =      -534.19  |proj g|=       0.39102

iterations 36
function evaluations 43
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.391017
final function value -534.186

F = -534.186
final  value -534.185828 
converged
 
INFO  [22:46:24.587] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:46:24.644] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:46:24.651] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:46:36.442] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:46:48.675] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:47:00.790] [mlr3]  Finished benchmark 
INFO  [22:47:00.883] [bbotk] Result of batch 89: 
INFO  [22:47:00.886] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:47:00.886] [bbotk]              9.804406                 9.635071                       0.3310268 
INFO  [22:47:00.886] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:47:00.886] [bbotk]                     4158        0.687 -0.9527541         <NA>   0.9763485 
INFO  [22:47:00.886] [bbotk]                                 uhash 
INFO  [22:47:00.886] [bbotk]  7c6ab453-b6c2-4ae6-8cc9-eecc8fc5cf30 
DEBUG [22:47:01.920] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.208702e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.208702e-05 0.001541524 
  - best initial criterion value(s) :  499.9307 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -499.93  |proj g|=         7.15
At iterate     1  f =      -500.88  |proj g|=        7.8875
At iterate     2  f =      -503.03  |proj g|=        7.4768
At iterate     3  f =      -509.02  |proj g|=         5.415
At iterate     4  f =      -510.44  |proj g|=        4.7118
At iterate     5  f =       -511.3  |proj g|=         4.425
At iterate     6  f =      -511.43  |proj g|=        4.0824
At iterate     7  f =      -511.44  |proj g|=        3.9667
At iterate     8  f =      -511.44  |proj g|=        3.9621
At iterate     9  f =      -511.44  |proj g|=         3.956
At iterate    10  f =      -511.68  |proj g|=        3.7875
At iterate    11  f =      -514.44  |proj g|=        2.4075
At iterate    12  f =      -518.24  |proj g|=        1.8524
At iterate    13  f =      -520.52  |proj g|=        1.9045
At iterate    14  f =      -520.68  |proj g|=        1.7869
At iterate    15  f =      -520.72  |proj g|=        1.7839
At iterate    16  f =      -520.72  |proj g|=        1.7832
At iterate    17  f =      -520.72  |proj g|=        1.7824
At iterate    18  f =      -520.72  |proj g|=        1.7827
At iterate    19  f =      -520.72  |proj g|=        1.7828

iterations 19
function evaluations 29
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.78282
final function value -520.721

F = -520.721
final  value -520.721277 
converged
 
INFO  [22:47:01.923] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:47:01.988] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:47:01.996] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:47:10.028] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:47:17.133] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:47:25.906] [mlr3]  Finished benchmark 
INFO  [22:47:25.975] [bbotk] Result of batch 90: 
INFO  [22:47:25.977] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:47:25.977] [bbotk]               7.10337                 7.361245                       0.2849593 
INFO  [22:47:25.977] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:47:25.977] [bbotk]                     2645        0.703 -0.9568339         <NA>   0.9749073 
INFO  [22:47:25.977] [bbotk]                                 uhash 
INFO  [22:47:25.977] [bbotk]  1479c6d2-958b-447c-8f8b-90b09fac9a65 
DEBUG [22:47:26.954] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.201963e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.201963e-05 0.001531266 
  - best initial criterion value(s) :  495.7665 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -495.77  |proj g|=       3.5251
At iterate     1  f =      -503.41  |proj g|=        2.5608
At iterate     2  f =      -508.28  |proj g|=        2.9125
At iterate     3  f =      -508.54  |proj g|=        2.8471
At iterate     4  f =      -508.63  |proj g|=        2.7982
At iterate     5  f =      -508.63  |proj g|=        2.7975
At iterate     6  f =      -508.63  |proj g|=        2.8023
At iterate     7  f =      -508.63  |proj g|=         2.807
At iterate     8  f =      -508.63  |proj g|=        2.8081
At iterate     9  f =      -508.63  |proj g|=        2.8082

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.8082
final function value -508.632

F = -508.632
final  value -508.631823 
converged
 
INFO  [22:47:26.958] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:47:27.014] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:47:27.021] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:47:32.590] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:47:38.136] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:47:44.840] [mlr3]  Finished benchmark 
INFO  [22:47:44.908] [bbotk] Result of batch 91: 
INFO  [22:47:44.910] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:47:44.910] [bbotk]              8.786089                 7.340512                       0.1451702 
INFO  [22:47:44.910] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:47:44.910] [bbotk]                     2154        0.714 -0.9600365         <NA>   0.9710765 
INFO  [22:47:44.910] [bbotk]                                 uhash 
INFO  [22:47:44.910] [bbotk]  856e53af-1084-4833-be40-96e415e1f19a 
DEBUG [22:47:46.038] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.192529e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.192529e-05 0.001516469 
  - best initial criterion value(s) :  519.7536 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -519.75  |proj g|=       1.9827
At iterate     1  f =      -526.39  |proj g|=        1.4926
At iterate     2  f =      -526.85  |proj g|=        1.5879
At iterate     3  f =      -526.93  |proj g|=        1.5646
At iterate     4  f =      -526.94  |proj g|=        1.5535
At iterate     5  f =      -526.94  |proj g|=        1.5527
At iterate     6  f =      -526.94  |proj g|=        1.5528

iterations 6
function evaluations 9
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.55275
final function value -526.94

F = -526.94
final  value -526.940452 
converged
 
INFO  [22:47:46.042] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:47:46.098] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:47:46.112] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:47:54.362] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:48:03.033] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:48:11.221] [mlr3]  Finished benchmark 
INFO  [22:48:11.289] [bbotk] Result of batch 92: 
INFO  [22:48:11.291] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:48:11.291] [bbotk]              5.365167                  2.90092                      0.01663369 
INFO  [22:48:11.291] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:48:11.291] [bbotk]                     3333        0.882 -0.9588371         <NA>   0.9533079 
INFO  [22:48:11.291] [bbotk]                                 uhash 
INFO  [22:48:11.291] [bbotk]  30f950d0-e102-4c6d-a794-da10c4d52395 
DEBUG [22:48:12.517] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.201837e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.201837e-05 0.00151302 
  - best initial criterion value(s) :  525.2016 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -525.2  |proj g|=       2.9295
At iterate     1  f =      -531.57  |proj g|=        5.6059
At iterate     2  f =      -532.82  |proj g|=        5.3984
At iterate     3  f =      -533.38  |proj g|=        4.4904
At iterate     4  f =      -533.68  |proj g|=        4.9055
At iterate     5  f =      -533.74  |proj g|=        4.8003
At iterate     6  f =      -533.86  |proj g|=        4.4831
At iterate     7  f =      -533.96  |proj g|=        4.2503
At iterate     8  f =      -534.03  |proj g|=        4.0781
At iterate     9  f =      -534.04  |proj g|=        4.1142
At iterate    10  f =      -534.04  |proj g|=        4.1215
At iterate    11  f =      -534.04  |proj g|=        4.1236
At iterate    12  f =      -534.04  |proj g|=        4.1277
At iterate    13  f =      -534.04  |proj g|=        4.1363
At iterate    14  f =      -534.04  |proj g|=        4.1485
At iterate    15  f =      -534.04  |proj g|=        4.1676
At iterate    16  f =      -534.04  |proj g|=        4.1967
At iterate    17  f =      -534.06  |proj g|=        4.2428
At iterate    18  f =      -534.09  |proj g|=        4.3172
At iterate    19  f =      -534.17  |proj g|=        4.4387
At iterate    20  f =       -534.4  |proj g|=        4.6309
At iterate    21  f =      -534.97  |proj g|=        4.8999
At iterate    22  f =      -536.21  |proj g|=        5.1324
At iterate    23  f =      -537.83  |proj g|=        4.3445
At iterate    24  f =      -538.66  |proj g|=        4.5433
At iterate    25  f =      -538.79  |proj g|=        4.4456
At iterate    26  f =      -538.84  |proj g|=        4.4046
At iterate    27  f =      -538.88  |proj g|=        4.3804
At iterate    28  f =      -539.04  |proj g|=        4.2424
At iterate    29  f =      -539.73  |proj g|=        3.8967
At iterate    30  f =      -540.08  |proj g|=         3.307
At iterate    31  f =      -541.48  |proj g|=         2.878
At iterate    32  f =      -545.09  |proj g|=         1.922
At iterate    33  f =      -551.76  |proj g|=         1.159
At iterate    34  f =       -557.6  |proj g|=       0.46698
At iterate    35  f =      -557.78  |proj g|=       0.54806
At iterate    36  f =      -557.94  |proj g|=       0.25099
At iterate    37  f =      -557.94  |proj g|=      0.098509
At iterate    38  f =      -557.94  |proj g|=       0.10672
At iterate    39  f =      -557.94  |proj g|=       0.10688

iterations 39
function evaluations 45
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.106881
final function value -557.943

F = -557.943
final  value -557.942749 
converged
 
INFO  [22:48:12.522] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:48:12.576] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:48:12.582] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:48:15.772] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:48:19.031] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:48:22.400] [mlr3]  Finished benchmark 
INFO  [22:48:22.478] [bbotk] Result of batch 93: 
INFO  [22:48:22.480] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:48:22.480] [bbotk]              9.476484                 7.351828                      0.05758663 
INFO  [22:48:22.480] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:48:22.480] [bbotk]                     1716         0.78 -0.9491983         <NA>    0.962043 
INFO  [22:48:22.480] [bbotk]                                 uhash 
INFO  [22:48:22.480] [bbotk]  b62b0d2d-dd29-466b-9c86-fe36ca3bf2e3 
DEBUG [22:48:23.733] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.195432e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.195432e-05 0.001500594 
  - best initial criterion value(s) :  492.808 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -492.81  |proj g|=       11.859
At iterate     1  f =       -509.2  |proj g|=        4.6183
At iterate     2  f =      -511.23  |proj g|=        3.9492
At iterate     3  f =      -512.02  |proj g|=        2.9004
At iterate     4  f =      -512.18  |proj g|=        2.5334
At iterate     5  f =      -512.21  |proj g|=        2.4496
At iterate     6  f =      -512.22  |proj g|=        2.4516
At iterate     7  f =      -512.22  |proj g|=        2.4675
At iterate     8  f =      -512.22  |proj g|=        2.4714
At iterate     9  f =      -512.22  |proj g|=        2.4721
At iterate    10  f =      -512.22  |proj g|=         2.477
At iterate    11  f =      -512.22  |proj g|=        2.4817
At iterate    12  f =      -512.22  |proj g|=        2.4889
At iterate    13  f =      -512.22  |proj g|=        2.4984
At iterate    14  f =      -512.22  |proj g|=        2.5108
At iterate    15  f =      -512.23  |proj g|=        2.5224
At iterate    16  f =      -512.25  |proj g|=        2.5213
At iterate    17  f =       -512.3  |proj g|=        2.4671
At iterate    18  f =       -512.4  |proj g|=        2.2801
At iterate    19  f =      -512.58  |proj g|=        2.1006
At iterate    20  f =       -512.6  |proj g|=        2.0496
At iterate    21  f =       -512.6  |proj g|=        2.0409
At iterate    22  f =       -512.6  |proj g|=        2.0379
At iterate    23  f =       -512.6  |proj g|=        2.0339
At iterate    24  f =       -512.6  |proj g|=        2.0297
At iterate    25  f =       -512.6  |proj g|=        2.0243
At iterate    26  f =      -512.61  |proj g|=        2.0202
At iterate    27  f =      -512.63  |proj g|=        2.0033
At iterate    28  f =      -512.67  |proj g|=        1.9902
At iterate    29  f =      -512.79  |proj g|=        1.9749
At iterate    30  f =      -513.07  |proj g|=        2.1199
At iterate    31  f =      -513.88  |proj g|=        2.7202
At iterate    32  f =      -514.04  |proj g|=        2.3797
At iterate    33  f =       -516.1  |proj g|=        2.2964
At iterate    34  f =      -519.09  |proj g|=        2.2868
At iterate    35  f =      -521.33  |proj g|=        1.9759
At iterate    36  f =      -521.56  |proj g|=         1.964
At iterate    37  f =       -521.6  |proj g|=        1.9553
At iterate    38  f =      -521.61  |proj g|=        1.9325
At iterate    39  f =      -521.62  |proj g|=         1.958
At iterate    40  f =      -521.62  |proj g|=        1.9599
At iterate    41  f =      -521.62  |proj g|=        1.9598

iterations 41
function evaluations 47
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.95984
final function value -521.62

F = -521.62
final  value -521.620170 
converged
 
INFO  [22:48:23.738] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:48:23.799] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:48:23.807] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:48:33.372] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:48:43.952] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:48:54.232] [mlr3]  Finished benchmark 
INFO  [22:48:54.305] [bbotk] Result of batch 94: 
INFO  [22:48:54.307] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:48:54.307] [bbotk]              7.654452                 8.495489                       0.4972141 
INFO  [22:48:54.307] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:48:54.307] [bbotk]                     4962        0.792 -0.9607529         <NA>   0.9779066 
INFO  [22:48:54.307] [bbotk]                                 uhash 
INFO  [22:48:54.307] [bbotk]  ee8252b5-9a4e-45de-8d97-e0281f7adace 
DEBUG [22:48:55.269] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.192943e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.192943e-05 0.001503274 
  - best initial criterion value(s) :  513.1692 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -513.17  |proj g|=      0.93125
At iterate     1  f =      -513.62  |proj g|=       0.92709
At iterate     2  f =      -513.65  |proj g|=       0.83829
At iterate     3  f =      -513.66  |proj g|=       0.82133
At iterate     4  f =      -513.66  |proj g|=        0.8214
At iterate     5  f =      -513.66  |proj g|=       0.82135

iterations 5
function evaluations 8
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.821345
final function value -513.663

F = -513.663
final  value -513.663024 
converged
 
INFO  [22:48:55.273] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:48:55.356] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:48:55.363] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:49:03.408] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:49:11.612] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:49:20.083] [mlr3]  Finished benchmark 
INFO  [22:49:20.162] [bbotk] Result of batch 95: 
INFO  [22:49:20.164] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:49:20.164] [bbotk]              3.803254                 4.104927                      0.05707306 
INFO  [22:49:20.164] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:49:20.164] [bbotk]                     4247        0.713 -0.9642286         <NA>   0.9650814 
INFO  [22:49:20.164] [bbotk]                                 uhash 
INFO  [22:49:20.164] [bbotk]  ee64dd9e-647e-4c3d-a5fd-683c9e5c41f2 
DEBUG [22:49:21.412] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.184342e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.184342e-05 0.001492613 
  - best initial criterion value(s) :  524.9166 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -524.92  |proj g|=       4.5631
At iterate     1  f =      -540.21  |proj g|=        4.1533
At iterate     2  f =      -545.79  |proj g|=        3.6904
At iterate     3  f =      -555.41  |proj g|=        2.4025
At iterate     4  f =      -555.93  |proj g|=        2.2528
At iterate     5  f =      -556.59  |proj g|=        2.2051
At iterate     6  f =      -557.81  |proj g|=        2.1806
At iterate     7  f =      -558.03  |proj g|=        2.2198
At iterate     8  f =      -558.07  |proj g|=        2.2347
At iterate     9  f =      -558.07  |proj g|=        2.2418
At iterate    10  f =      -558.07  |proj g|=        2.2464
At iterate    11  f =      -558.07  |proj g|=        2.2447
At iterate    12  f =      -558.07  |proj g|=        2.2447
At iterate    13  f =      -558.07  |proj g|=        2.2447
At iterate    14  f =      -558.07  |proj g|=        2.2482
At iterate    15  f =      -558.07  |proj g|=        2.2482
At iterate    16  f =      -558.07  |proj g|=        2.2485
At iterate    17  f =       -558.1  |proj g|=        2.2517
At iterate    18  f =      -558.39  |proj g|=        2.2975
At iterate    19  f =      -558.58  |proj g|=        2.3368
At iterate    20  f =      -558.58  |proj g|=        2.3226
At iterate    21  f =      -558.71  |proj g|=        2.3596
At iterate    22  f =      -558.72  |proj g|=        2.3673
At iterate    23  f =      -558.72  |proj g|=        2.3697
At iterate    24  f =      -558.72  |proj g|=          2.37
At iterate    25  f =      -558.72  |proj g|=          2.37

iterations 25
function evaluations 34
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.37001
final function value -558.72

F = -558.72
final  value -558.719820 
converged
 
INFO  [22:49:21.417] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:49:21.474] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:49:21.482] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:49:23.305] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:49:24.840] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:49:26.515] [mlr3]  Finished benchmark 
INFO  [22:49:26.585] [bbotk] Result of batch 96: 
INFO  [22:49:26.587] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:49:26.587] [bbotk]              3.754493                 6.921304                       0.4521163 
INFO  [22:49:26.587] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:49:26.587] [bbotk]                      517        0.827 -0.9545505         <NA>   0.9644658 
INFO  [22:49:26.587] [bbotk]                                 uhash 
INFO  [22:49:26.587] [bbotk]  fc9a7d1c-a529-42a0-bfa9-5978c76ac4ea 
DEBUG [22:49:27.907] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.176224e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.176224e-05 0.001476071 
  - best initial criterion value(s) :  533.9412 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -533.94  |proj g|=       4.2407
At iterate     1  f =      -544.66  |proj g|=        5.5921
At iterate     2  f =      -546.38  |proj g|=        5.6449
At iterate     3  f =      -547.67  |proj g|=        5.5618
At iterate     4  f =      -547.72  |proj g|=        5.5096
At iterate     5  f =      -547.73  |proj g|=        5.5351
At iterate     6  f =      -547.73  |proj g|=        5.5413
At iterate     7  f =      -547.74  |proj g|=        5.6074
At iterate     8  f =      -547.75  |proj g|=        5.6543
At iterate     9  f =      -547.78  |proj g|=        5.7588
At iterate    10  f =      -547.86  |proj g|=        5.8846
At iterate    11  f =      -548.09  |proj g|=        6.0918
At iterate    12  f =      -548.68  |proj g|=        6.3691
At iterate    13  f =      -550.09  |proj g|=        6.6713
At iterate    14  f =       -552.8  |proj g|=         6.804
At iterate    15  f =      -552.87  |proj g|=         6.648
At iterate    16  f =      -557.51  |proj g|=         5.909
At iterate    17  f =      -566.24  |proj g|=        3.5896
At iterate    18  f =       -569.5  |proj g|=         2.819
At iterate    19  f =      -575.98  |proj g|=        1.3333
At iterate    20  f =      -577.53  |proj g|=       0.39629
At iterate    21  f =      -578.44  |proj g|=       0.42697
At iterate    22  f =      -578.46  |proj g|=       0.42426
At iterate    23  f =      -578.46  |proj g|=       0.14837
At iterate    24  f =      -578.46  |proj g|=       0.14839
At iterate    25  f =      -578.46  |proj g|=        0.1484
At iterate    26  f =      -578.46  |proj g|=        0.1482
At iterate    27  f =      -578.46  |proj g|=        0.4233
At iterate    28  f =      -578.46  |proj g|=       0.42692
At iterate    29  f =      -578.46  |proj g|=       0.42874
At iterate    30  f =      -578.47  |proj g|=       0.43044
At iterate    31  f =      -578.47  |proj g|=        0.4328
At iterate    32  f =      -578.48  |proj g|=       0.43298
At iterate    33  f =      -578.48  |proj g|=       0.43091
At iterate    34  f =      -578.48  |proj g|=      0.081768
At iterate    35  f =      -578.48  |proj g|=       0.03795
At iterate    36  f =      -578.48  |proj g|=     0.0011449
At iterate    37  f =      -578.48  |proj g|=     0.0004953

iterations 37
function evaluations 46
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000495297
final function value -578.485

F = -578.485
final  value -578.484887 
converged
 
INFO  [22:49:27.911] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:49:27.980] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:49:27.986] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:49:38.123] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:49:50.356] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:50:01.526] [mlr3]  Finished benchmark 
INFO  [22:50:01.594] [bbotk] Result of batch 97: 
INFO  [22:50:01.596] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:50:01.596] [bbotk]              9.528542                 6.859609                       0.2479522 
INFO  [22:50:01.596] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:50:01.596] [bbotk]                     4063         0.72 -0.9470313         <NA>   0.9764866 
INFO  [22:50:01.596] [bbotk]                                 uhash 
INFO  [22:50:01.596] [bbotk]  1704fa34-e2b0-4eb6-ba64-8d44c46fae1e 
DEBUG [22:50:02.842] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.171985e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.171985e-05 0.001476639 
  - best initial criterion value(s) :  544.0452 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -544.05  |proj g|=       4.0342
At iterate     1  f =      -560.02  |proj g|=        2.5194
At iterate     2  f =      -560.31  |proj g|=        2.4894
At iterate     3  f =      -560.78  |proj g|=        2.3964
At iterate     4  f =      -561.75  |proj g|=        2.4126
At iterate     5  f =      -565.77  |proj g|=        2.6048
At iterate     6  f =      -566.66  |proj g|=        2.7173
At iterate     7  f =      -566.99  |proj g|=        2.8188
At iterate     8  f =      -567.05  |proj g|=        2.8803
At iterate     9  f =      -567.06  |proj g|=        2.9227
At iterate    10  f =      -567.06  |proj g|=        2.9223
At iterate    11  f =      -567.06  |proj g|=        2.9215
At iterate    12  f =      -567.06  |proj g|=        2.9217
At iterate    13  f =      -567.06  |proj g|=         2.923
At iterate    14  f =      -567.06  |proj g|=        2.9245
At iterate    15  f =      -567.07  |proj g|=        2.9269
At iterate    16  f =      -567.07  |proj g|=        2.9305
At iterate    17  f =      -567.07  |proj g|=        2.9342
At iterate    18  f =      -567.09  |proj g|=         2.934
At iterate    19  f =      -567.11  |proj g|=        2.9183
At iterate    20  f =      -567.16  |proj g|=        2.8728
At iterate    21  f =      -567.16  |proj g|=        2.8858
At iterate    22  f =      -567.23  |proj g|=        2.8302
At iterate    23  f =      -567.49  |proj g|=        2.7188
At iterate    24  f =      -567.74  |proj g|=        2.6368
At iterate    25  f =      -567.77  |proj g|=        2.6571
At iterate    26  f =      -567.77  |proj g|=        2.6478
At iterate    27  f =      -567.77  |proj g|=        2.6491
At iterate    28  f =      -567.77  |proj g|=        2.6495
At iterate    29  f =      -567.77  |proj g|=        2.6496
At iterate    30  f =      -567.77  |proj g|=        2.6498
At iterate    31  f =      -567.77  |proj g|=        2.6501
At iterate    32  f =      -567.77  |proj g|=        2.6515
At iterate    33  f =      -567.77  |proj g|=        2.6509
At iterate    34  f =      -567.77  |proj g|=        2.6536
At iterate    35  f =      -567.77  |proj g|=        2.6559
At iterate    36  f =       -567.8  |proj g|=        2.6519
At iterate    37  f =      -567.91  |proj g|=        2.7386
At iterate    38  f =      -568.07  |proj g|=        2.7105
At iterate    39  f =      -568.07  |proj g|=        2.6957
At iterate    40  f =      -569.95  |proj g|=        2.2982
At iterate    41  f =      -572.49  |proj g|=        1.7377
At iterate    42  f =      -575.53  |proj g|=       0.50843
At iterate    43  f =      -576.79  |proj g|=       0.46607
At iterate    44  f =      -577.17  |proj g|=       0.44014
At iterate    45  f =      -577.56  |proj g|=       0.71046
At iterate    46  f =      -577.84  |proj g|=       0.61433
At iterate    47  f =      -578.03  |proj g|=        0.6127
At iterate    48  f =      -578.04  |proj g|=        0.2045
At iterate    49  f =      -578.04  |proj g|=      0.053902
At iterate    50  f =      -578.04  |proj g|=      0.011146
At iterate    51  f =      -578.04  |proj g|=      0.004569

iterations 51
function evaluations 65
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00456903
final function value -578.039

F = -578.039
final  value -578.039055 
converged
 
INFO  [22:50:02.846] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:50:02.901] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:50:02.908] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:50:09.270] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:50:16.592] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:50:24.181] [mlr3]  Finished benchmark 
INFO  [22:50:24.250] [bbotk] Result of batch 98: 
INFO  [22:50:24.252] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:50:24.252] [bbotk]              3.456439                 6.279765                       0.3099744 
INFO  [22:50:24.252] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:50:24.252] [bbotk]                     2704         0.72 -0.9524727         <NA>   0.9718757 
INFO  [22:50:24.252] [bbotk]                                 uhash 
INFO  [22:50:24.252] [bbotk]  08b36203-7aeb-4722-9886-155ab8c054b7 
DEBUG [22:50:25.411] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.163696e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.163696e-05 0.001466678 
  - best initial criterion value(s) :  524.7631 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -524.76  |proj g|=       8.4909
At iterate     1  f =      -527.26  |proj g|=        8.5431
At iterate     2  f =         -528  |proj g|=        8.3703
At iterate     3  f =      -530.49  |proj g|=        6.2246
At iterate     4  f =      -533.53  |proj g|=        6.5007
At iterate     5  f =      -536.64  |proj g|=        5.6842
At iterate     6  f =      -539.94  |proj g|=         4.287
At iterate     7  f =      -540.15  |proj g|=        4.1221
At iterate     8  f =      -540.21  |proj g|=         4.038
At iterate     9  f =      -540.21  |proj g|=        4.0516
At iterate    10  f =      -540.21  |proj g|=        4.0504
At iterate    11  f =      -540.21  |proj g|=        4.0499
At iterate    12  f =      -540.21  |proj g|=        4.0492
At iterate    13  f =      -540.21  |proj g|=        4.0469
At iterate    14  f =      -540.21  |proj g|=        4.0436
At iterate    15  f =      -540.21  |proj g|=        4.0366
At iterate    16  f =      -540.21  |proj g|=        4.0234
At iterate    17  f =      -540.22  |proj g|=        3.9963
At iterate    18  f =      -540.24  |proj g|=        3.9448
At iterate    19  f =      -540.27  |proj g|=         3.872
At iterate    20  f =      -540.28  |proj g|=         3.881
At iterate    21  f =      -540.28  |proj g|=        3.8471
At iterate    22  f =       -540.9  |proj g|=        3.5142
At iterate    23  f =      -543.33  |proj g|=        2.8373
At iterate    24  f =      -550.87  |proj g|=        1.6791
At iterate    25  f =      -559.45  |proj g|=        1.1303
At iterate    26  f =      -559.69  |proj g|=       0.79976
At iterate    27  f =      -562.21  |proj g|=       0.77572
At iterate    28  f =      -565.08  |proj g|=       0.72343
At iterate    29  f =       -565.6  |proj g|=       0.73458
At iterate    30  f =      -565.71  |proj g|=       0.94853
At iterate    31  f =      -565.72  |proj g|=        1.0319
At iterate    32  f =      -565.72  |proj g|=        1.0563
At iterate    33  f =      -565.72  |proj g|=        1.0706
At iterate    34  f =      -565.72  |proj g|=        1.0712

iterations 34
function evaluations 43
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.07122
final function value -565.719

F = -565.719
final  value -565.718751 
converged
 
INFO  [22:50:25.415] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:50:25.471] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:50:25.500] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:50:35.972] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:50:45.553] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:50:55.428] [mlr3]  Finished benchmark 
INFO  [22:50:55.498] [bbotk] Result of batch 99: 
INFO  [22:50:55.500] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:50:55.500] [bbotk]              9.432335                 5.034082                       0.2343357 
INFO  [22:50:55.500] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:50:55.500] [bbotk]                     3450        0.734 -0.9587688         <NA>   0.9758181 
INFO  [22:50:55.500] [bbotk]                                 uhash 
INFO  [22:50:55.500] [bbotk]  dc8459ac-1d8c-4cb9-8039-93cf1aae9824 
DEBUG [22:50:56.878] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.158732e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.158732e-05 0.001465912 
  - best initial criterion value(s) :  560.0923 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -560.09  |proj g|=       1.3259
At iterate     1  f =      -562.52  |proj g|=        2.6645
At iterate     2  f =      -562.85  |proj g|=        2.3707
At iterate     3  f =      -562.95  |proj g|=        2.0824
At iterate     4  f =      -562.96  |proj g|=        2.1261
At iterate     5  f =      -563.11  |proj g|=        2.3677
At iterate     6  f =      -563.36  |proj g|=        2.7072
At iterate     7  f =      -563.72  |proj g|=        3.1212
At iterate     8  f =      -564.02  |proj g|=        3.3272
At iterate     9  f =       -564.1  |proj g|=        3.3287
At iterate    10  f =      -564.11  |proj g|=         3.273
At iterate    11  f =      -564.11  |proj g|=        3.2504
At iterate    12  f =      -564.11  |proj g|=        3.2471
At iterate    13  f =      -564.11  |proj g|=        3.2444
At iterate    14  f =      -564.11  |proj g|=        3.2411
At iterate    15  f =      -564.11  |proj g|=        3.2311
At iterate    16  f =      -564.11  |proj g|=         3.218
At iterate    17  f =      -564.11  |proj g|=        3.1946
At iterate    18  f =      -564.12  |proj g|=        3.1569
At iterate    19  f =      -564.14  |proj g|=        3.0931
At iterate    20  f =      -564.19  |proj g|=        2.9822
At iterate    21  f =      -564.33  |proj g|=        2.7841
At iterate    22  f =      -564.73  |proj g|=        2.4217
At iterate    23  f =      -565.79  |proj g|=        1.7715
At iterate    24  f =      -568.14  |proj g|=       0.88863
At iterate    25  f =      -570.55  |proj g|=       0.78789
At iterate    26  f =      -571.76  |proj g|=        1.4713
At iterate    27  f =      -572.03  |proj g|=         1.827
At iterate    28  f =      -572.06  |proj g|=        1.9588
At iterate    29  f =      -572.06  |proj g|=        1.9834
At iterate    30  f =      -572.06  |proj g|=        1.9849
At iterate    31  f =      -572.06  |proj g|=        1.9855
At iterate    32  f =      -572.06  |proj g|=        1.9877
At iterate    33  f =      -572.06  |proj g|=        1.9909
At iterate    34  f =      -572.06  |proj g|=        1.9962
At iterate    35  f =      -572.06  |proj g|=         2.004
At iterate    36  f =      -572.06  |proj g|=        2.0155
At iterate    37  f =      -572.06  |proj g|=        2.0303
At iterate    38  f =      -572.07  |proj g|=        2.0433
At iterate    39  f =      -572.09  |proj g|=         2.034
At iterate    40  f =      -572.11  |proj g|=        1.9552
At iterate    41  f =      -572.13  |proj g|=        1.8504
At iterate    42  f =      -572.13  |proj g|=        1.7901
At iterate    43  f =      -572.13  |proj g|=        1.7962
At iterate    44  f =      -572.13  |proj g|=         1.796

iterations 44
function evaluations 49
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.79598
final function value -572.131

F = -572.131
final  value -572.131018 
converged
 
INFO  [22:50:56.883] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:50:56.939] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:50:56.946] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:50:59.887] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:51:02.921] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:51:06.204] [mlr3]  Finished benchmark 
INFO  [22:51:06.298] [bbotk] Result of batch 100: 
INFO  [22:51:06.300] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:51:06.300] [bbotk]              2.162111                 3.841133                       0.4656311 
INFO  [22:51:06.300] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:51:06.300] [bbotk]                     1112        0.892 -0.9592688         <NA>   0.9559555 
INFO  [22:51:06.300] [bbotk]                                 uhash 
INFO  [22:51:06.300] [bbotk]  649088fc-598a-4900-888d-f1f68d8ba6e0 
DEBUG [22:51:07.331] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.162047e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.162047e-05 0.001468381 
  - best initial criterion value(s) :  538.5805 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -538.58  |proj g|=       8.0317
At iterate     1  f =      -579.16  |proj g|=        3.2368
At iterate     2  f =      -583.33  |proj g|=        2.6889
At iterate     3  f =      -589.85  |proj g|=       0.86406
At iterate     4  f =         -590  |proj g|=       0.52524
At iterate     5  f =       -590.1  |proj g|=       0.65831
At iterate     6  f =      -590.32  |proj g|=       0.65116
At iterate     7  f =      -590.71  |proj g|=        0.6288
At iterate     8  f =      -590.95  |proj g|=       0.38129
At iterate     9  f =      -590.97  |proj g|=        0.3894
At iterate    10  f =      -590.97  |proj g|=       0.38957
At iterate    11  f =      -590.97  |proj g|=       0.39002
At iterate    12  f =      -590.97  |proj g|=       0.39004

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.390043
final function value -590.966

F = -590.966
final  value -590.966224 
converged
 
INFO  [22:51:07.335] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:51:07.391] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:51:07.398] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:51:09.217] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:51:12.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:51:14.354] [mlr3]  Finished benchmark 
INFO  [22:51:14.424] [bbotk] Result of batch 101: 
INFO  [22:51:14.425] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:51:14.425] [bbotk]              3.262437                 2.224187                       0.1489529 
INFO  [22:51:14.425] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:51:14.425] [bbotk]                      576        0.724 -0.9531537         <NA>   0.9491498 
INFO  [22:51:14.425] [bbotk]                                 uhash 
INFO  [22:51:14.425] [bbotk]  ddc0ff98-1e6b-4369-b824-337a7487f3ee 
DEBUG [22:51:15.596] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.18159e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.18159e-05 0.001504356 
  - best initial criterion value(s) :  566.3538 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -566.35  |proj g|=       2.4569
At iterate     1  f =      -578.09  |proj g|=        1.9423
At iterate     2  f =      -583.72  |proj g|=        3.3582
At iterate     3  f =      -584.34  |proj g|=        3.4218
At iterate     4  f =      -584.72  |proj g|=        3.4884
At iterate     5  f =      -584.75  |proj g|=        3.5258
At iterate     6  f =      -584.76  |proj g|=        3.5643
At iterate     7  f =      -584.76  |proj g|=        3.5971
At iterate     8  f =      -584.76  |proj g|=        3.6045
At iterate     9  f =      -584.76  |proj g|=        3.6047

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.60465
final function value -584.763

F = -584.763
final  value -584.763417 
converged
 
INFO  [22:51:15.600] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:51:15.658] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:51:15.665] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:51:21.754] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:51:28.019] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:51:33.578] [mlr3]  Finished benchmark 
INFO  [22:51:33.648] [bbotk] Result of batch 102: 
INFO  [22:51:33.650] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:51:33.650] [bbotk]              8.931446                 6.616932                      0.03442253 
INFO  [22:51:33.650] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:51:33.650] [bbotk]                     2107         0.86 -0.9562863         <NA>   0.9582526 
INFO  [22:51:33.650] [bbotk]                                 uhash 
INFO  [22:51:33.650] [bbotk]  0bff1556-ad6c-4d80-9943-e5ece5d34f33 
DEBUG [22:51:34.800] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.180333e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.180333e-05 0.001500378 
  - best initial criterion value(s) :  561.5208 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -561.52  |proj g|=       7.5055
At iterate     1  f =         -582  |proj g|=       0.82102
At iterate     2  f =       -586.3  |proj g|=       0.78316
At iterate     3  f =      -590.79  |proj g|=       0.93075
At iterate     4  f =       -591.5  |proj g|=          1.73
At iterate     5  f =      -591.79  |proj g|=        1.5967
At iterate     6  f =      -593.57  |proj g|=        1.2689
At iterate     7  f =      -594.77  |proj g|=        1.2889
At iterate     8  f =      -594.79  |proj g|=        1.1408
At iterate     9  f =      -595.06  |proj g|=        1.2436
At iterate    10  f =      -595.08  |proj g|=        1.2477
At iterate    11  f =      -595.32  |proj g|=       0.80119
At iterate    12  f =      -596.41  |proj g|=       0.70307
At iterate    13  f =      -597.91  |proj g|=       0.61158
At iterate    14  f =      -597.97  |proj g|=       0.54093
At iterate    15  f =         -598  |proj g|=        0.5422
At iterate    16  f =         -598  |proj g|=       0.54212
At iterate    17  f =         -598  |proj g|=        0.5421
At iterate    18  f =         -598  |proj g|=        0.5421
At iterate    19  f =         -598  |proj g|=        0.5421
At iterate    20  f =         -598  |proj g|=        0.5421

iterations 20
function evaluations 27
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.5421
final function value -597.996

F = -597.996
final  value -597.996471 
converged
 
INFO  [22:51:34.804] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:51:34.864] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:51:34.872] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:51:48.646] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:52:03.863] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:52:17.529] [mlr3]  Finished benchmark 
INFO  [22:52:17.597] [bbotk] Result of batch 103: 
INFO  [22:52:17.599] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:52:17.599] [bbotk]              6.832449                 7.686994                       0.3760503 
INFO  [22:52:17.599] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:52:17.599] [bbotk]                     4603         0.75 -0.9514922         <NA>   0.9765972 
INFO  [22:52:17.599] [bbotk]                                 uhash 
INFO  [22:52:17.599] [bbotk]  4b0cae04-824b-46ab-83c7-1fc0a63a39fd 
DEBUG [22:52:18.635] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.176605e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.176605e-05 0.001501661 
  - best initial criterion value(s) :  567.514 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -567.51  |proj g|=         4.66
At iterate     1  f =      -580.12  |proj g|=        4.4005
At iterate     2  f =      -589.99  |proj g|=        2.3732
At iterate     3  f =      -590.74  |proj g|=         1.264
At iterate     4  f =      -591.56  |proj g|=        1.4997
At iterate     5  f =      -591.59  |proj g|=        1.5264
At iterate     6  f =      -591.59  |proj g|=         1.538
At iterate     7  f =       -591.6  |proj g|=        1.5265
At iterate     8  f =       -591.6  |proj g|=        1.5271
At iterate     9  f =       -591.6  |proj g|=        1.5271

iterations 9
function evaluations 15
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.52712
final function value -591.596

F = -591.596
final  value -591.596122 
converged
 
INFO  [22:52:18.639] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:52:18.693] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:52:18.700] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:52:28.341] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:52:38.111] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:52:48.095] [mlr3]  Finished benchmark 
INFO  [22:52:48.164] [bbotk] Result of batch 104: 
INFO  [22:52:48.166] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:52:48.166] [bbotk]              5.771496                 2.679977                        0.422285 
INFO  [22:52:48.166] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:52:48.166] [bbotk]                     3573        0.744 -0.9572945         <NA>   0.9765369 
INFO  [22:52:48.166] [bbotk]                                 uhash 
INFO  [22:52:48.166] [bbotk]  0f630029-0b72-4f74-99bb-e236aee495f8 
DEBUG [22:52:49.188] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.172783e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.172783e-05 0.001501786 
  - best initial criterion value(s) :  588.5154 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -588.52  |proj g|=       2.1521
At iterate     1  f =         -589  |proj g|=         2.426
At iterate     2  f =      -589.16  |proj g|=        2.3893
At iterate     3  f =      -589.29  |proj g|=        2.3622
At iterate     4  f =       -589.3  |proj g|=        2.3809
At iterate     5  f =       -589.3  |proj g|=        2.3788
At iterate     6  f =       -589.3  |proj g|=        2.3788

iterations 6
function evaluations 11
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.37878
final function value -589.295

F = -589.295
final  value -589.295130 
converged
 
INFO  [22:52:49.192] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:52:49.249] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:52:49.256] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:52:56.860] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:53:03.890] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:53:09.766] [mlr3]  Finished benchmark 
INFO  [22:53:09.834] [bbotk] Result of batch 105: 
INFO  [22:53:09.836] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:53:09.836] [bbotk]               8.71641                  8.86738                       0.1699925 
INFO  [22:53:09.836] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:53:09.836] [bbotk]                     2300        0.765 -0.9590253         <NA>   0.9722926 
INFO  [22:53:09.836] [bbotk]                                 uhash 
INFO  [22:53:09.836] [bbotk]  2e7a851e-faf6-42ad-9784-39fde4494986 
DEBUG [22:53:10.955] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.165201e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.165201e-05 0.001488567 
  - best initial criterion value(s) :  569.2883 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -569.29  |proj g|=       9.3447
At iterate     1  f =      -574.04  |proj g|=        9.2372
At iterate     2  f =      -578.65  |proj g|=        7.0191
At iterate     3  f =      -582.52  |proj g|=        3.6063
At iterate     4  f =      -583.32  |proj g|=        3.8544
At iterate     5  f =      -583.34  |proj g|=        3.8613
At iterate     6  f =      -583.79  |proj g|=        3.9109
At iterate     7  f =      -586.87  |proj g|=        4.0582
At iterate     8  f =         -593  |proj g|=        4.0836
At iterate     9  f =      -601.46  |proj g|=        3.5211
At iterate    10  f =       -604.5  |proj g|=        3.1434
At iterate    11  f =      -604.55  |proj g|=        2.9076
At iterate    12  f =      -604.64  |proj g|=        2.9939
At iterate    13  f =       -604.7  |proj g|=        3.0125
At iterate    14  f =       -604.7  |proj g|=        3.0033
At iterate    15  f =      -604.72  |proj g|=        2.9879
At iterate    16  f =      -604.72  |proj g|=        2.9802
At iterate    17  f =      -604.72  |proj g|=        2.9766
At iterate    18  f =      -604.72  |proj g|=        2.9766

iterations 18
function evaluations 27
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.97662
final function value -604.72

F = -604.72
final  value -604.720471 
converged
 
INFO  [22:53:10.959] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:53:11.016] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:53:11.023] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:53:19.192] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:53:28.048] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:53:36.565] [mlr3]  Finished benchmark 
INFO  [22:53:36.634] [bbotk] Result of batch 106: 
INFO  [22:53:36.636] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:53:36.636] [bbotk]              9.435192                 8.637517                       0.4622911 
INFO  [22:53:36.636] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [22:53:36.636] [bbotk]                     3116        0.754 -0.950995         <NA>   0.9770711 
INFO  [22:53:36.636] [bbotk]                                 uhash 
INFO  [22:53:36.636] [bbotk]  4b8b60ee-5152-46dd-8872-32493a42f0ab 
DEBUG [22:53:38.074] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.162065e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.162065e-05 0.001487269 
  - best initial criterion value(s) :  593.6556 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -593.66  |proj g|=       6.5439
At iterate     1  f =      -594.16  |proj g|=        7.1055
At iterate     2  f =      -596.34  |proj g|=        6.7119
At iterate     3  f =      -598.44  |proj g|=        5.4116
At iterate     4  f =      -599.89  |proj g|=         4.494
At iterate     5  f =      -602.51  |proj g|=        2.0693
At iterate     6  f =      -602.66  |proj g|=        2.1099
At iterate     7  f =      -602.66  |proj g|=        2.1404
At iterate     8  f =      -602.66  |proj g|=        2.1319
At iterate     9  f =      -602.66  |proj g|=        2.1331
At iterate    10  f =      -602.66  |proj g|=         2.135
At iterate    11  f =      -602.66  |proj g|=        2.1522
At iterate    12  f =      -602.67  |proj g|=        2.1776
At iterate    13  f =      -602.69  |proj g|=        2.2945
At iterate    14  f =       -602.7  |proj g|=        2.2634
At iterate    15  f =      -602.74  |proj g|=        2.3845
At iterate    16  f =       -602.9  |proj g|=         2.627
At iterate    17  f =      -603.25  |proj g|=        2.8695
At iterate    18  f =      -604.04  |proj g|=        2.9776
At iterate    19  f =      -605.51  |proj g|=        2.5869
At iterate    20  f =      -605.54  |proj g|=        2.6446
At iterate    21  f =       -607.2  |proj g|=        1.9218
At iterate    22  f =      -608.69  |proj g|=        1.8613
At iterate    23  f =      -609.41  |proj g|=        1.8558
At iterate    24  f =      -609.45  |proj g|=        1.8312
At iterate    25  f =      -609.46  |proj g|=        1.8328
At iterate    26  f =      -609.46  |proj g|=         1.832
At iterate    27  f =      -609.46  |proj g|=        1.8316
At iterate    28  f =      -609.54  |proj g|=        1.8202
At iterate    29  f =      -609.85  |proj g|=        1.7613
At iterate    30  f =      -610.85  |proj g|=        1.5918
At iterate    31  f =      -611.74  |proj g|=        1.4753
At iterate    32  f =      -612.81  |proj g|=       0.96222
At iterate    33  f =         -614  |proj g|=       0.66859
At iterate    34  f =      -614.13  |proj g|=       0.65708
At iterate    35  f =      -614.21  |proj g|=       0.64688
At iterate    36  f =      -614.22  |proj g|=       0.13954
At iterate    37  f =      -614.22  |proj g|=      0.046346
At iterate    38  f =      -614.22  |proj g|=     0.0092508
At iterate    39  f =      -614.22  |proj g|=       0.00925

iterations 39
function evaluations 55
segments explored during Cauchy searches 41
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00924996
final function value -614.22

F = -614.22
final  value -614.220048 
converged
 
INFO  [22:53:38.078] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:53:38.137] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:53:38.144] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:53:43.420] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:53:48.677] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:53:55.263] [mlr3]  Finished benchmark 
INFO  [22:53:55.335] [bbotk] Result of batch 107: 
INFO  [22:53:55.336] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:53:55.336] [bbotk]              9.019941                  6.41015                      0.02877636 
INFO  [22:53:55.336] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:53:55.336] [bbotk]                     2064         0.74 -0.9548581         <NA>   0.9557296 
INFO  [22:53:55.336] [bbotk]                                 uhash 
INFO  [22:53:55.336] [bbotk]  267da408-3689-46f3-87a5-135e1a94767e 
DEBUG [22:53:56.535] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.165414e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.165414e-05 0.001489875 
  - best initial criterion value(s) :  608.9044 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -608.9  |proj g|=       3.5615
At iterate     1  f =      -611.21  |proj g|=        5.2292
At iterate     2  f =      -612.55  |proj g|=        4.0655
At iterate     3  f =      -613.64  |proj g|=        4.2875
At iterate     4  f =      -614.29  |proj g|=        4.1292
At iterate     5  f =      -614.35  |proj g|=        4.3592
At iterate     6  f =      -614.37  |proj g|=        4.2575
At iterate     7  f =      -614.37  |proj g|=        4.2694
At iterate     8  f =      -614.37  |proj g|=        4.2668
At iterate     9  f =      -614.37  |proj g|=         4.266
At iterate    10  f =      -614.37  |proj g|=         4.261
At iterate    11  f =      -614.37  |proj g|=        4.2548
At iterate    12  f =      -614.37  |proj g|=        4.2438
At iterate    13  f =      -614.37  |proj g|=        4.2277
At iterate    14  f =      -614.38  |proj g|=        4.1987
At iterate    15  f =      -614.39  |proj g|=        4.1539
At iterate    16  f =      -614.42  |proj g|=        4.0892
At iterate    17  f =      -614.48  |proj g|=        4.0257
At iterate    18  f =      -614.56  |proj g|=        3.9867
At iterate    19  f =      -614.65  |proj g|=        3.9448
At iterate    20  f =      -614.79  |proj g|=        3.9644
At iterate    21  f =      -614.97  |proj g|=        3.8881
At iterate    22  f =      -615.38  |proj g|=        3.7655
At iterate    23  f =      -616.04  |proj g|=        3.0889
At iterate    24  f =      -616.74  |proj g|=        3.0704
At iterate    25  f =      -617.64  |proj g|=        2.3084
At iterate    26  f =      -618.81  |proj g|=        1.7575
At iterate    27  f =      -624.66  |proj g|=       0.77987
At iterate    28  f =      -626.95  |proj g|=        1.2678
At iterate    29  f =      -627.24  |proj g|=        1.0596
At iterate    30  f =      -628.16  |proj g|=       0.52846
At iterate    31  f =      -628.25  |proj g|=       0.67041
At iterate    32  f =      -628.27  |proj g|=       0.65224
At iterate    33  f =      -628.27  |proj g|=       0.65012
At iterate    34  f =      -628.27  |proj g|=       0.64901
At iterate    35  f =      -628.27  |proj g|=       0.64852

iterations 35
function evaluations 42
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.648522
final function value -628.272

F = -628.272
final  value -628.271599 
converged
 
INFO  [22:53:56.540] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:53:56.596] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:53:56.604] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:54:01.691] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:54:05.495] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:54:09.337] [mlr3]  Finished benchmark 
INFO  [22:54:09.408] [bbotk] Result of batch 108: 
INFO  [22:54:09.410] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:54:09.410] [bbotk]              9.851433                 9.678906                       0.3607166 
INFO  [22:54:09.410] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:54:09.410] [bbotk]                     1942        0.743 -0.9487039         <NA>   0.9749492 
INFO  [22:54:09.410] [bbotk]                                 uhash 
INFO  [22:54:09.410] [bbotk]  e67ee415-d888-40d7-ad9e-db268d1465e9 
DEBUG [22:54:10.617] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.160041e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.160041e-05 0.00147783 
  - best initial criterion value(s) :  575.023 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -575.02  |proj g|=       2.4104
At iterate     1  f =      -585.72  |proj g|=        1.9197
At iterate     2  f =      -587.23  |proj g|=        2.3193
At iterate     3  f =      -587.49  |proj g|=        2.2206
At iterate     4  f =      -587.56  |proj g|=        2.1143
At iterate     5  f =      -587.56  |proj g|=        2.1311
At iterate     6  f =      -587.56  |proj g|=        2.1297
At iterate     7  f =      -587.56  |proj g|=        2.1291
At iterate     8  f =      -587.56  |proj g|=        2.1292
At iterate     9  f =      -587.56  |proj g|=        2.1296
At iterate    10  f =      -587.56  |proj g|=        2.1302
At iterate    11  f =      -587.56  |proj g|=        2.1311
At iterate    12  f =      -587.56  |proj g|=        2.1325
At iterate    13  f =      -587.56  |proj g|=        2.1342
At iterate    14  f =      -587.57  |proj g|=        2.1353
At iterate    15  f =      -587.57  |proj g|=        2.1336
At iterate    16  f =      -587.57  |proj g|=        2.1351
At iterate    17  f =      -587.59  |proj g|=        2.1243
At iterate    18  f =      -587.59  |proj g|=        2.1316
At iterate    19  f =      -587.62  |proj g|=        2.1121
At iterate    20  f =      -596.39  |proj g|=       0.72715
At iterate    21  f =      -596.48  |proj g|=       0.34468
At iterate    22  f =      -596.49  |proj g|=       0.31233
At iterate    23  f =      -596.49  |proj g|=        0.3048
At iterate    24  f =      -596.49  |proj g|=       0.30375
At iterate    25  f =      -596.49  |proj g|=       0.30339

iterations 25
function evaluations 32
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.303391
final function value -596.489

F = -596.489
final  value -596.488913 
converged
 
INFO  [22:54:10.622] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:54:10.680] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:54:10.687] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:54:11.945] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:54:13.275] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:54:14.459] [mlr3]  Finished benchmark 
INFO  [22:54:14.529] [bbotk] Result of batch 109: 
INFO  [22:54:14.531] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:54:14.531] [bbotk]              7.360133                 6.268618                        0.316067 
INFO  [22:54:14.531] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:54:14.531] [bbotk]                      418        0.794 -0.9622077         <NA>   0.9646398 
INFO  [22:54:14.531] [bbotk]                                 uhash 
INFO  [22:54:14.531] [bbotk]  5c98a1d0-364b-45bf-9347-3bb9ae732944 
DEBUG [22:54:15.707] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.152738e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.152738e-05 0.001463752 
  - best initial criterion value(s) :  599.8365 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -599.84  |proj g|=       1.1675
At iterate     1  f =      -616.28  |proj g|=        5.4168
At iterate     2  f =      -617.66  |proj g|=        5.1852
At iterate     3  f =      -619.72  |proj g|=        4.4958
At iterate     4  f =      -620.53  |proj g|=        3.2534
At iterate     5  f =      -621.59  |proj g|=        3.5255
At iterate     6  f =      -623.28  |proj g|=        3.0215
At iterate     7  f =      -623.47  |proj g|=        2.4809
At iterate     8  f =      -623.48  |proj g|=        2.4902
At iterate     9  f =      -623.48  |proj g|=        2.4909
At iterate    10  f =      -623.48  |proj g|=        2.4906

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.49061
final function value -623.477

F = -623.477
final  value -623.477150 
converged
 
INFO  [22:54:15.711] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:54:15.768] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:54:15.776] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:54:20.375] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:54:24.617] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:54:28.628] [mlr3]  Finished benchmark 
INFO  [22:54:28.694] [bbotk] Result of batch 110: 
INFO  [22:54:28.696] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:54:28.696] [bbotk]              6.425343                 4.076202                       0.1325793 
INFO  [22:54:28.696] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:54:28.696] [bbotk]                     2165        0.851 -0.9578576         <NA>   0.9703434 
INFO  [22:54:28.696] [bbotk]                                 uhash 
INFO  [22:54:28.696] [bbotk]  b768fec7-1118-4b13-a3df-5a073057cc50 
DEBUG [22:54:29.861] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.144763e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.144763e-05 0.001450702 
  - best initial criterion value(s) :  578.0395 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -578.04  |proj g|=       8.9796
At iterate     1  f =      -610.91  |proj g|=         2.997
At iterate     2  f =      -611.73  |proj g|=        2.9474
At iterate     3  f =      -613.27  |proj g|=        2.6152
At iterate     4  f =      -613.72  |proj g|=         2.741
At iterate     5  f =      -614.19  |proj g|=        2.7937
At iterate     6  f =      -617.72  |proj g|=        3.0874
At iterate     7  f =      -621.17  |proj g|=         3.321
At iterate     8  f =      -621.43  |proj g|=        3.1885
At iterate     9  f =      -622.64  |proj g|=        3.3809
At iterate    10  f =      -622.78  |proj g|=        3.4519
At iterate    11  f =      -622.93  |proj g|=        3.5009
At iterate    12  f =      -623.63  |proj g|=         3.673
At iterate    13  f =       -624.6  |proj g|=        3.8251
At iterate    14  f =      -626.05  |proj g|=        3.7461
At iterate    15  f =      -629.63  |proj g|=        3.8424
At iterate    16  f =       -632.3  |proj g|=         3.676
At iterate    17  f =      -634.06  |proj g|=        3.1497
At iterate    18  f =      -634.25  |proj g|=        2.9955
At iterate    19  f =      -634.26  |proj g|=        3.0293
At iterate    20  f =      -634.27  |proj g|=        3.0031
At iterate    21  f =      -634.27  |proj g|=        3.0072
At iterate    22  f =      -634.27  |proj g|=        3.0104
At iterate    23  f =      -634.27  |proj g|=        3.0104
At iterate    24  f =      -634.27  |proj g|=        3.0102

iterations 24
function evaluations 31
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.01024
final function value -634.273

F = -634.273
final  value -634.273415 
converged
 
INFO  [22:54:29.865] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:54:29.920] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:54:29.927] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:54:34.289] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:54:38.798] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:54:43.087] [mlr3]  Finished benchmark 
INFO  [22:54:43.169] [bbotk] Result of batch 111: 
INFO  [22:54:43.171] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:54:43.171] [bbotk]              4.497683                 4.603642                       0.2867375 
INFO  [22:54:43.171] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:54:43.171] [bbotk]                     2286        0.759 -0.9523799         <NA>   0.9732876 
INFO  [22:54:43.171] [bbotk]                                 uhash 
INFO  [22:54:43.171] [bbotk]  4531c543-7a48-4c5a-9b0c-7c500c1483c1 
DEBUG [22:54:44.555] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.138294e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.138294e-05 0.001438857 
  - best initial criterion value(s) :  602.2809 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -602.28  |proj g|=       5.9901
At iterate     1  f =      -609.53  |proj g|=        5.7006
At iterate     2  f =      -613.83  |proj g|=        5.5822
At iterate     3  f =      -617.91  |proj g|=        5.0542
At iterate     4  f =      -618.11  |proj g|=        4.8871
At iterate     5  f =      -618.13  |proj g|=        4.8452
At iterate     6  f =      -618.17  |proj g|=        4.7655
At iterate     7  f =      -618.23  |proj g|=        4.6712
At iterate     8  f =      -618.26  |proj g|=        4.6495
At iterate     9  f =      -618.26  |proj g|=        4.6632
At iterate    10  f =      -618.26  |proj g|=        4.6673
At iterate    11  f =      -618.26  |proj g|=        4.6678
At iterate    12  f =      -618.26  |proj g|=        4.6701
At iterate    13  f =      -618.26  |proj g|=        4.6734
At iterate    14  f =      -618.26  |proj g|=         4.679
At iterate    15  f =      -618.26  |proj g|=        4.6876
At iterate    16  f =      -618.26  |proj g|=        4.7011
At iterate    17  f =      -618.27  |proj g|=         4.721
At iterate    18  f =      -618.28  |proj g|=        4.7516
At iterate    19  f =      -618.31  |proj g|=        4.7858
At iterate    20  f =      -618.32  |proj g|=        4.8445
At iterate    21  f =      -618.38  |proj g|=        4.8612
At iterate    22  f =      -618.72  |proj g|=        4.8814
At iterate    23  f =      -619.54  |proj g|=        4.8112
At iterate    24  f =      -621.76  |proj g|=        4.4312
At iterate    25  f =      -624.89  |proj g|=        3.7083
At iterate    26  f =      -624.95  |proj g|=        3.5651
At iterate    27  f =       -626.7  |proj g|=        3.0935
At iterate    28  f =      -628.04  |proj g|=        2.9829
At iterate    29  f =      -628.05  |proj g|=        3.0352
At iterate    30  f =      -628.05  |proj g|=        3.0238
At iterate    31  f =      -628.05  |proj g|=        3.0226
At iterate    32  f =      -628.05  |proj g|=         3.023

iterations 32
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.02302
final function value -628.049

F = -628.049
final  value -628.049046 
converged
 
INFO  [22:54:44.559] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:54:44.616] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:54:44.623] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:54:48.273] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:54:51.950] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:54:55.771] [mlr3]  Finished benchmark 
INFO  [22:54:55.844] [bbotk] Result of batch 112: 
INFO  [22:54:55.846] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:54:55.846] [bbotk]              5.766589                 3.152005                      0.02905326 
INFO  [22:54:55.846] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:54:55.846] [bbotk]                     1877        0.743 -0.9577373         <NA>    0.953805 
INFO  [22:54:55.846] [bbotk]                                 uhash 
INFO  [22:54:55.846] [bbotk]  01d2fe3a-fdbb-477d-8e82-e2e20cb47d69 
DEBUG [22:54:57.044] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.145342e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.145341e-05 0.001443103 
  - best initial criterion value(s) :  607.3036 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -607.3  |proj g|=       6.0715
At iterate     1  f =      -608.54  |proj g|=        6.2255
At iterate     2  f =      -610.44  |proj g|=        5.6929
At iterate     3  f =      -612.16  |proj g|=        4.4659
At iterate     4  f =      -612.29  |proj g|=        4.4202
At iterate     5  f =      -612.32  |proj g|=        4.3444
At iterate     6  f =      -612.32  |proj g|=        4.3387
At iterate     7  f =      -612.32  |proj g|=         4.339
At iterate     8  f =      -612.32  |proj g|=        4.3393
At iterate     9  f =      -612.32  |proj g|=          4.34
At iterate    10  f =      -612.32  |proj g|=        4.3408
At iterate    11  f =      -612.32  |proj g|=         4.342
At iterate    12  f =      -612.32  |proj g|=        4.3433
At iterate    13  f =      -612.32  |proj g|=        4.3429
At iterate    14  f =      -612.32  |proj g|=        4.3351
At iterate    15  f =      -612.32  |proj g|=         4.311
At iterate    16  f =      -612.33  |proj g|=        4.3127
At iterate    17  f =      -612.34  |proj g|=        4.2845
At iterate    18  f =      -612.39  |proj g|=        4.1498
At iterate    19  f =      -612.48  |proj g|=        4.0059
At iterate    20  f =      -612.76  |proj g|=        3.7222
At iterate    21  f =      -613.37  |proj g|=        3.2774
At iterate    22  f =      -614.64  |proj g|=         2.759
At iterate    23  f =       -615.3  |proj g|=        1.6016
At iterate    24  f =      -618.34  |proj g|=        1.6834
At iterate    25  f =      -623.73  |proj g|=         1.728
At iterate    26  f =      -630.18  |proj g|=        2.7404
At iterate    27  f =      -632.84  |proj g|=        1.9432
At iterate    28  f =      -634.35  |proj g|=       0.69529
At iterate    29  f =      -634.43  |proj g|=        0.6378
At iterate    30  f =      -634.43  |proj g|=       0.69955
At iterate    31  f =      -634.43  |proj g|=       0.67093
At iterate    32  f =      -634.43  |proj g|=       0.67261
At iterate    33  f =      -634.43  |proj g|=       0.67268

iterations 33
function evaluations 38
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.672678
final function value -634.429

F = -634.429
final  value -634.429373 
converged
 
INFO  [22:54:57.048] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:54:57.116] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:54:57.123] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:55:02.833] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:55:08.424] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:55:13.978] [mlr3]  Finished benchmark 
INFO  [22:55:14.047] [bbotk] Result of batch 113: 
INFO  [22:55:14.049] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:55:14.049] [bbotk]              7.701533                 6.138409                       0.2554656 
INFO  [22:55:14.049] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:55:14.049] [bbotk]                     2929        0.773 -0.9590733         <NA>   0.9749785 
INFO  [22:55:14.049] [bbotk]                                 uhash 
INFO  [22:55:14.049] [bbotk]  678b16c8-f24e-4619-9746-ff3ba3374a7a 
DEBUG [22:55:15.262] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.140356e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.140356e-05 0.001439432 
  - best initial criterion value(s) :  638.2017 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -638.2  |proj g|=       1.7595
At iterate     1  f =       -640.1  |proj g|=        1.3544
At iterate     2  f =      -640.12  |proj g|=        1.3408
At iterate     3  f =      -640.14  |proj g|=        1.3295
At iterate     4  f =      -640.19  |proj g|=        1.3295
At iterate     5  f =      -640.23  |proj g|=        1.3793
At iterate     6  f =      -640.23  |proj g|=        1.3784
At iterate     7  f =      -640.23  |proj g|=        1.3781
At iterate     8  f =      -640.23  |proj g|=        1.3781

iterations 8
function evaluations 13
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.37806
final function value -640.232

F = -640.232
final  value -640.232071 
converged
 
INFO  [22:55:15.267] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:55:15.322] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:55:15.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:55:23.393] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:55:35.565] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:55:47.614] [mlr3]  Finished benchmark 
INFO  [22:55:47.684] [bbotk] Result of batch 114: 
INFO  [22:55:47.686] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:55:47.686] [bbotk]              2.486726                 2.317053                        0.377288 
INFO  [22:55:47.686] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:55:47.686] [bbotk]                     4178        0.883 -0.9580822         <NA>   0.9673402 
INFO  [22:55:47.686] [bbotk]                                 uhash 
INFO  [22:55:47.686] [bbotk]  6743ad4c-882d-4f02-8db9-3eb5cb04dbd3 
DEBUG [22:55:48.806] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.132518e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.132518e-05 0.001430134 
  - best initial criterion value(s) :  613.4138 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -613.41  |proj g|=       1.6471
At iterate     1  f =      -618.17  |proj g|=        3.8914
At iterate     2  f =      -619.96  |proj g|=        3.6186
At iterate     3  f =      -621.92  |proj g|=        3.1803
At iterate     4  f =      -623.38  |proj g|=        2.5183
At iterate     5  f =      -625.79  |proj g|=        2.6793
At iterate     6  f =      -629.94  |proj g|=        2.6635
At iterate     7  f =       -630.2  |proj g|=        2.8415
At iterate     8  f =      -630.22  |proj g|=        2.7884
At iterate     9  f =      -630.23  |proj g|=        2.8058
At iterate    10  f =      -630.23  |proj g|=        2.8044
At iterate    11  f =      -630.23  |proj g|=        2.8043

iterations 11
function evaluations 16
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.80431
final function value -630.23

F = -630.23
final  value -630.230053 
converged
 
INFO  [22:55:48.810] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:55:48.868] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:55:48.875] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:56:03.022] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:56:16.072] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:56:29.464] [mlr3]  Finished benchmark 
INFO  [22:56:29.534] [bbotk] Result of batch 115: 
INFO  [22:56:29.536] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:56:29.536] [bbotk]              9.503478                 4.947887                       0.2429409 
INFO  [22:56:29.536] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:56:29.536] [bbotk]                     4422        0.778 -0.9607535         <NA>   0.9766062 
INFO  [22:56:29.536] [bbotk]                                 uhash 
INFO  [22:56:29.536] [bbotk]  5367fce1-6848-4aec-885d-72e376b0ed67 
DEBUG [22:56:30.988] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.129301e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.1293e-05 0.001430531 
  - best initial criterion value(s) :  595.9707 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -595.97  |proj g|=       4.1496
At iterate     1  f =      -605.86  |proj g|=        7.4263
At iterate     2  f =      -613.95  |proj g|=        5.4417
At iterate     3  f =      -618.08  |proj g|=        5.9163
At iterate     4  f =      -629.98  |proj g|=        5.0898
At iterate     5  f =      -632.66  |proj g|=        4.5615
At iterate     6  f =      -633.44  |proj g|=        4.2192
At iterate     7  f =      -633.45  |proj g|=         4.159
At iterate     8  f =      -633.45  |proj g|=        4.1776
At iterate     9  f =      -633.45  |proj g|=        4.1769
At iterate    10  f =      -633.45  |proj g|=        4.1767
At iterate    11  f =      -633.45  |proj g|=        4.1765
At iterate    12  f =      -633.45  |proj g|=        4.1763
At iterate    13  f =      -633.45  |proj g|=        4.1758
At iterate    14  f =      -633.45  |proj g|=        4.1751
At iterate    15  f =      -633.45  |proj g|=        4.1744
At iterate    16  f =      -633.45  |proj g|=        4.1746
At iterate    17  f =      -633.45  |proj g|=        4.1752
At iterate    18  f =      -633.45  |proj g|=        4.1788
At iterate    19  f =      -633.46  |proj g|=         4.162
At iterate    20  f =      -633.47  |proj g|=        4.1712
At iterate    21  f =      -633.56  |proj g|=        4.1897
At iterate    22  f =      -633.82  |proj g|=        4.1543
At iterate    23  f =      -634.48  |proj g|=        4.0566
At iterate    24  f =      -635.82  |proj g|=        3.7652
At iterate    25  f =      -635.88  |proj g|=         3.859
At iterate    26  f =      -638.35  |proj g|=        3.1973
At iterate    27  f =      -642.49  |proj g|=        2.3068
At iterate    28  f =      -647.13  |proj g|=         1.555
At iterate    29  f =      -651.11  |proj g|=        1.0155
At iterate    30  f =      -651.15  |proj g|=        1.0668
At iterate    31  f =      -651.18  |proj g|=        1.1797
At iterate    32  f =      -651.18  |proj g|=        1.1783
At iterate    33  f =      -651.18  |proj g|=        1.1791

iterations 33
function evaluations 41
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.1791
final function value -651.18

F = -651.18
final  value -651.179901 
converged
 
INFO  [22:56:30.992] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:56:31.049] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:56:31.077] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:56:40.413] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:56:49.299] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:57:00.986] [mlr3]  Finished benchmark 
INFO  [22:57:01.058] [bbotk] Result of batch 116: 
INFO  [22:57:01.060] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:57:01.060] [bbotk]               8.39462                 2.222158                       0.2477865 
INFO  [22:57:01.060] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:57:01.060] [bbotk]                     3375        0.961 -0.9560906         <NA>   0.9754577 
INFO  [22:57:01.060] [bbotk]                                 uhash 
INFO  [22:57:01.060] [bbotk]  4e2cb844-4a8d-4b1e-9afb-84a72705b988 
DEBUG [22:57:02.133] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.124884e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.124884e-05 0.001430908 
  - best initial criterion value(s) :  599.6497 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -599.65  |proj g|=       6.3337
At iterate     1  f =      -610.11  |proj g|=        8.5963
At iterate     2  f =      -620.58  |proj g|=        7.3227
At iterate     3  f =      -655.67  |proj g|=        3.9522
At iterate     4  f =      -657.83  |proj g|=        3.7419
At iterate     5  f =      -658.19  |proj g|=        4.1209
At iterate     6  f =      -658.22  |proj g|=        4.1294
At iterate     7  f =      -658.24  |proj g|=        4.1424
At iterate     8  f =      -658.24  |proj g|=        4.1413
At iterate     9  f =      -658.24  |proj g|=        4.1412

iterations 9
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.14118
final function value -658.244

F = -658.244
final  value -658.244425 
converged
 
INFO  [22:57:02.137] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:57:02.194] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:57:02.201] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:57:11.062] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:57:19.270] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:57:28.737] [mlr3]  Finished benchmark 
INFO  [22:57:28.821] [bbotk] Result of batch 117: 
INFO  [22:57:28.823] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:57:28.823] [bbotk]              9.376717                 4.693777                       0.2865689 
INFO  [22:57:28.823] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [22:57:28.823] [bbotk]                     2720        0.782 -0.953401         <NA>   0.9756708 
INFO  [22:57:28.823] [bbotk]                                 uhash 
INFO  [22:57:28.823] [bbotk]  83429f9d-91c3-462c-bbeb-b279b109cf7f 
DEBUG [22:57:29.918] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.120685e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.120685e-05 0.001426796 
  - best initial criterion value(s) :  660.356 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -660.36  |proj g|=       5.5968
At iterate     1  f =      -680.79  |proj g|=         1.513
At iterate     2  f =      -682.54  |proj g|=        1.3012
At iterate     3  f =      -683.27  |proj g|=       0.64857
At iterate     4  f =      -683.64  |proj g|=       0.61521
At iterate     5  f =      -683.68  |proj g|=       0.62102
At iterate     6  f =      -683.69  |proj g|=       0.62262
At iterate     7  f =      -683.69  |proj g|=       0.62251
At iterate     8  f =      -683.69  |proj g|=       0.62251

iterations 8
function evaluations 10
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.622509
final function value -683.687

F = -683.687
final  value -683.687082 
converged
 
INFO  [22:57:29.922] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:57:29.980] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:57:29.987] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:57:31.377] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:57:33.480] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:57:34.835] [mlr3]  Finished benchmark 
INFO  [22:57:34.905] [bbotk] Result of batch 118: 
INFO  [22:57:34.907] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:57:34.907] [bbotk]              2.232972                  9.00286                      0.05672051 
INFO  [22:57:34.907] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:57:34.907] [bbotk]                      406        0.801 -0.9513503         <NA>   0.8956531 
INFO  [22:57:34.907] [bbotk]                                 uhash 
INFO  [22:57:34.907] [bbotk]  b19e071f-d358-4434-8851-b2f7688b4e78 
DEBUG [22:57:36.279] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.469946e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.469946e-05 0.001987387 
  - best initial criterion value(s) :  632.6689 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -632.67  |proj g|=       2.6105
At iterate     1  f =       -640.3  |proj g|=        7.6921
At iterate     2  f =      -644.73  |proj g|=        7.5197
At iterate     3  f =      -654.13  |proj g|=        5.9417
At iterate     4  f =      -655.74  |proj g|=        3.7692
At iterate     5  f =      -657.82  |proj g|=        4.1474
At iterate     6  f =      -658.97  |proj g|=        2.9689
At iterate     7  f =      -658.99  |proj g|=        2.5507
At iterate     8  f =      -659.01  |proj g|=        2.7148
At iterate     9  f =      -659.01  |proj g|=        2.7036
At iterate    10  f =      -659.01  |proj g|=         2.703
At iterate    11  f =      -659.01  |proj g|=        2.7008
At iterate    12  f =      -659.01  |proj g|=        2.6978
At iterate    13  f =      -659.01  |proj g|=        2.6923
At iterate    14  f =      -659.01  |proj g|=        2.6834
At iterate    15  f =      -659.01  |proj g|=        2.6701
At iterate    16  f =      -659.01  |proj g|=        2.6589
At iterate    17  f =      -659.01  |proj g|=        2.6571
At iterate    18  f =      -659.01  |proj g|=        2.6621
At iterate    19  f =      -659.01  |proj g|=        2.6684
At iterate    20  f =      -659.01  |proj g|=        2.6766
At iterate    21  f =      -659.01  |proj g|=        2.6901
At iterate    22  f =      -659.01  |proj g|=        2.7098
At iterate    23  f =      -659.02  |proj g|=        2.7377
At iterate    24  f =      -659.03  |proj g|=        2.7709
At iterate    25  f =      -659.07  |proj g|=        2.7927
At iterate    26  f =      -659.17  |proj g|=        2.7446
At iterate    27  f =      -659.38  |proj g|=        2.4914
At iterate    28  f =      -659.74  |proj g|=        1.8406
At iterate    29  f =      -659.95  |proj g|=        1.2877
At iterate    30  f =         -660  |proj g|=       0.97102
At iterate    31  f =      -660.05  |proj g|=       0.88084
At iterate    32  f =       -660.3  |proj g|=       0.86531
At iterate    33  f =      -661.09  |proj g|=       0.80952
At iterate    34  f =      -661.94  |proj g|=       0.73755
At iterate    35  f =      -662.25  |proj g|=       0.67846
At iterate    36  f =       -662.7  |proj g|=       0.78381
At iterate    37  f =      -662.79  |proj g|=       0.79731
At iterate    38  f =      -662.93  |proj g|=       0.65998
At iterate    39  f =      -662.99  |proj g|=       0.63544
At iterate    40  f =      -662.99  |proj g|=       0.62943
At iterate    41  f =      -662.99  |proj g|=       0.62691
At iterate    42  f =      -662.99  |proj g|=       0.62698
At iterate    43  f =      -662.99  |proj g|=       0.62698

iterations 43
function evaluations 52
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.62698
final function value -662.995

F = -662.995
final  value -662.994854 
converged
 
INFO  [22:57:36.283] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:57:36.338] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:57:36.345] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:57:43.998] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:57:52.382] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:58:01.765] [mlr3]  Finished benchmark 
INFO  [22:58:01.834] [bbotk] Result of batch 119: 
INFO  [22:58:01.836] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:58:01.836] [bbotk]              4.875008                 8.951055                       0.2976488 
INFO  [22:58:01.836] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:58:01.836] [bbotk]                     3028        0.793 -0.9537523         <NA>   0.9747048 
INFO  [22:58:01.836] [bbotk]                                 uhash 
INFO  [22:58:01.836] [bbotk]  6144a532-d50d-4123-900c-ad0cf04eae9a 
DEBUG [22:58:03.093] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.463006e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.463006e-05 0.001982906 
  - best initial criterion value(s) :  631.9502 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -631.95  |proj g|=       4.9399
At iterate     1  f =      -660.86  |proj g|=        1.6793
At iterate     2  f =      -672.01  |proj g|=        4.7652
At iterate     3  f =      -672.93  |proj g|=         4.487
At iterate     4  f =      -673.52  |proj g|=        4.0384
At iterate     5  f =      -673.53  |proj g|=        3.9894
At iterate     6  f =      -673.53  |proj g|=        3.9892
At iterate     7  f =      -673.53  |proj g|=        4.0343
At iterate     8  f =      -673.53  |proj g|=        4.0347
At iterate     9  f =      -673.53  |proj g|=         4.033
At iterate    10  f =      -673.53  |proj g|=        4.0328
At iterate    11  f =      -673.53  |proj g|=        4.0132
At iterate    12  f =      -673.54  |proj g|=        4.0169
At iterate    13  f =      -673.55  |proj g|=         4.037
At iterate    14  f =      -673.57  |proj g|=        4.0535
At iterate    15  f =      -673.63  |proj g|=        4.0624
At iterate    16  f =      -673.78  |proj g|=        4.0296
At iterate    17  f =       -674.1  |proj g|=        3.8292
At iterate    18  f =      -674.23  |proj g|=        4.0031
At iterate    19  f =      -675.28  |proj g|=        3.1484
At iterate    20  f =      -676.22  |proj g|=         2.428
At iterate    21  f =      -678.55  |proj g|=        1.2435
At iterate    22  f =      -680.62  |proj g|=       0.82901
At iterate    23  f =      -681.23  |proj g|=       0.59858
At iterate    24  f =      -681.29  |proj g|=       0.37932
At iterate    25  f =       -681.3  |proj g|=       0.38533
At iterate    26  f =       -681.3  |proj g|=       0.23334
At iterate    27  f =       -681.3  |proj g|=      0.079767
At iterate    28  f =       -681.3  |proj g|=      0.080923
At iterate    29  f =       -681.3  |proj g|=      0.080923

iterations 29
function evaluations 35
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0809233
final function value -681.303

F = -681.303
final  value -681.303075 
converged
 
INFO  [22:58:03.097] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:58:03.177] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:58:03.184] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:58:06.297] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:58:09.548] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:58:13.402] [mlr3]  Finished benchmark 
INFO  [22:58:13.472] [bbotk] Result of batch 120: 
INFO  [22:58:13.473] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:58:13.473] [bbotk]              6.130693                 8.780421                       0.3488155 
INFO  [22:58:13.473] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:58:13.473] [bbotk]                     1150        0.793 -0.9502483         <NA>   0.9720318 
INFO  [22:58:13.473] [bbotk]                                 uhash 
INFO  [22:58:13.473] [bbotk]  040afb5e-dbc8-490d-88c0-1b1350473aba 
DEBUG [22:58:15.010] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.454264e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.454264e-05 0.001958367 
  - best initial criterion value(s) :  653.1612 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -653.16  |proj g|=       4.5992
At iterate     1  f =      -660.44  |proj g|=        2.2224
At iterate     2  f =      -660.45  |proj g|=        2.2117
At iterate     3  f =      -660.45  |proj g|=        2.2016
At iterate     4  f =      -660.45  |proj g|=        2.2018
At iterate     5  f =      -660.45  |proj g|=        2.2023
At iterate     6  f =      -660.45  |proj g|=         2.202
At iterate     7  f =      -660.45  |proj g|=        2.2002
At iterate     8  f =      -660.45  |proj g|=        2.1992
At iterate     9  f =      -660.45  |proj g|=        2.1988
At iterate    10  f =      -660.45  |proj g|=        2.1986
At iterate    11  f =      -660.45  |proj g|=         2.198
At iterate    12  f =      -660.45  |proj g|=         2.197
At iterate    13  f =      -660.45  |proj g|=        2.1955
At iterate    14  f =      -660.45  |proj g|=        2.1929
At iterate    15  f =      -660.45  |proj g|=        2.1884
At iterate    16  f =      -660.46  |proj g|=        2.1808
At iterate    17  f =      -660.47  |proj g|=        2.1677
At iterate    18  f =      -660.49  |proj g|=        2.1453
At iterate    19  f =      -660.55  |proj g|=        2.1108
At iterate    20  f =      -660.66  |proj g|=        2.0727
At iterate    21  f =       -660.8  |proj g|=        2.0829
At iterate    22  f =      -660.81  |proj g|=         2.098
At iterate    23  f =      -660.81  |proj g|=        2.1004
At iterate    24  f =      -660.81  |proj g|=        2.1008
At iterate    25  f =      -660.81  |proj g|=        2.1048
At iterate    26  f =      -660.81  |proj g|=        2.1092
At iterate    27  f =      -660.81  |proj g|=        2.1168
At iterate    28  f =      -660.82  |proj g|=        2.1282
At iterate    29  f =      -660.85  |proj g|=         2.147
At iterate    30  f =      -660.92  |proj g|=         2.176
At iterate    31  f =      -661.08  |proj g|=        2.2161
At iterate    32  f =      -661.35  |proj g|=        2.2474
At iterate    33  f =      -661.42  |proj g|=        2.2043
At iterate    34  f =      -661.55  |proj g|=        2.2226
At iterate    35  f =      -663.84  |proj g|=        1.6528
At iterate    36  f =      -663.88  |proj g|=        1.6948
At iterate    37  f =      -663.99  |proj g|=        1.7007
At iterate    38  f =      -663.99  |proj g|=        1.6663
At iterate    39  f =         -664  |proj g|=        1.6807
At iterate    40  f =         -664  |proj g|=        1.6795
At iterate    41  f =         -664  |proj g|=        1.6796

iterations 41
function evaluations 47
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.67962
final function value -663.995

F = -663.995
final  value -663.995320 
converged
 
INFO  [22:58:15.014] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:58:15.072] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:58:15.080] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:58:19.410] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:58:25.271] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:58:29.060] [mlr3]  Finished benchmark 
INFO  [22:58:29.187] [bbotk] Result of batch 121: 
INFO  [22:58:29.189] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:58:29.189] [bbotk]              4.801274                  2.25668                       0.2722411 
INFO  [22:58:29.189] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:58:29.189] [bbotk]                     1628        0.992 -0.9566709         <NA>   0.9716588 
INFO  [22:58:29.189] [bbotk]                                 uhash 
INFO  [22:58:29.189] [bbotk]  03fb3242-06d8-4b5d-a274-33779b41a8b6 
DEBUG [22:58:30.671] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.445443e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.445443e-05 0.001935712 
  - best initial criterion value(s) :  673.6115 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -673.61  |proj g|=       5.2156
At iterate     1  f =      -685.22  |proj g|=         2.022
At iterate     2  f =      -687.52  |proj g|=        2.0525
At iterate     3  f =       -688.7  |proj g|=        2.1125
At iterate     4  f =      -688.94  |proj g|=        2.1048
At iterate     5  f =      -689.08  |proj g|=        2.1121
At iterate     6  f =      -689.99  |proj g|=        2.1978
At iterate     7  f =       -690.3  |proj g|=        2.2705
At iterate     8  f =      -690.33  |proj g|=        2.2963
At iterate     9  f =      -690.33  |proj g|=        2.2979
At iterate    10  f =      -690.33  |proj g|=        2.3002
At iterate    11  f =      -690.33  |proj g|=        2.3003
At iterate    12  f =      -690.33  |proj g|=        2.3004
At iterate    13  f =      -690.33  |proj g|=        2.3007
At iterate    14  f =      -690.33  |proj g|=         2.301
At iterate    15  f =      -690.33  |proj g|=        2.3017
At iterate    16  f =      -690.33  |proj g|=        2.3028
At iterate    17  f =      -690.33  |proj g|=        2.3046
At iterate    18  f =      -690.34  |proj g|=        2.3073
At iterate    19  f =      -690.34  |proj g|=        2.3117
At iterate    20  f =      -690.34  |proj g|=        2.3112
At iterate    21  f =      -690.35  |proj g|=        2.3159
At iterate    22  f =      -690.41  |proj g|=        2.3164
At iterate    23  f =      -690.68  |proj g|=        2.2677
At iterate    24  f =      -691.12  |proj g|=        2.0944
At iterate    25  f =      -691.21  |proj g|=        1.9984
At iterate    26  f =      -691.21  |proj g|=        1.9973
At iterate    27  f =      -691.21  |proj g|=        2.0093
At iterate    28  f =      -691.21  |proj g|=        2.0095
At iterate    29  f =      -691.21  |proj g|=        2.0096
At iterate    30  f =      -691.21  |proj g|=        2.0101
At iterate    31  f =      -691.21  |proj g|=        2.0107
At iterate    32  f =      -691.21  |proj g|=        2.0118
At iterate    33  f =      -691.21  |proj g|=         2.012
At iterate    34  f =      -691.21  |proj g|=        2.0136
At iterate    35  f =      -691.22  |proj g|=        2.0167
At iterate    36  f =      -691.22  |proj g|=        2.0219
At iterate    37  f =      -691.23  |proj g|=        2.0304
At iterate    38  f =      -691.24  |proj g|=        2.0398
At iterate    39  f =      -691.24  |proj g|=        2.0405
At iterate    40  f =      -691.25  |proj g|=        2.0457
At iterate    41  f =      -691.26  |proj g|=        2.0428
At iterate    42  f =      -691.26  |proj g|=        2.0412
At iterate    43  f =      -691.26  |proj g|=        2.0399
At iterate    44  f =      -691.27  |proj g|=         2.034
At iterate    45  f =      -691.27  |proj g|=        2.0288
At iterate    46  f =      -691.31  |proj g|=        2.0024
At iterate    47  f =      -691.43  |proj g|=        1.9092
At iterate    48  f =      -691.73  |proj g|=        1.6668
At iterate    49  f =      -692.41  |proj g|=        1.0743
At iterate    50  f =      -693.52  |proj g|=       0.50019
At iterate    51  f =      -693.53  |proj g|=       0.50765
At iterate    52  f =      -694.03  |proj g|=       0.48267
At iterate    53  f =       -695.3  |proj g|=       0.41697
At iterate    54  f =      -695.39  |proj g|=       0.59137
At iterate    55  f =       -695.4  |proj g|=         0.201
At iterate    56  f =       -695.4  |proj g|=       0.20727
At iterate    57  f =       -695.4  |proj g|=       0.33838
At iterate    58  f =       -695.4  |proj g|=       0.32244

iterations 58
function evaluations 69
segments explored during Cauchy searches 60
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.322444
final function value -695.403

F = -695.403
final  value -695.403008 
converged
 
INFO  [22:58:30.676] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:58:30.733] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:58:30.741] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:58:42.209] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:58:54.087] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:59:05.664] [mlr3]  Finished benchmark 
INFO  [22:59:05.738] [bbotk] Result of batch 122: 
INFO  [22:59:05.740] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:59:05.740] [bbotk]              4.671884                 6.402906                        0.343228 
INFO  [22:59:05.740] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:59:05.740] [bbotk]                     4074        0.803 -0.9479709         <NA>   0.9758727 
INFO  [22:59:05.740] [bbotk]                                 uhash 
INFO  [22:59:05.740] [bbotk]  53b9e0b0-9c54-4d9b-a516-202bdb1e13e2 
DEBUG [22:59:07.183] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.439808e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.83246 0.9821542 9446 
  - variance bounds :  1.439808e-05 0.001934331 
  - best initial criterion value(s) :  658.8541 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -658.85  |proj g|=       3.7697
At iterate     1  f =      -660.89  |proj g|=        6.1137
At iterate     2  f =      -665.59  |proj g|=         5.971
At iterate     3  f =      -669.99  |proj g|=        5.3622
At iterate     4  f =      -670.21  |proj g|=        5.0119
At iterate     5  f =      -670.55  |proj g|=        5.0874
At iterate     6  f =       -671.3  |proj g|=        5.0175
At iterate     7  f =      -671.67  |proj g|=        4.8042
At iterate     8  f =      -671.77  |proj g|=        4.6941
At iterate     9  f =      -671.78  |proj g|=        4.6518
At iterate    10  f =       -671.8  |proj g|=        4.6283
At iterate    11  f =         -672  |proj g|=        4.4783
At iterate    12  f =      -672.51  |proj g|=        4.1994
At iterate    13  f =      -673.91  |proj g|=        3.6441
At iterate    14  f =      -676.23  |proj g|=        2.7484
At iterate    15  f =      -678.38  |proj g|=         6.449
At iterate    16  f =      -679.65  |proj g|=        5.7873
At iterate    17  f =      -679.95  |proj g|=        5.6508
At iterate    18  f =      -680.02  |proj g|=        5.5709
At iterate    19  f =      -680.04  |proj g|=        5.7639
At iterate    20  f =      -680.04  |proj g|=        5.8007
At iterate    21  f =      -680.04  |proj g|=        5.8361
At iterate    22  f =      -680.04  |proj g|=        5.8343
At iterate    23  f =      -680.04  |proj g|=        5.8349
At iterate    24  f =      -680.04  |proj g|=        5.8373
At iterate    25  f =      -680.04  |proj g|=        5.8405
At iterate    26  f =      -680.05  |proj g|=        5.8336
At iterate    27  f =      -680.05  |proj g|=        5.8922
At iterate    28  f =      -680.06  |proj g|=        5.8775
At iterate    29  f =      -680.07  |proj g|=        6.0361
At iterate    30  f =      -680.13  |proj g|=        5.9898
At iterate    31  f =       -682.5  |proj g|=        5.4983
At iterate    32  f =       -690.2  |proj g|=        4.0488
At iterate    33  f =      -690.45  |proj g|=        3.3697
At iterate    34  f =      -694.35  |proj g|=         1.414
At iterate    35  f =      -695.56  |proj g|=       0.43038
At iterate    36  f =      -695.88  |proj g|=       0.36704
At iterate    37  f =      -695.93  |proj g|=       0.23823
At iterate    38  f =      -695.94  |proj g|=       0.61058
At iterate    39  f =      -695.94  |proj g|=       0.61081
At iterate    40  f =      -695.94  |proj g|=       0.61059
At iterate    41  f =      -695.94  |proj g|=       0.61049
At iterate    42  f =      -695.94  |proj g|=       0.61012
At iterate    43  f =      -695.94  |proj g|=       0.60917
At iterate    44  f =      -695.94  |proj g|=       0.60778
At iterate    45  f =      -695.94  |proj g|=       0.60777
At iterate    46  f =      -695.95  |proj g|=       0.46478
At iterate    47  f =      -695.95  |proj g|=      0.013046
At iterate    48  f =      -695.95  |proj g|=      0.014642
At iterate    49  f =      -695.95  |proj g|=     0.0085095

iterations 49
function evaluations 63
segments explored during Cauchy searches 52
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00850947
final function value -695.946

F = -695.946
final  value -695.946191 
converged
 
INFO  [22:59:07.187] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:59:07.247] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:59:07.255] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:59:08.397] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:59:10.044] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:59:11.057] [mlr3]  Finished benchmark 
INFO  [22:59:11.124] [bbotk] Result of batch 123: 
INFO  [22:59:11.126] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:59:11.126] [bbotk]              4.098199                 9.964278                        0.123558 
INFO  [22:59:11.126] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:59:11.126] [bbotk]                      246         0.79 -0.9509224         <NA>   0.9365579 
INFO  [22:59:11.126] [bbotk]                                 uhash 
INFO  [22:59:11.126] [bbotk]  bd796bfb-3a4a-46f7-a716-69da3ec8836a 
DEBUG [22:59:12.442] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.495509e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.495509e-05 0.002030825 
  - best initial criterion value(s) :  654.8836 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -654.88  |proj g|=       4.5459
At iterate     1  f =      -678.84  |proj g|=        5.5537
At iterate     2  f =      -681.14  |proj g|=        5.3703
At iterate     3  f =      -685.46  |proj g|=        4.1006
At iterate     4  f =      -685.81  |proj g|=         3.562
At iterate     5  f =      -686.39  |proj g|=        3.8952
At iterate     6  f =      -686.62  |proj g|=        4.1265
At iterate     7  f =      -686.62  |proj g|=        4.1118
At iterate     8  f =      -686.62  |proj g|=        4.1107
At iterate     9  f =      -686.62  |proj g|=          4.11
At iterate    10  f =      -686.62  |proj g|=        4.1084
At iterate    11  f =      -686.62  |proj g|=         4.105
At iterate    12  f =      -686.62  |proj g|=        4.1001
At iterate    13  f =      -686.62  |proj g|=        4.0924
At iterate    14  f =      -686.63  |proj g|=        4.0813
At iterate    15  f =      -686.64  |proj g|=        4.0666
At iterate    16  f =      -686.66  |proj g|=        4.0542
At iterate    17  f =       -686.7  |proj g|=         4.065
At iterate    18  f =      -686.74  |proj g|=        4.1738
At iterate    19  f =      -686.74  |proj g|=        4.1631
At iterate    20  f =      -686.74  |proj g|=        4.1595
At iterate    21  f =      -686.75  |proj g|=        4.1471
At iterate    22  f =      -686.75  |proj g|=         4.125
At iterate    23  f =      -686.77  |proj g|=        4.0855
At iterate    24  f =      -686.81  |proj g|=         4.013
At iterate    25  f =      -686.92  |proj g|=        3.8817
At iterate    26  f =      -687.14  |proj g|=        3.6842
At iterate    27  f =      -687.47  |proj g|=         3.374
At iterate    28  f =      -688.09  |proj g|=         4.115
At iterate    29  f =      -688.61  |proj g|=        4.7048
At iterate    30  f =      -689.17  |proj g|=        5.3301
At iterate    31  f =      -689.28  |proj g|=        5.1337
At iterate    32  f =       -689.3  |proj g|=        4.9493
At iterate    33  f =       -689.3  |proj g|=        4.9111
At iterate    34  f =       -689.3  |proj g|=        4.9186
At iterate    35  f =       -689.3  |proj g|=        4.9188

iterations 35
function evaluations 41
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.9188
final function value -689.299

F = -689.299
final  value -689.298516 
converged
 
INFO  [22:59:12.446] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:59:12.503] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:59:12.510] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:59:13.909] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:59:14.961] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:59:16.119] [mlr3]  Finished benchmark 
INFO  [22:59:16.190] [bbotk] Result of batch 124: 
INFO  [22:59:16.192] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:59:16.192] [bbotk]              5.050465                 3.116856                       0.4156218 
INFO  [22:59:16.192] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:59:16.192] [bbotk]                      285        0.794 -0.9524496         <NA>   0.9613594 
INFO  [22:59:16.192] [bbotk]                                 uhash 
INFO  [22:59:16.192] [bbotk]  450a71d5-4c5c-490a-a01d-d67aecc9ce20 
DEBUG [22:59:17.509] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.488659e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.488659e-05 0.002014836 
  - best initial criterion value(s) :  658.0779 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -658.08  |proj g|=        5.108
At iterate     1  f =      -685.82  |proj g|=        4.0945
At iterate     2  f =      -691.59  |proj g|=        3.6914
At iterate     3  f =      -696.13  |proj g|=        3.0869
At iterate     4  f =      -696.86  |proj g|=         2.883
At iterate     5  f =      -697.67  |proj g|=        2.8865
At iterate     6  f =      -698.13  |proj g|=        3.1428
At iterate     7  f =      -698.15  |proj g|=        3.1278
At iterate     8  f =      -698.15  |proj g|=        3.1269
At iterate     9  f =      -698.15  |proj g|=        3.1272

iterations 9
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.12723
final function value -698.146

F = -698.146
final  value -698.146190 
converged
 
INFO  [22:59:17.513] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:59:17.568] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:59:17.575] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:59:19.404] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:59:21.510] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:59:23.341] [mlr3]  Finished benchmark 
INFO  [22:59:23.411] [bbotk] Result of batch 125: 
INFO  [22:59:23.413] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:59:23.413] [bbotk]              6.859384                 7.881502                       0.1107128 
INFO  [22:59:23.413] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:59:23.413] [bbotk]                      562        0.989 -0.9508521         <NA>   0.9559891 
INFO  [22:59:23.413] [bbotk]                                 uhash 
INFO  [22:59:23.413] [bbotk]  9ff39f03-977d-424b-931a-c8f9ad3def4e 
DEBUG [22:59:24.989] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.488264e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.488264e-05 0.002011974 
  - best initial criterion value(s) :  663.1689 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -663.17  |proj g|=       7.9075
At iterate     1  f =      -686.05  |proj g|=        8.5148
At iterate     2  f =      -692.21  |proj g|=        6.7733
At iterate     3  f =      -695.31  |proj g|=        4.5962
At iterate     4  f =      -697.18  |proj g|=        3.3067
At iterate     5  f =      -697.28  |proj g|=        3.6115
At iterate     6  f =      -697.61  |proj g|=        3.3068
At iterate     7  f =      -697.81  |proj g|=        3.2863
At iterate     8  f =      -698.42  |proj g|=        3.2608
At iterate     9  f =      -700.37  |proj g|=        3.2052
At iterate    10  f =       -702.6  |proj g|=        3.1508
At iterate    11  f =      -702.74  |proj g|=        3.2931
At iterate    12  f =      -704.44  |proj g|=        3.2241
At iterate    13  f =      -705.48  |proj g|=        3.2319
At iterate    14  f =      -705.99  |proj g|=        3.3744
At iterate    15  f =      -706.32  |proj g|=        3.3968
At iterate    16  f =      -706.35  |proj g|=        3.4083
At iterate    17  f =      -706.35  |proj g|=        3.4262
At iterate    18  f =      -706.36  |proj g|=        3.4291
At iterate    19  f =      -706.36  |proj g|=        3.4292
At iterate    20  f =      -706.36  |proj g|=        3.4311
At iterate    21  f =      -706.36  |proj g|=        3.4311
At iterate    22  f =      -706.36  |proj g|=        3.4334
At iterate    23  f =      -706.36  |proj g|=        3.4265
At iterate    24  f =      -706.36  |proj g|=        3.4336
At iterate    25  f =      -706.38  |proj g|=        3.4423
At iterate    26  f =      -706.44  |proj g|=        3.4515
At iterate    27  f =      -706.58  |proj g|=        3.4452
At iterate    28  f =      -706.89  |proj g|=        3.3764
At iterate    29  f =      -707.22  |proj g|=        3.4354
At iterate    30  f =      -708.17  |proj g|=        3.1137
At iterate    31  f =      -709.56  |proj g|=        2.1994
At iterate    32  f =      -712.86  |proj g|=       0.97809
At iterate    33  f =       -713.5  |proj g|=       0.82509
At iterate    34  f =      -715.62  |proj g|=         0.521
At iterate    35  f =      -716.82  |proj g|=       0.45788
At iterate    36  f =      -717.72  |proj g|=       0.68404
At iterate    37  f =       -717.8  |proj g|=       0.54361
At iterate    38  f =       -717.8  |proj g|=       0.52863
At iterate    39  f =      -717.81  |proj g|=       0.53882
At iterate    40  f =      -717.92  |proj g|=       0.57639
At iterate    41  f =      -718.01  |proj g|=       0.57399
At iterate    42  f =      -718.03  |proj g|=        0.4124
At iterate    43  f =      -718.04  |proj g|=      0.099797
At iterate    44  f =      -718.04  |proj g|=     0.0030238
At iterate    45  f =      -718.04  |proj g|=     0.0052746
At iterate    46  f =      -718.04  |proj g|=     0.0030291

iterations 46
function evaluations 63
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00302908
final function value -718.041

F = -718.041
final  value -718.040737 
converged
 
INFO  [22:59:24.991] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:59:25.037] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:59:25.044] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [22:59:34.728] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [22:59:45.841] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [22:59:55.718] [mlr3]  Finished benchmark 
INFO  [22:59:55.788] [bbotk] Result of batch 126: 
INFO  [22:59:55.790] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [22:59:55.790] [bbotk]              7.338275                 8.309175                       0.1817605 
INFO  [22:59:55.790] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [22:59:55.790] [bbotk]                     3454        0.879 -0.9455862         <NA>   0.9742823 
INFO  [22:59:55.790] [bbotk]                                 uhash 
INFO  [22:59:55.790] [bbotk]  f26c964b-ae40-4082-b037-fd1f7ba4bca5 
DEBUG [22:59:56.927] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.48132e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.48132e-05 0.002007937 
  - best initial criterion value(s) :  676.9839 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -676.98  |proj g|=       3.4224
At iterate     1  f =      -680.61  |proj g|=        2.4444
At iterate     2  f =      -684.84  |proj g|=        2.3997
At iterate     3  f =      -688.57  |proj g|=        2.1701
At iterate     4  f =      -689.29  |proj g|=        2.0649
At iterate     5  f =      -689.57  |proj g|=        2.0863
At iterate     6  f =      -689.58  |proj g|=        2.0884
At iterate     7  f =      -689.58  |proj g|=        2.0897
At iterate     8  f =      -689.58  |proj g|=        2.0897

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.08972
final function value -689.577

F = -689.577
final  value -689.577171 
converged
 
INFO  [22:59:56.931] [bbotk] Evaluating 1 configuration(s) 
INFO  [22:59:56.985] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [22:59:56.992] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:00:05.350] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:00:11.062] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:00:16.471] [mlr3]  Finished benchmark 
INFO  [23:00:16.584] [bbotk] Result of batch 127: 
INFO  [23:00:16.586] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:00:16.586] [bbotk]               6.72764                 8.953738                       0.3416508 
INFO  [23:00:16.586] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:00:16.586] [bbotk]                     2833        0.816 -0.9562993         <NA>   0.9751725 
INFO  [23:00:16.586] [bbotk]                                 uhash 
INFO  [23:00:16.586] [bbotk]  72b50ecb-7926-4ad1-9503-4993d87d677a 
DEBUG [23:00:18.207] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.475196e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.475196e-05 0.00200251 
  - best initial criterion value(s) :  665.5939 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -665.59  |proj g|=       4.7134
At iterate     1  f =         -676  |proj g|=         2.984
At iterate     2  f =      -676.12  |proj g|=        2.9413
At iterate     3  f =      -676.28  |proj g|=        2.8478
At iterate     4  f =      -676.39  |proj g|=        2.8175
At iterate     5  f =      -677.18  |proj g|=        2.6191
At iterate     6  f =      -677.91  |proj g|=        2.5909
At iterate     7  f =      -678.32  |proj g|=        2.7193
At iterate     8  f =      -678.53  |proj g|=        2.6496
At iterate     9  f =      -678.53  |proj g|=        2.6433
At iterate    10  f =      -678.53  |proj g|=         2.645
At iterate    11  f =      -678.53  |proj g|=        2.6449
At iterate    12  f =      -678.53  |proj g|=        2.6448
At iterate    13  f =      -678.53  |proj g|=        2.6446
At iterate    14  f =      -678.53  |proj g|=        2.6443
At iterate    15  f =      -678.53  |proj g|=        2.6438
At iterate    16  f =      -678.53  |proj g|=        2.6433
At iterate    17  f =      -678.54  |proj g|=        2.6432
At iterate    18  f =      -678.54  |proj g|=        2.6428
At iterate    19  f =      -678.55  |proj g|=        2.6459
At iterate    20  f =      -678.55  |proj g|=        2.6362
At iterate    21  f =      -678.57  |proj g|=        2.6395
At iterate    22  f =       -679.2  |proj g|=        2.5878
At iterate    23  f =      -680.09  |proj g|=        2.2793
At iterate    24  f =      -680.16  |proj g|=        2.3545
At iterate    25  f =      -680.16  |proj g|=        2.3707
At iterate    26  f =      -680.17  |proj g|=        2.3574
At iterate    27  f =      -680.17  |proj g|=          2.35
At iterate    28  f =      -680.17  |proj g|=        2.3482
At iterate    29  f =      -680.17  |proj g|=        2.3479
At iterate    30  f =      -680.17  |proj g|=        2.3476
At iterate    31  f =      -680.17  |proj g|=        2.3464
At iterate    32  f =      -680.17  |proj g|=        2.3458
At iterate    33  f =      -680.18  |proj g|=        2.3441
At iterate    34  f =      -680.18  |proj g|=        2.3397
At iterate    35  f =      -680.18  |proj g|=        2.3336
At iterate    36  f =      -680.19  |proj g|=        2.3211
At iterate    37  f =      -680.21  |proj g|=        2.3032
At iterate    38  f =      -680.21  |proj g|=        2.3079
At iterate    39  f =      -680.26  |proj g|=        2.2803
At iterate    40  f =      -680.46  |proj g|=        2.2209
At iterate    41  f =      -681.11  |proj g|=        2.7492
At iterate    42  f =      -682.58  |proj g|=        2.8592
At iterate    43  f =       -686.1  |proj g|=        2.2426
At iterate    44  f =      -686.16  |proj g|=        2.4207
At iterate    45  f =      -687.46  |proj g|=       0.62483
At iterate    46  f =       -687.6  |proj g|=       0.31759
At iterate    47  f =       -687.6  |proj g|=      0.039653
At iterate    48  f =       -687.6  |proj g|=       0.11463
At iterate    49  f =       -687.6  |proj g|=       0.12104
At iterate    50  f =       -687.6  |proj g|=       0.07494
At iterate    51  f =       -687.6  |proj g|=      0.074906
At iterate    52  f =       -687.6  |proj g|=      0.039667
At iterate    53  f =       -687.6  |proj g|=      0.039666

iterations 53
function evaluations 66
segments explored during Cauchy searches 55
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.039666
final function value -687.601

F = -687.601
final  value -687.601486 
converged
 
INFO  [23:00:18.212] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:00:18.267] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:00:18.275] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:00:23.469] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:00:28.839] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:00:34.117] [mlr3]  Finished benchmark 
INFO  [23:00:34.198] [bbotk] Result of batch 128: 
INFO  [23:00:34.200] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:00:34.200] [bbotk]              6.245604                 2.640288                       0.2760617 
INFO  [23:00:34.200] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:00:34.200] [bbotk]                     2699        0.822 -0.9587248         <NA>   0.9747921 
INFO  [23:00:34.200] [bbotk]                                 uhash 
INFO  [23:00:34.200] [bbotk]  73171b21-6adf-485c-9237-0de2ef72da4e 
DEBUG [23:00:35.481] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.468774e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.468774e-05 0.001996591 
  - best initial criterion value(s) :  696.8002 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -696.8  |proj g|=       7.3751
At iterate     1  f =      -706.42  |proj g|=        2.2189
At iterate     2  f =      -709.68  |proj g|=        2.2634
At iterate     3  f =      -711.16  |proj g|=         3.591
At iterate     4  f =      -711.68  |proj g|=        2.8112
At iterate     5  f =      -712.16  |proj g|=        2.9877
At iterate     6  f =      -713.03  |proj g|=        2.9864
At iterate     7  f =       -713.3  |proj g|=        2.5266
At iterate     8  f =      -713.46  |proj g|=        2.5982
At iterate     9  f =      -713.47  |proj g|=        2.6074
At iterate    10  f =      -713.47  |proj g|=        2.6074
At iterate    11  f =      -713.47  |proj g|=        2.6074
At iterate    12  f =      -713.47  |proj g|=        2.6074
At iterate    13  f =      -713.47  |proj g|=        2.6074
At iterate    14  f =      -713.47  |proj g|=        2.6074
At iterate    15  f =      -714.96  |proj g|=        2.6068
At iterate    16  f =      -717.68  |proj g|=        2.6048
At iterate    17  f =      -717.95  |proj g|=        2.6041
At iterate    18  f =      -717.98  |proj g|=        2.6038
At iterate    19  f =      -717.99  |proj g|=        2.6037
At iterate    20  f =      -717.99  |proj g|=        2.6037
At iterate    21  f =      -717.99  |proj g|=        2.6037
At iterate    22  f =      -717.99  |proj g|=        2.6037

iterations 22
function evaluations 33
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.60371
final function value -717.986

F = -717.986
final  value -717.985686 
converged
 
INFO  [23:00:35.485] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:00:35.552] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:00:35.560] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:00:45.140] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:00:54.310] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:01:04.106] [mlr3]  Finished benchmark 
INFO  [23:01:04.174] [bbotk] Result of batch 129: 
INFO  [23:01:04.176] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:01:04.176] [bbotk]              8.147863                 5.484435                       0.3709716 
INFO  [23:01:04.176] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:01:04.176] [bbotk]                     4762        0.809 -0.9463573         <NA>   0.9774533 
INFO  [23:01:04.176] [bbotk]                                 uhash 
INFO  [23:01:04.176] [bbotk]  644e178e-78c2-4e55-9453-7709be168daf 
DEBUG [23:01:05.729] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.465089e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.465089e-05 0.00199648 
  - best initial criterion value(s) :  705.2756 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -705.28  |proj g|=       10.872
At iterate     1  f =      -710.22  |proj g|=       0.98215
At iterate     2  f =       -715.3  |proj g|=         2.727
At iterate     3  f =      -720.34  |proj g|=        1.9252
At iterate     4  f =      -722.89  |proj g|=       0.95992
At iterate     5  f =      -725.69  |proj g|=        1.2749
At iterate     6  f =      -728.58  |proj g|=        1.6326
At iterate     7  f =      -729.33  |proj g|=        4.3619
At iterate     8  f =      -730.01  |proj g|=        3.1193
At iterate     9  f =      -730.03  |proj g|=        3.0815
At iterate    10  f =      -730.04  |proj g|=        3.1951
At iterate    11  f =      -730.04  |proj g|=        3.1863
At iterate    12  f =      -730.04  |proj g|=        3.1644
At iterate    13  f =      -730.05  |proj g|=        3.1239
At iterate    14  f =      -730.06  |proj g|=        3.0346
At iterate    15  f =       -730.1  |proj g|=        2.9157
At iterate    16  f =      -730.11  |proj g|=        2.8458
At iterate    17  f =      -730.21  |proj g|=        2.6578
At iterate    18  f =      -736.05  |proj g|=        1.2853
At iterate    19  f =      -737.29  |proj g|=        1.0486
At iterate    20  f =      -737.54  |proj g|=       0.98675
At iterate    21  f =      -737.58  |proj g|=        0.9572
At iterate    22  f =      -737.58  |proj g|=       0.95834
At iterate    23  f =      -737.58  |proj g|=       0.95859

iterations 23
function evaluations 31
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.958585
final function value -737.579

F = -737.579
final  value -737.579031 
converged
 
INFO  [23:01:05.733] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:01:05.793] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:01:05.800] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:01:08.770] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:01:11.579] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:01:14.352] [mlr3]  Finished benchmark 
INFO  [23:01:14.423] [bbotk] Result of batch 130: 
INFO  [23:01:14.425] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:01:14.425] [bbotk]              9.437971                 3.559229                       0.1769388 
INFO  [23:01:14.425] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:01:14.425] [bbotk]                     1425        0.872 -0.9470317         <NA>   0.9700596 
INFO  [23:01:14.425] [bbotk]                                 uhash 
INFO  [23:01:14.425] [bbotk]  637b8660-7efe-4085-bbb6-0ad58ad20921 
DEBUG [23:01:16.023] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.456174e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.456174e-05 0.001974382 
  - best initial criterion value(s) :  687.7665 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -687.77  |proj g|=        6.316
At iterate     1  f =      -698.15  |proj g|=        7.3491
At iterate     2  f =      -702.91  |proj g|=        7.3531
At iterate     3  f =      -709.46  |proj g|=         6.594
At iterate     4  f =      -709.68  |proj g|=        6.1773
At iterate     5  f =       -710.2  |proj g|=        6.1693
At iterate     6  f =      -710.76  |proj g|=        5.8063
At iterate     7  f =      -710.77  |proj g|=          5.75
At iterate     8  f =      -710.77  |proj g|=        5.7452
At iterate     9  f =      -710.77  |proj g|=        5.7452
At iterate    10  f =      -710.77  |proj g|=        5.7455
At iterate    11  f =      -710.77  |proj g|=        5.7458
At iterate    12  f =      -710.77  |proj g|=        5.7442
At iterate    13  f =      -710.77  |proj g|=        5.7375
At iterate    14  f =      -710.78  |proj g|=        5.7215
At iterate    15  f =       -710.8  |proj g|=         5.683
At iterate    16  f =      -710.83  |proj g|=        5.6238
At iterate    17  f =       -710.9  |proj g|=        5.5823
At iterate    18  f =      -711.05  |proj g|=        5.4601
At iterate    19  f =      -711.34  |proj g|=        5.4308
At iterate    20  f =      -712.42  |proj g|=        5.0129
At iterate    21  f =      -715.15  |proj g|=        4.0088
At iterate    22  f =      -717.37  |proj g|=        3.7988
At iterate    23  f =      -719.44  |proj g|=        3.7917
At iterate    24  f =      -719.78  |proj g|=        3.9102
At iterate    25  f =       -719.8  |proj g|=        3.9166
At iterate    26  f =      -719.82  |proj g|=         3.915
At iterate    27  f =      -719.82  |proj g|=         3.916
At iterate    28  f =      -719.82  |proj g|=        3.9169
At iterate    29  f =      -719.82  |proj g|=         3.919
At iterate    30  f =      -719.82  |proj g|=        3.9214
At iterate    31  f =      -719.82  |proj g|=        3.9248
At iterate    32  f =      -719.82  |proj g|=        3.9311
At iterate    33  f =      -719.82  |proj g|=        3.9354
At iterate    34  f =      -719.82  |proj g|=        3.9333
At iterate    35  f =      -719.82  |proj g|=        3.9303
At iterate    36  f =      -719.82  |proj g|=        3.9036
At iterate    37  f =      -719.82  |proj g|=        3.8956
At iterate    38  f =      -719.83  |proj g|=        3.8882
At iterate    39  f =      -719.83  |proj g|=        3.8844
At iterate    40  f =      -719.83  |proj g|=        3.8759
At iterate    41  f =      -719.83  |proj g|=        3.8687
At iterate    42  f =      -719.84  |proj g|=         3.828
At iterate    43  f =      -719.85  |proj g|=        3.8315
At iterate    44  f =      -719.87  |proj g|=        3.8407
At iterate    45  f =      -719.89  |proj g|=        3.8265
At iterate    46  f =      -719.95  |proj g|=         3.832
At iterate    47  f =      -721.14  |proj g|=        3.7119
At iterate    48  f =       -726.8  |proj g|=        2.0187
At iterate    49  f =      -735.62  |proj g|=       0.72985
At iterate    50  f =      -739.57  |proj g|=       0.65299
At iterate    51  f =      -740.03  |proj g|=       0.35003
At iterate    52  f =      -740.12  |proj g|=       0.36083
At iterate    53  f =      -740.14  |proj g|=       0.36613
At iterate    54  f =      -740.15  |proj g|=       0.36762
At iterate    55  f =      -740.16  |proj g|=       0.36729
At iterate    56  f =      -740.17  |proj g|=       0.18696
At iterate    57  f =      -740.17  |proj g|=        0.3687
At iterate    58  f =      -740.18  |proj g|=        0.1643
At iterate    59  f =      -740.18  |proj g|=       0.36468
At iterate    60  f =      -740.18  |proj g|=     0.0079597
At iterate    61  f =      -740.18  |proj g|=     0.0079581

iterations 61
function evaluations 71
segments explored during Cauchy searches 64
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00795806
final function value -740.176

F = -740.176
final  value -740.176373 
converged
 
INFO  [23:01:16.028] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:01:16.085] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:01:16.092] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:01:24.658] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:01:33.183] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:01:41.332] [mlr3]  Finished benchmark 
INFO  [23:01:41.401] [bbotk] Result of batch 131: 
INFO  [23:01:41.403] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:01:41.403] [bbotk]              3.399326                  7.85167                       0.1200172 
INFO  [23:01:41.403] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:01:41.403] [bbotk]                     2670        0.825 -0.9493919         <NA>   0.9656216 
INFO  [23:01:41.403] [bbotk]                                 uhash 
INFO  [23:01:41.403] [bbotk]  e3ee666e-da91-4e22-bcb7-41c2527c9d53 
DEBUG [23:01:42.901] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.447509e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.447509e-05 0.001963755 
  - best initial criterion value(s) :  706.5807 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -706.58  |proj g|=       4.4004
At iterate     1  f =      -717.23  |proj g|=        5.7692
At iterate     2  f =      -717.43  |proj g|=        5.7166
At iterate     3  f =      -717.53  |proj g|=         5.623
At iterate     4  f =      -717.53  |proj g|=        5.6379
At iterate     5  f =      -717.53  |proj g|=        5.6368
At iterate     6  f =      -717.53  |proj g|=        5.6367
At iterate     7  f =      -717.53  |proj g|=        5.6365
At iterate     8  f =      -717.53  |proj g|=        5.6373
At iterate     9  f =      -717.53  |proj g|=        5.6411
At iterate    10  f =      -717.53  |proj g|=        5.6488
At iterate    11  f =      -717.53  |proj g|=        5.6421
At iterate    12  f =      -717.53  |proj g|=        5.6498
At iterate    13  f =      -719.08  |proj g|=        5.4055
At iterate    14  f =      -725.61  |proj g|=        4.6219
At iterate    15  f =      -725.66  |proj g|=        4.7908
At iterate    16  f =      -725.67  |proj g|=        4.7982
At iterate    17  f =      -725.67  |proj g|=        4.8069
At iterate    18  f =      -725.67  |proj g|=        4.7994
At iterate    19  f =      -725.67  |proj g|=         4.796
At iterate    20  f =      -725.67  |proj g|=        4.7937
At iterate    21  f =      -725.67  |proj g|=        4.7867
At iterate    22  f =      -725.67  |proj g|=        4.7671
At iterate    23  f =      -725.68  |proj g|=        4.7506
At iterate    24  f =       -725.7  |proj g|=        4.6161
At iterate    25  f =      -725.74  |proj g|=        4.4436
At iterate    26  f =      -725.85  |proj g|=        4.1353
At iterate    27  f =      -726.07  |proj g|=        3.8348
At iterate    28  f =      -726.67  |proj g|=        3.9678
At iterate    29  f =      -726.68  |proj g|=        3.9867
At iterate    30  f =      -727.71  |proj g|=        3.9826
At iterate    31  f =      -732.14  |proj g|=        4.8674
At iterate    32  f =      -738.51  |proj g|=        3.0694
At iterate    33  f =      -745.69  |proj g|=       0.80661
At iterate    34  f =      -747.11  |proj g|=       0.34342
At iterate    35  f =      -747.31  |proj g|=       0.76061
At iterate    36  f =      -747.74  |proj g|=       0.36731
At iterate    37  f =      -747.79  |proj g|=        0.3743
At iterate    38  f =       -747.8  |proj g|=       0.37564
At iterate    39  f =      -747.81  |proj g|=       0.37514
At iterate    40  f =      -747.81  |proj g|=       0.37398
At iterate    41  f =      -747.81  |proj g|=       0.19985
At iterate    42  f =      -747.81  |proj g|=       0.61049
At iterate    43  f =      -747.81  |proj g|=      0.051445
At iterate    44  f =      -747.81  |proj g|=     0.0067519
At iterate    45  f =      -747.81  |proj g|=     0.0066966

iterations 45
function evaluations 55
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00669656
final function value -747.809

F = -747.809
final  value -747.808978 
converged
 
INFO  [23:01:42.906] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:01:42.963] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:01:42.970] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:01:47.849] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:01:53.067] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:01:58.982] [mlr3]  Finished benchmark 
INFO  [23:01:59.073] [bbotk] Result of batch 132: 
INFO  [23:01:59.075] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:01:59.075] [bbotk]              6.600389                 2.590169                       0.3918588 
INFO  [23:01:59.075] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:01:59.075] [bbotk]                     2040        0.833 -0.9483873         <NA>   0.9748188 
INFO  [23:01:59.075] [bbotk]                                 uhash 
INFO  [23:01:59.075] [bbotk]  51a22d32-e8bf-4d0e-81d2-7fad5a6965bf 
DEBUG [23:02:00.404] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.441356e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.441356e-05 0.001952413 
  - best initial criterion value(s) :  708.4851 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -708.49  |proj g|=       4.2746
At iterate     1  f =      -710.52  |proj g|=        3.5381
At iterate     2  f =      -720.73  |proj g|=        3.2611
At iterate     3  f =      -726.47  |proj g|=        2.6741
At iterate     4  f =      -727.28  |proj g|=        2.5413
At iterate     5  f =       -728.2  |proj g|=        2.8302
At iterate     6  f =      -728.22  |proj g|=        2.8109
At iterate     7  f =      -728.22  |proj g|=        2.8091
At iterate     8  f =      -728.22  |proj g|=          2.81
At iterate     9  f =      -728.22  |proj g|=        2.8099

iterations 9
function evaluations 12
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.80995
final function value -728.222

F = -728.222
final  value -728.222187 
converged
 
INFO  [23:02:00.408] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:02:00.464] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:02:00.471] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:02:05.247] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:02:09.172] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:02:12.946] [mlr3]  Finished benchmark 
INFO  [23:02:13.018] [bbotk] Result of batch 133: 
INFO  [23:02:13.020] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:02:13.020] [bbotk]              3.010522                 5.572867                        0.284763 
INFO  [23:02:13.020] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:02:13.020] [bbotk]                     1413         1.01 -0.9537761         <NA>     0.96421 
INFO  [23:02:13.020] [bbotk]                                 uhash 
INFO  [23:02:13.020] [bbotk]  086b36e9-f7b0-4312-abcf-85e0ffc8de5a 
DEBUG [23:02:14.174] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.433448e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9821542 9500 
  - variance bounds :  1.433448e-05 0.001935058 
  - best initial criterion value(s) :  708.2006 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -708.2  |proj g|=       9.9573
At iterate     1  f =      -737.06  |proj g|=          4.58
At iterate     2  f =      -746.61  |proj g|=        1.5039
At iterate     3  f =      -750.07  |proj g|=       0.71728
At iterate     4  f =      -750.29  |proj g|=       0.71656
At iterate     5  f =      -750.55  |proj g|=       0.72968
At iterate     6  f =      -750.58  |proj g|=       0.72198
At iterate     7  f =      -750.59  |proj g|=       0.72405
At iterate     8  f =      -750.59  |proj g|=       0.72425
At iterate     9  f =      -750.59  |proj g|=       0.72422

iterations 9
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.724216
final function value -750.591

F = -750.591
final  value -750.591365 
converged
 
INFO  [23:02:14.178] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:02:14.239] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:02:14.246] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:02:26.691] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:02:38.523] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:02:49.732] [mlr3]  Finished benchmark 
INFO  [23:02:49.803] [bbotk] Result of batch 134: 
INFO  [23:02:49.805] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:02:49.805] [bbotk]              8.372325                 3.093544                     0.008304733 
INFO  [23:02:49.805] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:02:49.805] [bbotk]                     4123        0.813 -0.9508605         <NA>   0.9483177 
INFO  [23:02:49.805] [bbotk]                                 uhash 
INFO  [23:02:49.805] [bbotk]  d78c6840-e828-4fe6-b81c-23493845e375 
DEBUG [23:02:51.176] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.448427e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.448427e-05 0.001938579 
  - best initial criterion value(s) :  716.1053 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -716.11  |proj g|=        8.797
At iterate     1  f =      -735.48  |proj g|=        8.5564
At iterate     2  f =      -740.42  |proj g|=        7.0213
At iterate     3  f =      -742.13  |proj g|=        4.6536
At iterate     4  f =      -743.52  |proj g|=        4.1147
At iterate     5  f =      -743.52  |proj g|=        4.0277
At iterate     6  f =      -743.52  |proj g|=        4.0318
At iterate     7  f =      -743.52  |proj g|=        4.0345
At iterate     8  f =      -743.53  |proj g|=        4.0412
At iterate     9  f =      -743.53  |proj g|=        4.0533
At iterate    10  f =      -743.53  |proj g|=        4.0715
At iterate    11  f =      -743.55  |proj g|=        4.1021
At iterate    12  f =      -743.59  |proj g|=        4.1777
At iterate    13  f =       -743.7  |proj g|=        4.2755
At iterate    14  f =      -743.96  |proj g|=        4.5145
At iterate    15  f =      -744.01  |proj g|=        4.2337
At iterate    16  f =      -744.62  |proj g|=        4.4987
At iterate    17  f =      -748.11  |proj g|=        3.8543
At iterate    18  f =      -751.07  |proj g|=        1.2884
At iterate    19  f =      -756.25  |proj g|=       0.74831
At iterate    20  f =      -756.77  |proj g|=        1.0759
At iterate    21  f =      -757.99  |proj g|=       0.81769
At iterate    22  f =      -758.32  |proj g|=       0.86724
At iterate    23  f =      -758.37  |proj g|=       0.88373
At iterate    24  f =      -758.38  |proj g|=       0.88952
At iterate    25  f =      -758.38  |proj g|=       0.88986
At iterate    26  f =      -758.38  |proj g|=       0.88945
At iterate    27  f =      -758.38  |proj g|=       0.88947

iterations 27
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.889466
final function value -758.383

F = -758.383
final  value -758.382538 
converged
 
INFO  [23:02:51.181] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:02:51.249] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:02:51.268] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:03:05.301] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:03:16.821] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:03:28.849] [mlr3]  Finished benchmark 
INFO  [23:03:28.920] [bbotk] Result of batch 135: 
INFO  [23:03:28.922] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:03:28.922] [bbotk]               6.64686                 6.918543                        0.223186 
INFO  [23:03:28.922] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:03:28.922] [bbotk]                     4203         0.84 -0.9438021         <NA>   0.9751244 
INFO  [23:03:28.922] [bbotk]                                 uhash 
INFO  [23:03:28.922] [bbotk]  2d1f202b-85fb-4732-93e6-325abbfe514e 
DEBUG [23:03:30.419] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.442723e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.442723e-05 0.001935813 
  - best initial criterion value(s) :  683.1957 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -683.2  |proj g|=        9.676
At iterate     1  f =      -704.81  |proj g|=        8.6915
At iterate     2  f =      -708.92  |proj g|=        9.0668
At iterate     3  f =      -719.71  |proj g|=        8.0938
At iterate     4  f =      -721.69  |proj g|=        7.5243
At iterate     5  f =       -722.2  |proj g|=        6.5069
At iterate     6  f =      -722.38  |proj g|=        6.4572
At iterate     7  f =      -722.38  |proj g|=        6.4155
At iterate     8  f =      -722.38  |proj g|=        6.4138
At iterate     9  f =      -722.38  |proj g|=        6.4118
At iterate    10  f =      -722.38  |proj g|=        6.4086
At iterate    11  f =      -722.38  |proj g|=        6.4041
At iterate    12  f =      -722.38  |proj g|=        6.3993
At iterate    13  f =      -722.39  |proj g|=         6.397
At iterate    14  f =       -722.4  |proj g|=        6.4076
At iterate    15  f =      -722.44  |proj g|=        6.4594
At iterate    16  f =      -722.51  |proj g|=        6.6046
At iterate    17  f =      -722.61  |proj g|=         6.914
At iterate    18  f =      -722.61  |proj g|=        6.9429
At iterate    19  f =      -722.61  |proj g|=        6.9482
At iterate    20  f =      -722.61  |proj g|=        6.9634
At iterate    21  f =      -722.62  |proj g|=        6.9896
At iterate    22  f =      -722.63  |proj g|=        7.0411
At iterate    23  f =      -722.65  |proj g|=        7.1272
At iterate    24  f =      -722.71  |proj g|=         7.277
At iterate    25  f =      -722.77  |proj g|=        7.4392
At iterate    26  f =      -722.83  |proj g|=        7.5408
At iterate    27  f =      -722.97  |proj g|=        7.6131
At iterate    28  f =      -723.13  |proj g|=        7.6497
At iterate    29  f =       -723.8  |proj g|=        7.7011
At iterate    30  f =      -725.19  |proj g|=        7.5469
At iterate    31  f =      -728.22  |proj g|=        7.0832
At iterate    32  f =      -728.57  |proj g|=        6.3437
At iterate    33  f =      -732.63  |proj g|=        5.2507
At iterate    34  f =      -737.65  |proj g|=        3.7725
At iterate    35  f =      -738.32  |proj g|=        4.5447
At iterate    36  f =      -738.35  |proj g|=        4.7113
At iterate    37  f =      -738.35  |proj g|=        4.7525
At iterate    38  f =      -738.36  |proj g|=         4.735
At iterate    39  f =      -738.36  |proj g|=        4.7436
At iterate    40  f =      -738.36  |proj g|=         4.732
At iterate    41  f =      -738.36  |proj g|=        4.7291
At iterate    42  f =      -738.36  |proj g|=        4.7288

iterations 42
function evaluations 50
segments explored during Cauchy searches 45
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.72883
final function value -738.355

F = -738.355
final  value -738.355467 
converged
 
INFO  [23:03:30.423] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:03:30.483] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:03:30.490] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:03:32.804] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:03:35.211] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:03:37.609] [mlr3]  Finished benchmark 
INFO  [23:03:37.680] [bbotk] Result of batch 136: 
INFO  [23:03:37.682] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:03:37.682] [bbotk]              2.004576                 4.890838                       0.1036614 
INFO  [23:03:37.682] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:03:37.682] [bbotk]                      661        0.853 -0.9531683         <NA>   0.9249432 
INFO  [23:03:37.682] [bbotk]                                 uhash 
INFO  [23:03:37.682] [bbotk]  7f1eadb2-d42f-48ab-9028-4cbab58690bf 
DEBUG [23:03:38.945] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.545167e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.545167e-05 0.00209662 
  - best initial criterion value(s) :  659.1267 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -659.13  |proj g|=      0.86572
At iterate     1  f =      -692.23  |proj g|=        10.592
At iterate     2  f =      -698.69  |proj g|=        10.567
At iterate     3  f =      -702.55  |proj g|=        10.484
At iterate     4  f =      -705.55  |proj g|=        10.522
At iterate     5  f =      -706.34  |proj g|=        10.515
At iterate     6  f =      -710.03  |proj g|=        10.479
At iterate     7  f =      -734.95  |proj g|=        10.421
At iterate     8  f =      -736.17  |proj g|=        10.426
At iterate     9  f =       -736.2  |proj g|=         10.43
At iterate    10  f =      -736.23  |proj g|=        10.429
At iterate    11  f =      -736.23  |proj g|=        10.429
At iterate    12  f =      -736.23  |proj g|=        10.429
At iterate    13  f =      -736.23  |proj g|=        10.429

iterations 13
function evaluations 20
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 10.429
final function value -736.233

F = -736.233
final  value -736.233416 
converged
 
INFO  [23:03:38.949] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:03:39.005] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:03:39.012] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:03:42.339] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:03:46.381] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:03:50.874] [mlr3]  Finished benchmark 
INFO  [23:03:50.941] [bbotk] Result of batch 137: 
INFO  [23:03:50.943] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:03:50.943] [bbotk]              4.371935                 8.214792                      0.02681829 
INFO  [23:03:50.943] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:03:50.943] [bbotk]                     1305        0.847 -0.9542827         <NA>   0.9411629 
INFO  [23:03:50.943] [bbotk]                                 uhash 
INFO  [23:03:50.943] [bbotk]  bf8f62dd-50f0-49a2-9b2d-3bb449cafd16 
DEBUG [23:03:52.311] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.578041e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.578041e-05 0.002133831 
  - best initial criterion value(s) :  734.3855 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -734.39  |proj g|=       4.5069
At iterate     1  f =      -739.83  |proj g|=        2.5208
At iterate     2  f =         -746  |proj g|=        1.7299
At iterate     3  f =       -746.7  |proj g|=        1.3991
At iterate     4  f =      -747.35  |proj g|=        1.4808
At iterate     5  f =      -747.36  |proj g|=        1.5831
At iterate     6  f =      -747.37  |proj g|=        1.5495
At iterate     7  f =      -747.37  |proj g|=        1.5497
At iterate     8  f =      -747.37  |proj g|=        1.5497

iterations 8
function evaluations 15
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.54974
final function value -747.37

F = -747.37
final  value -747.369849 
converged
 
INFO  [23:03:52.315] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:03:52.371] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:03:52.378] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:03:56.377] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:03:59.499] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:04:03.522] [mlr3]  Finished benchmark 
INFO  [23:04:03.590] [bbotk] Result of batch 138: 
INFO  [23:04:03.592] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:04:03.592] [bbotk]              8.406068                 4.935471                       0.3620393 
INFO  [23:04:03.592] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:04:03.592] [bbotk]                     1223        0.831 -0.9522169         <NA>   0.9728993 
INFO  [23:04:03.592] [bbotk]                                 uhash 
INFO  [23:04:03.592] [bbotk]  b2382377-a8e9-4141-bc8a-2b1409cbe43b 
DEBUG [23:04:05.229] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.570305e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.570305e-05 0.00211184 
  - best initial criterion value(s) :  709.6519 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -709.65  |proj g|=       6.0156
At iterate     1  f =      -747.56  |proj g|=        8.3931
At iterate     2  f =      -748.27  |proj g|=        8.4319
At iterate     3  f =      -749.44  |proj g|=        7.7297
At iterate     4  f =      -749.65  |proj g|=        7.7727
At iterate     5  f =      -749.75  |proj g|=        7.5575
At iterate     6  f =      -749.82  |proj g|=        7.1072
At iterate     7  f =      -749.82  |proj g|=        7.1324
At iterate     8  f =      -749.82  |proj g|=        7.1421
At iterate     9  f =      -749.82  |proj g|=        7.1642
At iterate    10  f =      -749.82  |proj g|=        7.1965
At iterate    11  f =      -749.83  |proj g|=        7.2485
At iterate    12  f =      -749.84  |proj g|=        7.3332
At iterate    13  f =      -749.88  |proj g|=        7.4671
At iterate    14  f =      -749.96  |proj g|=        7.6559
At iterate    15  f =      -750.17  |proj g|=        7.9295
At iterate    16  f =      -750.22  |proj g|=        8.0272
At iterate    17  f =       -750.7  |proj g|=        8.2657
At iterate    18  f =      -754.16  |proj g|=        7.8214
At iterate    19  f =      -766.05  |proj g|=        4.0937
At iterate    20  f =      -769.12  |proj g|=        3.9493
At iterate    21  f =      -769.84  |proj g|=        4.3413
At iterate    22  f =      -769.85  |proj g|=        4.4662
At iterate    23  f =      -769.91  |proj g|=        4.5508
At iterate    24  f =      -769.91  |proj g|=        4.5664
At iterate    25  f =      -769.91  |proj g|=        4.5734
At iterate    26  f =      -769.91  |proj g|=        4.5731
At iterate    27  f =      -769.91  |proj g|=        4.5711
At iterate    28  f =      -769.91  |proj g|=        4.5695
At iterate    29  f =      -769.91  |proj g|=        4.5659
At iterate    30  f =      -769.91  |proj g|=        4.5591
At iterate    31  f =      -769.91  |proj g|=        4.5467
At iterate    32  f =      -769.91  |proj g|=        4.5288
At iterate    33  f =      -769.91  |proj g|=        4.5222
At iterate    34  f =      -769.92  |proj g|=        4.5001
At iterate    35  f =      -769.93  |proj g|=        4.4912
At iterate    36  f =      -769.93  |proj g|=        4.4914
At iterate    37  f =      -769.93  |proj g|=        4.4906
At iterate    38  f =      -769.93  |proj g|=        4.4888
At iterate    39  f =      -769.93  |proj g|=        4.4697
At iterate    40  f =      -769.94  |proj g|=        4.4968
At iterate    41  f =      -769.95  |proj g|=        4.4807
At iterate    42  f =      -770.07  |proj g|=        4.3597
At iterate    43  f =      -770.29  |proj g|=        4.2001
At iterate    44  f =       -770.9  |proj g|=        3.8635
At iterate    45  f =      -772.19  |proj g|=        3.3031
At iterate    46  f =      -774.68  |proj g|=        2.5735
At iterate    47  f =      -775.02  |proj g|=        2.2615
At iterate    48  f =      -779.93  |proj g|=        1.5446
At iterate    49  f =      -792.08  |proj g|=       0.55041
At iterate    50  f =      -792.33  |proj g|=       0.56935
At iterate    51  f =      -792.42  |proj g|=       0.40389
At iterate    52  f =      -792.44  |proj g|=       0.57624
At iterate    53  f =      -792.44  |proj g|=       0.57648
At iterate    54  f =      -792.44  |proj g|=       0.57638
At iterate    55  f =      -792.44  |proj g|=       0.28122
At iterate    56  f =      -792.44  |proj g|=      0.027351
At iterate    57  f =      -792.44  |proj g|=      0.085579
At iterate    58  f =      -792.44  |proj g|=    0.00062389
At iterate    59  f =      -792.44  |proj g|=    0.00029795

iterations 59
function evaluations 68
segments explored during Cauchy searches 61
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000297955
final function value -792.44

F = -792.44
final  value -792.439541 
converged
 
INFO  [23:04:05.233] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:04:05.289] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:04:05.295] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:04:17.615] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:04:29.001] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:04:39.477] [mlr3]  Finished benchmark 
INFO  [23:04:39.544] [bbotk] Result of batch 139: 
INFO  [23:04:39.546] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:04:39.546] [bbotk]              6.857297                 9.624859                       0.1525188 
INFO  [23:04:39.546] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [23:04:39.546] [bbotk]                     3967        0.848 -0.935396         <NA>   0.9741375 
INFO  [23:04:39.546] [bbotk]                                 uhash 
INFO  [23:04:39.546] [bbotk]  32491283-21c6-4789-b57a-77374ae2d057 
DEBUG [23:04:40.988] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.563497e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.563497e-05 0.002107885 
  - best initial criterion value(s) :  734.0722 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -734.07  |proj g|=       2.8463
At iterate     1  f =      -749.08  |proj g|=        7.5553
At iterate     2  f =       -750.2  |proj g|=        7.3205
At iterate     3  f =      -753.58  |proj g|=        6.3842
At iterate     4  f =      -754.55  |proj g|=        5.7377
At iterate     5  f =      -755.19  |proj g|=        5.6055
At iterate     6  f =      -756.01  |proj g|=        5.8546
At iterate     7  f =      -756.08  |proj g|=        6.1268
At iterate     8  f =      -756.12  |proj g|=        5.9981
At iterate     9  f =      -756.12  |proj g|=        5.9929
At iterate    10  f =      -756.12  |proj g|=         5.993
At iterate    11  f =      -756.12  |proj g|=        5.9985
At iterate    12  f =      -756.13  |proj g|=        6.0068
At iterate    13  f =      -756.14  |proj g|=        6.0225
At iterate    14  f =      -756.19  |proj g|=        5.9943
At iterate    15  f =       -756.2  |proj g|=        6.0879
At iterate    16  f =       -756.3  |proj g|=        6.0374
At iterate    17  f =      -756.87  |proj g|=        5.8307
At iterate    18  f =      -759.58  |proj g|=        4.9657
At iterate    19  f =      -765.95  |proj g|=        3.2847
At iterate    20  f =      -776.64  |proj g|=        1.6522
At iterate    21  f =      -777.59  |proj g|=        1.1743
At iterate    22  f =      -787.35  |proj g|=       0.44716
At iterate    23  f =      -787.81  |proj g|=       0.66765
At iterate    24  f =      -788.18  |proj g|=       0.35113
At iterate    25  f =       -788.2  |proj g|=       0.34242
At iterate    26  f =       -788.2  |proj g|=       0.17198
At iterate    27  f =       -788.2  |proj g|=       0.17361
At iterate    28  f =       -788.2  |proj g|=       0.17353

iterations 28
function evaluations 38
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.173529
final function value -788.199

F = -788.199
final  value -788.198615 
converged
 
INFO  [23:04:40.992] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:04:41.048] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:04:41.054] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:04:54.424] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:05:07.645] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:05:20.669] [mlr3]  Finished benchmark 
INFO  [23:05:20.737] [bbotk] Result of batch 140: 
INFO  [23:05:20.739] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:05:20.739] [bbotk]              6.864422                  8.26773                       0.2298306 
INFO  [23:05:20.739] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [23:05:20.739] [bbotk]                     4348        0.861 -0.943289         <NA>   0.9752674 
INFO  [23:05:20.739] [bbotk]                                 uhash 
INFO  [23:05:20.739] [bbotk]  402a723d-95d8-4ae4-b12a-aff4340cc710 
DEBUG [23:05:22.850] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.557669e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.557669e-05 0.002105247 
  - best initial criterion value(s) :  713.255 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -713.26  |proj g|=       8.2855
At iterate     1  f =      -754.19  |proj g|=        8.7685
At iterate     2  f =      -756.48  |proj g|=         8.867
At iterate     3  f =      -758.31  |proj g|=          8.18
At iterate     4  f =       -759.2  |proj g|=        8.7455
At iterate     5  f =      -759.35  |proj g|=        8.6249
At iterate     6  f =      -759.37  |proj g|=        8.5568
At iterate     7  f =      -759.39  |proj g|=        8.4969
At iterate     8  f =      -759.43  |proj g|=        8.3471
At iterate     9  f =      -759.43  |proj g|=        8.3278
At iterate    10  f =      -759.43  |proj g|=        8.3312
At iterate    11  f =      -759.43  |proj g|=        8.3326
At iterate    12  f =      -759.43  |proj g|=        8.3367
At iterate    13  f =      -759.43  |proj g|=        8.3416
At iterate    14  f =      -759.44  |proj g|=        8.3501
At iterate    15  f =      -759.44  |proj g|=        8.3629
At iterate    16  f =      -759.45  |proj g|=        8.3812
At iterate    17  f =      -759.48  |proj g|=        8.4029
At iterate    18  f =      -759.56  |proj g|=        8.4154
At iterate    19  f =      -759.75  |proj g|=        8.3732
At iterate    20  f =      -760.21  |proj g|=        8.1626
At iterate    21  f =      -761.11  |proj g|=         7.604
At iterate    22  f =      -762.57  |proj g|=        6.4613
At iterate    23  f =      -762.72  |proj g|=        5.9868
At iterate    24  f =      -762.77  |proj g|=        6.2006
At iterate    25  f =      -762.77  |proj g|=        6.1809
At iterate    26  f =      -762.77  |proj g|=        6.1699
At iterate    27  f =      -762.77  |proj g|=        6.1573
At iterate    28  f =      -762.78  |proj g|=        6.1587
At iterate    29  f =       -762.8  |proj g|=        6.1879
At iterate    30  f =      -762.81  |proj g|=        6.2598
At iterate    31  f =         -763  |proj g|=        6.2749
At iterate    32  f =      -764.75  |proj g|=        6.0715
At iterate    33  f =      -766.38  |proj g|=        5.9601
At iterate    34  f =       -767.6  |proj g|=        6.1191
At iterate    35  f =      -767.96  |proj g|=        5.2989
At iterate    36  f =      -768.02  |proj g|=        5.4838
At iterate    37  f =      -768.03  |proj g|=        5.5645
At iterate    38  f =      -768.03  |proj g|=        5.5635
At iterate    39  f =      -768.03  |proj g|=         5.566
At iterate    40  f =      -768.03  |proj g|=        5.5808
At iterate    41  f =      -768.04  |proj g|=        5.5962
At iterate    42  f =      -768.04  |proj g|=        5.6794
At iterate    43  f =      -768.06  |proj g|=        5.6576
At iterate    44  f =      -768.18  |proj g|=        5.7727
At iterate    45  f =      -769.01  |proj g|=         6.113
At iterate    46  f =      -771.01  |proj g|=        6.3569
At iterate    47  f =      -775.78  |proj g|=        6.0675
At iterate    48  f =       -784.1  |proj g|=        4.6561
At iterate    49  f =      -784.22  |proj g|=        4.5494
At iterate    50  f =      -784.25  |proj g|=        4.4421
At iterate    51  f =      -784.25  |proj g|=        4.4551
At iterate    52  f =      -784.25  |proj g|=        4.4544
At iterate    53  f =      -784.25  |proj g|=        4.4567
At iterate    54  f =      -784.25  |proj g|=        4.4632
At iterate    55  f =      -784.25  |proj g|=        4.4748
At iterate    56  f =      -784.26  |proj g|=        4.4897
At iterate    57  f =      -784.27  |proj g|=        4.5061
At iterate    58  f =       -784.3  |proj g|=        4.5112
At iterate    59  f =      -784.34  |proj g|=         4.476
At iterate    60  f =      -784.36  |proj g|=        4.3888
At iterate    61  f =      -784.37  |proj g|=        4.3583
At iterate    62  f =      -784.37  |proj g|=        4.3563
At iterate    63  f =      -784.37  |proj g|=        4.3538
At iterate    64  f =      -784.37  |proj g|=        4.3512
At iterate    65  f =      -784.37  |proj g|=         4.346
At iterate    66  f =      -784.38  |proj g|=        4.3419
At iterate    67  f =      -784.38  |proj g|=        4.3296
At iterate    68  f =      -784.38  |proj g|=        4.3246
At iterate    69  f =       -784.4  |proj g|=        4.3081
At iterate    70  f =      -784.46  |proj g|=        4.2651
At iterate    71  f =      -784.74  |proj g|=        4.1437
At iterate    72  f =      -785.52  |proj g|=        3.8401
At iterate    73  f =      -785.57  |proj g|=        3.9931
At iterate    74  f =      -787.07  |proj g|=        3.3921
At iterate    75  f =      -789.61  |proj g|=        2.6223
At iterate    76  f =       -794.5  |proj g|=       0.54717
At iterate    77  f =       -796.2  |proj g|=       0.52668
At iterate    78  f =      -800.75  |proj g|=       0.41473
At iterate    79  f =      -800.82  |proj g|=       0.40377
At iterate    80  f =      -801.05  |proj g|=       0.61346
At iterate    81  f =       -801.1  |proj g|=       0.38312
At iterate    82  f =      -801.11  |proj g|=       0.22843
At iterate    83  f =      -801.11  |proj g|=       0.09732
At iterate    84  f =      -801.11  |proj g|=       0.09713

iterations 84
function evaluations 98
segments explored during Cauchy searches 86
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.09713
final function value -801.105

F = -801.105
final  value -801.105239 
converged
 
INFO  [23:05:22.854] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:05:22.908] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:05:22.915] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:05:26.612] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:05:29.180] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:05:31.725] [mlr3]  Finished benchmark 
INFO  [23:05:31.794] [bbotk] Result of batch 141: 
INFO  [23:05:31.795] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:05:31.795] [bbotk]              3.816304                 5.272159                       0.1810504 
INFO  [23:05:31.795] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:05:31.795] [bbotk]                      885        0.861 -0.9383254         <NA>    0.960952 
INFO  [23:05:31.795] [bbotk]                                 uhash 
INFO  [23:05:31.795] [bbotk]  ba105ac8-cf40-4282-a360-ff0360785a57 
DEBUG [23:05:33.198] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.551224e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.551224e-05 0.002091878 
  - best initial criterion value(s) :  733.3628 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -733.36  |proj g|=       6.1197
At iterate     1  f =      -750.05  |proj g|=       0.99964
At iterate     2  f =      -764.05  |proj g|=        5.9549
At iterate     3  f =      -767.18  |proj g|=        4.5197
At iterate     4  f =      -768.26  |proj g|=        4.4156
At iterate     5  f =      -770.09  |proj g|=        3.9864
At iterate     6  f =      -771.18  |proj g|=        4.4494
At iterate     7  f =      -772.01  |proj g|=        5.3468
At iterate     8  f =      -772.04  |proj g|=        5.4211
At iterate     9  f =      -772.05  |proj g|=        5.2887
At iterate    10  f =      -772.05  |proj g|=        5.3187
At iterate    11  f =      -772.05  |proj g|=        5.3299
At iterate    12  f =      -772.05  |proj g|=        5.3418
At iterate    13  f =      -772.05  |proj g|=        5.3807
At iterate    14  f =      -772.07  |proj g|=        5.4289
At iterate    15  f =       -772.1  |proj g|=        5.5113
At iterate    16  f =      -772.18  |proj g|=        5.6219
At iterate    17  f =      -772.39  |proj g|=        5.7626
At iterate    18  f =       -772.9  |proj g|=        5.8287
At iterate    19  f =      -772.99  |proj g|=        5.9873
At iterate    20  f =      -774.14  |proj g|=        5.8138
At iterate    21  f =      -794.27  |proj g|=        3.5123
At iterate    22  f =      -803.16  |proj g|=        2.2581
At iterate    23  f =      -803.98  |proj g|=        2.0629
At iterate    24  f =      -804.25  |proj g|=        2.0626
At iterate    25  f =      -804.25  |proj g|=        2.0626
At iterate    26  f =      -804.25  |proj g|=        2.0626
At iterate    27  f =      -804.25  |proj g|=        2.0626

iterations 27
function evaluations 33
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.06257
final function value -804.248

F = -804.248
final  value -804.247537 
converged
 
INFO  [23:05:33.202] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:05:33.259] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:05:33.266] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:05:48.059] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:05:58.146] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:06:07.291] [mlr3]  Finished benchmark 
INFO  [23:06:07.408] [bbotk] Result of batch 142: 
INFO  [23:06:07.410] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:06:07.410] [bbotk]              7.065097                 3.200033                      0.09909087 
INFO  [23:06:07.410] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:06:07.410] [bbotk]                     4536        0.856 -0.9378935         <NA>   0.9726961 
INFO  [23:06:07.410] [bbotk]                                 uhash 
INFO  [23:06:07.410] [bbotk]  db0f23f5-0631-4759-a712-21730ab3d254 
DEBUG [23:06:09.471] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.543659e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.543659e-05 0.002083138 
  - best initial criterion value(s) :  720.569 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -720.57  |proj g|=       5.7112
At iterate     1  f =      -769.43  |proj g|=         5.252
At iterate     2  f =      -771.54  |proj g|=        5.1197
At iterate     3  f =      -773.33  |proj g|=        5.7594
At iterate     4  f =      -773.61  |proj g|=        5.2987
At iterate     5  f =      -773.62  |proj g|=        5.3275
At iterate     6  f =      -773.62  |proj g|=           5.3
At iterate     7  f =      -773.63  |proj g|=        5.3214
At iterate     8  f =      -773.63  |proj g|=        5.3199
At iterate     9  f =      -773.63  |proj g|=        5.3175
At iterate    10  f =      -773.63  |proj g|=        5.3047
At iterate    11  f =      -773.63  |proj g|=        5.2903
At iterate    12  f =      -773.63  |proj g|=        5.2823
At iterate    13  f =      -773.65  |proj g|=        5.2607
At iterate    14  f =       -774.5  |proj g|=        7.2661
At iterate    15  f =      -775.12  |proj g|=        6.4223
At iterate    16  f =      -775.14  |proj g|=         6.252
At iterate    17  f =      -775.14  |proj g|=        6.2643
At iterate    18  f =      -775.14  |proj g|=        6.2686
At iterate    19  f =      -775.14  |proj g|=        6.2702
At iterate    20  f =      -775.14  |proj g|=        6.2727
At iterate    21  f =      -775.14  |proj g|=        6.2777
At iterate    22  f =      -775.14  |proj g|=        6.2829
At iterate    23  f =      -775.14  |proj g|=        6.2831
At iterate    24  f =      -775.14  |proj g|=        6.2845
At iterate    25  f =      -775.14  |proj g|=        6.2747
At iterate    26  f =      -775.14  |proj g|=        6.2557
At iterate    27  f =      -775.14  |proj g|=        6.2499
At iterate    28  f =      -775.14  |proj g|=         6.238
At iterate    29  f =      -775.14  |proj g|=        6.2193
At iterate    30  f =      -775.15  |proj g|=        6.1932
At iterate    31  f =      -775.15  |proj g|=        6.1684
At iterate    32  f =      -775.15  |proj g|=        6.1409
At iterate    33  f =      -775.16  |proj g|=        6.0567
At iterate    34  f =      -775.19  |proj g|=        6.0679
At iterate    35  f =      -775.29  |proj g|=         6.123
At iterate    36  f =      -775.66  |proj g|=        6.2136
At iterate    37  f =      -776.21  |proj g|=        6.6315
At iterate    38  f =      -777.75  |proj g|=        6.4375
At iterate    39  f =       -782.3  |proj g|=        6.1909
At iterate    40  f =      -790.91  |proj g|=        5.4743
At iterate    41  f =      -791.16  |proj g|=         5.786
At iterate    42  f =      -791.16  |proj g|=        5.7664
At iterate    43  f =      -791.16  |proj g|=        5.7627
At iterate    44  f =      -791.16  |proj g|=        5.7633
At iterate    45  f =      -791.17  |proj g|=        5.7538
At iterate    46  f =      -791.17  |proj g|=        5.7369
At iterate    47  f =       -791.2  |proj g|=        5.6824
At iterate    48  f =      -791.26  |proj g|=        5.6136
At iterate    49  f =      -791.39  |proj g|=        5.5111
At iterate    50  f =      -791.58  |proj g|=        5.4324
At iterate    51  f =      -791.71  |proj g|=        5.6863
At iterate    52  f =       -791.8  |proj g|=        5.5803
At iterate    53  f =       -791.8  |proj g|=        5.5733
At iterate    54  f =       -791.8  |proj g|=        5.5748
At iterate    55  f =       -791.8  |proj g|=        5.5758
At iterate    56  f =       -791.8  |proj g|=        5.5763
At iterate    57  f =       -791.8  |proj g|=        5.5767
At iterate    58  f =       -791.8  |proj g|=        5.5781
At iterate    59  f =       -791.8  |proj g|=        5.5782
At iterate    60  f =      -791.81  |proj g|=         5.581
At iterate    61  f =      -791.81  |proj g|=        5.5743
At iterate    62  f =      -791.81  |proj g|=        5.5982
At iterate    63  f =      -791.82  |proj g|=        5.5834
At iterate    64  f =      -796.47  |proj g|=        4.6871
At iterate    65  f =      -814.42  |proj g|=        0.5859
At iterate    66  f =      -814.85  |proj g|=       0.42404
At iterate    67  f =       -814.9  |proj g|=       0.41542
At iterate    68  f =      -814.91  |proj g|=      0.039452
At iterate    69  f =      -814.91  |proj g|=      0.020158
At iterate    70  f =      -814.91  |proj g|=    0.00074536

iterations 70
function evaluations 84
segments explored during Cauchy searches 72
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000745356
final function value -814.908

F = -814.908
final  value -814.907855 
converged
 
INFO  [23:06:09.476] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:06:09.539] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:06:09.547] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:06:12.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:06:15.939] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:06:19.130] [mlr3]  Finished benchmark 
INFO  [23:06:19.201] [bbotk] Result of batch 143: 
INFO  [23:06:19.203] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:06:19.203] [bbotk]              7.314553                 5.341948                      0.09259792 
INFO  [23:06:19.203] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [23:06:19.203] [bbotk]                     1550        0.988 -0.934017         <NA>    0.965258 
INFO  [23:06:19.203] [bbotk]                                 uhash 
INFO  [23:06:19.203] [bbotk]  8c8aa7c8-7fd6-4bc1-ad96-e0a98a15da66 
DEBUG [23:06:21.182] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.535082e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.535082e-05 0.002065878 
  - best initial criterion value(s) :  768.3554 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -768.36  |proj g|=       5.4673
At iterate     1  f =      -789.04  |proj g|=        2.4461
At iterate     2  f =      -793.12  |proj g|=        2.4182
At iterate     3  f =       -795.1  |proj g|=        1.5984
At iterate     4  f =      -796.31  |proj g|=        2.2315
At iterate     5  f =      -796.44  |proj g|=        2.1284
At iterate     6  f =      -796.52  |proj g|=        2.0661
At iterate     7  f =      -796.72  |proj g|=        1.9844
At iterate     8  f =      -797.08  |proj g|=        1.9137
At iterate     9  f =      -797.22  |proj g|=        2.1105
At iterate    10  f =      -797.34  |proj g|=         2.022
At iterate    11  f =      -797.35  |proj g|=        2.0142
At iterate    12  f =      -797.35  |proj g|=        2.0171
At iterate    13  f =      -797.35  |proj g|=        2.0185
At iterate    14  f =      -797.35  |proj g|=        2.0188
At iterate    15  f =      -797.35  |proj g|=        2.0199
At iterate    16  f =      -797.35  |proj g|=        2.0213
At iterate    17  f =      -797.35  |proj g|=        2.0237
At iterate    18  f =      -797.35  |proj g|=        2.0277
At iterate    19  f =      -797.35  |proj g|=        2.0342
At iterate    20  f =      -797.35  |proj g|=        2.0451
At iterate    21  f =      -797.36  |proj g|=        2.0634
At iterate    22  f =      -797.37  |proj g|=        2.0939
At iterate    23  f =      -797.41  |proj g|=         2.141
At iterate    24  f =      -797.49  |proj g|=        2.1799
At iterate    25  f =      -797.62  |proj g|=        2.1299
At iterate    26  f =      -797.67  |proj g|=         2.109
At iterate    27  f =      -797.67  |proj g|=        2.1101
At iterate    28  f =      -797.67  |proj g|=        2.1104
At iterate    29  f =      -797.67  |proj g|=        2.1106
At iterate    30  f =      -797.67  |proj g|=        2.1112
At iterate    31  f =      -797.67  |proj g|=         2.112
At iterate    32  f =      -797.68  |proj g|=        2.1131
At iterate    33  f =      -797.68  |proj g|=        2.1145
At iterate    34  f =      -797.68  |proj g|=        2.1159
At iterate    35  f =      -797.69  |proj g|=        2.1144
At iterate    36  f =       -797.7  |proj g|=        2.1068
At iterate    37  f =       -797.7  |proj g|=        2.1007
At iterate    38  f =      -797.72  |proj g|=        2.0825
At iterate    39  f =      -797.73  |proj g|=        2.0509
At iterate    40  f =      -797.74  |proj g|=        2.0361
At iterate    41  f =      -797.74  |proj g|=        2.0357
At iterate    42  f =      -797.74  |proj g|=        2.0351
At iterate    43  f =      -797.74  |proj g|=        2.0352
At iterate    44  f =      -797.74  |proj g|=        2.0351

iterations 44
function evaluations 50
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.03512
final function value -797.739

F = -797.739
final  value -797.738903 
converged
 
INFO  [23:06:21.187] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:06:21.269] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:06:21.281] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:06:28.718] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:06:36.063] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:06:43.546] [mlr3]  Finished benchmark 
INFO  [23:06:43.615] [bbotk] Result of batch 144: 
INFO  [23:06:43.617] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:06:43.617] [bbotk]              2.356394                 4.316954                       0.1068807 
INFO  [23:06:43.617] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:06:43.617] [bbotk]                     3737        0.969 -0.9459503         <NA>   0.9559557 
INFO  [23:06:43.617] [bbotk]                                 uhash 
INFO  [23:06:43.617] [bbotk]  ea01e789-b7a7-4ab1-8bde-527cedfff853 
DEBUG [23:06:44.867] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.534137e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.534137e-05 0.002057212 
  - best initial criterion value(s) :  744.5921 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -744.59  |proj g|=       9.2845
At iterate     1  f =       -764.3  |proj g|=        4.8252
At iterate     2  f =      -767.66  |proj g|=        4.2638
At iterate     3  f =      -774.56  |proj g|=        2.3715
At iterate     4  f =      -778.91  |proj g|=       0.30663
At iterate     5  f =      -780.22  |proj g|=       0.67274
At iterate     6  f =      -780.22  |proj g|=       0.27863
At iterate     7  f =      -780.23  |proj g|=       0.12986
At iterate     8  f =      -780.23  |proj g|=       0.13487

iterations 8
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.134866
final function value -780.225

F = -780.225
final  value -780.225458 
converged
 
INFO  [23:06:44.871] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:06:44.928] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:06:44.935] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:06:47.617] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:06:50.030] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:06:52.375] [mlr3]  Finished benchmark 
INFO  [23:06:52.457] [bbotk] Result of batch 145: 
INFO  [23:06:52.459] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:06:52.459] [bbotk]              9.159112                 7.105257                       0.4195016 
INFO  [23:06:52.459] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [23:06:52.459] [bbotk]                     1140        0.855 -0.953464         <NA>   0.9735471 
INFO  [23:06:52.459] [bbotk]                                 uhash 
INFO  [23:06:52.459] [bbotk]  16c20645-4925-4aa7-9295-90e4a86a2a37 
DEBUG [23:06:54.016] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.52736e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.52736e-05 0.002035138 
  - best initial criterion value(s) :  728.6124 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -728.61  |proj g|=       10.023
At iterate     1  f =      -749.22  |proj g|=        4.2394
At iterate     2  f =      -793.11  |proj g|=        4.2948
At iterate     3  f =      -793.57  |proj g|=        3.9176
At iterate     4  f =      -793.66  |proj g|=        3.7485
At iterate     5  f =      -793.69  |proj g|=        3.5934
At iterate     6  f =      -793.71  |proj g|=        3.5614
At iterate     7  f =      -793.92  |proj g|=          3.33
At iterate     8  f =      -794.37  |proj g|=        3.0346
At iterate     9  f =      -795.63  |proj g|=        2.5377
At iterate    10  f =      -798.78  |proj g|=        1.8813
At iterate    11  f =      -807.11  |proj g|=         1.282
At iterate    12  f =      -810.47  |proj g|=        1.6766
At iterate    13  f =      -820.42  |proj g|=        3.1364
At iterate    14  f =      -821.68  |proj g|=        3.1363
At iterate    15  f =      -822.26  |proj g|=        3.1354
At iterate    16  f =       -822.4  |proj g|=        3.1354
At iterate    17  f =      -822.41  |proj g|=        3.1353
At iterate    18  f =      -822.41  |proj g|=        3.1353
At iterate    19  f =      -822.41  |proj g|=        3.1339
At iterate    20  f =      -822.45  |proj g|=        3.1184
At iterate    21  f =      -822.54  |proj g|=        3.0764
At iterate    22  f =       -822.8  |proj g|=        2.9502
At iterate    23  f =      -823.48  |proj g|=        2.6055
At iterate    24  f =       -823.8  |proj g|=        2.5959
At iterate    25  f =      -829.41  |proj g|=        0.8536
At iterate    26  f =      -831.62  |proj g|=       0.42328
At iterate    27  f =      -831.63  |proj g|=         0.423
At iterate    28  f =      -831.63  |proj g|=       0.42137
At iterate    29  f =      -831.63  |proj g|=       0.42064
At iterate    30  f =      -831.63  |proj g|=       0.26616
At iterate    31  f =      -831.63  |proj g|=      0.001612
At iterate    32  f =      -831.63  |proj g|=     0.0016119

iterations 32
function evaluations 38
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00161185
final function value -831.63

F = -831.63
final  value -831.630180 
converged
 
INFO  [23:06:54.020] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:06:54.090] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:06:54.098] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:06:57.859] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:07:01.614] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:07:05.494] [mlr3]  Finished benchmark 
INFO  [23:07:05.563] [bbotk] Result of batch 146: 
INFO  [23:07:05.569] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:07:05.569] [bbotk]              5.130798                 2.385824                       0.4351631 
INFO  [23:07:05.569] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:07:05.569] [bbotk]                     1924        0.902 -0.9328659         <NA>    0.974689 
INFO  [23:07:05.569] [bbotk]                                 uhash 
INFO  [23:07:05.569] [bbotk]  2490034c-f07b-438e-850f-d7e837c96126 
DEBUG [23:07:07.373] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.52147e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9832273 9500 
  - variance bounds :  1.52147e-05 0.002022803 
  - best initial criterion value(s) :  732.8555 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -732.86  |proj g|=       4.5421
At iterate     1  f =      -781.59  |proj g|=        8.3343
At iterate     2  f =      -789.01  |proj g|=        7.6755
At iterate     3  f =      -801.35  |proj g|=        5.1149
At iterate     4  f =      -802.43  |proj g|=        4.6687
At iterate     5  f =       -806.3  |proj g|=        3.7706
At iterate     6  f =       -810.1  |proj g|=        3.4067
At iterate     7  f =      -811.52  |proj g|=        3.2407
At iterate     8  f =      -812.42  |proj g|=        3.1841
At iterate     9  f =      -812.84  |proj g|=        3.2592
At iterate    10  f =      -812.96  |proj g|=        3.1013
At iterate    11  f =         -813  |proj g|=        3.2735
At iterate    12  f =      -813.01  |proj g|=        3.2113
At iterate    13  f =      -813.01  |proj g|=        3.2029
At iterate    14  f =      -813.01  |proj g|=        3.1944
At iterate    15  f =      -813.02  |proj g|=         3.181
At iterate    16  f =      -813.04  |proj g|=        3.1616
At iterate    17  f =      -813.08  |proj g|=        3.0256
At iterate    18  f =      -813.13  |proj g|=        3.1132
At iterate    19  f =      -813.28  |proj g|=        3.0101
At iterate    20  f =      -813.68  |proj g|=        2.7517
At iterate    21  f =       -814.3  |proj g|=        2.5416
At iterate    22  f =      -821.14  |proj g|=        1.1101
At iterate    23  f =      -824.85  |proj g|=        0.4883
At iterate    24  f =      -833.03  |proj g|=       0.60537
At iterate    25  f =       -833.7  |proj g|=       0.48173
At iterate    26  f =       -833.8  |proj g|=       0.85541
At iterate    27  f =      -833.81  |proj g|=       0.77115
At iterate    28  f =      -833.81  |proj g|=       0.75592
At iterate    29  f =      -833.81  |proj g|=       0.75684

iterations 29
function evaluations 34
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.75684
final function value -833.814

F = -833.814
final  value -833.814263 
converged
 
INFO  [23:07:07.378] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:07:07.440] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:07:07.448] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:07:13.262] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:07:19.204] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:07:27.072] [mlr3]  Finished benchmark 
INFO  [23:07:27.141] [bbotk] Result of batch 147: 
INFO  [23:07:27.142] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:07:27.142] [bbotk]              2.954794                 6.534856                     0.005047981 
INFO  [23:07:27.142] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:07:27.142] [bbotk]                     2470        0.984 -0.9387035         <NA>   0.8789273 
INFO  [23:07:27.142] [bbotk]                                 uhash 
INFO  [23:07:27.142] [bbotk]  aca81cc4-1519-442e-8cef-346f324662ee 
DEBUG [23:07:28.570] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.955638e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9897408 9500 
  - variance bounds :  1.955638e-05 0.002353688 
  - best initial criterion value(s) :  611.8833 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -611.88  |proj g|=      0.97593
At iterate     1  f =      -635.55  |proj g|=        3.9099
At iterate     2  f =      -648.67  |proj g|=        1.3651
At iterate     3  f =      -649.02  |proj g|=        1.2865
At iterate     4  f =      -649.52  |proj g|=       0.96858
At iterate     5  f =      -649.55  |proj g|=       0.91506
At iterate     6  f =      -649.55  |proj g|=       0.93639
At iterate     7  f =      -649.56  |proj g|=       0.91748
At iterate     8  f =      -649.56  |proj g|=       0.91656
At iterate     9  f =      -649.56  |proj g|=       0.91244
At iterate    10  f =      -649.56  |proj g|=       0.90833
At iterate    11  f =      -649.56  |proj g|=       0.90009
At iterate    12  f =      -649.56  |proj g|=       0.89139
At iterate    13  f =      -649.56  |proj g|=        0.8821
At iterate    14  f =      -649.58  |proj g|=       0.86678
At iterate    15  f =      -649.61  |proj g|=       0.84227
At iterate    16  f =      -649.68  |proj g|=       0.80243
At iterate    17  f =      -649.86  |proj g|=       0.73567
At iterate    18  f =      -650.28  |proj g|=       0.73937
At iterate    19  f =      -650.76  |proj g|=       0.26894
At iterate    20  f =      -651.35  |proj g|=       0.47292
At iterate    21  f =      -652.16  |proj g|=       0.85786
At iterate    22  f =      -652.27  |proj g|=        1.0121
At iterate    23  f =      -652.29  |proj g|=       0.92334
At iterate    24  f =      -652.29  |proj g|=       0.94964
At iterate    25  f =      -652.29  |proj g|=       0.94362
At iterate    26  f =      -652.29  |proj g|=       0.94368

iterations 26
function evaluations 33
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.943684
final function value -652.29

F = -652.29
final  value -652.289772 
converged
 
INFO  [23:07:28.574] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:07:28.629] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:07:28.636] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:07:34.671] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:07:40.069] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:07:45.856] [mlr3]  Finished benchmark 
INFO  [23:07:45.944] [bbotk] Result of batch 148: 
INFO  [23:07:45.946] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:07:45.946] [bbotk]              5.067281                 2.158984                      0.01070499 
INFO  [23:07:45.946] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:07:45.946] [bbotk]                     2049        0.864 -0.9681782         <NA>   0.9342762 
INFO  [23:07:45.946] [bbotk]                                 uhash 
INFO  [23:07:45.946] [bbotk]  4704d0da-4ce6-4f1b-8faf-dcb5b3fa400e 
DEBUG [23:07:47.362] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.005225e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9897408 9500 
  - variance bounds :  2.005225e-05 0.002401828 
  - best initial criterion value(s) :  656.8217 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -656.82  |proj g|=       13.973
At iterate     1  f =      -656.96  |proj g|=        10.424
At iterate     2  f =      -685.02  |proj g|=        4.4641
At iterate     3  f =      -686.59  |proj g|=        3.2115
At iterate     4  f =      -686.73  |proj g|=        2.4939
At iterate     5  f =      -686.79  |proj g|=        2.9254
At iterate     6  f =       -686.8  |proj g|=        3.0416
At iterate     7  f =      -687.64  |proj g|=        3.7193
At iterate     8  f =      -690.59  |proj g|=        4.3628
At iterate     9  f =      -696.19  |proj g|=        3.2519
At iterate    10  f =      -700.02  |proj g|=        1.5669
At iterate    11  f =      -700.33  |proj g|=        2.4698
At iterate    12  f =      -701.86  |proj g|=        1.5468
At iterate    13  f =      -702.39  |proj g|=        1.3775
At iterate    14  f =      -702.71  |proj g|=        1.4268
At iterate    15  f =      -702.82  |proj g|=        1.3456
At iterate    16  f =      -702.84  |proj g|=        1.3335
At iterate    17  f =      -702.84  |proj g|=        1.3588
At iterate    18  f =      -702.84  |proj g|=        1.3517
At iterate    19  f =      -702.84  |proj g|=        1.3514
At iterate    20  f =      -702.84  |proj g|=        1.3514

iterations 20
function evaluations 31
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.35143
final function value -702.841

F = -702.841
final  value -702.841346 
converged
 
INFO  [23:07:47.366] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:07:47.421] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:07:47.428] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:07:54.855] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:08:02.198] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:08:12.244] [mlr3]  Finished benchmark 
INFO  [23:08:12.313] [bbotk] Result of batch 149: 
INFO  [23:08:12.315] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:08:12.315] [bbotk]              3.721298                 7.940751                      0.06495689 
INFO  [23:08:12.315] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:08:12.315] [bbotk]                     2762         0.87 -0.9599518         <NA>   0.9616519 
INFO  [23:08:12.315] [bbotk]                                 uhash 
INFO  [23:08:12.315] [bbotk]  c863de94-ae17-4216-9dec-167bf89825ff 
DEBUG [23:08:14.020] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.995624e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9897408 9500 
  - variance bounds :  1.995624e-05 0.002388592 
  - best initial criterion value(s) :  585.3011 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -585.3  |proj g|=        14.96
At iterate     1  f =      -635.08  |proj g|=        13.548
At iterate     2  f =      -650.59  |proj g|=        12.033
At iterate     3  f =      -652.28  |proj g|=        10.715
At iterate     4  f =      -653.64  |proj g|=        8.4523
At iterate     5  f =      -653.75  |proj g|=        8.4633
At iterate     6  f =      -654.11  |proj g|=        8.8756
At iterate     7  f =      -654.15  |proj g|=        9.3529
At iterate     8  f =      -654.16  |proj g|=         9.401
At iterate     9  f =      -654.16  |proj g|=        9.3738
At iterate    10  f =      -654.16  |proj g|=        9.3728
At iterate    11  f =      -654.16  |proj g|=        9.3684
At iterate    12  f =      -654.16  |proj g|=        9.3609
At iterate    13  f =      -654.16  |proj g|=        9.3511
At iterate    14  f =      -654.17  |proj g|=        9.3511
At iterate    15  f =       -654.2  |proj g|=         9.381
At iterate    16  f =      -654.25  |proj g|=        9.5055
At iterate    17  f =      -654.37  |proj g|=        9.8588
At iterate    18  f =      -654.56  |proj g|=         10.06
At iterate    19  f =      -655.18  |proj g|=         10.72
At iterate    20  f =      -655.25  |proj g|=        10.359
At iterate    21  f =      -656.99  |proj g|=        10.878
At iterate    22  f =      -663.31  |proj g|=        10.136
At iterate    23  f =      -674.11  |proj g|=        7.0295
At iterate    24  f =      -686.73  |proj g|=        3.4755
At iterate    25  f =      -694.47  |proj g|=        1.9035
At iterate    26  f =      -694.66  |proj g|=        2.1109
At iterate    27  f =      -699.86  |proj g|=        1.1615
At iterate    28  f =      -702.24  |proj g|=       0.85654
At iterate    29  f =      -702.24  |proj g|=       0.66472
At iterate    30  f =      -702.24  |proj g|=       0.68966
At iterate    31  f =      -702.24  |proj g|=        0.7143
At iterate    32  f =      -702.24  |proj g|=       0.71388

iterations 32
function evaluations 41
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.713876
final function value -702.244

F = -702.244
final  value -702.244301 
converged
 
INFO  [23:08:14.024] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:08:14.081] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:08:14.087] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:08:19.770] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:08:24.179] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:08:29.972] [mlr3]  Finished benchmark 
INFO  [23:08:30.042] [bbotk] Result of batch 150: 
INFO  [23:08:30.044] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:08:30.044] [bbotk]              6.861025                 3.156523                       0.4012772 
INFO  [23:08:30.044] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:08:30.044] [bbotk]                     1606        1.046 -0.9623065         <NA>   0.9743771 
INFO  [23:08:30.044] [bbotk]                                 uhash 
INFO  [23:08:30.044] [bbotk]  e7239d2a-7a1e-43a5-9ac2-3d5648b22aec 
DEBUG [23:08:31.377] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.987551e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9897408 9500 
  - variance bounds :  1.987551e-05 0.002367916 
  - best initial criterion value(s) :  607.5979 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -607.6  |proj g|=       1.0097
At iterate     1  f =      -629.04  |proj g|=        3.1416
At iterate     2  f =      -630.69  |proj g|=        2.3935
At iterate     3  f =      -639.45  |proj g|=       0.98123
At iterate     4  f =      -647.32  |proj g|=       0.22105
At iterate     5  f =      -653.76  |proj g|=        1.2261
At iterate     6  f =       -653.9  |proj g|=        1.4471
At iterate     7  f =       -654.1  |proj g|=        1.6017
At iterate     8  f =      -654.12  |proj g|=        1.4715
At iterate     9  f =      -654.13  |proj g|=        1.4979
At iterate    10  f =      -654.13  |proj g|=        1.4967
At iterate    11  f =      -654.13  |proj g|=        1.4966

iterations 11
function evaluations 21
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.49661
final function value -654.126

F = -654.126
final  value -654.126262 
converged
 
INFO  [23:08:31.382] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:08:31.438] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:08:31.445] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:08:43.130] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:08:52.041] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:09:01.441] [mlr3]  Finished benchmark 
INFO  [23:09:01.510] [bbotk] Result of batch 151: 
INFO  [23:09:01.512] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:09:01.512] [bbotk]              4.486824                 2.574275                       0.2187373 
INFO  [23:09:01.512] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:09:01.512] [bbotk]                     3359        0.886 -0.9691203         <NA>   0.9736973 
INFO  [23:09:01.512] [bbotk]                                 uhash 
INFO  [23:09:01.512] [bbotk]  41e23e93-4983-4757-b599-8e1c9be05ff6 
DEBUG [23:09:03.042] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.979012e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9897408 9500 
  - variance bounds :  1.979012e-05 0.002374895 
  - best initial criterion value(s) :  681.3166 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -681.32  |proj g|=       3.5303
At iterate     1  f =      -683.06  |proj g|=        3.2467
At iterate     2  f =      -693.43  |proj g|=        2.0443
At iterate     3  f =      -698.08  |proj g|=        1.6013
At iterate     4  f =      -699.31  |proj g|=        1.5529
At iterate     5  f =      -699.42  |proj g|=        1.3326
At iterate     6  f =      -699.44  |proj g|=        1.3144
At iterate     7  f =      -699.44  |proj g|=        1.3149
At iterate     8  f =      -699.44  |proj g|=        1.3145
At iterate     9  f =      -699.44  |proj g|=        1.3145
At iterate    10  f =      -699.44  |proj g|=        1.3145
At iterate    11  f =      -699.44  |proj g|=        1.3145
At iterate    12  f =      -699.44  |proj g|=        1.3138
At iterate    13  f =      -699.44  |proj g|=        1.3154
At iterate    14  f =      -699.44  |proj g|=        1.3037
At iterate    15  f =      -699.44  |proj g|=        1.3086
At iterate    16  f =      -699.46  |proj g|=        1.3211
At iterate    17  f =      -699.74  |proj g|=        1.4137
At iterate    18  f =      -700.49  |proj g|=        1.5708
At iterate    19  f =      -702.01  |proj g|=        1.5919
At iterate    20  f =      -702.34  |proj g|=         2.023
At iterate    21  f =      -705.24  |proj g|=        1.3982
At iterate    22  f =      -706.24  |proj g|=        1.4693
At iterate    23  f =       -706.3  |proj g|=        1.3322
At iterate    24  f =      -706.34  |proj g|=        1.3689
At iterate    25  f =      -706.34  |proj g|=        1.3815
At iterate    26  f =      -706.34  |proj g|=        1.3796
At iterate    27  f =      -706.34  |proj g|=        1.3796

iterations 27
function evaluations 37
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.37956
final function value -706.339

F = -706.339
final  value -706.339066 
converged
 
INFO  [23:09:03.046] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:09:03.102] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:09:03.109] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:09:11.508] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:09:18.069] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:09:26.239] [mlr3]  Finished benchmark 
INFO  [23:09:26.311] [bbotk] Result of batch 152: 
INFO  [23:09:26.328] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:09:26.328] [bbotk]              6.715217                  9.04771                     0.002000142 
INFO  [23:09:26.328] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:09:26.328] [bbotk]                     2832        0.897 -0.9629422         <NA>   0.9078614 
INFO  [23:09:26.328] [bbotk]                                 uhash 
INFO  [23:09:26.328] [bbotk]  531beff2-1a9d-49a3-9afb-6c9d3d12997b 
DEBUG [23:09:28.048] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.159693e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9958364 9500 
  - variance bounds :  2.159693e-05 0.002507747 
  - best initial criterion value(s) :  633.8216 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -633.82  |proj g|=       6.4662
At iterate     1  f =      -638.13  |proj g|=        5.7775
At iterate     2  f =      -642.65  |proj g|=        6.4815
At iterate     3  f =      -643.38  |proj g|=        6.4637
At iterate     4  f =      -643.89  |proj g|=        6.3183
At iterate     5  f =      -643.96  |proj g|=        6.2752
At iterate     6  f =      -643.96  |proj g|=        6.2731
At iterate     7  f =      -643.96  |proj g|=        6.2786
At iterate     8  f =      -643.96  |proj g|=        6.2831
At iterate     9  f =      -643.96  |proj g|=        6.2832
At iterate    10  f =      -643.96  |proj g|=        6.2836
At iterate    11  f =      -643.96  |proj g|=        6.2842
At iterate    12  f =      -643.96  |proj g|=        6.2844
At iterate    13  f =      -643.97  |proj g|=        6.2844
At iterate    14  f =      -643.97  |proj g|=        6.2761
At iterate    15  f =      -643.99  |proj g|=        6.2531
At iterate    16  f =      -644.02  |proj g|=        6.2142
At iterate    17  f =       -644.1  |proj g|=        6.0661
At iterate    18  f =      -644.11  |proj g|=         6.186
At iterate    19  f =      -644.28  |proj g|=        5.9534
At iterate    20  f =      -644.74  |proj g|=        5.4975
At iterate    21  f =      -645.95  |proj g|=        4.6939
At iterate    22  f =      -649.16  |proj g|=        3.4694
At iterate    23  f =      -657.22  |proj g|=        2.0395
At iterate    24  f =      -658.26  |proj g|=        1.7788
At iterate    25  f =      -668.18  |proj g|=       0.88946
At iterate    26  f =      -669.21  |proj g|=       0.88069
At iterate    27  f =      -669.44  |proj g|=       0.33891
At iterate    28  f =      -669.45  |proj g|=       0.27927
At iterate    29  f =      -669.45  |proj g|=       0.26367
At iterate    30  f =      -669.45  |proj g|=       0.26292

iterations 30
function evaluations 37
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.262923
final function value -669.45

F = -669.45
final  value -669.449753 
converged
 
INFO  [23:09:28.053] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:09:28.108] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:09:28.115] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:09:41.466] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:09:54.749] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:10:07.881] [mlr3]  Finished benchmark 
INFO  [23:10:07.952] [bbotk] Result of batch 153: 
INFO  [23:10:07.954] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:10:07.954] [bbotk]               7.14272                 9.883688                       0.3750578 
INFO  [23:10:07.954] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:10:07.954] [bbotk]                     4660        1.075 -0.9681526         <NA>   0.9772472 
INFO  [23:10:07.954] [bbotk]                                 uhash 
INFO  [23:10:07.954] [bbotk]  3160f98d-f41c-4ffd-8979-ed845092355d 
DEBUG [23:10:09.550] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.153886e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9958364 9500 
  - variance bounds :  2.153886e-05 0.002506031 
  - best initial criterion value(s) :  668.6763 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -668.68  |proj g|=       7.6375
At iterate     1  f =      -693.19  |proj g|=        11.624
At iterate     2  f =      -700.31  |proj g|=        10.741
At iterate     3  f =      -702.28  |proj g|=        7.7701
At iterate     4  f =      -702.53  |proj g|=        7.0541
At iterate     5  f =      -702.83  |proj g|=        6.3152
At iterate     6  f =      -702.83  |proj g|=        6.4686
At iterate     7  f =      -702.84  |proj g|=        6.4608
At iterate     8  f =      -702.84  |proj g|=        6.3901
At iterate     9  f =      -702.86  |proj g|=        6.3174
At iterate    10  f =       -702.9  |proj g|=        6.1898
At iterate    11  f =         -703  |proj g|=        6.0273
At iterate    12  f =      -703.26  |proj g|=        5.8424
At iterate    13  f =      -703.86  |proj g|=         5.848
At iterate    14  f =      -704.84  |proj g|=        6.6515
At iterate    15  f =      -705.39  |proj g|=        7.8251
At iterate    16  f =      -705.53  |proj g|=        8.3934
At iterate    17  f =      -705.58  |proj g|=        8.6615
At iterate    18  f =       -705.6  |proj g|=        8.7667
At iterate    19  f =      -705.62  |proj g|=        8.8981
At iterate    20  f =       -705.7  |proj g|=        9.1147
At iterate    21  f =       -705.9  |proj g|=        9.4258
At iterate    22  f =      -706.42  |proj g|=        9.8138
At iterate    23  f =      -707.79  |proj g|=        9.9675
At iterate    24  f =      -711.35  |proj g|=        8.9003
At iterate    25  f =      -715.18  |proj g|=        5.3845
At iterate    26  f =      -715.46  |proj g|=        4.6359
At iterate    27  f =       -715.8  |proj g|=        4.3214
At iterate    28  f =      -716.02  |proj g|=        1.3285
At iterate    29  f =      -717.42  |proj g|=         2.357
At iterate    30  f =      -719.52  |proj g|=        3.0334
At iterate    31  f =       -723.6  |proj g|=        3.2333
At iterate    32  f =      -726.95  |proj g|=        2.3883
At iterate    33  f =      -727.39  |proj g|=        1.8337
At iterate    34  f =      -729.92  |proj g|=        1.8686
At iterate    35  f =      -731.12  |proj g|=         1.496
At iterate    36  f =      -731.72  |proj g|=        1.7275
At iterate    37  f =      -731.87  |proj g|=        1.5191
At iterate    38  f =      -731.88  |proj g|=        1.4934
At iterate    39  f =      -731.88  |proj g|=        1.4975
At iterate    40  f =      -731.88  |proj g|=         1.498
At iterate    41  f =      -731.88  |proj g|=        1.4979

iterations 41
function evaluations 46
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.49794
final function value -731.876

F = -731.876
final  value -731.876042 
converged
 
INFO  [23:10:09.554] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:10:09.609] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:10:09.616] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:10:11.054] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:10:11.998] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:10:13.002] [mlr3]  Finished benchmark 
INFO  [23:10:13.337] [bbotk] Result of batch 154: 
INFO  [23:10:13.339] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:10:13.339] [bbotk]               5.54458                 4.949931                       0.3762201 
INFO  [23:10:13.339] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [23:10:13.339] [bbotk]                      208        0.883 -0.947529         <NA>   0.9580058 
INFO  [23:10:13.339] [bbotk]                                 uhash 
INFO  [23:10:13.339] [bbotk]  7bd5eb11-0854-4025-b0cf-0121a15dd4d7 
DEBUG [23:10:15.056] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.146362e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.85892 0.9958364 9576 
  - variance bounds :  2.146362e-05 0.002480273 
  - best initial criterion value(s) :  651.2084 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -651.21  |proj g|=       13.294
At iterate     1  f =      -653.97  |proj g|=        10.867
At iterate     2  f =      -673.97  |proj g|=        9.2323
At iterate     3  f =      -678.45  |proj g|=        6.8174
At iterate     4  f =      -684.32  |proj g|=        5.4342
At iterate     5  f =      -685.86  |proj g|=        5.7846
At iterate     6  f =      -685.88  |proj g|=        5.6785
At iterate     7  f =       -685.9  |proj g|=        5.6607
At iterate     8  f =         -686  |proj g|=        5.5736
At iterate     9  f =      -686.29  |proj g|=        5.3406
At iterate    10  f =      -686.55  |proj g|=        5.8838
At iterate    11  f =      -687.63  |proj g|=        5.2273
At iterate    12  f =       -689.8  |proj g|=        4.1899
At iterate    13  f =      -693.46  |proj g|=        3.5944
At iterate    14  f =      -700.63  |proj g|=        4.1595
At iterate    15  f =      -703.44  |proj g|=         6.679
At iterate    16  f =      -706.17  |proj g|=         8.436
At iterate    17  f =       -706.4  |proj g|=        9.3006
At iterate    18  f =      -706.58  |proj g|=        9.2092
At iterate    19  f =      -706.59  |proj g|=        9.2117
At iterate    20  f =      -706.59  |proj g|=        9.2212
At iterate    21  f =      -706.59  |proj g|=        9.2255
At iterate    22  f =      -706.59  |proj g|=        9.2288
At iterate    23  f =      -706.59  |proj g|=        9.2313
At iterate    24  f =      -706.59  |proj g|=        9.2465
At iterate    25  f =      -706.59  |proj g|=        9.2471
At iterate    26  f =      -706.59  |proj g|=         9.248
At iterate    27  f =       -706.6  |proj g|=        9.2448
At iterate    28  f =      -706.66  |proj g|=        9.1956
At iterate    29  f =      -706.88  |proj g|=         8.962
At iterate    30  f =      -707.03  |proj g|=         9.449
At iterate    31  f =      -707.68  |proj g|=        8.2663
At iterate    32  f =      -708.71  |proj g|=         6.583
At iterate    33  f =      -710.57  |proj g|=        4.2753
At iterate    34  f =      -713.62  |proj g|=         2.285
At iterate    35  f =      -718.74  |proj g|=        1.8754
At iterate    36  f =      -720.14  |proj g|=        1.2598
At iterate    37  f =      -720.79  |proj g|=        1.6683
At iterate    38  f =       -721.5  |proj g|=         1.363
At iterate    39  f =      -722.86  |proj g|=       0.88805
At iterate    40  f =      -722.99  |proj g|=       0.11526
At iterate    41  f =      -723.01  |proj g|=       0.11443
At iterate    42  f =      -723.01  |proj g|=       0.17826
At iterate    43  f =      -723.01  |proj g|=      0.056295
At iterate    44  f =      -723.01  |proj g|=      0.038991

iterations 44
function evaluations 55
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0389909
final function value -723.009

F = -723.009
final  value -723.009153 
converged
 
INFO  [23:10:15.060] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:10:15.116] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:10:15.123] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:10:26.437] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:10:38.476] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:10:49.309] [mlr3]  Finished benchmark 
INFO  [23:10:49.382] [bbotk] Result of batch 155: 
INFO  [23:10:49.384] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:10:49.384] [bbotk]              8.957797                 9.997072                       0.3686278 
INFO  [23:10:49.384] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:10:49.384] [bbotk]                     3953        0.909 -0.9579725         <NA>   0.9772137 
INFO  [23:10:49.384] [bbotk]                                 uhash 
INFO  [23:10:49.384] [bbotk]  623f7bbc-b51e-4957-935c-b41d0d98859f 
DEBUG [23:10:50.868] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.140642e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.140642e-05 0.002481185 
  - best initial criterion value(s) :  666.8135 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -666.81  |proj g|=       5.3971
At iterate     1  f =       -708.5  |proj g|=        4.1353
At iterate     2  f =      -713.83  |proj g|=        3.6249
At iterate     3  f =      -727.65  |proj g|=        3.1279
At iterate     4  f =      -732.02  |proj g|=        2.2485
At iterate     5  f =      -732.03  |proj g|=        2.2104
At iterate     6  f =      -732.04  |proj g|=         2.202
At iterate     7  f =      -732.05  |proj g|=        2.2264
At iterate     8  f =      -732.06  |proj g|=         2.235
At iterate     9  f =      -732.06  |proj g|=        2.2356
At iterate    10  f =      -732.06  |proj g|=        2.2358

iterations 10
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.23576
final function value -732.055

F = -732.055
final  value -732.055240 
converged
 
INFO  [23:10:50.872] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:10:51.009] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:10:51.017] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:10:58.633] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:11:07.088] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:11:16.403] [mlr3]  Finished benchmark 
INFO  [23:11:16.474] [bbotk] Result of batch 156: 
INFO  [23:11:16.476] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:11:16.476] [bbotk]              6.568608                 4.315952                       0.3140401 
INFO  [23:11:16.476] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:11:16.476] [bbotk]                     2762        0.891 -0.9532965         <NA>   0.9750018 
INFO  [23:11:16.476] [bbotk]                                 uhash 
INFO  [23:11:16.476] [bbotk]  2b8d3e2a-4a97-432a-b0b7-7e65e863bd5f 
DEBUG [23:11:17.908] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.132721e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.132721e-05 0.002474496 
  - best initial criterion value(s) :  692.4612 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -692.46  |proj g|=       7.7074
At iterate     1  f =      -713.25  |proj g|=        2.1443
At iterate     2  f =      -720.01  |proj g|=        1.8805
At iterate     3  f =      -726.35  |proj g|=        2.8446
At iterate     4  f =      -728.67  |proj g|=        1.7498
At iterate     5  f =      -730.28  |proj g|=        1.5617
At iterate     6  f =       -737.7  |proj g|=        1.3953
At iterate     7  f =      -740.04  |proj g|=        1.3524
At iterate     8  f =       -740.2  |proj g|=        1.3162
At iterate     9  f =      -740.22  |proj g|=        1.3162
At iterate    10  f =      -740.22  |proj g|=        1.3105
At iterate    11  f =      -740.22  |proj g|=        1.3162
At iterate    12  f =      -740.22  |proj g|=        1.3129
At iterate    13  f =      -740.48  |proj g|=        1.2667
At iterate    14  f =      -742.74  |proj g|=       0.97441
At iterate    15  f =      -743.44  |proj g|=       0.96133
At iterate    16  f =      -743.69  |proj g|=        1.0201
At iterate    17  f =      -743.74  |proj g|=         1.077
At iterate    18  f =      -743.75  |proj g|=        1.1104
At iterate    19  f =      -743.75  |proj g|=        1.1153
At iterate    20  f =      -743.75  |proj g|=        1.1154

iterations 20
function evaluations 25
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.11538
final function value -743.75

F = -743.75
final  value -743.749951 
converged
 
INFO  [23:11:17.913] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:11:17.969] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:11:17.997] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:11:25.144] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:11:31.637] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:11:39.627] [mlr3]  Finished benchmark 
INFO  [23:11:39.698] [bbotk] Result of batch 157: 
INFO  [23:11:39.700] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:11:39.700] [bbotk]              4.769266                 6.568542                       0.2306292 
INFO  [23:11:39.700] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:11:39.700] [bbotk]                     2464        0.907 -0.9497585         <NA>   0.9729423 
INFO  [23:11:39.700] [bbotk]                                 uhash 
INFO  [23:11:39.700] [bbotk]  819dff35-30a5-4077-8d1e-f0cc72ca9bd2 
DEBUG [23:11:41.254] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.123288e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.123287e-05 0.002474759 
  - best initial criterion value(s) :  681.6595 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -681.66  |proj g|=       12.388
At iterate     1  f =      -690.59  |proj g|=        10.826
At iterate     2  f =      -696.86  |proj g|=        9.8717
At iterate     3  f =      -705.27  |proj g|=        7.2316
At iterate     4  f =      -707.52  |proj g|=        5.5573
At iterate     5  f =         -708  |proj g|=        4.7684
At iterate     6  f =      -708.39  |proj g|=        4.7569
At iterate     7  f =      -708.39  |proj g|=         4.719
At iterate     8  f =      -708.39  |proj g|=        4.7255
At iterate     9  f =       -708.4  |proj g|=        4.7309
At iterate    10  f =      -708.43  |proj g|=        4.7373
At iterate    11  f =       -708.5  |proj g|=        4.7222
At iterate    12  f =      -708.67  |proj g|=        4.6336
At iterate    13  f =      -709.01  |proj g|=        4.3965
At iterate    14  f =      -709.59  |proj g|=        3.9117
At iterate    15  f =      -709.98  |proj g|=        3.0614
At iterate    16  f =      -710.14  |proj g|=        3.2175
At iterate    17  f =      -710.38  |proj g|=        3.3081
At iterate    18  f =      -711.61  |proj g|=        3.5542
At iterate    19  f =      -714.26  |proj g|=        3.7297
At iterate    20  f =      -719.83  |proj g|=          3.64
At iterate    21  f =      -723.48  |proj g|=        4.7137
At iterate    22  f =      -727.56  |proj g|=        3.6259
At iterate    23  f =      -735.43  |proj g|=        1.2382
At iterate    24  f =      -739.36  |proj g|=        1.9734
At iterate    25  f =      -739.59  |proj g|=        1.6395
At iterate    26  f =      -739.64  |proj g|=        1.3531
At iterate    27  f =      -739.64  |proj g|=        1.3712
At iterate    28  f =      -739.64  |proj g|=         1.376
At iterate    29  f =      -739.64  |proj g|=         1.372
At iterate    30  f =      -739.64  |proj g|=        1.3695
At iterate    31  f =      -739.64  |proj g|=        1.3692

iterations 31
function evaluations 35
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.36919
final function value -739.644

F = -739.644
final  value -739.643819 
converged
 
INFO  [23:11:41.259] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:11:41.314] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:11:41.321] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:11:49.011] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:11:58.539] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:12:08.608] [mlr3]  Finished benchmark 
INFO  [23:12:08.678] [bbotk] Result of batch 158: 
INFO  [23:12:08.680] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:12:08.680] [bbotk]              2.753331                  8.49745                       0.2231619 
INFO  [23:12:08.680] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:12:08.680] [bbotk]                     3361        0.925 -0.9580118         <NA>   0.9658548 
INFO  [23:12:08.680] [bbotk]                                 uhash 
INFO  [23:12:08.680] [bbotk]  3f146777-a48c-49a8-aa09-80e81330ff37 
DEBUG [23:12:10.371] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.11205e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.11205e-05 0.002467661 
  - best initial criterion value(s) :  676.7264 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -676.73  |proj g|=       1.9095
At iterate     1  f =      -678.65  |proj g|=        2.1736
At iterate     2  f =      -678.65  |proj g|=        2.1587
At iterate     3  f =      -678.67  |proj g|=        2.1406
At iterate     4  f =      -678.69  |proj g|=        2.1328
At iterate     5  f =      -678.75  |proj g|=        2.1506
At iterate     6  f =      -678.83  |proj g|=        2.2279
At iterate     7  f =      -678.89  |proj g|=        2.3462
At iterate     8  f =      -678.92  |proj g|=        2.4145
At iterate     9  f =      -678.92  |proj g|=         2.426
At iterate    10  f =      -678.92  |proj g|=        2.4346
At iterate    11  f =      -678.92  |proj g|=        2.4425
At iterate    12  f =      -678.92  |proj g|=        2.4579
At iterate    13  f =      -678.93  |proj g|=        2.4687
At iterate    14  f =      -678.94  |proj g|=        2.5619
At iterate    15  f =      -678.96  |proj g|=        2.5308
At iterate    16  f =      -679.06  |proj g|=         2.412
At iterate    17  f =      -679.25  |proj g|=        2.2736
At iterate    18  f =      -679.88  |proj g|=        1.9588
At iterate    19  f =      -681.48  |proj g|=        1.5879
At iterate    20  f =      -685.17  |proj g|=        1.3564
At iterate    21  f =      -689.68  |proj g|=       0.79334
At iterate    22  f =      -691.11  |proj g|=        1.0981
At iterate    23  f =      -691.37  |proj g|=         0.877
At iterate    24  f =      -691.49  |proj g|=       0.56925
At iterate    25  f =      -691.52  |proj g|=       0.88392
At iterate    26  f =      -691.52  |proj g|=        0.7571
At iterate    27  f =      -691.52  |proj g|=        0.7532
At iterate    28  f =      -691.52  |proj g|=       0.75336

iterations 28
function evaluations 33
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.753364
final function value -691.517

F = -691.517
final  value -691.517297 
converged
 
INFO  [23:12:10.375] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:12:10.432] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:12:10.439] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:12:22.180] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:12:32.099] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:12:43.704] [mlr3]  Finished benchmark 
INFO  [23:12:43.773] [bbotk] Result of batch 159: 
INFO  [23:12:43.775] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:12:43.775] [bbotk]              6.040589                 5.679103                       0.2003869 
INFO  [23:12:43.775] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:12:43.775] [bbotk]                     3612        0.909 -0.9683469         <NA>   0.9747145 
INFO  [23:12:43.775] [bbotk]                                 uhash 
INFO  [23:12:43.775] [bbotk]  47689614-6900-46cf-b68a-e14148a5f61f 
DEBUG [23:12:45.095] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.104104e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.104104e-05 0.002464432 
  - best initial criterion value(s) :  687.3738 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -687.37  |proj g|=       4.1659
At iterate     1  f =      -718.39  |proj g|=        4.4008
At iterate     2  f =      -724.83  |proj g|=        2.3749
At iterate     3  f =      -731.03  |proj g|=        1.9977
At iterate     4  f =      -733.77  |proj g|=        1.2704
At iterate     5  f =      -733.79  |proj g|=        1.3166
At iterate     6  f =       -733.8  |proj g|=        1.3193
At iterate     7  f =      -733.81  |proj g|=        1.3007
At iterate     8  f =      -733.81  |proj g|=        1.2933
At iterate     9  f =      -733.81  |proj g|=        1.2936

iterations 9
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.29365
final function value -733.809

F = -733.809
final  value -733.808993 
converged
 
INFO  [23:12:45.099] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:12:45.155] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:12:45.162] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:12:48.298] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:12:52.166] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:12:56.111] [mlr3]  Finished benchmark 
INFO  [23:12:56.180] [bbotk] Result of batch 160: 
INFO  [23:12:56.182] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:12:56.182] [bbotk]              4.046832                 2.774134                       0.3957694 
INFO  [23:12:56.182] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:12:56.182] [bbotk]                     1187        0.905 -0.9596982         <NA>   0.9707209 
INFO  [23:12:56.182] [bbotk]                                 uhash 
INFO  [23:12:56.182] [bbotk]  d4d8dddd-b360-435e-a026-5f9556490368 
DEBUG [23:12:58.070] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.093786e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.093786e-05 0.002443097 
  - best initial criterion value(s) :  687.7397 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -687.74  |proj g|=        8.008
At iterate     1  f =      -722.14  |proj g|=        7.6528
At iterate     2  f =      -731.61  |proj g|=        6.9367
At iterate     3  f =      -740.76  |proj g|=        5.1936
At iterate     4  f =      -741.98  |proj g|=        4.4355
At iterate     5  f =      -743.18  |proj g|=        4.1143
At iterate     6  f =      -747.27  |proj g|=        3.3032
At iterate     7  f =      -749.38  |proj g|=        4.1256
At iterate     8  f =       -750.6  |proj g|=        3.3317
At iterate     9  f =      -750.96  |proj g|=        2.9507
At iterate    10  f =      -751.19  |proj g|=        2.9196
At iterate    11  f =      -751.33  |proj g|=        2.9657
At iterate    12  f =      -751.37  |proj g|=        2.9729
At iterate    13  f =      -751.38  |proj g|=         2.937
At iterate    14  f =      -751.38  |proj g|=        2.9995
At iterate    15  f =      -751.39  |proj g|=        2.9782
At iterate    16  f =      -751.58  |proj g|=        2.7961
At iterate    17  f =      -751.98  |proj g|=        2.5511
At iterate    18  f =      -753.36  |proj g|=        2.2131
At iterate    19  f =      -754.49  |proj g|=        2.6344
At iterate    20  f =      -758.65  |proj g|=        2.7233
At iterate    21  f =      -759.02  |proj g|=        2.6482
At iterate    22  f =      -759.02  |proj g|=        2.8446
At iterate    23  f =      -759.05  |proj g|=        2.7735
At iterate    24  f =      -759.05  |proj g|=         2.766
At iterate    25  f =      -759.05  |proj g|=        2.7682
At iterate    26  f =      -759.05  |proj g|=         2.768
At iterate    27  f =      -759.05  |proj g|=        2.7679
At iterate    28  f =      -759.05  |proj g|=        2.7683
At iterate    29  f =      -759.05  |proj g|=        2.7668
At iterate    30  f =      -759.05  |proj g|=        2.7674
At iterate    31  f =       -759.1  |proj g|=        2.7587
At iterate    32  f =      -759.63  |proj g|=        2.6052
At iterate    33  f =      -760.51  |proj g|=        2.3524
At iterate    34  f =      -763.15  |proj g|=        1.7658
At iterate    35  f =      -763.27  |proj g|=        1.5552
At iterate    36  f =      -767.32  |proj g|=       0.86176
At iterate    37  f =      -767.91  |proj g|=       0.85229
At iterate    38  f =      -768.08  |proj g|=        0.2495
At iterate    39  f =       -768.1  |proj g|=       0.18426
At iterate    40  f =       -768.1  |proj g|=       0.16004
At iterate    41  f =       -768.1  |proj g|=        0.1558
At iterate    42  f =       -768.1  |proj g|=        0.1557

iterations 42
function evaluations 51
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.155699
final function value -768.1

F = -768.1
final  value -768.100415 
converged
 
INFO  [23:12:58.074] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:12:58.132] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:12:58.140] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:13:15.437] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:13:30.290] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:13:46.541] [mlr3]  Finished benchmark 
INFO  [23:13:46.641] [bbotk] Result of batch 161: 
INFO  [23:13:46.643] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:13:46.643] [bbotk]              5.536903                 4.267346                       0.0175633 
INFO  [23:13:46.643] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:13:46.643] [bbotk]                     4776        0.914 -0.9477457         <NA>    0.958938 
INFO  [23:13:46.643] [bbotk]                                 uhash 
INFO  [23:13:46.643] [bbotk]  39ac055a-c758-4723-a2a8-fe9a99be0567 
DEBUG [23:13:47.964] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.08616e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.08616e-05 0.002426427 
  - best initial criterion value(s) :  741.543 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -741.54  |proj g|=       2.2482
At iterate     1  f =      -748.16  |proj g|=        3.1697
At iterate     2  f =      -757.62  |proj g|=        4.6128
At iterate     3  f =       -763.7  |proj g|=        3.7247
At iterate     4  f =      -765.96  |proj g|=         2.399
At iterate     5  f =      -765.99  |proj g|=        2.2366
At iterate     6  f =         -766  |proj g|=        2.1792
At iterate     7  f =      -766.02  |proj g|=        2.1139
At iterate     8  f =      -766.02  |proj g|=        2.1517
At iterate     9  f =      -766.02  |proj g|=        2.1547
At iterate    10  f =      -766.02  |proj g|=        2.1548

iterations 10
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.15483
final function value -766.021

F = -766.021
final  value -766.020598 
converged
 
INFO  [23:13:47.969] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:13:48.022] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:13:48.029] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:13:51.923] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:13:55.773] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:13:59.088] [mlr3]  Finished benchmark 
INFO  [23:13:59.156] [bbotk] Result of batch 162: 
INFO  [23:13:59.158] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:13:59.158] [bbotk]               9.55122                 3.489301                       0.3985697 
INFO  [23:13:59.158] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:13:59.158] [bbotk]                     1191        0.925 -0.9527997         <NA>   0.9736357 
INFO  [23:13:59.158] [bbotk]                                 uhash 
INFO  [23:13:59.158] [bbotk]  7c6a78f4-2f7f-4c77-b60f-1156a1938db8 
DEBUG [23:14:00.801] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.077645e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.077645e-05 0.00240385 
  - best initial criterion value(s) :  737.8864 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -737.89  |proj g|=       3.3137
At iterate     1  f =       -751.5  |proj g|=       0.78389
At iterate     2  f =      -760.85  |proj g|=        2.8438
At iterate     3  f =      -760.97  |proj g|=        2.7205
At iterate     4  f =      -761.04  |proj g|=        2.5795
At iterate     5  f =      -761.05  |proj g|=        2.6037
At iterate     6  f =      -761.05  |proj g|=        2.6509
At iterate     7  f =      -761.05  |proj g|=        2.6661
At iterate     8  f =      -761.05  |proj g|=         2.669
At iterate     9  f =      -761.05  |proj g|=        2.6701
At iterate    10  f =      -761.05  |proj g|=        2.6772
At iterate    11  f =      -761.05  |proj g|=        2.6866
At iterate    12  f =      -761.05  |proj g|=         2.703
At iterate    13  f =      -761.05  |proj g|=        2.7277
At iterate    14  f =      -761.06  |proj g|=        2.7682
At iterate    15  f =      -761.07  |proj g|=        2.8286
At iterate    16  f =      -761.09  |proj g|=        2.9095
At iterate    17  f =      -761.14  |proj g|=        2.9731
At iterate    18  f =       -761.2  |proj g|=        2.9062
At iterate    19  f =      -761.24  |proj g|=        2.8094
At iterate    20  f =       -761.3  |proj g|=        2.5868
At iterate    21  f =      -761.36  |proj g|=         2.413
At iterate    22  f =      -761.58  |proj g|=        2.0323
At iterate    23  f =      -762.11  |proj g|=        1.4231
At iterate    24  f =      -763.51  |proj g|=        1.0375
At iterate    25  f =      -766.43  |proj g|=        0.7062
At iterate    26  f =      -768.81  |proj g|=       0.89163
At iterate    27  f =         -769  |proj g|=       0.88966
At iterate    28  f =      -769.33  |proj g|=       0.88617
At iterate    29  f =      -770.19  |proj g|=       0.11939
At iterate    30  f =      -770.37  |proj g|=       0.19492
At iterate    31  f =      -770.39  |proj g|=       0.30292
At iterate    32  f =      -770.39  |proj g|=       0.33136
At iterate    33  f =      -770.39  |proj g|=       0.33464
At iterate    34  f =      -770.39  |proj g|=       0.33469

iterations 34
function evaluations 38
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.33469
final function value -770.392

F = -770.392
final  value -770.392333 
converged
 
INFO  [23:14:00.805] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:14:00.860] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:14:00.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:14:13.085] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:14:26.728] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:14:44.187] [mlr3]  Finished benchmark 
INFO  [23:14:44.256] [bbotk] Result of batch 163: 
INFO  [23:14:44.257] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:14:44.257] [bbotk]              3.830586                 2.967388                       0.0832692 
INFO  [23:14:44.257] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:14:44.257] [bbotk]                     4629        0.955 -0.9539797         <NA>   0.9689891 
INFO  [23:14:44.257] [bbotk]                                 uhash 
INFO  [23:14:44.257] [bbotk]  28782182-a147-46d7-8e59-210fb9d621bd 
DEBUG [23:14:45.790] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.067098e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.067098e-05 0.002383987 
  - best initial criterion value(s) :  702.373 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -702.37  |proj g|=      0.95202
At iterate     1  f =      -748.27  |proj g|=        1.1738
At iterate     2  f =      -749.15  |proj g|=         8.466
At iterate     3  f =       -755.1  |proj g|=        5.7869
At iterate     4  f =      -755.24  |proj g|=        5.2205
At iterate     5  f =      -755.26  |proj g|=        5.2293
At iterate     6  f =       -755.3  |proj g|=        5.3834
At iterate     7  f =      -755.31  |proj g|=        5.4146
At iterate     8  f =      -755.31  |proj g|=         5.418
At iterate     9  f =      -755.31  |proj g|=        5.4185

iterations 9
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 5.41848
final function value -755.305

F = -755.305
final  value -755.305400 
converged
 
INFO  [23:14:45.794] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:14:45.850] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:14:45.873] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:14:53.338] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:15:00.846] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:15:07.921] [mlr3]  Finished benchmark 
INFO  [23:15:07.990] [bbotk] Result of batch 164: 
INFO  [23:15:07.992] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:15:07.992] [bbotk]              6.785722                 6.052135                       0.1737377 
INFO  [23:15:07.992] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:15:07.992] [bbotk]                     2802        0.938 -0.9588389         <NA>    0.973106 
INFO  [23:15:07.992] [bbotk]                                 uhash 
INFO  [23:15:07.992] [bbotk]  62dcfa13-95ab-48f9-8fc9-35a7208fb3cd 
DEBUG [23:15:09.758] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.058388e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.058388e-05 0.002381255 
  - best initial criterion value(s) :  730.3064 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -730.31  |proj g|=       8.4502
At iterate     1  f =      -741.95  |proj g|=        5.5553
At iterate     2  f =      -741.95  |proj g|=        5.4485
At iterate     3  f =      -741.98  |proj g|=        5.5136
At iterate     4  f =         -742  |proj g|=        5.6261
At iterate     5  f =         -742  |proj g|=        5.6282
At iterate     6  f =         -742  |proj g|=        5.6308
At iterate     7  f =      -742.01  |proj g|=        5.6312
At iterate     8  f =      -742.02  |proj g|=        5.5406
At iterate     9  f =      -742.03  |proj g|=        5.6755
At iterate    10  f =      -742.06  |proj g|=        5.5542
At iterate    11  f =      -747.74  |proj g|=        2.4178
At iterate    12  f =      -749.74  |proj g|=         1.052
At iterate    13  f =      -750.54  |proj g|=       0.73983
At iterate    14  f =      -751.19  |proj g|=       0.89234
At iterate    15  f =      -751.19  |proj g|=       0.89115
At iterate    16  f =      -751.25  |proj g|=       0.88827
At iterate    17  f =      -751.25  |proj g|=      0.045759
At iterate    18  f =      -751.25  |proj g|=       0.01598
At iterate    19  f =      -751.25  |proj g|=       0.22325
At iterate    20  f =      -751.25  |proj g|=       0.53268
At iterate    21  f =      -751.25  |proj g|=         0.887
At iterate    22  f =      -751.26  |proj g|=       0.88664
At iterate    23  f =      -751.26  |proj g|=       0.88609
At iterate    24  f =      -751.26  |proj g|=       0.79474
At iterate    25  f =      -751.27  |proj g|=       0.10858
At iterate    26  f =      -751.27  |proj g|=       0.10851
At iterate    27  f =      -751.27  |proj g|=       0.68931
At iterate    28  f =      -751.27  |proj g|=       0.88742
At iterate    29  f =      -751.27  |proj g|=       0.88745
At iterate    30  f =      -751.27  |proj g|=       0.88748
At iterate    31  f =      -751.27  |proj g|=       0.88752
At iterate    32  f =      -751.27  |proj g|=       0.38442
At iterate    33  f =      -751.27  |proj g|=      0.036829
At iterate    34  f =      -751.27  |proj g|=      0.014111

iterations 34
function evaluations 46
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0141106
final function value -751.269

F = -751.269
final  value -751.268784 
converged
 
INFO  [23:15:09.762] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:15:09.815] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:15:09.822] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:15:12.507] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:15:15.479] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:15:18.417] [mlr3]  Finished benchmark 
INFO  [23:15:18.486] [bbotk] Result of batch 165: 
INFO  [23:15:18.488] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:15:18.488] [bbotk]              7.838318                 6.793585                       0.1521989 
INFO  [23:15:18.488] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:15:18.488] [bbotk]                      939        0.963 -0.9630293         <NA>   0.9655194 
INFO  [23:15:18.488] [bbotk]                                 uhash 
INFO  [23:15:18.488] [bbotk]  19599931-6a26-42bb-978c-53af6f6f7db2 
DEBUG [23:15:20.260] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.047941e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.047941e-05 0.002356974 
  - best initial criterion value(s) :  697.7719 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -697.77  |proj g|=       5.6871
At iterate     1  f =       -728.5  |proj g|=        11.616
At iterate     2  f =      -740.14  |proj g|=         9.701
At iterate     3  f =      -750.39  |proj g|=        4.4796
At iterate     4  f =      -750.72  |proj g|=        3.8964
At iterate     5  f =      -751.07  |proj g|=        3.7728
At iterate     6  f =      -752.66  |proj g|=        3.2868
At iterate     7  f =      -753.07  |proj g|=        3.4857
At iterate     8  f =       -753.2  |proj g|=        3.2849
At iterate     9  f =      -753.23  |proj g|=        3.2434
At iterate    10  f =      -753.24  |proj g|=        3.2388
At iterate    11  f =      -753.25  |proj g|=        3.2368
At iterate    12  f =      -753.26  |proj g|=        3.2385
At iterate    13  f =      -753.28  |proj g|=        3.1814
At iterate    14  f =      -753.29  |proj g|=        3.3155
At iterate    15  f =      -753.35  |proj g|=        3.2005
At iterate    16  f =       -753.5  |proj g|=        3.0033
At iterate    17  f =      -753.92  |proj g|=        2.7213
At iterate    18  f =      -755.66  |proj g|=         2.123
At iterate    19  f =      -761.41  |proj g|=        1.1903
At iterate    20  f =      -766.45  |proj g|=       0.39522
At iterate    21  f =      -782.93  |proj g|=       0.85955
At iterate    22  f =      -782.96  |proj g|=       0.85955
At iterate    23  f =      -783.04  |proj g|=       0.58153
At iterate    24  f =      -783.05  |proj g|=       0.56592
At iterate    25  f =      -783.05  |proj g|=       0.85357
At iterate    26  f =      -783.05  |proj g|=       0.85357
At iterate    27  f =      -783.05  |proj g|=       0.85357
At iterate    28  f =      -783.05  |proj g|=       0.85357

iterations 28
function evaluations 37
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.853571
final function value -783.047

F = -783.047
final  value -783.047326 
converged
 
INFO  [23:15:20.264] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:15:20.320] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:15:20.327] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:15:22.566] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:15:24.747] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:15:26.800] [mlr3]  Finished benchmark 
INFO  [23:15:26.868] [bbotk] Result of batch 166: 
INFO  [23:15:26.870] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:15:26.870] [bbotk]              7.647655                 6.619307                       0.1022407 
INFO  [23:15:26.870] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [23:15:26.870] [bbotk]                      707        1.084 -0.952358         <NA>   0.9581922 
INFO  [23:15:26.870] [bbotk]                                 uhash 
INFO  [23:15:26.870] [bbotk]  fe89f3cf-d7ba-4262-b724-8ee3a1f43ef9 
DEBUG [23:15:28.812] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.041404e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.041404e-05 0.002350235 
  - best initial criterion value(s) :  711.6447 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -711.64  |proj g|=       10.557
At iterate     1  f =      -743.95  |proj g|=        5.4447
At iterate     2  f =      -748.81  |proj g|=        6.2273
At iterate     3  f =      -749.59  |proj g|=        5.7815
At iterate     4  f =      -749.89  |proj g|=        5.3648
At iterate     5  f =      -749.92  |proj g|=        5.3316
At iterate     6  f =      -749.94  |proj g|=        5.3595
At iterate     7  f =      -749.94  |proj g|=        5.3989
At iterate     8  f =      -749.94  |proj g|=         5.412
At iterate     9  f =      -749.94  |proj g|=        5.4136
At iterate    10  f =      -749.94  |proj g|=        5.4267
At iterate    11  f =      -749.94  |proj g|=        5.4413
At iterate    12  f =      -749.95  |proj g|=        5.4688
At iterate    13  f =      -749.95  |proj g|=        5.5107
At iterate    14  f =      -749.97  |proj g|=        5.5808
At iterate    15  f =      -750.02  |proj g|=        5.6933
At iterate    16  f =      -750.13  |proj g|=        5.8593
At iterate    17  f =      -750.33  |proj g|=        6.0246
At iterate    18  f =      -750.46  |proj g|=        5.9111
At iterate    19  f =       -750.5  |proj g|=        5.9012
At iterate    20  f =      -750.54  |proj g|=        5.8595
At iterate    21  f =      -750.55  |proj g|=         5.905
At iterate    22  f =      -750.71  |proj g|=        5.7837
At iterate    23  f =      -751.04  |proj g|=        5.6058
At iterate    24  f =      -753.24  |proj g|=        5.2322
At iterate    25  f =      -766.15  |proj g|=        3.6042
At iterate    26  f =      -783.35  |proj g|=        2.6037
At iterate    27  f =      -786.25  |proj g|=        1.7811
At iterate    28  f =      -787.56  |proj g|=        1.4518
At iterate    29  f =      -788.05  |proj g|=        1.2891
At iterate    30  f =      -788.07  |proj g|=        1.2313
At iterate    31  f =      -788.07  |proj g|=        1.2385
At iterate    32  f =      -788.07  |proj g|=        1.2362
At iterate    33  f =      -788.07  |proj g|=        1.2384
At iterate    34  f =      -788.07  |proj g|=        1.2368
At iterate    35  f =      -788.07  |proj g|=        1.2308
At iterate    36  f =      -788.08  |proj g|=        1.2202
At iterate    37  f =      -788.08  |proj g|=        1.1997
At iterate    38  f =       -788.1  |proj g|=        1.1826
At iterate    39  f =      -788.11  |proj g|=        1.1816
At iterate    40  f =      -788.12  |proj g|=        1.2193
At iterate    41  f =      -788.12  |proj g|=          1.22
At iterate    42  f =      -788.12  |proj g|=          1.22

iterations 42
function evaluations 49
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.21998
final function value -788.117

F = -788.117
final  value -788.116876 
converged
 
INFO  [23:15:28.816] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:15:28.873] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:15:28.880] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:15:38.164] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:15:46.748] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:15:54.967] [mlr3]  Finished benchmark 
INFO  [23:15:55.038] [bbotk] Result of batch 167: 
INFO  [23:15:55.039] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:15:55.039] [bbotk]              4.793679                 3.716984                       0.2895053 
INFO  [23:15:55.039] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:15:55.039] [bbotk]                     3106        1.096 -0.9521073         <NA>   0.9746287 
INFO  [23:15:55.039] [bbotk]                                 uhash 
INFO  [23:15:55.039] [bbotk]  16498c28-d859-4b79-8e73-72681b0e8be2 
DEBUG [23:15:56.385] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.034038e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.034038e-05 0.002342256 
  - best initial criterion value(s) :  712.939 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -712.94  |proj g|=       4.3711
At iterate     1  f =      -761.49  |proj g|=        5.0466
At iterate     2  f =       -774.7  |proj g|=        3.8214
At iterate     3  f =       -780.8  |proj g|=        3.3719
At iterate     4  f =      -783.42  |proj g|=        2.6117
At iterate     5  f =      -783.43  |proj g|=        2.5826
At iterate     6  f =      -783.45  |proj g|=        2.5726
At iterate     7  f =      -783.46  |proj g|=        2.6076
At iterate     8  f =      -783.46  |proj g|=        2.6217
At iterate     9  f =      -783.46  |proj g|=        2.6228
At iterate    10  f =      -783.46  |proj g|=        2.6229

iterations 10
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.62289
final function value -783.459

F = -783.459
final  value -783.458866 
converged
 
INFO  [23:15:56.389] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:15:56.448] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:15:56.456] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:16:07.798] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:16:19.111] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:16:34.080] [mlr3]  Finished benchmark 
INFO  [23:16:34.150] [bbotk] Result of batch 168: 
INFO  [23:16:34.152] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:16:34.152] [bbotk]              9.602398                 7.502625                        0.483401 
INFO  [23:16:34.152] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:16:34.152] [bbotk]                     3803        0.915 -0.9544883         <NA>    0.977149 
INFO  [23:16:34.152] [bbotk]                                 uhash 
INFO  [23:16:34.152] [bbotk]  f642ce2b-ca61-49a5-83d1-3736ef92adab 
DEBUG [23:16:36.142] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.028977e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.94607 15.92451 0.9958364 9576 
  - variance bounds :  2.028977e-05 0.002341013 
  - best initial criterion value(s) :  737.3057 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -737.31  |proj g|=       7.4334
At iterate     1  f =       -749.2  |proj g|=        2.1952
At iterate     2  f =      -757.45  |proj g|=        1.8894
At iterate     3  f =      -764.51  |proj g|=        2.0975
At iterate     4  f =      -764.85  |proj g|=        2.4506
At iterate     5  f =      -765.26  |proj g|=        2.4936
At iterate     6  f =      -767.86  |proj g|=        2.3735
At iterate     7  f =      -768.28  |proj g|=        1.8776
At iterate     8  f =       -768.6  |proj g|=        1.8654
At iterate     9  f =       -768.6  |proj g|=        1.8513
At iterate    10  f =      -768.61  |proj g|=        1.8362
At iterate    11  f =      -768.61  |proj g|=        1.8465
At iterate    12  f =      -768.61  |proj g|=         1.867
At iterate    13  f =      -768.61  |proj g|=        1.8556
At iterate    14  f =       -768.7  |proj g|=        1.7907
At iterate    15  f =      -769.63  |proj g|=        1.3898
At iterate    16  f =       -770.9  |proj g|=        1.3923
At iterate    17  f =       -771.9  |proj g|=        1.3715
At iterate    18  f =      -772.23  |proj g|=        1.2851
At iterate    19  f =      -772.38  |proj g|=        1.1536
At iterate    20  f =       -772.4  |proj g|=        1.0884
At iterate    21  f =       -772.4  |proj g|=        1.0947
At iterate    22  f =       -772.4  |proj g|=        1.0948
At iterate    23  f =       -772.4  |proj g|=         1.095
At iterate    24  f =       -772.4  |proj g|=        1.0967
At iterate    25  f =       -772.4  |proj g|=        1.0986
At iterate    26  f =       -772.4  |proj g|=        1.1021
At iterate    27  f =       -772.4  |proj g|=        1.1073
At iterate    28  f =       -772.4  |proj g|=        1.1159
At iterate    29  f =       -772.4  |proj g|=        1.1287
At iterate    30  f =      -772.41  |proj g|=         1.147
At iterate    31  f =      -772.44  |proj g|=        1.1667
At iterate    32  f =      -772.49  |proj g|=         1.168
At iterate    33  f =      -772.54  |proj g|=        1.0636
At iterate    34  f =      -772.54  |proj g|=        1.0772
At iterate    35  f =      -772.55  |proj g|=        1.0941
At iterate    36  f =      -772.57  |proj g|=        1.1237
At iterate    37  f =      -772.63  |proj g|=        1.1656
At iterate    38  f =      -772.78  |proj g|=        1.2121
At iterate    39  f =      -773.11  |proj g|=        1.0906
At iterate    40  f =      -773.66  |proj g|=       0.87354
At iterate    41  f =      -774.22  |proj g|=        0.8755
At iterate    42  f =      -774.83  |proj g|=       0.87156
At iterate    43  f =      -775.19  |proj g|=       0.91986
At iterate    44  f =       -775.2  |proj g|=       0.86401
At iterate    45  f =       -775.2  |proj g|=       0.83744
At iterate    46  f =       -775.2  |proj g|=        0.8385

iterations 46
function evaluations 52
segments explored during Cauchy searches 49
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.838498
final function value -775.197

F = -775.197
final  value -775.196630 
converged
 
INFO  [23:16:36.146] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:16:36.203] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:16:36.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:16:45.297] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:16:54.873] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:17:03.639] [mlr3]  Finished benchmark 
INFO  [23:17:03.708] [bbotk] Result of batch 169: 
INFO  [23:17:03.709] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:17:03.709] [bbotk]              5.468046                 3.023136                      0.06507692 
INFO  [23:17:03.709] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:17:03.709] [bbotk]                     3209        0.936 -0.9602159         <NA>   0.9674512 
INFO  [23:17:03.709] [bbotk]                                 uhash 
INFO  [23:17:03.709] [bbotk]  64de46a8-e6f7-40d7-8262-bd24185dd967 
DEBUG [23:17:03.763] [bbotk]  
INFO  [23:17:03.776] [bbotk] Finished optimizing after 200 evaluation(s) 
INFO  [23:17:03.777] [bbotk] Result: 
INFO  [23:17:03.780] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:17:03.780] [bbotk]              7.654452                 8.495489                       0.4972141 
INFO  [23:17:03.780] [bbotk]  ps_cboost_anneal1.mstop learner_param_vals  x_domain classif.auc 
INFO  [23:17:03.780] [bbotk]                     4962         <list[18]> <list[4]>   0.9779066 
INFO  [23:17:20.807] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1.tuned' on task 'spam' (iter 1/5) 
INFO  [23:17:20.910] [bbotk] Starting to optimize 4 parameter(s) with '<OptimizerInterMBO>' and '<TerminatorEvals> [n_evals=200]' 
DEBUG [23:17:20.961] [bbotk]  
INFO  [23:17:20.969] [bbotk] Evaluating 32 configuration(s) 
INFO  [23:17:22.865] [mlr3]  Running benchmark with 96 resampling iterations 
INFO  [23:17:22.873] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:17:25.278] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:17:37.360] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:17:49.633] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:18:02.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:18:13.610] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:18:15.096] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:18:19.935] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:18:22.286] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:18:33.620] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:18:38.510] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:18:53.246] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:18:58.738] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:19:05.193] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:19:07.001] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:19:12.010] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:19:21.466] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:19:23.105] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:19:25.048] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:19:32.640] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:19:37.028] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:19:49.303] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:19:56.863] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:20:07.023] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:20:18.584] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:20:20.980] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:20:27.931] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:20:35.476] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:20:41.713] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:20:45.259] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:20:48.998] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:20:51.606] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:21:01.110] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:21:14.316] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:21:29.652] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:21:39.446] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:21:41.470] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:21:45.578] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:21:47.591] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:21:56.688] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:22:05.229] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:22:15.909] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:22:18.042] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:22:22.702] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:22:25.369] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:22:30.370] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:22:35.189] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:22:45.014] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:22:52.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:22:55.907] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:23:01.634] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:23:10.341] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:23:15.760] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:23:23.723] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:23:32.911] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:23:38.976] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:23:40.717] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:23:48.075] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:23:54.298] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:24:01.233] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:24:13.267] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:24:15.459] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:24:28.670] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:24:35.478] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:24:38.372] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:24:48.897] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:24:53.564] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:25:05.662] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:25:11.391] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:25:20.080] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:25:27.630] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:25:40.933] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:25:44.299] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:26:00.049] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:26:13.853] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:26:28.138] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:26:38.953] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:26:50.013] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:26:58.501] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:27:02.250] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:27:05.467] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:27:10.657] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:27:13.485] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:27:20.635] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:27:34.212] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:27:39.871] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:27:42.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:27:55.617] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:28:01.937] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:28:05.060] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:28:17.914] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:28:24.812] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:28:33.350] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:28:35.088] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:28:44.244] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:28:54.415] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:29:03.164] [mlr3]  Finished benchmark 
INFO  [23:29:04.921] [bbotk] Result of batch 1: 
INFO  [23:29:04.924] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:29:04.924] [bbotk]              6.465655                 6.015830                      0.27437258 
INFO  [23:29:04.924] [bbotk]              7.274568                 6.866384                      0.19441177 
INFO  [23:29:04.924] [bbotk]              5.553751                 8.283651                      0.07470661 
INFO  [23:29:04.924] [bbotk]              8.936164                 4.372708                      0.42236146 
INFO  [23:29:04.924] [bbotk]              4.313169                 8.517967                      0.22006641 
INFO  [23:29:04.924] [bbotk]              3.816244                 8.038559                      0.24687340 
INFO  [23:29:04.924] [bbotk]              7.749313                 3.697903                      0.11711022 
INFO  [23:29:04.924] [bbotk]              5.375964                 5.128769                      0.41528201 
INFO  [23:29:04.924] [bbotk]              6.835418                 8.758966                      0.48097890 
INFO  [23:29:04.924] [bbotk]              4.803215                 2.758832                      0.33198546 
INFO  [23:29:04.924] [bbotk]              8.728190                 7.347052                      0.10640340 
INFO  [23:29:04.924] [bbotk]              7.220392                 5.294330                      0.29562477 
INFO  [23:29:04.924] [bbotk]              7.773623                 7.074984                      0.39521919 
INFO  [23:29:04.924] [bbotk]              3.507812                 4.186036                      0.06260783 
INFO  [23:29:04.924] [bbotk]              9.533375                 7.971203                      0.21399019 
INFO  [23:29:04.924] [bbotk]              3.267651                 5.896713                      0.16665469 
INFO  [23:29:04.924] [bbotk]              4.239082                 6.629240                      0.32385432 
INFO  [23:29:04.924] [bbotk]              3.193578                 3.479247                      0.25332737 
INFO  [23:29:04.924] [bbotk]              5.865962                 9.077312                      0.29825278 
INFO  [23:29:04.924] [bbotk]              8.484400                 3.189597                      0.08760682 
INFO  [23:29:04.924] [bbotk]              6.590564                 2.692558                      0.02623131 
INFO  [23:29:04.924] [bbotk]              8.110766                 9.539163                      0.15161240 
INFO  [23:29:04.924] [bbotk]              2.135188                 5.686190                      0.44368341 
INFO  [23:29:04.924] [bbotk]              6.050053                 4.941442                      0.36251096 
INFO  [23:29:04.924] [bbotk]              9.312095                 6.280867                      0.35549568 
INFO  [23:29:04.924] [bbotk]              2.953956                 3.890139                      0.18128777 
INFO  [23:29:04.924] [bbotk]              2.307258                 2.199089                      0.01614831 
INFO  [23:29:04.924] [bbotk]              9.902219                 4.611624                      0.13553854 
INFO  [23:29:04.924] [bbotk]              9.117838                 9.356462                      0.46332448 
INFO  [23:29:04.924] [bbotk]              2.571790                 9.998654                      0.38699038 
INFO  [23:29:04.924] [bbotk]              5.074862                 2.364182                      0.48952878 
INFO  [23:29:04.924] [bbotk]              4.621883                 7.687701                      0.03585721 
INFO  [23:29:04.924] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:29:04.924] [bbotk]  ps_cboost_anneal1.mstop classif.auc                                uhash 
INFO  [23:29:04.924] [bbotk]                     2808   0.9742953 4fd7b1a2-1e1f-43c5-9c9b-38d443437f94 
INFO  [23:29:04.924] [bbotk]                     2952   0.9734803 f93732c7-7a90-42e6-834c-af482fa7eb13 
INFO  [23:29:04.924] [bbotk]                     3860   0.9697874 5e5abf32-d4b7-40de-a53b-f9c416aa1ecf 
INFO  [23:29:04.924] [bbotk]                      650   0.9704529 3057b0d1-0817-4671-a93e-95345fca8699 
INFO  [23:29:04.924] [bbotk]                     4042   0.9734935 1cbfafdf-0cc8-4321-a042-a430c04a146b 
INFO  [23:29:04.924] [bbotk]                     1592   0.9684920 95d51669-44d9-4f05-a7e4-9812f66e7b8b 
INFO  [23:29:04.924] [bbotk]                     2607   0.9706199 5cea7c27-ae20-4b46-9470-a44e183d146a 
INFO  [23:29:04.924] [bbotk]                     3436   0.9761171 90de04fb-2a95-4cd0-9ac3-385f95bafff7 
INFO  [23:29:04.924] [bbotk]                     1539   0.9742206 4db6ac0b-bca5-452f-bd8e-ae3ac3d34d7f 
INFO  [23:29:04.924] [bbotk]                     4438   0.9757224 9cb66664-985f-4ab1-a1fa-c0c633c8c8f0 
INFO  [23:29:04.924] [bbotk]                     2016   0.9690106 0b5d1710-3ce6-4901-b70d-7b3f12a2301b 
INFO  [23:29:04.924] [bbotk]                     3621   0.9751903 aa39bcfe-9560-4460-8fb6-554713a20001 
INFO  [23:29:04.924] [bbotk]                     2586   0.9752227 726c10f0-b59d-48e2-a8e1-1aebc144dff6 
INFO  [23:29:04.924] [bbotk]                     3167   0.9620038 7557e28a-feb8-4b94-b1f1-4554b396222e 
INFO  [23:29:04.924] [bbotk]                      522   0.9634278 7d2f8f35-9c01-41e4-859e-f5413c9e4340 
INFO  [23:29:04.924] [bbotk]                      423   0.9478428 5ca98862-3b63-4856-8fc9-34d3e3123f3f 
INFO  [23:29:04.924] [bbotk]                     3657   0.9743881 d8c3ed59-4d91-4841-88a2-68935a70fb27 
INFO  [23:29:04.924] [bbotk]                     1854   0.9671864 42e098b4-69c0-41bf-84d0-6fb0d6cff9c6 
INFO  [23:29:04.924] [bbotk]                     1117   0.9708356 32e23086-b121-4298-a976-5fb7c5812624 
INFO  [23:29:04.924] [bbotk]                     4747   0.9723855 f33dbd2e-b1c6-4ea9-9515-e438cb8981d3 
INFO  [23:29:04.924] [bbotk]                     1302   0.9462659 71c4bf14-5510-4de7-a78f-afe76427b5a8 
INFO  [23:29:04.924] [bbotk]                     4248   0.9741139 fc30a4f5-ec31-4c83-9368-8b909c39f572 
INFO  [23:29:04.924] [bbotk]                     2448   0.9624699 39b3cb05-a06c-4603-a1d0-8a7670ffc66d 
INFO  [23:29:04.924] [bbotk]                      982   0.9713488 df78fec1-225c-463f-9954-a071d37183c0 
INFO  [23:29:04.924] [bbotk]                     4972   0.9769276 8c270ae8-4534-4fdd-9867-467f2314dc59 
INFO  [23:29:04.924] [bbotk]                     4625   0.9688657 83e55628-732b-4350-ab5b-aecfdcb2017a 
INFO  [23:29:04.924] [bbotk]                      870   0.8838553 6adb1681-1e79-477a-948d-ca374bfa68b5 
INFO  [23:29:04.924] [bbotk]                     1847   0.9698693 a8462e4f-331c-4d1d-a3f9-b06595a653bb 
INFO  [23:29:04.924] [bbotk]                      245   0.9636776 27478afb-78f2-4e23-bc35-8a91ac3fa853 
INFO  [23:29:04.924] [bbotk]                     4353   0.9697355 eebb080f-d571-4a3f-9260-b58f1c053fe8 
INFO  [23:29:04.924] [bbotk]                     3234   0.9762561 8139bf41-40d7-4b71-89be-abb91b571564 
INFO  [23:29:04.924] [bbotk]                     2259   0.9562347 1c2bffc9-7b30-47fe-b3ea-45e28cfb7eed 
INFO  [23:29:04.924] [bbotk]  ps_cboost_anneal1.mstop classif.auc                                uhash 
DEBUG [23:29:05.669] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.831005e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.53406 15.59913 0.9467609 9454 
  - variance bounds :  2.831005e-05 0.003499796 
  - best initial criterion value(s) :  95.93114 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -95.931  |proj g|=      0.79559
At iterate     1  f =      -98.708  |proj g|=       0.82648
At iterate     2  f =      -101.11  |proj g|=       0.56366
At iterate     3  f =      -102.11  |proj g|=       0.34261
At iterate     4  f =      -102.15  |proj g|=       0.31471
At iterate     5  f =      -102.19  |proj g|=       0.28186
At iterate     6  f =      -102.23  |proj g|=       0.14526
At iterate     7  f =      -102.23  |proj g|=       0.14634
At iterate     8  f =      -102.23  |proj g|=       0.14643
At iterate     9  f =      -102.23  |proj g|=       0.14642

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.146419
final function value -102.227

F = -102.227
final  value -102.226715 
converged
 
INFO  [23:29:05.674] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:29:05.729] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:29:05.736] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:29:17.951] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:29:30.390] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:29:43.878] [mlr3]  Finished benchmark 
INFO  [23:29:43.963] [bbotk] Result of batch 2: 
INFO  [23:29:43.966] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:29:43.966] [bbotk]              7.623801                 3.293886                       0.1520259 
INFO  [23:29:43.966] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:29:43.966] [bbotk]                     4266        0.484 -0.9662331         <NA>   0.9739673 
INFO  [23:29:43.966] [bbotk]                                 uhash 
INFO  [23:29:43.966] [bbotk]  8c07d95c-67e9-451e-a2c5-946a94ac4d24 
DEBUG [23:29:44.686] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.760033e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.53406 15.59913 0.9467609 9454 
  - variance bounds :  2.760033e-05 0.003483028 
  - best initial criterion value(s) :  101.4151 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -101.42  |proj g|=       0.9728
At iterate     1  f =       -102.4  |proj g|=        1.4754
At iterate     2  f =      -102.43  |proj g|=        1.4032
At iterate     3  f =      -102.47  |proj g|=        1.2787
At iterate     4  f =      -102.49  |proj g|=        1.2521
At iterate     5  f =       -102.7  |proj g|=        1.0636
At iterate     6  f =      -102.86  |proj g|=       0.93433
At iterate     7  f =      -102.93  |proj g|=        1.0325
At iterate     8  f =      -102.94  |proj g|=       0.97538
At iterate     9  f =      -102.94  |proj g|=       0.98272
At iterate    10  f =      -102.94  |proj g|=       0.98178
At iterate    11  f =      -102.94  |proj g|=       0.97932
At iterate    12  f =      -102.94  |proj g|=       0.97711
At iterate    13  f =      -102.94  |proj g|=       0.97274
At iterate    14  f =      -102.94  |proj g|=       0.96595
At iterate    15  f =      -102.94  |proj g|=       0.95533
At iterate    16  f =      -102.94  |proj g|=       0.93992
At iterate    17  f =      -102.94  |proj g|=       0.91974
At iterate    18  f =      -102.95  |proj g|=       0.90153
At iterate    19  f =      -102.96  |proj g|=       0.87722
At iterate    20  f =      -106.04  |proj g|=       0.94676
At iterate    21  f =      -106.07  |proj g|=       0.75257
At iterate    22  f =       -106.1  |proj g|=        0.3207
At iterate    23  f =       -106.1  |proj g|=       0.30693
At iterate    24  f =      -106.11  |proj g|=       0.33274
At iterate    25  f =      -106.11  |proj g|=       0.31569
At iterate    26  f =      -106.11  |proj g|=       0.31294
At iterate    27  f =      -106.11  |proj g|=       0.31299
At iterate    28  f =      -106.11  |proj g|=        0.3131
At iterate    29  f =      -106.11  |proj g|=       0.31309
At iterate    30  f =      -106.11  |proj g|=       0.31307
At iterate    31  f =      -106.11  |proj g|=       0.31267
At iterate    32  f =      -106.11  |proj g|=        0.3127
At iterate    33  f =      -106.11  |proj g|=       0.31021
At iterate    34  f =      -106.11  |proj g|=       0.31032
At iterate    35  f =      -106.11  |proj g|=        0.3042
At iterate    36  f =      -106.11  |proj g|=       0.30449
At iterate    37  f =      -106.11  |proj g|=       0.30825
At iterate    38  f =      -106.11  |proj g|=       0.30907
At iterate    39  f =      -106.11  |proj g|=       0.30988
At iterate    40  f =      -106.11  |proj g|=       0.30902
At iterate    41  f =      -106.11  |proj g|=       0.30945
At iterate    42  f =      -106.11  |proj g|=       0.30988
At iterate    43  f =      -106.11  |proj g|=        0.3009
At iterate    44  f =      -106.12  |proj g|=       0.25171
At iterate    45  f =      -106.12  |proj g|=       0.25086
At iterate    46  f =      -106.12  |proj g|=       0.25108
At iterate    47  f =      -106.12  |proj g|=       0.25091
At iterate    48  f =      -106.12  |proj g|=       0.25162
At iterate    49  f =      -106.12  |proj g|=       0.25089
At iterate    50  f =      -106.12  |proj g|=       0.24949
At iterate    51  f =      -106.12  |proj g|=       0.24769
At iterate    52  f =      -106.12  |proj g|=        0.2445
At iterate    53  f =      -106.12  |proj g|=       0.23925
At iterate    54  f =      -106.12  |proj g|=       0.23119
At iterate    55  f =      -106.12  |proj g|=       0.23213
At iterate    56  f =      -106.13  |proj g|=          0.24
At iterate    57  f =      -106.13  |proj g|=       0.23666
At iterate    58  f =      -106.13  |proj g|=       0.23329
At iterate    59  f =      -106.15  |proj g|=       0.23609
At iterate    60  f =      -106.18  |proj g|=       0.25757
At iterate    61  f =      -106.27  |proj g|=       0.27113
At iterate    62  f =      -106.41  |proj g|=       0.27057
At iterate    63  f =      -106.63  |proj g|=       0.19624
At iterate    64  f =      -106.69  |proj g|=       0.20709
At iterate    65  f =      -106.93  |proj g|=       0.12464
At iterate    66  f =      -107.17  |proj g|=      0.048077
At iterate    67  f =      -107.54  |proj g|=       0.94675
At iterate    68  f =      -107.54  |proj g|=       0.94675
At iterate    69  f =      -107.54  |proj g|=       0.94675
At iterate    70  f =      -107.54  |proj g|=       0.94674
At iterate    71  f =      -107.54  |proj g|=       0.94674
At iterate    72  f =      -107.54  |proj g|=       0.94672
At iterate    73  f =      -107.54  |proj g|=       0.94665
At iterate    74  f =      -107.54  |proj g|=       0.94645
At iterate    75  f =      -107.54  |proj g|=       0.94591
At iterate    76  f =      -107.54  |proj g|=       0.94443
At iterate    77  f =      -107.55  |proj g|=       0.94054
At iterate    78  f =      -107.55  |proj g|=       0.93514
At iterate    79  f =      -107.58  |proj g|=       0.77789
At iterate    80  f =      -107.63  |proj g|=       0.45385
At iterate    81  f =      -107.63  |proj g|=       0.39299
At iterate    82  f =      -107.72  |proj g|=       0.21021
At iterate    83  f =      -107.79  |proj g|=       0.30629
At iterate    84  f =       -107.8  |proj g|=      0.050136
At iterate    85  f =       -107.8  |proj g|=      0.016079
At iterate    86  f =       -107.8  |proj g|=     0.0037944
At iterate    87  f =       -107.8  |proj g|=     0.0022438
At iterate    88  f =       -107.8  |proj g|=    0.00028281

iterations 88
function evaluations 108
segments explored during Cauchy searches 90
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.000282813
final function value -107.799

F = -107.799
final  value -107.799305 
converged
 
INFO  [23:29:44.691] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:29:44.746] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:29:44.753] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:29:46.499] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:29:47.996] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:29:50.310] [mlr3]  Finished benchmark 
INFO  [23:29:50.380] [bbotk] Result of batch 3: 
INFO  [23:29:50.382] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:29:50.382] [bbotk]              2.503039                 2.201781                       0.2737256 
INFO  [23:29:50.382] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:29:50.382] [bbotk]                      446        0.463 -0.9664931         <NA>   0.9433904 
INFO  [23:29:50.382] [bbotk]                                 uhash 
INFO  [23:29:50.382] [bbotk]  0ecc6017-b995-4e94-9c3a-cc5b8da8e701 
DEBUG [23:29:51.053] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.834817e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.53406 15.59913 0.9467609 9454 
  - variance bounds :  2.834817e-05 0.003574444 
  - best initial criterion value(s) :  104.016 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -104.02  |proj g|=      0.66418
At iterate     1  f =      -104.82  |proj g|=       0.29035
At iterate     2  f =      -104.82  |proj g|=       0.30163
At iterate     3  f =      -104.82  |proj g|=       0.28876
At iterate     4  f =      -104.82  |proj g|=       0.28877

iterations 4
function evaluations 7
segments explored during Cauchy searches 6
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.288769
final function value -104.821

F = -104.821
final  value -104.820727 
converged
 
INFO  [23:29:51.057] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:29:51.113] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:29:51.120] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:29:57.201] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:30:02.659] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:30:09.893] [mlr3]  Finished benchmark 
INFO  [23:30:09.964] [bbotk] Result of batch 4: 
INFO  [23:30:09.966] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:30:09.966] [bbotk]              9.938922                 6.300721                       0.3622629 
INFO  [23:30:09.966] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [23:30:09.966] [bbotk]                     1977        0.496 -0.975501         <NA>   0.9745555 
INFO  [23:30:09.966] [bbotk]                                 uhash 
INFO  [23:30:09.966] [bbotk]  0adc6108-0180-4f40-8297-533be5eb9ef9 
DEBUG [23:30:10.632] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.772765e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.772765e-05 0.003415505 
  - best initial criterion value(s) :  110.5235 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -110.52  |proj g|=      0.45879
At iterate     1  f =      -110.72  |proj g|=       0.45021
At iterate     2  f =      -110.73  |proj g|=       0.45073
At iterate     3  f =      -110.73  |proj g|=        0.4504
At iterate     4  f =      -110.73  |proj g|=       0.44872
At iterate     5  f =      -110.75  |proj g|=       0.44198
At iterate     6  f =      -110.78  |proj g|=         0.427
At iterate     7  f =      -110.81  |proj g|=       0.40314
At iterate     8  f =      -110.83  |proj g|=       0.39876
At iterate     9  f =      -110.83  |proj g|=       0.23991
At iterate    10  f =      -110.83  |proj g|=       0.24018
At iterate    11  f =      -110.83  |proj g|=       0.24016

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.240161
final function value -110.829

F = -110.829
final  value -110.828592 
converged
 
INFO  [23:30:10.636] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:30:10.692] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:30:10.699] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:30:15.508] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:30:19.545] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:30:24.101] [mlr3]  Finished benchmark 
INFO  [23:30:24.167] [bbotk] Result of batch 5: 
INFO  [23:30:24.168] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:30:24.168] [bbotk]              9.273273                 4.316683                       0.4816807 
INFO  [23:30:24.168] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [23:30:24.168] [bbotk]                     1581        0.471 -0.974039         <NA>   0.9748117 
INFO  [23:30:24.168] [bbotk]                                 uhash 
INFO  [23:30:24.168] [bbotk]  b581a604-6163-438a-9759-ac06670d3e8d 
DEBUG [23:30:24.816] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.71432e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.71432e-05 0.003226273 
  - best initial criterion value(s) :  115.7643 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -115.76  |proj g|=       0.6286
At iterate     1  f =      -116.55  |proj g|=        1.2693
At iterate     2  f =      -117.27  |proj g|=        1.0479
At iterate     3  f =      -117.72  |proj g|=       0.67502
At iterate     4  f =      -117.78  |proj g|=       0.60138
At iterate     5  f =      -118.05  |proj g|=       0.49623
At iterate     6  f =      -118.24  |proj g|=       0.42801
At iterate     7  f =      -118.26  |proj g|=       0.53249
At iterate     8  f =      -118.27  |proj g|=       0.51137
At iterate     9  f =      -118.27  |proj g|=       0.50918
At iterate    10  f =      -118.27  |proj g|=       0.50925

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.509251
final function value -118.266

F = -118.266
final  value -118.265675 
converged
 
INFO  [23:30:24.820] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:30:24.874] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:30:24.881] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:30:26.146] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:30:27.447] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:30:28.505] [mlr3]  Finished benchmark 
INFO  [23:30:28.571] [bbotk] Result of batch 6: 
INFO  [23:30:28.573] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:30:28.573] [bbotk]              5.741114                 9.565733                        0.193568 
INFO  [23:30:28.573] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:30:28.573] [bbotk]                      250        0.466 -0.9705781         <NA>   0.9516489 
INFO  [23:30:28.573] [bbotk]                                 uhash 
INFO  [23:30:28.573] [bbotk]  667b10ac-87da-4185-a79a-66036edbb127 
DEBUG [23:30:29.205] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.697758e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.697758e-05 0.003198573 
  - best initial criterion value(s) :  116.9949 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -116.99  |proj g|=        1.356
At iterate     1  f =      -117.62  |proj g|=        0.6357
At iterate     2  f =      -118.61  |proj g|=       0.61652
At iterate     3  f =       -119.1  |proj g|=       0.59681
At iterate     4  f =      -119.17  |proj g|=       0.58538
At iterate     5  f =      -119.24  |proj g|=       0.59368
At iterate     6  f =      -119.54  |proj g|=       0.52762
At iterate     7  f =      -119.59  |proj g|=       0.50016
At iterate     8  f =       -119.6  |proj g|=       0.49153
At iterate     9  f =       -119.6  |proj g|=       0.48968
At iterate    10  f =       -119.6  |proj g|=       0.48958
At iterate    11  f =       -119.6  |proj g|=       0.48954

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.489543
final function value -119.6

F = -119.6
final  value -119.600057 
converged
 
INFO  [23:30:29.209] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:30:29.281] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:30:29.288] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:30:31.434] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:30:33.509] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:30:35.998] [mlr3]  Finished benchmark 
INFO  [23:30:36.065] [bbotk] Result of batch 7: 
INFO  [23:30:36.066] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:30:36.066] [bbotk]              9.526175                 2.322711                       0.3341257 
INFO  [23:30:36.066] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:30:36.066] [bbotk]                      638         0.47 -0.9683382         <NA>   0.9690699 
INFO  [23:30:36.066] [bbotk]                                 uhash 
INFO  [23:30:36.066] [bbotk]  d4d99007-8c6a-4067-8b65-36ca0cebe2fc 
DEBUG [23:30:36.720] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.627319e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.627319e-05 0.0030331 
  - best initial criterion value(s) :  123.3335 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -123.33  |proj g|=      0.68178
At iterate     1  f =      -124.51  |proj g|=       0.61606
At iterate     2  f =      -124.76  |proj g|=       0.60306
At iterate     3  f =      -125.31  |proj g|=       0.53784
At iterate     4  f =      -125.37  |proj g|=       0.52052
At iterate     5  f =       -125.4  |proj g|=       0.25744
At iterate     6  f =       -125.4  |proj g|=       0.14386
At iterate     7  f =       -125.4  |proj g|=       0.14591
At iterate     8  f =       -125.4  |proj g|=       0.14601

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.146011
final function value -125.4

F = -125.4
final  value -125.400291 
converged
 
INFO  [23:30:36.724] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:30:36.791] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:30:36.798] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:30:42.605] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:30:48.755] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:30:55.027] [mlr3]  Finished benchmark 
INFO  [23:30:55.095] [bbotk] Result of batch 8: 
INFO  [23:30:55.097] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:30:55.097] [bbotk]              6.263215                 7.469312                       0.1507618 
INFO  [23:30:55.097] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:30:55.097] [bbotk]                     2132        0.475 -0.9670964         <NA>   0.9707705 
INFO  [23:30:55.097] [bbotk]                                 uhash 
INFO  [23:30:55.097] [bbotk]  95209f3e-bb89-4ae6-8bbc-50a8002567e1 
DEBUG [23:30:55.785] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.563807e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.563807e-05 0.002913731 
  - best initial criterion value(s) :  123.0625 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -123.06  |proj g|=       1.3876
At iterate     1  f =      -124.02  |proj g|=        2.3449
At iterate     2  f =       -125.8  |proj g|=        2.1097
At iterate     3  f =      -128.31  |proj g|=        1.3062
At iterate     4  f =      -128.46  |proj g|=        1.0383
At iterate     5  f =      -128.46  |proj g|=         1.007
At iterate     6  f =      -128.49  |proj g|=       0.95476
At iterate     7  f =      -128.52  |proj g|=       0.93176
At iterate     8  f =      -128.53  |proj g|=        1.0512
At iterate     9  f =      -128.54  |proj g|=        1.0005
At iterate    10  f =      -128.54  |proj g|=       0.99313
At iterate    11  f =      -128.54  |proj g|=       0.99333
At iterate    12  f =      -128.54  |proj g|=       0.99339
At iterate    13  f =      -128.54  |proj g|=       0.99359
At iterate    14  f =      -128.54  |proj g|=       0.99386
At iterate    15  f =      -128.54  |proj g|=       0.99438
At iterate    16  f =      -128.54  |proj g|=       0.99485
At iterate    17  f =      -128.54  |proj g|=       0.99679
At iterate    18  f =      -128.54  |proj g|=        0.9934
At iterate    19  f =      -128.54  |proj g|=        1.0033
At iterate    20  f =      -128.54  |proj g|=        1.0002
At iterate    21  f =      -128.55  |proj g|=       0.98204
At iterate    22  f =      -128.56  |proj g|=       0.95097
At iterate    23  f =      -128.61  |proj g|=       0.87214
At iterate    24  f =      -128.73  |proj g|=       0.70895
At iterate    25  f =      -128.93  |proj g|=       0.57375
At iterate    26  f =      -129.18  |proj g|=        0.6185
At iterate    27  f =      -129.53  |proj g|=       0.57033
At iterate    28  f =      -129.77  |proj g|=       0.14107
At iterate    29  f =      -129.81  |proj g|=       0.45829
At iterate    30  f =      -129.82  |proj g|=       0.12652
At iterate    31  f =      -129.82  |proj g|=       0.12385
At iterate    32  f =      -129.82  |proj g|=       0.12392
At iterate    33  f =      -129.82  |proj g|=       0.12397

iterations 33
function evaluations 38
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.123974
final function value -129.816

F = -129.816
final  value -129.816249 
converged
 
INFO  [23:30:55.789] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:30:55.844] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:30:55.851] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:31:04.536] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:31:13.108] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:31:21.895] [mlr3]  Finished benchmark 
INFO  [23:31:21.963] [bbotk] Result of batch 9: 
INFO  [23:31:21.965] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:31:21.965] [bbotk]              5.069836                 6.457112                       0.3172421 
INFO  [23:31:21.965] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:31:21.965] [bbotk]                     3135        0.488 -0.9663527         <NA>   0.9748317 
INFO  [23:31:21.965] [bbotk]                                 uhash 
INFO  [23:31:21.965] [bbotk]  d5fb4566-edf5-40ea-a8b0-5e12c3d89d97 
DEBUG [23:31:22.606] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.516672e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.516672e-05 0.002915504 
  - best initial criterion value(s) :  133.47 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -133.47  |proj g|=      0.62932
At iterate     1  f =      -134.65  |proj g|=       0.59876
At iterate     2  f =      -134.71  |proj g|=       0.56735
At iterate     3  f =      -134.89  |proj g|=        0.5386
At iterate     4  f =      -134.93  |proj g|=         0.526
At iterate     5  f =      -134.97  |proj g|=       0.44492
At iterate     6  f =      -134.97  |proj g|=       0.41663
At iterate     7  f =      -134.97  |proj g|=       0.41867
At iterate     8  f =      -134.97  |proj g|=       0.41875

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.418754
final function value -134.969

F = -134.969
final  value -134.969359 
converged
 
INFO  [23:31:22.610] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:31:22.667] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:31:22.674] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:31:34.086] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:31:46.682] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:31:58.854] [mlr3]  Finished benchmark 
INFO  [23:31:59.073] [bbotk] Result of batch 10: 
INFO  [23:31:59.075] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:31:59.075] [bbotk]              7.714875                 5.812871                      0.05011135 
INFO  [23:31:59.075] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:31:59.075] [bbotk]                     4459         0.48 -0.9658027         <NA>   0.9690578 
INFO  [23:31:59.075] [bbotk]                                 uhash 
INFO  [23:31:59.075] [bbotk]  74f0afa1-3c4c-48ef-802d-b6e53c18854f 
DEBUG [23:31:59.757] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.455451e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.455451e-05 0.002889908 
  - best initial criterion value(s) :  135.0835 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -135.08  |proj g|=       1.7608
At iterate     1  f =      -138.17  |proj g|=       0.92588
At iterate     2  f =      -138.91  |proj g|=       0.66912
At iterate     3  f =      -139.37  |proj g|=       0.48801
At iterate     4  f =      -139.38  |proj g|=       0.46511
At iterate     5  f =      -139.39  |proj g|=       0.18017
At iterate     6  f =      -139.39  |proj g|=       0.18531
At iterate     7  f =      -139.39  |proj g|=       0.47845
At iterate     8  f =      -139.39  |proj g|=       0.48002
At iterate     9  f =      -139.39  |proj g|=       0.48007

iterations 9
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.48007
final function value -139.393

F = -139.393
final  value -139.393084 
converged
 
INFO  [23:31:59.761] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:31:59.816] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:31:59.823] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:32:05.791] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:32:09.454] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:32:14.437] [mlr3]  Finished benchmark 
INFO  [23:32:14.504] [bbotk] Result of batch 11: 
INFO  [23:32:14.506] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:32:14.506] [bbotk]              5.942772                 7.879223                       0.4677686 
INFO  [23:32:14.506] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:32:14.506] [bbotk]                     1483        0.492 -0.9656224         <NA>   0.9740353 
INFO  [23:32:14.506] [bbotk]                                 uhash 
INFO  [23:32:14.506] [bbotk]  998b6c8b-6cc1-40ea-b988-726724d9cf76 
DEBUG [23:32:15.212] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.409134e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.409134e-05 0.002759502 
  - best initial criterion value(s) :  136.6248 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -136.62  |proj g|=       1.8254
At iterate     1  f =      -137.72  |proj g|=        2.3656
At iterate     2  f =      -137.86  |proj g|=         2.306
At iterate     3  f =      -137.92  |proj g|=        2.1987
At iterate     4  f =      -137.93  |proj g|=        2.2122
At iterate     5  f =      -137.97  |proj g|=        2.2057
At iterate     6  f =      -138.06  |proj g|=        2.1314
At iterate     7  f =      -138.15  |proj g|=        1.9875
At iterate     8  f =      -138.21  |proj g|=         1.788
At iterate     9  f =      -138.21  |proj g|=        1.8008
At iterate    10  f =      -138.22  |proj g|=        1.7991
At iterate    11  f =      -138.22  |proj g|=         1.792
At iterate    12  f =      -138.22  |proj g|=        1.7797
At iterate    13  f =      -138.23  |proj g|=        1.7564
At iterate    14  f =      -138.25  |proj g|=        1.7126
At iterate    15  f =      -138.32  |proj g|=        1.6231
At iterate    16  f =      -138.49  |proj g|=        1.4394
At iterate    17  f =      -138.93  |proj g|=        1.0795
At iterate    18  f =      -139.74  |proj g|=       0.59608
At iterate    19  f =      -140.15  |proj g|=        1.1415
At iterate    20  f =      -140.65  |proj g|=       0.62064
At iterate    21  f =      -140.77  |proj g|=       0.58223
At iterate    22  f =      -141.14  |proj g|=       0.53682
At iterate    23  f =       -141.2  |proj g|=       0.53632
At iterate    24  f =      -141.65  |proj g|=       0.55091
At iterate    25  f =      -141.68  |proj g|=       0.54148
At iterate    26  f =      -141.71  |proj g|=        0.5106
At iterate    27  f =      -141.72  |proj g|=       0.50291
At iterate    28  f =      -141.72  |proj g|=       0.50296
At iterate    29  f =      -141.72  |proj g|=       0.50317
At iterate    30  f =      -141.72  |proj g|=       0.50322

iterations 30
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.503218
final function value -141.717

F = -141.717
final  value -141.717447 
converged
 
INFO  [23:32:15.216] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:32:15.271] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:32:15.278] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:32:29.818] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:32:44.654] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:32:59.331] [mlr3]  Finished benchmark 
INFO  [23:32:59.400] [bbotk] Result of batch 12: 
INFO  [23:32:59.401] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:32:59.401] [bbotk]              3.523815                 4.051103                        0.343824 
INFO  [23:32:59.401] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:32:59.401] [bbotk]                     4896        0.496 -0.9687962         <NA>   0.9738001 
INFO  [23:32:59.401] [bbotk]                                 uhash 
INFO  [23:32:59.401] [bbotk]  a22c60ae-6817-4ae1-bddf-235324e3c13a 
DEBUG [23:33:00.140] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.363612e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.363612e-05 0.002752999 
  - best initial criterion value(s) :  137.345 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -137.35  |proj g|=       2.0239
At iterate     1  f =      -140.77  |proj g|=        1.9851
At iterate     2  f =      -142.19  |proj g|=        1.7057
At iterate     3  f =      -143.43  |proj g|=        1.2087
At iterate     4  f =       -143.7  |proj g|=       0.79922
At iterate     5  f =      -143.82  |proj g|=       0.88328
At iterate     6  f =      -144.47  |proj g|=        1.1157
At iterate     7  f =      -144.74  |proj g|=         1.152
At iterate     8  f =      -144.77  |proj g|=        1.3476
At iterate     9  f =      -144.81  |proj g|=        1.2447
At iterate    10  f =      -144.81  |proj g|=        1.2116
At iterate    11  f =      -144.81  |proj g|=        1.2135
At iterate    12  f =      -144.81  |proj g|=        1.2138
At iterate    13  f =      -144.81  |proj g|=        1.2141
At iterate    14  f =      -144.81  |proj g|=        1.2148
At iterate    15  f =      -144.81  |proj g|=        1.2157
At iterate    16  f =      -144.81  |proj g|=         1.217
At iterate    17  f =      -144.81  |proj g|=        1.2193
At iterate    18  f =      -144.82  |proj g|=        1.2174
At iterate    19  f =      -144.82  |proj g|=        1.2289
At iterate    20  f =      -144.82  |proj g|=        1.2257
At iterate    21  f =      -144.83  |proj g|=         1.212
At iterate    22  f =      -144.85  |proj g|=        1.1809
At iterate    23  f =      -144.92  |proj g|=        1.0982
At iterate    24  f =      -145.05  |proj g|=       0.95034
At iterate    25  f =      -145.25  |proj g|=       0.78588
At iterate    26  f =      -145.29  |proj g|=       0.85423
At iterate    27  f =      -145.49  |proj g|=       0.66658
At iterate    28  f =      -145.56  |proj g|=       0.59738
At iterate    29  f =      -145.56  |proj g|=       0.62209
At iterate    30  f =      -145.56  |proj g|=       0.61938
At iterate    31  f =      -145.56  |proj g|=       0.62024
At iterate    32  f =      -145.56  |proj g|=       0.62029

iterations 32
function evaluations 38
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.620293
final function value -145.561

F = -145.561
final  value -145.561241 
converged
 
INFO  [23:33:00.144] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:33:00.200] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:33:00.207] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:33:03.816] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:33:07.884] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:33:12.541] [mlr3]  Finished benchmark 
INFO  [23:33:12.607] [bbotk] Result of batch 13: 
INFO  [23:33:12.608] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:33:12.608] [bbotk]              7.054611                 9.622374                       0.3935787 
INFO  [23:33:12.608] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:33:12.608] [bbotk]                     1574        0.503 -0.9643314         <NA>   0.9737095 
INFO  [23:33:12.608] [bbotk]                                 uhash 
INFO  [23:33:12.608] [bbotk]  d0f58545-6732-479b-855c-c09bd13333c4 
DEBUG [23:33:13.327] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.319398e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.319398e-05 0.002636583 
  - best initial criterion value(s) :  147.5491 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -147.55  |proj g|=      0.39595
At iterate     1  f =      -149.71  |proj g|=        0.9717
At iterate     2  f =      -149.72  |proj g|=       0.94115
At iterate     3  f =      -149.75  |proj g|=       0.89372
At iterate     4  f =      -149.77  |proj g|=       0.88404
At iterate     5  f =      -149.85  |proj g|=        0.8982
At iterate     6  f =      -149.92  |proj g|=        0.9839
At iterate     7  f =      -149.95  |proj g|=        1.0611
At iterate     8  f =      -149.95  |proj g|=         1.084
At iterate     9  f =      -149.95  |proj g|=        1.0874
At iterate    10  f =      -149.95  |proj g|=        1.0874
At iterate    11  f =      -149.95  |proj g|=        1.0872
At iterate    12  f =      -149.95  |proj g|=        1.0878
At iterate    13  f =      -149.95  |proj g|=        1.0876
At iterate    14  f =      -149.95  |proj g|=        1.0813
At iterate    15  f =      -149.96  |proj g|=        1.0684
At iterate    16  f =      -149.99  |proj g|=        1.0308
At iterate    17  f =      -150.12  |proj g|=       0.90749
At iterate    18  f =      -150.12  |proj g|=       0.89587
At iterate    19  f =       -150.4  |proj g|=       0.72593
At iterate    20  f =      -152.33  |proj g|=       0.54341
At iterate    21  f =      -152.59  |proj g|=       0.52505
At iterate    22  f =      -152.78  |proj g|=       0.31107
At iterate    23  f =      -152.81  |proj g|=        0.3146
At iterate    24  f =      -152.83  |proj g|=       0.32708
At iterate    25  f =      -152.83  |proj g|=       0.31061
At iterate    26  f =      -152.83  |proj g|=       0.31291
At iterate    27  f =      -152.83  |proj g|=       0.31112
At iterate    28  f =      -152.83  |proj g|=        0.3112
At iterate    29  f =      -152.83  |proj g|=       0.31124

iterations 29
function evaluations 41
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.311237
final function value -152.833

F = -152.833
final  value -152.833302 
converged
 
INFO  [23:33:13.331] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:33:13.388] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:33:13.395] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:33:14.900] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:33:16.303] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:33:17.786] [mlr3]  Finished benchmark 
INFO  [23:33:17.853] [bbotk] Result of batch 14: 
INFO  [23:33:17.855] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:33:17.855] [bbotk]              4.118971                 7.887113                       0.1927945 
INFO  [23:33:17.855] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:33:17.855] [bbotk]                      467        0.494 -0.9638464         <NA>   0.9559619 
INFO  [23:33:17.855] [bbotk]                                 uhash 
INFO  [23:33:17.855] [bbotk]  2708354a-4e6e-4195-af2d-5d3425b50d95 
DEBUG [23:33:18.536] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.293698e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.293698e-05 0.002581877 
  - best initial criterion value(s) :  149.4651 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -149.47  |proj g|=      0.57796
At iterate     1  f =      -150.18  |proj g|=       0.55564
At iterate     2  f =      -150.19  |proj g|=       0.55543
At iterate     3  f =      -150.19  |proj g|=        0.5522
At iterate     4  f =       -150.2  |proj g|=       0.54627
At iterate     5  f =      -150.23  |proj g|=       0.52706
At iterate     6  f =      -150.24  |proj g|=       0.39809
At iterate     7  f =      -150.25  |proj g|=       0.24353
At iterate     8  f =      -150.25  |proj g|=        0.2387
At iterate     9  f =      -150.25  |proj g|=        0.2382
At iterate    10  f =      -150.25  |proj g|=       0.23819

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.238195
final function value -150.247

F = -150.247
final  value -150.247098 
converged
 
INFO  [23:33:18.540] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:33:18.594] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:33:18.601] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:33:21.591] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:33:24.119] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:33:26.288] [mlr3]  Finished benchmark 
INFO  [23:33:26.354] [bbotk] Result of batch 15: 
INFO  [23:33:26.356] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:33:26.356] [bbotk]              5.538724                 4.202581                        0.331623 
INFO  [23:33:26.356] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [23:33:26.356] [bbotk]                      801        0.496 -0.972692         <NA>   0.9692882 
INFO  [23:33:26.356] [bbotk]                                 uhash 
INFO  [23:33:26.356] [bbotk]  486993a5-e9fe-47ce-816e-0510d97f8e66 
DEBUG [23:33:27.121] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.244136e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.244136e-05 0.002477418 
  - best initial criterion value(s) :  156.8504 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -156.85  |proj g|=      0.96437
At iterate     1  f =      -157.87  |proj g|=        1.4731
At iterate     2  f =      -158.17  |proj g|=        1.4306
At iterate     3  f =      -158.79  |proj g|=        1.2236
At iterate     4  f =      -158.86  |proj g|=        1.2893
At iterate     5  f =      -158.88  |proj g|=        1.3205
At iterate     6  f =      -158.88  |proj g|=        1.3265
At iterate     7  f =      -158.88  |proj g|=        1.3272
At iterate     8  f =      -158.88  |proj g|=        1.3272
At iterate     9  f =      -158.88  |proj g|=        1.3276
At iterate    10  f =      -158.88  |proj g|=         1.328
At iterate    11  f =      -158.88  |proj g|=        1.3288
At iterate    12  f =      -158.88  |proj g|=        1.3298
At iterate    13  f =      -158.88  |proj g|=        1.3314
At iterate    14  f =      -158.88  |proj g|=        1.3333
At iterate    15  f =      -158.89  |proj g|=        1.3376
At iterate    16  f =      -158.89  |proj g|=        1.3411
At iterate    17  f =      -158.89  |proj g|=        1.3505
At iterate    18  f =       -158.9  |proj g|=        1.3499
At iterate    19  f =      -158.91  |proj g|=        1.3685
At iterate    20  f =      -158.93  |proj g|=        1.3621
At iterate    21  f =      -159.32  |proj g|=        1.2482
At iterate    22  f =      -161.17  |proj g|=       0.69343
At iterate    23  f =      -161.29  |proj g|=       0.67216
At iterate    24  f =       -161.8  |proj g|=       0.40761
At iterate    25  f =      -161.81  |proj g|=       0.52592
At iterate    26  f =      -161.82  |proj g|=       0.55246
At iterate    27  f =      -161.82  |proj g|=        0.5386
At iterate    28  f =      -161.82  |proj g|=       0.53842
At iterate    29  f =      -161.82  |proj g|=       0.53834
At iterate    30  f =      -161.82  |proj g|=       0.53773
At iterate    31  f =      -161.82  |proj g|=       0.53665
At iterate    32  f =      -161.82  |proj g|=         0.537
At iterate    33  f =      -161.82  |proj g|=       0.53785
At iterate    34  f =      -161.82  |proj g|=       0.53914
At iterate    35  f =      -161.82  |proj g|=       0.54119
At iterate    36  f =      -161.82  |proj g|=       0.54465
At iterate    37  f =      -161.82  |proj g|=       0.55056
At iterate    38  f =      -161.83  |proj g|=       0.56656
At iterate    39  f =      -161.83  |proj g|=       0.57554
At iterate    40  f =      -161.83  |proj g|=       0.62983
At iterate    41  f =      -161.85  |proj g|=       0.64309
At iterate    42  f =      -161.89  |proj g|=       0.72107
At iterate    43  f =      -161.89  |proj g|=       0.75149
At iterate    44  f =       -161.9  |proj g|=       0.75315
At iterate    45  f =      -161.91  |proj g|=       0.76278
At iterate    46  f =      -161.95  |proj g|=       0.87282
At iterate    47  f =      -161.97  |proj g|=       0.79204
At iterate    48  f =      -162.04  |proj g|=       0.85488
At iterate    49  f =      -162.54  |proj g|=       0.87208
At iterate    50  f =      -162.78  |proj g|=       0.84302
At iterate    51  f =      -163.18  |proj g|=       0.51778
At iterate    52  f =      -163.42  |proj g|=       0.52842
At iterate    53  f =      -163.47  |proj g|=       0.53302
At iterate    54  f =      -163.48  |proj g|=       0.53528
At iterate    55  f =      -163.49  |proj g|=       0.53381
At iterate    56  f =      -163.52  |proj g|=       0.51539
At iterate    57  f =      -163.56  |proj g|=       0.12367
At iterate    58  f =      -163.58  |proj g|=       0.47519
At iterate    59  f =      -163.59  |proj g|=       0.15658
At iterate    60  f =      -163.59  |proj g|=      0.026966
At iterate    61  f =      -163.59  |proj g|=       0.07375
At iterate    62  f =      -163.59  |proj g|=      0.075738
At iterate    63  f =      -163.59  |proj g|=      0.056555
At iterate    64  f =      -163.59  |proj g|=      0.015399
At iterate    65  f =      -163.59  |proj g|=     0.0018357
At iterate    66  f =      -163.59  |proj g|=    0.00074867

iterations 66
function evaluations 80
segments explored during Cauchy searches 68
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.000748671
final function value -163.586

F = -163.586
final  value -163.586475 
converged
 
INFO  [23:33:27.125] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:33:27.181] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:33:27.188] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:33:28.633] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:33:30.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:33:31.625] [mlr3]  Finished benchmark 
INFO  [23:33:31.862] [bbotk] Result of batch 16: 
INFO  [23:33:31.863] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:33:31.863] [bbotk]              9.753716                 4.193709                       0.4284394 
INFO  [23:33:31.863] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:33:31.863] [bbotk]                      412        0.499 -0.9644175         <NA>   0.9676232 
INFO  [23:33:31.863] [bbotk]                                 uhash 
INFO  [23:33:31.863] [bbotk]  ba4eab73-2b23-421f-9fd4-f59f01439124 
DEBUG [23:33:32.555] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.195495e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.195495e-05 0.002378044 
  - best initial criterion value(s) :  164.0254 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -164.03  |proj g|=      0.37982
At iterate     1  f =      -164.59  |proj g|=       0.88435
At iterate     2  f =      -164.59  |proj g|=        0.8543
At iterate     3  f =      -164.59  |proj g|=       0.83916
At iterate     4  f =      -164.59  |proj g|=       0.83724
At iterate     5  f =      -164.59  |proj g|=        0.8282
At iterate     6  f =       -164.6  |proj g|=       0.83254
At iterate     7  f =       -164.6  |proj g|=       0.86488
At iterate     8  f =       -164.6  |proj g|=       0.87109
At iterate     9  f =       -164.6  |proj g|=       0.87168
At iterate    10  f =       -164.6  |proj g|=       0.87169

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.871688
final function value -164.601

F = -164.601
final  value -164.601089 
converged
 
INFO  [23:33:32.560] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:33:32.614] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:33:32.621] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:33:37.221] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:33:43.001] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:33:49.464] [mlr3]  Finished benchmark 
INFO  [23:33:49.532] [bbotk] Result of batch 17: 
INFO  [23:33:49.534] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:33:49.534] [bbotk]              6.330225                 8.483508                       0.4476678 
INFO  [23:33:49.534] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:33:49.534] [bbotk]                     1568        0.506 -0.9684459         <NA>   0.9740234 
INFO  [23:33:49.534] [bbotk]                                 uhash 
INFO  [23:33:49.534] [bbotk]  9582f8fd-b12f-4ffb-b60e-01b4ffbda497 
DEBUG [23:33:50.265] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.159607e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.159607e-05 0.002289891 
  - best initial criterion value(s) :  165.1867 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -165.19  |proj g|=       1.5325
At iterate     1  f =      -165.95  |proj g|=        3.8614
At iterate     2  f =      -167.62  |proj g|=        3.6113
At iterate     3  f =      -170.72  |proj g|=        2.6334
At iterate     4  f =      -170.95  |proj g|=        2.2602
At iterate     5  f =      -170.96  |proj g|=        2.1889
At iterate     6  f =      -170.96  |proj g|=        2.2082
At iterate     7  f =      -170.96  |proj g|=        2.2085
At iterate     8  f =      -170.96  |proj g|=        2.2095
At iterate     9  f =      -171.17  |proj g|=        1.9814
At iterate    10  f =      -172.29  |proj g|=       0.98807
At iterate    11  f =       -173.5  |proj g|=       0.45173
At iterate    12  f =      -173.61  |proj g|=       0.52454
At iterate    13  f =      -174.16  |proj g|=        0.4677
At iterate    14  f =       -174.3  |proj g|=        0.4874
At iterate    15  f =      -174.33  |proj g|=       0.50506
At iterate    16  f =      -174.33  |proj g|=       0.23821
At iterate    17  f =      -174.33  |proj g|=        0.2472
At iterate    18  f =      -174.33  |proj g|=       0.24246
At iterate    19  f =      -174.33  |proj g|=        0.2439
At iterate    20  f =      -174.33  |proj g|=       0.24392
At iterate    21  f =      -174.33  |proj g|=       0.24393

iterations 21
function evaluations 30
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.243934
final function value -174.335

F = -174.335
final  value -174.334775 
converged
 
INFO  [23:33:50.269] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:33:50.349] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:33:50.356] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:34:01.107] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:34:10.852] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:34:19.768] [mlr3]  Finished benchmark 
INFO  [23:34:19.974] [bbotk] Result of batch 18: 
INFO  [23:34:19.976] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:34:19.976] [bbotk]              8.467143                 8.984793                       0.2272606 
INFO  [23:34:19.976] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:34:19.976] [bbotk]                     3467        0.529 -0.9629647         <NA>   0.9747486 
INFO  [23:34:19.976] [bbotk]                                 uhash 
INFO  [23:34:19.976] [bbotk]  b58b3303-707e-4eee-adc3-c968553aa0e5 
DEBUG [23:34:20.745] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.126978e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.126978e-05 0.002300192 
  - best initial criterion value(s) :  166.2019 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -166.2  |proj g|=       1.5369
At iterate     1  f =      -170.12  |proj g|=        1.8973
At iterate     2  f =      -170.25  |proj g|=        1.8648
At iterate     3  f =      -170.34  |proj g|=        1.7738
At iterate     4  f =      -170.35  |proj g|=        1.7983
At iterate     5  f =      -170.35  |proj g|=        1.7948
At iterate     6  f =      -170.36  |proj g|=        1.7748
At iterate     7  f =      -170.37  |proj g|=        1.7525
At iterate     8  f =      -170.38  |proj g|=        1.7262
At iterate     9  f =      -170.38  |proj g|=        1.7392
At iterate    10  f =      -170.38  |proj g|=        1.7276
At iterate    11  f =      -170.38  |proj g|=        1.7279
At iterate    12  f =      -170.38  |proj g|=        1.7297
At iterate    13  f =      -170.38  |proj g|=        1.7317
At iterate    14  f =      -170.38  |proj g|=        1.7353
At iterate    15  f =      -170.38  |proj g|=        1.7546
At iterate    16  f =      -170.38  |proj g|=        1.7479
At iterate    17  f =      -170.39  |proj g|=        1.7382
At iterate    18  f =      -170.41  |proj g|=         1.715
At iterate    19  f =      -170.44  |proj g|=        1.6741
At iterate    20  f =      -170.55  |proj g|=        1.5935
At iterate    21  f =       -170.8  |proj g|=        1.4413
At iterate    22  f =      -171.35  |proj g|=        1.2006
At iterate    23  f =      -172.04  |proj g|=        1.0376
At iterate    24  f =      -172.21  |proj g|=         1.052
At iterate    25  f =      -172.24  |proj g|=        1.0833
At iterate    26  f =      -172.24  |proj g|=        1.0977
At iterate    27  f =      -172.24  |proj g|=        1.0993
At iterate    28  f =      -172.24  |proj g|=        1.1012
At iterate    29  f =      -172.24  |proj g|=        1.1031
At iterate    30  f =      -172.24  |proj g|=         1.106
At iterate    31  f =      -172.24  |proj g|=        1.1092
At iterate    32  f =      -172.25  |proj g|=        1.1125
At iterate    33  f =      -172.26  |proj g|=        1.1135
At iterate    34  f =      -172.29  |proj g|=        1.1048
At iterate    35  f =      -172.34  |proj g|=        1.0698
At iterate    36  f =      -172.43  |proj g|=       0.98601
At iterate    37  f =      -172.47  |proj g|=       0.92775
At iterate    38  f =      -172.47  |proj g|=       0.91293
At iterate    39  f =      -172.47  |proj g|=       0.91303
At iterate    40  f =      -172.48  |proj g|=       0.92016
At iterate    41  f =      -172.48  |proj g|=       0.92887
At iterate    42  f =      -172.48  |proj g|=       0.92986
At iterate    43  f =      -172.48  |proj g|=       0.93009
At iterate    44  f =      -172.48  |proj g|=       0.92998

iterations 44
function evaluations 51
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.929983
final function value -172.478

F = -172.478
final  value -172.477722 
converged
 
INFO  [23:34:20.749] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:34:20.805] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:34:20.812] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:34:27.907] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:34:35.328] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:34:43.932] [mlr3]  Finished benchmark 
INFO  [23:34:44.001] [bbotk] Result of batch 19: 
INFO  [23:34:44.002] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:34:44.002] [bbotk]              3.674446                 3.191869                       0.3886921 
INFO  [23:34:44.002] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:34:44.002] [bbotk]                     2709        0.527 -0.9693445         <NA>    0.972606 
INFO  [23:34:44.002] [bbotk]                                 uhash 
INFO  [23:34:44.002] [bbotk]  3586c774-ac45-43f4-8142-ccf4a1a5be79 
DEBUG [23:34:44.728] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.08958e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.08958e-05 0.00229484 
  - best initial criterion value(s) :  171.3345 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -171.33  |proj g|=       1.3359
At iterate     1  f =      -172.59  |proj g|=        1.3878
At iterate     2  f =       -172.6  |proj g|=        1.3827
At iterate     3  f =      -172.61  |proj g|=        1.3748
At iterate     4  f =      -172.62  |proj g|=        1.3778
At iterate     5  f =      -172.66  |proj g|=        1.4085
At iterate     6  f =      -172.67  |proj g|=         1.516
At iterate     7  f =      -172.69  |proj g|=        1.4876
At iterate     8  f =      -172.69  |proj g|=        1.4842
At iterate     9  f =      -172.69  |proj g|=        1.4846
At iterate    10  f =      -172.69  |proj g|=        1.4846
At iterate    11  f =      -172.69  |proj g|=        1.4851
At iterate    12  f =      -172.69  |proj g|=        1.4856
At iterate    13  f =      -172.69  |proj g|=        1.4864
At iterate    14  f =      -172.69  |proj g|=        1.4892
At iterate    15  f =      -172.69  |proj g|=        1.4891
At iterate    16  f =      -172.69  |proj g|=        1.4888
At iterate    17  f =      -172.69  |proj g|=        1.4886
At iterate    18  f =      -172.69  |proj g|=        1.4882
At iterate    19  f =       -172.7  |proj g|=          1.49
At iterate    20  f =      -172.71  |proj g|=         1.489
At iterate    21  f =      -172.75  |proj g|=        1.4893
At iterate    22  f =      -172.84  |proj g|=        1.4912
At iterate    23  f =      -173.03  |proj g|=        1.4392
At iterate    24  f =      -173.47  |proj g|=        1.4219
At iterate    25  f =      -173.81  |proj g|=        1.1425
At iterate    26  f =      -174.55  |proj g|=        1.0425
At iterate    27  f =       -176.2  |proj g|=       0.76027
At iterate    28  f =      -177.37  |proj g|=       0.59247
At iterate    29  f =      -178.22  |proj g|=       0.53054
At iterate    30  f =       -178.4  |proj g|=       0.54571
At iterate    31  f =      -178.41  |proj g|=       0.41869
At iterate    32  f =      -178.41  |proj g|=       0.31825
At iterate    33  f =      -178.41  |proj g|=        0.3163
At iterate    34  f =      -178.41  |proj g|=        0.3166
At iterate    35  f =      -178.41  |proj g|=       0.31663
At iterate    36  f =      -178.41  |proj g|=        0.3166

iterations 36
function evaluations 40
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.316601
final function value -178.407

F = -178.407
final  value -178.407175 
converged
 
INFO  [23:34:44.732] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:34:44.787] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:34:44.794] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:34:48.259] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:34:53.036] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:34:57.674] [mlr3]  Finished benchmark 
INFO  [23:34:57.742] [bbotk] Result of batch 20: 
INFO  [23:34:57.744] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:34:57.744] [bbotk]              4.294665                 5.930554                       0.1200751 
INFO  [23:34:57.744] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:34:57.744] [bbotk]                     1409        0.513 -0.9691343         <NA>   0.9634008 
INFO  [23:34:57.744] [bbotk]                                 uhash 
INFO  [23:34:57.744] [bbotk]  059bbc4b-b6a7-45fb-874e-2ab95997e151 
DEBUG [23:34:58.524] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.050669e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.050669e-05 0.002221003 
  - best initial criterion value(s) :  179.6592 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -179.66  |proj g|=       1.3769
At iterate     1  f =      -183.27  |proj g|=        1.3463
At iterate     2  f =      -184.47  |proj g|=        1.1104
At iterate     3  f =      -185.43  |proj g|=       0.62786
At iterate     4  f =      -185.43  |proj g|=       0.60304
At iterate     5  f =      -185.44  |proj g|=       0.61054
At iterate     6  f =      -185.44  |proj g|=       0.61471
At iterate     7  f =      -185.44  |proj g|=       0.62409
At iterate     8  f =      -185.45  |proj g|=       0.62795
At iterate     9  f =      -185.45  |proj g|=       0.62083
At iterate    10  f =      -185.45  |proj g|=       0.62292
At iterate    11  f =      -185.45  |proj g|=       0.62304
At iterate    12  f =      -185.45  |proj g|=       0.62314
At iterate    13  f =      -185.45  |proj g|=       0.62333
At iterate    14  f =      -185.45  |proj g|=       0.62372
At iterate    15  f =      -185.45  |proj g|=       0.62429
At iterate    16  f =      -185.45  |proj g|=       0.62537
At iterate    17  f =      -185.45  |proj g|=       0.62447
At iterate    18  f =      -185.45  |proj g|=       0.63319
At iterate    19  f =      -185.45  |proj g|=       0.63056
At iterate    20  f =      -185.46  |proj g|=       0.61181
At iterate    21  f =      -185.49  |proj g|=       0.59238
At iterate    22  f =      -185.56  |proj g|=       0.55582
At iterate    23  f =       -185.7  |proj g|=       0.51664
At iterate    24  f =      -185.88  |proj g|=       0.50082
At iterate    25  f =      -185.93  |proj g|=       0.55656
At iterate    26  f =      -185.99  |proj g|=        0.5319
At iterate    27  f =      -186.01  |proj g|=       0.53992
At iterate    28  f =      -186.02  |proj g|=       0.58245
At iterate    29  f =      -186.02  |proj g|=       0.56511
At iterate    30  f =      -186.03  |proj g|=       0.56462
At iterate    31  f =      -186.03  |proj g|=       0.56558
At iterate    32  f =      -186.03  |proj g|=       0.56583
At iterate    33  f =      -186.03  |proj g|=       0.56594

iterations 33
function evaluations 38
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.565936
final function value -186.025

F = -186.025
final  value -186.025150 
converged
 
INFO  [23:34:58.529] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:34:58.584] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:34:58.592] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:35:05.338] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:35:13.315] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:35:21.072] [mlr3]  Finished benchmark 
INFO  [23:35:21.143] [bbotk] Result of batch 21: 
INFO  [23:35:21.145] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:35:21.145] [bbotk]              5.799556                 4.409485                       0.1847113 
INFO  [23:35:21.145] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:35:21.145] [bbotk]                     2745        0.557 -0.9633075         <NA>   0.9728582 
INFO  [23:35:21.145] [bbotk]                                 uhash 
INFO  [23:35:21.145] [bbotk]  04cb62fb-598e-4013-a92e-a2f41c2dd1f1 
DEBUG [23:35:21.969] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.016707e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  2.016707e-05 0.002214131 
  - best initial criterion value(s) :  185.6203 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -185.62  |proj g|=       1.6591
At iterate     1  f =      -188.79  |proj g|=        1.7113
At iterate     2  f =      -190.91  |proj g|=       0.55699
At iterate     3  f =      -190.94  |proj g|=       0.59958
At iterate     4  f =      -190.94  |proj g|=       0.56547
At iterate     5  f =      -190.94  |proj g|=       0.55841
At iterate     6  f =      -190.94  |proj g|=       0.55812
At iterate     7  f =      -190.94  |proj g|=       0.55784
At iterate     8  f =      -190.94  |proj g|=       0.55731
At iterate     9  f =      -190.94  |proj g|=       0.55647
At iterate    10  f =      -190.94  |proj g|=       0.55296
At iterate    11  f =      -190.94  |proj g|=       0.55281
At iterate    12  f =      -190.94  |proj g|=        0.5524
At iterate    13  f =      -190.94  |proj g|=       0.55149
At iterate    14  f =      -190.94  |proj g|=       0.54938
At iterate    15  f =      -190.95  |proj g|=       0.54438
At iterate    16  f =      -190.96  |proj g|=       0.54756
At iterate    17  f =      -190.98  |proj g|=       0.56614
At iterate    18  f =      -191.01  |proj g|=         0.552
At iterate    19  f =      -191.31  |proj g|=       0.53955
At iterate    20  f =      -191.39  |proj g|=       0.57184
At iterate    21  f =      -191.57  |proj g|=       0.49655
At iterate    22  f =      -191.59  |proj g|=        0.4821
At iterate    23  f =      -191.59  |proj g|=       0.45455
At iterate    24  f =      -191.59  |proj g|=       0.45279
At iterate    25  f =      -191.59  |proj g|=       0.45357
At iterate    26  f =      -191.59  |proj g|=       0.45389
At iterate    27  f =      -191.59  |proj g|=       0.45402
At iterate    28  f =      -191.59  |proj g|=       0.45453
At iterate    29  f =      -191.59  |proj g|=        0.4552
At iterate    30  f =      -191.59  |proj g|=       0.45556
At iterate    31  f =      -191.59  |proj g|=        0.4557
At iterate    32  f =       -191.6  |proj g|=       0.47806
At iterate    33  f =       -191.6  |proj g|=       0.47931
At iterate    34  f =       -191.6  |proj g|=       0.47829
At iterate    35  f =       -191.6  |proj g|=       0.47698
At iterate    36  f =       -191.6  |proj g|=       0.47237
At iterate    37  f =      -191.61  |proj g|=       0.44045
At iterate    38  f =      -191.61  |proj g|=        0.4411
At iterate    39  f =      -191.61  |proj g|=       0.44066
At iterate    40  f =      -191.61  |proj g|=       0.44177
At iterate    41  f =      -191.61  |proj g|=       0.46881
At iterate    42  f =      -191.63  |proj g|=       0.46916
At iterate    43  f =      -191.68  |proj g|=       0.46838
At iterate    44  f =      -191.79  |proj g|=       0.46864
At iterate    45  f =      -191.97  |proj g|=       0.47093
At iterate    46  f =      -192.23  |proj g|=       0.47624
At iterate    47  f =      -192.42  |proj g|=       0.47725
At iterate    48  f =      -192.79  |proj g|=       0.47758
At iterate    49  f =      -192.83  |proj g|=       0.46892
At iterate    50  f =      -192.86  |proj g|=       0.47777
At iterate    51  f =      -192.86  |proj g|=       0.17826
At iterate    52  f =      -192.86  |proj g|=        0.1421
At iterate    53  f =      -192.86  |proj g|=       0.15018
At iterate    54  f =      -192.86  |proj g|=       0.15355
At iterate    55  f =      -192.86  |proj g|=       0.15561
At iterate    56  f =      -192.86  |proj g|=       0.14933
At iterate    57  f =      -192.86  |proj g|=     0.0014405
At iterate    58  f =      -192.86  |proj g|=     0.0014405

iterations 58
function evaluations 74
segments explored during Cauchy searches 60
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00144047
final function value -192.862

F = -192.862
final  value -192.862467 
converged
 
INFO  [23:35:21.973] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:35:22.028] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:35:22.035] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:35:33.428] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:35:45.754] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:35:59.855] [mlr3]  Finished benchmark 
INFO  [23:35:59.926] [bbotk] Result of batch 22: 
INFO  [23:35:59.928] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:35:59.928] [bbotk]              7.296963                 9.765666                         0.37564 
INFO  [23:35:59.928] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:35:59.928] [bbotk]                     4181        0.527 -0.9604241         <NA>   0.9764055 
INFO  [23:35:59.928] [bbotk]                                 uhash 
INFO  [23:35:59.928] [bbotk]  91ece1b8-1ec6-4324-b519-2e666f54414d 
DEBUG [23:36:00.683] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.993676e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  1.993676e-05 0.002231326 
  - best initial criterion value(s) :  183.0333 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -183.03  |proj g|=       0.7351
At iterate     1  f =       -184.3  |proj g|=        1.9579
At iterate     2  f =      -184.92  |proj g|=        1.8231
At iterate     3  f =      -185.81  |proj g|=        1.4718
At iterate     4  f =      -186.03  |proj g|=        1.3481
At iterate     5  f =      -186.35  |proj g|=        1.4143
At iterate     6  f =      -186.48  |proj g|=        1.6176
At iterate     7  f =       -186.6  |proj g|=         1.602
At iterate     8  f =      -186.61  |proj g|=        1.6008
At iterate     9  f =      -186.61  |proj g|=        1.6044
At iterate    10  f =      -186.61  |proj g|=        1.6053
At iterate    11  f =      -186.61  |proj g|=        1.6055

iterations 11
function evaluations 16
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.60548
final function value -186.614

F = -186.614
final  value -186.614489 
converged
 
INFO  [23:36:00.687] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:36:00.744] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:36:00.751] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:36:08.459] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:36:16.042] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:36:23.341] [mlr3]  Finished benchmark 
INFO  [23:36:23.407] [bbotk] Result of batch 23: 
INFO  [23:36:23.408] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:36:23.408] [bbotk]              5.450225                 7.454505                       0.4014732 
INFO  [23:36:23.408] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:36:23.408] [bbotk]                     2627        0.559 -0.9692553         <NA>    0.975287 
INFO  [23:36:23.408] [bbotk]                                 uhash 
INFO  [23:36:23.408] [bbotk]  2189dec3-90bc-46f8-b01b-62ff3c3bcded 
DEBUG [23:36:24.216] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.967461e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9454 
  - variance bounds :  1.96746e-05 0.002232323 
  - best initial criterion value(s) :  189.7116 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -189.71  |proj g|=       4.0236
At iterate     1  f =      -192.47  |proj g|=        5.5702
At iterate     2  f =       -193.2  |proj g|=        4.9162
At iterate     3  f =      -194.04  |proj g|=        3.4929
At iterate     4  f =       -194.8  |proj g|=        3.1745
At iterate     5  f =      -195.14  |proj g|=        2.7083
At iterate     6  f =      -195.15  |proj g|=        2.8543
At iterate     7  f =      -195.15  |proj g|=         2.852
At iterate     8  f =      -195.15  |proj g|=         2.852
At iterate     9  f =      -195.15  |proj g|=         2.852
At iterate    10  f =      -195.15  |proj g|=        2.8519
At iterate    11  f =      -195.15  |proj g|=        2.8518
At iterate    12  f =      -195.15  |proj g|=         2.851
At iterate    13  f =      -195.15  |proj g|=        2.8451
At iterate    14  f =      -195.15  |proj g|=        2.8266
At iterate    15  f =      -195.16  |proj g|=        2.7891
At iterate    16  f =      -195.18  |proj g|=        2.7234
At iterate    17  f =      -195.22  |proj g|=        2.5661
At iterate    18  f =      -195.23  |proj g|=        2.6302
At iterate    19  f =      -195.32  |proj g|=        2.4192
At iterate    20  f =      -195.66  |proj g|=        1.9045
At iterate    21  f =      -196.51  |proj g|=        1.1254
At iterate    22  f =      -198.18  |proj g|=       0.69843
At iterate    23  f =       -199.8  |proj g|=        0.6553
At iterate    24  f =       -199.8  |proj g|=        0.6566
At iterate    25  f =      -200.68  |proj g|=        0.6101
At iterate    26  f =      -200.96  |proj g|=       0.59401
At iterate    27  f =      -201.33  |proj g|=       0.54999
At iterate    28  f =      -201.41  |proj g|=       0.32665
At iterate    29  f =      -201.42  |proj g|=       0.43111
At iterate    30  f =      -201.42  |proj g|=       0.34008
At iterate    31  f =      -201.42  |proj g|=       0.34151
At iterate    32  f =      -201.42  |proj g|=       0.34186
At iterate    33  f =      -201.42  |proj g|=       0.34181

iterations 33
function evaluations 44
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.341813
final function value -201.423

F = -201.423
final  value -201.423314 
converged
 
INFO  [23:36:24.220] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:36:24.276] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:36:24.283] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:36:38.343] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:36:53.933] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:37:09.349] [mlr3]  Finished benchmark 
INFO  [23:37:09.437] [bbotk] Result of batch 24: 
INFO  [23:37:09.439] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:37:09.439] [bbotk]              7.693669                 3.940974                       0.4563975 
INFO  [23:37:09.439] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:37:09.439] [bbotk]                     4997        0.568 -0.9610655         <NA>   0.9774298 
INFO  [23:37:09.439] [bbotk]                                 uhash 
INFO  [23:37:09.439] [bbotk]  3400b091-c42a-48c8-9e8a-60f87a2a963a 
DEBUG [23:37:10.395] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.948644e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.948644e-05 0.002252787 
  - best initial criterion value(s) :  196.5085 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -196.51  |proj g|=      0.82765
At iterate     1  f =      -200.54  |proj g|=        3.3507
At iterate     2  f =       -201.8  |proj g|=        3.0043
At iterate     3  f =      -202.94  |proj g|=        2.2147
At iterate     4  f =      -202.98  |proj g|=         1.977
At iterate     5  f =         -203  |proj g|=        2.0378
At iterate     6  f =      -203.08  |proj g|=        2.1404
At iterate     7  f =      -203.14  |proj g|=        2.1299
At iterate     8  f =      -203.15  |proj g|=        2.0354
At iterate     9  f =      -203.15  |proj g|=        2.0259
At iterate    10  f =      -203.15  |proj g|=        2.0286
At iterate    11  f =      -203.15  |proj g|=        2.0282
At iterate    12  f =      -203.15  |proj g|=        2.0258
At iterate    13  f =      -203.15  |proj g|=        2.0224
At iterate    14  f =      -203.15  |proj g|=        2.0179
At iterate    15  f =      -203.15  |proj g|=        2.0096
At iterate    16  f =      -203.15  |proj g|=         1.997
At iterate    17  f =      -203.16  |proj g|=        1.9768
At iterate    18  f =      -203.18  |proj g|=        1.9536
At iterate    19  f =      -203.18  |proj g|=        1.9104
At iterate    20  f =      -203.22  |proj g|=        1.8657
At iterate    21  f =      -203.83  |proj g|=        1.4994
At iterate    22  f =      -204.81  |proj g|=       0.82174
At iterate    23  f =      -205.53  |proj g|=       0.41415
At iterate    24  f =      -205.69  |proj g|=       0.42514
At iterate    25  f =      -205.69  |proj g|=       0.36815
At iterate    26  f =      -205.72  |proj g|=       0.36204
At iterate    27  f =      -205.72  |proj g|=       0.36154
At iterate    28  f =      -205.72  |proj g|=        0.3617
At iterate    29  f =      -205.72  |proj g|=       0.36174

iterations 29
function evaluations 40
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.361737
final function value -205.719

F = -205.719
final  value -205.719133 
converged
 
INFO  [23:37:10.400] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:37:10.454] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:37:10.461] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:37:12.075] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:37:13.877] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:37:15.800] [mlr3]  Finished benchmark 
INFO  [23:37:15.866] [bbotk] Result of batch 25: 
INFO  [23:37:15.868] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:37:15.868] [bbotk]              3.231087                 4.844751                       0.1537896 
INFO  [23:37:15.868] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:37:15.868] [bbotk]                      500        0.534 -0.9606898         <NA>    0.948609 
INFO  [23:37:15.868] [bbotk]                                 uhash 
INFO  [23:37:15.868] [bbotk]  0b31943a-a963-4131-b734-87e020db1fa5 
DEBUG [23:37:16.572] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.978741e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.978741e-05 0.002287192 
  - best initial criterion value(s) :  186.5996 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -186.6  |proj g|=       2.9429
At iterate     1  f =      -197.22  |proj g|=        2.3983
At iterate     2  f =       -197.5  |proj g|=        2.2963
At iterate     3  f =      -197.91  |proj g|=         1.634
At iterate     4  f =      -198.06  |proj g|=        1.9178
At iterate     5  f =      -198.26  |proj g|=         1.805
At iterate     6  f =       -198.9  |proj g|=        1.5771
At iterate     7  f =       -199.5  |proj g|=        1.5205
At iterate     8  f =      -199.85  |proj g|=        1.6289
At iterate     9  f =      -199.95  |proj g|=         1.692
At iterate    10  f =      -199.97  |proj g|=        1.7403
At iterate    11  f =      -199.98  |proj g|=        1.7558
At iterate    12  f =      -199.98  |proj g|=        1.7576
At iterate    13  f =      -199.98  |proj g|=        1.7583

iterations 13
function evaluations 17
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.75833
final function value -199.975

F = -199.975
final  value -199.975470 
converged
 
INFO  [23:37:16.576] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:37:16.631] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:37:16.638] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:37:28.790] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:37:41.400] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:37:55.211] [mlr3]  Finished benchmark 
INFO  [23:37:55.279] [bbotk] Result of batch 26: 
INFO  [23:37:55.281] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:37:55.281] [bbotk]               8.24933                 8.280751                       0.1763121 
INFO  [23:37:55.281] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:37:55.281] [bbotk]                     4461         0.51 -0.9661811         <NA>    0.974666 
INFO  [23:37:55.281] [bbotk]                                 uhash 
INFO  [23:37:55.281] [bbotk]  3a0f7a85-0dae-4dd1-bea6-9ae770a9dbe9 
DEBUG [23:37:56.033] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.952611e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.952611e-05 0.002281581 
  - best initial criterion value(s) :  200.9145 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -200.91  |proj g|=       1.8056
At iterate     1  f =      -202.97  |proj g|=        4.7983
At iterate     2  f =       -205.9  |proj g|=        4.3651
At iterate     3  f =      -210.19  |proj g|=        2.9363
At iterate     4  f =      -210.45  |proj g|=        2.4357
At iterate     5  f =      -210.73  |proj g|=        2.1936
At iterate     6  f =      -211.25  |proj g|=        1.9905
At iterate     7  f =      -211.38  |proj g|=        2.0061
At iterate     8  f =      -211.41  |proj g|=        1.9973
At iterate     9  f =      -211.41  |proj g|=        2.0012
At iterate    10  f =      -211.41  |proj g|=        2.0117
At iterate    11  f =      -211.41  |proj g|=         2.008
At iterate    12  f =      -211.41  |proj g|=        2.0063
At iterate    13  f =      -211.41  |proj g|=        2.0009
At iterate    14  f =      -211.41  |proj g|=        1.9916
At iterate    15  f =      -211.41  |proj g|=        1.9775
At iterate    16  f =      -211.42  |proj g|=        1.9541
At iterate    17  f =      -211.43  |proj g|=         1.916
At iterate    18  f =      -211.46  |proj g|=        1.8618
At iterate    19  f =      -211.52  |proj g|=         1.805
At iterate    20  f =      -211.63  |proj g|=        1.7864
At iterate    21  f =      -211.65  |proj g|=        1.6404
At iterate    22  f =      -211.88  |proj g|=        1.5101
At iterate    23  f =      -213.02  |proj g|=       0.85139
At iterate    24  f =      -213.77  |proj g|=       0.63839
At iterate    25  f =      -214.07  |proj g|=       0.49704
At iterate    26  f =      -214.19  |proj g|=       0.34395
At iterate    27  f =       -214.2  |proj g|=       0.33428
At iterate    28  f =      -214.21  |proj g|=       0.32531
At iterate    29  f =      -214.21  |proj g|=       0.32771
At iterate    30  f =      -214.21  |proj g|=       0.32757
At iterate    31  f =      -214.21  |proj g|=       0.32814
At iterate    32  f =      -214.21  |proj g|=       0.32802

iterations 32
function evaluations 45
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.328019
final function value -214.209

F = -214.209
final  value -214.209335 
converged
 
INFO  [23:37:56.038] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:37:56.093] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:37:56.100] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:38:06.256] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:38:15.355] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:38:24.310] [mlr3]  Finished benchmark 
INFO  [23:38:24.377] [bbotk] Result of batch 27: 
INFO  [23:38:24.379] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:38:24.379] [bbotk]              3.889711                 4.213122                       0.3291948 
INFO  [23:38:24.379] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:38:24.379] [bbotk]                     3349        0.516 -0.9596156         <NA>   0.9733015 
INFO  [23:38:24.379] [bbotk]                                 uhash 
INFO  [23:38:24.379] [bbotk]  61519570-056a-4770-8fcc-b9e4740e4d56 
DEBUG [23:38:25.093] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.924058e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.924058e-05 0.002280004 
  - best initial criterion value(s) :  205.5344 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -205.53  |proj g|=       1.4661
At iterate     1  f =       -207.6  |proj g|=         2.236
At iterate     2  f =      -209.88  |proj g|=        2.0498
At iterate     3  f =      -212.46  |proj g|=         1.349
At iterate     4  f =      -212.47  |proj g|=        1.2994
At iterate     5  f =       -212.5  |proj g|=        1.2994
At iterate     6  f =      -212.57  |proj g|=        1.3688
At iterate     7  f =      -212.58  |proj g|=        1.3603
At iterate     8  f =      -212.58  |proj g|=        1.3582
At iterate     9  f =      -212.58  |proj g|=        1.3581

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.35808
final function value -212.576

F = -212.576
final  value -212.575603 
converged
 
INFO  [23:38:25.097] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:38:25.154] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:38:25.161] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:38:31.661] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:38:38.153] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:38:43.028] [mlr3]  Finished benchmark 
INFO  [23:38:43.106] [bbotk] Result of batch 28: 
INFO  [23:38:43.108] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:38:43.108] [bbotk]              2.493728                 8.807273                       0.1425775 
INFO  [23:38:43.108] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:38:43.108] [bbotk]                     2360        0.524 -0.9640532         <NA>   0.9562578 
INFO  [23:38:43.108] [bbotk]                                 uhash 
INFO  [23:38:43.108] [bbotk]  11c6745b-af8f-4a76-ab00-bea73e8abe87 
DEBUG [23:38:43.877] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.912878e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.912878e-05 0.002239281 
  - best initial criterion value(s) :  204.6195 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -204.62  |proj g|=       4.1613
At iterate     1  f =      -205.79  |proj g|=        4.9109
At iterate     2  f =       -206.8  |proj g|=        4.6827
At iterate     3  f =      -208.74  |proj g|=        3.7453
At iterate     4  f =      -209.38  |proj g|=        3.3411
At iterate     5  f =      -210.16  |proj g|=        2.9285
At iterate     6  f =      -210.21  |proj g|=        2.7464
At iterate     7  f =      -210.22  |proj g|=        2.7093
At iterate     8  f =      -210.22  |proj g|=        2.7103
At iterate     9  f =      -210.22  |proj g|=        2.7125
At iterate    10  f =      -210.22  |proj g|=        2.7128
At iterate    11  f =      -210.22  |proj g|=        2.7142
At iterate    12  f =      -210.22  |proj g|=        2.7158
At iterate    13  f =      -210.22  |proj g|=        2.7189
At iterate    14  f =      -210.22  |proj g|=        2.7236
At iterate    15  f =      -210.22  |proj g|=        2.7315
At iterate    16  f =      -210.22  |proj g|=        2.7443
At iterate    17  f =      -210.22  |proj g|=        2.7655
At iterate    18  f =      -210.23  |proj g|=        2.7998
At iterate    19  f =      -210.26  |proj g|=        2.8543
At iterate    20  f =      -210.33  |proj g|=        2.9341
At iterate    21  f =      -210.47  |proj g|=        3.0256
At iterate    22  f =      -210.73  |proj g|=        3.0441
At iterate    23  f =      -210.99  |proj g|=        2.7588
At iterate    24  f =      -210.99  |proj g|=        2.7224
At iterate    25  f =      -210.99  |proj g|=        2.7325
At iterate    26  f =      -210.99  |proj g|=        2.7325
At iterate    27  f =      -210.99  |proj g|=        2.7294
At iterate    28  f =      -210.99  |proj g|=         2.724
At iterate    29  f =         -211  |proj g|=        2.7177
At iterate    30  f =         -211  |proj g|=        2.6957
At iterate    31  f =      -211.01  |proj g|=        2.6645
At iterate    32  f =      -211.03  |proj g|=        2.6042
At iterate    33  f =       -211.1  |proj g|=        2.5045
At iterate    34  f =      -211.25  |proj g|=        2.3404
At iterate    35  f =      -211.59  |proj g|=        2.0308
At iterate    36  f =      -212.45  |proj g|=        1.6363
At iterate    37  f =      -213.08  |proj g|=       0.86242
At iterate    38  f =      -215.09  |proj g|=       0.73557
At iterate    39  f =      -218.05  |proj g|=       0.62392
At iterate    40  f =      -219.98  |proj g|=       0.98917
At iterate    41  f =      -220.18  |proj g|=        1.0883
At iterate    42  f =       -220.2  |proj g|=        1.0449
At iterate    43  f =      -220.21  |proj g|=       0.95923
At iterate    44  f =      -220.22  |proj g|=       0.92565
At iterate    45  f =      -220.22  |proj g|=       0.87828
At iterate    46  f =      -220.22  |proj g|=       0.88022
At iterate    47  f =      -220.22  |proj g|=        0.8827
At iterate    48  f =      -220.22  |proj g|=       0.88272

iterations 48
function evaluations 55
segments explored during Cauchy searches 50
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.882717
final function value -220.225

F = -220.225
final  value -220.224813 
converged
 
INFO  [23:38:43.882] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:38:43.944] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:38:43.953] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:38:46.443] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:38:48.785] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:38:51.180] [mlr3]  Finished benchmark 
INFO  [23:38:51.260] [bbotk] Result of batch 29: 
INFO  [23:38:51.262] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:38:51.262] [bbotk]              7.250383                 4.947886                       0.3629673 
INFO  [23:38:51.262] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:38:51.262] [bbotk]                     1075        0.524 -0.9631343         <NA>   0.9718847 
INFO  [23:38:51.262] [bbotk]                                 uhash 
INFO  [23:38:51.262] [bbotk]  3f100ad3-4fad-4389-9747-d5d0d92dbeb2 
DEBUG [23:38:52.111] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.883725e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.883725e-05 0.002165355 
  - best initial criterion value(s) :  205.1146 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -205.11  |proj g|=       1.2719
At iterate     1  f =      -205.83  |proj g|=        1.0893
At iterate     2  f =      -210.78  |proj g|=       0.94676
At iterate     3  f =      -212.81  |proj g|=       0.89831
At iterate     4  f =      -213.51  |proj g|=       0.80478
At iterate     5  f =      -216.13  |proj g|=        0.7937
At iterate     6  f =      -216.42  |proj g|=       0.48398
At iterate     7  f =      -216.42  |proj g|=       0.48504
At iterate     8  f =      -216.42  |proj g|=        0.4875
At iterate     9  f =      -216.42  |proj g|=       0.48845
At iterate    10  f =      -216.42  |proj g|=        0.4883
At iterate    11  f =      -216.42  |proj g|=       0.48697
At iterate    12  f =      -216.42  |proj g|=       0.48531
At iterate    13  f =      -216.42  |proj g|=       0.48232
At iterate    14  f =      -216.42  |proj g|=       0.47766
At iterate    15  f =      -216.42  |proj g|=       0.47034
At iterate    16  f =      -216.42  |proj g|=       0.46006
At iterate    17  f =      -216.43  |proj g|=       0.44527
At iterate    18  f =      -216.44  |proj g|=       0.42629
At iterate    19  f =      -216.44  |proj g|=       0.40718
At iterate    20  f =      -216.47  |proj g|=       0.41679
At iterate    21  f =      -216.58  |proj g|=        0.4355
At iterate    22  f =      -216.83  |proj g|=       0.45016
At iterate    23  f =      -217.46  |proj g|=        0.4322
At iterate    24  f =      -218.02  |proj g|=       0.36538
At iterate    25  f =      -218.19  |proj g|=       0.66128
At iterate    26  f =      -218.26  |proj g|=       0.29202
At iterate    27  f =      -218.32  |proj g|=       0.31268
At iterate    28  f =      -218.34  |proj g|=       0.40174
At iterate    29  f =      -218.34  |proj g|=       0.23271
At iterate    30  f =      -218.34  |proj g|=       0.17036
At iterate    31  f =      -218.34  |proj g|=       0.17031

iterations 31
function evaluations 41
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.170314
final function value -218.336

F = -218.336
final  value -218.335612 
converged
 
INFO  [23:38:52.116] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:38:52.178] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:38:52.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:38:56.543] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:39:00.773] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:39:04.919] [mlr3]  Finished benchmark 
INFO  [23:39:04.987] [bbotk] Result of batch 30: 
INFO  [23:39:04.989] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:39:04.989] [bbotk]              5.829983                 8.814078                       0.2610202 
INFO  [23:39:04.989] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:39:04.989] [bbotk]                     2108         0.59 -0.9669724         <NA>   0.9731921 
INFO  [23:39:04.989] [bbotk]                                 uhash 
INFO  [23:39:04.989] [bbotk]  85488272-751a-4427-b4df-7d8ec32b4691 
DEBUG [23:39:05.819] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.857586e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.857586e-05 0.002113479 
  - best initial criterion value(s) :  221.9394 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -221.94  |proj g|=       1.0141
At iterate     1  f =      -223.86  |proj g|=        3.2496
At iterate     2  f =      -224.62  |proj g|=         2.981
At iterate     3  f =      -224.84  |proj g|=         2.389
At iterate     4  f =      -224.92  |proj g|=        2.6617
At iterate     5  f =      -224.92  |proj g|=        2.6233
At iterate     6  f =      -224.92  |proj g|=        2.6184
At iterate     7  f =      -224.92  |proj g|=        2.6189
At iterate     8  f =      -224.93  |proj g|=        2.6392
At iterate     9  f =      -224.93  |proj g|=        2.6638
At iterate    10  f =      -224.93  |proj g|=        2.6641
At iterate    11  f =      -224.93  |proj g|=        2.6645
At iterate    12  f =      -224.93  |proj g|=        2.6679
At iterate    13  f =      -224.93  |proj g|=        2.6704
At iterate    14  f =      -224.93  |proj g|=        2.6751
At iterate    15  f =      -224.93  |proj g|=        2.6781
At iterate    16  f =      -224.93  |proj g|=         2.684
At iterate    17  f =      -224.94  |proj g|=         2.698
At iterate    18  f =      -224.97  |proj g|=        2.7114
At iterate    19  f =      -225.07  |proj g|=        2.7101
At iterate    20  f =       -225.1  |proj g|=        2.5624
At iterate    21  f =      -225.33  |proj g|=        2.5316
At iterate    22  f =      -225.81  |proj g|=        2.3345
At iterate    23  f =      -226.55  |proj g|=        2.0255
At iterate    24  f =      -227.46  |proj g|=        1.7336
At iterate    25  f =      -228.31  |proj g|=        1.7236
At iterate    26  f =      -228.55  |proj g|=        1.6661
At iterate    27  f =      -228.98  |proj g|=        1.9801
At iterate    28  f =      -229.12  |proj g|=        1.7862
At iterate    29  f =      -229.13  |proj g|=        1.6926
At iterate    30  f =      -229.13  |proj g|=         1.685
At iterate    31  f =      -229.13  |proj g|=        1.6726
At iterate    32  f =      -229.13  |proj g|=        1.6722
At iterate    33  f =      -229.13  |proj g|=         1.671
At iterate    34  f =      -229.13  |proj g|=        1.6693
At iterate    35  f =      -229.13  |proj g|=        1.6664
At iterate    36  f =      -229.13  |proj g|=        1.6647
At iterate    37  f =      -229.13  |proj g|=        1.6558
At iterate    38  f =      -229.13  |proj g|=        1.6565
At iterate    39  f =      -229.15  |proj g|=        1.6568
At iterate    40  f =      -230.25  |proj g|=       0.99483
At iterate    41  f =      -232.14  |proj g|=       0.68317
At iterate    42  f =      -234.36  |proj g|=       0.43725
At iterate    43  f =      -234.68  |proj g|=       0.53638
At iterate    44  f =      -235.59  |proj g|=       0.47827
At iterate    45  f =      -235.68  |proj g|=       0.47366
At iterate    46  f =      -235.78  |proj g|=       0.48668
At iterate    47  f =      -235.79  |proj g|=       0.48517
At iterate    48  f =      -235.79  |proj g|=       0.48529
At iterate    49  f =      -235.79  |proj g|=       0.48542
At iterate    50  f =      -235.79  |proj g|=       0.48533
At iterate    51  f =      -235.79  |proj g|=        0.4847
At iterate    52  f =      -235.79  |proj g|=        0.4409
At iterate    53  f =       -235.8  |proj g|=      0.028555
At iterate    54  f =       -235.8  |proj g|=      0.080223
At iterate    55  f =       -235.8  |proj g|=       0.20161
At iterate    56  f =       -235.8  |proj g|=       0.27359
At iterate    57  f =       -235.8  |proj g|=       0.14167
At iterate    58  f =       -235.8  |proj g|=       0.01072
At iterate    59  f =       -235.8  |proj g|=     0.0010427
At iterate    60  f =       -235.8  |proj g|=     0.0010426

iterations 60
function evaluations 68
segments explored during Cauchy searches 62
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00104264
final function value -235.8

F = -235.8
final  value -235.800020 
converged
 
INFO  [23:39:05.823] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:39:05.881] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:39:05.888] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:39:14.140] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:39:21.910] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:39:29.755] [mlr3]  Finished benchmark 
INFO  [23:39:29.822] [bbotk] Result of batch 31: 
INFO  [23:39:29.824] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:39:29.824] [bbotk]               2.85152                 9.084825                       0.2486683 
INFO  [23:39:29.824] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:39:29.824] [bbotk]                     3857         0.53 -0.9559608         <NA>   0.9688668 
INFO  [23:39:29.824] [bbotk]                                 uhash 
INFO  [23:39:29.824] [bbotk]  cc96ef85-d407-4b22-945c-4bcbce3be017 
DEBUG [23:39:30.536] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.827383e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.827383e-05 0.002100876 
  - best initial criterion value(s) :  227.3644 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -227.36  |proj g|=       3.1426
At iterate     1  f =      -234.35  |proj g|=        2.6676
At iterate     2  f =      -236.94  |proj g|=        1.2159
At iterate     3  f =      -237.28  |proj g|=       0.86194
At iterate     4  f =      -237.29  |proj g|=       0.75467
At iterate     5  f =      -237.29  |proj g|=       0.80401
At iterate     6  f =      -237.29  |proj g|=       0.79132
At iterate     7  f =      -237.29  |proj g|=       0.79089
At iterate     8  f =      -237.29  |proj g|=       0.79113

iterations 8
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.791133
final function value -237.289

F = -237.289
final  value -237.288519 
converged
 
INFO  [23:39:30.541] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:39:30.603] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:39:30.611] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:39:32.931] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:39:35.322] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:39:37.608] [mlr3]  Finished benchmark 
INFO  [23:39:37.677] [bbotk] Result of batch 32: 
INFO  [23:39:37.679] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:39:37.679] [bbotk]              5.539778                 5.077414                       0.1466637 
INFO  [23:39:37.679] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:39:37.679] [bbotk]                     1080        0.536 -0.9608856         <NA>   0.9653453 
INFO  [23:39:37.679] [bbotk]                                 uhash 
INFO  [23:39:37.679] [bbotk]  003dc2f2-5767-42c8-a40f-f4fa5eaf7fae 
DEBUG [23:39:38.493] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.798747e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.798747e-05 0.00204537 
  - best initial criterion value(s) :  233.8422 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -233.84  |proj g|=      0.91685
At iterate     1  f =      -234.56  |proj g|=        1.5854
At iterate     2  f =      -234.56  |proj g|=        1.5573
At iterate     3  f =      -234.57  |proj g|=        1.5385
At iterate     4  f =      -234.57  |proj g|=        1.5302
At iterate     5  f =      -234.59  |proj g|=        1.5389
At iterate     6  f =      -234.61  |proj g|=        1.5954
At iterate     7  f =      -234.62  |proj g|=        1.6812
At iterate     8  f =      -234.62  |proj g|=        1.7149
At iterate     9  f =      -234.62  |proj g|=        1.7175
At iterate    10  f =      -234.62  |proj g|=        1.7189
At iterate    11  f =      -234.62  |proj g|=        1.7216
At iterate    12  f =      -234.62  |proj g|=        1.7254
At iterate    13  f =      -234.62  |proj g|=        1.7225
At iterate    14  f =      -234.62  |proj g|=         1.731
At iterate    15  f =      -234.62  |proj g|=        1.7458
At iterate    16  f =      -234.63  |proj g|=          1.77
At iterate    17  f =      -234.63  |proj g|=        1.8049
At iterate    18  f =      -234.66  |proj g|=        1.8532
At iterate    19  f =      -234.71  |proj g|=        1.9017
At iterate    20  f =      -234.81  |proj g|=        1.9985
At iterate    21  f =      -235.01  |proj g|=        1.9425
At iterate    22  f =      -235.18  |proj g|=        1.8724
At iterate    23  f =      -235.88  |proj g|=        1.4973
At iterate    24  f =      -236.58  |proj g|=       0.95142
At iterate    25  f =      -237.32  |proj g|=       0.69545
At iterate    26  f =      -238.12  |proj g|=       0.53786
At iterate    27  f =      -238.17  |proj g|=       0.52663
At iterate    28  f =      -238.18  |proj g|=       0.52126
At iterate    29  f =      -238.18  |proj g|=       0.50876
At iterate    30  f =      -238.18  |proj g|=       0.50135
At iterate    31  f =      -238.18  |proj g|=       0.50123

iterations 31
function evaluations 39
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.501233
final function value -238.178

F = -238.178
final  value -238.177737 
converged
 
INFO  [23:39:38.497] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:39:38.554] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:39:38.561] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:39:42.395] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:39:46.174] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:39:49.926] [mlr3]  Finished benchmark 
INFO  [23:39:49.995] [bbotk] Result of batch 33: 
INFO  [23:39:49.997] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:39:49.997] [bbotk]              6.093153                 8.121677                       0.2580556 
INFO  [23:39:49.997] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:39:49.997] [bbotk]                     2014        0.549 -0.9621569         <NA>   0.9729927 
INFO  [23:39:49.997] [bbotk]                                 uhash 
INFO  [23:39:49.997] [bbotk]  2d94eaee-d3b5-40a6-b360-cec25c1d7166 
DEBUG [23:39:50.751] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.774729e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.774729e-05 0.002022582 
  - best initial criterion value(s) :  237.1105 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -237.11  |proj g|=      0.47119
At iterate     1  f =      -237.55  |proj g|=        2.1745
At iterate     2  f =      -238.73  |proj g|=        1.8593
At iterate     3  f =      -239.19  |proj g|=        1.5496
At iterate     4  f =      -239.27  |proj g|=        1.3306
At iterate     5  f =      -239.52  |proj g|=        1.2884
At iterate     6  f =      -239.74  |proj g|=        1.0282
At iterate     7  f =      -239.77  |proj g|=        1.0768
At iterate     8  f =      -239.77  |proj g|=        1.0571
At iterate     9  f =      -239.77  |proj g|=        1.0577
At iterate    10  f =      -239.77  |proj g|=        1.0574
At iterate    11  f =      -239.77  |proj g|=        1.0574

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.05744
final function value -239.77

F = -239.77
final  value -239.769513 
converged
 
INFO  [23:39:50.755] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:39:50.810] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:39:50.817] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:39:57.881] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:40:09.028] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:40:18.357] [mlr3]  Finished benchmark 
INFO  [23:40:18.424] [bbotk] Result of batch 34: 
INFO  [23:40:18.426] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:40:18.426] [bbotk]              2.765781                 9.325996                         0.36189 
INFO  [23:40:18.426] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:40:18.426] [bbotk]                     3356        0.551 -0.9652006         <NA>   0.9694811 
INFO  [23:40:18.426] [bbotk]                                 uhash 
INFO  [23:40:18.426] [bbotk]  731e9629-a600-4d7b-86f4-ac54c8485363 
DEBUG [23:40:19.234] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.747492e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.747492e-05 0.002013496 
  - best initial criterion value(s) :  238.1285 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -238.13  |proj g|=      0.80373
At iterate     1  f =      -240.67  |proj g|=        3.8855
At iterate     2  f =      -248.32  |proj g|=        2.9387
At iterate     3  f =      -249.43  |proj g|=         2.016
At iterate     4  f =      -250.96  |proj g|=        2.2583
At iterate     5  f =      -251.83  |proj g|=        2.0053
At iterate     6  f =      -251.88  |proj g|=         2.479
At iterate     7  f =      -251.95  |proj g|=        2.2584
At iterate     8  f =      -251.95  |proj g|=        2.2292
At iterate     9  f =      -251.95  |proj g|=        2.2338
At iterate    10  f =      -251.95  |proj g|=        2.2342

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.23419
final function value -251.952

F = -251.952
final  value -251.952246 
converged
 
INFO  [23:40:19.238] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:40:19.297] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:40:19.304] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:40:28.926] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:40:38.769] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:40:49.595] [mlr3]  Finished benchmark 
INFO  [23:40:49.665] [bbotk] Result of batch 35: 
INFO  [23:40:49.667] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:40:49.667] [bbotk]              6.192041                   3.4295                       0.2465971 
INFO  [23:40:49.667] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:40:49.667] [bbotk]                     3391        0.584 -0.9598699         <NA>    0.974556 
INFO  [23:40:49.667] [bbotk]                                 uhash 
INFO  [23:40:49.667] [bbotk]  9fc97bd8-f54a-44b5-96e3-8c7970f57275 
DEBUG [23:40:50.513] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.727692e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.727692e-05 0.002014438 
  - best initial criterion value(s) :  236.8982 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -236.9  |proj g|=       6.7569
At iterate     1  f =      -237.31  |proj g|=        6.5194
At iterate     2  f =      -242.99  |proj g|=        4.6392
At iterate     3  f =      -244.43  |proj g|=        3.1925
At iterate     4  f =      -246.94  |proj g|=        1.1602
At iterate     5  f =      -246.97  |proj g|=         1.169
At iterate     6  f =      -246.97  |proj g|=         1.152
At iterate     7  f =      -246.97  |proj g|=        1.1533
At iterate     8  f =      -246.97  |proj g|=        1.1536
At iterate     9  f =      -246.97  |proj g|=        1.1553
At iterate    10  f =      -246.97  |proj g|=        1.1572
At iterate    11  f =      -246.97  |proj g|=        1.1607
At iterate    12  f =      -246.97  |proj g|=        1.1661
At iterate    13  f =      -246.97  |proj g|=        1.1751
At iterate    14  f =      -246.97  |proj g|=        1.1906
At iterate    15  f =      -246.98  |proj g|=        1.2183
At iterate    16  f =      -246.98  |proj g|=        1.2653
At iterate    17  f =      -246.99  |proj g|=        1.3286
At iterate    18  f =      -246.99  |proj g|=        1.3272
At iterate    19  f =         -247  |proj g|=        1.3432
At iterate    20  f =         -247  |proj g|=         1.347
At iterate    21  f =      -247.01  |proj g|=        1.3575
At iterate    22  f =      -247.03  |proj g|=        1.3555
At iterate    23  f =       -247.1  |proj g|=        1.3049
At iterate    24  f =      -247.23  |proj g|=        1.1454
At iterate    25  f =      -247.47  |proj g|=       0.78829
At iterate    26  f =      -247.47  |proj g|=       0.82881
At iterate    27  f =      -247.75  |proj g|=       0.71274
At iterate    28  f =      -248.91  |proj g|=       0.32594
At iterate    29  f =      -248.98  |proj g|=       0.22366
At iterate    30  f =         -249  |proj g|=       0.15384
At iterate    31  f =         -249  |proj g|=       0.11099
At iterate    32  f =         -249  |proj g|=       0.11085
At iterate    33  f =         -249  |proj g|=       0.11062
At iterate    34  f =         -249  |proj g|=        0.1106
At iterate    35  f =         -249  |proj g|=       0.11061

iterations 35
function evaluations 42
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.110614
final function value -249.005

F = -249.005
final  value -249.004635 
converged
 
INFO  [23:40:50.517] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:40:50.574] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:40:50.582] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:41:02.661] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:41:15.696] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:41:27.717] [mlr3]  Finished benchmark 
INFO  [23:41:27.787] [bbotk] Result of batch 36: 
INFO  [23:41:27.789] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:41:27.789] [bbotk]              6.151486                 6.762174                       0.3361601 
INFO  [23:41:27.789] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:41:27.789] [bbotk]                     4007        0.586 -0.9654238         <NA>    0.975854 
INFO  [23:41:27.789] [bbotk]                                 uhash 
INFO  [23:41:27.789] [bbotk]  56e6db76-57d5-46ad-9732-1c88173ec096 
DEBUG [23:41:28.638] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.711144e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.711144e-05 0.002021501 
  - best initial criterion value(s) :  240.4718 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -240.47  |proj g|=       2.3436
At iterate     1  f =      -248.58  |proj g|=        4.2184
At iterate     2  f =      -252.95  |proj g|=        3.3562
At iterate     3  f =      -255.58  |proj g|=        2.5187
At iterate     4  f =      -255.81  |proj g|=        2.1259
At iterate     5  f =      -255.82  |proj g|=        2.1292
At iterate     6  f =      -255.82  |proj g|=        2.1079
At iterate     7  f =      -255.82  |proj g|=        2.1122
At iterate     8  f =      -255.82  |proj g|=        2.1142
At iterate     9  f =      -255.82  |proj g|=        2.1226
At iterate    10  f =      -255.82  |proj g|=        2.1351
At iterate    11  f =      -255.82  |proj g|=        2.1581
At iterate    12  f =      -255.83  |proj g|=        2.1876
At iterate    13  f =      -255.84  |proj g|=        2.2455
At iterate    14  f =      -255.88  |proj g|=        2.2956
At iterate    15  f =      -255.92  |proj g|=        2.3874
At iterate    16  f =      -256.05  |proj g|=        2.4066
At iterate    17  f =      -256.71  |proj g|=        2.2606
At iterate    18  f =      -258.65  |proj g|=        1.8386
At iterate    19  f =      -260.65  |proj g|=        1.4099
At iterate    20  f =      -262.04  |proj g|=        1.0946
At iterate    21  f =      -262.07  |proj g|=        1.1797
At iterate    22  f =      -262.56  |proj g|=        1.0021
At iterate    23  f =      -262.57  |proj g|=       0.85954
At iterate    24  f =       -262.6  |proj g|=        0.9448
At iterate    25  f =       -262.6  |proj g|=       0.95196
At iterate    26  f =       -262.6  |proj g|=       0.95548
At iterate    27  f =       -262.6  |proj g|=       0.95599
At iterate    28  f =       -262.6  |proj g|=         0.956

iterations 28
function evaluations 40
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.956
final function value -262.604

F = -262.604
final  value -262.604408 
converged
 
INFO  [23:41:28.642] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:41:28.700] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:41:28.707] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:41:35.463] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:41:43.132] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:41:52.289] [mlr3]  Finished benchmark 
INFO  [23:41:52.357] [bbotk] Result of batch 37: 
INFO  [23:41:52.359] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:41:52.359] [bbotk]              2.922993                 3.804525                       0.2472936 
INFO  [23:41:52.359] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:41:52.359] [bbotk]                     2858        0.569 -0.9563335         <NA>   0.9678137 
INFO  [23:41:52.359] [bbotk]                                 uhash 
INFO  [23:41:52.359] [bbotk]  c9d45b0d-6390-41a4-bf32-fef5a4be45ba 
DEBUG [23:41:53.186] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.685607e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.685607e-05 0.002005202 
  - best initial criterion value(s) :  247.449 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -247.45  |proj g|=       6.8167
At iterate     1  f =      -254.84  |proj g|=         3.556
At iterate     2  f =      -262.94  |proj g|=        3.3482
At iterate     3  f =      -264.64  |proj g|=        2.7601
At iterate     4  f =      -266.01  |proj g|=        2.1165
At iterate     5  f =      -266.51  |proj g|=        1.8573
At iterate     6  f =      -266.84  |proj g|=        1.7677
At iterate     7  f =      -267.04  |proj g|=        2.4734
At iterate     8  f =      -267.18  |proj g|=        2.0662
At iterate     9  f =      -267.19  |proj g|=         2.034
At iterate    10  f =      -267.19  |proj g|=        2.0338
At iterate    11  f =      -267.19  |proj g|=        2.0348
At iterate    12  f =      -267.19  |proj g|=        2.0357
At iterate    13  f =      -267.19  |proj g|=        2.0372
At iterate    14  f =      -267.19  |proj g|=        2.0391
At iterate    15  f =      -267.19  |proj g|=        2.0417
At iterate    16  f =      -267.19  |proj g|=        2.0428
At iterate    17  f =       -267.2  |proj g|=        2.0353
At iterate    18  f =       -267.2  |proj g|=        2.0036
At iterate    19  f =      -267.21  |proj g|=        1.9608
At iterate    20  f =      -267.21  |proj g|=        1.7796
At iterate    21  f =      -267.23  |proj g|=        1.8489
At iterate    22  f =      -267.25  |proj g|=        1.8941
At iterate    23  f =      -267.31  |proj g|=        1.9827
At iterate    24  f =      -267.44  |proj g|=        2.0702
At iterate    25  f =      -267.74  |proj g|=        2.1071
At iterate    26  f =      -268.32  |proj g|=        1.9843
At iterate    27  f =      -269.27  |proj g|=        1.6134
At iterate    28  f =       -270.1  |proj g|=        1.2535
At iterate    29  f =      -270.41  |proj g|=        0.9075
At iterate    30  f =      -270.52  |proj g|=       0.72809
At iterate    31  f =      -270.96  |proj g|=       0.57113
At iterate    32  f =      -271.23  |proj g|=       0.53064
At iterate    33  f =      -271.26  |proj g|=       0.53486
At iterate    34  f =      -271.27  |proj g|=       0.55019
At iterate    35  f =      -271.27  |proj g|=       0.56905
At iterate    36  f =      -271.27  |proj g|=       0.57192
At iterate    37  f =      -271.27  |proj g|=       0.57203

iterations 37
function evaluations 43
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.572026
final function value -271.274

F = -271.274
final  value -271.274306 
converged
 
INFO  [23:41:53.190] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:41:53.246] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:41:53.253] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:42:07.776] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:42:21.214] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:42:35.056] [mlr3]  Finished benchmark 
INFO  [23:42:35.124] [bbotk] Result of batch 38: 
INFO  [23:42:35.126] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:42:35.126] [bbotk]                6.6808                 4.563979                        0.162819 
INFO  [23:42:35.126] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:42:35.126] [bbotk]                     4899        0.569 -0.9541123         <NA>   0.9743375 
INFO  [23:42:35.126] [bbotk]                                 uhash 
INFO  [23:42:35.126] [bbotk]  a999a933-587b-405d-bde5-ffd97026c988 
DEBUG [23:42:36.110] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.666751e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.666751e-05 0.002001959 
  - best initial criterion value(s) :  252.0132 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -252.01  |proj g|=      0.77526
At iterate     1  f =      -261.79  |proj g|=        4.4614
At iterate     2  f =      -262.09  |proj g|=        4.3429
At iterate     3  f =      -262.38  |proj g|=        3.6351
At iterate     4  f =      -262.51  |proj g|=        3.9852
At iterate     5  f =      -262.52  |proj g|=        3.9191
At iterate     6  f =      -262.52  |proj g|=        3.9037
At iterate     7  f =      -262.52  |proj g|=         3.892
At iterate     8  f =      -262.52  |proj g|=        3.8535
At iterate     9  f =      -262.53  |proj g|=        3.8071
At iterate    10  f =      -262.54  |proj g|=        3.7627
At iterate    11  f =      -262.54  |proj g|=        3.7607
At iterate    12  f =      -262.54  |proj g|=        3.7742
At iterate    13  f =      -262.54  |proj g|=        3.7783
At iterate    14  f =      -262.54  |proj g|=        3.7787
At iterate    15  f =      -262.54  |proj g|=        3.7811
At iterate    16  f =      -262.54  |proj g|=         3.784
At iterate    17  f =      -262.54  |proj g|=        3.7892
At iterate    18  f =      -262.54  |proj g|=        3.7974
At iterate    19  f =      -262.54  |proj g|=        3.8098
At iterate    20  f =      -262.54  |proj g|=        3.8272
At iterate    21  f =      -262.54  |proj g|=        3.8531
At iterate    22  f =      -262.55  |proj g|=        3.8783
At iterate    23  f =      -262.55  |proj g|=        3.9388
At iterate    24  f =      -262.57  |proj g|=        3.9447
At iterate    25  f =      -262.68  |proj g|=        3.9245
At iterate    26  f =      -262.89  |proj g|=        3.8043
At iterate    27  f =      -263.42  |proj g|=        3.3881
At iterate    28  f =      -264.24  |proj g|=        2.6255
At iterate    29  f =      -265.15  |proj g|=        1.8231
At iterate    30  f =      -265.17  |proj g|=        1.6877
At iterate    31  f =      -266.22  |proj g|=       0.91681
At iterate    32  f =      -267.14  |proj g|=       0.73868
At iterate    33  f =      -267.53  |proj g|=       0.55902
At iterate    34  f =      -267.63  |proj g|=       0.56227
At iterate    35  f =      -267.64  |proj g|=       0.55987
At iterate    36  f =      -267.64  |proj g|=       0.56424
At iterate    37  f =      -267.64  |proj g|=       0.56481
At iterate    38  f =      -267.64  |proj g|=       0.56483
At iterate    39  f =      -267.64  |proj g|=       0.56487

iterations 39
function evaluations 47
segments explored during Cauchy searches 41
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.564872
final function value -267.638

F = -267.638
final  value -267.638224 
converged
 
INFO  [23:42:36.114] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:42:36.536] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:42:36.543] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:42:50.121] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:43:02.024] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:43:15.672] [mlr3]  Finished benchmark 
INFO  [23:43:15.740] [bbotk] Result of batch 39: 
INFO  [23:43:15.742] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:43:15.742] [bbotk]              7.308873                 8.419607                      0.09550453 
INFO  [23:43:15.742] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [23:43:15.742] [bbotk]                     4468        0.711 -0.962232         <NA>   0.9722428 
INFO  [23:43:15.742] [bbotk]                                 uhash 
INFO  [23:43:15.742] [bbotk]  fd3cda9d-c076-44ab-ab5c-c14960d30c8e 
DEBUG [23:43:16.806] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.645128e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.645128e-05 0.001973728 
  - best initial criterion value(s) :  249.8715 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -249.87  |proj g|=       3.2757
At iterate     1  f =      -261.05  |proj g|=        3.8056
At iterate     2  f =      -263.95  |proj g|=        3.2611
At iterate     3  f =       -266.7  |proj g|=        2.5822
At iterate     4  f =      -267.43  |proj g|=        2.0982
At iterate     5  f =      -268.74  |proj g|=        2.9538
At iterate     6  f =      -268.98  |proj g|=        3.7645
At iterate     7  f =      -269.01  |proj g|=        3.6799
At iterate     8  f =      -269.03  |proj g|=        3.5422
At iterate     9  f =      -269.03  |proj g|=        3.6149
At iterate    10  f =      -269.03  |proj g|=        3.6065
At iterate    11  f =      -269.03  |proj g|=        3.6006
At iterate    12  f =      -269.04  |proj g|=        3.5564
At iterate    13  f =      -269.05  |proj g|=        3.4965
At iterate    14  f =      -269.08  |proj g|=        3.3904
At iterate    15  f =      -269.16  |proj g|=        3.2014
At iterate    16  f =      -269.38  |proj g|=        2.8417
At iterate    17  f =      -269.97  |proj g|=          2.21
At iterate    18  f =      -271.55  |proj g|=        1.3077
At iterate    19  f =      -275.04  |proj g|=       0.81086
At iterate    20  f =      -277.59  |proj g|=        1.3232
At iterate    21  f =      -277.62  |proj g|=        1.6055
At iterate    22  f =      -277.63  |proj g|=        1.5306
At iterate    23  f =      -277.63  |proj g|=         1.523
At iterate    24  f =      -277.63  |proj g|=        1.5246
At iterate    25  f =      -277.63  |proj g|=        1.4829
At iterate    26  f =      -277.66  |proj g|=        1.5532
At iterate    27  f =      -277.76  |proj g|=        1.6667
At iterate    28  f =      -278.16  |proj g|=        1.8507
At iterate    29  f =      -278.88  |proj g|=        1.1919
At iterate    30  f =      -278.94  |proj g|=        1.0393
At iterate    31  f =      -278.95  |proj g|=        1.2582
At iterate    32  f =      -278.98  |proj g|=        1.1607
At iterate    33  f =      -278.98  |proj g|=        1.1056
At iterate    34  f =      -278.98  |proj g|=        1.1073
At iterate    35  f =      -278.98  |proj g|=        1.1074

iterations 35
function evaluations 43
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.10745
final function value -278.978

F = -278.978
final  value -278.978319 
converged
 
INFO  [23:43:16.810] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:43:16.864] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:43:16.871] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:43:25.537] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:43:33.319] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:43:41.018] [mlr3]  Finished benchmark 
INFO  [23:43:41.085] [bbotk] Result of batch 40: 
INFO  [23:43:41.087] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:43:41.087] [bbotk]               9.15954                 5.211562                      0.01703478 
INFO  [23:43:41.087] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:43:41.087] [bbotk]                     3100        0.746 -0.9580193         <NA>   0.9534242 
INFO  [23:43:41.087] [bbotk]                                 uhash 
INFO  [23:43:41.087] [bbotk]  c2e11fc8-0a7d-4b11-a43a-9c65d34dbb14 
DEBUG [23:43:42.228] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.65193e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.65193e-05 0.001989819 
  - best initial criterion value(s) :  256.4206 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -256.42  |proj g|=       1.1617
At iterate     1  f =      -257.14  |proj g|=        1.4085
At iterate     2  f =      -259.04  |proj g|=        1.2345
At iterate     3  f =      -261.03  |proj g|=       0.63484
At iterate     4  f =      -262.24  |proj g|=       0.70603
At iterate     5  f =      -262.49  |proj g|=       0.65779
At iterate     6  f =      -262.59  |proj g|=       0.62272
At iterate     7  f =      -262.59  |proj g|=       0.61992
At iterate     8  f =      -262.59  |proj g|=       0.61789
At iterate     9  f =      -262.59  |proj g|=       0.61893
At iterate    10  f =      -262.59  |proj g|=       0.61937
At iterate    11  f =      -262.59  |proj g|=       0.61943

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.61943
final function value -262.594

F = -262.594
final  value -262.593958 
converged
 
INFO  [23:43:42.232] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:43:42.289] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:43:42.296] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:43:43.638] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:43:44.795] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:43:46.429] [mlr3]  Finished benchmark 
INFO  [23:43:46.495] [bbotk] Result of batch 41: 
INFO  [23:43:46.497] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:43:46.497] [bbotk]              9.068038                 9.515422                       0.4535842 
INFO  [23:43:46.497] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:43:46.497] [bbotk]                      300         0.89 -0.9680089         <NA>   0.9654998 
INFO  [23:43:46.497] [bbotk]                                 uhash 
INFO  [23:43:46.497] [bbotk]  d1664646-59d9-41ba-a703-b611b52ec426 
DEBUG [23:43:47.308] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.629454e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.629454e-05 0.001922873 
  - best initial criterion value(s) :  261.2335 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -261.23  |proj g|=       6.0115
At iterate     1  f =      -261.84  |proj g|=        6.5392
At iterate     2  f =      -266.26  |proj g|=        5.7307
At iterate     3  f =      -267.11  |proj g|=        4.7698
At iterate     4  f =      -268.62  |proj g|=         3.848
At iterate     5  f =      -269.05  |proj g|=        3.2376
At iterate     6  f =      -269.05  |proj g|=        3.2327
At iterate     7  f =      -269.05  |proj g|=        3.2285
At iterate     8  f =      -269.05  |proj g|=        3.2221
At iterate     9  f =      -269.05  |proj g|=        3.2105
At iterate    10  f =      -269.06  |proj g|=        3.1913
At iterate    11  f =      -269.08  |proj g|=        3.1599
At iterate    12  f =      -269.12  |proj g|=        3.1123
At iterate    13  f =      -269.25  |proj g|=          3.05
At iterate    14  f =      -269.55  |proj g|=        3.0104
At iterate    15  f =      -270.16  |proj g|=        3.1344
At iterate    16  f =      -270.34  |proj g|=        3.5965
At iterate    17  f =      -270.57  |proj g|=        3.5612
At iterate    18  f =      -271.08  |proj g|=         3.382
At iterate    19  f =      -273.02  |proj g|=        2.6273
At iterate    20  f =      -277.75  |proj g|=        1.3608
At iterate    21  f =      -281.41  |proj g|=        1.0923
At iterate    22  f =      -284.12  |proj g|=       0.81935
At iterate    23  f =      -284.32  |proj g|=        1.8532
At iterate    24  f =      -286.24  |proj g|=        1.4064
At iterate    25  f =      -286.37  |proj g|=        1.1204
At iterate    26  f =      -286.38  |proj g|=       0.98947
At iterate    27  f =      -286.38  |proj g|=        1.0225
At iterate    28  f =      -286.38  |proj g|=        1.0206
At iterate    29  f =      -286.38  |proj g|=        1.0195
At iterate    30  f =      -286.38  |proj g|=        1.0205
At iterate    31  f =      -286.38  |proj g|=        1.0202

iterations 31
function evaluations 39
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.02022
final function value -286.377

F = -286.377
final  value -286.376825 
converged
 
INFO  [23:43:47.312] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:43:47.367] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:43:47.374] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:44:02.141] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:44:16.654] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:44:29.422] [mlr3]  Finished benchmark 
INFO  [23:44:29.489] [bbotk] Result of batch 42: 
INFO  [23:44:29.491] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:44:29.491] [bbotk]              6.675885                 8.279409                       0.2875017 
INFO  [23:44:29.491] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:44:29.491] [bbotk]                     4502        0.567 -0.9562729         <NA>   0.9757183 
INFO  [23:44:29.491] [bbotk]                                 uhash 
INFO  [23:44:29.491] [bbotk]  9d7d8b27-8c24-48bd-a654-ee8c6b41b68f 
DEBUG [23:44:30.403] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.615298e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.615298e-05 0.00192389 
  - best initial criterion value(s) :  275.2708 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -275.27  |proj g|=       2.3996
At iterate     1  f =      -278.36  |proj g|=        1.5787
At iterate     2  f =      -281.07  |proj g|=        2.4237
At iterate     3  f =       -281.4  |proj g|=        2.4308
At iterate     4  f =      -281.56  |proj g|=        2.4394
At iterate     5  f =      -281.58  |proj g|=        2.4603
At iterate     6  f =      -281.58  |proj g|=        2.4851
At iterate     7  f =      -281.59  |proj g|=        2.5093
At iterate     8  f =      -281.59  |proj g|=        2.5126
At iterate     9  f =      -281.59  |proj g|=        2.5131
At iterate    10  f =      -281.59  |proj g|=        2.5148
At iterate    11  f =      -281.59  |proj g|=        2.5174
At iterate    12  f =      -281.59  |proj g|=        2.5207
At iterate    13  f =      -281.59  |proj g|=        2.5254
At iterate    14  f =      -281.59  |proj g|=        2.5314
At iterate    15  f =      -281.59  |proj g|=        2.5336
At iterate    16  f =      -281.59  |proj g|=        2.5302
At iterate    17  f =      -281.59  |proj g|=        2.5524
At iterate    18  f =       -281.6  |proj g|=        2.5391
At iterate    19  f =      -283.55  |proj g|=         1.777
At iterate    20  f =      -287.26  |proj g|=       0.99647
At iterate    21  f =      -288.67  |proj g|=       0.75853
At iterate    22  f =      -288.95  |proj g|=       0.63471
At iterate    23  f =      -288.97  |proj g|=       0.85145
At iterate    24  f =      -289.12  |proj g|=       0.69146
At iterate    25  f =      -289.13  |proj g|=       0.65662
At iterate    26  f =      -289.13  |proj g|=       0.65345
At iterate    27  f =      -289.13  |proj g|=       0.65881
At iterate    28  f =      -289.13  |proj g|=       0.65733
At iterate    29  f =      -289.13  |proj g|=       0.65915
At iterate    30  f =      -289.13  |proj g|=       0.65893
At iterate    31  f =      -289.14  |proj g|=       0.65612
At iterate    32  f =       -289.2  |proj g|=       0.64037
At iterate    33  f =       -289.4  |proj g|=       0.59822
At iterate    34  f =      -289.83  |proj g|=       0.58514
At iterate    35  f =      -289.85  |proj g|=       0.56901
At iterate    36  f =      -290.27  |proj g|=       0.61582
At iterate    37  f =      -292.04  |proj g|=       0.49687
At iterate    38  f =      -292.18  |proj g|=        0.4979
At iterate    39  f =      -292.19  |proj g|=       0.49071
At iterate    40  f =      -292.19  |proj g|=       0.49028
At iterate    41  f =      -292.19  |proj g|=       0.49028
At iterate    42  f =      -292.19  |proj g|=       0.49029
At iterate    43  f =      -292.19  |proj g|=       0.49028
At iterate    44  f =      -292.19  |proj g|=       0.49027
At iterate    45  f =      -292.19  |proj g|=       0.49022
At iterate    46  f =      -292.19  |proj g|=       0.49008
At iterate    47  f =      -292.19  |proj g|=       0.48967
At iterate    48  f =       -292.2  |proj g|=       0.48859
At iterate    49  f =       -292.2  |proj g|=       0.48581
At iterate    50  f =      -292.21  |proj g|=       0.47954
At iterate    51  f =      -292.23  |proj g|=       0.46901
At iterate    52  f =      -292.23  |proj g|=       0.48162
At iterate    53  f =      -292.24  |proj g|=        0.1974
At iterate    54  f =      -292.24  |proj g|=       0.24175
At iterate    55  f =      -292.24  |proj g|=       0.32651
At iterate    56  f =      -292.24  |proj g|=       0.46283
At iterate    57  f =      -292.24  |proj g|=       0.46171
At iterate    58  f =      -292.24  |proj g|=       0.46039
At iterate    59  f =      -292.25  |proj g|=      0.021603
At iterate    60  f =      -292.25  |proj g|=     0.0069512
At iterate    61  f =      -292.25  |proj g|=     0.0010888
At iterate    62  f =      -292.25  |proj g|=    0.00098918

iterations 62
function evaluations 83
segments explored during Cauchy searches 64
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.000989177
final function value -292.245

F = -292.245
final  value -292.245114 
converged
 
INFO  [23:44:30.407] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:44:30.462] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:44:30.469] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:44:37.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:44:44.248] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:44:52.129] [mlr3]  Finished benchmark 
INFO  [23:44:52.197] [bbotk] Result of batch 43: 
INFO  [23:44:52.199] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:44:52.199] [bbotk]              9.415893                 9.891677                       0.4447677 
INFO  [23:44:52.199] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:44:52.199] [bbotk]                     2491        0.567 -0.9538274         <NA>   0.9757843 
INFO  [23:44:52.199] [bbotk]                                 uhash 
INFO  [23:44:52.199] [bbotk]  25065d4f-d213-4974-92d6-4221a8862212 
DEBUG [23:44:53.044] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.601442e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.601442e-05 0.001923278 
  - best initial criterion value(s) :  282.895 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -282.9  |proj g|=       3.5145
At iterate     1  f =      -283.35  |proj g|=        4.2211
At iterate     2  f =      -284.02  |proj g|=        3.9432
At iterate     3  f =         -285  |proj g|=        2.9599
At iterate     4  f =      -285.27  |proj g|=        2.9592
At iterate     5  f =      -285.43  |proj g|=        2.7918
At iterate     6  f =      -285.45  |proj g|=        2.7503
At iterate     7  f =      -285.45  |proj g|=          2.75
At iterate     8  f =      -285.45  |proj g|=        2.7546
At iterate     9  f =      -285.45  |proj g|=        2.7565
At iterate    10  f =      -285.45  |proj g|=         2.757
At iterate    11  f =      -285.45  |proj g|=         2.759
At iterate    12  f =      -285.45  |proj g|=        2.7615
At iterate    13  f =      -285.45  |proj g|=        2.7661
At iterate    14  f =      -285.45  |proj g|=        2.7733
At iterate    15  f =      -285.45  |proj g|=         2.785
At iterate    16  f =      -285.46  |proj g|=        2.8017
At iterate    17  f =      -285.46  |proj g|=        2.8182
At iterate    18  f =      -285.46  |proj g|=        2.8286
At iterate    19  f =      -285.46  |proj g|=         2.844
At iterate    20  f =      -287.88  |proj g|=        1.8061
At iterate    21  f =      -290.02  |proj g|=       0.91055
At iterate    22  f =      -290.48  |proj g|=       0.83061
At iterate    23  f =       -290.6  |proj g|=       0.80204
At iterate    24  f =      -290.61  |proj g|=       0.84928
At iterate    25  f =      -290.62  |proj g|=       0.82209
At iterate    26  f =      -290.62  |proj g|=       0.81996
At iterate    27  f =      -290.62  |proj g|=       0.82084
At iterate    28  f =      -290.62  |proj g|=        0.8218
At iterate    29  f =      -290.62  |proj g|=       0.82222
At iterate    30  f =      -290.62  |proj g|=       0.82176
At iterate    31  f =      -290.62  |proj g|=       0.82189
At iterate    32  f =      -290.62  |proj g|=       0.82185

iterations 32
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.821854
final function value -290.624

F = -290.624
final  value -290.624023 
converged
 
INFO  [23:44:53.048] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:44:53.103] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:44:53.110] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:45:03.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:45:16.277] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:45:27.639] [mlr3]  Finished benchmark 
INFO  [23:45:27.707] [bbotk] Result of batch 44: 
INFO  [23:45:27.709] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:45:27.709] [bbotk]              9.794227                 7.326729                       0.3670792 
INFO  [23:45:27.709] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:45:27.709] [bbotk]                     3994        0.591 -0.9583621         <NA>   0.9763791 
INFO  [23:45:27.709] [bbotk]                                 uhash 
INFO  [23:45:27.709] [bbotk]  e401e303-20f9-4b8e-8f82-6f5be62c6481 
DEBUG [23:45:28.555] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.589015e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.589015e-05 0.001927957 
  - best initial criterion value(s) :  275.8253 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -275.83  |proj g|=      0.70197
At iterate     1  f =      -276.97  |proj g|=        2.5424
At iterate     2  f =      -278.48  |proj g|=        2.2509
At iterate     3  f =      -279.36  |proj g|=        1.7635
At iterate     4  f =      -279.45  |proj g|=        1.6579
At iterate     5  f =      -279.73  |proj g|=         1.454
At iterate     6  f =      -280.16  |proj g|=        1.2165
At iterate     7  f =       -280.3  |proj g|=        1.3644
At iterate     8  f =      -280.31  |proj g|=        1.4012
At iterate     9  f =      -280.31  |proj g|=        1.3995
At iterate    10  f =      -280.31  |proj g|=        1.3988
At iterate    11  f =      -280.31  |proj g|=        1.3964
At iterate    12  f =      -280.31  |proj g|=        1.3928
At iterate    13  f =      -280.31  |proj g|=        1.3867
At iterate    14  f =      -280.31  |proj g|=         1.377
At iterate    15  f =      -280.31  |proj g|=        1.3601
At iterate    16  f =      -280.32  |proj g|=        1.3321
At iterate    17  f =      -280.33  |proj g|=        1.2864
At iterate    18  f =      -280.36  |proj g|=        1.2282
At iterate    19  f =       -280.4  |proj g|=        1.2071
At iterate    20  f =      -280.42  |proj g|=        1.2282
At iterate    21  f =      -280.43  |proj g|=        1.2663
At iterate    22  f =      -280.44  |proj g|=        1.2895
At iterate    23  f =      -280.46  |proj g|=        1.3186
At iterate    24  f =       -280.5  |proj g|=        1.3544
At iterate    25  f =      -280.59  |proj g|=        1.3793
At iterate    26  f =       -280.8  |proj g|=        1.3509
At iterate    27  f =      -281.21  |proj g|=        1.2132
At iterate    28  f =      -281.94  |proj g|=       0.81352
At iterate    29  f =      -281.98  |proj g|=       0.82954
At iterate    30  f =      -282.01  |proj g|=       0.83058
At iterate    31  f =      -282.14  |proj g|=       0.82005
At iterate    32  f =      -282.28  |proj g|=        0.8694
At iterate    33  f =      -282.37  |proj g|=       0.93994
At iterate    34  f =      -282.37  |proj g|=       0.99068
At iterate    35  f =      -282.37  |proj g|=       0.98041
At iterate    36  f =      -282.37  |proj g|=       0.96877
At iterate    37  f =      -282.37  |proj g|=       0.97179
At iterate    38  f =      -282.37  |proj g|=       0.97174

iterations 38
function evaluations 43
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.97174
final function value -282.371

F = -282.371
final  value -282.371085 
converged
 
INFO  [23:45:28.560] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:45:28.614] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:45:28.621] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:45:36.719] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:45:44.848] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:45:54.726] [mlr3]  Finished benchmark 
INFO  [23:45:54.795] [bbotk] Result of batch 45: 
INFO  [23:45:54.796] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:45:54.796] [bbotk]              5.169822                 7.322134                       0.1702007 
INFO  [23:45:54.796] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:45:54.796] [bbotk]                     3047        0.582 -0.9663402         <NA>   0.9726955 
INFO  [23:45:54.796] [bbotk]                                 uhash 
INFO  [23:45:54.796] [bbotk]  29c8fff8-fcfe-4bca-968e-33cd32e3739c 
DEBUG [23:45:55.853] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.570514e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.570514e-05 0.001938378 
  - best initial criterion value(s) :  290.14 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -290.14  |proj g|=       6.2711
At iterate     1  f =      -295.16  |proj g|=        6.3283
At iterate     2  f =      -298.79  |proj g|=        3.7811
At iterate     3  f =      -299.44  |proj g|=        2.9588
At iterate     4  f =      -299.49  |proj g|=        3.0755
At iterate     5  f =      -299.62  |proj g|=        2.4114
At iterate     6  f =      -299.62  |proj g|=        2.4664
At iterate     7  f =      -299.62  |proj g|=        2.4773
At iterate     8  f =      -299.65  |proj g|=        2.5197
At iterate     9  f =      -299.72  |proj g|=        2.5708
At iterate    10  f =      -299.92  |proj g|=         2.787
At iterate    11  f =      -299.95  |proj g|=         2.561
At iterate    12  f =      -300.37  |proj g|=        2.6925
At iterate    13  f =      -304.45  |proj g|=       0.81167
At iterate    14  f =      -305.59  |proj g|=       0.43273
At iterate    15  f =      -306.14  |proj g|=       0.42105
At iterate    16  f =      -306.34  |proj g|=       0.43645
At iterate    17  f =      -306.41  |proj g|=       0.53239
At iterate    18  f =      -306.47  |proj g|=        0.5288
At iterate    19  f =      -306.49  |proj g|=       0.54002
At iterate    20  f =      -306.49  |proj g|=       0.54666
At iterate    21  f =      -306.49  |proj g|=       0.54904
At iterate    22  f =      -306.49  |proj g|=       0.55302
At iterate    23  f =      -306.49  |proj g|=       0.55383
At iterate    24  f =      -306.49  |proj g|=       0.55943
At iterate    25  f =      -306.49  |proj g|=       0.55771
At iterate    26  f =      -306.49  |proj g|=       0.55177
At iterate    27  f =      -306.49  |proj g|=       0.55026
At iterate    28  f =      -306.49  |proj g|=       0.55021
At iterate    29  f =      -306.49  |proj g|=       0.55017
At iterate    30  f =      -306.49  |proj g|=       0.54967
At iterate    31  f =      -306.49  |proj g|=        0.5494
At iterate    32  f =      -306.49  |proj g|=       0.54891
At iterate    33  f =      -306.49  |proj g|=       0.54808
At iterate    34  f =      -306.49  |proj g|=       0.54722
At iterate    35  f =      -306.49  |proj g|=       0.54715
At iterate    36  f =      -306.49  |proj g|=       0.54482
At iterate    37  f =       -306.5  |proj g|=       0.54476
At iterate    38  f =       -306.5  |proj g|=       0.54595
At iterate    39  f =       -306.5  |proj g|=       0.54573
At iterate    40  f =      -306.52  |proj g|=       0.56901
At iterate    41  f =      -306.58  |proj g|=        0.5871
At iterate    42  f =      -306.95  |proj g|=       0.61221
At iterate    43  f =      -307.43  |proj g|=       0.45724
At iterate    44  f =      -307.45  |proj g|=       0.44618
At iterate    45  f =      -307.53  |proj g|=       0.45054
At iterate    46  f =      -307.62  |proj g|=       0.48281
At iterate    47  f =      -307.63  |proj g|=       0.48043
At iterate    48  f =      -307.64  |proj g|=       0.28987
At iterate    49  f =      -307.66  |proj g|=       0.48386
At iterate    50  f =      -307.67  |proj g|=        0.2325
At iterate    51  f =      -307.68  |proj g|=       0.28635
At iterate    52  f =      -307.68  |proj g|=      0.055051
At iterate    53  f =      -307.68  |proj g|=     0.0030613
At iterate    54  f =      -307.68  |proj g|=     0.0009142

iterations 54
function evaluations 68
segments explored during Cauchy searches 56
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.000914205
final function value -307.677

F = -307.677
final  value -307.676773 
converged
 
INFO  [23:45:55.857] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:45:55.943] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:45:55.951] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:46:00.372] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:46:05.606] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:46:10.619] [mlr3]  Finished benchmark 
INFO  [23:46:10.687] [bbotk] Result of batch 46: 
INFO  [23:46:10.689] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:46:10.689] [bbotk]              3.170686                 5.995881                       0.3529919 
INFO  [23:46:10.689] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:46:10.689] [bbotk]                     1764        0.707 -0.9523825         <NA>    0.968708 
INFO  [23:46:10.689] [bbotk]                                 uhash 
INFO  [23:46:10.689] [bbotk]  73d8edda-e367-4702-9cbd-77c831ff095a 
DEBUG [23:46:11.735] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.549878e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.549878e-05 0.001894528 
  - best initial criterion value(s) :  281.309 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -281.31  |proj g|=       6.6328
At iterate     1  f =      -292.76  |proj g|=        2.3142
At iterate     2  f =       -296.7  |proj g|=        1.8184
At iterate     3  f =       -303.5  |proj g|=       0.86072
At iterate     4  f =      -303.98  |proj g|=        0.7014
At iterate     5  f =      -304.56  |proj g|=         0.752
At iterate     6  f =      -305.51  |proj g|=        0.8728
At iterate     7  f =      -305.82  |proj g|=       0.78811
At iterate     8  f =      -305.92  |proj g|=       0.76012
At iterate     9  f =      -305.94  |proj g|=       0.73005
At iterate    10  f =      -305.95  |proj g|=        0.6756
At iterate    11  f =      -305.95  |proj g|=       0.69625
At iterate    12  f =      -305.95  |proj g|=       0.69588
At iterate    13  f =      -305.95  |proj g|=        0.6841
At iterate    14  f =      -305.98  |proj g|=       0.66765
At iterate    15  f =      -306.53  |proj g|=       0.61207
At iterate    16  f =      -306.85  |proj g|=       0.67469
At iterate    17  f =      -306.95  |proj g|=       0.63894
At iterate    18  f =      -306.96  |proj g|=       0.63257
At iterate    19  f =      -306.96  |proj g|=        0.6351
At iterate    20  f =      -306.96  |proj g|=       0.63496
At iterate    21  f =      -306.96  |proj g|=       0.63499

iterations 21
function evaluations 31
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.63499
final function value -306.957

F = -306.957
final  value -306.956773 
converged
 
INFO  [23:46:11.739] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:46:12.153] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:46:12.160] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:46:17.381] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:46:23.189] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:46:27.944] [mlr3]  Finished benchmark 
INFO  [23:46:28.012] [bbotk] Result of batch 47: 
INFO  [23:46:28.014] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:46:28.014] [bbotk]              9.569554                 9.443247                        0.379177 
INFO  [23:46:28.014] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:46:28.014] [bbotk]                     1947        0.736 -0.9572765         <NA>   0.9746149 
INFO  [23:46:28.014] [bbotk]                                 uhash 
INFO  [23:46:28.014] [bbotk]  cdd50449-8a5d-4986-b06d-fd89f4ae92f5 
DEBUG [23:46:28.875] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.534956e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.534956e-05 0.001857189 
  - best initial criterion value(s) :  285.0806 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -285.08  |proj g|=       6.0829
At iterate     1  f =         -301  |proj g|=       0.86789
At iterate     2  f =      -303.47  |proj g|=       0.79258
At iterate     3  f =      -306.74  |proj g|=         1.818
At iterate     4  f =       -307.8  |proj g|=         1.094
At iterate     5  f =      -308.58  |proj g|=       0.98301
At iterate     6  f =      -312.09  |proj g|=        0.9912
At iterate     7  f =      -313.42  |proj g|=        1.1325
At iterate     8  f =       -313.7  |proj g|=       0.65701
At iterate     9  f =      -314.25  |proj g|=       0.87094
At iterate    10  f =      -314.32  |proj g|=       0.91088
At iterate    11  f =      -314.33  |proj g|=       0.89569
At iterate    12  f =      -314.34  |proj g|=       0.87201
At iterate    13  f =      -314.34  |proj g|=       0.85977
At iterate    14  f =      -314.34  |proj g|=       0.87334
At iterate    15  f =      -314.34  |proj g|=       0.86618
At iterate    16  f =      -314.34  |proj g|=       0.85862
At iterate    17  f =      -315.29  |proj g|=       0.82444
At iterate    18  f =      -316.03  |proj g|=       0.78705
At iterate    19  f =      -316.17  |proj g|=       0.90177
At iterate    20  f =      -316.18  |proj g|=       0.94791
At iterate    21  f =      -316.18  |proj g|=       0.95064
At iterate    22  f =      -316.18  |proj g|=       0.95069

iterations 22
function evaluations 30
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.950692
final function value -316.185

F = -316.185
final  value -316.184775 
converged
 
INFO  [23:46:28.879] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:46:28.934] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:46:28.940] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:46:40.774] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:46:54.406] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:47:06.827] [mlr3]  Finished benchmark 
INFO  [23:47:07.031] [bbotk] Result of batch 48: 
INFO  [23:47:07.033] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:47:07.033] [bbotk]               3.88956                 4.556634                      0.04325312 
INFO  [23:47:07.033] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:47:07.033] [bbotk]                     4417        0.592 -0.9420908         <NA>   0.9633067 
INFO  [23:47:07.033] [bbotk]                                 uhash 
INFO  [23:47:07.033] [bbotk]  e67c33fe-9a3b-48c2-b1dc-21b9ec812c2a 
DEBUG [23:47:07.833] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.518464e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.518464e-05 0.001842524 
  - best initial criterion value(s) :  296.4295 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -296.43  |proj g|=       2.2467
At iterate     1  f =      -307.14  |proj g|=        5.2285
At iterate     2  f =       -313.6  |proj g|=        2.7456
At iterate     3  f =      -313.63  |proj g|=        2.5488
At iterate     4  f =      -313.64  |proj g|=        2.5154
At iterate     5  f =      -313.64  |proj g|=        2.5147
At iterate     6  f =      -313.64  |proj g|=        2.5035
At iterate     7  f =      -313.64  |proj g|=        2.5041

iterations 7
function evaluations 13
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.50413
final function value -313.64

F = -313.64
final  value -313.639903 
converged
 
INFO  [23:47:07.837] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:47:07.894] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:47:07.901] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:47:15.675] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:47:22.093] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:47:28.828] [mlr3]  Finished benchmark 
INFO  [23:47:28.897] [bbotk] Result of batch 49: 
INFO  [23:47:28.899] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:47:28.899] [bbotk]              3.992889                 4.346374                       0.2146004 
INFO  [23:47:28.899] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [23:47:28.899] [bbotk]                     2580        0.585 -0.960034         <NA>   0.9709509 
INFO  [23:47:28.899] [bbotk]                                 uhash 
INFO  [23:47:28.899] [bbotk]  99de9654-62ff-4a55-871e-e5680f01431e 
DEBUG [23:47:29.758] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.500147e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.59913 0.9467609 9504 
  - variance bounds :  1.500147e-05 0.001829787 
  - best initial criterion value(s) :  293.7468 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -293.75  |proj g|=       3.6548
At iterate     1  f =       -303.4  |proj g|=        0.9967
At iterate     2  f =      -305.22  |proj g|=       0.93184
At iterate     3  f =      -306.56  |proj g|=        1.6571
At iterate     4  f =      -307.36  |proj g|=        1.0433
At iterate     5  f =      -307.52  |proj g|=         1.112
At iterate     6  f =      -308.13  |proj g|=        1.2783
At iterate     7  f =      -308.99  |proj g|=        1.2986
At iterate     8  f =      -310.17  |proj g|=       0.79973
At iterate     9  f =      -310.18  |proj g|=       0.84078
At iterate    10  f =      -310.18  |proj g|=       0.86656
At iterate    11  f =      -310.18  |proj g|=       0.86508
At iterate    12  f =      -310.19  |proj g|=       0.85437
At iterate    13  f =      -310.19  |proj g|=       0.85957
At iterate    14  f =      -310.68  |proj g|=        0.9513
At iterate    15  f =      -311.87  |proj g|=       0.91771
At iterate    16  f =      -312.38  |proj g|=       0.80155
At iterate    17  f =      -312.51  |proj g|=       0.72003
At iterate    18  f =      -312.53  |proj g|=       0.68042
At iterate    19  f =      -312.53  |proj g|=       0.65788
At iterate    20  f =      -312.53  |proj g|=       0.65936
At iterate    21  f =      -312.53  |proj g|=       0.65937

iterations 21
function evaluations 29
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.659369
final function value -312.53

F = -312.53
final  value -312.529918 
converged
 
INFO  [23:47:29.762] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:47:29.842] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:47:29.848] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:47:36.504] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:47:43.303] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:47:50.453] [mlr3]  Finished benchmark 
INFO  [23:47:50.550] [bbotk] Result of batch 50: 
INFO  [23:47:50.552] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:47:50.552] [bbotk]              8.562471                  2.05746                        0.155721 
INFO  [23:47:50.552] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:47:50.552] [bbotk]                     2592        0.604 -0.9589046         <NA>   0.9722816 
INFO  [23:47:50.552] [bbotk]                                 uhash 
INFO  [23:47:50.552] [bbotk]  18064348-96fc-4c24-a88e-e0bb87cd4d90 
DEBUG [23:47:51.393] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.483358e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9467609 9504 
  - variance bounds :  1.483358e-05 0.001819204 
  - best initial criterion value(s) :  311.9845 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -311.98  |proj g|=       1.4189
At iterate     1  f =      -315.82  |proj g|=        2.8885
At iterate     2  f =      -317.85  |proj g|=         2.431
At iterate     3  f =      -319.28  |proj g|=        1.5498
At iterate     4  f =      -319.29  |proj g|=        1.4176
At iterate     5  f =      -319.29  |proj g|=        1.4612
At iterate     6  f =      -319.29  |proj g|=        1.4827
At iterate     7  f =       -319.3  |proj g|=        1.5109
At iterate     8  f =      -319.31  |proj g|=        1.5142
At iterate     9  f =      -319.31  |proj g|=         1.483
At iterate    10  f =      -319.31  |proj g|=        1.4922
At iterate    11  f =      -319.31  |proj g|=        1.4924

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.49243
final function value -319.307

F = -319.307
final  value -319.306816 
converged
 
INFO  [23:47:51.398] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:47:51.454] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:47:51.461] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:47:58.404] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:48:03.898] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:48:10.338] [mlr3]  Finished benchmark 
INFO  [23:48:10.407] [bbotk] Result of batch 51: 
INFO  [23:48:10.408] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:48:10.408] [bbotk]              6.570982                   8.9301                      0.09527209 
INFO  [23:48:10.408] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:48:10.408] [bbotk]                     1910        0.621 -0.9614792         <NA>   0.9671378 
INFO  [23:48:10.408] [bbotk]                                 uhash 
INFO  [23:48:10.408] [bbotk]  e6219232-0d9e-4cc7-a2b7-8686bbcc59b6 
DEBUG [23:48:11.290] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.465222e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9467609 9504 
  - variance bounds :  1.465222e-05 0.001783551 
  - best initial criterion value(s) :  305.0241 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -305.02  |proj g|=      0.94517
At iterate     1  f =      -311.55  |proj g|=        1.9237
At iterate     2  f =      -318.67  |proj g|=        1.1227
At iterate     3  f =      -319.71  |proj g|=       0.42935
At iterate     4  f =      -319.75  |proj g|=        0.5129
At iterate     5  f =      -319.79  |proj g|=       0.47504
At iterate     6  f =      -319.86  |proj g|=       0.57779
At iterate     7  f =      -319.87  |proj g|=       0.31837
At iterate     8  f =      -319.87  |proj g|=       0.31163
At iterate     9  f =      -319.87  |proj g|=       0.31137

iterations 9
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.311369
final function value -319.865

F = -319.865
final  value -319.865348 
converged
 
INFO  [23:48:11.294] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:48:11.351] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:48:11.358] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:48:19.667] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:48:27.770] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:48:37.150] [mlr3]  Finished benchmark 
INFO  [23:48:37.246] [bbotk] Result of batch 52: 
INFO  [23:48:37.248] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:48:37.248] [bbotk]              5.947069                 2.611943                       0.3595534 
INFO  [23:48:37.248] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:48:37.248] [bbotk]                     3158         0.64 -0.9635991         <NA>   0.9754299 
INFO  [23:48:37.248] [bbotk]                                 uhash 
INFO  [23:48:37.248] [bbotk]  3a74fe62-1f6e-48a9-9563-5c0c08dc2614 
DEBUG [23:48:38.271] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.453429e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9467609 9504 
  - variance bounds :  1.453429e-05 0.001785337 
  - best initial criterion value(s) :  319.5512 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -319.55  |proj g|=        3.467
At iterate     1  f =      -328.11  |proj g|=        6.5052
At iterate     2  f =      -328.64  |proj g|=         6.311
At iterate     3  f =      -330.79  |proj g|=        4.6881
At iterate     4  f =      -331.84  |proj g|=        3.1921
At iterate     5  f =      -332.86  |proj g|=        2.5415
At iterate     6  f =      -332.88  |proj g|=         2.649
At iterate     7  f =      -332.88  |proj g|=        2.6243
At iterate     8  f =      -332.97  |proj g|=        2.5599
At iterate     9  f =      -334.08  |proj g|=        1.8362
At iterate    10  f =      -335.21  |proj g|=       0.66828
At iterate    11  f =      -336.58  |proj g|=       0.61959
At iterate    12  f =      -337.05  |proj g|=       0.57995
At iterate    13  f =      -337.12  |proj g|=       0.36722
At iterate    14  f =       -337.3  |proj g|=       0.41472
At iterate    15  f =      -337.35  |proj g|=       0.43589
At iterate    16  f =      -337.36  |proj g|=       0.38202
At iterate    17  f =      -337.37  |proj g|=       0.38526
At iterate    18  f =      -337.37  |proj g|=       0.38583
At iterate    19  f =      -337.37  |proj g|=       0.38583
At iterate    20  f =      -337.37  |proj g|=       0.38587

iterations 20
function evaluations 28
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.385874
final function value -337.367

F = -337.367
final  value -337.366861 
converged
 
INFO  [23:48:38.275] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:48:38.330] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:48:38.337] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:48:46.102] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:48:56.176] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:49:03.515] [mlr3]  Finished benchmark 
INFO  [23:49:03.585] [bbotk] Result of batch 53: 
INFO  [23:49:03.587] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:49:03.587] [bbotk]              3.959925                 9.046719                       0.3133631 
INFO  [23:49:03.587] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:49:03.587] [bbotk]                     2896        0.773 -0.9550034         <NA>   0.9726974 
INFO  [23:49:03.587] [bbotk]                                 uhash 
INFO  [23:49:03.587] [bbotk]  bc0b5c42-5f0b-4177-b2dd-45aae224ce7f 
DEBUG [23:49:04.400] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.438101e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9467609 9504 
  - variance bounds :  1.438101e-05 0.001779658 
  - best initial criterion value(s) :  314.0186 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -314.02  |proj g|=       1.4745
At iterate     1  f =      -314.89  |proj g|=        2.6625
At iterate     2  f =      -316.06  |proj g|=        2.4383
At iterate     3  f =      -316.89  |proj g|=        2.1053
At iterate     4  f =      -317.46  |proj g|=         1.746
At iterate     5  f =      -318.59  |proj g|=        1.3432
At iterate     6  f =       -320.3  |proj g|=       0.99978
At iterate     7  f =      -320.34  |proj g|=        1.4597
At iterate     8  f =       -320.6  |proj g|=        1.2496
At iterate     9  f =       -320.6  |proj g|=        1.2011
At iterate    10  f =       -320.6  |proj g|=        1.2156
At iterate    11  f =       -320.6  |proj g|=        1.2151

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.21514
final function value -320.602

F = -320.602
final  value -320.601746 
converged
 
INFO  [23:49:04.404] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:49:04.462] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:49:04.469] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:49:09.228] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:49:13.833] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:49:17.619] [mlr3]  Finished benchmark 
INFO  [23:49:17.685] [bbotk] Result of batch 54: 
INFO  [23:49:17.687] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:49:17.687] [bbotk]              3.158078                 7.419739                        0.492094 
INFO  [23:49:17.687] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:49:17.687] [bbotk]                     1367        0.589 -0.9678947         <NA>   0.9690159 
INFO  [23:49:17.687] [bbotk]                                 uhash 
INFO  [23:49:17.687] [bbotk]  ccfb7f8d-df13-428a-80f8-366f58ec8918 
DEBUG [23:49:18.561] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.421017e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.421017e-05 0.0017416 
  - best initial criterion value(s) :  307.4214 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -307.42  |proj g|=       4.5719
At iterate     1  f =      -308.97  |proj g|=        5.5529
At iterate     2  f =      -324.12  |proj g|=        3.3862
At iterate     3  f =      -324.53  |proj g|=        2.8899
At iterate     4  f =      -327.18  |proj g|=        2.4099
At iterate     5  f =      -331.57  |proj g|=        2.3259
At iterate     6  f =         -332  |proj g|=        2.6611
At iterate     7  f =         -332  |proj g|=        2.6501
At iterate     8  f =         -332  |proj g|=        2.6706
At iterate     9  f =         -332  |proj g|=        2.6636
At iterate    10  f =         -332  |proj g|=        2.6623
At iterate    11  f =         -332  |proj g|=         2.658
At iterate    12  f =         -332  |proj g|=        2.6503
At iterate    13  f =      -332.01  |proj g|=        2.6381
At iterate    14  f =      -332.01  |proj g|=        2.6178
At iterate    15  f =      -332.02  |proj g|=        2.5843
At iterate    16  f =      -332.06  |proj g|=         2.536
At iterate    17  f =      -332.14  |proj g|=        2.4838
At iterate    18  f =       -332.3  |proj g|=        2.4041
At iterate    19  f =      -332.67  |proj g|=        2.2247
At iterate    20  f =      -333.43  |proj g|=        1.8381
At iterate    21  f =      -333.58  |proj g|=        2.0589
At iterate    22  f =      -334.99  |proj g|=        1.5147
At iterate    23  f =      -336.41  |proj g|=        2.1304
At iterate    24  f =      -336.42  |proj g|=        2.1574
At iterate    25  f =       -336.6  |proj g|=        2.6646
At iterate    26  f =      -336.61  |proj g|=        2.6629
At iterate    27  f =      -336.61  |proj g|=        2.6551
At iterate    28  f =      -336.61  |proj g|=        2.6567
At iterate    29  f =      -336.61  |proj g|=        2.6566

iterations 29
function evaluations 45
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.65656
final function value -336.608

F = -336.608
final  value -336.608114 
converged
 
INFO  [23:49:18.565] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:49:18.622] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:49:18.629] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:49:25.985] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:49:32.501] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:49:39.975] [mlr3]  Finished benchmark 
INFO  [23:49:40.044] [bbotk] Result of batch 55: 
INFO  [23:49:40.045] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:49:40.045] [bbotk]              7.506008                 9.263605                        0.461558 
INFO  [23:49:40.045] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:49:40.045] [bbotk]                     2658        0.583 -0.9622921         <NA>    0.975708 
INFO  [23:49:40.045] [bbotk]                                 uhash 
INFO  [23:49:40.045] [bbotk]  c4a93da7-91dc-4f00-adc1-9ed472eae996 
DEBUG [23:49:40.879] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.410387e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.410387e-05 0.001737795 
  - best initial criterion value(s) :  333.9043 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -333.9  |proj g|=       2.9523
At iterate     1  f =      -339.39  |proj g|=        2.4017
At iterate     2  f =      -342.12  |proj g|=        1.8946
At iterate     3  f =      -344.48  |proj g|=       0.79206
At iterate     4  f =      -344.53  |proj g|=       0.64265
At iterate     5  f =      -344.56  |proj g|=        0.6642
At iterate     6  f =      -344.63  |proj g|=        0.6994
At iterate     7  f =       -344.8  |proj g|=       0.81666
At iterate     8  f =      -345.03  |proj g|=       0.84891
At iterate     9  f =      -345.18  |proj g|=       0.60505
At iterate    10  f =      -345.18  |proj g|=       0.62379
At iterate    11  f =      -345.18  |proj g|=       0.63578
At iterate    12  f =      -345.18  |proj g|=       0.63657
At iterate    13  f =      -345.18  |proj g|=       0.63666

iterations 13
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.636656
final function value -345.181

F = -345.181
final  value -345.180774 
converged
 
INFO  [23:49:40.883] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:49:40.939] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:49:40.945] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:49:48.548] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:49:55.643] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:50:03.657] [mlr3]  Finished benchmark 
INFO  [23:50:03.723] [bbotk] Result of batch 56: 
INFO  [23:50:03.725] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:50:03.725] [bbotk]              9.786043                 7.628978                       0.2556023 
INFO  [23:50:03.725] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:50:03.725] [bbotk]                     2658        0.601 -0.9603463         <NA>   0.9743801 
INFO  [23:50:03.725] [bbotk]                                 uhash 
INFO  [23:50:03.725] [bbotk]  fafbec57-81b7-4eea-9a9d-ac676716423e 
DEBUG [23:50:04.600] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.397886e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.397886e-05 0.001735072 
  - best initial criterion value(s) :  326.3742 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -326.37  |proj g|=       2.3192
At iterate     1  f =      -326.79  |proj g|=         2.711
At iterate     2  f =      -326.81  |proj g|=        2.6713
At iterate     3  f =      -326.83  |proj g|=        2.6222
At iterate     4  f =      -326.87  |proj g|=        2.5524
At iterate     5  f =      -326.97  |proj g|=        2.3902
At iterate     6  f =      -327.17  |proj g|=        2.1314
At iterate     7  f =      -327.42  |proj g|=        1.8482
At iterate     8  f =      -327.52  |proj g|=        1.9295
At iterate     9  f =      -327.52  |proj g|=        1.9719
At iterate    10  f =      -327.52  |proj g|=        1.9696
At iterate    11  f =      -327.52  |proj g|=        1.9694
At iterate    12  f =      -327.52  |proj g|=        1.9691
At iterate    13  f =      -327.52  |proj g|=        1.9684
At iterate    14  f =      -327.52  |proj g|=        1.9674
At iterate    15  f =      -327.52  |proj g|=        1.9654
At iterate    16  f =      -327.52  |proj g|=        1.9606
At iterate    17  f =      -327.52  |proj g|=        1.9531
At iterate    18  f =      -327.52  |proj g|=        1.9328
At iterate    19  f =      -327.52  |proj g|=        1.9504
At iterate    20  f =      -327.53  |proj g|=         1.917
At iterate    21  f =      -332.09  |proj g|=       0.40153
At iterate    22  f =      -332.21  |proj g|=       0.45046
At iterate    23  f =      -332.28  |proj g|=       0.51019
At iterate    24  f =      -332.29  |proj g|=       0.51302
At iterate    25  f =      -332.29  |proj g|=       0.51339
At iterate    26  f =      -332.29  |proj g|=       0.51136
At iterate    27  f =      -332.29  |proj g|=       0.51092
At iterate    28  f =      -332.29  |proj g|=       0.51093

iterations 28
function evaluations 36
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.510931
final function value -332.289

F = -332.289
final  value -332.289466 
converged
 
INFO  [23:50:04.605] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:50:04.658] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:50:04.665] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:50:13.559] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:50:22.045] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:50:29.371] [mlr3]  Finished benchmark 
INFO  [23:50:29.461] [bbotk] Result of batch 57: 
INFO  [23:50:29.463] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:50:29.463] [bbotk]              8.828797                 4.226639                      0.02467172 
INFO  [23:50:29.463] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:50:29.463] [bbotk]                     2832        0.602 -0.9680195         <NA>    0.957175 
INFO  [23:50:29.463] [bbotk]                                 uhash 
INFO  [23:50:29.463] [bbotk]  52d43713-1ffb-4670-999c-bedd6e00294f 
DEBUG [23:50:30.374] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.396712e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.396712e-05 0.0017293 
  - best initial criterion value(s) :  338.0736 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -338.07  |proj g|=       1.3183
At iterate     1  f =      -346.81  |proj g|=        3.3957
At iterate     2  f =      -352.77  |proj g|=         2.632
At iterate     3  f =      -354.26  |proj g|=        1.8148
At iterate     4  f =      -354.42  |proj g|=         1.426
At iterate     5  f =      -354.59  |proj g|=        1.3722
At iterate     6  f =      -354.72  |proj g|=        1.2991
At iterate     7  f =      -354.72  |proj g|=        1.3118
At iterate     8  f =      -354.72  |proj g|=        1.3092
At iterate     9  f =      -354.72  |proj g|=        1.3097
At iterate    10  f =      -354.72  |proj g|=        1.3105
At iterate    11  f =      -354.72  |proj g|=        1.3115
At iterate    12  f =      -354.72  |proj g|=        1.3133
At iterate    13  f =      -354.72  |proj g|=        1.3162
At iterate    14  f =      -354.72  |proj g|=        1.3208
At iterate    15  f =      -354.72  |proj g|=         1.328
At iterate    16  f =      -354.72  |proj g|=         1.339
At iterate    17  f =      -354.72  |proj g|=        1.3542
At iterate    18  f =      -354.73  |proj g|=        1.3701
At iterate    19  f =      -354.74  |proj g|=        1.3705
At iterate    20  f =      -354.76  |proj g|=        1.3151
At iterate    21  f =      -354.77  |proj g|=         1.218
At iterate    22  f =      -354.78  |proj g|=         1.197
At iterate    23  f =       -355.1  |proj g|=       0.82529
At iterate    24  f =       -355.8  |proj g|=        0.7883
At iterate    25  f =      -360.25  |proj g|=       0.44766
At iterate    26  f =      -361.24  |proj g|=       0.43596
At iterate    27  f =      -361.35  |proj g|=       0.42524
At iterate    28  f =      -361.37  |proj g|=        0.5295
At iterate    29  f =      -361.37  |proj g|=       0.52823
At iterate    30  f =       -361.4  |proj g|=       0.51825
At iterate    31  f =      -361.41  |proj g|=       0.50698
At iterate    32  f =      -361.42  |proj g|=       0.19368
At iterate    33  f =      -361.42  |proj g|=      0.019935
At iterate    34  f =      -361.42  |proj g|=     0.0028425
At iterate    35  f =      -361.42  |proj g|=     0.0028425

iterations 35
function evaluations 40
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00284253
final function value -361.418

F = -361.418
final  value -361.417997 
converged
 
INFO  [23:50:30.378] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:50:30.434] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:50:30.441] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:50:38.591] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:50:46.313] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:50:54.501] [mlr3]  Finished benchmark 
INFO  [23:50:54.569] [bbotk] Result of batch 58: 
INFO  [23:50:54.571] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:50:54.571] [bbotk]              6.713127                 8.071502                      0.02349929 
INFO  [23:50:54.571] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:50:54.571] [bbotk]                     2703        0.618 -0.9549572         <NA>   0.9552701 
INFO  [23:50:54.571] [bbotk]                                 uhash 
INFO  [23:50:54.571] [bbotk]  3e4a3156-2f47-40bb-a53a-ea9c465d4e96 
DEBUG [23:50:55.544] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.400485e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.400485e-05 0.001736783 
  - best initial criterion value(s) :  338.1019 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -338.1  |proj g|=       3.3926
At iterate     1  f =       -349.5  |proj g|=        7.5244
At iterate     2  f =      -352.17  |proj g|=        6.2636
At iterate     3  f =      -353.61  |proj g|=        4.9679
At iterate     4  f =         -356  |proj g|=        3.1396
At iterate     5  f =      -356.38  |proj g|=        3.2529
At iterate     6  f =      -356.62  |proj g|=        3.1782
At iterate     7  f =      -356.62  |proj g|=        3.0873
At iterate     8  f =      -356.62  |proj g|=         3.094
At iterate     9  f =      -356.62  |proj g|=        3.0935
At iterate    10  f =      -356.62  |proj g|=         3.091
At iterate    11  f =      -356.62  |proj g|=        3.0876
At iterate    12  f =      -356.62  |proj g|=        3.0816
At iterate    13  f =      -356.62  |proj g|=        3.0722
At iterate    14  f =      -356.62  |proj g|=        3.0572
At iterate    15  f =      -356.62  |proj g|=        3.0353
At iterate    16  f =      -356.63  |proj g|=        3.0077
At iterate    17  f =      -356.65  |proj g|=        2.9907
At iterate    18  f =      -356.69  |proj g|=        3.0395
At iterate    19  f =      -356.73  |proj g|=        3.3084
At iterate    20  f =      -356.73  |proj g|=        3.2854
At iterate    21  f =      -356.76  |proj g|=        3.1468
At iterate    22  f =       -356.8  |proj g|=        2.9898
At iterate    23  f =      -356.97  |proj g|=        2.6397
At iterate    24  f =      -357.36  |proj g|=        2.1046
At iterate    25  f =      -358.23  |proj g|=        1.3889
At iterate    26  f =      -358.31  |proj g|=         1.077
At iterate    27  f =      -359.76  |proj g|=       0.74994
At iterate    28  f =      -362.24  |proj g|=       0.64128
At iterate    29  f =      -363.12  |proj g|=       0.63488
At iterate    30  f =      -363.57  |proj g|=       0.69382
At iterate    31  f =      -363.76  |proj g|=       0.77214
At iterate    32  f =      -363.82  |proj g|=       0.88866
At iterate    33  f =      -363.86  |proj g|=       0.90886
At iterate    34  f =      -363.86  |proj g|=       0.92306
At iterate    35  f =      -363.86  |proj g|=       0.92956
At iterate    36  f =      -363.86  |proj g|=       0.93165
At iterate    37  f =      -363.86  |proj g|=       0.93184
At iterate    38  f =      -363.86  |proj g|=       0.92924
At iterate    39  f =      -363.86  |proj g|=       0.92814
At iterate    40  f =      -363.86  |proj g|=       0.92589
At iterate    41  f =      -363.86  |proj g|=       0.92543
At iterate    42  f =       -365.4  |proj g|=       0.72599
At iterate    43  f =      -367.64  |proj g|=       0.50821
At iterate    44  f =      -367.65  |proj g|=       0.50761
At iterate    45  f =      -367.71  |proj g|=      0.040867
At iterate    46  f =      -367.72  |proj g|=       0.48087
At iterate    47  f =      -367.73  |proj g|=      0.028897
At iterate    48  f =      -367.73  |proj g|=      0.010379
At iterate    49  f =      -367.73  |proj g|=     0.0021381
At iterate    50  f =      -367.73  |proj g|=     0.0021382

iterations 50
function evaluations 68
segments explored during Cauchy searches 52
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00213817
final function value -367.731

F = -367.731
final  value -367.730778 
converged
 
INFO  [23:50:55.548] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:50:55.604] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:50:55.611] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:50:59.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:51:02.320] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:51:05.587] [mlr3]  Finished benchmark 
INFO  [23:51:05.655] [bbotk] Result of batch 59: 
INFO  [23:51:05.657] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:51:05.657] [bbotk]              8.246011                 2.173778                       0.0403868 
INFO  [23:51:05.657] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:51:05.657] [bbotk]                     1082        0.613 -0.9510429         <NA>   0.9507537 
INFO  [23:51:05.657] [bbotk]                                 uhash 
INFO  [23:51:05.657] [bbotk]  6be7db91-c94a-4b18-82fb-00bbb7f0188f 
DEBUG [23:51:06.581] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.419131e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.419131e-05 0.001758128 
  - best initial criterion value(s) :  353.9273 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -353.93  |proj g|=       2.2682
At iterate     1  f =      -354.56  |proj g|=        3.2556
At iterate     2  f =         -355  |proj g|=        3.0543
At iterate     3  f =      -355.59  |proj g|=        2.4398
At iterate     4  f =      -355.88  |proj g|=        2.5572
At iterate     5  f =       -356.3  |proj g|=        2.5565
At iterate     6  f =      -356.36  |proj g|=        2.5835
At iterate     7  f =      -356.36  |proj g|=         2.582
At iterate     8  f =      -356.36  |proj g|=        2.5799
At iterate     9  f =      -356.36  |proj g|=         2.582
At iterate    10  f =      -356.36  |proj g|=         2.581
At iterate    11  f =      -356.36  |proj g|=        2.5797
At iterate    12  f =      -356.36  |proj g|=        2.5761
At iterate    13  f =      -356.36  |proj g|=        2.5709
At iterate    14  f =      -356.37  |proj g|=        2.5614
At iterate    15  f =      -356.37  |proj g|=        2.5367
At iterate    16  f =      -356.39  |proj g|=        2.5523
At iterate    17  f =      -356.42  |proj g|=        2.4146
At iterate    18  f =      -357.42  |proj g|=        2.0815
At iterate    19  f =      -360.87  |proj g|=        1.3071
At iterate    20  f =      -365.03  |proj g|=       0.78064
At iterate    21  f =      -367.29  |proj g|=       0.78254
At iterate    22  f =         -368  |proj g|=       0.62557
At iterate    23  f =      -368.12  |proj g|=       0.83541
At iterate    24  f =      -368.31  |proj g|=       0.71456
At iterate    25  f =      -368.42  |proj g|=       0.57121
At iterate    26  f =      -368.42  |proj g|=       0.58081
At iterate    27  f =      -368.42  |proj g|=       0.58474
At iterate    28  f =      -368.42  |proj g|=       0.58898
At iterate    29  f =      -368.42  |proj g|=       0.58916

iterations 29
function evaluations 36
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.589164
final function value -368.424

F = -368.424
final  value -368.424112 
converged
 
INFO  [23:51:06.585] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:51:06.641] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:51:06.648] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:51:14.950] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:51:22.415] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:51:30.002] [mlr3]  Finished benchmark 
INFO  [23:51:30.074] [bbotk] Result of batch 60: 
INFO  [23:51:30.076] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:51:30.076] [bbotk]               3.24216                 2.552887                       0.0796633 
INFO  [23:51:30.076] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:51:30.076] [bbotk]                     2738        0.636 -0.9514262         <NA>   0.9611837 
INFO  [23:51:30.076] [bbotk]                                 uhash 
INFO  [23:51:30.076] [bbotk]  ffc254e9-4ff1-43d0-81e6-e994aed41106 
DEBUG [23:51:30.916] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.408694e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.408694e-05 0.001745488 
  - best initial criterion value(s) :  361.2218 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -361.22  |proj g|=       1.1679
At iterate     1  f =      -363.67  |proj g|=        1.9144
At iterate     2  f =      -363.94  |proj g|=        1.8098
At iterate     3  f =       -364.4  |proj g|=        1.4145
At iterate     4  f =      -364.43  |proj g|=        1.4701
At iterate     5  f =      -364.45  |proj g|=        1.5575
At iterate     6  f =      -364.45  |proj g|=        1.5677
At iterate     7  f =      -364.45  |proj g|=        1.5686
At iterate     8  f =      -364.45  |proj g|=        1.5687

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.56868
final function value -364.451

F = -364.451
final  value -364.450918 
converged
 
INFO  [23:51:30.920] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:51:30.975] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:51:30.982] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:51:33.845] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:51:36.603] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:51:40.292] [mlr3]  Finished benchmark 
INFO  [23:51:40.360] [bbotk] Result of batch 61: 
INFO  [23:51:40.362] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:51:40.362] [bbotk]              5.770205                  3.74731                       0.1004597 
INFO  [23:51:40.362] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:51:40.362] [bbotk]                     1130        0.618 -0.9600233         <NA>   0.9620318 
INFO  [23:51:40.362] [bbotk]                                 uhash 
INFO  [23:51:40.362] [bbotk]  51d2db83-4cf4-4516-9f2f-945e158803ea 
DEBUG [23:51:41.223] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.39718e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.39718e-05 0.001721315 
  - best initial criterion value(s) :  356.9741 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -356.97  |proj g|=      0.93221
At iterate     1  f =      -360.69  |proj g|=        4.0909
At iterate     2  f =      -362.15  |proj g|=         3.836
At iterate     3  f =      -364.14  |proj g|=        3.1305
At iterate     4  f =      -364.52  |proj g|=        2.2588
At iterate     5  f =      -364.76  |proj g|=        2.6539
At iterate     6  f =      -364.87  |proj g|=        2.7449
At iterate     7  f =      -364.99  |proj g|=         2.812
At iterate     8  f =         -365  |proj g|=        2.7624
At iterate     9  f =         -365  |proj g|=        2.7945
At iterate    10  f =         -365  |proj g|=         2.802
At iterate    11  f =         -365  |proj g|=        2.8023

iterations 11
function evaluations 16
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.80233
final function value -365

F = -365
final  value -364.999858 
converged
 
INFO  [23:51:41.227] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:51:41.284] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:51:41.291] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:51:45.061] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:51:47.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:51:50.351] [mlr3]  Finished benchmark 
INFO  [23:51:50.417] [bbotk] Result of batch 62: 
INFO  [23:51:50.419] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:51:50.419] [bbotk]              7.286502                 4.428549                       0.3376056 
INFO  [23:51:50.419] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:51:50.419] [bbotk]                      798        0.626 -0.9630941         <NA>   0.9699985 
INFO  [23:51:50.419] [bbotk]                                 uhash 
INFO  [23:51:50.419] [bbotk]  9b1cd895-d81d-4434-97f9-d46f7fde1f1c 
DEBUG [23:51:51.388] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.38242e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.38242e-05 0.001676398 
  - best initial criterion value(s) :  350.9292 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -350.93  |proj g|=       13.464
At iterate     1  f =      -368.48  |proj g|=        7.1351
At iterate     2  f =      -376.36  |proj g|=       0.85547
At iterate     3  f =      -378.35  |proj g|=        1.8133
At iterate     4  f =      -378.79  |proj g|=        1.3071
At iterate     5  f =      -378.97  |proj g|=        1.1099
At iterate     6  f =      -378.97  |proj g|=        1.1245
At iterate     7  f =      -378.97  |proj g|=        1.1244
At iterate     8  f =      -378.97  |proj g|=        1.1242
At iterate     9  f =      -378.98  |proj g|=        1.1238
At iterate    10  f =      -379.01  |proj g|=        1.1224
At iterate    11  f =      -379.08  |proj g|=        1.1193
At iterate    12  f =       -379.1  |proj g|=        1.1473
At iterate    13  f =      -379.28  |proj g|=        1.1275
At iterate    14  f =      -379.71  |proj g|=        1.0843
At iterate    15  f =      -380.41  |proj g|=        1.0059
At iterate    16  f =      -381.07  |proj g|=       0.91447
At iterate    17  f =      -381.47  |proj g|=       0.87143
At iterate    18  f =      -381.48  |proj g|=        0.9161
At iterate    19  f =      -381.74  |proj g|=       0.89818
At iterate    20  f =      -381.93  |proj g|=       0.96901
At iterate    21  f =      -381.97  |proj g|=       0.96887
At iterate    22  f =      -381.97  |proj g|=       0.96291
At iterate    23  f =      -381.97  |proj g|=       0.96867
At iterate    24  f =      -381.97  |proj g|=       0.97159
At iterate    25  f =      -381.97  |proj g|=       0.97203
At iterate    26  f =      -381.98  |proj g|=        0.9737
At iterate    27  f =      -381.99  |proj g|=        0.9767
At iterate    28  f =      -382.02  |proj g|=       0.99704
At iterate    29  f =      -382.07  |proj g|=       0.98948
At iterate    30  f =      -382.08  |proj g|=        1.0209
At iterate    31  f =      -382.34  |proj g|=       0.95649
At iterate    32  f =      -382.72  |proj g|=       0.87125
At iterate    33  f =      -383.38  |proj g|=       0.58011
At iterate    34  f =       -383.5  |proj g|=       0.53106
At iterate    35  f =      -384.08  |proj g|=       0.50166
At iterate    36  f =      -384.34  |proj g|=       0.52155
At iterate    37  f =      -384.45  |proj g|=       0.42354
At iterate    38  f =      -384.46  |proj g|=       0.40261
At iterate    39  f =      -384.46  |proj g|=      0.028016
At iterate    40  f =      -384.46  |proj g|=      0.005246
At iterate    41  f =      -384.46  |proj g|=     0.0039213

iterations 41
function evaluations 50
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00392126
final function value -384.461

F = -384.461
final  value -384.461057 
converged
 
INFO  [23:51:51.392] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:51:51.465] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:51:51.472] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:52:02.073] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:52:12.682] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:52:22.556] [mlr3]  Finished benchmark 
INFO  [23:52:22.642] [bbotk] Result of batch 63: 
INFO  [23:52:22.644] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:52:22.644] [bbotk]              8.092561                 8.823531                      0.06785361 
INFO  [23:52:22.644] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:52:22.644] [bbotk]                     3516        0.639 -0.9527582         <NA>   0.9694698 
INFO  [23:52:22.644] [bbotk]                                 uhash 
INFO  [23:52:22.644] [bbotk]  bbade287-7834-499e-a749-d39b26c6b742 
DEBUG [23:52:23.601] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.367776e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.367776e-05 0.001678464 
  - best initial criterion value(s) :  367.143 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -367.14  |proj g|=       5.3078
At iterate     1  f =      -372.31  |proj g|=        7.5484
At iterate     2  f =      -373.23  |proj g|=        7.2067
At iterate     3  f =      -375.26  |proj g|=        5.3391
At iterate     4  f =      -375.96  |proj g|=        4.1491
At iterate     5  f =      -376.66  |proj g|=        3.5416
At iterate     6  f =      -376.66  |proj g|=        3.4235
At iterate     7  f =      -376.66  |proj g|=        3.4155
At iterate     8  f =      -376.66  |proj g|=        3.4144
At iterate     9  f =      -376.66  |proj g|=        3.4052
At iterate    10  f =      -376.66  |proj g|=        3.3946
At iterate    11  f =      -376.66  |proj g|=        3.3745
At iterate    12  f =      -376.67  |proj g|=        3.3425
At iterate    13  f =      -376.67  |proj g|=        3.2874
At iterate    14  f =      -376.68  |proj g|=        3.2008
At iterate    15  f =       -376.7  |proj g|=        3.0948
At iterate    16  f =      -376.72  |proj g|=        2.9201
At iterate    17  f =      -376.78  |proj g|=        2.7974
At iterate    18  f =      -376.85  |proj g|=        2.4741
At iterate    19  f =      -377.26  |proj g|=        2.0793
At iterate    20  f =      -385.71  |proj g|=        0.8548
At iterate    21  f =       -386.7  |proj g|=       0.98613
At iterate    22  f =      -387.86  |proj g|=        1.2197
At iterate    23  f =      -388.22  |proj g|=        1.2002
At iterate    24  f =      -388.36  |proj g|=        1.2232
At iterate    25  f =       -389.1  |proj g|=        1.0853
At iterate    26  f =      -389.21  |proj g|=        1.1013
At iterate    27  f =      -389.29  |proj g|=        1.1289
At iterate    28  f =      -389.32  |proj g|=        1.1667
At iterate    29  f =      -389.32  |proj g|=        1.1632
At iterate    30  f =      -389.32  |proj g|=        1.1662
At iterate    31  f =      -389.32  |proj g|=        1.1667
At iterate    32  f =      -389.32  |proj g|=        1.1683
At iterate    33  f =      -389.32  |proj g|=        1.1685

iterations 33
function evaluations 43
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.16845
final function value -389.323

F = -389.323
final  value -389.322852 
converged
 
INFO  [23:52:23.605] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:52:23.659] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:52:23.666] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:52:35.328] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:52:47.113] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:53:00.060] [mlr3]  Finished benchmark 
INFO  [23:53:00.129] [bbotk] Result of batch 64: 
INFO  [23:53:00.131] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:53:00.131] [bbotk]              9.202268                 7.299002                       0.3845422 
INFO  [23:53:00.131] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:53:00.131] [bbotk]                     4162         0.64 -0.9468121         <NA>   0.9767698 
INFO  [23:53:00.131] [bbotk]                                 uhash 
INFO  [23:53:00.131] [bbotk]  abb839c5-79ce-4a37-b6f8-e553c708b7b0 
DEBUG [23:53:01.181] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.361241e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.361241e-05 0.001670808 
  - best initial criterion value(s) :  383.8495 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -383.85  |proj g|=         2.22
At iterate     1  f =      -390.87  |proj g|=        1.8237
At iterate     2  f =      -391.22  |proj g|=        1.6651
At iterate     3  f =       -391.8  |proj g|=       0.95788
At iterate     4  f =      -392.07  |proj g|=        0.9544
At iterate     5  f =      -392.08  |proj g|=       0.99194
At iterate     6  f =      -392.09  |proj g|=       0.97372
At iterate     7  f =      -392.09  |proj g|=       0.97395
At iterate     8  f =      -392.09  |proj g|=       0.97404
At iterate     9  f =      -392.09  |proj g|=       0.97404

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.974038
final function value -392.086

F = -392.086
final  value -392.085944 
converged
 
INFO  [23:53:01.185] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:53:01.240] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:53:01.246] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:53:09.663] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:53:17.494] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:53:25.054] [mlr3]  Finished benchmark 
INFO  [23:53:25.122] [bbotk] Result of batch 65: 
INFO  [23:53:25.124] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:53:25.124] [bbotk]              9.897508                 9.348143                       0.2470574 
INFO  [23:53:25.124] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:53:25.124] [bbotk]                     2762        0.644 -0.9557101         <NA>   0.9743624 
INFO  [23:53:25.124] [bbotk]                                 uhash 
INFO  [23:53:25.124] [bbotk]  c2cb0dda-6d43-402c-af4b-1312f2269ae6 
DEBUG [23:53:25.973] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.350951e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.350951e-05 0.001677842 
  - best initial criterion value(s) :  387.5471 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -387.55  |proj g|=      0.92823
At iterate     1  f =      -388.68  |proj g|=        2.9807
At iterate     2  f =      -391.76  |proj g|=         1.226
At iterate     3  f =      -392.25  |proj g|=        1.6375
At iterate     4  f =      -392.71  |proj g|=        1.4447
At iterate     5  f =       -392.8  |proj g|=        1.1797
At iterate     6  f =      -392.82  |proj g|=        1.1298
At iterate     7  f =      -392.82  |proj g|=        1.1512
At iterate     8  f =      -392.82  |proj g|=         1.148
At iterate     9  f =      -392.82  |proj g|=        1.1482

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.14823
final function value -392.821

F = -392.821
final  value -392.821442 
converged
 
INFO  [23:53:25.977] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:53:26.057] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:53:26.065] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:53:37.929] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:53:49.695] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:54:02.612] [mlr3]  Finished benchmark 
INFO  [23:54:02.680] [bbotk] Result of batch 66: 
INFO  [23:54:02.682] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:54:02.682] [bbotk]              7.570037                 9.391636                       0.4142608 
INFO  [23:54:02.682] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:54:02.682] [bbotk]                     4314        0.626 -0.9592534         <NA>   0.9767776 
INFO  [23:54:02.682] [bbotk]                                 uhash 
INFO  [23:54:02.682] [bbotk]  e643e570-8727-49e3-abd4-036000a16d2a 
DEBUG [23:54:03.633] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.344464e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.344464e-05 0.001670824 
  - best initial criterion value(s) :  378.476 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -378.48  |proj g|=        3.019
At iterate     1  f =       -380.5  |proj g|=         3.773
At iterate     2  f =      -383.58  |proj g|=        3.2958
At iterate     3  f =      -385.45  |proj g|=        2.2025
At iterate     4  f =      -385.76  |proj g|=        2.4507
At iterate     5  f =      -385.85  |proj g|=        2.4335
At iterate     6  f =      -385.87  |proj g|=        2.4113
At iterate     7  f =      -385.87  |proj g|=        2.3926
At iterate     8  f =      -385.87  |proj g|=        2.4037
At iterate     9  f =      -385.87  |proj g|=        2.4049
At iterate    10  f =      -385.87  |proj g|=        2.4066
At iterate    11  f =      -385.87  |proj g|=        2.4089
At iterate    12  f =      -385.87  |proj g|=         2.411
At iterate    13  f =      -385.87  |proj g|=        2.4103
At iterate    14  f =      -385.88  |proj g|=        2.4451
At iterate    15  f =      -385.88  |proj g|=        2.4342
At iterate    16  f =      -385.93  |proj g|=        2.3511
At iterate    17  f =      -386.03  |proj g|=        2.2483
At iterate    18  f =      -386.27  |proj g|=        2.0456
At iterate    19  f =      -386.79  |proj g|=        1.7618
At iterate    20  f =      -386.96  |proj g|=        1.4612
At iterate    21  f =      -388.14  |proj g|=        1.2081
At iterate    22  f =      -391.13  |proj g|=        1.0176
At iterate    23  f =      -394.96  |proj g|=        1.8513
At iterate    24  f =      -395.79  |proj g|=        1.6481
At iterate    25  f =      -396.15  |proj g|=        1.1708
At iterate    26  f =      -396.16  |proj g|=        1.1163
At iterate    27  f =      -396.16  |proj g|=        1.1361
At iterate    28  f =      -396.16  |proj g|=        1.1325
At iterate    29  f =      -396.16  |proj g|=        1.1338
At iterate    30  f =      -396.16  |proj g|=        1.1338

iterations 30
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.13382
final function value -396.158

F = -396.158
final  value -396.157804 
converged
 
INFO  [23:54:03.637] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:54:03.692] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:54:03.699] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:54:15.423] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:54:25.046] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:54:33.975] [mlr3]  Finished benchmark 
INFO  [23:54:34.128] [bbotk] Result of batch 67: 
INFO  [23:54:34.130] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:54:34.130] [bbotk]              5.347519                 9.895479                       0.2711931 
INFO  [23:54:34.130] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:54:34.130] [bbotk]                     3547        0.658 -0.9606559         <NA>   0.9748981 
INFO  [23:54:34.130] [bbotk]                                 uhash 
INFO  [23:54:34.130] [bbotk]  a222fcdb-d315-4d19-ba3b-af8ff3acd780 
DEBUG [23:54:35.011] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.335061e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.60747 15.88239 0.9518914 9504 
  - variance bounds :  1.335061e-05 0.00167848 
  - best initial criterion value(s) :  391.1242 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -391.12  |proj g|=       1.4998
At iterate     1  f =      -396.11  |proj g|=        2.1001
At iterate     2  f =      -396.13  |proj g|=        2.0801
At iterate     3  f =      -396.23  |proj g|=        1.9968
At iterate     4  f =      -396.33  |proj g|=        1.9501
At iterate     5  f =      -396.72  |proj g|=        1.8615
At iterate     6  f =       -397.2  |proj g|=        1.8681
At iterate     7  f =       -397.6  |proj g|=        2.1505
At iterate     8  f =      -397.63  |proj g|=        2.1615
At iterate     9  f =      -397.63  |proj g|=        2.1822
At iterate    10  f =      -397.63  |proj g|=        2.1724
At iterate    11  f =      -397.63  |proj g|=        2.1714
At iterate    12  f =      -397.63  |proj g|=        2.1714

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.17144
final function value -397.633

F = -397.633
final  value -397.633080 
converged
 
INFO  [23:54:35.015] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:54:35.072] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:54:35.079] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:54:39.657] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:54:44.473] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:54:49.441] [mlr3]  Finished benchmark 
INFO  [23:54:49.525] [bbotk] Result of batch 68: 
INFO  [23:54:49.527] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:54:49.527] [bbotk]              2.092205                 5.460877                       0.2935752 
INFO  [23:54:49.527] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:54:49.527] [bbotk]                     1767        0.644 -0.9602927         <NA>   0.9584256 
INFO  [23:54:49.527] [bbotk]                                 uhash 
INFO  [23:54:49.527] [bbotk]  ece202f3-ff36-4753-a610-90ae9d1671f6 
DEBUG [23:54:50.517] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.331399e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.331399e-05 0.001662567 
  - best initial criterion value(s) :  386.8789 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -386.88  |proj g|=       4.7435
At iterate     1  f =      -396.95  |proj g|=         1.594
At iterate     2  f =      -399.23  |proj g|=        2.9114
At iterate     3  f =      -400.13  |proj g|=        2.6009
At iterate     4  f =      -401.03  |proj g|=        2.0716
At iterate     5  f =      -401.51  |proj g|=        2.2821
At iterate     6  f =         -402  |proj g|=        2.4872
At iterate     7  f =      -402.07  |proj g|=         2.782
At iterate     8  f =       -402.1  |proj g|=        2.7328
At iterate     9  f =       -402.1  |proj g|=        2.7203
At iterate    10  f =       -402.1  |proj g|=        2.7226
At iterate    11  f =       -402.1  |proj g|=        2.7374
At iterate    12  f =      -402.11  |proj g|=        2.7543
At iterate    13  f =      -402.12  |proj g|=        2.7734
At iterate    14  f =      -402.15  |proj g|=        2.7964
At iterate    15  f =      -402.23  |proj g|=        2.7682
At iterate    16  f =      -402.39  |proj g|=        2.7193
At iterate    17  f =      -402.66  |proj g|=        2.2885
At iterate    18  f =      -403.08  |proj g|=        2.3009
At iterate    19  f =      -403.83  |proj g|=        2.1792
At iterate    20  f =      -410.87  |proj g|=         1.561
At iterate    21  f =      -414.87  |proj g|=         1.611
At iterate    22  f =      -417.01  |proj g|=        1.3251
At iterate    23  f =      -417.39  |proj g|=        1.1693
At iterate    24  f =      -417.53  |proj g|=        1.1219
At iterate    25  f =      -417.54  |proj g|=        1.1315
At iterate    26  f =      -417.55  |proj g|=         1.145
At iterate    27  f =      -417.89  |proj g|=        1.0557
At iterate    28  f =      -419.19  |proj g|=       0.53329
At iterate    29  f =      -419.56  |proj g|=       0.49805
At iterate    30  f =      -419.67  |proj g|=       0.49664
At iterate    31  f =      -419.72  |proj g|=       0.10031
At iterate    32  f =       -419.8  |proj g|=       0.45786
At iterate    33  f =      -419.81  |proj g|=      0.045929
At iterate    34  f =      -419.81  |proj g|=      0.020614
At iterate    35  f =      -419.81  |proj g|=     0.0043697
At iterate    36  f =      -419.81  |proj g|=      0.001338

iterations 36
function evaluations 52
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00133805
final function value -419.807

F = -419.807
final  value -419.806838 
converged
 
INFO  [23:54:50.521] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:54:50.574] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:54:50.581] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:55:02.106] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:55:11.709] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:55:21.211] [mlr3]  Finished benchmark 
INFO  [23:55:21.308] [bbotk] Result of batch 69: 
INFO  [23:55:21.310] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:55:21.310] [bbotk]              2.973568                 7.143977                      0.03840735 
INFO  [23:55:21.310] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:55:21.310] [bbotk]                     4681        0.642 -0.9448386         <NA>   0.9560915 
INFO  [23:55:21.310] [bbotk]                                 uhash 
INFO  [23:55:21.310] [bbotk]  b31317c0-44ae-4d61-bda4-2e60125db0f2 
DEBUG [23:55:22.187] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.332747e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.332747e-05 0.001653023 
  - best initial criterion value(s) :  406.5444 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -406.54  |proj g|=       1.1086
At iterate     1  f =      -406.98  |proj g|=        2.7489
At iterate     2  f =      -410.26  |proj g|=        1.4363
At iterate     3  f =      -410.35  |proj g|=        1.2037
At iterate     4  f =      -410.36  |proj g|=         1.207
At iterate     5  f =      -410.37  |proj g|=        1.2243
At iterate     6  f =      -410.37  |proj g|=        1.2221
At iterate     7  f =      -410.37  |proj g|=         1.222

iterations 7
function evaluations 13
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.22204
final function value -410.366

F = -410.366
final  value -410.366483 
converged
 
INFO  [23:55:22.192] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:55:22.255] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:55:22.263] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:55:24.018] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:55:25.770] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:55:27.511] [mlr3]  Finished benchmark 
INFO  [23:55:27.587] [bbotk] Result of batch 70: 
INFO  [23:55:27.589] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:55:27.589] [bbotk]              9.650645                 6.351554                      0.08344479 
INFO  [23:55:27.589] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:55:27.589] [bbotk]                      734        0.651 -0.9594285         <NA>   0.9556239 
INFO  [23:55:27.589] [bbotk]                                 uhash 
INFO  [23:55:27.589] [bbotk]  c3e9902f-acb0-4215-8da3-080269aeacf4 
DEBUG [23:55:28.678] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.334915e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.334915e-05 0.001651757 
  - best initial criterion value(s) :  375.1917 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -375.19  |proj g|=       7.1886
At iterate     1  f =      -387.35  |proj g|=        9.5266
At iterate     2  f =      -401.27  |proj g|=        8.0338
At iterate     3  f =      -403.69  |proj g|=        4.5114
At iterate     4  f =      -408.22  |proj g|=        2.9458
At iterate     5  f =      -408.25  |proj g|=        2.6191
At iterate     6  f =      -408.26  |proj g|=        2.6221
At iterate     7  f =      -408.26  |proj g|=        2.6234
At iterate     8  f =      -408.26  |proj g|=        2.6301
At iterate     9  f =      -408.26  |proj g|=        2.6389
At iterate    10  f =      -408.26  |proj g|=        2.6629
At iterate    11  f =      -408.26  |proj g|=        2.6917
At iterate    12  f =      -408.28  |proj g|=        2.8274
At iterate    13  f =       -408.3  |proj g|=         2.779
At iterate    14  f =      -408.34  |proj g|=        2.8233
At iterate    15  f =      -408.73  |proj g|=        2.9376
At iterate    16  f =      -409.53  |proj g|=        2.9044
At iterate    17  f =      -411.33  |proj g|=        2.5452
At iterate    18  f =      -414.15  |proj g|=        1.8437
At iterate    19  f =         -417  |proj g|=        1.3764
At iterate    20  f =      -417.63  |proj g|=        1.2874
At iterate    21  f =      -417.74  |proj g|=        1.1873
At iterate    22  f =      -417.74  |proj g|=        1.1877
At iterate    23  f =      -417.74  |proj g|=        1.1805
At iterate    24  f =      -417.74  |proj g|=        1.1799
At iterate    25  f =      -417.74  |proj g|=          1.18

iterations 25
function evaluations 34
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.18002
final function value -417.738

F = -417.738
final  value -417.738103 
converged
 
INFO  [23:55:28.683] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:55:28.746] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:55:28.755] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:55:30.917] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:55:32.904] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:55:34.945] [mlr3]  Finished benchmark 
INFO  [23:55:35.024] [bbotk] Result of batch 71: 
INFO  [23:55:35.026] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:55:35.026] [bbotk]              7.099802                  8.33108                       0.1549637 
INFO  [23:55:35.026] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:55:35.026] [bbotk]                      952        0.745 -0.9559874         <NA>   0.9654374 
INFO  [23:55:35.026] [bbotk]                                 uhash 
INFO  [23:55:35.026] [bbotk]  40a67cc0-6eaf-4211-bf20-4945bd768aca 
DEBUG [23:55:36.198] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.322348e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.322348e-05 0.001622792 
  - best initial criterion value(s) :  384.0232 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -384.02  |proj g|=       5.8485
At iterate     1  f =      -405.87  |proj g|=        3.6447
At iterate     2  f =      -408.05  |proj g|=        3.3964
At iterate     3  f =      -410.57  |proj g|=        2.1425
At iterate     4  f =      -411.23  |proj g|=        2.5768
At iterate     5  f =      -412.82  |proj g|=        2.6929
At iterate     6  f =      -415.25  |proj g|=        2.5097
At iterate     7  f =      -415.26  |proj g|=        2.5921
At iterate     8  f =      -415.72  |proj g|=        2.4859
At iterate     9  f =      -415.72  |proj g|=        2.4846
At iterate    10  f =      -415.72  |proj g|=        2.4853
At iterate    11  f =      -415.72  |proj g|=         2.488
At iterate    12  f =      -415.72  |proj g|=        2.4866
At iterate    13  f =      -415.72  |proj g|=        2.4845
At iterate    14  f =      -416.25  |proj g|=        2.4738
At iterate    15  f =      -416.82  |proj g|=         2.471
At iterate    16  f =      -416.86  |proj g|=        2.4842
At iterate    17  f =      -416.86  |proj g|=        2.4926
At iterate    18  f =      -416.86  |proj g|=        2.4951
At iterate    19  f =      -416.86  |proj g|=        2.4961
At iterate    20  f =      -416.86  |proj g|=        2.4964
At iterate    21  f =      -416.86  |proj g|=        2.4979
At iterate    22  f =      -416.86  |proj g|=        2.4996
At iterate    23  f =      -416.86  |proj g|=        2.5029
At iterate    24  f =      -416.86  |proj g|=        2.5076
At iterate    25  f =      -416.86  |proj g|=        2.5148
At iterate    26  f =      -416.86  |proj g|=        2.5237
At iterate    27  f =      -416.86  |proj g|=        2.5288
At iterate    28  f =      -416.87  |proj g|=        2.5042
At iterate    29  f =      -416.87  |proj g|=        2.5007
At iterate    30  f =      -416.87  |proj g|=        2.4986
At iterate    31  f =      -416.87  |proj g|=        2.4941
At iterate    32  f =      -416.87  |proj g|=        2.4874
At iterate    33  f =      -416.87  |proj g|=        2.4764
At iterate    34  f =      -416.87  |proj g|=        2.4629
At iterate    35  f =      -416.88  |proj g|=        2.4498
At iterate    36  f =      -416.88  |proj g|=         2.452
At iterate    37  f =      -416.89  |proj g|=        2.5239
At iterate    38  f =      -416.89  |proj g|=        2.5045
At iterate    39  f =      -416.89  |proj g|=         2.496
At iterate    40  f =       -416.9  |proj g|=        2.4688
At iterate    41  f =      -416.91  |proj g|=        2.4297
At iterate    42  f =      -416.95  |proj g|=         2.359
At iterate    43  f =      -417.04  |proj g|=        2.2501
At iterate    44  f =      -417.29  |proj g|=        2.0833
At iterate    45  f =      -417.83  |proj g|=        1.9154
At iterate    46  f =      -418.79  |proj g|=        1.7242
At iterate    47  f =      -418.92  |proj g|=        1.5071
At iterate    48  f =      -421.63  |proj g|=        1.3121
At iterate    49  f =      -427.15  |proj g|=       0.68787
At iterate    50  f =      -428.97  |proj g|=       0.67064
At iterate    51  f =      -429.37  |proj g|=       0.56351
At iterate    52  f =      -429.53  |proj g|=       0.39242
At iterate    53  f =      -429.55  |proj g|=       0.32871
At iterate    54  f =      -429.55  |proj g|=        0.3123
At iterate    55  f =      -429.55  |proj g|=       0.31056
At iterate    56  f =      -429.55  |proj g|=        0.3107

iterations 56
function evaluations 67
segments explored during Cauchy searches 58
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.310696
final function value -429.55

F = -429.55
final  value -429.550117 
converged
 
INFO  [23:55:36.202] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:55:36.257] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:55:36.265] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:55:39.909] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:55:43.507] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:55:47.079] [mlr3]  Finished benchmark 
INFO  [23:55:47.151] [bbotk] Result of batch 72: 
INFO  [23:55:47.153] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:55:47.153] [bbotk]               8.86748                 6.962385                       0.4660234 
INFO  [23:55:47.153] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:55:47.153] [bbotk]                     1907        0.697 -0.9485117         <NA>   0.9751727 
INFO  [23:55:47.153] [bbotk]                                 uhash 
INFO  [23:55:47.153] [bbotk]  7f802f03-0004-4811-a0f6-2121bb4e36df 
DEBUG [23:55:48.573] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.314399e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.314399e-05 0.001604803 
  - best initial criterion value(s) :  405.3097 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -405.31  |proj g|=       3.4548
At iterate     1  f =      -413.22  |proj g|=        1.4757
At iterate     2  f =      -415.92  |proj g|=        2.5649
At iterate     3  f =      -416.75  |proj g|=        2.5942
At iterate     4  f =         -417  |proj g|=        3.1525
At iterate     5  f =      -417.29  |proj g|=        2.8755
At iterate     6  f =      -417.35  |proj g|=        2.6726
At iterate     7  f =      -417.35  |proj g|=        2.6879
At iterate     8  f =      -417.35  |proj g|=        2.6901
At iterate     9  f =      -417.35  |proj g|=        2.6783
At iterate    10  f =      -417.36  |proj g|=        2.6629
At iterate    11  f =      -417.42  |proj g|=        2.6069
At iterate    12  f =      -417.54  |proj g|=        2.5971
At iterate    13  f =      -417.67  |proj g|=        2.2157
At iterate    14  f =      -417.97  |proj g|=        2.1681
At iterate    15  f =      -419.62  |proj g|=        1.6966
At iterate    16  f =       -422.2  |proj g|=        1.1217
At iterate    17  f =      -424.99  |proj g|=        1.0783
At iterate    18  f =      -426.35  |proj g|=        1.0489
At iterate    19  f =      -426.56  |proj g|=       0.89325
At iterate    20  f =      -426.91  |proj g|=        0.8081
At iterate    21  f =      -427.05  |proj g|=       0.88631
At iterate    22  f =      -427.07  |proj g|=       0.89428
At iterate    23  f =      -427.07  |proj g|=       0.88602
At iterate    24  f =      -427.07  |proj g|=       0.88577
At iterate    25  f =      -427.07  |proj g|=       0.88566

iterations 25
function evaluations 32
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.885664
final function value -427.066

F = -427.066
final  value -427.066293 
converged
 
INFO  [23:55:48.575] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:55:48.619] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:55:48.626] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:55:54.969] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:56:01.507] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:56:07.924] [mlr3]  Finished benchmark 
INFO  [23:56:07.993] [bbotk] Result of batch 73: 
INFO  [23:56:07.995] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:56:07.995] [bbotk]              3.548645                 8.263418                        0.261099 
INFO  [23:56:07.995] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:56:07.995] [bbotk]                     3233        0.858 -0.9549481         <NA>   0.9713369 
INFO  [23:56:07.995] [bbotk]                                 uhash 
INFO  [23:56:07.995] [bbotk]  fbfe093a-a1b3-45c8-8450-9b1a46debecd 
DEBUG [23:56:08.964] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.302674e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.302674e-05 0.001598867 
  - best initial criterion value(s) :  414.7943 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -414.79  |proj g|=       3.9005
At iterate     1  f =      -430.22  |proj g|=        2.7707
At iterate     2  f =      -430.39  |proj g|=        2.5559
At iterate     3  f =      -430.66  |proj g|=        1.9236
At iterate     4  f =      -431.14  |proj g|=        1.6162
At iterate     5  f =      -433.14  |proj g|=        0.9908
At iterate     6  f =      -433.22  |proj g|=        2.2449
At iterate     7  f =      -434.67  |proj g|=        1.3052
At iterate     8  f =      -434.99  |proj g|=        1.0121
At iterate     9  f =      -435.07  |proj g|=       0.98767
At iterate    10  f =       -435.1  |proj g|=       0.99559
At iterate    11  f =      -435.11  |proj g|=         1.014
At iterate    12  f =      -435.11  |proj g|=        1.0263
At iterate    13  f =      -435.11  |proj g|=        1.0276
At iterate    14  f =      -435.11  |proj g|=        1.0279
At iterate    15  f =      -435.11  |proj g|=        1.0283
At iterate    16  f =      -435.11  |proj g|=        1.0294
At iterate    17  f =      -435.11  |proj g|=        1.0304
At iterate    18  f =      -435.11  |proj g|=        1.0312
At iterate    19  f =      -435.11  |proj g|=         1.034
At iterate    20  f =      -435.11  |proj g|=        1.0366
At iterate    21  f =      -435.12  |proj g|=        1.0376
At iterate    22  f =      -435.12  |proj g|=        1.0468
At iterate    23  f =      -435.13  |proj g|=        1.0471
At iterate    24  f =      -436.11  |proj g|=         1.097
At iterate    25  f =      -436.22  |proj g|=        1.0914
At iterate    26  f =      -436.23  |proj g|=         1.085
At iterate    27  f =      -436.23  |proj g|=         1.085
At iterate    28  f =      -436.23  |proj g|=        1.0852

iterations 28
function evaluations 39
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.08523
final function value -436.228

F = -436.228
final  value -436.228211 
converged
 
INFO  [23:56:08.969] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:56:09.027] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:56:09.035] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:56:11.859] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:56:14.905] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:56:19.366] [mlr3]  Finished benchmark 
INFO  [23:56:19.436] [bbotk] Result of batch 74: 
INFO  [23:56:19.437] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:56:19.437] [bbotk]              8.771112                 2.337592                      0.06323759 
INFO  [23:56:19.437] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:56:19.437] [bbotk]                     1434        0.643 -0.9537498         <NA>   0.9606576 
INFO  [23:56:19.437] [bbotk]                                 uhash 
INFO  [23:56:19.437] [bbotk]  d5e35c07-34af-4a29-b2fa-85031cfd4580 
DEBUG [23:56:20.574] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.295404e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.295404e-05 0.00159135 
  - best initial criterion value(s) :  417.603 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -417.6  |proj g|=        3.824
At iterate     1  f =      -419.02  |proj g|=        2.7244
At iterate     2  f =      -421.74  |proj g|=        2.4473
At iterate     3  f =      -422.91  |proj g|=        2.1127
At iterate     4  f =      -423.05  |proj g|=        1.9727
At iterate     5  f =       -423.5  |proj g|=        1.8698
At iterate     6  f =      -424.45  |proj g|=        1.8339
At iterate     7  f =      -425.09  |proj g|=        2.1121
At iterate     8  f =      -425.15  |proj g|=         2.136
At iterate     9  f =      -425.15  |proj g|=        2.1797
At iterate    10  f =      -425.16  |proj g|=        2.1633
At iterate    11  f =      -425.16  |proj g|=        2.1573
At iterate    12  f =      -425.16  |proj g|=        2.1461
At iterate    13  f =      -425.16  |proj g|=         2.129
At iterate    14  f =      -425.18  |proj g|=        2.1011
At iterate    15  f =      -425.22  |proj g|=        2.0591
At iterate    16  f =      -425.31  |proj g|=        1.9961
At iterate    17  f =      -425.54  |proj g|=        1.9296
At iterate    18  f =      -425.97  |proj g|=        1.9132
At iterate    19  f =      -426.02  |proj g|=        1.7628
At iterate    20  f =      -426.77  |proj g|=        1.7402
At iterate    21  f =      -429.89  |proj g|=        1.6611
At iterate    22  f =      -430.09  |proj g|=        1.6912
At iterate    23  f =      -430.14  |proj g|=        1.7035
At iterate    24  f =      -430.14  |proj g|=        1.6931
At iterate    25  f =      -430.14  |proj g|=        1.6951
At iterate    26  f =      -430.14  |proj g|=        1.6954
At iterate    27  f =      -430.14  |proj g|=        1.6954
At iterate    28  f =      -430.14  |proj g|=        1.6954
At iterate    29  f =      -430.14  |proj g|=        1.6952
At iterate    30  f =      -430.14  |proj g|=         1.695
At iterate    31  f =      -430.14  |proj g|=        1.6952
At iterate    32  f =      -430.14  |proj g|=         1.694
At iterate    33  f =      -430.14  |proj g|=        1.6943
At iterate    34  f =      -430.14  |proj g|=        1.6947
At iterate    35  f =      -430.14  |proj g|=        1.6945
At iterate    36  f =      -430.14  |proj g|=        1.6932
At iterate    37  f =      -430.14  |proj g|=        1.6921
At iterate    38  f =      -430.14  |proj g|=        1.6904
At iterate    39  f =      -430.14  |proj g|=         1.685
At iterate    40  f =      -430.14  |proj g|=        1.6844
At iterate    41  f =      -430.14  |proj g|=        1.6824
At iterate    42  f =      -430.15  |proj g|=        1.6801
At iterate    43  f =      -430.16  |proj g|=        1.6767
At iterate    44  f =      -430.22  |proj g|=        1.6632
At iterate    45  f =      -430.22  |proj g|=        1.7199
At iterate    46  f =      -430.51  |proj g|=        1.6205
At iterate    47  f =      -430.98  |proj g|=        1.4774
At iterate    48  f =      -431.88  |proj g|=         1.219
At iterate    49  f =      -432.91  |proj g|=       0.93442
At iterate    50  f =      -434.03  |proj g|=       0.70667
At iterate    51  f =      -434.16  |proj g|=       0.81054
At iterate    52  f =      -435.24  |proj g|=       0.70251
At iterate    53  f =      -436.39  |proj g|=       0.63108
At iterate    54  f =      -437.39  |proj g|=        1.0497
At iterate    55  f =      -437.66  |proj g|=       0.47418
At iterate    56  f =      -437.74  |proj g|=       0.48202
At iterate    57  f =      -437.95  |proj g|=       0.74931
At iterate    58  f =      -438.12  |proj g|=       0.51374
At iterate    59  f =      -438.37  |proj g|=       0.15417
At iterate    60  f =      -438.37  |proj g|=      0.016889
At iterate    61  f =      -438.37  |proj g|=      0.008506
At iterate    62  f =      -438.37  |proj g|=     0.0063243

iterations 62
function evaluations 76
segments explored during Cauchy searches 64
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00632426
final function value -438.372

F = -438.372
final  value -438.371566 
converged
 
INFO  [23:56:20.578] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:56:20.634] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:56:20.641] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:56:29.271] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:56:38.577] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:56:48.572] [mlr3]  Finished benchmark 
INFO  [23:56:48.641] [bbotk] Result of batch 75: 
INFO  [23:56:48.643] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:56:48.643] [bbotk]              3.512788                 3.263406                       0.3122358 
INFO  [23:56:48.643] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:56:48.643] [bbotk]                     3538        0.671 -0.9574284         <NA>   0.9723399 
INFO  [23:56:48.643] [bbotk]                                 uhash 
INFO  [23:56:48.643] [bbotk]  358d6dba-db36-4c70-9e7d-f0005f4f062e 
DEBUG [23:56:49.589] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.284831e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.284831e-05 0.001585405 
  - best initial criterion value(s) :  428.2213 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -428.22  |proj g|=       2.5595
At iterate     1  f =      -439.65  |proj g|=        3.0312
At iterate     2  f =      -439.89  |proj g|=        2.7841
At iterate     3  f =      -440.14  |proj g|=         2.156
At iterate     4  f =      -440.38  |proj g|=        2.3612
At iterate     5  f =      -441.27  |proj g|=        2.4546
At iterate     6  f =      -442.58  |proj g|=        2.1511
At iterate     7  f =      -442.69  |proj g|=        1.8054
At iterate     8  f =      -443.22  |proj g|=        1.6104
At iterate     9  f =      -443.35  |proj g|=        1.4729
At iterate    10  f =      -443.53  |proj g|=        1.3767
At iterate    11  f =      -444.18  |proj g|=       0.99418
At iterate    12  f =      -444.47  |proj g|=        1.0345
At iterate    13  f =      -444.51  |proj g|=       0.97738
At iterate    14  f =      -444.63  |proj g|=        1.0127
At iterate    15  f =      -444.65  |proj g|=        1.0211
At iterate    16  f =      -444.65  |proj g|=        1.0126
At iterate    17  f =      -444.66  |proj g|=        1.0184
At iterate    18  f =      -444.66  |proj g|=        1.0177
At iterate    19  f =      -444.66  |proj g|=        1.0177

iterations 19
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.01774
final function value -444.655

F = -444.655
final  value -444.655246 
converged
 
INFO  [23:56:49.593] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:56:49.653] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:56:49.660] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:56:57.433] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:57:04.084] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:57:12.082] [mlr3]  Finished benchmark 
INFO  [23:57:12.153] [bbotk] Result of batch 76: 
INFO  [23:57:12.155] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:57:12.155] [bbotk]              3.790473                 6.997862                       0.4715727 
INFO  [23:57:12.155] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:57:12.155] [bbotk]                     2865        0.657 -0.9566682         <NA>   0.9738054 
INFO  [23:57:12.155] [bbotk]                                 uhash 
INFO  [23:57:12.155] [bbotk]  9c7f46d1-6d3b-4e16-beee-6aff350ef7ed 
DEBUG [23:57:13.170] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.275799e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9518914 9504 
  - variance bounds :  1.275799e-05 0.001581626 
  - best initial criterion value(s) :  415.2363 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -415.24  |proj g|=       4.6065
At iterate     1  f =      -436.11  |proj g|=        9.7241
At iterate     2  f =      -440.07  |proj g|=        8.1668
At iterate     3  f =      -442.74  |proj g|=        3.3033
At iterate     4  f =      -443.63  |proj g|=        5.2286
At iterate     5  f =      -443.76  |proj g|=        4.9438
At iterate     6  f =      -444.23  |proj g|=        4.1228
At iterate     7  f =      -444.88  |proj g|=        3.4723
At iterate     8  f =      -445.99  |proj g|=        3.8859
At iterate     9  f =      -446.21  |proj g|=        3.2565
At iterate    10  f =      -446.23  |proj g|=        3.1252
At iterate    11  f =      -446.24  |proj g|=        3.1154
At iterate    12  f =      -446.24  |proj g|=        3.1338
At iterate    13  f =      -446.24  |proj g|=        3.1408
At iterate    14  f =      -446.24  |proj g|=        3.1436
At iterate    15  f =      -446.24  |proj g|=        3.1505
At iterate    16  f =      -446.24  |proj g|=        3.1559
At iterate    17  f =      -446.24  |proj g|=        3.1559
At iterate    18  f =      -446.25  |proj g|=        3.1318
At iterate    19  f =      -446.26  |proj g|=        3.0554
At iterate    20  f =      -446.26  |proj g|=        3.0053
At iterate    21  f =      -446.27  |proj g|=        2.9126
At iterate    22  f =      -446.28  |proj g|=        2.8222
At iterate    23  f =      -446.32  |proj g|=        2.6847
At iterate    24  f =       -446.4  |proj g|=        2.4571
At iterate    25  f =      -446.62  |proj g|=        2.0866
At iterate    26  f =      -447.16  |proj g|=        1.5252
At iterate    27  f =      -448.36  |proj g|=        1.0247
At iterate    28  f =      -450.55  |proj g|=       0.84139
At iterate    29  f =      -454.16  |proj g|=        1.0508
At iterate    30  f =      -455.32  |proj g|=        1.1319
At iterate    31  f =      -455.72  |proj g|=        1.3362
At iterate    32  f =      -456.08  |proj g|=        1.3091
At iterate    33  f =      -456.33  |proj g|=        1.2393
At iterate    34  f =      -456.36  |proj g|=        1.2537
At iterate    35  f =      -456.36  |proj g|=        1.2585
At iterate    36  f =      -456.36  |proj g|=        1.2555
At iterate    37  f =      -456.36  |proj g|=        1.2563
At iterate    38  f =      -456.36  |proj g|=        1.2563

iterations 38
function evaluations 42
segments explored during Cauchy searches 41
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.25625
final function value -456.359

F = -456.359
final  value -456.358861 
converged
 
INFO  [23:57:13.175] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:57:13.235] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:57:13.242] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:57:19.682] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:57:24.820] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:57:30.297] [mlr3]  Finished benchmark 
INFO  [23:57:30.367] [bbotk] Result of batch 77: 
INFO  [23:57:30.369] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:57:30.369] [bbotk]              4.325831                 5.679778                       0.4977645 
INFO  [23:57:30.369] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [23:57:30.369] [bbotk]                     2014        0.662  -0.94951         <NA>   0.9738897 
INFO  [23:57:30.369] [bbotk]                                 uhash 
INFO  [23:57:30.369] [bbotk]  1fa69b18-30ad-4647-b419-567426a80c9f 
DEBUG [23:57:31.317] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.266968e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9632324 9504 
  - variance bounds :  1.266968e-05 0.001560393 
  - best initial criterion value(s) :  427.8287 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -427.83  |proj g|=       4.3636
At iterate     1  f =      -445.64  |proj g|=        2.4908
At iterate     2  f =      -449.71  |proj g|=        1.5793
At iterate     3  f =      -450.34  |proj g|=        1.3491
At iterate     4  f =      -450.43  |proj g|=        1.3054
At iterate     5  f =      -450.46  |proj g|=        1.3451
At iterate     6  f =      -450.46  |proj g|=        1.3524
At iterate     7  f =      -450.46  |proj g|=        1.3522

iterations 7
function evaluations 11
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.35217
final function value -450.464

F = -450.464
final  value -450.464343 
converged
 
INFO  [23:57:31.322] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:57:31.379] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:57:31.386] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:57:40.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:57:49.221] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:57:58.842] [mlr3]  Finished benchmark 
INFO  [23:57:58.915] [bbotk] Result of batch 78: 
INFO  [23:57:58.917] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:57:58.917] [bbotk]              4.759129                 5.992226                       0.1617532 
INFO  [23:57:58.917] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:57:58.917] [bbotk]                     3413        0.688 -0.9582267         <NA>   0.9724383 
INFO  [23:57:58.917] [bbotk]                                 uhash 
INFO  [23:57:58.917] [bbotk]  0ae5c0b5-4983-4b2f-a3ba-3827bb739d08 
DEBUG [23:57:59.993] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.256913e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9632324 9504 
  - variance bounds :  1.256913e-05 0.001554904 
  - best initial criterion value(s) :  430.0692 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -430.07  |proj g|=       4.6569
At iterate     1  f =      -436.18  |proj g|=         6.827
At iterate     2  f =      -437.19  |proj g|=         6.068
At iterate     3  f =      -438.15  |proj g|=        5.1071
At iterate     4  f =      -440.25  |proj g|=        3.5915
At iterate     5  f =      -442.03  |proj g|=        2.2631
At iterate     6  f =      -442.06  |proj g|=        2.5307
At iterate     7  f =      -442.07  |proj g|=        2.5282
At iterate     8  f =      -442.07  |proj g|=        2.5305
At iterate     9  f =      -442.07  |proj g|=        2.5308
At iterate    10  f =      -442.07  |proj g|=        2.5331
At iterate    11  f =      -442.07  |proj g|=        2.5357
At iterate    12  f =      -442.07  |proj g|=        2.5408
At iterate    13  f =      -442.07  |proj g|=        2.5494
At iterate    14  f =      -442.07  |proj g|=        2.5647
At iterate    15  f =      -442.07  |proj g|=        2.5916
At iterate    16  f =      -442.07  |proj g|=        2.6325
At iterate    17  f =      -442.07  |proj g|=        2.6661
At iterate    18  f =      -442.07  |proj g|=         2.658
At iterate    19  f =      -442.07  |proj g|=        2.6525
At iterate    20  f =      -442.07  |proj g|=        2.6487
At iterate    21  f =      -442.07  |proj g|=        2.6416
At iterate    22  f =      -442.07  |proj g|=        2.6297
At iterate    23  f =      -442.08  |proj g|=        2.6128
At iterate    24  f =      -442.08  |proj g|=        2.5853
At iterate    25  f =      -442.08  |proj g|=         2.534
At iterate    26  f =      -442.09  |proj g|=         2.458
At iterate    27  f =      -442.11  |proj g|=         2.317
At iterate    28  f =      -442.17  |proj g|=        2.1223
At iterate    29  f =      -442.19  |proj g|=        1.9858
At iterate    30  f =      -442.36  |proj g|=        1.7471
At iterate    31  f =      -444.18  |proj g|=        1.6922
At iterate    32  f =      -447.97  |proj g|=        1.4225
At iterate    33  f =       -449.6  |proj g|=        1.2717
At iterate    34  f =      -449.96  |proj g|=        1.2017
At iterate    35  f =      -450.19  |proj g|=        1.4248
At iterate    36  f =      -450.47  |proj g|=         1.388
At iterate    37  f =      -450.53  |proj g|=        1.3911
At iterate    38  f =      -450.53  |proj g|=        1.4024
At iterate    39  f =      -450.53  |proj g|=        1.4095
At iterate    40  f =      -450.53  |proj g|=        1.4117
At iterate    41  f =      -450.53  |proj g|=        1.4119
At iterate    42  f =      -450.53  |proj g|=        1.4119
At iterate    43  f =      -450.53  |proj g|=        1.4119

iterations 43
function evaluations 52
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.41187
final function value -450.533

F = -450.533
final  value -450.532559 
converged
 
INFO  [23:57:59.997] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:58:00.052] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:58:00.059] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:58:11.871] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:58:23.153] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:58:34.146] [mlr3]  Finished benchmark 
INFO  [23:58:34.218] [bbotk] Result of batch 79: 
INFO  [23:58:34.220] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:58:34.220] [bbotk]              6.729115                 7.705763                       0.3843796 
INFO  [23:58:34.220] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:58:34.220] [bbotk]                     3783        0.684 -0.9599385         <NA>   0.9760209 
INFO  [23:58:34.220] [bbotk]                                 uhash 
INFO  [23:58:34.220] [bbotk]  c7d2922d-69dc-4419-8df4-895a3626b647 
DEBUG [23:58:35.257] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.250938e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9632324 9504 
  - variance bounds :  1.250938e-05 0.001556274 
  - best initial criterion value(s) :  441.5537 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -441.55  |proj g|=       2.9552
At iterate     1  f =      -448.24  |proj g|=        4.8616
At iterate     2  f =      -452.68  |proj g|=        4.6465
At iterate     3  f =      -466.07  |proj g|=        2.3216
At iterate     4  f =      -468.55  |proj g|=        1.3112
At iterate     5  f =      -468.82  |proj g|=        1.3746
At iterate     6  f =      -468.86  |proj g|=        1.4361
At iterate     7  f =      -468.86  |proj g|=        1.4369
At iterate     8  f =      -468.86  |proj g|=        1.4367
At iterate     9  f =      -468.86  |proj g|=        1.4365
At iterate    10  f =      -468.86  |proj g|=        1.4363
At iterate    11  f =      -468.86  |proj g|=         1.436
At iterate    12  f =      -468.86  |proj g|=        1.4358
At iterate    13  f =      -468.86  |proj g|=        1.4349
At iterate    14  f =      -468.86  |proj g|=        1.4347
At iterate    15  f =      -469.16  |proj g|=        1.3972
At iterate    16  f =      -470.81  |proj g|=        1.1612
At iterate    17  f =      -472.61  |proj g|=       0.53519
At iterate    18  f =      -473.13  |proj g|=         0.501
At iterate    19  f =      -473.36  |proj g|=         0.562
At iterate    20  f =      -473.42  |proj g|=       0.55695
At iterate    21  f =       -473.5  |proj g|=       0.44026
At iterate    22  f =      -473.51  |proj g|=       0.43584
At iterate    23  f =      -473.51  |proj g|=       0.43544
At iterate    24  f =      -473.51  |proj g|=       0.43547

iterations 24
function evaluations 34
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.435467
final function value -473.507

F = -473.507
final  value -473.507199 
converged
 
INFO  [23:58:35.261] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:58:35.348] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:58:35.360] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:58:48.915] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:59:02.872] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:59:17.728] [mlr3]  Finished benchmark 
INFO  [23:59:17.795] [bbotk] Result of batch 80: 
INFO  [23:59:17.797] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:59:17.797] [bbotk]              2.799509                 6.698283                       0.4088881 
INFO  [23:59:17.797] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:59:17.797] [bbotk]                     4599        0.693 -0.9496865         <NA>   0.9718156 
INFO  [23:59:17.797] [bbotk]                                 uhash 
INFO  [23:59:17.797] [bbotk]  4978fd62-42bb-45ea-9adb-f671e0457731 
DEBUG [23:59:18.859] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.240696e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9632324 9504 
  - variance bounds :  1.240696e-05 0.001549945 
  - best initial criterion value(s) :  441.6445 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -441.64  |proj g|=       5.5723
At iterate     1  f =      -442.95  |proj g|=        6.3676
At iterate     2  f =      -444.19  |proj g|=        5.5497
At iterate     3  f =      -446.56  |proj g|=        3.1323
At iterate     4  f =      -448.28  |proj g|=        2.2146
At iterate     5  f =      -448.49  |proj g|=        2.0007
At iterate     6  f =      -448.49  |proj g|=        2.0789
At iterate     7  f =      -448.49  |proj g|=         2.081
At iterate     8  f =      -448.49  |proj g|=        2.0816
At iterate     9  f =      -448.49  |proj g|=        2.0823
At iterate    10  f =      -448.49  |proj g|=        2.0845
At iterate    11  f =      -448.49  |proj g|=        2.0874
At iterate    12  f =      -448.49  |proj g|=        2.0927
At iterate    13  f =      -448.49  |proj g|=        2.1007
At iterate    14  f =       -448.5  |proj g|=        2.1121
At iterate    15  f =       -448.5  |proj g|=        2.1247
At iterate    16  f =      -448.51  |proj g|=        2.1269
At iterate    17  f =      -448.54  |proj g|=        2.0822
At iterate    18  f =       -448.6  |proj g|=        1.9164
At iterate    19  f =      -448.68  |proj g|=        1.5263
At iterate    20  f =      -448.68  |proj g|=        1.4374
At iterate    21  f =      -448.69  |proj g|=        1.4352
At iterate    22  f =       -448.7  |proj g|=        1.4239
At iterate    23  f =      -448.72  |proj g|=        1.4108
At iterate    24  f =      -448.78  |proj g|=        1.3981
At iterate    25  f =      -448.92  |proj g|=        1.4565
At iterate    26  f =      -449.21  |proj g|=        1.6325
At iterate    27  f =      -449.81  |proj g|=        1.5294
At iterate    28  f =      -451.09  |proj g|=        1.6158
At iterate    29  f =       -451.7  |proj g|=        0.5929
At iterate    30  f =      -453.42  |proj g|=       0.77978
At iterate    31  f =      -454.34  |proj g|=       0.86287
At iterate    32  f =      -455.21  |proj g|=       0.94742
At iterate    33  f =      -455.55  |proj g|=       0.99707
At iterate    34  f =      -455.62  |proj g|=        1.0544
At iterate    35  f =      -455.63  |proj g|=        1.0609
At iterate    36  f =      -455.63  |proj g|=        1.0491
At iterate    37  f =      -455.63  |proj g|=        1.0517
At iterate    38  f =      -455.63  |proj g|=        1.0481
At iterate    39  f =      -455.63  |proj g|=        1.0492
At iterate    40  f =      -455.63  |proj g|=        1.0491

iterations 40
function evaluations 46
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.04908
final function value -455.632

F = -455.632
final  value -455.632084 
converged
 
INFO  [23:59:18.864] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:59:18.919] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:59:18.925] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [23:59:32.916] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [23:59:45.091] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [23:59:58.132] [mlr3]  Finished benchmark 
INFO  [23:59:58.199] [bbotk] Result of batch 81: 
INFO  [23:59:58.201] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [23:59:58.201] [bbotk]              9.115354                  4.17744                      0.01263552 
INFO  [23:59:58.201] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [23:59:58.201] [bbotk]                     4657        0.675 -0.9614392         <NA>   0.9548718 
INFO  [23:59:58.201] [bbotk]                                 uhash 
INFO  [23:59:58.201] [bbotk]  3722dcbd-7d32-44d1-817d-10f377a92d93 
DEBUG [23:59:59.222] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.245633e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.245633e-05 0.001554208 
  - best initial criterion value(s) :  461.7146 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -461.71  |proj g|=       2.6208
At iterate     1  f =       -466.2  |proj g|=         1.538
At iterate     2  f =       -470.7  |proj g|=        3.0491
At iterate     3  f =      -474.47  |proj g|=        3.9399
At iterate     4  f =      -477.77  |proj g|=        3.3519
At iterate     5  f =      -478.21  |proj g|=        2.6738
At iterate     6  f =      -478.23  |proj g|=         2.628
At iterate     7  f =      -478.23  |proj g|=        2.6347
At iterate     8  f =      -478.23  |proj g|=        2.6321
At iterate     9  f =      -478.23  |proj g|=        2.6317
At iterate    10  f =      -478.23  |proj g|=        2.6306
At iterate    11  f =      -478.23  |proj g|=        2.6284
At iterate    12  f =      -478.23  |proj g|=        2.6251
At iterate    13  f =      -478.23  |proj g|=        2.6206
At iterate    14  f =      -478.24  |proj g|=        2.6122
At iterate    15  f =      -478.24  |proj g|=         2.609
At iterate    16  f =      -478.24  |proj g|=        2.5868
At iterate    17  f =      -478.24  |proj g|=        2.5837
At iterate    18  f =      -482.68  |proj g|=          1.18
At iterate    19  f =         -485  |proj g|=       0.39611
At iterate    20  f =         -485  |proj g|=       0.25862
At iterate    21  f =      -485.01  |proj g|=       0.29079
At iterate    22  f =      -485.01  |proj g|=       0.30747
At iterate    23  f =      -485.01  |proj g|=        0.3082

iterations 23
function evaluations 32
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.308201
final function value -485.008

F = -485.008
final  value -485.008473 
converged
 
INFO  [23:59:59.226] [bbotk] Evaluating 1 configuration(s) 
INFO  [23:59:59.283] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [23:59:59.289] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:00:05.797] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:00:12.110] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:00:17.141] [mlr3]  Finished benchmark 
INFO  [00:00:17.209] [bbotk] Result of batch 82: 
INFO  [00:00:17.211] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:00:17.211] [bbotk]              4.642434                 2.568314                       0.2743102 
INFO  [00:00:17.211] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:00:17.211] [bbotk]                     2062        0.693 -0.9460027         <NA>   0.9723738 
INFO  [00:00:17.211] [bbotk]                                 uhash 
INFO  [00:00:17.211] [bbotk]  e8ae92d7-2629-4680-b05c-42c2622241b3 
DEBUG [00:00:18.360] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.236063e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.236063e-05 0.001533332 
  - best initial criterion value(s) :  415.0901 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -415.09  |proj g|=       14.062
At iterate     1  f =      -440.13  |proj g|=        7.4903
At iterate     2  f =      -447.47  |proj g|=         6.049
At iterate     3  f =      -459.45  |proj g|=        4.5415
At iterate     4  f =      -462.56  |proj g|=        3.3494
At iterate     5  f =      -464.84  |proj g|=        3.1203
At iterate     6  f =       -466.2  |proj g|=        2.4135
At iterate     7  f =      -469.65  |proj g|=        1.4575
At iterate     8  f =       -474.6  |proj g|=        1.3814
At iterate     9  f =      -482.78  |proj g|=        1.2481
At iterate    10  f =      -483.87  |proj g|=       0.86337
At iterate    11  f =      -485.36  |proj g|=       0.30757
At iterate    12  f =      -485.78  |proj g|=       0.33287
At iterate    13  f =      -485.91  |proj g|=        0.4204
At iterate    14  f =      -485.93  |proj g|=       0.52364
At iterate    15  f =      -485.93  |proj g|=       0.54975
At iterate    16  f =      -485.93  |proj g|=       0.55128
At iterate    17  f =      -485.93  |proj g|=       0.55158

iterations 17
function evaluations 23
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.551582
final function value -485.927

F = -485.927
final  value -485.926533 
converged
 
INFO  [00:00:18.364] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:00:18.438] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:00:18.444] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:00:31.407] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:00:42.997] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:00:53.598] [mlr3]  Finished benchmark 
INFO  [00:00:53.666] [bbotk] Result of batch 83: 
INFO  [00:00:53.668] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:00:53.668] [bbotk]              3.864311                 2.366984                       0.4094146 
INFO  [00:00:53.668] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:00:53.668] [bbotk]                     3989        0.671 -0.9507615         <NA>   0.9745272 
INFO  [00:00:53.668] [bbotk]                                 uhash 
INFO  [00:00:53.668] [bbotk]  26284245-a125-46c5-93cf-c7c30fa37649 
DEBUG [00:00:54.723] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.22861e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.22861e-05 0.001531141 
  - best initial criterion value(s) :  440.4445 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -440.44  |proj g|=        2.369
At iterate     1  f =      -449.45  |proj g|=        12.711
At iterate     2  f =      -456.91  |proj g|=        9.7098
At iterate     3  f =      -457.53  |proj g|=        10.722
At iterate     4  f =      -458.34  |proj g|=        10.056
At iterate     5  f =      -459.68  |proj g|=        6.6073
At iterate     6  f =      -460.09  |proj g|=        8.0026
At iterate     7  f =      -460.13  |proj g|=        7.7551
At iterate     8  f =      -460.14  |proj g|=         7.664
At iterate     9  f =      -460.14  |proj g|=        7.6723
At iterate    10  f =      -460.14  |proj g|=         7.676
At iterate    11  f =      -460.14  |proj g|=        7.6805
At iterate    12  f =      -460.14  |proj g|=        7.6814
At iterate    13  f =      -460.14  |proj g|=        7.6737
At iterate    14  f =      -460.15  |proj g|=        7.6617
At iterate    15  f =      -460.19  |proj g|=        7.6835
At iterate    16  f =      -460.26  |proj g|=        7.4949
At iterate    17  f =      -460.42  |proj g|=        7.4974
At iterate    18  f =      -461.09  |proj g|=         6.804
At iterate    19  f =      -462.43  |proj g|=         6.582
At iterate    20  f =      -462.89  |proj g|=        5.1173
At iterate    21  f =      -466.86  |proj g|=        4.2222
At iterate    22  f =      -474.72  |proj g|=        2.0808
At iterate    23  f =      -487.06  |proj g|=        1.2792
At iterate    24  f =      -493.52  |proj g|=        1.0468
At iterate    25  f =      -495.37  |proj g|=       0.87283
At iterate    26  f =      -497.05  |proj g|=       0.75242
At iterate    27  f =      -497.37  |proj g|=       0.57155
At iterate    28  f =      -497.43  |proj g|=       0.55662
At iterate    29  f =      -497.43  |proj g|=       0.46527
At iterate    30  f =      -497.43  |proj g|=       0.47096
At iterate    31  f =      -497.43  |proj g|=       0.47648
At iterate    32  f =      -497.43  |proj g|=       0.47751
At iterate    33  f =      -497.43  |proj g|=       0.47754

iterations 33
function evaluations 40
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.477542
final function value -497.429

F = -497.429
final  value -497.429049 
converged
 
INFO  [00:00:54.727] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:00:54.799] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:00:54.805] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:01:04.917] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:01:16.286] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:01:28.363] [mlr3]  Finished benchmark 
INFO  [00:01:28.432] [bbotk] Result of batch 84: 
INFO  [00:01:28.434] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:01:28.434] [bbotk]              4.913991                   4.1072                       0.1173638 
INFO  [00:01:28.434] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:01:28.434] [bbotk]                     3964        0.685 -0.9432492         <NA>    0.971942 
INFO  [00:01:28.434] [bbotk]                                 uhash 
INFO  [00:01:28.434] [bbotk]  8edce954-a933-4a14-a433-cc66f69ac290 
DEBUG [00:01:29.456] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.219e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.219e-05 0.001525732 
  - best initial criterion value(s) :  444.2661 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -444.27  |proj g|=       9.2631
At iterate     1  f =      -473.28  |proj g|=        2.3325
At iterate     2  f =      -477.28  |proj g|=        2.2477
At iterate     3  f =      -482.89  |proj g|=        1.8569
At iterate     4  f =      -483.04  |proj g|=        1.7169
At iterate     5  f =      -483.14  |proj g|=        1.7611
At iterate     6  f =      -483.31  |proj g|=        1.8008
At iterate     7  f =       -483.7  |proj g|=        1.8341
At iterate     8  f =         -484  |proj g|=        1.8099
At iterate     9  f =      -484.04  |proj g|=        1.7399
At iterate    10  f =      -484.05  |proj g|=        1.7592
At iterate    11  f =      -484.05  |proj g|=        1.7659
At iterate    12  f =      -484.05  |proj g|=        1.7655
At iterate    13  f =      -484.05  |proj g|=        1.7637
At iterate    14  f =      -484.06  |proj g|=         1.749
At iterate    15  f =      -484.07  |proj g|=        1.7325
At iterate    16  f =       -484.1  |proj g|=        1.7055
At iterate    17  f =      -484.19  |proj g|=        1.7183
At iterate    18  f =      -484.41  |proj g|=        1.8468
At iterate    19  f =      -484.94  |proj g|=        1.9392
At iterate    20  f =      -485.83  |proj g|=        1.8282
At iterate    21  f =      -486.55  |proj g|=        1.6595
At iterate    22  f =      -486.91  |proj g|=        1.5491
At iterate    23  f =      -487.25  |proj g|=        1.4843
At iterate    24  f =       -488.7  |proj g|=        1.5925
At iterate    25  f =      -488.94  |proj g|=        1.6032
At iterate    26  f =      -489.02  |proj g|=        1.6563
At iterate    27  f =      -489.02  |proj g|=        1.6412
At iterate    28  f =      -489.02  |proj g|=        1.6447
At iterate    29  f =      -489.02  |proj g|=        1.6418
At iterate    30  f =      -489.02  |proj g|=        1.6431
At iterate    31  f =      -489.02  |proj g|=        1.6432

iterations 31
function evaluations 35
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.64317
final function value -489.024

F = -489.024
final  value -489.024489 
converged
 
INFO  [00:01:29.460] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:01:29.515] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:01:29.522] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:01:33.200] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:01:37.333] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:01:40.997] [mlr3]  Finished benchmark 
INFO  [00:01:41.066] [bbotk] Result of batch 85: 
INFO  [00:01:41.068] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:01:41.068] [bbotk]                 8.169                 6.136886                       0.3215271 
INFO  [00:01:41.068] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:01:41.068] [bbotk]                     1251        0.681 -0.9518434         <NA>   0.9721991 
INFO  [00:01:41.068] [bbotk]                                 uhash 
INFO  [00:01:41.068] [bbotk]  b958a0d2-45aa-4f76-87e2-bf58bbd8ed2c 
DEBUG [00:01:42.130] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.209704e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.209704e-05 0.001502214 
  - best initial criterion value(s) :  449.6529 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -449.65  |proj g|=        1.557
At iterate     1  f =      -462.96  |proj g|=        12.917
At iterate     2  f =      -467.35  |proj g|=        12.853
At iterate     3  f =      -474.18  |proj g|=         11.14
At iterate     4  f =       -474.4  |proj g|=        10.384
At iterate     5  f =      -474.41  |proj g|=        10.332
At iterate     6  f =      -474.42  |proj g|=        10.306
At iterate     7  f =      -474.44  |proj g|=        10.369
At iterate     8  f =      -474.45  |proj g|=        10.527
At iterate     9  f =      -474.46  |proj g|=         10.65
At iterate    10  f =      -474.46  |proj g|=        10.661
At iterate    11  f =      -474.46  |proj g|=        10.661
At iterate    12  f =      -474.46  |proj g|=        10.661
At iterate    13  f =      -474.46  |proj g|=        10.662
At iterate    14  f =      -474.46  |proj g|=        10.662
At iterate    15  f =      -474.46  |proj g|=        10.663
At iterate    16  f =      -474.46  |proj g|=        10.662
At iterate    17  f =      -474.46  |proj g|=        10.652
At iterate    18  f =      -474.46  |proj g|=        10.639
At iterate    19  f =      -474.47  |proj g|=        10.575
At iterate    20  f =      -474.47  |proj g|=         10.64
At iterate    21  f =      -474.49  |proj g|=        10.544
At iterate    22  f =      -485.71  |proj g|=        5.3255
At iterate    23  f =      -493.68  |proj g|=        1.7109
At iterate    24  f =      -495.45  |proj g|=        1.0829
At iterate    25  f =      -496.99  |proj g|=       0.62629
At iterate    26  f =      -497.06  |proj g|=        0.6175
At iterate    27  f =      -497.09  |proj g|=       0.36334
At iterate    28  f =      -497.09  |proj g|=       0.21537
At iterate    29  f =       -497.1  |proj g|=       0.18596
At iterate    30  f =       -497.1  |proj g|=      0.093185
At iterate    31  f =       -497.1  |proj g|=       0.09289

iterations 31
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.0928901
final function value -497.098

F = -497.098
final  value -497.097743 
converged
 
INFO  [00:01:42.135] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:01:42.190] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:01:42.197] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:01:51.918] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:02:02.260] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:02:13.224] [mlr3]  Finished benchmark 
INFO  [00:02:13.292] [bbotk] Result of batch 86: 
INFO  [00:02:13.294] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:02:13.294] [bbotk]              8.321613                 5.183828                       0.2251743 
INFO  [00:02:13.294] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:02:13.294] [bbotk]                     3449        0.697 -0.9520473         <NA>    0.974654 
INFO  [00:02:13.294] [bbotk]                                 uhash 
INFO  [00:02:13.294] [bbotk]  228f71f8-579c-4499-8cbf-33a7ae463279 
DEBUG [00:02:14.362] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.202679e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.202679e-05 0.001498938 
  - best initial criterion value(s) :  465.1819 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -465.18  |proj g|=       3.0707
At iterate     1  f =      -465.61  |proj g|=        3.6655
At iterate     2  f =      -466.36  |proj g|=         3.575
At iterate     3  f =      -468.47  |proj g|=        3.0872
At iterate     4  f =      -468.81  |proj g|=        3.0101
At iterate     5  f =      -468.93  |proj g|=        2.9949
At iterate     6  f =      -468.94  |proj g|=        3.0072
At iterate     7  f =      -468.94  |proj g|=        3.0278
At iterate     8  f =      -468.94  |proj g|=        3.0252
At iterate     9  f =      -468.95  |proj g|=        3.0248
At iterate    10  f =      -468.95  |proj g|=        3.0238
At iterate    11  f =      -468.95  |proj g|=        3.0201
At iterate    12  f =      -468.96  |proj g|=         3.012
At iterate    13  f =      -468.97  |proj g|=        2.8898
At iterate    14  f =         -469  |proj g|=        2.9312
At iterate    15  f =      -469.08  |proj g|=        2.9543
At iterate    16  f =      -469.36  |proj g|=        2.9142
At iterate    17  f =      -469.92  |proj g|=        2.6823
At iterate    18  f =      -470.87  |proj g|=        2.1507
At iterate    19  f =      -471.17  |proj g|=        1.5029
At iterate    20  f =      -471.84  |proj g|=        1.2387
At iterate    21  f =      -473.63  |proj g|=       0.82383
At iterate    22  f =      -473.99  |proj g|=       0.93719
At iterate    23  f =      -474.29  |proj g|=       0.72977
At iterate    24  f =      -474.35  |proj g|=       0.47881
At iterate    25  f =      -474.36  |proj g|=       0.53231
At iterate    26  f =      -474.36  |proj g|=        0.5407
At iterate    27  f =      -474.36  |proj g|=       0.54101
At iterate    28  f =      -474.36  |proj g|=       0.54009
At iterate    29  f =      -474.36  |proj g|=       0.54023

iterations 29
function evaluations 40
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.540234
final function value -474.358

F = -474.358
final  value -474.357550 
converged
 
INFO  [00:02:14.366] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:02:14.422] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:02:14.429] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:02:27.190] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:02:38.005] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:02:48.431] [mlr3]  Finished benchmark 
INFO  [00:02:48.505] [bbotk] Result of batch 87: 
INFO  [00:02:48.507] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:02:48.507] [bbotk]              9.670508                 3.411804                       0.3598603 
INFO  [00:02:48.507] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:02:48.507] [bbotk]                     4051          0.7 -0.9614807         <NA>   0.9763717 
INFO  [00:02:48.507] [bbotk]                                 uhash 
INFO  [00:02:48.507] [bbotk]  b78b0d88-33d4-449a-9679-4fcf083c2e28 
DEBUG [00:02:49.701] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.197788e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.197788e-05 0.001499638 
  - best initial criterion value(s) :  470.8669 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -470.87  |proj g|=       4.2495
At iterate     1  f =      -495.46  |proj g|=       0.97026
At iterate     2  f =      -506.05  |proj g|=        2.1395
At iterate     3  f =      -507.29  |proj g|=        3.5904
At iterate     4  f =      -508.78  |proj g|=        3.4228
At iterate     5  f =      -509.63  |proj g|=        2.5882
At iterate     6  f =         -510  |proj g|=        3.4094
At iterate     7  f =      -510.01  |proj g|=        3.3432
At iterate     8  f =      -510.01  |proj g|=        3.3157
At iterate     9  f =      -510.01  |proj g|=        3.3191
At iterate    10  f =      -510.01  |proj g|=        3.3201
At iterate    11  f =      -510.01  |proj g|=        3.3248
At iterate    12  f =      -510.01  |proj g|=        3.3305
At iterate    13  f =      -510.01  |proj g|=        3.3409
At iterate    14  f =      -510.01  |proj g|=        3.3564
At iterate    15  f =      -510.01  |proj g|=        3.3789
At iterate    16  f =      -510.02  |proj g|=        3.4076
At iterate    17  f =      -510.03  |proj g|=        3.4451
At iterate    18  f =      -510.05  |proj g|=        3.4767
At iterate    19  f =      -510.06  |proj g|=        3.6085
At iterate    20  f =      -510.13  |proj g|=         3.593
At iterate    21  f =      -510.48  |proj g|=        3.4403
At iterate    22  f =      -511.48  |proj g|=        3.0315
At iterate    23  f =      -516.69  |proj g|=        1.4925
At iterate    24  f =      -516.84  |proj g|=        1.2819
At iterate    25  f =      -516.84  |proj g|=         1.303
At iterate    26  f =      -516.84  |proj g|=        1.3027
At iterate    27  f =      -516.84  |proj g|=        1.3043
At iterate    28  f =      -516.84  |proj g|=        1.3043
At iterate    29  f =      -516.84  |proj g|=        1.3042
At iterate    30  f =      -516.84  |proj g|=        1.3041
At iterate    31  f =      -516.84  |proj g|=        1.3039
At iterate    32  f =      -516.84  |proj g|=        1.3034
At iterate    33  f =      -516.84  |proj g|=        1.3019
At iterate    34  f =      -516.85  |proj g|=         1.316
At iterate    35  f =      -516.85  |proj g|=        1.2846
At iterate    36  f =      -516.85  |proj g|=        1.2928
At iterate    37  f =      -516.89  |proj g|=        1.3372
At iterate    38  f =      -516.97  |proj g|=        1.3586
At iterate    39  f =      -517.17  |proj g|=         1.316
At iterate    40  f =      -517.52  |proj g|=        1.1274
At iterate    41  f =      -517.53  |proj g|=        1.2196
At iterate    42  f =      -517.95  |proj g|=       0.82876
At iterate    43  f =      -518.57  |proj g|=        0.4715
At iterate    44  f =      -518.68  |proj g|=       0.52833
At iterate    45  f =      -518.73  |proj g|=       0.11656
At iterate    46  f =      -518.73  |proj g|=       0.02097
At iterate    47  f =      -518.73  |proj g|=       0.03488
At iterate    48  f =      -518.73  |proj g|=     0.0065571
At iterate    49  f =      -518.73  |proj g|=     0.0011537

iterations 49
function evaluations 60
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00115371
final function value -518.726

F = -518.726
final  value -518.725702 
converged
 
INFO  [00:02:49.703] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:02:49.759] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:02:49.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:02:51.502] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:02:52.979] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:02:54.614] [mlr3]  Finished benchmark 
INFO  [00:02:54.717] [bbotk] Result of batch 88: 
INFO  [00:02:54.720] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:02:54.720] [bbotk]              2.642099                 7.952767                       0.3196548 
INFO  [00:02:54.720] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:02:54.720] [bbotk]                      482        0.698 -0.9404451         <NA>   0.9488375 
INFO  [00:02:54.720] [bbotk]                                 uhash 
INFO  [00:02:54.720] [bbotk]  e7efe062-6259-48fd-919a-eef935a84ee0 
DEBUG [00:02:55.968] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.220011e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.220011e-05 0.001535701 
  - best initial criterion value(s) :  473.5799 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -473.58  |proj g|=       4.6187
At iterate     1  f =      -495.56  |proj g|=        10.687
At iterate     2  f =      -499.93  |proj g|=        8.8214
At iterate     3  f =      -502.82  |proj g|=         3.355
At iterate     4  f =      -503.66  |proj g|=        5.3862
At iterate     5  f =      -503.81  |proj g|=        5.1249
At iterate     6  f =      -504.62  |proj g|=         3.893
At iterate     7  f =       -505.4  |proj g|=        3.2516
At iterate     8  f =      -505.91  |proj g|=        4.3837
At iterate     9  f =      -506.48  |proj g|=        3.4016
At iterate    10  f =      -506.59  |proj g|=        3.1005
At iterate    11  f =      -506.63  |proj g|=        3.0617
At iterate    12  f =      -506.64  |proj g|=        3.1041
At iterate    13  f =      -506.64  |proj g|=        3.1378
At iterate    14  f =      -506.64  |proj g|=        3.1429
At iterate    15  f =      -506.64  |proj g|=        3.1502
At iterate    16  f =      -506.64  |proj g|=        3.1569
At iterate    17  f =      -506.65  |proj g|=        3.1566
At iterate    18  f =      -506.65  |proj g|=        3.1292
At iterate    19  f =      -506.66  |proj g|=        3.0484
At iterate    20  f =      -506.66  |proj g|=        3.0072
At iterate    21  f =      -506.68  |proj g|=        2.8647
At iterate    22  f =       -506.7  |proj g|=         2.781
At iterate    23  f =      -506.81  |proj g|=         2.492
At iterate    24  f =      -507.05  |proj g|=        2.1272
At iterate    25  f =      -507.69  |proj g|=         1.526
At iterate    26  f =      -509.16  |proj g|=        1.3393
At iterate    27  f =      -512.19  |proj g|=        1.3114
At iterate    28  f =      -512.75  |proj g|=        1.1507
At iterate    29  f =      -515.46  |proj g|=        1.4043
At iterate    30  f =      -516.16  |proj g|=        1.5686
At iterate    31  f =      -516.48  |proj g|=        1.6663
At iterate    32  f =       -516.5  |proj g|=        1.6303
At iterate    33  f =       -516.5  |proj g|=        1.6366
At iterate    34  f =       -516.5  |proj g|=        1.6362
At iterate    35  f =       -516.5  |proj g|=        1.6361

iterations 35
function evaluations 40
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.63615
final function value -516.505

F = -516.505
final  value -516.504575 
converged
 
INFO  [00:02:55.973] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:02:56.031] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:02:56.038] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:03:09.914] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:03:27.085] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:03:41.732] [mlr3]  Finished benchmark 
INFO  [00:03:41.801] [bbotk] Result of batch 89: 
INFO  [00:03:41.803] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:03:41.803] [bbotk]              9.300492                 6.032525                         0.45646 
INFO  [00:03:41.803] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:03:41.803] [bbotk]                     4537        0.875 -0.9455208         <NA>   0.9772123 
INFO  [00:03:41.803] [bbotk]                                 uhash 
INFO  [00:03:41.803] [bbotk]  8db762ad-d487-4094-9916-af5455d21b73 
DEBUG [00:03:42.831] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.216378e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.216378e-05 0.001539462 
  - best initial criterion value(s) :  503.8006 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -503.8  |proj g|=       1.8827
At iterate     1  f =      -504.76  |proj g|=        5.9714
At iterate     2  f =      -509.65  |proj g|=        4.8966
At iterate     3  f =      -512.79  |proj g|=        3.0666
At iterate     4  f =      -512.92  |proj g|=        2.5477
At iterate     5  f =       -513.3  |proj g|=        2.7538
At iterate     6  f =       -514.3  |proj g|=         2.696
At iterate     7  f =      -514.67  |proj g|=        2.4742
At iterate     8  f =      -514.74  |proj g|=        2.3948
At iterate     9  f =      -514.74  |proj g|=        2.4416
At iterate    10  f =      -514.74  |proj g|=        2.4084
At iterate    11  f =      -514.74  |proj g|=        2.4058
At iterate    12  f =      -514.74  |proj g|=        2.4049
At iterate    13  f =      -514.75  |proj g|=        2.4008
At iterate    14  f =      -514.75  |proj g|=        2.3908
At iterate    15  f =      -514.76  |proj g|=        2.2313
At iterate    16  f =      -514.79  |proj g|=         2.293
At iterate    17  f =      -514.85  |proj g|=        2.3285
At iterate    18  f =      -515.05  |proj g|=        2.2917
At iterate    19  f =      -515.31  |proj g|=        2.0801
At iterate    20  f =      -515.57  |proj g|=        1.9488
At iterate    21  f =      -515.61  |proj g|=        1.9204
At iterate    22  f =       -515.8  |proj g|=        1.9254
At iterate    23  f =      -515.86  |proj g|=        1.8626
At iterate    24  f =      -515.87  |proj g|=        1.8647
At iterate    25  f =      -515.87  |proj g|=         1.866
At iterate    26  f =      -515.87  |proj g|=        1.8655
At iterate    27  f =      -515.87  |proj g|=        1.8656

iterations 27
function evaluations 35
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.86559
final function value -515.868

F = -515.868
final  value -515.868260 
converged
 
INFO  [00:03:42.836] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:03:42.930] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:03:42.938] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:03:49.942] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:03:56.944] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:04:04.661] [mlr3]  Finished benchmark 
INFO  [00:04:04.771] [bbotk] Result of batch 90: 
INFO  [00:04:04.773] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:04:04.773] [bbotk]              5.202196                 4.490409                       0.4041492 
INFO  [00:04:04.773] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [00:04:04.773] [bbotk]                     2792        0.681 -0.951429         <NA>   0.9753217 
INFO  [00:04:04.773] [bbotk]                                 uhash 
INFO  [00:04:04.773] [bbotk]  5e53e3f2-2594-4be1-a72c-c9b55a3f1ed7 
DEBUG [00:04:05.869] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.21023e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.21023e-05 0.001537401 
  - best initial criterion value(s) :  485.1695 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -485.17  |proj g|=       2.0612
At iterate     1  f =      -494.31  |proj g|=        5.5004
At iterate     2  f =      -494.98  |proj g|=        5.1739
At iterate     3  f =      -495.39  |proj g|=        3.9561
At iterate     4  f =      -495.56  |proj g|=         4.533
At iterate     5  f =      -495.57  |proj g|=        4.4316
At iterate     6  f =      -495.57  |proj g|=        4.4132
At iterate     7  f =      -495.57  |proj g|=        4.4028
At iterate     8  f =      -495.57  |proj g|=        4.3684
At iterate     9  f =      -495.58  |proj g|=         4.329
At iterate    10  f =      -495.58  |proj g|=        4.2878
At iterate    11  f =      -495.59  |proj g|=        4.2857
At iterate    12  f =      -495.59  |proj g|=        4.3133
At iterate    13  f =      -495.59  |proj g|=        4.3246
At iterate    14  f =      -495.59  |proj g|=        4.3258
At iterate    15  f =      -495.59  |proj g|=         4.327
At iterate    16  f =      -495.59  |proj g|=        4.3303
At iterate    17  f =      -495.59  |proj g|=        4.3362
At iterate    18  f =      -495.59  |proj g|=        4.3455
At iterate    19  f =      -495.59  |proj g|=        4.3603
At iterate    20  f =      -495.59  |proj g|=        4.3833
At iterate    21  f =       -495.6  |proj g|=        4.4153
At iterate    22  f =      -495.61  |proj g|=        4.4565
At iterate    23  f =      -495.63  |proj g|=        4.5037
At iterate    24  f =      -495.63  |proj g|=        4.7762
At iterate    25  f =      -495.71  |proj g|=        4.6731
At iterate    26  f =      -495.86  |proj g|=        4.5286
At iterate    27  f =      -496.22  |proj g|=        4.3326
At iterate    28  f =      -497.18  |proj g|=        4.0133
At iterate    29  f =      -499.12  |proj g|=        3.6692
At iterate    30  f =      -502.36  |proj g|=        1.4089
At iterate    31  f =      -507.27  |proj g|=        1.1175
At iterate    32  f =      -514.21  |proj g|=        1.4171
At iterate    33  f =      -515.83  |proj g|=        2.3464
At iterate    34  f =      -515.88  |proj g|=        2.5228
At iterate    35  f =      -515.88  |proj g|=        2.4923
At iterate    36  f =      -515.88  |proj g|=        2.4877
At iterate    37  f =      -515.88  |proj g|=        2.4645
At iterate    38  f =      -515.88  |proj g|=        2.4648

iterations 38
function evaluations 42
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.46483
final function value -515.884

F = -515.884
final  value -515.884143 
converged
 
INFO  [00:04:05.874] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:04:05.933] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:04:05.940] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:04:20.746] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:04:33.591] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:04:46.632] [mlr3]  Finished benchmark 
INFO  [00:04:46.702] [bbotk] Result of batch 91: 
INFO  [00:04:46.704] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:04:46.704] [bbotk]              6.747742                 6.334249                      0.07145808 
INFO  [00:04:46.704] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:04:46.704] [bbotk]                     4427        0.706 -0.9575382         <NA>   0.9707266 
INFO  [00:04:46.704] [bbotk]                                 uhash 
INFO  [00:04:46.704] [bbotk]  8ae153a5-c7e6-4efa-b895-6f1d0fd34435 
DEBUG [00:04:47.699] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.20066e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.20066e-05 0.001530054 
  - best initial criterion value(s) :  506.0662 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -506.07  |proj g|=       4.2453
At iterate     1  f =      -514.73  |proj g|=       0.73529
At iterate     2  f =      -514.86  |proj g|=       0.73391
At iterate     3  f =      -514.95  |proj g|=       0.73118
At iterate     4  f =      -515.07  |proj g|=       0.72724
At iterate     5  f =       -515.9  |proj g|=       0.79212
At iterate     6  f =      -516.01  |proj g|=       0.80635
At iterate     7  f =      -516.13  |proj g|=       0.85915
At iterate     8  f =      -516.15  |proj g|=       0.88725
At iterate     9  f =      -516.15  |proj g|=         0.893
At iterate    10  f =      -516.15  |proj g|=       0.89383
At iterate    11  f =      -516.15  |proj g|=       0.89381
At iterate    12  f =      -516.15  |proj g|=        0.8938

iterations 12
function evaluations 17
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.893799
final function value -516.151

F = -516.151
final  value -516.151352 
converged
 
INFO  [00:04:47.703] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:04:47.758] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:04:47.765] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:04:50.619] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:04:53.844] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:04:56.697] [mlr3]  Finished benchmark 
INFO  [00:04:56.764] [bbotk] Result of batch 92: 
INFO  [00:04:56.766] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:04:56.766] [bbotk]              4.986861                 2.834726                       0.4457851 
INFO  [00:04:56.766] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:04:56.766] [bbotk]                     1020        0.697 -0.9568132         <NA>   0.9719401 
INFO  [00:04:56.766] [bbotk]                                 uhash 
INFO  [00:04:56.766] [bbotk]  6e83966c-b1f5-4045-b868-0771de4495a4 
DEBUG [00:04:57.831] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.191808e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.191808e-05 0.001507832 
  - best initial criterion value(s) :  480.2902 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -480.29  |proj g|=       13.239
At iterate     1  f =      -494.78  |proj g|=        3.7915
At iterate     2  f =      -498.59  |proj g|=        3.6004
At iterate     3  f =      -500.36  |proj g|=        2.4143
At iterate     4  f =      -501.18  |proj g|=        1.6467
At iterate     5  f =      -501.33  |proj g|=         1.346
At iterate     6  f =      -501.35  |proj g|=         1.277
At iterate     7  f =      -501.37  |proj g|=        1.4049
At iterate     8  f =      -501.37  |proj g|=        1.3585
At iterate     9  f =      -501.37  |proj g|=        1.3349
At iterate    10  f =      -501.38  |proj g|=        1.3031
At iterate    11  f =      -501.38  |proj g|=        1.2496
At iterate    12  f =       -501.4  |proj g|=        1.1711
At iterate    13  f =      -501.41  |proj g|=        1.0834
At iterate    14  f =      -501.47  |proj g|=       0.97243
At iterate    15  f =      -504.58  |proj g|=        1.5617
At iterate    16  f =      -506.83  |proj g|=        1.4431
At iterate    17  f =       -507.2  |proj g|=        1.3603
At iterate    18  f =      -507.21  |proj g|=        1.3148
At iterate    19  f =      -507.22  |proj g|=        1.3259
At iterate    20  f =      -507.22  |proj g|=        1.3271
At iterate    21  f =      -507.22  |proj g|=        1.3277
At iterate    22  f =      -507.22  |proj g|=        1.3275
At iterate    23  f =      -507.22  |proj g|=        1.3275

iterations 23
function evaluations 34
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.32753
final function value -507.216

F = -507.216
final  value -507.216259 
converged
 
INFO  [00:04:57.835] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:04:57.889] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:04:57.896] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:05:12.521] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:05:28.593] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:05:42.680] [mlr3]  Finished benchmark 
INFO  [00:05:42.747] [bbotk] Result of batch 93: 
INFO  [00:05:42.748] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:05:42.748] [bbotk]              3.892558                 2.638432                       0.3898746 
INFO  [00:05:42.748] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [00:05:42.748] [bbotk]                     4812        0.704 -0.960276         <NA>   0.9749976 
INFO  [00:05:42.748] [bbotk]                                 uhash 
INFO  [00:05:42.748] [bbotk]  d5119748-d10d-44a2-863a-69c01694005c 
DEBUG [00:05:43.818] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.185545e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.185545e-05 0.001499318 
  - best initial criterion value(s) :  467.3973 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -467.4  |proj g|=       8.3276
At iterate     1  f =      -494.82  |proj g|=        8.9753
At iterate     2  f =      -501.41  |proj g|=        9.2457
At iterate     3  f =      -505.75  |proj g|=        7.0564
At iterate     4  f =      -509.77  |proj g|=        5.5793
At iterate     5  f =      -509.97  |proj g|=         4.871
At iterate     6  f =      -510.08  |proj g|=        5.1208
At iterate     7  f =      -510.08  |proj g|=        5.1068
At iterate     8  f =      -510.08  |proj g|=        5.0914
At iterate     9  f =      -510.08  |proj g|=        5.0942
At iterate    10  f =      -510.09  |proj g|=        5.1144
At iterate    11  f =      -510.09  |proj g|=        5.1362
At iterate    12  f =       -510.1  |proj g|=         5.177
At iterate    13  f =      -510.13  |proj g|=        5.2343
At iterate    14  f =      -510.13  |proj g|=        5.2482
At iterate    15  f =      -510.19  |proj g|=        5.3287
At iterate    16  f =       -511.9  |proj g|=        5.1605
At iterate    17  f =      -522.21  |proj g|=        3.9116
At iterate    18  f =      -523.48  |proj g|=        5.2186
At iterate    19  f =      -523.58  |proj g|=        5.2481
At iterate    20  f =      -523.59  |proj g|=        5.1954
At iterate    21  f =      -523.59  |proj g|=        5.2241
At iterate    22  f =      -523.59  |proj g|=         5.175
At iterate    23  f =      -523.59  |proj g|=        5.1797
At iterate    24  f =      -523.59  |proj g|=        5.1798
At iterate    25  f =      -523.59  |proj g|=        5.1795

iterations 25
function evaluations 31
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 5.17951
final function value -523.59

F = -523.59
final  value -523.589666 
converged
 
INFO  [00:05:43.822] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:05:43.893] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:05:43.899] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:05:50.110] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:05:57.190] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:06:03.931] [mlr3]  Finished benchmark 
INFO  [00:06:03.998] [bbotk] Result of batch 94: 
INFO  [00:06:03.999] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:06:03.999] [bbotk]              2.710699                 2.348497                       0.4094176 
INFO  [00:06:03.999] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:06:03.999] [bbotk]                     2498        0.716 -0.9575052         <NA>   0.9680567 
INFO  [00:06:03.999] [bbotk]                                 uhash 
INFO  [00:06:03.999] [bbotk]  a6a50ff4-bad3-4704-9c24-72aa45134088 
DEBUG [00:06:05.095] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.176002e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.176002e-05 0.001490833 
  - best initial criterion value(s) :  512.4566 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -512.46  |proj g|=       13.519
At iterate     1  f =      -527.61  |proj g|=        4.5618
At iterate     2  f =      -537.49  |proj g|=        4.3399
At iterate     3  f =      -541.01  |proj g|=        2.7651
At iterate     4  f =      -543.67  |proj g|=        1.4122
At iterate     5  f =      -544.82  |proj g|=        1.1058
At iterate     6  f =      -545.64  |proj g|=        1.0401
At iterate     7  f =      -545.72  |proj g|=        3.1989
At iterate     8  f =       -547.2  |proj g|=        1.5095
At iterate     9  f =       -547.3  |proj g|=         1.281
At iterate    10  f =      -547.36  |proj g|=         1.235
At iterate    11  f =      -547.36  |proj g|=        1.2401
At iterate    12  f =      -547.36  |proj g|=        1.2469
At iterate    13  f =      -547.36  |proj g|=        1.2487
At iterate    14  f =      -547.36  |proj g|=        1.2516
At iterate    15  f =      -547.36  |proj g|=        1.2552
At iterate    16  f =      -547.36  |proj g|=        1.2604
At iterate    17  f =      -547.36  |proj g|=         1.266
At iterate    18  f =      -547.37  |proj g|=        1.2645
At iterate    19  f =      -547.38  |proj g|=        1.2372
At iterate    20  f =      -547.39  |proj g|=        1.2068
At iterate    21  f =      -547.42  |proj g|=        1.0613
At iterate    22  f =      -547.46  |proj g|=        1.0188
At iterate    23  f =      -547.61  |proj g|=        0.7505
At iterate    24  f =      -547.92  |proj g|=       0.69178
At iterate    25  f =      -548.63  |proj g|=        0.6269
At iterate    26  f =      -550.09  |proj g|=       0.54933
At iterate    27  f =         -551  |proj g|=       0.65476
At iterate    28  f =      -551.23  |proj g|=       0.56189
At iterate    29  f =      -551.32  |proj g|=       0.67561
At iterate    30  f =      -551.33  |proj g|=       0.65444
At iterate    31  f =      -551.34  |proj g|=       0.64879
At iterate    32  f =      -551.34  |proj g|=       0.65194
At iterate    33  f =      -551.34  |proj g|=       0.65175

iterations 33
function evaluations 37
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.651746
final function value -551.337

F = -551.337
final  value -551.336913 
converged
 
INFO  [00:06:05.099] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:06:05.154] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:06:05.160] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:06:16.001] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:06:26.865] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:06:37.820] [mlr3]  Finished benchmark 
INFO  [00:06:37.887] [bbotk] Result of batch 95: 
INFO  [00:06:37.889] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:06:37.889] [bbotk]               9.87537                 2.699046                      0.01394463 
INFO  [00:06:37.889] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:06:37.889] [bbotk]                     4040        0.718 -0.9435512         <NA>   0.9544316 
INFO  [00:06:37.889] [bbotk]                                 uhash 
INFO  [00:06:37.889] [bbotk]  beff9dc1-ebfd-4da7-8433-ea423394b591 
DEBUG [00:06:39.120] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.182365e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.182365e-05 0.001489339 
  - best initial criterion value(s) :  496.763 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -496.76  |proj g|=       4.7285
At iterate     1  f =      -504.07  |proj g|=        9.1231
At iterate     2  f =      -507.61  |proj g|=        8.5422
At iterate     3  f =      -514.03  |proj g|=        6.4606
At iterate     4  f =      -514.57  |proj g|=        5.6728
At iterate     5  f =       -514.8  |proj g|=        5.5541
At iterate     6  f =      -515.12  |proj g|=        5.7611
At iterate     7  f =      -515.12  |proj g|=        5.7694
At iterate     8  f =      -515.12  |proj g|=        5.7675
At iterate     9  f =      -515.12  |proj g|=        5.7645
At iterate    10  f =      -515.13  |proj g|=        5.7622
At iterate    11  f =      -515.13  |proj g|=        5.7422
At iterate    12  f =      -515.13  |proj g|=        5.7397
At iterate    13  f =      -515.13  |proj g|=        5.6397
At iterate    14  f =      -515.15  |proj g|=        5.6754
At iterate    15  f =      -515.21  |proj g|=        5.8015
At iterate    16  f =      -515.35  |proj g|=        5.9601
At iterate    17  f =      -515.73  |proj g|=        6.2445
At iterate    18  f =      -516.68  |proj g|=        6.7016
At iterate    19  f =      -519.02  |proj g|=        7.7871
At iterate    20  f =      -523.89  |proj g|=          9.09
At iterate    21  f =      -526.15  |proj g|=        12.215
At iterate    22  f =      -536.35  |proj g|=        10.499
At iterate    23  f =      -536.57  |proj g|=         9.485
At iterate    24  f =      -536.66  |proj g|=         9.595
At iterate    25  f =      -536.69  |proj g|=        9.5055
At iterate    26  f =      -536.69  |proj g|=        9.5248
At iterate    27  f =      -536.69  |proj g|=        9.5256
At iterate    28  f =      -536.69  |proj g|=        9.5259
At iterate    29  f =      -536.69  |proj g|=        9.5278
At iterate    30  f =      -536.69  |proj g|=        9.5295
At iterate    31  f =      -536.69  |proj g|=        9.5457
At iterate    32  f =      -536.69  |proj g|=        9.5398
At iterate    33  f =      -536.69  |proj g|=        9.5281
At iterate    34  f =      -536.69  |proj g|=        9.5118
At iterate    35  f =      -536.69  |proj g|=        9.4847
At iterate    36  f =       -536.7  |proj g|=         9.449
At iterate    37  f =      -536.71  |proj g|=        9.3822
At iterate    38  f =      -536.74  |proj g|=        9.2818
At iterate    39  f =      -536.81  |proj g|=        9.1514
At iterate    40  f =      -536.96  |proj g|=        8.8425
At iterate    41  f =      -537.32  |proj g|=         8.637
At iterate    42  f =      -537.44  |proj g|=        7.6481
At iterate    43  f =       -538.1  |proj g|=        7.4144
At iterate    44  f =      -540.41  |proj g|=        6.1668
At iterate    45  f =      -547.04  |proj g|=        3.9922
At iterate    46  f =      -554.28  |proj g|=        2.6245
At iterate    47  f =      -556.51  |proj g|=         1.358
At iterate    48  f =      -557.07  |proj g|=       0.40869
At iterate    49  f =      -557.63  |proj g|=       0.57268
At iterate    50  f =      -557.65  |proj g|=       0.29123
At iterate    51  f =      -557.66  |proj g|=       0.56504
At iterate    52  f =      -557.67  |proj g|=      0.070092
At iterate    53  f =      -557.67  |proj g|=     0.0070819
At iterate    54  f =      -557.67  |proj g|=     0.0025941

iterations 54
function evaluations 61
segments explored during Cauchy searches 58
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00259406
final function value -557.665

F = -557.665
final  value -557.665256 
converged
 
INFO  [00:06:39.124] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:06:39.178] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:06:39.185] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:06:52.272] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:07:01.663] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:07:12.497] [mlr3]  Finished benchmark 
INFO  [00:07:12.566] [bbotk] Result of batch 96: 
INFO  [00:07:12.568] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:07:12.568] [bbotk]              5.529112                 6.271226                       0.2541603 
INFO  [00:07:12.568] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:07:12.568] [bbotk]                     4905        0.732 -0.9432142         <NA>   0.9757826 
INFO  [00:07:12.568] [bbotk]                                 uhash 
INFO  [00:07:12.568] [bbotk]  cd87c18a-ee53-4b2f-bbc5-ba2309cd044b 
DEBUG [00:07:13.785] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.177254e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.177254e-05 0.001487949 
  - best initial criterion value(s) :  522.7911 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -522.79  |proj g|=       4.4628
At iterate     1  f =      -525.28  |proj g|=        5.9067
At iterate     2  f =      -526.58  |proj g|=         5.387
At iterate     3  f =      -527.22  |proj g|=        4.6581
At iterate     4  f =      -527.72  |proj g|=        4.8297
At iterate     5  f =      -528.81  |proj g|=        4.4778
At iterate     6  f =      -529.21  |proj g|=        4.0402
At iterate     7  f =      -529.23  |proj g|=        4.1231
At iterate     8  f =      -529.32  |proj g|=         4.074
At iterate     9  f =      -530.06  |proj g|=        3.7792
At iterate    10  f =      -530.06  |proj g|=        3.7818
At iterate    11  f =      -531.59  |proj g|=        3.3799
At iterate    12  f =      -558.22  |proj g|=        2.1024
At iterate    13  f =      -559.85  |proj g|=         1.458
At iterate    14  f =      -561.55  |proj g|=       0.64583
At iterate    15  f =      -562.15  |proj g|=       0.62972
At iterate    16  f =      -562.52  |proj g|=       0.60476
At iterate    17  f =      -562.62  |proj g|=       0.58642
At iterate    18  f =      -562.64  |proj g|=       0.57791
At iterate    19  f =      -562.65  |proj g|=       0.40116
At iterate    20  f =      -562.65  |proj g|=       0.39927
At iterate    21  f =      -562.65  |proj g|=       0.39945

iterations 21
function evaluations 27
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.399455
final function value -562.653

F = -562.653
final  value -562.652649 
converged
 
INFO  [00:07:13.788] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:07:13.837] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:07:13.844] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:07:19.642] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:07:25.359] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:07:31.037] [mlr3]  Finished benchmark 
INFO  [00:07:31.108] [bbotk] Result of batch 97: 
INFO  [00:07:31.110] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:07:31.110] [bbotk]               7.07906                  6.69617                       0.0523601 
INFO  [00:07:31.110] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:07:31.110] [bbotk]                     2883        0.877 -0.9448768         <NA>   0.9656582 
INFO  [00:07:31.110] [bbotk]                                 uhash 
INFO  [00:07:31.110] [bbotk]  277b4881-c9ce-409b-9900-225e78d8abe8 
DEBUG [00:07:32.187] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.168604e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.168604e-05 0.001479849 
  - best initial criterion value(s) :  518.9662 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -518.97  |proj g|=       3.8113
At iterate     1  f =      -534.67  |proj g|=        3.1171
At iterate     2  f =       -545.2  |proj g|=        3.7348
At iterate     3  f =      -546.42  |proj g|=        3.6153
At iterate     4  f =      -547.86  |proj g|=         3.345
At iterate     5  f =       -548.1  |proj g|=        3.2365
At iterate     6  f =      -548.16  |proj g|=        3.2026
At iterate     7  f =      -548.21  |proj g|=        3.3072
At iterate     8  f =      -548.22  |proj g|=         3.284
At iterate     9  f =      -548.22  |proj g|=        3.2836
At iterate    10  f =      -548.23  |proj g|=        3.2836
At iterate    11  f =      -548.23  |proj g|=        3.2836
At iterate    12  f =      -548.24  |proj g|=         3.283
At iterate    13  f =      -548.25  |proj g|=        3.2608
At iterate    14  f =      -548.26  |proj g|=        3.2937
At iterate    15  f =       -548.3  |proj g|=        3.2653
At iterate    16  f =      -548.92  |proj g|=        3.1321
At iterate    17  f =      -554.49  |proj g|=        2.1871
At iterate    18  f =      -561.68  |proj g|=       0.95785
At iterate    19  f =      -564.93  |proj g|=        1.2176
At iterate    20  f =      -566.73  |proj g|=       0.54613
At iterate    21  f =      -566.78  |proj g|=       0.68154
At iterate    22  f =      -566.82  |proj g|=        0.5155
At iterate    23  f =      -566.82  |proj g|=        0.4957
At iterate    24  f =      -566.82  |proj g|=       0.49791
At iterate    25  f =      -566.82  |proj g|=       0.49787

iterations 25
function evaluations 34
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.497873
final function value -566.817

F = -566.817
final  value -566.817454 
converged
 
INFO  [00:07:32.191] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:07:32.248] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:07:32.255] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:07:42.583] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:07:52.965] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:08:03.142] [mlr3]  Finished benchmark 
INFO  [00:08:03.212] [bbotk] Result of batch 98: 
INFO  [00:08:03.214] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:08:03.214] [bbotk]              7.918328                 3.934351                       0.1721373 
INFO  [00:08:03.214] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:08:03.214] [bbotk]                     4996        0.707 -0.9472178         <NA>   0.9748219 
INFO  [00:08:03.214] [bbotk]                                 uhash 
INFO  [00:08:03.214] [bbotk]  413360bc-018d-4729-921e-00d5e5216108 
DEBUG [00:08:04.226] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.162619e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.162619e-05 0.001474946 
  - best initial criterion value(s) :  544.7917 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -544.79  |proj g|=       2.1484
At iterate     1  f =      -559.18  |proj g|=        3.3507
At iterate     2  f =      -559.78  |proj g|=        2.9687
At iterate     3  f =      -560.36  |proj g|=        2.3982
At iterate     4  f =      -560.71  |proj g|=        2.6412
At iterate     5  f =      -560.82  |proj g|=        2.6442
At iterate     6  f =      -560.84  |proj g|=          2.64
At iterate     7  f =      -560.84  |proj g|=        2.6424
At iterate     8  f =      -560.84  |proj g|=        2.6422
At iterate     9  f =      -560.84  |proj g|=        2.6422

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.64218
final function value -560.844

F = -560.844
final  value -560.843882 
converged
 
INFO  [00:08:04.231] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:08:04.287] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:08:04.294] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:08:11.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:08:20.149] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:08:29.446] [mlr3]  Finished benchmark 
INFO  [00:08:29.515] [bbotk] Result of batch 99: 
INFO  [00:08:29.517] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:08:29.517] [bbotk]              7.894463                 6.147737                       0.4568734 
INFO  [00:08:29.517] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:08:29.517] [bbotk]                     3267        0.742 -0.9510817         <NA>   0.9763265 
INFO  [00:08:29.517] [bbotk]                                 uhash 
INFO  [00:08:29.517] [bbotk]  3f1a1172-e476-4936-91c6-2f41ff0e396a 
DEBUG [00:08:30.650] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.158317e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.158317e-05 0.001477477 
  - best initial criterion value(s) :  519.5714 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -519.57  |proj g|=       5.1143
At iterate     1  f =      -527.87  |proj g|=        6.1837
At iterate     2  f =      -530.97  |proj g|=        5.8516
At iterate     3  f =      -533.63  |proj g|=        4.9667
At iterate     4  f =      -533.67  |proj g|=        4.7043
At iterate     5  f =       -533.7  |proj g|=        4.7917
At iterate     6  f =      -533.71  |proj g|=        4.8056
At iterate     7  f =      -533.78  |proj g|=        4.7965
At iterate     8  f =      -533.82  |proj g|=        4.7198
At iterate     9  f =      -533.83  |proj g|=        4.6434
At iterate    10  f =      -533.83  |proj g|=        4.6362
At iterate    11  f =      -533.83  |proj g|=        4.6361
At iterate    12  f =      -533.83  |proj g|=        4.6355
At iterate    13  f =      -533.83  |proj g|=        4.6316
At iterate    14  f =      -533.83  |proj g|=        4.6262
At iterate    15  f =      -533.83  |proj g|=        4.6152
At iterate    16  f =      -533.84  |proj g|=        4.6009
At iterate    17  f =      -533.86  |proj g|=        4.5843
At iterate    18  f =       -533.9  |proj g|=        4.5698
At iterate    19  f =      -533.99  |proj g|=        4.5538
At iterate    20  f =      -534.19  |proj g|=        4.5788
At iterate    21  f =      -534.21  |proj g|=        4.4701
At iterate    22  f =      -534.62  |proj g|=        4.4581
At iterate    23  f =      -539.42  |proj g|=        3.7422
At iterate    24  f =      -539.73  |proj g|=        3.4753
At iterate    25  f =      -539.82  |proj g|=          3.58
At iterate    26  f =      -539.82  |proj g|=        3.5633
At iterate    27  f =      -539.82  |proj g|=        3.5647
At iterate    28  f =      -539.82  |proj g|=        3.5643

iterations 28
function evaluations 38
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.56431
final function value -539.82

F = -539.82
final  value -539.819999 
converged
 
INFO  [00:08:30.654] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:08:30.710] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:08:30.718] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:08:35.888] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:08:39.513] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:08:43.870] [mlr3]  Finished benchmark 
INFO  [00:08:43.939] [bbotk] Result of batch 100: 
INFO  [00:08:43.941] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:08:43.941] [bbotk]               2.53997                 3.025179                       0.3726612 
INFO  [00:08:43.941] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:08:43.941] [bbotk]                     1362        0.736 -0.9604102         <NA>   0.9613354 
INFO  [00:08:43.941] [bbotk]                                 uhash 
INFO  [00:08:43.941] [bbotk]  ed7ac381-b179-4ef4-a26a-06e42f4566d5 
DEBUG [00:08:45.077] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.153393e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.153393e-05 0.001465905 
  - best initial criterion value(s) :  522.6869 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -522.69  |proj g|=        14.06
At iterate     1  f =      -555.32  |proj g|=        5.9479
At iterate     2  f =       -563.8  |proj g|=        6.0772
At iterate     3  f =      -566.58  |proj g|=        4.2839
At iterate     4  f =      -568.82  |proj g|=        2.2196
At iterate     5  f =      -569.26  |proj g|=        1.5857
At iterate     6  f =      -569.52  |proj g|=        1.2961
At iterate     7  f =       -569.7  |proj g|=        2.6089
At iterate     8  f =      -570.13  |proj g|=        1.6964
At iterate     9  f =      -570.13  |proj g|=        1.5965
At iterate    10  f =      -570.13  |proj g|=        1.5851
At iterate    11  f =      -570.14  |proj g|=        1.5937
At iterate    12  f =      -570.14  |proj g|=        1.6187
At iterate    13  f =      -570.15  |proj g|=        1.6375
At iterate    14  f =      -570.17  |proj g|=        1.6676
At iterate    15  f =      -570.24  |proj g|=        1.6825
At iterate    16  f =      -570.39  |proj g|=        1.6101
At iterate    17  f =      -570.66  |proj g|=        1.3217
At iterate    18  f =      -570.77  |proj g|=       0.89236
At iterate    19  f =      -570.87  |proj g|=       0.85279
At iterate    20  f =       -571.5  |proj g|=       0.70942
At iterate    21  f =      -573.41  |proj g|=       0.48752
At iterate    22  f =      -574.49  |proj g|=       0.56497
At iterate    23  f =      -574.65  |proj g|=        0.5083
At iterate    24  f =      -574.67  |proj g|=       0.52489
At iterate    25  f =      -574.69  |proj g|=       0.60267
At iterate    26  f =      -574.69  |proj g|=       0.54468
At iterate    27  f =      -574.69  |proj g|=       0.54395
At iterate    28  f =      -574.69  |proj g|=       0.54398

iterations 28
function evaluations 34
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.543983
final function value -574.687

F = -574.687
final  value -574.686954 
converged
 
INFO  [00:08:45.081] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:08:45.137] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:08:45.144] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:08:54.592] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:09:03.236] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:09:13.239] [mlr3]  Finished benchmark 
INFO  [00:09:13.310] [bbotk] Result of batch 101: 
INFO  [00:09:13.312] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:09:13.312] [bbotk]              9.715047                 5.077988                       0.1448428 
INFO  [00:09:13.312] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:09:13.312] [bbotk]                     3211        0.748 -0.9510052         <NA>   0.9730211 
INFO  [00:09:13.312] [bbotk]                                 uhash 
INFO  [00:09:13.312] [bbotk]  c1bc902e-7931-4e95-bd7d-780b88ab6882 
DEBUG [00:09:14.584] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.146132e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.146132e-05 0.001461842 
  - best initial criterion value(s) :  523.6276 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -523.63  |proj g|=       4.9511
At iterate     1  f =      -542.06  |proj g|=        2.9167
At iterate     2  f =      -545.55  |proj g|=         3.142
At iterate     3  f =       -553.3  |proj g|=        2.7951
At iterate     4  f =      -555.59  |proj g|=        2.1413
At iterate     5  f =      -556.65  |proj g|=        2.5015
At iterate     6  f =      -556.65  |proj g|=        2.5402
At iterate     7  f =      -556.66  |proj g|=          2.53
At iterate     8  f =      -556.66  |proj g|=        2.5286
At iterate     9  f =      -556.66  |proj g|=        2.5302
At iterate    10  f =      -556.66  |proj g|=        2.5338
At iterate    11  f =      -556.66  |proj g|=        2.5412
At iterate    12  f =      -556.66  |proj g|=         2.552
At iterate    13  f =      -556.66  |proj g|=        2.5695
At iterate    14  f =      -556.68  |proj g|=        2.5955
At iterate    15  f =      -556.71  |proj g|=        2.6338
At iterate    16  f =      -556.81  |proj g|=        2.6847
At iterate    17  f =      -557.06  |proj g|=        2.7362
At iterate    18  f =      -557.64  |proj g|=        2.7416
At iterate    19  f =      -558.81  |proj g|=         2.608
At iterate    20  f =      -560.98  |proj g|=         2.207
At iterate    21  f =      -561.82  |proj g|=        1.9118
At iterate    22  f =       -562.1  |proj g|=        1.7037
At iterate    23  f =      -562.17  |proj g|=        1.7577
At iterate    24  f =      -562.34  |proj g|=        1.8187
At iterate    25  f =      -562.89  |proj g|=        1.9385
At iterate    26  f =      -563.87  |proj g|=        2.0383
At iterate    27  f =      -565.41  |proj g|=        2.0177
At iterate    28  f =      -565.68  |proj g|=         2.081
At iterate    29  f =      -566.52  |proj g|=        1.9929
At iterate    30  f =      -567.35  |proj g|=        1.8221
At iterate    31  f =      -567.49  |proj g|=        1.7307
At iterate    32  f =       -567.5  |proj g|=        1.7212
At iterate    33  f =      -567.53  |proj g|=        1.7556
At iterate    34  f =      -567.53  |proj g|=        1.7548
At iterate    35  f =      -567.53  |proj g|=        1.7541
At iterate    36  f =      -567.53  |proj g|=        1.7541

iterations 36
function evaluations 49
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.75412
final function value -567.53

F = -567.53
final  value -567.530331 
converged
 
INFO  [00:09:14.587] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:09:14.676] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:09:14.684] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:09:18.755] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:09:23.593] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:09:28.723] [mlr3]  Finished benchmark 
INFO  [00:09:28.794] [bbotk] Result of batch 102: 
INFO  [00:09:28.796] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:09:28.796] [bbotk]              2.674352                   5.7495                       0.4251656 
INFO  [00:09:28.796] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:09:28.796] [bbotk]                     1271        0.816 -0.9567273         <NA>   0.9635845 
INFO  [00:09:28.796] [bbotk]                                 uhash 
INFO  [00:09:28.796] [bbotk]  f2b4b083-de2b-47d8-b737-b0086a0eecc7 
DEBUG [00:09:30.202] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.139296e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.139296e-05 0.001447417 
  - best initial criterion value(s) :  541.1004 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -541.1  |proj g|=       1.1576
At iterate     1  f =       -567.2  |proj g|=        11.993
At iterate     2  f =      -572.09  |proj g|=        10.082
At iterate     3  f =       -573.1  |proj g|=        7.0123
At iterate     4  f =      -573.38  |proj g|=        8.6484
At iterate     5  f =      -573.49  |proj g|=        8.2359
At iterate     6  f =      -573.52  |proj g|=         8.009
At iterate     7  f =      -573.52  |proj g|=        8.0642
At iterate     8  f =      -573.52  |proj g|=        8.0747
At iterate     9  f =      -573.52  |proj g|=        8.0748

iterations 9
function evaluations 15
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 8.07483
final function value -573.523

F = -573.523
final  value -573.522746 
converged
 
INFO  [00:09:30.206] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:09:30.606] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:09:30.613] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:09:35.044] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:09:39.943] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:09:43.765] [mlr3]  Finished benchmark 
INFO  [00:09:43.833] [bbotk] Result of batch 103: 
INFO  [00:09:43.835] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:09:43.835] [bbotk]              9.106597                 5.830963                      0.09052983 
INFO  [00:09:43.835] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:09:43.835] [bbotk]                     1622        1.061 -0.9564697         <NA>   0.9661417 
INFO  [00:09:43.835] [bbotk]                                 uhash 
INFO  [00:09:43.835] [bbotk]  f1a13678-1274-493a-972c-dce129f591c4 
DEBUG [00:09:45.161] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.131146e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.131146e-05 0.001430868 
  - best initial criterion value(s) :  534.6796 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -534.68  |proj g|=       3.0419
At iterate     1  f =      -542.44  |proj g|=        2.8575
At iterate     2  f =      -547.84  |proj g|=         2.386
At iterate     3  f =      -548.34  |proj g|=        2.3019
At iterate     4  f =      -548.34  |proj g|=        2.3119
At iterate     5  f =      -548.54  |proj g|=        2.2266
At iterate     6  f =      -548.55  |proj g|=        2.2129
At iterate     7  f =      -548.55  |proj g|=        2.2118
At iterate     8  f =      -548.55  |proj g|=         2.209
At iterate     9  f =      -548.55  |proj g|=        2.2058
At iterate    10  f =      -548.55  |proj g|=        2.1591
At iterate    11  f =      -548.57  |proj g|=        2.1817
At iterate    12  f =       -548.6  |proj g|=        2.2022
At iterate    13  f =       -548.7  |proj g|=        2.2418
At iterate    14  f =      -548.91  |proj g|=        2.2711
At iterate    15  f =       -549.4  |proj g|=        2.2532
At iterate    16  f =      -550.28  |proj g|=        2.1256
At iterate    17  f =      -551.81  |proj g|=        2.1499
At iterate    18  f =      -555.71  |proj g|=        2.7701
At iterate    19  f =       -556.4  |proj g|=        1.9244
At iterate    20  f =      -556.59  |proj g|=        2.5537
At iterate    21  f =      -556.62  |proj g|=        2.4285
At iterate    22  f =      -556.65  |proj g|=        2.3241
At iterate    23  f =       -556.7  |proj g|=        2.1894
At iterate    24  f =       -556.8  |proj g|=        1.9953
At iterate    25  f =      -557.01  |proj g|=         1.751
At iterate    26  f =      -557.24  |proj g|=        1.7054
At iterate    27  f =      -557.31  |proj g|=        1.9167
At iterate    28  f =      -557.31  |proj g|=        1.9595
At iterate    29  f =      -557.31  |proj g|=         1.963
At iterate    30  f =      -557.31  |proj g|=        1.9631

iterations 30
function evaluations 35
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.96307
final function value -557.308

F = -557.308
final  value -557.307873 
converged
 
INFO  [00:09:45.165] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:09:45.221] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:09:45.227] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:09:51.445] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:09:57.165] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:10:03.900] [mlr3]  Finished benchmark 
INFO  [00:10:03.985] [bbotk] Result of batch 104: 
INFO  [00:10:03.987] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:10:03.987] [bbotk]              3.178865                 7.720675                       0.2439346 
INFO  [00:10:03.987] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:10:03.987] [bbotk]                     2311        0.868 -0.9621477         <NA>   0.9682507 
INFO  [00:10:03.987] [bbotk]                                 uhash 
INFO  [00:10:03.987] [bbotk]  35799c47-fe99-4ef2-a51b-26eb88c55e62 
DEBUG [00:10:05.396] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.122709e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.970258 9504 
  - variance bounds :  1.122709e-05 0.001429533 
  - best initial criterion value(s) :  539.7277 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -539.73  |proj g|=       13.298
At iterate     1  f =      -565.32  |proj g|=        2.8191
At iterate     2  f =         -585  |proj g|=        3.2601
At iterate     3  f =      -588.79  |proj g|=        2.2385
At iterate     4  f =      -592.71  |proj g|=        2.1467
At iterate     5  f =      -594.46  |proj g|=        2.1123
At iterate     6  f =      -595.66  |proj g|=        2.1359
At iterate     7  f =       -596.7  |proj g|=        2.5287
At iterate     8  f =      -597.51  |proj g|=        2.4914
At iterate     9  f =      -597.87  |proj g|=        2.5089
At iterate    10  f =      -597.99  |proj g|=        2.5525
At iterate    11  f =      -598.03  |proj g|=        2.5968
At iterate    12  f =      -598.03  |proj g|=        2.6167
At iterate    13  f =      -598.03  |proj g|=          2.62
At iterate    14  f =      -598.03  |proj g|=        2.6209
At iterate    15  f =      -598.03  |proj g|=        2.6232
At iterate    16  f =      -598.03  |proj g|=        2.6266
At iterate    17  f =      -598.04  |proj g|=        2.6321
At iterate    18  f =      -598.04  |proj g|=        2.6406
At iterate    19  f =      -598.04  |proj g|=        2.6547
At iterate    20  f =      -598.06  |proj g|=        2.6764
At iterate    21  f =       -598.1  |proj g|=        2.7097
At iterate    22  f =      -598.19  |proj g|=        2.7536
At iterate    23  f =      -598.41  |proj g|=        2.7877
At iterate    24  f =      -598.81  |proj g|=         2.718
At iterate    25  f =      -598.89  |proj g|=        2.5412
At iterate    26  f =      -598.92  |proj g|=        2.6044
At iterate    27  f =      -598.93  |proj g|=        2.5847
At iterate    28  f =      -598.99  |proj g|=        2.5537
At iterate    29  f =      -599.36  |proj g|=        2.4289
At iterate    30  f =      -600.03  |proj g|=        2.3126
At iterate    31  f =      -601.38  |proj g|=        2.2121
At iterate    32  f =      -601.39  |proj g|=         2.232
At iterate    33  f =      -601.95  |proj g|=         2.243
At iterate    34  f =      -602.19  |proj g|=        2.3099
At iterate    35  f =      -602.26  |proj g|=         2.362
At iterate    36  f =      -602.27  |proj g|=        2.3811
At iterate    37  f =      -602.27  |proj g|=        2.3891
At iterate    38  f =      -602.27  |proj g|=        2.3873
At iterate    39  f =      -602.27  |proj g|=        2.3882
At iterate    40  f =      -602.27  |proj g|=        2.3883

iterations 40
function evaluations 49
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.3883
final function value -602.271

F = -602.271
final  value -602.271061 
converged
 
INFO  [00:10:05.400] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:10:05.454] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:10:05.461] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:10:18.497] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:10:34.632] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:10:47.726] [mlr3]  Finished benchmark 
INFO  [00:10:47.794] [bbotk] Result of batch 105: 
INFO  [00:10:47.796] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:10:47.796] [bbotk]              4.071746                 9.718978                      0.01085691 
INFO  [00:10:47.796] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:10:47.796] [bbotk]                     4947        0.891 -0.9383142         <NA>   0.9493762 
INFO  [00:10:47.796] [bbotk]                                 uhash 
INFO  [00:10:47.796] [bbotk]  26f345c4-8a2e-4699-a0f3-86fb3abf6b0e 
DEBUG [00:10:49.152] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.141239e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9738152 9504 
  - variance bounds :  1.141239e-05 0.00144731 
  - best initial criterion value(s) :  539.9603 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -539.96  |proj g|=       7.2047
At iterate     1  f =      -574.63  |proj g|=        6.7114
At iterate     2  f =      -579.45  |proj g|=        5.4699
At iterate     3  f =      -583.58  |proj g|=        3.9069
At iterate     4  f =      -584.72  |proj g|=         4.533
At iterate     5  f =      -584.94  |proj g|=        4.4842
At iterate     6  f =      -586.33  |proj g|=        4.2519
At iterate     7  f =      -587.24  |proj g|=        4.2832
At iterate     8  f =      -587.77  |proj g|=        4.4114
At iterate     9  f =      -587.97  |proj g|=         4.523
At iterate    10  f =      -588.03  |proj g|=        4.6135
At iterate    11  f =      -588.03  |proj g|=        4.6365
At iterate    12  f =      -588.03  |proj g|=        4.6444
At iterate    13  f =      -588.03  |proj g|=        4.6465
At iterate    14  f =      -588.03  |proj g|=        4.6476
At iterate    15  f =      -588.03  |proj g|=        4.6537
At iterate    16  f =      -588.04  |proj g|=        4.6619
At iterate    17  f =      -588.05  |proj g|=        4.6758
At iterate    18  f =      -588.08  |proj g|=        4.6921
At iterate    19  f =      -588.14  |proj g|=        4.7728
At iterate    20  f =      -588.28  |proj g|=        4.7572
At iterate    21  f =      -588.38  |proj g|=        4.9439
At iterate    22  f =      -588.68  |proj g|=         4.878
At iterate    23  f =      -589.52  |proj g|=        4.7051
At iterate    24  f =      -590.55  |proj g|=        4.4372
At iterate    25  f =      -590.84  |proj g|=        4.2988
At iterate    26  f =       -590.9  |proj g|=        4.5003
At iterate    27  f =      -590.92  |proj g|=        4.4513
At iterate    28  f =      -590.92  |proj g|=        4.4417
At iterate    29  f =      -590.92  |proj g|=        4.4438
At iterate    30  f =      -590.92  |proj g|=        4.4437
At iterate    31  f =      -590.92  |proj g|=        4.4445
At iterate    32  f =      -590.93  |proj g|=        4.4053
At iterate    33  f =      -590.97  |proj g|=        4.4022
At iterate    34  f =      -593.83  |proj g|=        3.9075
At iterate    35  f =      -607.62  |proj g|=        2.0742
At iterate    36  f =      -611.53  |proj g|=       0.55919
At iterate    37  f =      -611.54  |proj g|=       0.41748
At iterate    38  f =      -611.54  |proj g|=       0.41723
At iterate    39  f =      -611.54  |proj g|=       0.41707
At iterate    40  f =      -611.54  |proj g|=       0.41613
At iterate    41  f =      -611.54  |proj g|=       0.39885
At iterate    42  f =      -611.54  |proj g|=       0.21866
At iterate    43  f =      -611.54  |proj g|=      0.035265
At iterate    44  f =      -611.54  |proj g|=       0.20903
At iterate    45  f =      -611.55  |proj g|=       0.15527
At iterate    46  f =      -611.55  |proj g|=     0.0014197
At iterate    47  f =      -611.55  |proj g|=     0.0014197

iterations 47
function evaluations 57
segments explored during Cauchy searches 50
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00141968
final function value -611.545

F = -611.545
final  value -611.545187 
converged
 
INFO  [00:10:49.156] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:10:49.211] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:10:49.218] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:10:58.384] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:11:07.960] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:11:17.851] [mlr3]  Finished benchmark 
INFO  [00:11:17.921] [bbotk] Result of batch 106: 
INFO  [00:11:17.923] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:11:17.923] [bbotk]              7.307257                 7.800454                       0.2668451 
INFO  [00:11:17.923] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:11:17.923] [bbotk]                     3617        0.815 -0.9379967         <NA>    0.974975 
INFO  [00:11:17.923] [bbotk]                                 uhash 
INFO  [00:11:17.923] [bbotk]  1159e131-a89d-4111-80a6-c1334585f302 
DEBUG [00:11:19.122] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.136057e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9738152 9504 
  - variance bounds :  1.136057e-05 0.001444941 
  - best initial criterion value(s) :  538.9525 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -538.95  |proj g|=       6.5044
At iterate     1  f =      -545.03  |proj g|=        3.6191
At iterate     2  f =      -545.35  |proj g|=        3.4621
At iterate     3  f =      -545.74  |proj g|=        2.9661
At iterate     4  f =      -545.76  |proj g|=        3.0701
At iterate     5  f =      -545.79  |proj g|=        2.9094
At iterate     6  f =      -545.79  |proj g|=        2.8788
At iterate     7  f =       -545.8  |proj g|=        2.8626
At iterate     8  f =      -545.83  |proj g|=        2.8382
At iterate     9  f =      -545.96  |proj g|=        2.7683
At iterate    10  f =      -546.26  |proj g|=         2.454
At iterate    11  f =      -546.34  |proj g|=        2.7195
At iterate    12  f =      -546.93  |proj g|=        2.3757
At iterate    13  f =      -548.79  |proj g|=        2.3433
At iterate    14  f =      -553.01  |proj g|=        2.5555
At iterate    15  f =      -554.61  |proj g|=        2.5258
At iterate    16  f =      -555.88  |proj g|=        2.3192
At iterate    17  f =      -556.01  |proj g|=        2.2002
At iterate    18  f =       -556.1  |proj g|=        2.2047
At iterate    19  f =      -556.12  |proj g|=        2.2199
At iterate    20  f =      -556.12  |proj g|=        2.2209
At iterate    21  f =      -556.12  |proj g|=        2.2208
At iterate    22  f =      -556.12  |proj g|=        2.2209

iterations 22
function evaluations 32
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.22094
final function value -556.117

F = -556.117
final  value -556.116613 
converged
 
INFO  [00:11:19.127] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:11:19.183] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:11:19.190] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:11:32.177] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:11:44.236] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:11:57.774] [mlr3]  Finished benchmark 
INFO  [00:11:57.844] [bbotk] Result of batch 107: 
INFO  [00:11:57.846] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:11:57.846] [bbotk]              7.559464                 5.033261                       0.3887044 
INFO  [00:11:57.846] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:11:57.846] [bbotk]                     4207        0.768 -0.9616145         <NA>   0.9765288 
INFO  [00:11:57.846] [bbotk]                                 uhash 
INFO  [00:11:57.846] [bbotk]  f522ddd1-3f0b-47ba-bf32-5ce4fc379856 
DEBUG [00:11:59.138] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.132563e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9738152 9504 
  - variance bounds :  1.132563e-05 0.001445229 
  - best initial criterion value(s) :  582.9795 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -582.98  |proj g|=       3.3816
At iterate     1  f =      -611.26  |proj g|=        2.8084
At iterate     2  f =      -611.64  |proj g|=        2.5864
At iterate     3  f =      -612.18  |proj g|=        2.3973
At iterate     4  f =      -612.42  |proj g|=          2.47
At iterate     5  f =      -612.45  |proj g|=         2.511
At iterate     6  f =      -612.45  |proj g|=        2.5098
At iterate     7  f =      -612.45  |proj g|=        2.5087
At iterate     8  f =      -612.45  |proj g|=        2.5066
At iterate     9  f =      -612.46  |proj g|=        2.5039
At iterate    10  f =      -612.46  |proj g|=         2.499
At iterate    11  f =      -612.46  |proj g|=        2.4916
At iterate    12  f =      -612.48  |proj g|=        2.4817
At iterate    13  f =      -612.52  |proj g|=        2.4642
At iterate    14  f =      -612.63  |proj g|=        2.4483
At iterate    15  f =      -612.67  |proj g|=        2.3864
At iterate    16  f =      -612.95  |proj g|=        2.3609
At iterate    17  f =      -618.19  |proj g|=        1.9073
At iterate    18  f =      -619.12  |proj g|=        1.1765
At iterate    19  f =      -619.55  |proj g|=        1.3072
At iterate    20  f =      -619.81  |proj g|=        1.2666
At iterate    21  f =      -619.93  |proj g|=       0.74801
At iterate    22  f =      -620.03  |proj g|=        0.9592
At iterate    23  f =      -620.03  |proj g|=       0.93731
At iterate    24  f =      -620.05  |proj g|=       0.85743
At iterate    25  f =      -620.06  |proj g|=       0.81653
At iterate    26  f =      -620.08  |proj g|=        0.7953
At iterate    27  f =      -620.08  |proj g|=       0.83115
At iterate    28  f =      -620.08  |proj g|=       0.84635
At iterate    29  f =      -620.08  |proj g|=       0.84782
At iterate    30  f =      -620.08  |proj g|=       0.84998
At iterate    31  f =      -620.09  |proj g|=       0.85246
At iterate    32  f =      -620.09  |proj g|=       0.86005
At iterate    33  f =      -620.09  |proj g|=       0.86993
At iterate    34  f =      -620.09  |proj g|=       0.88673
At iterate    35  f =      -620.09  |proj g|=       0.90958
At iterate    36  f =       -620.1  |proj g|=       0.95945
At iterate    37  f =      -620.13  |proj g|=       0.99963
At iterate    38  f =      -620.15  |proj g|=        1.1134
At iterate    39  f =      -620.24  |proj g|=        1.1317
At iterate    40  f =      -620.67  |proj g|=       0.88701
At iterate    41  f =      -621.28  |proj g|=       0.82741
At iterate    42  f =      -622.07  |proj g|=       0.60278
At iterate    43  f =      -622.17  |proj g|=       0.14572
At iterate    44  f =      -622.17  |proj g|=       0.40055
At iterate    45  f =      -622.17  |proj g|=       0.46011
At iterate    46  f =      -622.17  |proj g|=     0.0021642
At iterate    47  f =      -622.17  |proj g|=     0.0021639

iterations 47
function evaluations 54
segments explored during Cauchy searches 49
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00216388
final function value -622.175

F = -622.175
final  value -622.174803 
converged
 
INFO  [00:11:59.143] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:11:59.202] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:11:59.209] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:12:13.833] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:12:27.436] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:12:40.697] [mlr3]  Finished benchmark 
INFO  [00:12:40.768] [bbotk] Result of batch 108: 
INFO  [00:12:40.770] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:12:40.770] [bbotk]              7.781282                 5.250948                     0.005642083 
INFO  [00:12:40.770] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:12:40.770] [bbotk]                     4284        0.764 -0.9400567         <NA>   0.9386851 
INFO  [00:12:40.770] [bbotk]                                 uhash 
INFO  [00:12:40.770] [bbotk]  4799761e-72d1-4259-959a-03fd0c60e922 
DEBUG [00:12:42.313] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.188097e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.188097e-05 0.001493669 
  - best initial criterion value(s) :  540.7234 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -540.72  |proj g|=        6.882
At iterate     1  f =      -552.56  |proj g|=        7.9692
At iterate     2  f =      -554.02  |proj g|=        7.9924
At iterate     3  f =      -556.46  |proj g|=        7.1847
At iterate     4  f =      -557.05  |proj g|=        6.5607
At iterate     5  f =      -557.76  |proj g|=        5.7164
At iterate     6  f =      -557.76  |proj g|=        5.6821
At iterate     7  f =      -557.76  |proj g|=        5.6696
At iterate     8  f =      -557.77  |proj g|=        5.6347
At iterate     9  f =      -557.79  |proj g|=        5.5566
At iterate    10  f =      -557.79  |proj g|=        5.5453
At iterate    11  f =      -557.82  |proj g|=        5.4414
At iterate    12  f =      -560.43  |proj g|=        4.4377
At iterate    13  f =      -568.03  |proj g|=        3.3188
At iterate    14  f =      -576.78  |proj g|=         6.503
At iterate    15  f =      -579.51  |proj g|=        5.5649
At iterate    16  f =      -579.64  |proj g|=        6.3299
At iterate    17  f =       -579.9  |proj g|=        6.8055
At iterate    18  f =       -579.9  |proj g|=        6.8667
At iterate    19  f =       -579.9  |proj g|=        6.8676
At iterate    20  f =       -579.9  |proj g|=        6.8675
At iterate    21  f =       -579.9  |proj g|=        6.8731
At iterate    22  f =       -579.9  |proj g|=        6.8638
At iterate    23  f =       -579.9  |proj g|=        6.8697
At iterate    24  f =       -579.9  |proj g|=        6.8835
At iterate    25  f =      -579.91  |proj g|=         6.867
At iterate    26  f =      -579.91  |proj g|=        6.8938
At iterate    27  f =      -579.92  |proj g|=        6.9438
At iterate    28  f =      -579.94  |proj g|=         6.996
At iterate    29  f =      -579.99  |proj g|=        7.1523
At iterate    30  f =      -580.01  |proj g|=        6.9473
At iterate    31  f =      -580.14  |proj g|=        7.1704
At iterate    32  f =      -580.19  |proj g|=        7.3201
At iterate    33  f =      -580.58  |proj g|=        7.7323
At iterate    34  f =         -583  |proj g|=        7.9905
At iterate    35  f =      -586.84  |proj g|=        7.9634
At iterate    36  f =      -589.99  |proj g|=        2.1868
At iterate    37  f =      -599.16  |proj g|=        2.1333
At iterate    38  f =      -603.13  |proj g|=        0.9579
At iterate    39  f =      -604.67  |proj g|=       0.25738
At iterate    40  f =      -604.86  |proj g|=       0.74101
At iterate    41  f =      -605.16  |proj g|=       0.62945
At iterate    42  f =      -605.59  |proj g|=       0.69962
At iterate    43  f =      -605.62  |proj g|=       0.28601
At iterate    44  f =      -605.62  |proj g|=       0.28623
At iterate    45  f =      -605.62  |proj g|=       0.02697
At iterate    46  f =      -605.62  |proj g|=      0.027747
At iterate    47  f =      -605.62  |proj g|=     0.0019951

iterations 47
function evaluations 57
segments explored during Cauchy searches 49
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00199514
final function value -605.621

F = -605.621
final  value -605.620753 
converged
 
INFO  [00:12:42.317] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:12:42.376] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:12:42.383] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:12:55.403] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:13:07.250] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:13:20.080] [mlr3]  Finished benchmark 
INFO  [00:13:20.169] [bbotk] Result of batch 109: 
INFO  [00:13:20.172] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:13:20.172] [bbotk]              7.224038                 4.892657                       0.3013798 
INFO  [00:13:20.172] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:13:20.172] [bbotk]                     4319        0.973 -0.9432256         <NA>   0.9758566 
INFO  [00:13:20.172] [bbotk]                                 uhash 
INFO  [00:13:20.172] [bbotk]  00eb2ede-bf87-4e20-a944-7e61531c9f26 
DEBUG [00:13:21.279] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.183697e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.183697e-05 0.001492088 
  - best initial criterion value(s) :  569.4209 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -569.42  |proj g|=       3.2127
At iterate     1  f =      -588.33  |proj g|=        2.2006
At iterate     2  f =      -592.85  |proj g|=        3.9788
At iterate     3  f =       -594.3  |proj g|=        3.4934
At iterate     4  f =      -596.69  |proj g|=         2.769
At iterate     5  f =      -597.28  |proj g|=        2.8855
At iterate     6  f =      -597.32  |proj g|=        2.8822
At iterate     7  f =      -597.33  |proj g|=        2.9237
At iterate     8  f =      -597.33  |proj g|=        2.9023
At iterate     9  f =      -597.33  |proj g|=        2.9029
At iterate    10  f =      -597.33  |proj g|=        2.9029
At iterate    11  f =      -597.33  |proj g|=        2.9029

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.90295
final function value -597.334

F = -597.334
final  value -597.333966 
converged
 
INFO  [00:13:21.283] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:13:21.340] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:13:21.347] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:13:35.124] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:13:43.977] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:13:54.119] [mlr3]  Finished benchmark 
INFO  [00:13:54.189] [bbotk] Result of batch 110: 
INFO  [00:13:54.191] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:13:54.191] [bbotk]              5.882961                 5.850011                       0.1019168 
INFO  [00:13:54.191] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:13:54.191] [bbotk]                     3445        0.758 -0.9523715         <NA>   0.9711835 
INFO  [00:13:54.191] [bbotk]                                 uhash 
INFO  [00:13:54.191] [bbotk]  ac338681-1825-4076-bdaa-a6695098fbf2 
DEBUG [00:13:55.702] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.175835e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.175835e-05 0.001485339 
  - best initial criterion value(s) :  539.3432 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -539.34  |proj g|=       4.8335
At iterate     1  f =       -543.3  |proj g|=        8.3719
At iterate     2  f =      -552.22  |proj g|=        7.5992
At iterate     3  f =       -559.1  |proj g|=        5.8713
At iterate     4  f =      -566.65  |proj g|=        5.0308
At iterate     5  f =      -567.78  |proj g|=        5.3208
At iterate     6  f =      -568.03  |proj g|=        5.4379
At iterate     7  f =      -568.03  |proj g|=        5.4358
At iterate     8  f =      -568.03  |proj g|=        5.4333
At iterate     9  f =      -568.03  |proj g|=        5.4327
At iterate    10  f =      -568.03  |proj g|=        5.4295
At iterate    11  f =      -568.03  |proj g|=        5.4256
At iterate    12  f =      -568.03  |proj g|=        5.4178
At iterate    13  f =      -568.04  |proj g|=        5.4047
At iterate    14  f =      -568.05  |proj g|=        5.3802
At iterate    15  f =      -568.09  |proj g|=        5.3373
At iterate    16  f =      -568.16  |proj g|=        5.2775
At iterate    17  f =      -568.18  |proj g|=        5.2842
At iterate    18  f =       -568.2  |proj g|=        5.2578
At iterate    19  f =       -568.3  |proj g|=        5.1855
At iterate    20  f =       -568.7  |proj g|=        5.0132
At iterate    21  f =      -569.96  |proj g|=        4.6431
At iterate    22  f =      -573.15  |proj g|=        3.9703
At iterate    23  f =      -575.63  |proj g|=         3.227
At iterate    24  f =      -581.41  |proj g|=        2.7914
At iterate    25  f =      -583.07  |proj g|=        2.8202
At iterate    26  f =      -583.43  |proj g|=        2.6989
At iterate    27  f =      -586.73  |proj g|=        2.5689
At iterate    28  f =       -587.6  |proj g|=        2.3957
At iterate    29  f =      -588.16  |proj g|=        2.2617
At iterate    30  f =      -588.16  |proj g|=        2.2635
At iterate    31  f =      -588.16  |proj g|=        2.2644
At iterate    32  f =      -588.16  |proj g|=        2.2635
At iterate    33  f =      -588.16  |proj g|=        2.2644
At iterate    34  f =      -588.24  |proj g|=        2.3615
At iterate    35  f =      -588.62  |proj g|=        2.2785
At iterate    36  f =      -588.62  |proj g|=        2.2803
At iterate    37  f =      -588.62  |proj g|=         2.281
At iterate    38  f =      -588.62  |proj g|=        2.2803
At iterate    39  f =      -588.62  |proj g|=         2.281
At iterate    40  f =      -588.62  |proj g|=        2.2805
At iterate    41  f =      -588.62  |proj g|=        2.2765
At iterate    42  f =      -588.62  |proj g|=        2.2712
At iterate    43  f =      -588.64  |proj g|=        2.2569
At iterate    44  f =      -588.68  |proj g|=        2.2415
At iterate    45  f =      -588.76  |proj g|=        2.2262
At iterate    46  f =      -588.87  |proj g|=        2.2286
At iterate    47  f =      -588.91  |proj g|=        2.3437
At iterate    48  f =         -589  |proj g|=        2.3019
At iterate    49  f =         -589  |proj g|=        2.2992
At iterate    50  f =         -589  |proj g|=        2.2993
At iterate    51  f =         -589  |proj g|=        2.2997
At iterate    52  f =         -589  |proj g|=        2.3004
At iterate    53  f =         -589  |proj g|=        2.3017
At iterate    54  f =         -589  |proj g|=        2.3036
At iterate    55  f =         -589  |proj g|=        2.3066
At iterate    56  f =         -589  |proj g|=        2.3105
At iterate    57  f =      -589.01  |proj g|=        2.3139
At iterate    58  f =      -589.03  |proj g|=        2.3212
At iterate    59  f =      -589.08  |proj g|=        2.3149
At iterate    60  f =      -589.09  |proj g|=        2.3458
At iterate    61  f =      -589.19  |proj g|=        2.3213
At iterate    62  f =      -589.52  |proj g|=        2.1718
At iterate    63  f =      -590.56  |proj g|=        1.5862
At iterate    64  f =       -593.4  |proj g|=       0.74638
At iterate    65  f =      -594.93  |proj g|=       0.91004
At iterate    66  f =      -594.99  |proj g|=       0.63597
At iterate    67  f =      -596.33  |proj g|=        1.1823
At iterate    68  f =      -596.34  |proj g|=        1.2906
At iterate    69  f =      -596.35  |proj g|=        1.2269
At iterate    70  f =      -596.35  |proj g|=        1.2398
At iterate    71  f =      -596.35  |proj g|=        1.2378
At iterate    72  f =      -596.35  |proj g|=        1.2377

iterations 72
function evaluations 88
segments explored during Cauchy searches 77
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.23772
final function value -596.347

F = -596.347
final  value -596.347403 
converged
 
INFO  [00:13:55.706] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:13:55.765] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:13:55.772] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:14:09.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:14:23.617] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:14:39.837] [mlr3]  Finished benchmark 
INFO  [00:14:39.920] [bbotk] Result of batch 111: 
INFO  [00:14:39.921] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:14:39.921] [bbotk]              2.498209                 4.314545                       0.1261244 
INFO  [00:14:39.921] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:14:39.921] [bbotk]                     4952        0.773 -0.9564447         <NA>   0.9626482 
INFO  [00:14:39.921] [bbotk]                                 uhash 
INFO  [00:14:39.921] [bbotk]  57a8a08a-97be-4dfe-8cee-d62f7a140f8f 
DEBUG [00:14:41.099] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.169755e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.169755e-05 0.001475705 
  - best initial criterion value(s) :  553.2456 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -553.25  |proj g|=       8.5604
At iterate     1  f =      -578.73  |proj g|=        10.397
At iterate     2  f =      -587.04  |proj g|=        7.7172
At iterate     3  f =      -590.58  |proj g|=        4.5976
At iterate     4  f =      -591.52  |proj g|=        4.2044
At iterate     5  f =      -591.99  |proj g|=        3.0684
At iterate     6  f =      -592.02  |proj g|=        3.2683
At iterate     7  f =      -592.02  |proj g|=        3.2239
At iterate     8  f =      -592.02  |proj g|=        3.2185
At iterate     9  f =      -592.02  |proj g|=        3.2039
At iterate    10  f =      -592.03  |proj g|=        3.1047
At iterate    11  f =      -592.05  |proj g|=        3.0883
At iterate    12  f =       -592.1  |proj g|=        3.0695
At iterate    13  f =      -592.22  |proj g|=        3.0462
At iterate    14  f =      -592.39  |proj g|=        2.9265
At iterate    15  f =      -592.85  |proj g|=        2.9498
At iterate    16  f =      -594.88  |proj g|=        2.9951
At iterate    17  f =      -598.59  |proj g|=        3.0253
At iterate    18  f =      -603.82  |proj g|=        2.9499
At iterate    19  f =      -606.39  |proj g|=        2.8181
At iterate    20  f =      -606.87  |proj g|=        3.1247
At iterate    21  f =       -607.7  |proj g|=        2.9044
At iterate    22  f =      -607.75  |proj g|=        2.8781
At iterate    23  f =      -607.76  |proj g|=         2.885
At iterate    24  f =      -607.76  |proj g|=        2.8923
At iterate    25  f =      -607.76  |proj g|=        2.8929
At iterate    26  f =      -607.76  |proj g|=        2.8916
At iterate    27  f =      -607.76  |proj g|=         2.893
At iterate    28  f =      -607.76  |proj g|=        2.8928

iterations 28
function evaluations 33
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.89279
final function value -607.761

F = -607.761
final  value -607.761372 
converged
 
INFO  [00:14:41.103] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:14:41.159] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:14:41.166] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:14:52.194] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:15:03.704] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:15:15.199] [mlr3]  Finished benchmark 
INFO  [00:15:15.268] [bbotk] Result of batch 112: 
INFO  [00:15:15.270] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:15:15.270] [bbotk]              2.319842                 2.474369                       0.1676758 
INFO  [00:15:15.270] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:15:15.270] [bbotk]                     4044        0.757 -0.9471984         <NA>   0.9610505 
INFO  [00:15:15.270] [bbotk]                                 uhash 
INFO  [00:15:15.270] [bbotk]  9604d16c-12e1-41c5-97bb-525445f58a01 
DEBUG [00:15:16.609] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.165164e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.165164e-05 0.001468872 
  - best initial criterion value(s) :  565.2513 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -565.25  |proj g|=       4.5587
At iterate     1  f =      -592.75  |proj g|=        6.5945
At iterate     2  f =      -593.25  |proj g|=        6.1949
At iterate     3  f =      -594.63  |proj g|=        4.3745
At iterate     4  f =      -597.95  |proj g|=        2.7021
At iterate     5  f =      -604.27  |proj g|=        2.4317
At iterate     6  f =      -607.15  |proj g|=        2.5443
At iterate     7  f =      -608.96  |proj g|=        2.6712
At iterate     8  f =      -609.92  |proj g|=        2.8097
At iterate     9  f =      -610.37  |proj g|=        3.0015
At iterate    10  f =      -610.46  |proj g|=        3.0283
At iterate    11  f =      -610.53  |proj g|=        3.1301
At iterate    12  f =      -610.54  |proj g|=        3.1118
At iterate    13  f =      -610.55  |proj g|=        3.1046
At iterate    14  f =      -610.55  |proj g|=        3.0958
At iterate    15  f =      -610.56  |proj g|=         3.087
At iterate    16  f =      -610.58  |proj g|=        3.0724
At iterate    17  f =      -610.61  |proj g|=        3.0826
At iterate    18  f =      -610.65  |proj g|=        3.0292
At iterate    19  f =      -610.74  |proj g|=        3.0566
At iterate    20  f =      -610.93  |proj g|=        3.1578
At iterate    21  f =      -610.95  |proj g|=        3.1793
At iterate    22  f =      -610.95  |proj g|=        3.1826
At iterate    23  f =      -610.95  |proj g|=        3.1856
At iterate    24  f =      -610.95  |proj g|=        3.1838
At iterate    25  f =      -610.95  |proj g|=        3.1831
At iterate    26  f =      -610.95  |proj g|=        3.1827
At iterate    27  f =      -610.95  |proj g|=        3.1812
At iterate    28  f =      -610.95  |proj g|=        3.1798
At iterate    29  f =      -610.95  |proj g|=        3.1738
At iterate    30  f =      -610.95  |proj g|=        3.1634
At iterate    31  f =      -610.96  |proj g|=        3.1757
At iterate    32  f =      -610.97  |proj g|=        3.1438
At iterate    33  f =         -611  |proj g|=        3.1119
At iterate    34  f =      -611.07  |proj g|=        3.0519
At iterate    35  f =      -611.17  |proj g|=        3.0055
At iterate    36  f =      -611.26  |proj g|=        2.9498
At iterate    37  f =      -611.66  |proj g|=        2.8241
At iterate    38  f =      -614.04  |proj g|=        2.4862
At iterate    39  f =      -618.92  |proj g|=        2.2209
At iterate    40  f =      -619.26  |proj g|=        2.5351
At iterate    41  f =      -622.38  |proj g|=        1.3129
At iterate    42  f =      -624.05  |proj g|=       0.31199
At iterate    43  f =      -624.37  |proj g|=       0.27247
At iterate    44  f =      -624.57  |proj g|=       0.27252
At iterate    45  f =       -624.6  |proj g|=       0.27225
At iterate    46  f =      -624.61  |proj g|=       0.71112
At iterate    47  f =      -624.62  |proj g|=       0.70903
At iterate    48  f =      -624.62  |proj g|=       0.13822
At iterate    49  f =      -624.62  |proj g|=      0.021662
At iterate    50  f =      -624.62  |proj g|=      0.012772
At iterate    51  f =      -624.62  |proj g|=     0.0016836

iterations 51
function evaluations 60
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00168361
final function value -624.618

F = -624.618
final  value -624.618466 
converged
 
INFO  [00:15:16.613] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:15:16.670] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:15:16.677] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:15:23.026] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:15:30.129] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:15:36.709] [mlr3]  Finished benchmark 
INFO  [00:15:36.780] [bbotk] Result of batch 113: 
INFO  [00:15:36.782] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:15:36.782] [bbotk]              4.886416                 9.185166                       0.4865165 
INFO  [00:15:36.782] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:15:36.782] [bbotk]                     2181        0.766 -0.9443666         <NA>     0.97484 
INFO  [00:15:36.782] [bbotk]                                 uhash 
INFO  [00:15:36.782] [bbotk]  af70af27-5ed8-484e-a749-368ebded4e6a 
DEBUG [00:15:38.391] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.160058e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.160058e-05 0.001458144 
  - best initial criterion value(s) :  592.6096 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -592.61  |proj g|=       3.5942
At iterate     1  f =       -596.5  |proj g|=        4.0027
At iterate     2  f =      -596.54  |proj g|=         3.986
At iterate     3  f =      -596.55  |proj g|=        3.9732
At iterate     4  f =      -596.56  |proj g|=        3.9806
At iterate     5  f =      -596.57  |proj g|=        4.0198
At iterate     6  f =      -596.57  |proj g|=        4.0309
At iterate     7  f =      -596.57  |proj g|=        4.0313
At iterate     8  f =      -596.57  |proj g|=        4.0309
At iterate     9  f =      -596.57  |proj g|=        4.0304
At iterate    10  f =      -596.57  |proj g|=        4.0295
At iterate    11  f =      -596.57  |proj g|=        4.0281
At iterate    12  f =      -596.57  |proj g|=        4.0257
At iterate    13  f =      -596.57  |proj g|=        4.0218
At iterate    14  f =      -596.58  |proj g|=         4.015
At iterate    15  f =      -596.58  |proj g|=        4.0028
At iterate    16  f =      -596.61  |proj g|=          3.98
At iterate    17  f =      -596.68  |proj g|=        3.9352
At iterate    18  f =      -596.87  |proj g|=        3.8424
At iterate    19  f =      -597.42  |proj g|=         3.644
At iterate    20  f =      -598.95  |proj g|=        3.2271
At iterate    21  f =      -603.26  |proj g|=        2.4616
At iterate    22  f =      -613.55  |proj g|=       0.18394
At iterate    23  f =      -617.52  |proj g|=        3.7313
At iterate    24  f =       -617.7  |proj g|=        3.4326
At iterate    25  f =      -617.76  |proj g|=        3.0647
At iterate    26  f =      -617.76  |proj g|=        3.1288
At iterate    27  f =      -617.76  |proj g|=         3.124
At iterate    28  f =      -617.76  |proj g|=        3.1228
At iterate    29  f =      -617.76  |proj g|=        3.1172
At iterate    30  f =      -617.76  |proj g|=        3.1105
At iterate    31  f =      -617.76  |proj g|=        3.0984
At iterate    32  f =      -617.76  |proj g|=        3.0798
At iterate    33  f =      -617.76  |proj g|=        3.0497
At iterate    34  f =      -617.77  |proj g|=        3.0028
At iterate    35  f =      -617.79  |proj g|=        2.9326
At iterate    36  f =      -617.84  |proj g|=        2.8412
At iterate    37  f =      -617.96  |proj g|=        2.7705
At iterate    38  f =      -618.17  |proj g|=        2.8581
At iterate    39  f =      -618.38  |proj g|=        3.5198
At iterate    40  f =      -618.45  |proj g|=        3.5258
At iterate    41  f =      -618.45  |proj g|=        3.5433
At iterate    42  f =      -618.45  |proj g|=        3.5487
At iterate    43  f =      -618.45  |proj g|=         3.552
At iterate    44  f =      -618.45  |proj g|=        3.5541
At iterate    45  f =      -618.45  |proj g|=        3.5593
At iterate    46  f =      -618.45  |proj g|=        3.5666
At iterate    47  f =      -618.45  |proj g|=        3.5782
At iterate    48  f =      -618.45  |proj g|=        3.5933
At iterate    49  f =      -618.45  |proj g|=        3.6108
At iterate    50  f =      -618.46  |proj g|=        3.6909
At iterate    51  f =      -618.46  |proj g|=        3.6781
At iterate    52  f =      -618.51  |proj g|=        3.6079
At iterate    53  f =      -618.59  |proj g|=        3.5057
At iterate    54  f =      -618.82  |proj g|=        3.2521
At iterate    55  f =      -619.27  |proj g|=        2.8061
At iterate    56  f =      -619.92  |proj g|=        1.3324
At iterate    57  f =      -620.97  |proj g|=         1.046
At iterate    58  f =       -622.8  |proj g|=       0.40163
At iterate    59  f =      -623.68  |proj g|=       0.22658
At iterate    60  f =      -623.75  |proj g|=       0.11657
At iterate    61  f =      -623.76  |proj g|=       0.71808
At iterate    62  f =      -623.76  |proj g|=       0.75909
At iterate    63  f =      -623.76  |proj g|=       0.75747
At iterate    64  f =      -623.76  |proj g|=       0.28064
At iterate    65  f =      -623.77  |proj g|=     0.0093391
At iterate    66  f =      -623.77  |proj g|=     0.0034626

iterations 66
function evaluations 75
segments explored during Cauchy searches 69
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00346256
final function value -623.765

F = -623.765
final  value -623.765186 
converged
 
INFO  [00:15:38.395] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:15:38.489] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:15:38.497] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:15:44.731] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:15:51.331] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:15:59.121] [mlr3]  Finished benchmark 
INFO  [00:15:59.206] [bbotk] Result of batch 114: 
INFO  [00:15:59.208] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:15:59.208] [bbotk]              3.816916                 8.374514                       0.2327339 
INFO  [00:15:59.208] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:15:59.208] [bbotk]                     2391         0.76 -0.9524717         <NA>   0.9704398 
INFO  [00:15:59.208] [bbotk]                                 uhash 
INFO  [00:15:59.208] [bbotk]  87741091-0286-45bc-8ace-4a4f86415730 
DEBUG [00:16:00.413] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.152327e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.152327e-05 0.001451604 
  - best initial criterion value(s) :  586.3328 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -586.33  |proj g|=       4.4497
At iterate     1  f =      -596.55  |proj g|=        3.6648
At iterate     2  f =      -606.26  |proj g|=        4.3634
At iterate     3  f =      -607.09  |proj g|=        4.3242
At iterate     4  f =       -607.7  |proj g|=        4.2813
At iterate     5  f =      -607.81  |proj g|=        4.2888
At iterate     6  f =      -607.85  |proj g|=         4.318
At iterate     7  f =      -607.86  |proj g|=         4.363
At iterate     8  f =      -607.86  |proj g|=        4.3691
At iterate     9  f =      -607.86  |proj g|=        4.3693
At iterate    10  f =      -607.86  |proj g|=        4.3697
At iterate    11  f =      -607.86  |proj g|=        4.3702
At iterate    12  f =      -607.86  |proj g|=        4.3706
At iterate    13  f =      -607.86  |proj g|=        4.3709
At iterate    14  f =      -607.86  |proj g|=        4.3712
At iterate    15  f =      -607.86  |proj g|=        4.3691
At iterate    16  f =      -607.86  |proj g|=        4.3826
At iterate    17  f =      -607.87  |proj g|=        4.3742
At iterate    18  f =      -607.89  |proj g|=        4.3341
At iterate    19  f =      -607.93  |proj g|=         4.282
At iterate    20  f =      -608.05  |proj g|=        4.1801
At iterate    21  f =      -608.32  |proj g|=        4.0029
At iterate    22  f =      -608.94  |proj g|=        3.6396
At iterate    23  f =      -610.35  |proj g|=        3.1597
At iterate    24  f =      -611.15  |proj g|=        2.6794
At iterate    25  f =      -615.04  |proj g|=        2.1416
At iterate    26  f =      -627.46  |proj g|=       0.86412
At iterate    27  f =      -633.11  |proj g|=        1.7286
At iterate    28  f =       -633.4  |proj g|=        1.8261
At iterate    29  f =      -633.46  |proj g|=        1.7233
At iterate    30  f =      -633.47  |proj g|=        1.5982
At iterate    31  f =      -633.47  |proj g|=        1.6062
At iterate    32  f =      -633.47  |proj g|=        1.6058

iterations 32
function evaluations 36
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.60581
final function value -633.47

F = -633.47
final  value -633.469731 
converged
 
INFO  [00:16:00.417] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:16:00.472] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:16:00.479] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:16:07.767] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:16:14.553] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:16:21.268] [mlr3]  Finished benchmark 
INFO  [00:16:21.353] [bbotk] Result of batch 115: 
INFO  [00:16:21.355] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:16:21.355] [bbotk]               3.80509                 8.148266                       0.3813202 
INFO  [00:16:21.355] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:16:21.355] [bbotk]                     2549        0.765 -0.9492626         <NA>   0.9726559 
INFO  [00:16:21.355] [bbotk]                                 uhash 
INFO  [00:16:21.355] [bbotk]  4c32ab58-788e-4383-8e2a-690fa5479ac2 
DEBUG [00:16:23.035] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.14569e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.14569e-05 0.001453473 
  - best initial criterion value(s) :  567.3692 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -567.37  |proj g|=       5.8232
At iterate     1  f =      -578.41  |proj g|=        8.4827
At iterate     2  f =      -587.26  |proj g|=        7.1819
At iterate     3  f =       -598.7  |proj g|=        5.4627
At iterate     4  f =      -599.29  |proj g|=        5.0834
At iterate     5  f =       -600.3  |proj g|=        5.3754
At iterate     6  f =      -602.45  |proj g|=        5.9194
At iterate     7  f =      -604.37  |proj g|=        6.6284
At iterate     8  f =      -604.59  |proj g|=        6.8869
At iterate     9  f =       -604.6  |proj g|=        7.0331
At iterate    10  f =       -604.6  |proj g|=        7.0028
At iterate    11  f =       -604.6  |proj g|=        7.0012
At iterate    12  f =       -604.6  |proj g|=         7.001
At iterate    13  f =       -604.6  |proj g|=        7.0007
At iterate    14  f =       -604.6  |proj g|=        7.0007
At iterate    15  f =       -604.6  |proj g|=        7.0027
At iterate    16  f =       -604.6  |proj g|=        7.0092
At iterate    17  f =       -604.6  |proj g|=        7.0101
At iterate    18  f =      -604.61  |proj g|=        7.0182
At iterate    19  f =      -604.62  |proj g|=        7.0471
At iterate    20  f =      -604.63  |proj g|=        6.9878
At iterate    21  f =      -604.66  |proj g|=        7.0278
At iterate    22  f =      -604.78  |proj g|=        7.0753
At iterate    23  f =      -604.97  |proj g|=        7.0136
At iterate    24  f =      -605.13  |proj g|=        6.8104
At iterate    25  f =      -605.15  |proj g|=        6.7113
At iterate    26  f =      -605.15  |proj g|=        6.7077
At iterate    27  f =      -605.15  |proj g|=        6.6906
At iterate    28  f =      -605.15  |proj g|=        6.6915
At iterate    29  f =      -605.15  |proj g|=        6.6918
At iterate    30  f =      -605.15  |proj g|=        6.6926
At iterate    31  f =      -605.15  |proj g|=        6.6939
At iterate    32  f =      -605.15  |proj g|=        6.6978
At iterate    33  f =      -605.15  |proj g|=        6.6955
At iterate    34  f =      -605.15  |proj g|=        6.6994
At iterate    35  f =      -605.15  |proj g|=        6.7145
At iterate    36  f =      -605.15  |proj g|=        6.7343
At iterate    37  f =      -605.16  |proj g|=         6.772
At iterate    38  f =      -605.18  |proj g|=        6.8301
At iterate    39  f =      -605.21  |proj g|=        6.9037
At iterate    40  f =      -605.22  |proj g|=         6.961
At iterate    41  f =      -605.28  |proj g|=        7.0193
At iterate    42  f =      -605.36  |proj g|=        7.0313
At iterate    43  f =       -605.4  |proj g|=        6.9651
At iterate    44  f =       -605.4  |proj g|=        6.9214
At iterate    45  f =       -605.4  |proj g|=        6.9263
At iterate    46  f =       -605.4  |proj g|=         6.918
At iterate    47  f =      -605.41  |proj g|=         6.923
At iterate    48  f =      -605.42  |proj g|=        6.9284
At iterate    49  f =      -605.46  |proj g|=        6.9346
At iterate    50  f =      -605.56  |proj g|=        6.9406
At iterate    51  f =      -605.81  |proj g|=        6.9348
At iterate    52  f =       -606.4  |proj g|=        6.8893
At iterate    53  f =      -607.77  |proj g|=        6.6698
At iterate    54  f =      -607.91  |proj g|=        6.9299
At iterate    55  f =      -610.62  |proj g|=        6.5285
At iterate    56  f =      -613.64  |proj g|=        5.8175
At iterate    57  f =      -613.99  |proj g|=        5.5261
At iterate    58  f =      -614.09  |proj g|=        5.4165
At iterate    59  f =      -614.13  |proj g|=        5.4189
At iterate    60  f =      -614.16  |proj g|=        5.5042
At iterate    61  f =      -614.16  |proj g|=        5.5287
At iterate    62  f =      -614.16  |proj g|=        5.5308
At iterate    63  f =      -614.16  |proj g|=        5.5303
At iterate    64  f =      -614.16  |proj g|=        5.5286
At iterate    65  f =      -614.17  |proj g|=        5.5247
At iterate    66  f =      -614.17  |proj g|=        5.5191
At iterate    67  f =      -614.17  |proj g|=        5.5096
At iterate    68  f =      -614.17  |proj g|=        5.4948
At iterate    69  f =      -614.18  |proj g|=        5.4719
At iterate    70  f =      -614.19  |proj g|=        5.4382
At iterate    71  f =      -614.23  |proj g|=        5.3972
At iterate    72  f =      -614.31  |proj g|=        5.3758
At iterate    73  f =      -614.44  |proj g|=        5.4774
At iterate    74  f =      -614.46  |proj g|=        5.5436
At iterate    75  f =      -614.46  |proj g|=        5.5638
At iterate    76  f =      -614.46  |proj g|=        5.5661
At iterate    77  f =      -614.46  |proj g|=        5.5662

iterations 77
function evaluations 92
segments explored during Cauchy searches 80
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 5.56622
final function value -614.458

F = -614.458
final  value -614.457837 
converged
 
INFO  [00:16:23.037] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:16:23.081] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:16:23.087] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:16:34.656] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:16:44.197] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:16:54.574] [mlr3]  Finished benchmark 
INFO  [00:16:54.642] [bbotk] Result of batch 116: 
INFO  [00:16:54.644] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:16:54.644] [bbotk]              2.221962                 2.968268                       0.1253542 
INFO  [00:16:54.644] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:16:54.644] [bbotk]                     3485        0.867 -0.9442018         <NA>    0.956333 
INFO  [00:16:54.644] [bbotk]                                 uhash 
INFO  [00:16:54.644] [bbotk]  f78fc7c7-91f0-4cec-8153-ce8e7f4add85 
DEBUG [00:16:55.882] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.147605e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.147605e-05 0.001448592 
  - best initial criterion value(s) :  581.5653 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -581.57  |proj g|=       6.1178
At iterate     1  f =      -586.11  |proj g|=        10.003
At iterate     2  f =      -598.01  |proj g|=        8.4526
At iterate     3  f =      -617.28  |proj g|=        4.1885
At iterate     4  f =      -619.76  |proj g|=        2.3366
At iterate     5  f =      -624.93  |proj g|=        2.3856
At iterate     6  f =      -633.06  |proj g|=        2.6056
At iterate     7  f =      -634.91  |proj g|=        2.6525
At iterate     8  f =      -636.16  |proj g|=         2.883
At iterate     9  f =      -636.45  |proj g|=        2.9596
At iterate    10  f =      -636.48  |proj g|=        3.0273
At iterate    11  f =      -636.54  |proj g|=        3.0526
At iterate    12  f =      -636.54  |proj g|=        3.0633
At iterate    13  f =      -636.54  |proj g|=        3.0676
At iterate    14  f =      -636.54  |proj g|=        3.0695
At iterate    15  f =      -636.54  |proj g|=         3.074
At iterate    16  f =      -636.54  |proj g|=        3.0797
At iterate    17  f =      -636.55  |proj g|=        3.0913
At iterate    18  f =      -636.55  |proj g|=        3.1047
At iterate    19  f =      -636.57  |proj g|=        3.1252
At iterate    20  f =      -636.61  |proj g|=        3.1472
At iterate    21  f =       -636.7  |proj g|=        3.1627
At iterate    22  f =      -636.73  |proj g|=         3.108
At iterate    23  f =      -636.83  |proj g|=        3.1247
At iterate    24  f =         -637  |proj g|=        3.1013
At iterate    25  f =      -637.09  |proj g|=        3.0233
At iterate    26  f =      -637.09  |proj g|=        3.0159
At iterate    27  f =      -637.09  |proj g|=        3.0177
At iterate    28  f =      -637.09  |proj g|=        3.0173

iterations 28
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.01731
final function value -637.089

F = -637.089
final  value -637.089422 
converged
 
INFO  [00:16:55.886] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:16:55.940] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:16:55.947] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:17:03.103] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:17:09.805] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:17:17.830] [mlr3]  Finished benchmark 
INFO  [00:17:17.900] [bbotk] Result of batch 117: 
INFO  [00:17:17.902] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:17:17.902] [bbotk]              6.669077                 2.754208                       0.1663774 
INFO  [00:17:17.902] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:17:17.902] [bbotk]                     2720        0.785 -0.9461853         <NA>   0.9724199 
INFO  [00:17:17.902] [bbotk]                                 uhash 
INFO  [00:17:17.902] [bbotk]  aa18f0db-404a-4b93-8cd7-259e70de917f 
DEBUG [00:17:19.282] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.140984e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.140984e-05 0.001444829 
  - best initial criterion value(s) :  557.2172 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -557.22  |proj g|=       11.124
At iterate     1  f =      -565.95  |proj g|=        6.8029
At iterate     2  f =      -565.97  |proj g|=        6.8123
At iterate     3  f =      -565.99  |proj g|=        6.6974
At iterate     4  f =         -566  |proj g|=        6.5576
At iterate     5  f =         -566  |proj g|=        6.5334
At iterate     6  f =         -566  |proj g|=        6.5223
At iterate     7  f =         -566  |proj g|=        6.5118
At iterate     8  f =         -566  |proj g|=        6.4887
At iterate     9  f =         -566  |proj g|=        6.4551
At iterate    10  f =         -566  |proj g|=        6.3941
At iterate    11  f =      -566.01  |proj g|=         6.303
At iterate    12  f =      -566.04  |proj g|=        6.1466
At iterate    13  f =      -566.04  |proj g|=        6.0901
At iterate    14  f =       -566.1  |proj g|=        5.8862
At iterate    15  f =      -571.34  |proj g|=        3.9053
At iterate    16  f =      -579.86  |proj g|=        1.8067
At iterate    17  f =         -581  |proj g|=        1.7749
At iterate    18  f =      -581.15  |proj g|=        1.7804
At iterate    19  f =      -581.19  |proj g|=        1.7948
At iterate    20  f =      -581.21  |proj g|=        1.7913
At iterate    21  f =      -581.21  |proj g|=        1.7905
At iterate    22  f =      -581.21  |proj g|=        1.7904
At iterate    23  f =      -581.21  |proj g|=        1.7904

iterations 23
function evaluations 28
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.79043
final function value -581.208

F = -581.208
final  value -581.207566 
converged
 
INFO  [00:17:19.286] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:17:19.354] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:17:19.361] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:17:28.407] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:17:38.131] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:17:52.873] [mlr3]  Finished benchmark 
INFO  [00:17:52.968] [bbotk] Result of batch 118: 
INFO  [00:17:52.970] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:17:52.970] [bbotk]              5.784703                 5.003667                       0.2733031 
INFO  [00:17:52.970] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:17:52.970] [bbotk]                     3233        0.969 -0.9669049         <NA>   0.9748056 
INFO  [00:17:52.970] [bbotk]                                 uhash 
INFO  [00:17:52.970] [bbotk]  fa590557-b719-4bd7-a4fc-e41021901ced 
DEBUG [00:17:54.181] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.136151e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.136151e-05 0.00144204 
  - best initial criterion value(s) :  613.1479 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -613.15  |proj g|=       6.2716
At iterate     1  f =      -624.12  |proj g|=         5.946
At iterate     2  f =      -628.24  |proj g|=        8.2412
At iterate     3  f =      -629.19  |proj g|=        9.1865
At iterate     4  f =      -630.61  |proj g|=        9.8204
At iterate     5  f =      -632.43  |proj g|=        9.7017
At iterate     6  f =      -632.73  |proj g|=        9.2519
At iterate     7  f =      -632.96  |proj g|=        8.7426
At iterate     8  f =      -632.96  |proj g|=          8.73
At iterate     9  f =      -632.96  |proj g|=        8.7275
At iterate    10  f =      -632.96  |proj g|=        8.7084
At iterate    11  f =      -632.97  |proj g|=        8.6862
At iterate    12  f =      -632.97  |proj g|=        8.6428
At iterate    13  f =      -632.98  |proj g|=        8.5748
At iterate    14  f =         -633  |proj g|=        8.4599
At iterate    15  f =      -633.06  |proj g|=         8.284
At iterate    16  f =      -633.19  |proj g|=        8.0031
At iterate    17  f =      -633.48  |proj g|=        7.5463
At iterate    18  f =      -634.06  |proj g|=        6.9743
At iterate    19  f =      -634.28  |proj g|=        6.0789
At iterate    20  f =      -635.46  |proj g|=        5.3781
At iterate    21  f =      -638.99  |proj g|=        3.8005
At iterate    22  f =      -646.22  |proj g|=        2.1418
At iterate    23  f =      -649.65  |proj g|=       0.89949
At iterate    24  f =       -650.2  |proj g|=       0.75885
At iterate    25  f =      -650.33  |proj g|=       0.22661
At iterate    26  f =      -650.33  |proj g|=        0.2255
At iterate    27  f =      -650.33  |proj g|=       0.22344
At iterate    28  f =      -650.33  |proj g|=       0.22232

iterations 28
function evaluations 33
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.222318
final function value -650.329

F = -650.329
final  value -650.329335 
converged
 
INFO  [00:17:54.185] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:17:54.242] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:17:54.249] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:17:59.922] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:18:05.175] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:18:10.729] [mlr3]  Finished benchmark 
INFO  [00:18:10.799] [bbotk] Result of batch 119: 
INFO  [00:18:10.801] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:18:10.801] [bbotk]              4.895682                 7.334515                       0.3941678 
INFO  [00:18:10.801] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:18:10.801] [bbotk]                     2150        0.777 -0.9537254         <NA>   0.9741412 
INFO  [00:18:10.801] [bbotk]                                 uhash 
INFO  [00:18:10.801] [bbotk]  2494c4d8-2372-41b7-956b-9493f4549dee 
DEBUG [00:18:12.046] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.130798e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.130798e-05 0.00143164 
  - best initial criterion value(s) :  625.3921 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -625.39  |proj g|=       5.3711
At iterate     1  f =      -634.35  |proj g|=        2.4279
At iterate     2  f =      -643.17  |proj g|=        4.7682
At iterate     3  f =      -643.87  |proj g|=        4.8062
At iterate     4  f =      -644.38  |proj g|=        4.9524
At iterate     5  f =      -644.49  |proj g|=        5.1016
At iterate     6  f =      -644.53  |proj g|=        5.2531
At iterate     7  f =      -644.54  |proj g|=        5.3623
At iterate     8  f =      -644.54  |proj g|=        5.3706
At iterate     9  f =      -644.54  |proj g|=        5.3727
At iterate    10  f =      -644.54  |proj g|=        5.3755
At iterate    11  f =      -644.54  |proj g|=        5.3827
At iterate    12  f =      -644.54  |proj g|=        5.3917
At iterate    13  f =      -644.54  |proj g|=         5.406
At iterate    14  f =      -644.54  |proj g|=        5.4253
At iterate    15  f =      -644.54  |proj g|=        5.4429
At iterate    16  f =      -644.55  |proj g|=        5.4456
At iterate    17  f =      -644.56  |proj g|=         5.509
At iterate    18  f =      -644.58  |proj g|=        5.4917
At iterate    19  f =      -648.89  |proj g|=        3.5219
At iterate    20  f =      -655.94  |proj g|=        1.7784
At iterate    21  f =      -658.63  |proj g|=        1.0305
At iterate    22  f =      -659.63  |proj g|=        0.9485
At iterate    23  f =      -659.73  |proj g|=       0.74349
At iterate    24  f =      -660.16  |proj g|=       0.81496
At iterate    25  f =      -660.18  |proj g|=       0.75467
At iterate    26  f =      -660.19  |proj g|=       0.72614
At iterate    27  f =      -660.19  |proj g|=       0.72454
At iterate    28  f =      -660.19  |proj g|=       0.71055
At iterate    29  f =      -660.19  |proj g|=       0.71483
At iterate    30  f =      -660.19  |proj g|=       0.71542

iterations 30
function evaluations 38
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.715422
final function value -660.194

F = -660.194
final  value -660.194272 
converged
 
INFO  [00:18:12.050] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:18:12.105] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:18:12.112] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:18:21.405] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:18:32.620] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:18:41.028] [mlr3]  Finished benchmark 
INFO  [00:18:41.097] [bbotk] Result of batch 120: 
INFO  [00:18:41.098] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:18:41.098] [bbotk]              8.382483                 7.680072                        0.134704 
INFO  [00:18:41.098] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [00:18:41.098] [bbotk]                     3626        0.775 -0.948585         <NA>   0.9730869 
INFO  [00:18:41.098] [bbotk]                                 uhash 
INFO  [00:18:41.098] [bbotk]  715781b1-f58f-42e2-821a-90404396b936 
DEBUG [00:18:42.704] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.124751e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.124751e-05 0.001426715 
  - best initial criterion value(s) :  561.757 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -561.76  |proj g|=       2.7726
At iterate     1  f =       -628.7  |proj g|=        1.3675
At iterate     2  f =      -647.69  |proj g|=        8.8734
At iterate     3  f =         -649  |proj g|=        8.6155
At iterate     4  f =      -653.52  |proj g|=        5.7858
At iterate     5  f =      -653.64  |proj g|=        6.2795
At iterate     6  f =      -653.67  |proj g|=        6.2145
At iterate     7  f =      -653.77  |proj g|=         5.858
At iterate     8  f =      -653.78  |proj g|=        5.9751
At iterate     9  f =      -653.78  |proj g|=        5.9811
At iterate    10  f =      -653.78  |proj g|=        5.9814
At iterate    11  f =      -653.78  |proj g|=        5.9813
At iterate    12  f =      -653.78  |proj g|=        5.9877
At iterate    13  f =      -653.79  |proj g|=          5.99
At iterate    14  f =      -653.79  |proj g|=         6.011
At iterate    15  f =      -653.79  |proj g|=        6.0068
At iterate    16  f =       -653.8  |proj g|=        5.9976
At iterate    17  f =      -653.82  |proj g|=        5.9773
At iterate    18  f =      -653.88  |proj g|=        5.9284
At iterate    19  f =      -654.04  |proj g|=        5.8028
At iterate    20  f =       -654.4  |proj g|=        5.3086
At iterate    21  f =      -655.15  |proj g|=        5.0815
At iterate    22  f =      -656.28  |proj g|=        3.3954
At iterate    23  f =      -658.13  |proj g|=        2.7682
At iterate    24  f =      -658.78  |proj g|=        1.9037
At iterate    25  f =      -668.81  |proj g|=       0.25249
At iterate    26  f =      -669.71  |proj g|=       0.25397
At iterate    27  f =      -669.76  |proj g|=       0.25763
At iterate    28  f =      -669.78  |proj g|=       0.72569
At iterate    29  f =      -669.78  |proj g|=        0.3284
At iterate    30  f =      -669.78  |proj g|=       0.32985
At iterate    31  f =      -669.78  |proj g|=       0.33013
At iterate    32  f =      -669.78  |proj g|=       0.33111
At iterate    33  f =      -669.78  |proj g|=        0.3326
At iterate    34  f =      -669.78  |proj g|=       0.32991
At iterate    35  f =      -669.78  |proj g|=       0.33971
At iterate    36  f =      -669.78  |proj g|=       0.34925
At iterate    37  f =      -669.79  |proj g|=        0.3618
At iterate    38  f =       -669.8  |proj g|=       0.35997
At iterate    39  f =      -669.83  |proj g|=       0.30912
At iterate    40  f =      -669.84  |proj g|=       0.71546
At iterate    41  f =      -669.88  |proj g|=       0.27177
At iterate    42  f =       -669.9  |proj g|=       0.26993
At iterate    43  f =      -669.91  |proj g|=        0.2669
At iterate    44  f =      -669.91  |proj g|=      0.025496
At iterate    45  f =      -669.91  |proj g|=     0.0008328

iterations 45
function evaluations 54
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.000832805
final function value -669.908

F = -669.908
final  value -669.908131 
converged
 
INFO  [00:18:42.709] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:18:42.765] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:18:42.772] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:18:50.416] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:18:57.887] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:19:05.249] [mlr3]  Finished benchmark 
INFO  [00:19:05.380] [bbotk] Result of batch 121: 
INFO  [00:19:05.382] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:19:05.382] [bbotk]              2.581133                 3.403891                       0.4198351 
INFO  [00:19:05.382] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:19:05.382] [bbotk]                     3787        0.961 -0.9453882         <NA>   0.9695045 
INFO  [00:19:05.382] [bbotk]                                 uhash 
INFO  [00:19:05.382] [bbotk]  bfcb4f86-8874-4f9a-90cc-7abdafd438c6 
DEBUG [00:19:06.518] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.117386e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.117386e-05 0.001419414 
  - best initial criterion value(s) :  622.3383 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -622.34  |proj g|=       8.1275
At iterate     1  f =      -650.02  |proj g|=        1.7394
At iterate     2  f =      -650.79  |proj g|=        1.5141
At iterate     3  f =      -651.55  |proj g|=       0.46023
At iterate     4  f =      -651.76  |proj g|=       0.79906
At iterate     5  f =      -651.76  |proj g|=       0.79672
At iterate     6  f =      -651.76  |proj g|=       0.79679
At iterate     7  f =      -651.76  |proj g|=       0.79697
At iterate     8  f =      -651.76  |proj g|=       0.79696

iterations 8
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.796963
final function value -651.761

F = -651.761
final  value -651.761287 
converged
 
INFO  [00:19:06.523] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:19:06.584] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:19:06.593] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:19:07.974] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:19:09.287] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:19:10.871] [mlr3]  Finished benchmark 
INFO  [00:19:11.005] [bbotk] Result of batch 122: 
INFO  [00:19:11.008] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:19:11.008] [bbotk]              7.660165                 8.577745                       0.3352987 
INFO  [00:19:11.008] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:19:11.008] [bbotk]                      497        0.828 -0.9597236         <NA>   0.9668912 
INFO  [00:19:11.008] [bbotk]                                 uhash 
INFO  [00:19:11.008] [bbotk]  37ad9c18-d1ae-4f5f-9ceb-91cca6ccea55 
DEBUG [00:19:12.757] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.11018e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.11018e-05 0.001404641 
  - best initial criterion value(s) :  649.572 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -649.57  |proj g|=       8.3305
At iterate     1  f =      -650.48  |proj g|=         8.648
At iterate     2  f =       -654.9  |proj g|=        5.5815
At iterate     3  f =      -656.91  |proj g|=        2.3932
At iterate     4  f =      -656.96  |proj g|=        2.4696
At iterate     5  f =      -656.96  |proj g|=        2.4195
At iterate     6  f =      -656.96  |proj g|=        2.4171
At iterate     7  f =      -656.96  |proj g|=        2.4161
At iterate     8  f =      -656.96  |proj g|=        2.4124
At iterate     9  f =      -656.96  |proj g|=        2.4079
At iterate    10  f =      -656.96  |proj g|=        2.4001
At iterate    11  f =      -656.96  |proj g|=         2.389
At iterate    12  f =      -656.96  |proj g|=        2.3749
At iterate    13  f =      -656.97  |proj g|=        2.3644
At iterate    14  f =      -656.98  |proj g|=        2.3835
At iterate    15  f =         -657  |proj g|=        2.4945
At iterate    16  f =      -657.02  |proj g|=        2.8201
At iterate    17  f =      -657.02  |proj g|=        2.7725
At iterate    18  f =      -657.02  |proj g|=        2.7045
At iterate    19  f =      -657.04  |proj g|=         2.582
At iterate    20  f =      -657.08  |proj g|=         2.363
At iterate    21  f =      -657.17  |proj g|=        2.0044
At iterate    22  f =      -657.38  |proj g|=        1.5085
At iterate    23  f =      -657.74  |proj g|=        0.8461
At iterate    24  f =      -658.48  |proj g|=        0.8448
At iterate    25  f =      -660.92  |proj g|=        1.2198
At iterate    26  f =      -661.39  |proj g|=        0.8287
At iterate    27  f =      -662.66  |proj g|=        1.0862
At iterate    28  f =      -663.36  |proj g|=        1.0695
At iterate    29  f =      -663.55  |proj g|=       0.79531
At iterate    30  f =      -663.77  |proj g|=       0.49831
At iterate    31  f =      -663.81  |proj g|=       0.47997
At iterate    32  f =      -663.82  |proj g|=       0.77914
At iterate    33  f =      -663.82  |proj g|=       0.46633
At iterate    34  f =      -663.82  |proj g|=       0.46565
At iterate    35  f =      -663.82  |proj g|=       0.46563

iterations 35
function evaluations 44
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.465626
final function value -663.819

F = -663.819
final  value -663.819073 
converged
 
INFO  [00:19:12.761] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:19:12.818] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:19:12.825] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:19:21.379] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:19:29.959] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:19:38.428] [mlr3]  Finished benchmark 
INFO  [00:19:38.498] [bbotk] Result of batch 123: 
INFO  [00:19:38.500] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:19:38.500] [bbotk]              7.880138                 5.879164                       0.1027367 
INFO  [00:19:38.500] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:19:38.500] [bbotk]                     4240        1.145 -0.9569709         <NA>   0.9724097 
INFO  [00:19:38.500] [bbotk]                                 uhash 
INFO  [00:19:38.500] [bbotk]  138ea8f5-8a9d-4b90-b989-7f48282fa61d 
DEBUG [00:19:39.881] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.103983e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.103983e-05 0.0013994 
  - best initial criterion value(s) :  650.9657 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -650.97  |proj g|=       2.5991
At iterate     1  f =      -656.66  |proj g|=        3.7583
At iterate     2  f =      -662.24  |proj g|=        6.5355
At iterate     3  f =      -664.65  |proj g|=        4.9082
At iterate     4  f =      -664.68  |proj g|=        4.9898
At iterate     5  f =      -664.68  |proj g|=        4.9972
At iterate     6  f =      -664.68  |proj g|=        4.9788
At iterate     7  f =      -664.68  |proj g|=        4.9795
At iterate     8  f =      -664.69  |proj g|=        4.9788
At iterate     9  f =      -664.69  |proj g|=        4.9771
At iterate    10  f =       -664.7  |proj g|=        4.9711
At iterate    11  f =      -664.73  |proj g|=        4.9586
At iterate    12  f =      -664.81  |proj g|=        4.8907
At iterate    13  f =      -664.98  |proj g|=        5.1008
At iterate    14  f =      -665.09  |proj g|=        4.0251
At iterate    15  f =      -665.66  |proj g|=        4.4915
At iterate    16  f =      -667.04  |proj g|=        4.9151
At iterate    17  f =      -670.83  |proj g|=        5.0144
At iterate    18  f =      -679.92  |proj g|=        3.6933
At iterate    19  f =       -680.1  |proj g|=         3.827
At iterate    20  f =      -681.91  |proj g|=         3.141
At iterate    21  f =      -683.12  |proj g|=        1.4691
At iterate    22  f =      -683.14  |proj g|=        1.9739
At iterate    23  f =      -683.17  |proj g|=        1.7815
At iterate    24  f =      -683.17  |proj g|=        1.7535
At iterate    25  f =      -683.17  |proj g|=         1.756
At iterate    26  f =      -683.17  |proj g|=        1.7561

iterations 26
function evaluations 39
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.75605
final function value -683.167

F = -683.167
final  value -683.166550 
converged
 
INFO  [00:19:39.886] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:19:39.942] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:19:39.949] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:19:48.961] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:19:59.165] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:20:11.757] [mlr3]  Finished benchmark 
INFO  [00:20:11.828] [bbotk] Result of batch 124: 
INFO  [00:20:11.830] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:20:11.830] [bbotk]              2.515219                 8.439027                       0.1722655 
INFO  [00:20:11.830] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [00:20:11.830] [bbotk]                     3783        0.843 -0.949865         <NA>   0.9632439 
INFO  [00:20:11.830] [bbotk]                                 uhash 
INFO  [00:20:11.830] [bbotk]  dc1063c3-9bf2-4686-a0e2-3a294b5ce59b 
DEBUG [00:20:13.196] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.098528e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.098528e-05 0.001391309 
  - best initial criterion value(s) :  642.9306 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -642.93  |proj g|=       5.3162
At iterate     1  f =      -666.89  |proj g|=        4.3413
At iterate     2  f =      -668.09  |proj g|=        10.997
At iterate     3  f =      -673.36  |proj g|=        8.3573
At iterate     4  f =      -673.63  |proj g|=        8.0971
At iterate     5  f =      -674.23  |proj g|=        6.7085
At iterate     6  f =      -674.68  |proj g|=        7.7119
At iterate     7  f =      -674.89  |proj g|=        7.8594
At iterate     8  f =      -674.91  |proj g|=        7.8267
At iterate     9  f =      -674.91  |proj g|=        7.8399
At iterate    10  f =      -674.91  |proj g|=        7.8384
At iterate    11  f =      -674.91  |proj g|=        7.8342
At iterate    12  f =      -674.91  |proj g|=        7.8313
At iterate    13  f =      -674.91  |proj g|=         7.814
At iterate    14  f =      -674.91  |proj g|=         7.804
At iterate    15  f =      -674.91  |proj g|=        7.7787
At iterate    16  f =      -674.92  |proj g|=        7.7485
At iterate    17  f =      -674.95  |proj g|=        7.6891
At iterate    18  f =      -675.02  |proj g|=        7.6343
At iterate    19  f =      -675.05  |proj g|=        7.3278
At iterate    20  f =      -675.25  |proj g|=        7.2379
At iterate    21  f =      -677.11  |proj g|=        6.8589
At iterate    22  f =      -680.77  |proj g|=        5.0111
At iterate    23  f =      -686.26  |proj g|=        2.5531
At iterate    24  f =      -689.59  |proj g|=        0.6039
At iterate    25  f =      -689.78  |proj g|=       0.90598
At iterate    26  f =      -689.78  |proj g|=       0.85409
At iterate    27  f =      -689.78  |proj g|=        0.8462
At iterate    28  f =      -689.79  |proj g|=       0.84992
At iterate    29  f =      -689.79  |proj g|=       0.85543
At iterate    30  f =      -689.79  |proj g|=        0.8805
At iterate    31  f =      -689.79  |proj g|=       0.89769
At iterate    32  f =      -689.79  |proj g|=       0.93325
At iterate    33  f =      -689.81  |proj g|=       0.97222
At iterate    34  f =      -689.84  |proj g|=         1.005
At iterate    35  f =       -689.9  |proj g|=       0.98087
At iterate    36  f =         -690  |proj g|=       0.87828
At iterate    37  f =      -690.02  |proj g|=         0.752
At iterate    38  f =      -690.13  |proj g|=       0.59552
At iterate    39  f =      -690.34  |proj g|=       0.74182
At iterate    40  f =       -690.4  |proj g|=      0.049616
At iterate    41  f =       -690.4  |proj g|=     0.0072634
At iterate    42  f =       -690.4  |proj g|=     0.0040232
At iterate    43  f =       -690.4  |proj g|=     0.0099702

iterations 43
function evaluations 47
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00997021
final function value -690.404

F = -690.404
final  value -690.404490 
converged
 
INFO  [00:20:13.200] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:20:13.256] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:20:13.263] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:20:22.788] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:20:34.354] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:20:46.213] [mlr3]  Finished benchmark 
INFO  [00:20:46.281] [bbotk] Result of batch 125: 
INFO  [00:20:46.282] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:20:46.282] [bbotk]              8.868606                 8.974263                      0.03310615 
INFO  [00:20:46.282] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [00:20:46.282] [bbotk]                     3347        0.804 -0.947032         <NA>   0.9632172 
INFO  [00:20:46.282] [bbotk]                                 uhash 
INFO  [00:20:46.282] [bbotk]  012c64cc-0ea9-4a50-9817-24c30cc4a231 
DEBUG [00:20:47.402] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.093138e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.093138e-05 0.001383777 
  - best initial criterion value(s) :  635.1774 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -635.18  |proj g|=       5.6623
At iterate     1  f =      -635.99  |proj g|=        5.1308
At iterate     2  f =      -637.06  |proj g|=        5.0945
At iterate     3  f =      -637.32  |proj g|=        4.9835
At iterate     4  f =      -637.37  |proj g|=        4.9324
At iterate     5  f =      -637.37  |proj g|=        4.9245
At iterate     6  f =      -637.37  |proj g|=        4.9258
At iterate     7  f =      -637.37  |proj g|=        4.9268
At iterate     8  f =      -637.37  |proj g|=        4.9272

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.92719
final function value -637.374

F = -637.374
final  value -637.374282 
converged
 
INFO  [00:20:47.407] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:20:47.460] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:20:47.467] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:21:03.478] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:21:22.099] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:21:36.944] [mlr3]  Finished benchmark 
INFO  [00:21:37.013] [bbotk] Result of batch 126: 
INFO  [00:21:37.015] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:21:37.015] [bbotk]              4.084297                 2.694303                       0.4339114 
INFO  [00:21:37.015] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:21:37.015] [bbotk]                     4885        0.808 -0.9620177         <NA>   0.9756247 
INFO  [00:21:37.015] [bbotk]                                 uhash 
INFO  [00:21:37.015] [bbotk]  43e021a1-adcd-4536-85a4-9a4bb4e4eb5f 
DEBUG [00:21:38.621] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.08952e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.08952e-05 0.00138145 
  - best initial criterion value(s) :  654.5307 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -654.53  |proj g|=       6.4295
At iterate     1  f =      -656.32  |proj g|=        7.5013
At iterate     2  f =      -658.77  |proj g|=        6.0207
At iterate     3  f =      -662.19  |proj g|=        4.0885
At iterate     4  f =      -662.38  |proj g|=        4.1103
At iterate     5  f =      -662.38  |proj g|=        4.1047
At iterate     6  f =      -662.38  |proj g|=        4.1044
At iterate     7  f =      -662.38  |proj g|=        4.1041
At iterate     8  f =      -662.38  |proj g|=        4.1035
At iterate     9  f =      -662.38  |proj g|=        4.1028
At iterate    10  f =      -662.38  |proj g|=         4.102
At iterate    11  f =      -662.39  |proj g|=        4.1018
At iterate    12  f =      -662.39  |proj g|=        4.1045
At iterate    13  f =       -662.4  |proj g|=        4.1159
At iterate    14  f =      -662.42  |proj g|=        4.1432
At iterate    15  f =      -662.42  |proj g|=         4.164
At iterate    16  f =      -662.42  |proj g|=        4.1682
At iterate    17  f =      -662.42  |proj g|=        4.1687
At iterate    18  f =      -662.42  |proj g|=         4.169
At iterate    19  f =      -662.43  |proj g|=        4.1694
At iterate    20  f =      -662.43  |proj g|=        4.1691
At iterate    21  f =      -662.43  |proj g|=        4.1662
At iterate    22  f =      -662.45  |proj g|=        4.1553
At iterate    23  f =      -662.47  |proj g|=         4.129
At iterate    24  f =      -662.51  |proj g|=        4.0993
At iterate    25  f =      -662.52  |proj g|=        4.0729
At iterate    26  f =      -662.58  |proj g|=        4.0431
At iterate    27  f =      -662.83  |proj g|=        3.9804
At iterate    28  f =      -663.98  |proj g|=        3.8147
At iterate    29  f =      -667.58  |proj g|=        3.4851
At iterate    30  f =      -678.53  |proj g|=         2.806
At iterate    31  f =      -688.16  |proj g|=        1.0066
At iterate    32  f =      -689.03  |proj g|=        1.7676
At iterate    33  f =      -689.11  |proj g|=         1.663
At iterate    34  f =      -689.22  |proj g|=        1.4371
At iterate    35  f =      -689.24  |proj g|=        1.3907
At iterate    36  f =      -689.24  |proj g|=        1.3889
At iterate    37  f =      -689.24  |proj g|=        1.3995
At iterate    38  f =      -689.24  |proj g|=        1.4066
At iterate    39  f =      -689.24  |proj g|=        1.4076
At iterate    40  f =      -689.24  |proj g|=        1.4076

iterations 40
function evaluations 45
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.40761
final function value -689.241

F = -689.241
final  value -689.241056 
converged
 
INFO  [00:21:38.625] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:21:38.681] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:21:38.688] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:21:48.032] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:21:57.205] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:22:05.307] [mlr3]  Finished benchmark 
INFO  [00:22:05.377] [bbotk] Result of batch 127: 
INFO  [00:22:05.379] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:22:05.379] [bbotk]              7.799967                 5.041104                       0.2300517 
INFO  [00:22:05.379] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:22:05.379] [bbotk]                     3159        0.804 -0.9495993         <NA>   0.9743124 
INFO  [00:22:05.379] [bbotk]                                 uhash 
INFO  [00:22:05.379] [bbotk]  6fc5c508-b3c8-4eed-a163-8d21ba3bbce4 
DEBUG [00:22:06.666] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.084809e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.084809e-05 0.001379249 
  - best initial criterion value(s) :  654.8198 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -654.82  |proj g|=        12.68
At iterate     1  f =      -676.94  |proj g|=        3.7381
At iterate     2  f =      -677.69  |proj g|=        4.8981
At iterate     3  f =      -680.56  |proj g|=        5.2799
At iterate     4  f =       -681.3  |proj g|=        5.3735
At iterate     5  f =      -681.87  |proj g|=        7.1899
At iterate     6  f =      -681.99  |proj g|=        6.7452
At iterate     7  f =      -681.99  |proj g|=        6.7496
At iterate     8  f =      -681.99  |proj g|=        6.7409
At iterate     9  f =      -681.99  |proj g|=        6.7571
At iterate    10  f =      -682.02  |proj g|=        6.8665
At iterate    11  f =      -682.06  |proj g|=        6.9693
At iterate    12  f =      -682.19  |proj g|=        7.1082
At iterate    13  f =       -682.5  |proj g|=        7.1564
At iterate    14  f =      -683.27  |proj g|=        6.9199
At iterate    15  f =      -684.86  |proj g|=        6.0735
At iterate    16  f =      -687.69  |proj g|=        4.4933
At iterate    17  f =      -689.54  |proj g|=        3.1492
At iterate    18  f =      -690.39  |proj g|=        2.3064
At iterate    19  f =      -692.29  |proj g|=       0.26795
At iterate    20  f =      -692.67  |proj g|=       0.21446
At iterate    21  f =       -692.7  |proj g|=       0.21201
At iterate    22  f =       -692.7  |proj g|=       0.51296
At iterate    23  f =      -692.71  |proj g|=       0.20931
At iterate    24  f =      -692.71  |proj g|=       0.20881
At iterate    25  f =      -692.71  |proj g|=        0.2088

iterations 25
function evaluations 35
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.208797
final function value -692.705

F = -692.705
final  value -692.705196 
converged
 
INFO  [00:22:06.670] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:22:06.741] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:22:06.747] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:22:12.072] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:22:17.755] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:22:22.738] [mlr3]  Finished benchmark 
INFO  [00:22:22.807] [bbotk] Result of batch 128: 
INFO  [00:22:22.809] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:22:22.809] [bbotk]              2.496205                 3.903767                       0.3146285 
INFO  [00:22:22.809] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [00:22:22.809] [bbotk]                     1899        0.814  -0.95624         <NA>   0.9622345 
INFO  [00:22:22.809] [bbotk]                                 uhash 
INFO  [00:22:22.809] [bbotk]  853e5058-a90a-48c0-9749-36e0a2c63069 
DEBUG [00:22:23.923] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.080346e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.080346e-05 0.001369513 
  - best initial criterion value(s) :  624.6117 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -624.61  |proj g|=       3.3144
At iterate     1  f =      -625.93  |proj g|=        2.9749
At iterate     2  f =      -626.29  |proj g|=        3.0069
At iterate     3  f =       -626.4  |proj g|=        2.9792
At iterate     4  f =      -626.41  |proj g|=        2.9643
At iterate     5  f =      -626.41  |proj g|=        2.9622
At iterate     6  f =      -626.41  |proj g|=        2.9622

iterations 6
function evaluations 9
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.96219
final function value -626.406

F = -626.406
final  value -626.405912 
converged
 
INFO  [00:22:23.927] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:22:23.999] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:22:24.006] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:22:38.947] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:22:52.804] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:23:06.039] [mlr3]  Finished benchmark 
INFO  [00:23:06.108] [bbotk] Result of batch 129: 
INFO  [00:23:06.110] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:23:06.110] [bbotk]              8.625207                 7.446723                       0.1327837 
INFO  [00:23:06.110] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [00:23:06.110] [bbotk]                     4840        0.811 -0.965917         <NA>   0.9741752 
INFO  [00:23:06.110] [bbotk]                                 uhash 
INFO  [00:23:06.110] [bbotk]  daa1dd58-9f5a-4d56-a4bb-d652b0cfc26d 
DEBUG [00:23:07.442] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.075653e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.075653e-05 0.001365287 
  - best initial criterion value(s) :  634.8448 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -634.84  |proj g|=       2.7961
At iterate     1  f =      -700.22  |proj g|=        1.4273
At iterate     2  f =      -704.29  |proj g|=        1.1234
At iterate     3  f =      -707.97  |proj g|=        1.1521
At iterate     4  f =      -708.76  |proj g|=        1.2083
At iterate     5  f =      -708.81  |proj g|=        1.2057
At iterate     6  f =      -708.81  |proj g|=        1.2092
At iterate     7  f =      -708.81  |proj g|=        1.2086
At iterate     8  f =      -708.81  |proj g|=        1.2086
At iterate     9  f =      -708.81  |proj g|=        1.2085
At iterate    10  f =      -708.81  |proj g|=        1.2084
At iterate    11  f =      -708.81  |proj g|=        1.2081
At iterate    12  f =      -708.82  |proj g|=        1.2075
At iterate    13  f =      -708.82  |proj g|=        1.2062
At iterate    14  f =      -708.82  |proj g|=        1.2032
At iterate    15  f =      -708.83  |proj g|=        1.1967
At iterate    16  f =      -708.84  |proj g|=         1.186
At iterate    17  f =      -708.86  |proj g|=        1.1664
At iterate    18  f =      -708.86  |proj g|=        1.1665
At iterate    19  f =       -708.9  |proj g|=        1.1326
At iterate    20  f =       -709.1  |proj g|=        1.0285
At iterate    21  f =      -710.33  |proj g|=       0.37363
At iterate    22  f =       -711.2  |proj g|=       0.74636
At iterate    23  f =      -711.94  |proj g|=       0.38318
At iterate    24  f =      -711.95  |proj g|=       0.47058
At iterate    25  f =      -711.98  |proj g|=       0.76254
At iterate    26  f =      -711.98  |proj g|=       0.30884
At iterate    27  f =      -711.98  |proj g|=        0.3042
At iterate    28  f =      -711.98  |proj g|=       0.30416

iterations 28
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.304159
final function value -711.982

F = -711.982
final  value -711.981597 
converged
 
INFO  [00:23:07.446] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:23:07.526] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:23:07.534] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:23:09.722] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:23:11.939] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:23:14.406] [mlr3]  Finished benchmark 
INFO  [00:23:14.474] [bbotk] Result of batch 130: 
INFO  [00:23:14.476] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:23:14.476] [bbotk]              9.235292                 4.600921                       0.1892603 
INFO  [00:23:14.476] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [00:23:14.476] [bbotk]                      679        0.816 -0.952754         <NA>    0.964969 
INFO  [00:23:14.476] [bbotk]                                 uhash 
INFO  [00:23:14.476] [bbotk]  161e056e-ee12-4bb4-93a3-46739cdc7334 
DEBUG [00:23:15.978] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.069667e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.069667e-05 0.001353318 
  - best initial criterion value(s) :  660.2897 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -660.29  |proj g|=       12.656
At iterate     1  f =      -678.37  |proj g|=        4.3303
At iterate     2  f =      -682.86  |proj g|=        2.7746
At iterate     3  f =      -686.17  |proj g|=        2.9137
At iterate     4  f =      -686.57  |proj g|=        2.9743
At iterate     5  f =      -686.57  |proj g|=        2.9721
At iterate     6  f =      -686.57  |proj g|=         2.972
At iterate     7  f =      -686.58  |proj g|=        2.9721
At iterate     8  f =      -686.58  |proj g|=        2.9704
At iterate     9  f =      -686.58  |proj g|=        2.9726
At iterate    10  f =      -686.58  |proj g|=         2.971
At iterate    11  f =      -687.88  |proj g|=        2.9422
At iterate    12  f =      -690.36  |proj g|=        2.8696
At iterate    13  f =      -690.96  |proj g|=        2.8355
At iterate    14  f =      -691.15  |proj g|=        2.8307
At iterate    15  f =      -691.18  |proj g|=         2.863
At iterate    16  f =      -691.22  |proj g|=        2.8555
At iterate    17  f =      -691.22  |proj g|=        2.8558
At iterate    18  f =      -691.22  |proj g|=        2.8564
At iterate    19  f =      -691.22  |proj g|=        2.8565

iterations 19
function evaluations 26
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.85649
final function value -691.223

F = -691.223
final  value -691.222857 
converged
 
INFO  [00:23:15.982] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:23:16.063] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:23:16.071] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:23:27.917] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:23:42.587] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:23:56.343] [mlr3]  Finished benchmark 
INFO  [00:23:56.446] [bbotk] Result of batch 131: 
INFO  [00:23:56.448] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:23:56.448] [bbotk]              2.167157                 3.654661                      0.03308133 
INFO  [00:23:56.448] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [00:23:56.448] [bbotk]                     4466        1.047 -0.958902         <NA>   0.9431357 
INFO  [00:23:56.448] [bbotk]                                 uhash 
INFO  [00:23:56.448] [bbotk]  fc06fd4d-9831-4b1a-8003-5dc06038d5be 
DEBUG [00:23:57.585] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.102395e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.102395e-05 0.001381605 
  - best initial criterion value(s) :  595.4868 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -595.49  |proj g|=       1.8306
At iterate     1  f =      -595.81  |proj g|=        2.2677
At iterate     2  f =      -595.86  |proj g|=        2.1478
At iterate     3  f =      -595.88  |proj g|=         2.095
At iterate     4  f =      -595.88  |proj g|=        2.0921
At iterate     5  f =      -595.88  |proj g|=        2.0934
At iterate     6  f =      -595.88  |proj g|=        2.0929

iterations 6
function evaluations 10
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.09295
final function value -595.876

F = -595.876
final  value -595.876029 
converged
 
INFO  [00:23:57.589] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:23:57.647] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:23:57.655] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:24:08.027] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:24:17.199] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:24:26.276] [mlr3]  Finished benchmark 
INFO  [00:24:26.345] [bbotk] Result of batch 132: 
INFO  [00:24:26.347] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:24:26.347] [bbotk]              6.066307                 3.593566                       0.2632624 
INFO  [00:24:26.347] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:24:26.347] [bbotk]                     3322        0.819 -0.9700059         <NA>   0.9746785 
INFO  [00:24:26.347] [bbotk]                                 uhash 
INFO  [00:24:26.347] [bbotk]  6128ed41-a1b4-412f-972c-4099e2578e8a 
DEBUG [00:24:27.720] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.098137e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.098137e-05 0.001378875 
  - best initial criterion value(s) :  690.9739 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -690.97  |proj g|=       2.2221
At iterate     1  f =      -715.82  |proj g|=        1.9582
At iterate     2  f =      -719.41  |proj g|=        4.6192
At iterate     3  f =      -722.31  |proj g|=         3.488
At iterate     4  f =      -723.45  |proj g|=        2.4009
At iterate     5  f =      -723.95  |proj g|=        2.6042
At iterate     6  f =      -723.95  |proj g|=        2.7938
At iterate     7  f =      -723.95  |proj g|=        2.7238
At iterate     8  f =      -723.95  |proj g|=        2.7203
At iterate     9  f =      -723.95  |proj g|=         2.721
At iterate    10  f =      -723.95  |proj g|=        2.7269
At iterate    11  f =      -723.95  |proj g|=        2.7335
At iterate    12  f =      -723.95  |proj g|=        2.7417
At iterate    13  f =      -723.95  |proj g|=         2.753
At iterate    14  f =      -723.96  |proj g|=        2.7633
At iterate    15  f =      -723.96  |proj g|=        2.7586
At iterate    16  f =      -723.96  |proj g|=        2.7112
At iterate    17  f =      -723.97  |proj g|=        2.6953
At iterate    18  f =      -723.97  |proj g|=        2.6457
At iterate    19  f =      -723.99  |proj g|=        2.6021
At iterate    20  f =      -725.13  |proj g|=        2.0629
At iterate    21  f =      -728.42  |proj g|=        1.3279
At iterate    22  f =      -729.63  |proj g|=        1.2754
At iterate    23  f =      -730.61  |proj g|=        1.5112
At iterate    24  f =      -730.88  |proj g|=        1.4752
At iterate    25  f =      -730.89  |proj g|=        1.9438
At iterate    26  f =      -730.92  |proj g|=        1.7324
At iterate    27  f =      -730.92  |proj g|=        1.7089
At iterate    28  f =      -730.92  |proj g|=        1.7108
At iterate    29  f =      -730.92  |proj g|=        1.7107

iterations 29
function evaluations 40
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.71072
final function value -730.916

F = -730.916
final  value -730.916156 
converged
 
INFO  [00:24:27.724] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:24:27.806] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:24:27.818] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:24:41.377] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:24:55.529] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:25:08.059] [mlr3]  Finished benchmark 
INFO  [00:25:08.130] [bbotk] Result of batch 133: 
INFO  [00:25:08.131] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:25:08.131] [bbotk]              3.764493                 2.399684                      0.08175344 
INFO  [00:25:08.131] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:25:08.131] [bbotk]                     4592        0.824 -0.9507597         <NA>   0.9680745 
INFO  [00:25:08.131] [bbotk]                                 uhash 
INFO  [00:25:08.131] [bbotk]  aed92798-54f3-4dca-9c78-72a18a900f86 
DEBUG [00:25:09.474] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.091403e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.091403e-05 0.001370705 
  - best initial criterion value(s) :  667.9145 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -667.91  |proj g|=       12.474
At iterate     1  f =      -694.67  |proj g|=        7.6786
At iterate     2  f =      -695.03  |proj g|=        7.8958
At iterate     3  f =      -695.15  |proj g|=        7.5201
At iterate     4  f =      -695.17  |proj g|=        7.2948
At iterate     5  f =      -695.17  |proj g|=        7.2826
At iterate     6  f =      -695.17  |proj g|=        7.2822
At iterate     7  f =      -695.17  |proj g|=        7.2837
At iterate     8  f =      -695.17  |proj g|=        7.2835
At iterate     9  f =      -695.17  |proj g|=        7.2815
At iterate    10  f =      -695.17  |proj g|=        7.2759
At iterate    11  f =      -695.18  |proj g|=        7.2537
At iterate    12  f =      -695.19  |proj g|=        7.1977
At iterate    13  f =      -695.22  |proj g|=        7.1317
At iterate    14  f =      -695.29  |proj g|=        6.8654
At iterate    15  f =      -695.31  |proj g|=        6.9945
At iterate    16  f =      -695.45  |proj g|=        6.6439
At iterate    17  f =      -695.88  |proj g|=        5.9037
At iterate    18  f =      -696.99  |proj g|=        4.7148
At iterate    19  f =      -700.07  |proj g|=        2.7752
At iterate    20  f =      -704.92  |proj g|=       0.47753
At iterate    21  f =      -704.94  |proj g|=       0.38709
At iterate    22  f =      -705.67  |proj g|=       0.79332
At iterate    23  f =       -705.7  |proj g|=       0.23135
At iterate    24  f =      -705.71  |proj g|=       0.23269
At iterate    25  f =      -705.71  |proj g|=       0.23262
At iterate    26  f =      -705.71  |proj g|=       0.23259

iterations 26
function evaluations 33
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.232591
final function value -705.705

F = -705.705
final  value -705.705424 
converged
 
INFO  [00:25:09.479] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:25:09.535] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:25:09.542] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:25:22.639] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:25:37.570] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:25:52.232] [mlr3]  Finished benchmark 
INFO  [00:25:52.301] [bbotk] Result of batch 134: 
INFO  [00:25:52.303] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:25:52.303] [bbotk]              5.342745                  2.44123                      0.07264912 
INFO  [00:25:52.303] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:25:52.303] [bbotk]                     4829        0.832 -0.9595646         <NA>   0.9708641 
INFO  [00:25:52.303] [bbotk]                                 uhash 
INFO  [00:25:52.303] [bbotk]  c4a109f8-6cb0-43dc-aaf5-44a5ba28376f 
DEBUG [00:25:53.726] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.085154e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.085154e-05 0.001364106 
  - best initial criterion value(s) :  672.8861 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -672.89  |proj g|=       8.0532
At iterate     1  f =      -696.91  |proj g|=        7.2019
At iterate     2  f =      -706.02  |proj g|=        5.7449
At iterate     3  f =      -716.81  |proj g|=        4.5437
At iterate     4  f =      -717.03  |proj g|=         4.304
At iterate     5  f =      -717.52  |proj g|=        4.4413
At iterate     6  f =      -718.12  |proj g|=         4.554
At iterate     7  f =      -718.86  |proj g|=        4.6751
At iterate     8  f =      -718.98  |proj g|=        4.6654
At iterate     9  f =      -718.99  |proj g|=        4.6896
At iterate    10  f =         -719  |proj g|=        4.7185
At iterate    11  f =         -719  |proj g|=        4.7209
At iterate    12  f =         -719  |proj g|=         4.721

iterations 12
function evaluations 15
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.72102
final function value -718.998

F = -718.998
final  value -718.998363 
converged
 
INFO  [00:25:53.730] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:25:53.787] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:25:53.794] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:26:03.651] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:26:12.851] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:26:22.906] [mlr3]  Finished benchmark 
INFO  [00:26:22.976] [bbotk] Result of batch 135: 
INFO  [00:26:22.978] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:26:22.978] [bbotk]              4.986092                 5.942932                       0.1547806 
INFO  [00:26:22.978] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:26:22.978] [bbotk]                     3335        1.035 -0.9531998         <NA>   0.9725108 
INFO  [00:26:22.978] [bbotk]                                 uhash 
INFO  [00:26:22.978] [bbotk]  d7e1fe1b-236b-4667-846a-86096a9258d3 
DEBUG [00:26:24.341] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.079651e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.079651e-05 0.001359093 
  - best initial criterion value(s) :  708.4713 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -708.47  |proj g|=       7.6777
At iterate     1  f =       -726.1  |proj g|=        1.2451
At iterate     2  f =      -735.43  |proj g|=        1.5101
At iterate     3  f =      -737.79  |proj g|=        1.4264
At iterate     4  f =      -738.08  |proj g|=        1.4411
At iterate     5  f =      -738.49  |proj g|=        1.5064
At iterate     6  f =      -738.63  |proj g|=        1.4859
At iterate     7  f =      -738.64  |proj g|=        1.4898
At iterate     8  f =      -738.64  |proj g|=        1.4907
At iterate     9  f =      -738.64  |proj g|=        1.4906
At iterate    10  f =      -738.64  |proj g|=        1.4906
At iterate    11  f =      -738.64  |proj g|=        1.4905
At iterate    12  f =      -738.64  |proj g|=        1.4904
At iterate    13  f =      -738.64  |proj g|=        1.4902
At iterate    14  f =      -738.64  |proj g|=        1.4898
At iterate    15  f =      -738.65  |proj g|=         1.489
At iterate    16  f =      -738.65  |proj g|=        1.4872
At iterate    17  f =      -738.65  |proj g|=        1.4836
At iterate    18  f =      -738.66  |proj g|=        1.4773
At iterate    19  f =      -738.67  |proj g|=        1.4669
At iterate    20  f =       -738.7  |proj g|=        1.4553
At iterate    21  f =      -738.81  |proj g|=        1.3865
At iterate    22  f =      -739.07  |proj g|=        1.3132
At iterate    23  f =      -739.75  |proj g|=        1.0959
At iterate    24  f =      -740.24  |proj g|=       0.93196
At iterate    25  f =      -740.67  |proj g|=       0.83195
At iterate    26  f =       -740.7  |proj g|=       0.88858
At iterate    27  f =       -740.7  |proj g|=       0.88146
At iterate    28  f =       -740.7  |proj g|=        0.8809

iterations 28
function evaluations 32
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.880904
final function value -740.701

F = -740.701
final  value -740.701301 
converged
 
INFO  [00:26:24.345] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:26:24.401] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:26:24.424] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:26:37.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:26:51.917] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:27:05.592] [mlr3]  Finished benchmark 
INFO  [00:27:05.663] [bbotk] Result of batch 136: 
INFO  [00:27:05.665] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:27:05.665] [bbotk]                  7.61                 6.700214                       0.4386299 
INFO  [00:27:05.665] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:27:05.665] [bbotk]                     4726        0.845 -0.9542585         <NA>   0.9771477 
INFO  [00:27:05.665] [bbotk]                                 uhash 
INFO  [00:27:05.665] [bbotk]  5838af5c-9f92-48f9-8182-3e5e852a3219 
DEBUG [00:27:06.997] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.07782e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.69343 15.88239 0.9842448 9504 
  - variance bounds :  1.07782e-05 0.00135953 
  - best initial criterion value(s) :  682.0047 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -682  |proj g|=       6.3237
At iterate     1  f =      -724.89  |proj g|=        4.9746
At iterate     2  f =      -725.54  |proj g|=        4.5841
At iterate     3  f =      -726.49  |proj g|=        3.6873
At iterate     4  f =      -726.62  |proj g|=        3.7411
At iterate     5  f =       -726.8  |proj g|=          3.76
At iterate     6  f =      -727.61  |proj g|=         3.917
At iterate     7  f =      -727.65  |proj g|=        3.9675
At iterate     8  f =      -727.68  |proj g|=        3.9881
At iterate     9  f =      -727.68  |proj g|=        3.9943
At iterate    10  f =      -727.68  |proj g|=        3.9972
At iterate    11  f =      -727.69  |proj g|=        4.0082
At iterate    12  f =       -727.7  |proj g|=        4.0235
At iterate    13  f =      -727.72  |proj g|=        4.0479
At iterate    14  f =      -727.73  |proj g|=        4.0616
At iterate    15  f =      -727.77  |proj g|=        4.0853
At iterate    16  f =      -727.95  |proj g|=        4.0796
At iterate    17  f =      -727.98  |proj g|=        4.0491
At iterate    18  f =      -727.98  |proj g|=        4.0524
At iterate    19  f =      -727.98  |proj g|=        4.0516
At iterate    20  f =      -727.98  |proj g|=        4.0514

iterations 20
function evaluations 27
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.05144
final function value -727.98

F = -727.98
final  value -727.980286 
converged
 
INFO  [00:27:07.001] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:27:07.058] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:27:07.065] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:27:14.726] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:27:22.323] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:27:29.673] [mlr3]  Finished benchmark 
INFO  [00:27:29.743] [bbotk] Result of batch 137: 
INFO  [00:27:29.745] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:27:29.745] [bbotk]              9.965316                 3.561995                       0.4746101 
INFO  [00:27:29.745] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:27:29.745] [bbotk]                     2680        0.862 -0.9572176         <NA>   0.9759958 
INFO  [00:27:29.745] [bbotk]                                 uhash 
INFO  [00:27:29.745] [bbotk]  35e587d7-18f3-4edd-aca1-b8ba07d45da4 
DEBUG [00:27:31.524] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.074829e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.074829e-05 0.001358497 
  - best initial criterion value(s) :  677.1447 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -677.14  |proj g|=       9.7966
At iterate     1  f =      -709.48  |proj g|=       0.83713
At iterate     2  f =      -710.16  |proj g|=       0.99618
At iterate     3  f =      -710.88  |proj g|=        2.5047
At iterate     4  f =      -710.98  |proj g|=        2.0139
At iterate     5  f =      -710.99  |proj g|=        2.0931
At iterate     6  f =      -710.99  |proj g|=        2.0995
At iterate     7  f =      -710.99  |proj g|=        2.1035
At iterate     8  f =      -710.99  |proj g|=        2.1144
At iterate     9  f =      -710.99  |proj g|=        2.1229
At iterate    10  f =      -710.99  |proj g|=        2.1224
At iterate    11  f =      -710.99  |proj g|=        2.1134
At iterate    12  f =      -710.99  |proj g|=        2.1074
At iterate    13  f =      -710.99  |proj g|=        2.1039
At iterate    14  f =      -710.99  |proj g|=         2.096
At iterate    15  f =      -710.99  |proj g|=         2.084
At iterate    16  f =      -710.99  |proj g|=        2.0645
At iterate    17  f =      -710.99  |proj g|=        2.0344
At iterate    18  f =         -711  |proj g|=        1.9892
At iterate    19  f =      -711.02  |proj g|=        1.9287
At iterate    20  f =      -711.07  |proj g|=        1.8758
At iterate    21  f =      -711.15  |proj g|=        1.9145
At iterate    22  f =       -711.2  |proj g|=        2.1577
At iterate    23  f =      -711.21  |proj g|=        2.1678
At iterate    24  f =      -711.41  |proj g|=        2.3021
At iterate    25  f =      -712.41  |proj g|=        2.4791
At iterate    26  f =      -713.89  |proj g|=        1.8831
At iterate    27  f =      -714.89  |proj g|=       0.37111
At iterate    28  f =      -715.01  |proj g|=       0.29174
At iterate    29  f =      -715.02  |proj g|=       0.29203
At iterate    30  f =      -715.02  |proj g|=       0.29187
At iterate    31  f =      -715.02  |proj g|=       0.29126
At iterate    32  f =      -715.02  |proj g|=       0.59775
At iterate    33  f =      -715.02  |proj g|=       0.28963
At iterate    34  f =      -715.02  |proj g|=       0.28935
At iterate    35  f =      -715.02  |proj g|=       0.28939
At iterate    36  f =      -715.02  |proj g|=        0.2896
At iterate    37  f =      -715.02  |proj g|=       0.28963
At iterate    38  f =      -715.07  |proj g|=       0.79611
At iterate    39  f =      -715.34  |proj g|=       0.79218
At iterate    40  f =      -715.55  |proj g|=       0.79067
At iterate    41  f =      -715.61  |proj g|=       0.18936
At iterate    42  f =      -715.62  |proj g|=       0.18839
At iterate    43  f =      -715.62  |proj g|=        0.7557
At iterate    44  f =      -715.62  |proj g|=       0.57094
At iterate    45  f =      -715.62  |proj g|=       0.24897
At iterate    46  f =      -715.62  |proj g|=      0.034137
At iterate    47  f =      -715.62  |proj g|=      0.059585

iterations 47
function evaluations 61
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0595845
final function value -715.618

F = -715.618
final  value -715.617874 
converged
 
INFO  [00:27:31.529] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:27:31.609] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:27:31.616] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:27:35.157] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:27:37.667] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:27:41.100] [mlr3]  Finished benchmark 
INFO  [00:27:41.170] [bbotk] Result of batch 138: 
INFO  [00:27:41.171] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:27:41.171] [bbotk]              6.378931                  4.32782                      0.04813211 
INFO  [00:27:41.171] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:27:41.171] [bbotk]                      894        1.023 -0.9612382         <NA>   0.9503089 
INFO  [00:27:41.171] [bbotk]                                 uhash 
INFO  [00:27:41.171] [bbotk]  2a20125a-a8ac-4bbe-90df-8a1ac0175962 
DEBUG [00:27:42.557] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.087825e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.087825e-05 0.00137708 
  - best initial criterion value(s) :  686.8697 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -686.87  |proj g|=        5.219
At iterate     1  f =       -744.2  |proj g|=        2.8499
At iterate     2  f =      -753.24  |proj g|=        1.8092
At iterate     3  f =      -753.59  |proj g|=        1.8178
At iterate     4  f =      -754.37  |proj g|=        1.8577
At iterate     5  f =      -754.63  |proj g|=        1.9018
At iterate     6  f =      -754.75  |proj g|=        1.9176
At iterate     7  f =      -754.75  |proj g|=        1.9209
At iterate     8  f =      -754.75  |proj g|=        1.9206
At iterate     9  f =      -754.75  |proj g|=        1.9207
At iterate    10  f =      -754.75  |proj g|=        1.9211
At iterate    11  f =      -754.75  |proj g|=        1.9217
At iterate    12  f =      -754.75  |proj g|=        1.9227
At iterate    13  f =      -754.76  |proj g|=        1.9239
At iterate    14  f =      -754.76  |proj g|=        1.9256
At iterate    15  f =      -754.76  |proj g|=        1.9248
At iterate    16  f =      -754.78  |proj g|=        1.9251
At iterate    17  f =      -754.85  |proj g|=        1.9146
At iterate    18  f =      -755.26  |proj g|=        1.8216
At iterate    19  f =      -756.47  |proj g|=        1.4668
At iterate    20  f =      -758.61  |proj g|=       0.83336
At iterate    21  f =      -758.74  |proj g|=        1.1114
At iterate    22  f =      -760.53  |proj g|=        1.2265
At iterate    23  f =      -760.59  |proj g|=        1.2992
At iterate    24  f =      -760.59  |proj g|=        1.3015
At iterate    25  f =      -760.59  |proj g|=        1.3018

iterations 25
function evaluations 33
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.30182
final function value -760.592

F = -760.592
final  value -760.592407 
converged
 
INFO  [00:27:42.561] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:27:42.617] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:27:42.624] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:27:47.406] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:27:51.141] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:27:54.730] [mlr3]  Finished benchmark 
INFO  [00:27:54.799] [bbotk] Result of batch 139: 
INFO  [00:27:54.801] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:27:54.801] [bbotk]              7.846153                 9.605024                       0.1928653 
INFO  [00:27:54.801] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [00:27:54.801] [bbotk]                     1220        0.843 -0.953292         <NA>   0.9693909 
INFO  [00:27:54.801] [bbotk]                                 uhash 
INFO  [00:27:54.801] [bbotk]  616e4f88-4847-4fe9-92d0-3ae23216d2c7 
DEBUG [00:27:55.996] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.081458e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.081458e-05 0.001364026 
  - best initial criterion value(s) :  736.2422 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -736.24  |proj g|=        3.384
At iterate     1  f =      -744.39  |proj g|=        2.9215
At iterate     2  f =      -752.03  |proj g|=        4.6884
At iterate     3  f =      -753.07  |proj g|=        4.3382
At iterate     4  f =      -755.34  |proj g|=        3.6058
At iterate     5  f =      -755.47  |proj g|=        3.5507
At iterate     6  f =      -755.47  |proj g|=        3.5682
At iterate     7  f =      -755.47  |proj g|=        3.5636
At iterate     8  f =      -755.47  |proj g|=        3.5637

iterations 8
function evaluations 13
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.5637
final function value -755.474

F = -755.474
final  value -755.474197 
converged
 
INFO  [00:27:56.000] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:27:56.056] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:27:56.064] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:28:07.368] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:28:17.675] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:28:28.357] [mlr3]  Finished benchmark 
INFO  [00:28:28.426] [bbotk] Result of batch 140: 
INFO  [00:28:28.428] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:28:28.428] [bbotk]              9.689823                 9.812155                        0.132025 
INFO  [00:28:28.428] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:28:28.428] [bbotk]                     3744        0.832 -0.9527557         <NA>   0.9732882 
INFO  [00:28:28.428] [bbotk]                                 uhash 
INFO  [00:28:28.428] [bbotk]  5817f530-d561-4271-9d9d-8610aeff8739 
DEBUG [00:28:30.001] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.076544e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.076544e-05 0.001360415 
  - best initial criterion value(s) :  698.1973 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -698.2  |proj g|=       5.7698
At iterate     1  f =      -708.91  |proj g|=        11.532
At iterate     2  f =      -755.22  |proj g|=        5.8232
At iterate     3  f =      -755.77  |proj g|=        4.7614
At iterate     4  f =      -755.83  |proj g|=         4.646
At iterate     5  f =      -756.51  |proj g|=        3.6619
At iterate     6  f =      -756.94  |proj g|=        3.2289
At iterate     7  f =      -757.19  |proj g|=        3.2784
At iterate     8  f =      -757.23  |proj g|=        3.2817
At iterate     9  f =      -757.23  |proj g|=         3.283
At iterate    10  f =      -757.23  |proj g|=        3.2839
At iterate    11  f =      -757.23  |proj g|=        3.2834
At iterate    12  f =      -757.23  |proj g|=        3.2861
At iterate    13  f =      -757.23  |proj g|=        3.2859
At iterate    14  f =      -757.23  |proj g|=        3.2836
At iterate    15  f =      -757.23  |proj g|=        3.2791
At iterate    16  f =      -757.24  |proj g|=        3.2639
At iterate    17  f =      -757.25  |proj g|=         3.216
At iterate    18  f =      -757.26  |proj g|=        3.2808
At iterate    19  f =       -757.3  |proj g|=        3.1783
At iterate    20  f =      -757.56  |proj g|=        3.0484
At iterate    21  f =      -758.07  |proj g|=        3.1575
At iterate    22  f =      -758.92  |proj g|=        3.2882
At iterate    23  f =      -759.86  |proj g|=        3.1982
At iterate    24  f =         -760  |proj g|=        3.2504
At iterate    25  f =      -760.06  |proj g|=        3.2216
At iterate    26  f =      -760.07  |proj g|=         3.212
At iterate    27  f =      -760.07  |proj g|=        3.2104
At iterate    28  f =      -760.07  |proj g|=        3.2113
At iterate    29  f =      -760.07  |proj g|=        3.2112

iterations 29
function evaluations 34
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.21117
final function value -760.07

F = -760.07
final  value -760.070487 
converged
 
INFO  [00:28:30.005] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:28:30.060] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:28:30.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:28:37.486] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:28:46.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:28:54.837] [mlr3]  Finished benchmark 
INFO  [00:28:54.907] [bbotk] Result of batch 141: 
INFO  [00:28:54.909] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:28:54.909] [bbotk]              5.774458                 5.130565                       0.1382091 
INFO  [00:28:54.909] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [00:28:54.909] [bbotk]                     2847        1.026 -0.954567         <NA>    0.971754 
INFO  [00:28:54.909] [bbotk]                                 uhash 
INFO  [00:28:54.909] [bbotk]  4e9bd858-1520-46a5-9c6a-298d9b2746ab 
DEBUG [00:28:56.330] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.070926e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.070926e-05 0.001356848 
  - best initial criterion value(s) :  694.9393 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -694.94  |proj g|=        8.852
At iterate     1  f =      -722.48  |proj g|=        7.5767
At iterate     2  f =      -723.11  |proj g|=        6.8711
At iterate     3  f =       -723.7  |proj g|=        6.6778
At iterate     4  f =      -725.02  |proj g|=        5.8788
At iterate     5  f =      -726.09  |proj g|=        6.2916
At iterate     6  f =      -726.26  |proj g|=        6.6208
At iterate     7  f =      -726.26  |proj g|=        6.5541
At iterate     8  f =      -726.26  |proj g|=         6.554
At iterate     9  f =      -726.26  |proj g|=        6.5613
At iterate    10  f =      -726.26  |proj g|=        6.5709
At iterate    11  f =      -726.27  |proj g|=        6.6072
At iterate    12  f =      -726.28  |proj g|=        6.6629
At iterate    13  f =      -726.32  |proj g|=        6.7508
At iterate    14  f =      -726.42  |proj g|=        6.8829
At iterate    15  f =      -726.68  |proj g|=        7.0677
At iterate    16  f =      -726.77  |proj g|=        7.3364
At iterate    17  f =      -727.77  |proj g|=        7.2668
At iterate    18  f =      -729.38  |proj g|=        7.0501
At iterate    19  f =      -733.93  |proj g|=        6.2525
At iterate    20  f =      -753.29  |proj g|=        3.7093
At iterate    21  f =      -768.58  |proj g|=        1.7149
At iterate    22  f =      -773.31  |proj g|=        1.9132
At iterate    23  f =      -773.83  |proj g|=        1.3538
At iterate    24  f =      -774.08  |proj g|=        1.1948
At iterate    25  f =      -774.43  |proj g|=       0.66794
At iterate    26  f =      -774.45  |proj g|=       0.51963
At iterate    27  f =      -774.45  |proj g|=       0.47385
At iterate    28  f =      -774.45  |proj g|=       0.46954
At iterate    29  f =      -774.45  |proj g|=       0.46939

iterations 29
function evaluations 38
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.469393
final function value -774.451

F = -774.451
final  value -774.450891 
converged
 
INFO  [00:28:56.332] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:28:56.409] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:28:56.417] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:29:09.512] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:29:23.166] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:29:37.017] [mlr3]  Finished benchmark 
INFO  [00:29:37.087] [bbotk] Result of batch 142: 
INFO  [00:29:37.089] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:29:37.089] [bbotk]              7.487295                 5.082052                       0.3700654 
INFO  [00:29:37.089] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:29:37.089] [bbotk]                     4815        0.837 -0.9523337         <NA>   0.9767312 
INFO  [00:29:37.089] [bbotk]                                 uhash 
INFO  [00:29:37.089] [bbotk]  bf287976-17be-43b2-95fa-c080d5220f62 
DEBUG [00:29:38.490] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.068749e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.068749e-05 0.001355838 
  - best initial criterion value(s) :  726.7317 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -726.73  |proj g|=       8.7349
At iterate     1  f =      -747.79  |proj g|=        10.079
At iterate     2  f =      -749.38  |proj g|=            10
At iterate     3  f =      -754.05  |proj g|=        7.3261
At iterate     4  f =      -754.32  |proj g|=        5.7622
At iterate     5  f =      -754.46  |proj g|=        5.8348
At iterate     6  f =      -754.46  |proj g|=        5.7881
At iterate     7  f =      -754.46  |proj g|=        5.7802
At iterate     8  f =      -754.46  |proj g|=        5.7518
At iterate     9  f =      -754.46  |proj g|=        5.7169
At iterate    10  f =      -754.47  |proj g|=        5.6526
At iterate    11  f =      -754.48  |proj g|=        5.5523
At iterate    12  f =      -754.51  |proj g|=        5.3763
At iterate    13  f =      -754.59  |proj g|=        5.0623
At iterate    14  f =      -754.79  |proj g|=        4.5014
At iterate    15  f =      -755.23  |proj g|=        3.6642
At iterate    16  f =      -755.78  |proj g|=        2.9793
At iterate    17  f =      -756.16  |proj g|=        2.6367
At iterate    18  f =       -756.8  |proj g|=         2.437
At iterate    19  f =      -757.72  |proj g|=        2.3364
At iterate    20  f =      -759.79  |proj g|=        1.9797
At iterate    21  f =      -764.41  |proj g|=        1.8696
At iterate    22  f =      -768.49  |proj g|=        1.5024
At iterate    23  f =      -775.74  |proj g|=       0.81419
At iterate    24  f =      -782.24  |proj g|=       0.77431
At iterate    25  f =      -786.54  |proj g|=        0.7293
At iterate    26  f =      -787.58  |proj g|=       0.79654
At iterate    27  f =      -787.76  |proj g|=       0.79752
At iterate    28  f =      -787.78  |proj g|=       0.67879
At iterate    29  f =      -787.79  |proj g|=       0.66883
At iterate    30  f =      -787.79  |proj g|=       0.66649
At iterate    31  f =      -787.79  |proj g|=       0.66615

iterations 31
function evaluations 35
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.66615
final function value -787.793

F = -787.793
final  value -787.793420 
converged
 
INFO  [00:29:38.494] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:29:38.552] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:29:38.559] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:29:54.461] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:30:09.021] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:30:20.127] [mlr3]  Finished benchmark 
INFO  [00:30:20.224] [bbotk] Result of batch 143: 
INFO  [00:30:20.226] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:30:20.226] [bbotk]              8.727386                 4.645766                       0.1211982 
INFO  [00:30:20.226] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:30:20.226] [bbotk]                     4670        0.849 -0.9400719         <NA>   0.9737456 
INFO  [00:30:20.226] [bbotk]                                 uhash 
INFO  [00:30:20.226] [bbotk]  5d40e5f7-a960-4528-91ca-398566c6f259 
DEBUG [00:30:21.766] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.064208e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.064208e-05 0.001351881 
  - best initial criterion value(s) :  678.9397 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -678.94  |proj g|=       2.1661
At iterate     1  f =      -688.75  |proj g|=        12.368
At iterate     2  f =      -691.48  |proj g|=        12.406
At iterate     3  f =      -697.38  |proj g|=        11.084
At iterate     4  f =      -699.99  |proj g|=         8.976
At iterate     5  f =      -709.26  |proj g|=         11.11
At iterate     6  f =      -713.77  |proj g|=        11.471
At iterate     7  f =      -713.79  |proj g|=        11.419
At iterate     8  f =      -713.82  |proj g|=        11.445
At iterate     9  f =      -713.82  |proj g|=        11.443
At iterate    10  f =      -713.82  |proj g|=        11.443
At iterate    11  f =      -713.82  |proj g|=        11.442
At iterate    12  f =      -713.82  |proj g|=        11.442
At iterate    13  f =      -713.82  |proj g|=         11.44
At iterate    14  f =      -713.82  |proj g|=        11.438
At iterate    15  f =      -713.83  |proj g|=        11.434
At iterate    16  f =      -713.83  |proj g|=        11.427
At iterate    17  f =      -713.86  |proj g|=        11.413
At iterate    18  f =      -713.91  |proj g|=        11.389
At iterate    19  f =      -714.05  |proj g|=        11.346
At iterate    20  f =       -714.4  |proj g|=        11.251
At iterate    21  f =      -714.48  |proj g|=        11.227
At iterate    22  f =      -715.41  |proj g|=        10.918
At iterate    23  f =      -744.83  |proj g|=        5.7903
At iterate    24  f =      -759.63  |proj g|=        3.5464
At iterate    25  f =      -768.29  |proj g|=        2.8546
At iterate    26  f =      -770.26  |proj g|=        2.8187
At iterate    27  f =      -771.06  |proj g|=        1.4912
At iterate    28  f =      -771.11  |proj g|=         1.629
At iterate    29  f =      -771.13  |proj g|=         1.733
At iterate    30  f =      -771.15  |proj g|=         1.755
At iterate    31  f =      -771.18  |proj g|=        1.7161
At iterate    32  f =       -771.2  |proj g|=        1.6082
At iterate    33  f =       -771.2  |proj g|=         1.573
At iterate    34  f =       -771.2  |proj g|=        1.5689
At iterate    35  f =       -771.2  |proj g|=        1.5688

iterations 35
function evaluations 44
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.56885
final function value -771.2

F = -771.2
final  value -771.200043 
converged
 
INFO  [00:30:21.771] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:30:21.844] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:30:21.852] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:30:26.421] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:30:31.141] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:30:35.834] [mlr3]  Finished benchmark 
INFO  [00:30:35.906] [bbotk] Result of batch 144: 
INFO  [00:30:35.908] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:30:35.908] [bbotk]              2.499971                 6.758763                       0.1808832 
INFO  [00:30:35.908] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:30:35.908] [bbotk]                     2385         0.85 -0.9542509         <NA>   0.9591687 
INFO  [00:30:35.908] [bbotk]                                 uhash 
INFO  [00:30:35.908] [bbotk]  8d5d367f-8a3b-4beb-902f-62bea2135484 
DEBUG [00:30:37.300] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.063004e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.063004e-05 0.001348683 
  - best initial criterion value(s) :  710.8469 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -710.85  |proj g|=       5.4123
At iterate     1  f =      -735.05  |proj g|=       0.67269
At iterate     2  f =      -735.97  |proj g|=       0.70048
At iterate     3  f =      -737.54  |proj g|=       0.72661
At iterate     4  f =      -739.76  |proj g|=         1.802
At iterate     5  f =      -739.87  |proj g|=        2.3268
At iterate     6  f =      -739.93  |proj g|=        2.0268
At iterate     7  f =      -739.93  |proj g|=         2.103
At iterate     8  f =      -739.93  |proj g|=        2.0877
At iterate     9  f =      -739.93  |proj g|=        2.0884

iterations 9
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.08835
final function value -739.934

F = -739.934
final  value -739.933658 
converged
 
INFO  [00:30:37.304] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:30:37.359] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:30:37.366] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:30:47.560] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:30:57.789] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:31:07.764] [mlr3]  Finished benchmark 
INFO  [00:31:07.833] [bbotk] Result of batch 145: 
INFO  [00:31:07.835] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:31:07.835] [bbotk]              3.448629                 8.054795                       0.2095843 
INFO  [00:31:07.835] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:31:07.835] [bbotk]                     4961        1.023 -0.9576825         <NA>   0.9719438 
INFO  [00:31:07.835] [bbotk]                                 uhash 
INFO  [00:31:07.835] [bbotk]  4b452331-fb91-43a6-ba56-af9a5f8cb6a3 
DEBUG [00:31:09.301] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.057648e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.057648e-05 0.001342706 
  - best initial criterion value(s) :  731.1602 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -731.16  |proj g|=        8.297
At iterate     1  f =      -741.62  |proj g|=        9.0518
At iterate     2  f =      -744.11  |proj g|=         9.149
At iterate     3  f =      -746.96  |proj g|=        8.4562
At iterate     4  f =      -747.42  |proj g|=        7.9054
At iterate     5  f =      -747.99  |proj g|=        7.2498
At iterate     6  f =      -748.05  |proj g|=        7.1031
At iterate     7  f =      -748.05  |proj g|=        7.0681
At iterate     8  f =      -748.05  |proj g|=        7.0651
At iterate     9  f =      -748.06  |proj g|=        7.0385
At iterate    10  f =      -748.07  |proj g|=         7.008
At iterate    11  f =       -748.1  |proj g|=        6.9453
At iterate    12  f =      -748.18  |proj g|=        6.8477
At iterate    13  f =       -748.4  |proj g|=        6.6666
At iterate    14  f =      -748.99  |proj g|=        6.3322
At iterate    15  f =      -750.65  |proj g|=        5.6931
At iterate    16  f =       -755.3  |proj g|=        4.6271
At iterate    17  f =      -765.94  |proj g|=        3.3978
At iterate    18  f =      -767.87  |proj g|=        5.2483
At iterate    19  f =      -770.04  |proj g|=        7.7506
At iterate    20  f =      -773.34  |proj g|=        7.2316
At iterate    21  f =      -778.12  |proj g|=        6.5625
At iterate    22  f =      -778.94  |proj g|=        7.1294
At iterate    23  f =      -779.17  |proj g|=         7.358
At iterate    24  f =      -779.19  |proj g|=        7.6695
At iterate    25  f =      -779.21  |proj g|=        7.6617
At iterate    26  f =      -779.21  |proj g|=        7.5898
At iterate    27  f =      -779.21  |proj g|=        7.6015
At iterate    28  f =      -779.21  |proj g|=        7.6022

iterations 28
function evaluations 34
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 7.60215
final function value -779.211

F = -779.211
final  value -779.211063 
converged
 
INFO  [00:31:09.306] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:31:09.382] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:31:09.390] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:31:18.476] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:31:27.704] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:31:36.753] [mlr3]  Finished benchmark 
INFO  [00:31:36.823] [bbotk] Result of batch 146: 
INFO  [00:31:36.825] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:31:36.825] [bbotk]               4.70151                 6.742236                       0.2650055 
INFO  [00:31:36.825] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:31:36.825] [bbotk]                     4815        0.858 -0.9540928         <NA>   0.9752277 
INFO  [00:31:36.825] [bbotk]                                 uhash 
INFO  [00:31:36.825] [bbotk]  88c7ec0e-1793-4417-af8b-8caddf51cdf8 
DEBUG [00:31:38.765] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.054267e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.054267e-05 0.001335898 
  - best initial criterion value(s) :  690.1219 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -690.12  |proj g|=       7.8455
At iterate     1  f =      -722.93  |proj g|=        10.207
At iterate     2  f =      -731.39  |proj g|=        10.269
At iterate     3  f =      -746.72  |proj g|=         9.966
At iterate     4  f =      -748.78  |proj g|=        9.1677
At iterate     5  f =       -748.8  |proj g|=        9.2558
At iterate     6  f =      -748.81  |proj g|=        9.2307
At iterate     7  f =      -748.82  |proj g|=        9.1846
At iterate     8  f =      -748.83  |proj g|=        9.1608
At iterate     9  f =      -748.84  |proj g|=        9.1637
At iterate    10  f =      -748.84  |proj g|=        9.1739
At iterate    11  f =      -748.84  |proj g|=        9.1762
At iterate    12  f =      -748.84  |proj g|=        9.1765
At iterate    13  f =      -748.84  |proj g|=        9.1774
At iterate    14  f =      -748.84  |proj g|=         9.179
At iterate    15  f =      -748.84  |proj g|=        9.1813
At iterate    16  f =      -748.84  |proj g|=        9.1851
At iterate    17  f =      -748.84  |proj g|=        9.1909
At iterate    18  f =      -748.84  |proj g|=        9.1992
At iterate    19  f =      -748.84  |proj g|=        9.2197
At iterate    20  f =      -748.85  |proj g|=        9.2366
At iterate    21  f =      -748.87  |proj g|=        9.2949
At iterate    22  f =      -748.93  |proj g|=        9.3528
At iterate    23  f =      -748.93  |proj g|=        9.4015
At iterate    24  f =      -749.05  |proj g|=        9.4947
At iterate    25  f =      -749.94  |proj g|=        9.5098
At iterate    26  f =      -750.12  |proj g|=        9.7361
At iterate    27  f =      -750.13  |proj g|=        9.7348
At iterate    28  f =      -750.14  |proj g|=        9.7368
At iterate    29  f =      -750.14  |proj g|=        9.7314
At iterate    30  f =      -750.14  |proj g|=        9.7338
At iterate    31  f =      -750.14  |proj g|=        9.7348
At iterate    32  f =      -750.14  |proj g|=        9.7373
At iterate    33  f =      -750.14  |proj g|=        9.7409
At iterate    34  f =      -750.14  |proj g|=        9.7453
At iterate    35  f =      -750.14  |proj g|=        9.7476
At iterate    36  f =      -750.14  |proj g|=        9.7481
At iterate    37  f =      -750.14  |proj g|=        9.7413
At iterate    38  f =      -750.14  |proj g|=        9.7415
At iterate    39  f =      -750.14  |proj g|=        9.7418
At iterate    40  f =      -750.14  |proj g|=        9.7416
At iterate    41  f =      -750.14  |proj g|=        9.7394
At iterate    42  f =      -750.15  |proj g|=        9.7326
At iterate    43  f =      -750.16  |proj g|=        9.7059
At iterate    44  f =      -750.17  |proj g|=        9.7098
At iterate    45  f =      -750.19  |proj g|=        9.6387
At iterate    46  f =      -750.22  |proj g|=        9.5549
At iterate    47  f =      -750.23  |proj g|=        9.5263
At iterate    48  f =      -750.24  |proj g|=        9.5306
At iterate    49  f =      -750.24  |proj g|=        9.5249
At iterate    50  f =      -750.24  |proj g|=        9.5285
At iterate    51  f =      -750.25  |proj g|=        9.4674
At iterate    52  f =      -754.39  |proj g|=        8.9197
At iterate    53  f =      -769.66  |proj g|=        6.1364
At iterate    54  f =      -785.48  |proj g|=        3.8822
At iterate    55  f =      -785.64  |proj g|=        3.9992
At iterate    56  f =      -797.89  |proj g|=        1.4076
At iterate    57  f =       -798.2  |proj g|=        1.4148
At iterate    58  f =      -799.72  |proj g|=        1.1036
At iterate    59  f =      -801.09  |proj g|=       0.52572
At iterate    60  f =      -801.28  |proj g|=       0.28151
At iterate    61  f =      -801.29  |proj g|=       0.24213
At iterate    62  f =      -801.33  |proj g|=       0.24104
At iterate    63  f =      -801.45  |proj g|=        0.2321
At iterate    64  f =      -801.49  |proj g|=       0.22595
At iterate    65  f =       -801.5  |proj g|=       0.30212
At iterate    66  f =       -801.5  |proj g|=      0.013259
At iterate    67  f =       -801.5  |proj g|=        0.0557
At iterate    68  f =       -801.5  |proj g|=     0.0081416

iterations 68
function evaluations 84
segments explored during Cauchy searches 72
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00814156
final function value -801.503

F = -801.503
final  value -801.502897 
converged
 
INFO  [00:31:38.769] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:31:39.009] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:31:39.016] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:31:51.083] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:32:00.060] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:32:08.995] [mlr3]  Finished benchmark 
INFO  [00:32:09.064] [bbotk] Result of batch 147: 
INFO  [00:32:09.066] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:32:09.066] [bbotk]              6.190509                 8.603913                       0.2693623 
INFO  [00:32:09.066] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:32:09.066] [bbotk]                     3220        0.866 -0.9536268         <NA>   0.9746321 
INFO  [00:32:09.066] [bbotk]                                 uhash 
INFO  [00:32:09.066] [bbotk]  cbd2a273-0f5f-4ad8-ae6f-013c479e68f5 
DEBUG [00:32:10.718] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.050461e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9504 
  - variance bounds :  1.050461e-05 0.001337742 
  - best initial criterion value(s) :  747.7207 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -747.72  |proj g|=        6.409
At iterate     1  f =      -754.71  |proj g|=        8.1609
At iterate     2  f =      -755.83  |proj g|=        7.7525
At iterate     3  f =      -756.57  |proj g|=        6.4802
At iterate     4  f =      -757.05  |proj g|=        6.7842
At iterate     5  f =      -758.02  |proj g|=        6.2922
At iterate     6  f =      -759.94  |proj g|=        5.3656
At iterate     7  f =      -759.99  |proj g|=        5.4085
At iterate     8  f =      -759.99  |proj g|=        5.4037
At iterate     9  f =      -759.99  |proj g|=        5.4037
At iterate    10  f =         -760  |proj g|=        5.4044
At iterate    11  f =         -760  |proj g|=        5.4048
At iterate    12  f =      -760.02  |proj g|=        5.4072
At iterate    13  f =      -760.07  |proj g|=        5.4094
At iterate    14  f =       -760.2  |proj g|=        5.4077
At iterate    15  f =      -760.54  |proj g|=        5.3863
At iterate    16  f =      -761.46  |proj g|=        5.2923
At iterate    17  f =       -763.9  |proj g|=        4.9851
At iterate    18  f =      -770.63  |proj g|=        4.1496
At iterate    19  f =      -781.86  |proj g|=        3.3619
At iterate    20  f =      -793.94  |proj g|=        1.3423
At iterate    21  f =      -794.96  |proj g|=         1.838
At iterate    22  f =         -797  |proj g|=        3.2073
At iterate    23  f =      -798.84  |proj g|=        3.1516
At iterate    24  f =      -806.62  |proj g|=        1.8541
At iterate    25  f =      -808.27  |proj g|=        1.2584
At iterate    26  f =      -808.86  |proj g|=        0.7226
At iterate    27  f =      -808.96  |proj g|=       0.42457
At iterate    28  f =      -808.97  |proj g|=       0.75525
At iterate    29  f =      -808.97  |proj g|=       0.26257
At iterate    30  f =      -808.97  |proj g|=       0.26581
At iterate    31  f =      -808.97  |proj g|=       0.26506

iterations 31
function evaluations 37
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.265064
final function value -808.973

F = -808.973
final  value -808.973056 
converged
 
INFO  [00:32:10.723] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:32:10.780] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:32:10.787] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:32:11.765] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:32:12.917] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:32:14.494] [mlr3]  Finished benchmark 
INFO  [00:32:14.563] [bbotk] Result of batch 148: 
INFO  [00:32:14.565] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:32:14.565] [bbotk]              7.192242                 2.432852                       0.4004142 
INFO  [00:32:14.565] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:32:14.565] [bbotk]                      244        1.054 -0.9527998         <NA>   0.9609361 
INFO  [00:32:14.565] [bbotk]                                 uhash 
INFO  [00:32:14.565] [bbotk]  935f7f98-ac2b-4c91-a8ea-ee2498ce4756 
DEBUG [00:32:15.956] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.047739e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.047739e-05 0.001329115 
  - best initial criterion value(s) :  710.4866 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -710.49  |proj g|=       12.895
At iterate     1  f =      -737.56  |proj g|=        11.156
At iterate     2  f =      -764.41  |proj g|=        7.4067
At iterate     3  f =      -768.47  |proj g|=        6.1323
At iterate     4  f =       -770.1  |proj g|=        5.7827
At iterate     5  f =      -770.29  |proj g|=        5.4749
At iterate     6  f =       -770.3  |proj g|=           5.5
At iterate     7  f =       -770.3  |proj g|=        5.5137
At iterate     8  f =      -770.34  |proj g|=        5.5766
At iterate     9  f =      -770.47  |proj g|=        5.6762
At iterate    10  f =      -770.92  |proj g|=        5.7779
At iterate    11  f =      -771.76  |proj g|=        6.6533
At iterate    12  f =      -773.87  |proj g|=        6.3586
At iterate    13  f =      -779.81  |proj g|=        5.2945
At iterate    14  f =      -789.11  |proj g|=        4.1977
At iterate    15  f =      -802.02  |proj g|=        2.8741
At iterate    16  f =      -804.88  |proj g|=        2.9507
At iterate    17  f =      -812.57  |proj g|=        3.2279
At iterate    18  f =      -818.59  |proj g|=         2.032
At iterate    19  f =      -820.52  |proj g|=        1.6186
At iterate    20  f =      -821.55  |proj g|=        1.1808
At iterate    21  f =      -821.82  |proj g|=        0.8944
At iterate    22  f =      -821.88  |proj g|=       0.72865
At iterate    23  f =      -821.89  |proj g|=       0.65714
At iterate    24  f =      -821.89  |proj g|=       0.67166
At iterate    25  f =      -821.89  |proj g|=       0.62639
At iterate    26  f =      -821.89  |proj g|=       0.62755

iterations 26
function evaluations 31
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.627553
final function value -821.893

F = -821.893
final  value -821.893055 
converged
 
INFO  [00:32:15.960] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:32:16.016] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:32:16.023] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:32:18.540] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:32:21.785] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:32:24.350] [mlr3]  Finished benchmark 
INFO  [00:32:24.442] [bbotk] Result of batch 149: 
INFO  [00:32:24.445] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:32:24.445] [bbotk]              9.691818                  4.26269                        0.285473 
INFO  [00:32:24.445] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:32:24.445] [bbotk]                      967        0.853 -0.9401019         <NA>   0.9704771 
INFO  [00:32:24.445] [bbotk]                                 uhash 
INFO  [00:32:24.445] [bbotk]  49864ae8-a2e7-4671-a44e-c4017b2dd1ce 
DEBUG [00:32:25.902] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.042117e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.042117e-05 0.001315785 
  - best initial criterion value(s) :  731.9936 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -731.99  |proj g|=       10.619
At iterate     1  f =      -789.75  |proj g|=         3.639
At iterate     2  f =       -807.7  |proj g|=        3.7807
At iterate     3  f =      -807.82  |proj g|=        3.8773
At iterate     4  f =      -807.89  |proj g|=        3.9126
At iterate     5  f =      -808.08  |proj g|=        3.9931
At iterate     6  f =       -808.1  |proj g|=        4.0007
At iterate     7  f =       -808.1  |proj g|=        3.9931
At iterate     8  f =       -808.1  |proj g|=        3.9961
At iterate     9  f =       -808.1  |proj g|=        3.9963
At iterate    10  f =       -808.1  |proj g|=        3.9969
At iterate    11  f =       -808.1  |proj g|=        3.9976
At iterate    12  f =       -808.1  |proj g|=        3.9989
At iterate    13  f =       -808.1  |proj g|=        4.0011
At iterate    14  f =       -808.1  |proj g|=        4.0029
At iterate    15  f =       -808.1  |proj g|=         4.019
At iterate    16  f =      -808.11  |proj g|=        4.0171
At iterate    17  f =      -808.21  |proj g|=        4.0289
At iterate    18  f =      -808.53  |proj g|=        4.0176
At iterate    19  f =      -809.16  |proj g|=        3.9757
At iterate    20  f =       -810.4  |proj g|=        3.7838
At iterate    21  f =      -810.56  |proj g|=        3.6108
At iterate    22  f =      -811.99  |proj g|=         3.526
At iterate    23  f =       -813.2  |proj g|=        3.3893
At iterate    24  f =      -813.23  |proj g|=        3.4357
At iterate    25  f =      -813.29  |proj g|=        3.4698
At iterate    26  f =      -813.29  |proj g|=         3.471
At iterate    27  f =      -813.29  |proj g|=        3.4719
At iterate    28  f =      -813.29  |proj g|=        3.4717

iterations 28
function evaluations 34
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.47167
final function value -813.288

F = -813.288
final  value -813.288440 
converged
 
INFO  [00:32:25.907] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:32:25.965] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:32:25.972] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:32:32.156] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:32:38.619] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:32:45.014] [mlr3]  Finished benchmark 
INFO  [00:32:45.085] [bbotk] Result of batch 150: 
INFO  [00:32:45.087] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:32:45.087] [bbotk]              7.592142                 7.470371                       0.1852948 
INFO  [00:32:45.087] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:32:45.087] [bbotk]                     2220        0.877 -0.9514984         <NA>   0.9720971 
INFO  [00:32:45.087] [bbotk]                                 uhash 
INFO  [00:32:45.087] [bbotk]  d577a899-9332-4aac-931c-99714c931be0 
DEBUG [00:32:47.224] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.037062e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.037062e-05 0.001307571 
  - best initial criterion value(s) :  731.8872 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -731.89  |proj g|=       10.354
At iterate     1  f =      -752.78  |proj g|=        7.1003
At iterate     2  f =      -773.88  |proj g|=        7.1203
At iterate     3  f =      -776.61  |proj g|=        6.7776
At iterate     4  f =      -779.83  |proj g|=        6.2199
At iterate     5  f =      -781.36  |proj g|=        5.9297
At iterate     6  f =      -782.58  |proj g|=        5.7484
At iterate     7  f =      -783.18  |proj g|=        6.3326
At iterate     8  f =       -783.9  |proj g|=        5.9678
At iterate     9  f =      -784.24  |proj g|=        5.7381
At iterate    10  f =      -784.38  |proj g|=        5.6681
At iterate    11  f =      -784.43  |proj g|=        5.6594
At iterate    12  f =      -784.44  |proj g|=        5.6593
At iterate    13  f =      -784.44  |proj g|=        5.6401
At iterate    14  f =      -784.44  |proj g|=        5.6509
At iterate    15  f =      -784.44  |proj g|=        5.6444
At iterate    16  f =      -784.45  |proj g|=        5.6242
At iterate    17  f =       -784.5  |proj g|=        5.5484
At iterate    18  f =      -784.64  |proj g|=        5.4367
At iterate    19  f =      -785.31  |proj g|=        5.1783
At iterate    20  f =      -785.35  |proj g|=        5.3278
At iterate    21  f =      -787.23  |proj g|=         4.645
At iterate    22  f =      -788.43  |proj g|=        4.3981
At iterate    23  f =       -796.7  |proj g|=        4.4114
At iterate    24  f =      -813.18  |proj g|=        4.1342
At iterate    25  f =      -819.13  |proj g|=        2.8929
At iterate    26  f =      -823.17  |proj g|=         1.499
At iterate    27  f =      -823.27  |proj g|=        1.4778
At iterate    28  f =      -823.27  |proj g|=        1.4778
At iterate    29  f =      -823.27  |proj g|=        1.4778
At iterate    30  f =      -823.29  |proj g|=        1.4771
At iterate    31  f =      -823.29  |proj g|=        1.4771
At iterate    32  f =      -823.29  |proj g|=        1.4771
At iterate    33  f =      -823.35  |proj g|=        1.4729
At iterate    34  f =      -823.35  |proj g|=         1.471
At iterate    35  f =      -823.35  |proj g|=         1.471
At iterate    36  f =      -823.36  |proj g|=        1.4701
At iterate    37  f =      -823.37  |proj g|=        1.4656
At iterate    38  f =       -823.4  |proj g|=        1.4524
At iterate    39  f =      -823.41  |proj g|=        1.4438
At iterate    40  f =      -823.48  |proj g|=        1.4091
At iterate    41  f =      -828.07  |proj g|=       0.99799
At iterate    42  f =      -828.15  |proj g|=        1.2739
At iterate    43  f =      -828.15  |proj g|=        1.2395
At iterate    44  f =      -828.15  |proj g|=        1.2445
At iterate    45  f =      -828.15  |proj g|=        1.2446
At iterate    46  f =      -828.15  |proj g|=        1.2464
At iterate    47  f =      -828.15  |proj g|=        1.2479
At iterate    48  f =      -828.15  |proj g|=        1.2542
At iterate    49  f =      -828.15  |proj g|=        1.2564
At iterate    50  f =      -828.15  |proj g|=        1.2606
At iterate    51  f =      -828.17  |proj g|=        1.2748
At iterate    52  f =      -828.19  |proj g|=        1.2894
At iterate    53  f =      -828.26  |proj g|=        1.3138
At iterate    54  f =      -828.33  |proj g|=        1.0069
At iterate    55  f =      -828.57  |proj g|=        1.2099
At iterate    56  f =      -829.14  |proj g|=        1.7641
At iterate    57  f =      -830.03  |proj g|=        1.5111
At iterate    58  f =      -831.52  |proj g|=       0.74219
At iterate    59  f =       -831.6  |proj g|=       0.71849
At iterate    60  f =      -831.77  |proj g|=       0.26178
At iterate    61  f =      -831.78  |proj g|=       0.34167
At iterate    62  f =      -831.78  |proj g|=       0.13712
At iterate    63  f =      -831.78  |proj g|=     0.0032242
At iterate    64  f =      -831.78  |proj g|=     0.0021026

iterations 64
function evaluations 83
segments explored during Cauchy searches 66
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00210259
final function value -831.776

F = -831.776
final  value -831.775580 
converged
 
INFO  [00:32:47.229] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:32:47.285] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:32:47.292] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:32:57.685] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:33:06.360] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:33:16.745] [mlr3]  Finished benchmark 
INFO  [00:33:16.845] [bbotk] Result of batch 151: 
INFO  [00:33:16.847] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:33:16.847] [bbotk]              9.435951                 4.528798                       0.2831148 
INFO  [00:33:16.847] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:33:16.847] [bbotk]                     3338        1.053 -0.9476761         <NA>   0.9753613 
INFO  [00:33:16.847] [bbotk]                                 uhash 
INFO  [00:33:16.847] [bbotk]  0d0c365e-ace8-4d3e-81a0-dd4aaf1898fa 
DEBUG [00:33:18.339] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.033942e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.033942e-05 0.00130575 
  - best initial criterion value(s) :  725.7279 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -725.73  |proj g|=       7.9092
At iterate     1  f =      -736.94  |proj g|=        10.161
At iterate     2  f =      -741.18  |proj g|=        8.1805
At iterate     3  f =      -744.15  |proj g|=         5.595
At iterate     4  f =      -750.54  |proj g|=        3.5673
At iterate     5  f =      -751.08  |proj g|=        3.8701
At iterate     6  f =      -753.06  |proj g|=        3.7899
At iterate     7  f =      -753.07  |proj g|=        3.7664
At iterate     8  f =      -753.07  |proj g|=        3.7683
At iterate     9  f =      -753.07  |proj g|=        3.7682
At iterate    10  f =      -753.07  |proj g|=         3.768
At iterate    11  f =      -753.07  |proj g|=        3.7678
At iterate    12  f =      -753.07  |proj g|=        3.7674
At iterate    13  f =      -753.07  |proj g|=        3.7669
At iterate    14  f =      -753.07  |proj g|=         3.766
At iterate    15  f =      -753.07  |proj g|=        3.7649
At iterate    16  f =      -753.08  |proj g|=        3.7634
At iterate    17  f =      -753.08  |proj g|=        3.7616
At iterate    18  f =      -753.08  |proj g|=        3.7498
At iterate    19  f =       -753.1  |proj g|=        3.7513
At iterate    20  f =      -753.18  |proj g|=        3.7552
At iterate    21  f =      -753.34  |proj g|=        3.7544
At iterate    22  f =      -753.71  |proj g|=         3.741
At iterate    23  f =      -754.34  |proj g|=         3.699
At iterate    24  f =      -754.37  |proj g|=        3.7432
At iterate    25  f =      -755.06  |proj g|=        3.6433
At iterate    26  f =      -755.48  |proj g|=        3.5633
At iterate    27  f =      -755.62  |proj g|=        3.5363
At iterate    28  f =      -755.63  |proj g|=        3.5342
At iterate    29  f =      -755.63  |proj g|=        3.5311
At iterate    30  f =      -755.63  |proj g|=         3.531
At iterate    31  f =      -755.63  |proj g|=        3.5314

iterations 31
function evaluations 38
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.53138
final function value -755.625

F = -755.625
final  value -755.625374 
converged
 
INFO  [00:33:18.343] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:33:18.398] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:33:18.405] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:33:31.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:33:45.315] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:33:59.993] [mlr3]  Finished benchmark 
INFO  [00:34:00.062] [bbotk] Result of batch 152: 
INFO  [00:34:00.064] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:34:00.064] [bbotk]               7.19351                 9.103273                       0.3501757 
INFO  [00:34:00.064] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:34:00.064] [bbotk]                     4614        0.882 -0.9626242         <NA>   0.9764519 
INFO  [00:34:00.064] [bbotk]                                 uhash 
INFO  [00:34:00.064] [bbotk]  117b7c03-a803-49ea-925e-c2fcf91fb3aa 
DEBUG [00:34:01.584] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.031709e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.031709e-05 0.001305284 
  - best initial criterion value(s) :  751.4041 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -751.4  |proj g|=        13.33
At iterate     1  f =      -809.34  |proj g|=        11.264
At iterate     2  f =      -812.14  |proj g|=         11.25
At iterate     3  f =      -813.28  |proj g|=        9.7629
At iterate     4  f =      -813.54  |proj g|=        8.7957
At iterate     5  f =      -813.56  |proj g|=        8.6481
At iterate     6  f =      -813.58  |proj g|=        8.5907
At iterate     7  f =      -813.58  |proj g|=        8.6168
At iterate     8  f =      -813.58  |proj g|=        8.6362
At iterate     9  f =      -813.58  |proj g|=         8.647
At iterate    10  f =      -813.59  |proj g|=        8.6708
At iterate    11  f =      -813.59  |proj g|=        8.6976
At iterate    12  f =       -813.6  |proj g|=        8.7261
At iterate    13  f =      -813.63  |proj g|=        8.7301
At iterate    14  f =      -813.69  |proj g|=        8.6394
At iterate    15  f =      -813.83  |proj g|=        8.2971
At iterate    16  f =      -814.09  |proj g|=        7.2458
At iterate    17  f =       -814.1  |proj g|=        7.1269
At iterate    18  f =       -814.1  |proj g|=        7.0922
At iterate    19  f =      -814.14  |proj g|=         6.843
At iterate    20  f =      -814.21  |proj g|=         6.555
At iterate    21  f =       -814.4  |proj g|=        6.0519
At iterate    22  f =      -814.86  |proj g|=        5.2968
At iterate    23  f =      -816.01  |proj g|=        4.1805
At iterate    24  f =      -816.23  |proj g|=         3.714
At iterate    25  f =      -818.73  |proj g|=        2.3986
At iterate    26  f =      -828.78  |proj g|=        1.5056
At iterate    27  f =      -831.93  |proj g|=       0.89048
At iterate    28  f =      -832.35  |proj g|=       0.76028
At iterate    29  f =      -832.43  |proj g|=       0.57087
At iterate    30  f =      -832.46  |proj g|=       0.57728
At iterate    31  f =      -832.46  |proj g|=       0.58264
At iterate    32  f =      -832.46  |proj g|=       0.58251
At iterate    33  f =      -832.46  |proj g|=       0.58255

iterations 33
function evaluations 40
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.582553
final function value -832.461

F = -832.461
final  value -832.461039 
converged
 
INFO  [00:34:01.588] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:34:01.644] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:34:01.651] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:34:02.840] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:34:03.916] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:34:05.311] [mlr3]  Finished benchmark 
INFO  [00:34:05.396] [bbotk] Result of batch 153: 
INFO  [00:34:05.399] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:34:05.399] [bbotk]              9.874783                 9.206334                      0.09111891 
INFO  [00:34:05.399] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:34:05.399] [bbotk]                      314        0.876 -0.9528264         <NA>   0.9429117 
INFO  [00:34:05.399] [bbotk]                                 uhash 
INFO  [00:34:05.399] [bbotk]  dcd928a7-1748-4692-88ca-38464ba9782a 
DEBUG [00:34:06.858] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.061799e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.061799e-05 0.001355265 
  - best initial criterion value(s) :  796.1977 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -796.2  |proj g|=       3.7141
At iterate     1  f =      -828.87  |proj g|=        1.8409
At iterate     2  f =      -829.62  |proj g|=        3.4897
At iterate     3  f =      -832.93  |proj g|=        2.6388
At iterate     4  f =      -836.72  |proj g|=        1.0335
At iterate     5  f =      -837.56  |proj g|=          1.09
At iterate     6  f =      -837.65  |proj g|=        1.0707
At iterate     7  f =      -837.66  |proj g|=        1.0748
At iterate     8  f =      -837.66  |proj g|=         1.075
At iterate     9  f =      -837.66  |proj g|=        1.0748
At iterate    10  f =      -837.66  |proj g|=        1.0748

iterations 10
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.07483
final function value -837.664

F = -837.664
final  value -837.663955 
converged
 
INFO  [00:34:06.862] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:34:06.917] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:34:06.923] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:34:16.396] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:34:27.628] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:34:37.874] [mlr3]  Finished benchmark 
INFO  [00:34:37.970] [bbotk] Result of batch 154: 
INFO  [00:34:37.971] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:34:37.971] [bbotk]               8.43956                 3.744912                       0.1310406 
INFO  [00:34:37.971] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:34:37.971] [bbotk]                     3626        1.051 -0.9502107         <NA>   0.9730062 
INFO  [00:34:37.971] [bbotk]                                 uhash 
INFO  [00:34:37.971] [bbotk]  b78c10ce-77bc-408d-9487-3b03579ae3f8 
DEBUG [00:34:39.595] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.057169e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.057169e-05 0.001351819 
  - best initial criterion value(s) :  785.6528 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -785.65  |proj g|=       7.1644
At iterate     1  f =       -786.3  |proj g|=        7.6004
At iterate     2  f =      -791.64  |proj g|=        5.3533
At iterate     3  f =       -796.9  |proj g|=        3.6018
At iterate     4  f =       -797.1  |proj g|=        3.7392
At iterate     5  f =      -797.15  |proj g|=        3.7131
At iterate     6  f =      -797.15  |proj g|=        3.7061
At iterate     7  f =      -797.15  |proj g|=        3.7069
At iterate     8  f =      -797.15  |proj g|=        3.7073
At iterate     9  f =      -797.15  |proj g|=        3.7088
At iterate    10  f =      -797.15  |proj g|=        3.7108
At iterate    11  f =      -797.15  |proj g|=        3.7136
At iterate    12  f =      -797.16  |proj g|=        3.7182
At iterate    13  f =      -797.17  |proj g|=        3.7261
At iterate    14  f =      -797.19  |proj g|=        3.7391
At iterate    15  f =      -797.24  |proj g|=        3.7607
At iterate    16  f =      -797.35  |proj g|=        3.7914
At iterate    17  f =      -797.52  |proj g|=        3.8144
At iterate    18  f =      -797.58  |proj g|=        3.7864
At iterate    19  f =       -797.6  |proj g|=        3.7975
At iterate    20  f =      -798.95  |proj g|=        3.7487
At iterate    21  f =      -802.73  |proj g|=        3.4124
At iterate    22  f =       -804.2  |proj g|=        3.1674
At iterate    23  f =       -804.8  |proj g|=        2.9185
At iterate    24  f =      -804.86  |proj g|=        2.9469
At iterate    25  f =      -804.97  |proj g|=        2.6659
At iterate    26  f =      -804.99  |proj g|=        2.5656
At iterate    27  f =      -804.99  |proj g|=          2.53
At iterate    28  f =      -804.99  |proj g|=        2.5173
At iterate    29  f =      -804.99  |proj g|=        2.5195
At iterate    30  f =      -804.99  |proj g|=        2.5186
At iterate    31  f =      -804.99  |proj g|=        2.5236
At iterate    32  f =      -804.99  |proj g|=        2.5248

iterations 32
function evaluations 41
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.5248
final function value -804.991

F = -804.991
final  value -804.991243 
converged
 
INFO  [00:34:39.599] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:34:39.653] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:34:39.660] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:34:50.613] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:34:59.318] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:35:07.513] [mlr3]  Finished benchmark 
INFO  [00:35:07.583] [bbotk] Result of batch 155: 
INFO  [00:35:07.585] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:35:07.585] [bbotk]              5.647395                 4.585264                       0.0101815 
INFO  [00:35:07.585] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:35:07.585] [bbotk]                     3091        0.943 -0.9565188         <NA>   0.9439192 
INFO  [00:35:07.585] [bbotk]                                 uhash 
INFO  [00:35:07.585] [bbotk]  408e33ab-0662-4f0b-86cb-53fb680139fb 
DEBUG [00:35:09.116] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.083772e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.083772e-05 0.001364938 
  - best initial criterion value(s) :  752.5835 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -752.58  |proj g|=       12.262
At iterate     1  f =      -776.85  |proj g|=        10.405
At iterate     2  f =      -788.99  |proj g|=        9.4816
At iterate     3  f =      -805.78  |proj g|=        7.6011
At iterate     4  f =      -810.19  |proj g|=        6.2888
At iterate     5  f =      -812.26  |proj g|=        5.1511
At iterate     6  f =      -812.96  |proj g|=        5.4484
At iterate     7  f =      -812.97  |proj g|=         5.407
At iterate     8  f =      -812.97  |proj g|=        5.4094
At iterate     9  f =      -812.97  |proj g|=          5.41
At iterate    10  f =      -812.97  |proj g|=        5.4131
At iterate    11  f =      -812.97  |proj g|=        5.4169
At iterate    12  f =      -812.97  |proj g|=        5.4219
At iterate    13  f =      -812.98  |proj g|=        5.4268
At iterate    14  f =      -813.01  |proj g|=        5.4265
At iterate    15  f =      -813.07  |proj g|=        5.4044
At iterate    16  f =      -813.22  |proj g|=        5.3209
At iterate    17  f =      -813.47  |proj g|=        5.1225
At iterate    18  f =      -813.63  |proj g|=        4.9714
At iterate    19  f =      -813.69  |proj g|=        4.8456
At iterate    20  f =      -815.88  |proj g|=         4.539
At iterate    21  f =      -835.36  |proj g|=        3.6794
At iterate    22  f =      -841.98  |proj g|=        3.8205
At iterate    23  f =      -846.27  |proj g|=        3.2375
At iterate    24  f =      -850.76  |proj g|=        1.7398
At iterate    25  f =      -852.08  |proj g|=        1.4409
At iterate    26  f =      -852.28  |proj g|=       0.87137
At iterate    27  f =      -852.44  |proj g|=        0.8367
At iterate    28  f =      -852.45  |proj g|=       0.80066
At iterate    29  f =      -852.45  |proj g|=       0.79077
At iterate    30  f =      -852.45  |proj g|=       0.78889
At iterate    31  f =      -852.45  |proj g|=       0.78873

iterations 31
function evaluations 38
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.78873
final function value -852.451

F = -852.451
final  value -852.451210 
converged
 
INFO  [00:35:09.120] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:35:09.177] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:35:09.184] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:35:16.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:35:22.682] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:35:30.623] [mlr3]  Finished benchmark 
INFO  [00:35:30.693] [bbotk] Result of batch 156: 
INFO  [00:35:30.695] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:35:30.695] [bbotk]              5.384744                 9.416008                      0.05299793 
INFO  [00:35:30.695] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [00:35:30.695] [bbotk]                     2497        0.883 -0.945714         <NA>   0.9631124 
INFO  [00:35:30.695] [bbotk]                                 uhash 
INFO  [00:35:30.695] [bbotk]  d7fef2f0-6a36-4eee-89e7-0b73a3f70000 
DEBUG [00:35:32.430] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.079387e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.079387e-05 0.00135968 
  - best initial criterion value(s) :  748.8935 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -748.89  |proj g|=       13.772
At iterate     1  f =      -808.63  |proj g|=        12.371
At iterate     2  f =       -831.3  |proj g|=        11.352
At iterate     3  f =      -833.39  |proj g|=        10.099
At iterate     4  f =      -834.73  |proj g|=         8.262
At iterate     5  f =      -835.13  |proj g|=        7.7736
At iterate     6  f =      -835.68  |proj g|=        7.4163
At iterate     7  f =      -836.18  |proj g|=        7.8629
At iterate     8  f =      -836.29  |proj g|=        7.7965
At iterate     9  f =      -836.31  |proj g|=        7.7302
At iterate    10  f =      -836.31  |proj g|=        7.7365
At iterate    11  f =      -836.31  |proj g|=        7.7165
At iterate    12  f =      -836.33  |proj g|=        7.6394
At iterate    13  f =      -836.42  |proj g|=        7.1307
At iterate    14  f =      -836.75  |proj g|=         6.758
At iterate    15  f =      -837.79  |proj g|=        5.9804
At iterate    16  f =      -840.94  |proj g|=        4.5992
At iterate    17  f =      -846.57  |proj g|=        2.9654
At iterate    18  f =      -851.68  |proj g|=         1.701
At iterate    19  f =      -852.56  |proj g|=       0.51208
At iterate    20  f =      -854.75  |proj g|=       0.39599
At iterate    21  f =      -855.52  |proj g|=       0.66126
At iterate    22  f =      -855.86  |proj g|=        1.0725
At iterate    23  f =       -856.1  |proj g|=       0.71667
At iterate    24  f =      -856.12  |proj g|=       0.58783
At iterate    25  f =      -856.12  |proj g|=       0.57777
At iterate    26  f =      -856.12  |proj g|=       0.57797
At iterate    27  f =      -856.12  |proj g|=       0.57871
At iterate    28  f =      -856.12  |proj g|=        0.5788

iterations 28
function evaluations 38
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.578803
final function value -856.119

F = -856.119
final  value -856.118800 
converged
 
INFO  [00:35:32.434] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:35:32.490] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:35:32.497] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:35:35.498] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:35:38.660] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:35:41.952] [mlr3]  Finished benchmark 
INFO  [00:35:42.023] [bbotk] Result of batch 157: 
INFO  [00:35:42.025] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:35:42.025] [bbotk]              9.936099                 6.789655                       0.1161921 
INFO  [00:35:42.025] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:35:42.025] [bbotk]                     1078        1.068 -0.9471306         <NA>    0.964488 
INFO  [00:35:42.025] [bbotk]                                 uhash 
INFO  [00:35:42.025] [bbotk]  2db8c5b9-ac46-445f-9a7e-f261f6b25260 
DEBUG [00:35:43.301] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.074379e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.074379e-05 0.001350696 
  - best initial criterion value(s) :  790.9567 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -790.96  |proj g|=       9.1055
At iterate     1  f =      -832.38  |proj g|=        2.1999
At iterate     2  f =       -847.4  |proj g|=        4.0198
At iterate     3  f =      -850.07  |proj g|=        3.9315
At iterate     4  f =      -850.48  |proj g|=          3.94
At iterate     5  f =      -851.08  |proj g|=        3.7329
At iterate     6  f =      -851.24  |proj g|=        3.9157
At iterate     7  f =      -851.26  |proj g|=        3.8874
At iterate     8  f =      -851.26  |proj g|=        3.8818
At iterate     9  f =      -851.26  |proj g|=        3.8821

iterations 9
function evaluations 11
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.88206
final function value -851.258

F = -851.258
final  value -851.257828 
converged
 
INFO  [00:35:43.305] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:35:43.360] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:35:43.367] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:35:59.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:36:13.519] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:36:28.647] [mlr3]  Finished benchmark 
INFO  [00:36:28.732] [bbotk] Result of batch 158: 
INFO  [00:36:28.734] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:36:28.734] [bbotk]              6.332201                 7.902009                      0.09403952 
INFO  [00:36:28.734] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:36:28.734] [bbotk]                     4837        0.898 -0.9452503         <NA>   0.9724407 
INFO  [00:36:28.734] [bbotk]                                 uhash 
INFO  [00:36:28.734] [bbotk]  1d005736-01cb-4953-81a3-b2dda868e930 
DEBUG [00:36:30.004] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.06959e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.06959e-05 0.00134501 
  - best initial criterion value(s) :  841.5792 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -841.58  |proj g|=       2.3762
At iterate     1  f =      -848.93  |proj g|=        2.1699
At iterate     2  f =      -849.31  |proj g|=        2.1534
At iterate     3  f =      -849.36  |proj g|=        2.1645
At iterate     4  f =      -849.37  |proj g|=        2.1719
At iterate     5  f =      -849.37  |proj g|=        2.1728
At iterate     6  f =      -849.37  |proj g|=        2.1728

iterations 6
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.17275
final function value -849.367

F = -849.367
final  value -849.367412 
converged
 
INFO  [00:36:30.008] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:36:30.064] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:36:30.071] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:36:41.269] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:36:54.074] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:37:05.661] [mlr3]  Finished benchmark 
INFO  [00:37:05.732] [bbotk] Result of batch 159: 
INFO  [00:37:05.733] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:37:05.733] [bbotk]              4.448932                 8.664527                       0.1111573 
INFO  [00:37:05.733] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:37:05.733] [bbotk]                     4198        0.897 -0.9547108         <NA>   0.9711012 
INFO  [00:37:05.733] [bbotk]                                 uhash 
INFO  [00:37:05.733] [bbotk]  04903b4a-6b37-4b8b-96c9-ec9fc6952a5e 
DEBUG [00:37:07.845] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.06435e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.06435e-05 0.001340064 
  - best initial criterion value(s) :  760.2778 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -760.28  |proj g|=       8.9085
At iterate     1  f =      -802.99  |proj g|=        11.113
At iterate     2  f =      -807.78  |proj g|=        10.812
At iterate     3  f =      -808.77  |proj g|=        10.502
At iterate     4  f =      -809.53  |proj g|=        9.4069
At iterate     5  f =      -809.56  |proj g|=        9.2053
At iterate     6  f =      -809.57  |proj g|=         9.227
At iterate     7  f =      -809.57  |proj g|=         9.231
At iterate     8  f =      -809.57  |proj g|=        9.2277
At iterate     9  f =      -809.57  |proj g|=        9.2195
At iterate    10  f =      -809.57  |proj g|=        9.2055
At iterate    11  f =      -809.57  |proj g|=        9.1864
At iterate    12  f =      -809.58  |proj g|=        9.1526
At iterate    13  f =      -809.59  |proj g|=        9.0936
At iterate    14  f =      -809.61  |proj g|=        8.9867
At iterate    15  f =      -809.68  |proj g|=        8.9171
At iterate    16  f =      -809.82  |proj g|=        9.1782
At iterate    17  f =      -809.97  |proj g|=        9.7148
At iterate    18  f =      -810.05  |proj g|=        10.026
At iterate    19  f =      -810.14  |proj g|=        10.381
At iterate    20  f =      -810.21  |proj g|=        10.617
At iterate    21  f =      -810.38  |proj g|=        10.842
At iterate    22  f =      -810.75  |proj g|=        10.914
At iterate    23  f =       -811.5  |proj g|=        11.065
At iterate    24  f =      -812.75  |proj g|=        11.318
At iterate    25  f =      -814.29  |proj g|=        11.706
At iterate    26  f =      -815.14  |proj g|=        11.691
At iterate    27  f =      -815.94  |proj g|=        11.512
At iterate    28  f =      -816.05  |proj g|=        11.437
At iterate    29  f =      -816.12  |proj g|=        11.489
At iterate    30  f =      -816.18  |proj g|=        11.516
At iterate    31  f =      -816.18  |proj g|=        11.507
At iterate    32  f =      -816.18  |proj g|=        11.503
At iterate    33  f =      -816.18  |proj g|=        11.503
At iterate    34  f =      -816.18  |proj g|=        11.504
At iterate    35  f =      -816.18  |proj g|=        11.505
At iterate    36  f =      -816.18  |proj g|=        11.506
At iterate    37  f =      -816.18  |proj g|=        11.506
At iterate    38  f =      -816.18  |proj g|=        11.506
At iterate    39  f =      -816.18  |proj g|=        11.507
At iterate    40  f =      -816.18  |proj g|=        11.504
At iterate    41  f =      -816.18  |proj g|=        11.503
At iterate    42  f =      -816.18  |proj g|=        11.498
At iterate    43  f =      -816.18  |proj g|=         11.49
At iterate    44  f =      -816.18  |proj g|=        11.486
At iterate    45  f =      -816.19  |proj g|=        11.476
At iterate    46  f =       -816.2  |proj g|=        11.446
At iterate    47  f =      -816.22  |proj g|=        11.416
At iterate    48  f =      -816.24  |proj g|=        11.393
At iterate    49  f =      -816.28  |proj g|=        11.364
At iterate    50  f =      -816.35  |proj g|=        11.262
At iterate    51  f =       -816.5  |proj g|=        11.107
At iterate    52  f =      -817.36  |proj g|=        11.325
At iterate    53  f =      -821.01  |proj g|=        11.255
At iterate    54  f =      -837.42  |proj g|=         2.714
At iterate    55  f =      -853.15  |proj g|=        3.0527
At iterate    56  f =      -870.47  |proj g|=        3.7744
At iterate    57  f =         -875  |proj g|=        2.2698
At iterate    58  f =      -877.68  |proj g|=       0.76186
At iterate    59  f =       -877.9  |proj g|=       0.33481
At iterate    60  f =      -878.18  |proj g|=       0.32093
At iterate    61  f =      -878.24  |proj g|=      0.092006
At iterate    62  f =      -878.24  |proj g|=       0.20947
At iterate    63  f =      -878.24  |proj g|=       0.34417
At iterate    64  f =      -878.24  |proj g|=      0.039628
At iterate    65  f =      -878.24  |proj g|=     0.0015853

iterations 65
function evaluations 74
segments explored during Cauchy searches 67
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00158532
final function value -878.244

F = -878.244
final  value -878.243954 
converged
 
INFO  [00:37:07.849] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:37:07.906] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:37:07.913] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:37:19.850] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:37:32.241] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:37:44.397] [mlr3]  Finished benchmark 
INFO  [00:37:44.466] [bbotk] Result of batch 160: 
INFO  [00:37:44.468] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:37:44.468] [bbotk]              8.321442                 3.077161                       0.1497246 
INFO  [00:37:44.468] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:37:44.468] [bbotk]                     4350        0.883 -0.9376816         <NA>    0.974153 
INFO  [00:37:44.468] [bbotk]                                 uhash 
INFO  [00:37:44.468] [bbotk]  86d1fb87-40b0-4633-99a7-ee911a3b1159 
DEBUG [00:37:45.954] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.060546e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9506 
  - variance bounds :  1.060546e-05 0.00133694 
  - best initial criterion value(s) :  789.3813 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -789.38  |proj g|=        6.266
At iterate     1  f =      -852.61  |proj g|=        10.981
At iterate     2  f =      -859.28  |proj g|=        10.719
At iterate     3  f =      -865.41  |proj g|=          6.31
At iterate     4  f =      -866.54  |proj g|=         8.016
At iterate     5  f =      -867.97  |proj g|=        7.3051
At iterate     6  f =       -869.8  |proj g|=        5.5965
At iterate     7  f =      -869.98  |proj g|=        6.2287
At iterate     8  f =      -870.34  |proj g|=        5.3372
At iterate     9  f =      -870.39  |proj g|=        5.0454
At iterate    10  f =       -870.4  |proj g|=        5.0159
At iterate    11  f =      -870.42  |proj g|=        5.0053
At iterate    12  f =      -870.43  |proj g|=        5.0057
At iterate    13  f =      -870.47  |proj g|=        4.9319
At iterate    14  f =      -870.58  |proj g|=        4.7517
At iterate    15  f =       -870.7  |proj g|=        5.0636
At iterate    16  f =      -871.02  |proj g|=         4.506
At iterate    17  f =      -871.33  |proj g|=        4.1337
At iterate    18  f =      -872.27  |proj g|=        3.5874
At iterate    19  f =      -874.52  |proj g|=        1.3622
At iterate    20  f =      -878.28  |proj g|=        2.1071
At iterate    21  f =      -881.58  |proj g|=        1.5995
At iterate    22  f =      -881.68  |proj g|=        2.0946
At iterate    23  f =      -881.69  |proj g|=        1.9591
At iterate    24  f =      -881.69  |proj g|=        1.9502
At iterate    25  f =      -881.69  |proj g|=        1.9506

iterations 25
function evaluations 30
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.95064
final function value -881.694

F = -881.694
final  value -881.694406 
converged
 
INFO  [00:37:45.958] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:37:46.015] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:37:46.022] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:37:46.970] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:37:47.952] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:37:49.043] [mlr3]  Finished benchmark 
INFO  [00:37:49.113] [bbotk] Result of batch 161: 
INFO  [00:37:49.115] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:37:49.115] [bbotk]              9.304016                 3.629654                       0.2609484 
INFO  [00:37:49.115] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:37:49.115] [bbotk]                      206          0.9 -0.9466454         <NA>   0.9536399 
INFO  [00:37:49.115] [bbotk]                                 uhash 
INFO  [00:37:49.115] [bbotk]  516396db-e5f0-43d3-881b-400cfc5b3244 
DEBUG [00:37:50.810] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.066224e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.066224e-05 0.001345396 
  - best initial criterion value(s) :  798.8997 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -798.9  |proj g|=        3.497
At iterate     1  f =      -834.19  |proj g|=        9.9783
At iterate     2  f =      -835.77  |proj g|=        8.8746
At iterate     3  f =      -839.78  |proj g|=        7.9484
At iterate     4  f =      -846.71  |proj g|=        6.0538
At iterate     5  f =      -850.65  |proj g|=         5.056
At iterate     6  f =      -851.09  |proj g|=        5.7413
At iterate     7  f =       -851.1  |proj g|=        5.5398
At iterate     8  f =      -851.11  |proj g|=        5.5963
At iterate     9  f =      -851.11  |proj g|=        5.5748
At iterate    10  f =      -851.11  |proj g|=        5.5411
At iterate    11  f =      -851.12  |proj g|=        5.4698
At iterate    12  f =      -851.15  |proj g|=        5.3735
At iterate    13  f =      -851.23  |proj g|=        5.2092
At iterate    14  f =      -851.43  |proj g|=         4.988
At iterate    15  f =      -851.95  |proj g|=        4.7545
At iterate    16  f =      -853.22  |proj g|=         4.597
At iterate    17  f =      -856.24  |proj g|=        5.3921
At iterate    18  f =      -858.45  |proj g|=        5.2518
At iterate    19  f =       -862.3  |proj g|=        7.3279
At iterate    20  f =      -862.93  |proj g|=        7.8756
At iterate    21  f =      -863.14  |proj g|=        8.3094
At iterate    22  f =      -863.15  |proj g|=        8.4452
At iterate    23  f =      -863.15  |proj g|=        8.4775
At iterate    24  f =      -863.15  |proj g|=        8.4834
At iterate    25  f =      -863.15  |proj g|=         8.484
At iterate    26  f =      -863.15  |proj g|=        8.4836

iterations 26
function evaluations 35
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 8.48361
final function value -863.153

F = -863.153
final  value -863.153293 
converged
 
INFO  [00:37:50.815] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:37:50.886] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:37:50.893] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:38:04.386] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:38:18.494] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:38:31.816] [mlr3]  Finished benchmark 
INFO  [00:38:31.884] [bbotk] Result of batch 162: 
INFO  [00:38:31.886] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:38:31.886] [bbotk]              2.827625                 8.318904                      0.04232385 
INFO  [00:38:31.886] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:38:31.886] [bbotk]                     4731        0.999 -0.9553548         <NA>   0.9551943 
INFO  [00:38:31.886] [bbotk]                                 uhash 
INFO  [00:38:31.886] [bbotk]  2c83a82c-0648-46a9-97fe-a0bb4f68b8ce 
DEBUG [00:38:33.577] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.0695e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.0695e-05 0.00134575 
  - best initial criterion value(s) :  817.1852 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -817.19  |proj g|=       8.5595
At iterate     1  f =      -845.17  |proj g|=        8.1498
At iterate     2  f =      -856.62  |proj g|=        6.4492
At iterate     3  f =      -870.48  |proj g|=        3.4622
At iterate     4  f =      -871.11  |proj g|=        3.5065
At iterate     5  f =      -872.15  |proj g|=         3.538
At iterate     6  f =      -874.27  |proj g|=        3.6833
At iterate     7  f =      -874.86  |proj g|=        3.7863
At iterate     8  f =      -874.91  |proj g|=        3.8275
At iterate     9  f =      -874.98  |proj g|=         3.845
At iterate    10  f =      -874.99  |proj g|=        3.8486
At iterate    11  f =      -874.99  |proj g|=        3.8491
At iterate    12  f =      -874.99  |proj g|=        3.8492
At iterate    13  f =      -874.99  |proj g|=        3.8501
At iterate    14  f =      -874.99  |proj g|=        3.8512
At iterate    15  f =      -874.99  |proj g|=        3.8533
At iterate    16  f =      -874.99  |proj g|=        3.8565
At iterate    17  f =      -874.99  |proj g|=        3.8593
At iterate    18  f =      -874.99  |proj g|=        3.8635
At iterate    19  f =      -875.04  |proj g|=        3.8712
At iterate    20  f =      -875.12  |proj g|=        3.8721
At iterate    21  f =      -875.34  |proj g|=        3.8331
At iterate    22  f =      -875.42  |proj g|=        3.7832
At iterate    23  f =      -875.44  |proj g|=         3.758
At iterate    24  f =      -875.44  |proj g|=        3.7524
At iterate    25  f =      -875.44  |proj g|=        3.7548
At iterate    26  f =      -875.44  |proj g|=        3.7548
At iterate    27  f =      -875.44  |proj g|=        3.7547

iterations 27
function evaluations 30
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.75473
final function value -875.441

F = -875.441
final  value -875.441432 
converged
 
INFO  [00:38:33.581] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:38:33.636] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:38:33.643] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:38:42.448] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:38:50.264] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:38:56.728] [mlr3]  Finished benchmark 
INFO  [00:38:56.796] [bbotk] Result of batch 163: 
INFO  [00:38:56.798] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:38:56.798] [bbotk]              7.581947                 3.275276                       0.4798709 
INFO  [00:38:56.798] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:38:56.798] [bbotk]                     3264        0.897 -0.9492789         <NA>   0.9764295 
INFO  [00:38:56.798] [bbotk]                                 uhash 
INFO  [00:38:56.798] [bbotk]  3ac129cc-d9d4-45b7-8eeb-6a474c3d3e7f 
DEBUG [00:38:58.349] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.067466e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.067466e-05 0.00134646 
  - best initial criterion value(s) :  785.7835 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -785.78  |proj g|=      0.85162
At iterate     1  f =      -842.12  |proj g|=        11.065
At iterate     2  f =      -843.82  |proj g|=        11.059
At iterate     3  f =      -846.18  |proj g|=        10.849
At iterate     4  f =      -847.07  |proj g|=        11.057
At iterate     5  f =      -847.45  |proj g|=         11.06
At iterate     6  f =      -848.33  |proj g|=        10.576
At iterate     7  f =      -848.87  |proj g|=        11.029
At iterate     8  f =      -849.15  |proj g|=        10.996
At iterate     9  f =      -849.15  |proj g|=        11.035
At iterate    10  f =      -849.15  |proj g|=        11.031
At iterate    11  f =      -849.15  |proj g|=        11.036
At iterate    12  f =      -849.15  |proj g|=        11.035
At iterate    13  f =      -849.94  |proj g|=        10.588
At iterate    14  f =      -853.17  |proj g|=         9.166
At iterate    15  f =      -862.65  |proj g|=        6.0942
At iterate    16  f =      -882.71  |proj g|=        1.8324
At iterate    17  f =      -883.02  |proj g|=        2.5239
At iterate    18  f =       -890.8  |proj g|=       0.97277
At iterate    19  f =      -893.33  |proj g|=        1.0322
At iterate    20  f =      -894.76  |proj g|=        1.2245
At iterate    21  f =      -894.95  |proj g|=        1.4012
At iterate    22  f =      -894.99  |proj g|=        1.5518
At iterate    23  f =         -895  |proj g|=        1.6942
At iterate    24  f =         -895  |proj g|=        1.6834
At iterate    25  f =         -895  |proj g|=        1.6837

iterations 25
function evaluations 33
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.68368
final function value -895.003

F = -895.003
final  value -895.003134 
converged
 
INFO  [00:38:58.353] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:38:58.411] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:38:58.418] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:39:02.347] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:39:06.697] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:39:10.964] [mlr3]  Finished benchmark 
INFO  [00:39:11.036] [bbotk] Result of batch 164: 
INFO  [00:39:11.038] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:39:11.038] [bbotk]              3.081202                 3.817841                       0.4041338 
INFO  [00:39:11.038] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:39:11.038] [bbotk]                     2101        0.913 -0.9452675         <NA>   0.9696449 
INFO  [00:39:11.038] [bbotk]                                 uhash 
INFO  [00:39:11.038] [bbotk]  028918e6-1439-4182-bfbc-2d9b75febd0c 
DEBUG [00:39:13.483] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.062068e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.062068e-05 0.00133759 
  - best initial criterion value(s) :  843.6118 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -843.61  |proj g|=       6.2315
At iterate     1  f =      -860.76  |proj g|=        6.5207
At iterate     2  f =      -867.94  |proj g|=        5.1808
At iterate     3  f =      -874.02  |proj g|=         2.777
At iterate     4  f =       -874.1  |proj g|=        1.8006
At iterate     5  f =      -874.24  |proj g|=         2.296
At iterate     6  f =      -874.33  |proj g|=        2.2805
At iterate     7  f =      -874.48  |proj g|=        2.4615
At iterate     8  f =      -874.49  |proj g|=        2.5696
At iterate     9  f =      -874.49  |proj g|=        2.5745
At iterate    10  f =      -874.49  |proj g|=        2.5713
At iterate    11  f =      -874.49  |proj g|=        2.5542
At iterate    12  f =      -874.49  |proj g|=        2.5306
At iterate    13  f =      -874.49  |proj g|=        2.4847
At iterate    14  f =       -874.5  |proj g|=        2.4092
At iterate    15  f =      -874.53  |proj g|=        2.2648
At iterate    16  f =       -874.6  |proj g|=        2.0018
At iterate    17  f =      -874.77  |proj g|=        1.5285
At iterate    18  f =      -875.11  |proj g|=        1.2547
At iterate    19  f =      -875.56  |proj g|=        1.3193
At iterate    20  f =      -875.58  |proj g|=        1.3248
At iterate    21  f =      -875.58  |proj g|=        1.3233
At iterate    22  f =      -875.58  |proj g|=        1.3224
At iterate    23  f =      -875.58  |proj g|=         1.321
At iterate    24  f =      -875.59  |proj g|=        1.3208
At iterate    25  f =      -875.59  |proj g|=        1.3237
At iterate    26  f =       -875.6  |proj g|=         1.342
At iterate    27  f =      -875.62  |proj g|=        1.3533
At iterate    28  f =      -875.62  |proj g|=        1.3679
At iterate    29  f =      -875.62  |proj g|=          1.37
At iterate    30  f =      -875.62  |proj g|=          1.37
At iterate    31  f =      -875.62  |proj g|=        1.3702
At iterate    32  f =      -875.62  |proj g|=        1.3709
At iterate    33  f =      -875.62  |proj g|=        1.3717
At iterate    34  f =      -875.62  |proj g|=        1.3736
At iterate    35  f =      -875.62  |proj g|=        1.3771
At iterate    36  f =      -875.63  |proj g|=        1.3808
At iterate    37  f =      -875.64  |proj g|=         1.387
At iterate    38  f =      -875.65  |proj g|=        1.3956
At iterate    39  f =      -875.66  |proj g|=        1.3917
At iterate    40  f =      -875.69  |proj g|=        1.3915
At iterate    41  f =      -875.76  |proj g|=        1.3368
At iterate    42  f =      -875.76  |proj g|=        1.3302
At iterate    43  f =      -875.76  |proj g|=        1.3254
At iterate    44  f =      -875.77  |proj g|=        1.3152
At iterate    45  f =      -875.78  |proj g|=        1.2969
At iterate    46  f =      -875.79  |proj g|=         1.293
At iterate    47  f =      -875.82  |proj g|=        1.2572
At iterate    48  f =      -875.87  |proj g|=        1.1664
At iterate    49  f =      -876.06  |proj g|=        1.0362
At iterate    50  f =      -876.59  |proj g|=        1.1079
At iterate    51  f =       -877.8  |proj g|=         1.674
At iterate    52  f =      -877.88  |proj g|=        1.1327
At iterate    53  f =      -878.68  |proj g|=       0.87006
At iterate    54  f =      -879.36  |proj g|=       0.76959
At iterate    55  f =      -879.42  |proj g|=       0.21997
At iterate    56  f =      -879.44  |proj g|=       0.22278
At iterate    57  f =      -879.44  |proj g|=       0.22317
At iterate    58  f =      -879.44  |proj g|=      0.088168
At iterate    59  f =      -879.44  |proj g|=      0.020467

iterations 59
function evaluations 72
segments explored during Cauchy searches 62
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0204673
final function value -879.437

F = -879.437
final  value -879.436934 
converged
 
INFO  [00:39:13.487] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:39:13.574] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:39:13.581] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:39:20.320] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:39:26.901] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:39:33.280] [mlr3]  Finished benchmark 
INFO  [00:39:33.348] [bbotk] Result of batch 165: 
INFO  [00:39:33.350] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:39:33.350] [bbotk]              3.358839                 8.576227                       0.1118234 
INFO  [00:39:33.350] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:39:33.350] [bbotk]                     3244        1.006 -0.9548722         <NA>   0.9662627 
INFO  [00:39:33.350] [bbotk]                                 uhash 
INFO  [00:39:33.350] [bbotk]  541f887d-19ea-44c1-b310-c6d223dd51b6 
DEBUG [00:39:35.128] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.056819e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.056819e-05 0.001332342 
  - best initial criterion value(s) :  833.8264 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -833.83  |proj g|=       1.4992
At iterate     1  f =      -871.43  |proj g|=        5.7741
At iterate     2  f =      -881.09  |proj g|=        10.073
At iterate     3  f =      -881.53  |proj g|=         10.07
At iterate     4  f =      -881.93  |proj g|=        9.4737
At iterate     5  f =      -882.16  |proj g|=        9.2852
At iterate     6  f =      -882.41  |proj g|=        9.2278
At iterate     7  f =      -882.42  |proj g|=        9.3151
At iterate     8  f =      -882.42  |proj g|=         9.288
At iterate     9  f =      -882.42  |proj g|=         9.289
At iterate    10  f =      -882.42  |proj g|=        9.2903
At iterate    11  f =      -882.42  |proj g|=        9.2925
At iterate    12  f =      -882.42  |proj g|=        9.2976
At iterate    13  f =      -882.42  |proj g|=        9.3046
At iterate    14  f =      -882.42  |proj g|=        9.3158
At iterate    15  f =      -882.42  |proj g|=        9.3261
At iterate    16  f =      -882.43  |proj g|=        9.3305
At iterate    17  f =      -882.46  |proj g|=        9.3308
At iterate    18  f =      -882.52  |proj g|=         9.252
At iterate    19  f =      -882.52  |proj g|=        9.4008
At iterate    20  f =      -882.66  |proj g|=        9.2224
At iterate    21  f =      -883.59  |proj g|=        8.6556
At iterate    22  f =      -889.38  |proj g|=          6.13
At iterate    23  f =      -900.43  |proj g|=        3.9361
At iterate    24  f =      -900.82  |proj g|=        3.7174
At iterate    25  f =      -900.95  |proj g|=        4.2161
At iterate    26  f =      -900.99  |proj g|=        4.1729
At iterate    27  f =      -900.99  |proj g|=        4.1537
At iterate    28  f =      -900.99  |proj g|=        4.1539
At iterate    29  f =      -900.99  |proj g|=        4.1533
At iterate    30  f =         -901  |proj g|=        4.1515
At iterate    31  f =         -901  |proj g|=        4.2084
At iterate    32  f =      -901.01  |proj g|=        4.1152
At iterate    33  f =      -901.33  |proj g|=        4.2506
At iterate    34  f =       -902.8  |proj g|=        3.9445
At iterate    35  f =      -905.43  |proj g|=        2.6293
At iterate    36  f =      -905.65  |proj g|=         2.638
At iterate    37  f =      -907.11  |proj g|=        1.3623
At iterate    38  f =      -907.74  |proj g|=       0.65215
At iterate    39  f =       -907.9  |proj g|=       0.67604
At iterate    40  f =      -907.94  |proj g|=       0.38954
At iterate    41  f =      -907.95  |proj g|=      0.055134
At iterate    42  f =      -907.95  |proj g|=      0.055947
At iterate    43  f =      -907.95  |proj g|=     0.0026651

iterations 43
function evaluations 53
segments explored during Cauchy searches 45
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00266514
final function value -907.946

F = -907.946
final  value -907.946435 
converged
 
INFO  [00:39:35.133] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:39:35.202] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:39:35.209] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:39:39.597] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:39:44.074] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:39:48.444] [mlr3]  Finished benchmark 
INFO  [00:39:48.514] [bbotk] Result of batch 166: 
INFO  [00:39:48.516] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:39:48.516] [bbotk]              5.038588                 7.477893                       0.1623285 
INFO  [00:39:48.516] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:39:48.516] [bbotk]                     2310        0.909 -0.9371961         <NA>   0.9709548 
INFO  [00:39:48.516] [bbotk]                                 uhash 
INFO  [00:39:48.516] [bbotk]  477e0d92-685e-4665-a804-d5efe4d7ecbf 
DEBUG [00:39:50.113] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.051806e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.051806e-05 0.001328566 
  - best initial criterion value(s) :  793.5216 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -793.52  |proj g|=       7.0258
At iterate     1  f =      -801.44  |proj g|=        5.0332
At iterate     2  f =      -813.25  |proj g|=        5.4285
At iterate     3  f =      -813.67  |proj g|=        5.1515
At iterate     4  f =      -813.71  |proj g|=        5.1297
At iterate     5  f =      -813.71  |proj g|=        5.1057
At iterate     6  f =      -813.71  |proj g|=        5.1064
At iterate     7  f =      -813.71  |proj g|=        5.1066

iterations 7
function evaluations 13
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 5.10659
final function value -813.71

F = -813.71
final  value -813.709699 
converged
 
INFO  [00:39:50.118] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:39:50.191] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:39:50.198] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:39:56.676] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:40:05.357] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:40:13.573] [mlr3]  Finished benchmark 
INFO  [00:40:13.658] [bbotk] Result of batch 167: 
INFO  [00:40:13.660] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:40:13.660] [bbotk]               3.67509                 6.663956                       0.2389979 
INFO  [00:40:13.660] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [00:40:13.660] [bbotk]                     3309         1.16  -0.96107         <NA>   0.9714758 
INFO  [00:40:13.660] [bbotk]                                 uhash 
INFO  [00:40:13.660] [bbotk]  276cd4e2-e9cc-4aea-bb1c-7f9eee779fa5 
DEBUG [00:40:15.394] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.046998e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.046998e-05 0.001324823 
  - best initial criterion value(s) :  797.6575 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -797.66  |proj g|=        14.26
At iterate     1  f =       -883.5  |proj g|=        2.4133
At iterate     2  f =      -898.88  |proj g|=        3.5365
At iterate     3  f =      -902.67  |proj g|=        3.7205
At iterate     4  f =      -903.38  |proj g|=        3.6829
At iterate     5  f =      -903.42  |proj g|=        3.6862
At iterate     6  f =      -903.43  |proj g|=        3.6865
At iterate     7  f =      -903.44  |proj g|=        3.6839
At iterate     8  f =      -903.44  |proj g|=        3.6829
At iterate     9  f =      -903.44  |proj g|=        3.6829
At iterate    10  f =      -903.44  |proj g|=        3.6829
At iterate    11  f =      -903.44  |proj g|=        3.6829
At iterate    12  f =      -903.44  |proj g|=        3.6828
At iterate    13  f =      -903.44  |proj g|=        3.6827
At iterate    14  f =      -903.44  |proj g|=        3.6825
At iterate    15  f =      -903.44  |proj g|=        3.6821
At iterate    16  f =      -903.45  |proj g|=        3.6813
At iterate    17  f =      -903.48  |proj g|=        3.6792
At iterate    18  f =      -903.53  |proj g|=        3.6738
At iterate    19  f =      -903.68  |proj g|=        3.6607
At iterate    20  f =      -903.99  |proj g|=         3.632
At iterate    21  f =      -904.58  |proj g|=        3.5831
At iterate    22  f =      -904.85  |proj g|=         3.513
At iterate    23  f =      -905.22  |proj g|=         3.537
At iterate    24  f =      -905.25  |proj g|=        3.5304
At iterate    25  f =      -905.31  |proj g|=        3.5167
At iterate    26  f =      -905.49  |proj g|=        3.4822
At iterate    27  f =      -905.77  |proj g|=        3.4325
At iterate    28  f =      -905.99  |proj g|=        3.4035
At iterate    29  f =      -906.07  |proj g|=        3.4153
At iterate    30  f =      -906.08  |proj g|=        3.4211
At iterate    31  f =      -906.08  |proj g|=        3.4201
At iterate    32  f =      -906.08  |proj g|=          3.42
At iterate    33  f =      -906.08  |proj g|=          3.42

iterations 33
function evaluations 36
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.42002
final function value -906.079

F = -906.079
final  value -906.079030 
converged
 
INFO  [00:40:15.398] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:40:15.455] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:40:15.462] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:40:25.769] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:40:34.701] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:40:44.434] [mlr3]  Finished benchmark 
INFO  [00:40:44.506] [bbotk] Result of batch 168: 
INFO  [00:40:44.507] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:40:44.507] [bbotk]              6.104239                 2.297199                       0.3700456 
INFO  [00:40:44.507] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:40:44.507] [bbotk]                     3546        1.025 -0.9489701         <NA>   0.9757668 
INFO  [00:40:44.507] [bbotk]                                 uhash 
INFO  [00:40:44.507] [bbotk]  0c62dcb5-143e-435c-8aab-fae77fc284a6 
DEBUG [00:40:46.284] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.044549e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.74622 15.88239 0.9842448 9582 
  - variance bounds :  1.044549e-05 0.001323557 
  - best initial criterion value(s) :  803.673 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -803.67  |proj g|=       5.9272
At iterate     1  f =      -881.32  |proj g|=        11.377
At iterate     2  f =      -889.98  |proj g|=        11.133
At iterate     3  f =      -901.02  |proj g|=        10.707
At iterate     4  f =      -902.62  |proj g|=        9.0465
At iterate     5  f =       -903.2  |proj g|=        9.6382
At iterate     6  f =      -904.07  |proj g|=        9.6462
At iterate     7  f =      -906.05  |proj g|=        8.4208
At iterate     8  f =      -907.09  |proj g|=        6.6608
At iterate     9  f =      -907.26  |proj g|=        6.3457
At iterate    10  f =      -907.28  |proj g|=        6.2243
At iterate    11  f =      -907.29  |proj g|=        6.2115
At iterate    12  f =      -907.29  |proj g|=         6.203
At iterate    13  f =      -907.29  |proj g|=        6.2007
At iterate    14  f =      -907.29  |proj g|=        6.1784
At iterate    15  f =      -907.29  |proj g|=        6.1642
At iterate    16  f =      -907.31  |proj g|=        6.1226
At iterate    17  f =      -907.34  |proj g|=        6.0228
At iterate    18  f =      -907.43  |proj g|=        5.8297
At iterate    19  f =       -907.6  |proj g|=         5.767
At iterate    20  f =      -907.97  |proj g|=        5.2228
At iterate    21  f =      -908.12  |proj g|=        5.7294
At iterate    22  f =      -909.18  |proj g|=         4.713
At iterate    23  f =      -913.11  |proj g|=        3.4917
At iterate    24  f =      -920.31  |proj g|=        2.2634
At iterate    25  f =      -923.29  |proj g|=       0.65515
At iterate    26  f =      -923.89  |proj g|=       0.71005
At iterate    27  f =      -924.02  |proj g|=       0.49233
At iterate    28  f =      -924.04  |proj g|=       0.71629
At iterate    29  f =      -924.04  |proj g|=       0.49546
At iterate    30  f =      -924.04  |proj g|=       0.49568
At iterate    31  f =      -924.04  |proj g|=       0.49568

iterations 31
function evaluations 40
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.495683
final function value -924.04

F = -924.04
final  value -924.039915 
converged
 
INFO  [00:40:46.286] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:40:46.331] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:40:46.338] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:40:57.685] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:41:06.772] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:41:15.944] [mlr3]  Finished benchmark 
INFO  [00:41:16.036] [bbotk] Result of batch 169: 
INFO  [00:41:16.038] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:41:16.038] [bbotk]              5.817495                 2.582679                      0.06895159 
INFO  [00:41:16.038] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:41:16.038] [bbotk]                     3220        1.024 -0.9462035         <NA>   0.9681951 
INFO  [00:41:16.038] [bbotk]                                 uhash 
INFO  [00:41:16.038] [bbotk]  8b986298-a4a6-4a75-b1fc-193d4b7aa15e 
DEBUG [00:41:16.111] [bbotk]  
INFO  [00:41:16.125] [bbotk] Finished optimizing after 200 evaluation(s) 
INFO  [00:41:16.126] [bbotk] Result: 
INFO  [00:41:16.129] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:41:16.129] [bbotk]              7.693669                 3.940974                       0.4563975 
INFO  [00:41:16.129] [bbotk]  ps_cboost_anneal1.mstop learner_param_vals  x_domain classif.auc 
INFO  [00:41:16.129] [bbotk]                     4997         <list[18]> <list[4]>   0.9774298 
INFO  [00:41:31.913] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1.tuned' on task 'spam' (iter 3/5) 
INFO  [00:41:32.036] [bbotk] Starting to optimize 4 parameter(s) with '<OptimizerInterMBO>' and '<TerminatorEvals> [n_evals=200]' 
DEBUG [00:41:32.106] [bbotk]  
INFO  [00:41:32.113] [bbotk] Evaluating 32 configuration(s) 
INFO  [00:41:33.381] [mlr3]  Running benchmark with 96 resampling iterations 
INFO  [00:41:33.389] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:41:44.308] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:41:51.850] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:41:58.482] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:42:08.361] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:42:12.176] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:42:19.487] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:42:31.037] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:42:45.296] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:42:47.193] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:42:48.548] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:42:55.567] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:42:59.112] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:43:05.588] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:43:07.850] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:43:14.042] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:43:24.047] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:43:35.242] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:43:46.344] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:43:51.201] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:44:01.351] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:44:08.267] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:44:19.188] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:44:22.477] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:44:36.826] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:44:44.668] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:44:57.216] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:45:10.624] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:45:23.373] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:45:30.186] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:45:38.248] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:45:42.309] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:45:43.885] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:45:49.346] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:45:51.427] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:45:55.622] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:46:09.001] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:46:15.222] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:46:21.848] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:46:31.459] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:46:35.342] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:46:41.595] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:46:45.517] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:46:50.013] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:47:00.610] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:47:11.860] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:47:12.895] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:47:20.924] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:47:26.796] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:47:30.425] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:47:40.640] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:47:42.556] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:47:46.847] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:47:50.001] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:47:59.549] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:48:05.235] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:48:11.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:48:13.127] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:48:15.431] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:48:24.122] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:48:34.108] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:48:35.499] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:48:40.780] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:48:50.574] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:48:56.629] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:49:12.743] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:49:19.645] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:49:33.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:49:41.771] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:49:54.181] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:49:58.252] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:50:03.019] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:50:14.872] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:50:22.007] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:50:24.209] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:50:33.390] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:50:36.834] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:50:38.703] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:50:45.228] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:50:55.247] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:51:00.186] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:51:10.277] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:51:16.013] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:51:31.710] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:51:35.888] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:51:38.298] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:51:42.907] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:51:59.248] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:52:02.056] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:52:14.852] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:52:24.610] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:52:37.661] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:52:42.691] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:52:54.672] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:53:05.022] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:53:16.848] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:53:20.295] [mlr3]  Finished benchmark 
INFO  [00:53:21.925] [bbotk] Result of batch 1: 
INFO  [00:53:21.927] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:53:21.927] [bbotk]              4.483621                 6.228855                      0.32915443 
INFO  [00:53:21.927] [bbotk]              3.347598                 5.902845                      0.23709822 
INFO  [00:53:21.927] [bbotk]              8.122224                 4.991188                      0.32314543 
INFO  [00:53:21.927] [bbotk]              6.543059                 7.427409                      0.46189140 
INFO  [00:53:21.927] [bbotk]              4.218013                 3.147246                      0.19473305 
INFO  [00:53:21.927] [bbotk]              7.656007                 7.681180                      0.26139734 
INFO  [00:53:21.927] [bbotk]              6.466064                 9.491400                      0.04789571 
INFO  [00:53:21.927] [bbotk]              6.833469                 2.614054                      0.09847733 
INFO  [00:53:21.927] [bbotk]              5.561947                 8.134251                      0.23433904 
INFO  [00:53:21.927] [bbotk]              5.428526                 4.344572                      0.40809636 
INFO  [00:53:21.927] [bbotk]              7.038314                 6.425783                      0.13751427 
INFO  [00:53:21.927] [bbotk]              9.116432                 9.967272                      0.29437264 
INFO  [00:53:21.927] [bbotk]              8.962114                 6.570451                      0.38215707 
INFO  [00:53:21.927] [bbotk]              2.762310                 4.638323                      0.12500188 
INFO  [00:53:21.927] [bbotk]              7.324563                 5.044534                      0.48656221 
INFO  [00:53:21.927] [bbotk]              5.129280                 6.969157                      0.01550380 
INFO  [00:53:21.927] [bbotk]              4.771280                 8.647891                      0.07606957 
INFO  [00:53:21.927] [bbotk]              9.742887                 3.297401                      0.36014778 
INFO  [00:53:21.927] [bbotk]              2.391206                 3.507509                      0.30364605 
INFO  [00:53:21.927] [bbotk]              4.574246                 3.937842                      0.35418648 
INFO  [00:53:21.927] [bbotk]              5.866590                 7.205919                      0.16316611 
INFO  [00:53:21.927] [bbotk]              6.060278                 5.542583                      0.27074703 
INFO  [00:53:21.927] [bbotk]              3.838239                 8.486918                      0.43697961 
INFO  [00:53:21.927] [bbotk]              7.884412                 9.666569                      0.14705074 
INFO  [00:53:21.927] [bbotk]              8.546692                 2.138450                      0.45098768 
INFO  [00:53:21.927] [bbotk]              2.505661                 9.086295                      0.21567859 
INFO  [00:53:21.927] [bbotk]              9.332692                 4.212189                      0.09151371 
INFO  [00:53:21.927] [bbotk]              3.042121                 2.771034                      0.03811754 
INFO  [00:53:21.927] [bbotk]              8.280532                 7.899037                      0.39541943 
INFO  [00:53:21.927] [bbotk]              3.589431                 2.307042                      0.48335745 
INFO  [00:53:21.927] [bbotk]              2.158209                 8.807409                      0.17492000 
INFO  [00:53:21.927] [bbotk]              9.768937                 5.387309                      0.02775922 
INFO  [00:53:21.927] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:53:21.927] [bbotk]  ps_cboost_anneal1.mstop classif.auc                                uhash 
INFO  [00:53:21.927] [bbotk]                     1243   0.9729537 907f9931-86fc-48c4-bea5-d7aad10ec0ef 
INFO  [00:53:21.927] [bbotk]                     3481   0.9734922 a7c84077-1447-42c0-8ff8-1bed1d05e06e 
INFO  [00:53:21.927] [bbotk]                      356   0.9665366 bc702ebf-3b35-4289-9244-9e2ac09723c3 
INFO  [00:53:21.927] [bbotk]                     3301   0.9787117 f020a973-e92e-4dba-bb7b-6300bdc36dec 
INFO  [00:53:21.927] [bbotk]                      536   0.9612713 fcb50645-d82b-4f95-86ea-238d397929e7 
INFO  [00:53:21.927] [bbotk]                     1553   0.9746547 e0d574f9-38c7-4c9b-8766-df2ae7362caa 
INFO  [00:53:21.927] [bbotk]                     1414   0.9595278 f2721574-f7a7-48ad-9807-53883e9624b4 
INFO  [00:53:21.927] [bbotk]                     2678   0.9726679 a394e693-4589-4baa-98ce-1b5eb527a493 
INFO  [00:53:21.927] [bbotk]                     3603   0.9768529 b693e45d-bebb-417d-a654-0ed575b8b116 
INFO  [00:53:21.927] [bbotk]                     4527   0.9787445 e34bb954-22a3-464b-bf7f-0e42b69a0d82 
INFO  [00:53:21.927] [bbotk]                     1893   0.9726186 44c42bee-100d-4ca5-b271-e23ec0863a73 
INFO  [00:53:21.927] [bbotk]                     3992   0.9778670 71de2642-a39f-45bc-bbd0-53e6ffa2c3a3 
INFO  [00:53:21.927] [bbotk]                     3811   0.9783663 95b4e1da-e3a4-4abd-b44b-980f9c66dee0 
INFO  [00:53:21.927] [bbotk]                     2354   0.9621396 108c4795-f778-4083-b32d-388193b0327e 
INFO  [00:53:21.927] [bbotk]                     2256   0.9777527 174f9a51-c60b-4a20-b2f3-f414352a74ee 
INFO  [00:53:21.927] [bbotk]                     2450   0.9492935 b16d5c0b-46c2-4959-83d3-0d49f730bb30 
INFO  [00:53:21.927] [bbotk]                     4726   0.9727792 93bbf005-f436-4801-91b3-9e05651a8356 
INFO  [00:53:21.927] [bbotk]                     1784   0.9754167 252612fa-9cd7-444c-96a8-7cbf5af243b0 
INFO  [00:53:21.927] [bbotk]                     3794   0.9679035 b40257b9-2050-4820-b2de-6e85cdaff72b 
INFO  [00:53:21.927] [bbotk]                      828   0.9712943 762f5a97-23a2-4a6c-bf83-3e33a305babe 
INFO  [00:53:21.927] [bbotk]                      295   0.9548467 56294840-4fbe-438e-b6d8-89e489fb0ef9 
INFO  [00:53:21.927] [bbotk]                     3186   0.9771700 64ef813f-f96c-4ee7-8a41-268b9eab028d 
INFO  [00:53:21.927] [bbotk]                     2014   0.9750128 0a5d4dab-51c8-4931-8f75-50708a8f5bf5 
INFO  [00:53:21.927] [bbotk]                     2788   0.9745616 e4c127f9-b1c4-4ed2-ab63-10776c4aa944 
INFO  [00:53:21.927] [bbotk]                     4288   0.9787208 a5fc273e-c11d-46b0-a5cf-9857742800ad 
INFO  [00:53:21.927] [bbotk]                     4955   0.9687813 ddeb605e-e4b3-4b05-87d7-f851a25baf2b 
INFO  [00:53:21.927] [bbotk]                     1100   0.9656664 bdc9a6ed-062c-4f87-b260-5c104c6a1e1c 
INFO  [00:53:21.927] [bbotk]                     4135   0.9583901 63be57c4-9995-4210-8231-af83d04e1d9d 
INFO  [00:53:21.927] [bbotk]                     1321   0.9755766 3b5c14e4-1369-48b6-8c21-b52446bd684c 
INFO  [00:53:21.927] [bbotk]                     2937   0.9760223 25afc80b-897b-4a36-9bfc-814fa2394262 
INFO  [00:53:21.927] [bbotk]                      768   0.9426950 4eff2e7e-84c6-4afa-be5f-d0face0cfeb4 
INFO  [00:53:21.927] [bbotk]                     4608   0.9676179 03a6ffda-9d7e-4a2d-9495-0636d886ace2 
INFO  [00:53:21.927] [bbotk]  ps_cboost_anneal1.mstop classif.auc                                uhash 
DEBUG [00:53:22.642] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.243728e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9421168 9320 
  - variance bounds :  8.243727e-06 0.0009215716 
  - best initial criterion value(s) :  117.568 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -117.57  |proj g|=         0.85
At iterate     1  f =      -119.04  |proj g|=        0.3681
At iterate     2  f =      -119.19  |proj g|=        0.3499
At iterate     3  f =      -119.65  |proj g|=       0.26067
At iterate     4  f =      -119.78  |proj g|=       0.21351
At iterate     5  f =      -119.84  |proj g|=       0.14463
At iterate     6  f =      -119.84  |proj g|=       0.14603
At iterate     7  f =      -119.84  |proj g|=       0.14571
At iterate     8  f =      -119.84  |proj g|=       0.14572

iterations 8
function evaluations 13
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.14572
final function value -119.842

F = -119.842
final  value -119.841978 
converged
 
INFO  [00:53:22.647] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:53:22.715] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:53:22.722] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:53:27.549] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:53:33.315] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:53:38.679] [mlr3]  Finished benchmark 
INFO  [00:53:38.747] [bbotk] Result of batch 2: 
INFO  [00:53:38.749] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:53:38.749] [bbotk]              9.239725                  2.87764                       0.1689626 
INFO  [00:53:38.749] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:53:38.749] [bbotk]                     1994        0.468 -0.9734703         <NA>   0.9735763 
INFO  [00:53:38.749] [bbotk]                                 uhash 
INFO  [00:53:38.749] [bbotk]  ea0bdf49-fc62-4eac-953b-696e46d25096 
DEBUG [00:53:39.398] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.027691e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9421168 9320 
  - variance bounds :  8.027691e-06 0.0008931076 
  - best initial criterion value(s) :  123.9931 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -123.99  |proj g|=      0.17653
At iterate     1  f =      -124.21  |proj g|=       0.76931
At iterate     2  f =      -124.22  |proj g|=       0.76878
At iterate     3  f =      -124.22  |proj g|=        0.7683
At iterate     4  f =      -124.22  |proj g|=       0.76749
At iterate     5  f =      -124.23  |proj g|=        0.7645
At iterate     6  f =      -124.26  |proj g|=       0.75779
At iterate     7  f =       -124.3  |proj g|=       0.19923
At iterate     8  f =      -124.37  |proj g|=       0.22193
At iterate     9  f =       -124.4  |proj g|=       0.23605
At iterate    10  f =       -124.4  |proj g|=       0.17622
At iterate    11  f =       -124.4  |proj g|=        0.1779
At iterate    12  f =       -124.4  |proj g|=       0.17799
At iterate    13  f =       -124.4  |proj g|=       0.17799

iterations 13
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.17799
final function value -124.402

F = -124.402
final  value -124.401962 
converged
 
INFO  [00:53:39.402] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:53:39.701] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:53:39.708] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:53:54.301] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:54:09.036] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:54:25.384] [mlr3]  Finished benchmark 
INFO  [00:54:25.455] [bbotk] Result of batch 3: 
INFO  [00:54:25.476] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:54:25.476] [bbotk]              2.795457                  9.84162                       0.2698544 
INFO  [00:54:25.476] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:54:25.476] [bbotk]                     4787         0.46 -0.9719691         <NA>   0.9725765 
INFO  [00:54:25.476] [bbotk]                                 uhash 
INFO  [00:54:25.476] [bbotk]  cbd7d9d9-e98c-4e8d-8197-3d59938c1949 
DEBUG [00:54:26.177] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.80419e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9421168 9320 
  - variance bounds :  7.80419e-06 0.0008729289 
  - best initial criterion value(s) :  123.5296 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -123.53  |proj g|=      0.74787
At iterate     1  f =      -126.51  |proj g|=       0.77103
At iterate     2  f =      -127.48  |proj g|=       0.76105
At iterate     3  f =      -128.54  |proj g|=       0.74657
At iterate     4  f =      -128.56  |proj g|=       0.50128
At iterate     5  f =      -128.58  |proj g|=        0.7431
At iterate     6  f =      -128.64  |proj g|=       0.72957
At iterate     7  f =      -128.76  |proj g|=       0.68292
At iterate     8  f =      -128.76  |proj g|=       0.63332
At iterate     9  f =      -128.78  |proj g|=       0.17206
At iterate    10  f =      -128.79  |proj g|=       0.17694
At iterate    11  f =      -128.79  |proj g|=       0.18111
At iterate    12  f =      -128.79  |proj g|=       0.18205
At iterate    13  f =      -128.79  |proj g|=       0.17919

iterations 13
function evaluations 19
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.179194
final function value -128.793

F = -128.793
final  value -128.793064 
converged
 
INFO  [00:54:26.182] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:54:26.247] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:54:26.254] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:54:38.678] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:54:50.436] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:55:03.249] [mlr3]  Finished benchmark 
INFO  [00:55:03.318] [bbotk] Result of batch 4: 
INFO  [00:55:03.320] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:55:03.320] [bbotk]              8.190903                 4.549301                       0.2785673 
INFO  [00:55:03.320] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:55:03.320] [bbotk]                     4291        0.482 -0.9712559         <NA>   0.9778384 
INFO  [00:55:03.320] [bbotk]                                 uhash 
INFO  [00:55:03.320] [bbotk]  392b5b34-a716-4ded-8d80-0cf7151866d4 
DEBUG [00:55:04.211] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.747499e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9421168 9320 
  - variance bounds :  7.747499e-06 0.0008846263 
  - best initial criterion value(s) :  130.3016 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -130.3  |proj g|=       1.0053
At iterate     1  f =      -130.95  |proj g|=       0.74971
At iterate     2  f =      -131.51  |proj g|=       0.71582
At iterate     3  f =      -132.62  |proj g|=       0.57201
At iterate     4  f =      -132.83  |proj g|=       0.44677
At iterate     5  f =      -132.85  |proj g|=       0.47368
At iterate     6  f =      -132.86  |proj g|=       0.48023
At iterate     7  f =      -132.87  |proj g|=       0.43004
At iterate     8  f =      -132.87  |proj g|=       0.31916
At iterate     9  f =      -132.87  |proj g|=       0.31969

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.319685
final function value -132.868

F = -132.868
final  value -132.867584 
converged
 
INFO  [00:55:04.215] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:55:04.270] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:55:04.277] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:55:08.186] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:55:12.594] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:55:16.587] [mlr3]  Finished benchmark 
INFO  [00:55:16.688] [bbotk] Result of batch 5: 
INFO  [00:55:16.690] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:55:16.690] [bbotk]              9.547685                 3.910578                        0.412641 
INFO  [00:55:16.690] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:55:16.690] [bbotk]                     1298        0.699 -0.9716143         <NA>   0.9750631 
INFO  [00:55:16.690] [bbotk]                                 uhash 
INFO  [00:55:16.690] [bbotk]  48a833f5-3d47-474e-95fb-2e2c26b27be2 
DEBUG [00:55:17.342] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.589618e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9421168 9320 
  - variance bounds :  7.589618e-06 0.0008428251 
  - best initial criterion value(s) :  134.8587 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -134.86  |proj g|=       2.5612
At iterate     1  f =       -136.3  |proj g|=        1.2013
At iterate     2  f =      -137.29  |proj g|=        1.1056
At iterate     3  f =      -137.82  |proj g|=       0.79632
At iterate     4  f =      -137.94  |proj g|=       0.74923
At iterate     5  f =      -137.97  |proj g|=       0.78041
At iterate     6  f =      -137.98  |proj g|=       0.82214
At iterate     7  f =      -137.98  |proj g|=       0.84611
At iterate     8  f =      -137.98  |proj g|=       0.84562
At iterate     9  f =      -137.98  |proj g|=       0.84579

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.845786
final function value -137.978

F = -137.978
final  value -137.977799 
converged
 
INFO  [00:55:17.346] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:55:17.402] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:55:17.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:55:22.863] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:55:28.294] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:55:33.632] [mlr3]  Finished benchmark 
INFO  [00:55:33.702] [bbotk] Result of batch 6: 
INFO  [00:55:33.703] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:55:33.703] [bbotk]              5.499556                 9.266761                       0.3733318 
INFO  [00:55:33.703] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [00:55:33.703] [bbotk]                     2021        0.474 -0.971815         <NA>   0.9764882 
INFO  [00:55:33.703] [bbotk]                                 uhash 
INFO  [00:55:33.703] [bbotk]  108def47-6215-4a74-84e3-686f9cf0f28c 
DEBUG [00:55:34.356] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.478463e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9421168 9320 
  - variance bounds :  7.478463e-06 0.0008212627 
  - best initial criterion value(s) :  141.1108 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -141.11  |proj g|=       1.4771
At iterate     1  f =      -141.52  |proj g|=        1.0399
At iterate     2  f =      -141.61  |proj g|=        1.1005
At iterate     3  f =      -141.63  |proj g|=        1.1053
At iterate     4  f =      -141.63  |proj g|=        1.1122
At iterate     5  f =      -141.63  |proj g|=        1.1136
At iterate     6  f =      -141.63  |proj g|=        1.1137

iterations 6
function evaluations 9
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.1137
final function value -141.627

F = -141.627
final  value -141.626716 
converged
 
INFO  [00:55:34.360] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:55:34.415] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:55:34.423] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:55:35.299] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:55:36.213] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:55:37.118] [mlr3]  Finished benchmark 
INFO  [00:55:37.201] [bbotk] Result of batch 7: 
INFO  [00:55:37.203] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:55:37.203] [bbotk]              9.738131                 7.044283                     0.001518807 
INFO  [00:55:37.203] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:55:37.203] [bbotk]                      206        0.475 -0.9730077         <NA>   0.8459108 
INFO  [00:55:37.203] [bbotk]                                 uhash 
INFO  [00:55:37.203] [bbotk]  69dc4d39-87ea-4d22-8e30-8c34fca2a73c 
DEBUG [00:55:37.990] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.817721e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  4.817721e-05 0.006724322 
  - best initial criterion value(s) :  101.8631 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -101.86  |proj g|=      0.56913
At iterate     1  f =      -103.47  |proj g|=       0.39819
At iterate     2  f =      -103.49  |proj g|=       0.39918
At iterate     3  f =      -103.51  |proj g|=       0.39898
At iterate     4  f =      -103.52  |proj g|=       0.39675
At iterate     5  f =      -103.62  |proj g|=       0.37108
At iterate     6  f =      -103.77  |proj g|=       0.34952
At iterate     7  f =      -103.99  |proj g|=       0.33373
At iterate     8  f =      -104.06  |proj g|=       0.34629
At iterate     9  f =      -104.06  |proj g|=       0.34656
At iterate    10  f =      -104.06  |proj g|=       0.34651
At iterate    11  f =      -104.06  |proj g|=        0.3465
At iterate    12  f =      -104.06  |proj g|=        0.3465
At iterate    13  f =      -104.06  |proj g|=        0.3465
At iterate    14  f =      -104.06  |proj g|=       0.34647
At iterate    15  f =      -104.06  |proj g|=       0.34643
At iterate    16  f =      -104.06  |proj g|=       0.34632
At iterate    17  f =      -104.06  |proj g|=       0.34609
At iterate    18  f =      -104.06  |proj g|=       0.34579
At iterate    19  f =      -104.06  |proj g|=       0.34507
At iterate    20  f =      -104.06  |proj g|=       0.44089
At iterate    21  f =      -104.06  |proj g|=         0.522
At iterate    22  f =      -104.07  |proj g|=       0.74123
At iterate    23  f =      -104.08  |proj g|=       0.75068
At iterate    24  f =      -104.11  |proj g|=       0.76793
At iterate    25  f =      -104.18  |proj g|=       0.79298
At iterate    26  f =       -104.2  |proj g|=       0.79274
At iterate    27  f =      -104.35  |proj g|=       0.81769
At iterate    28  f =      -104.76  |proj g|=       0.83207
At iterate    29  f =      -105.12  |proj g|=       0.40856
At iterate    30  f =      -105.19  |proj g|=       0.40947
At iterate    31  f =       -105.2  |proj g|=       0.40041
At iterate    32  f =       -105.2  |proj g|=       0.39994
At iterate    33  f =       -105.2  |proj g|=       0.39978
At iterate    34  f =       -105.2  |proj g|=           0.4
At iterate    35  f =       -105.2  |proj g|=       0.40035
At iterate    36  f =       -105.2  |proj g|=       0.40122
At iterate    37  f =       -105.2  |proj g|=       0.40236
At iterate    38  f =       -105.2  |proj g|=       0.40529
At iterate    39  f =       -105.2  |proj g|=       0.40663
At iterate    40  f =      -105.21  |proj g|=       0.40712
At iterate    41  f =      -105.27  |proj g|=       0.40495
At iterate    42  f =       -105.4  |proj g|=       0.39372
At iterate    43  f =      -105.69  |proj g|=        0.3588
At iterate    44  f =      -105.95  |proj g|=       0.22686
At iterate    45  f =      -106.16  |proj g|=       0.20866
At iterate    46  f =      -106.37  |proj g|=       0.17405
At iterate    47  f =      -106.38  |proj g|=       0.81259
At iterate    48  f =      -106.39  |proj g|=       0.09675
At iterate    49  f =      -106.39  |proj g|=      0.048434
At iterate    50  f =      -106.39  |proj g|=     0.0060347
At iterate    51  f =      -106.39  |proj g|=     0.0060347

iterations 51
function evaluations 60
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00603474
final function value -106.39

F = -106.39
final  value -106.389636 
converged
 
INFO  [00:55:37.995] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:55:38.051] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:55:38.058] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:55:41.354] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:55:44.597] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:55:47.721] [mlr3]  Finished benchmark 
INFO  [00:55:47.802] [bbotk] Result of batch 8: 
INFO  [00:55:47.804] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:55:47.804] [bbotk]              6.213062                 7.886272                      0.05004802 
INFO  [00:55:47.804] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:55:47.804] [bbotk]                     1533        0.545 -0.9760017         <NA>   0.9608564 
INFO  [00:55:47.804] [bbotk]                                 uhash 
INFO  [00:55:47.804] [bbotk]  b797ca86-7df1-4280-b2a1-e727d97a7a3c 
DEBUG [00:55:48.505] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.701582e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  4.701582e-05 0.006441959 
  - best initial criterion value(s) :  101.7289 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -101.73  |proj g|=      0.93697
At iterate     1  f =      -106.58  |proj g|=       0.86954
At iterate     2  f =      -107.43  |proj g|=       0.86367
At iterate     3  f =      -107.43  |proj g|=       0.86137
At iterate     4  f =      -107.43  |proj g|=       0.85935
At iterate     5  f =      -107.43  |proj g|=       0.85919
At iterate     6  f =      -107.43  |proj g|=       0.85904
At iterate     7  f =      -107.43  |proj g|=       0.85885
At iterate     8  f =      -107.43  |proj g|=       0.85851
At iterate     9  f =      -107.43  |proj g|=       0.85752
At iterate    10  f =      -107.43  |proj g|=       0.85457
At iterate    11  f =      -107.44  |proj g|=       0.85262
At iterate    12  f =      -107.44  |proj g|=        0.8465
At iterate    13  f =      -107.46  |proj g|=       0.84309
At iterate    14  f =      -107.55  |proj g|=       0.85095
At iterate    15  f =      -107.81  |proj g|=       0.86054
At iterate    16  f =      -108.92  |proj g|=       0.86663
At iterate    17  f =      -111.09  |proj g|=       0.85655
At iterate    18  f =       -111.1  |proj g|=       0.85606
At iterate    19  f =      -111.33  |proj g|=       0.84197
At iterate    20  f =       -111.4  |proj g|=        0.8301
At iterate    21  f =      -111.41  |proj g|=       0.26945
At iterate    22  f =      -111.41  |proj g|=       0.18062
At iterate    23  f =      -111.41  |proj g|=       0.18093
At iterate    24  f =      -111.41  |proj g|=       0.18092
At iterate    25  f =      -111.41  |proj g|=       0.18147
At iterate    26  f =      -111.41  |proj g|=       0.18141
At iterate    27  f =      -111.41  |proj g|=       0.18108
At iterate    28  f =      -111.41  |proj g|=       0.18061
At iterate    29  f =      -111.41  |proj g|=        0.1795
At iterate    30  f =      -111.42  |proj g|=       0.17719
At iterate    31  f =      -111.43  |proj g|=       0.17309
At iterate    32  f =      -111.44  |proj g|=       0.15783
At iterate    33  f =      -111.48  |proj g|=       0.16217
At iterate    34  f =      -111.51  |proj g|=       0.16263
At iterate    35  f =      -111.54  |proj g|=       0.15813
At iterate    36  f =      -111.57  |proj g|=       0.82632
At iterate    37  f =      -111.57  |proj g|=      0.073381
At iterate    38  f =      -111.57  |proj g|=     0.0011676
At iterate    39  f =      -111.57  |proj g|=     0.0011675

iterations 39
function evaluations 50
segments explored during Cauchy searches 41
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00116751
final function value -111.57

F = -111.57
final  value -111.569798 
converged
 
INFO  [00:55:48.510] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:55:48.577] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:55:48.586] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:55:50.147] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:55:51.578] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:55:53.285] [mlr3]  Finished benchmark 
INFO  [00:55:53.370] [bbotk] Result of batch 9: 
INFO  [00:55:53.372] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:55:53.372] [bbotk]              7.252082                 3.082532                       0.2654941 
INFO  [00:55:53.372] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:55:53.372] [bbotk]                      521        0.469 -0.9738602         <NA>   0.9677197 
INFO  [00:55:53.372] [bbotk]                                 uhash 
INFO  [00:55:53.372] [bbotk]  fa468859-3c12-48b3-a457-cd321d4383d3 
DEBUG [00:55:54.030] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.581114e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  4.581114e-05 0.006118018 
  - best initial criterion value(s) :  112.5639 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -112.56  |proj g|=      0.37065
At iterate     1  f =       -113.5  |proj g|=       0.40109
At iterate     2  f =      -113.52  |proj g|=        0.3992
At iterate     3  f =      -113.53  |proj g|=       0.39721
At iterate     4  f =      -113.53  |proj g|=       0.39649
At iterate     5  f =      -113.57  |proj g|=       0.38919
At iterate     6  f =      -113.63  |proj g|=        0.3797
At iterate     7  f =      -113.71  |proj g|=       0.36045
At iterate     8  f =      -113.74  |proj g|=       0.35769
At iterate     9  f =      -113.74  |proj g|=       0.36037
At iterate    10  f =      -113.74  |proj g|=       0.37777
At iterate    11  f =      -113.74  |proj g|=        0.3754

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.375403
final function value -113.737

F = -113.737
final  value -113.737007 
converged
 
INFO  [00:55:54.034] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:55:54.089] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:55:54.096] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:56:02.744] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:56:11.459] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:56:20.254] [mlr3]  Finished benchmark 
INFO  [00:56:20.341] [bbotk] Result of batch 10: 
INFO  [00:56:20.343] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:56:20.343] [bbotk]               7.57592                 4.676382                       0.4312018 
INFO  [00:56:20.343] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:56:20.343] [bbotk]                     4202        0.475 -0.9739893         <NA>   0.9786449 
INFO  [00:56:20.343] [bbotk]                                 uhash 
INFO  [00:56:20.343] [bbotk]  a94fec23-81bc-46f9-83cf-58c188b84ac0 
DEBUG [00:56:21.117] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.498823e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  4.498823e-05 0.00608548 
  - best initial criterion value(s) :  117.3261 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -117.33  |proj g|=      0.87173
At iterate     1  f =      -118.38  |proj g|=       0.79314
At iterate     2  f =      -118.63  |proj g|=        0.7926
At iterate     3  f =      -118.82  |proj g|=       0.79677
At iterate     4  f =      -118.84  |proj g|=       0.42193
At iterate     5  f =      -118.84  |proj g|=       0.42593
At iterate     6  f =      -118.84  |proj g|=        0.4248
At iterate     7  f =      -118.84  |proj g|=       0.42228
At iterate     8  f =      -118.84  |proj g|=       0.42244
At iterate     9  f =      -118.84  |proj g|=       0.42235
At iterate    10  f =      -118.84  |proj g|=       0.42233
At iterate    11  f =      -118.84  |proj g|=       0.42227
At iterate    12  f =      -118.84  |proj g|=       0.42217
At iterate    13  f =      -118.84  |proj g|=         0.422
At iterate    14  f =      -118.84  |proj g|=        0.4217
At iterate    15  f =      -118.84  |proj g|=       0.42122
At iterate    16  f =      -118.85  |proj g|=        0.4204
At iterate    17  f =      -118.85  |proj g|=         0.419
At iterate    18  f =      -118.86  |proj g|=       0.41663
At iterate    19  f =       -118.9  |proj g|=       0.41268
At iterate    20  f =      -118.99  |proj g|=       0.40654
At iterate    21  f =      -119.19  |proj g|=        0.3982
At iterate    22  f =      -119.42  |proj g|=       0.23359
At iterate    23  f =      -119.47  |proj g|=       0.23389
At iterate    24  f =      -119.48  |proj g|=       0.23402
At iterate    25  f =      -119.48  |proj g|=       0.23403
At iterate    26  f =      -119.48  |proj g|=       0.23401
At iterate    27  f =      -119.48  |proj g|=       0.23388
At iterate    28  f =      -119.48  |proj g|=       0.23354
At iterate    29  f =      -119.48  |proj g|=       0.23239
At iterate    30  f =       -119.5  |proj g|=       0.22947
At iterate    31  f =      -119.52  |proj g|=       0.22219
At iterate    32  f =      -119.58  |proj g|=       0.76323
At iterate    33  f =      -119.66  |proj g|=       0.78855
At iterate    34  f =      -119.74  |proj g|=       0.79918
At iterate    35  f =      -119.74  |proj g|=       0.17249
At iterate    36  f =      -119.74  |proj g|=       0.17106
At iterate    37  f =      -119.74  |proj g|=       0.17107

iterations 37
function evaluations 44
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.171066
final function value -119.744

F = -119.744
final  value -119.743585 
converged
 
INFO  [00:56:21.123] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:56:21.177] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:56:21.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:56:29.362] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:56:37.678] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:56:46.269] [mlr3]  Finished benchmark 
INFO  [00:56:46.365] [bbotk] Result of batch 11: 
INFO  [00:56:46.367] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:56:46.367] [bbotk]              7.484523                 2.792094                       0.1466859 
INFO  [00:56:46.367] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:56:46.367] [bbotk]                     4122        0.527 -0.9740004         <NA>   0.9762258 
INFO  [00:56:46.367] [bbotk]                                 uhash 
INFO  [00:56:46.367] [bbotk]  92a26a2f-9616-4176-a152-cfdf75cb027e 
DEBUG [00:56:47.085] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.407521e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  4.407521e-05 0.006040495 
  - best initial criterion value(s) :  110.1177 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -110.12  |proj g|=        1.154
At iterate     1  f =      -113.35  |proj g|=        1.0729
At iterate     2  f =      -117.83  |proj g|=       0.41547
At iterate     3  f =      -117.94  |proj g|=       0.43067
At iterate     4  f =      -117.97  |proj g|=       0.42919
At iterate     5  f =      -118.07  |proj g|=        0.4926
At iterate     6  f =      -118.09  |proj g|=       0.51975
At iterate     7  f =      -118.09  |proj g|=       0.52727
At iterate     8  f =      -118.09  |proj g|=       0.52616
At iterate     9  f =      -118.09  |proj g|=       0.52534
At iterate    10  f =      -118.09  |proj g|=       0.52453
At iterate    11  f =      -118.09  |proj g|=       0.52291
At iterate    12  f =      -118.09  |proj g|=       0.52042
At iterate    13  f =      -118.09  |proj g|=       0.51631
At iterate    14  f =      -118.09  |proj g|=       0.50989
At iterate    15  f =      -118.09  |proj g|=       0.49974
At iterate    16  f =       -118.1  |proj g|=       0.48501
At iterate    17  f =       -118.1  |proj g|=       0.47554
At iterate    18  f =       -118.1  |proj g|=       0.45792
At iterate    19  f =      -118.92  |proj g|=       0.57007
At iterate    20  f =      -120.02  |proj g|=       0.83197
At iterate    21  f =       -121.8  |proj g|=       0.59202
At iterate    22  f =      -122.01  |proj g|=       0.57647
At iterate    23  f =      -122.28  |proj g|=       0.47124
At iterate    24  f =      -122.35  |proj g|=       0.52609
At iterate    25  f =      -122.39  |proj g|=       0.50788
At iterate    26  f =      -122.39  |proj g|=       0.50408
At iterate    27  f =      -122.39  |proj g|=       0.50159
At iterate    28  f =      -122.39  |proj g|=       0.50193
At iterate    29  f =      -122.39  |proj g|=       0.50189
At iterate    30  f =      -122.39  |proj g|=       0.50172
At iterate    31  f =      -122.39  |proj g|=       0.50148
At iterate    32  f =      -122.39  |proj g|=       0.50114
At iterate    33  f =      -122.39  |proj g|=       0.50083
At iterate    34  f =      -122.39  |proj g|=       0.50051
At iterate    35  f =      -122.39  |proj g|=       0.49988
At iterate    36  f =      -122.39  |proj g|=       0.49888
At iterate    37  f =      -122.39  |proj g|=       0.49681
At iterate    38  f =       -122.4  |proj g|=       0.49277
At iterate    39  f =      -122.42  |proj g|=       0.48395
At iterate    40  f =      -122.48  |proj g|=       0.46428
At iterate    41  f =      -122.63  |proj g|=       0.42083
At iterate    42  f =      -122.99  |proj g|=       0.33581
At iterate    43  f =      -123.34  |proj g|=       0.14374
At iterate    44  f =      -123.47  |proj g|=       0.82635
At iterate    45  f =      -123.48  |proj g|=       0.82635
At iterate    46  f =      -123.48  |proj g|=       0.82634
At iterate    47  f =      -123.48  |proj g|=       0.82634
At iterate    48  f =      -123.48  |proj g|=       0.82634
At iterate    49  f =      -123.48  |proj g|=       0.82634
At iterate    50  f =      -123.48  |proj g|=       0.82633
At iterate    51  f =      -123.48  |proj g|=       0.82632
At iterate    52  f =      -123.48  |proj g|=       0.82626
At iterate    53  f =      -123.49  |proj g|=       0.82613
At iterate    54  f =      -123.49  |proj g|=       0.82576
At iterate    55  f =      -123.49  |proj g|=       0.82478
At iterate    56  f =       -123.5  |proj g|=       0.82229
At iterate    57  f =      -123.53  |proj g|=       0.81668
At iterate    58  f =      -123.57  |proj g|=       0.80676
At iterate    59  f =       -123.6  |proj g|=       0.40023
At iterate    60  f =       -123.6  |proj g|=      0.076041
At iterate    61  f =       -123.6  |proj g|=       0.13337
At iterate    62  f =       -123.6  |proj g|=     0.0052431
At iterate    63  f =       -123.6  |proj g|=     0.0012737

iterations 63
function evaluations 76
segments explored during Cauchy searches 65
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00127373
final function value -123.6

F = -123.6
final  value -123.600158 
converged
 
INFO  [00:56:47.088] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:56:47.144] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:56:47.151] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:56:56.639] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:57:06.936] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:57:17.241] [mlr3]  Finished benchmark 
INFO  [00:57:17.308] [bbotk] Result of batch 12: 
INFO  [00:57:17.310] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:57:17.310] [bbotk]              2.718964                 6.026358                       0.1797256 
INFO  [00:57:17.310] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:57:17.310] [bbotk]                     3595        0.476 -0.9735355         <NA>   0.9680584 
INFO  [00:57:17.310] [bbotk]                                 uhash 
INFO  [00:57:17.310] [bbotk]  644bd99e-1b1a-4991-867f-9fe14451fce8 
DEBUG [00:57:17.960] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.302621e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  4.302621e-05 0.005941262 
  - best initial criterion value(s) :  121.0617 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -121.06  |proj g|=      0.89246
At iterate     1  f =       -122.3  |proj g|=       0.39341
At iterate     2  f =      -123.13  |proj g|=       0.83259
At iterate     3  f =       -123.2  |proj g|=       0.82332
At iterate     4  f =      -123.26  |proj g|=       0.70448
At iterate     5  f =      -123.26  |proj g|=        0.4309
At iterate     6  f =      -123.26  |proj g|=       0.43005
At iterate     7  f =      -123.26  |proj g|=       0.43001
At iterate     8  f =      -123.26  |proj g|=       0.42994
At iterate     9  f =      -123.26  |proj g|=       0.42994

iterations 9
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.429938
final function value -123.263

F = -123.263
final  value -123.263120 
converged
 
INFO  [00:57:17.964] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:57:18.019] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:57:18.026] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:57:20.293] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:57:22.616] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:57:24.756] [mlr3]  Finished benchmark 
INFO  [00:57:24.823] [bbotk] Result of batch 13: 
INFO  [00:57:24.825] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:57:24.825] [bbotk]              6.599454                 8.994685                       0.3700591 
INFO  [00:57:24.825] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:57:24.825] [bbotk]                      696        0.486 -0.9746862         <NA>   0.9724967 
INFO  [00:57:24.825] [bbotk]                                 uhash 
INFO  [00:57:24.825] [bbotk]  fac7a342-1cda-458f-8b51-e9a55d01e639 
DEBUG [00:57:25.541] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.207903e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  4.207903e-05 0.005677346 
  - best initial criterion value(s) :  124.1779 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -124.18  |proj g|=       0.9721
At iterate     1  f =       -124.4  |proj g|=        1.0435
At iterate     2  f =      -124.41  |proj g|=        1.0361
At iterate     3  f =      -124.41  |proj g|=        1.0337
At iterate     4  f =      -124.41  |proj g|=        1.0325
At iterate     5  f =      -124.41  |proj g|=        1.0304
At iterate     6  f =      -124.42  |proj g|=         1.028
At iterate     7  f =      -124.42  |proj g|=        1.0281
At iterate     8  f =      -124.42  |proj g|=        1.0314
At iterate     9  f =      -124.42  |proj g|=        1.0332
At iterate    10  f =      -124.42  |proj g|=        1.0336
At iterate    11  f =      -124.42  |proj g|=        1.0337
At iterate    12  f =      -124.42  |proj g|=        1.0338
At iterate    13  f =      -124.42  |proj g|=        1.0342
At iterate    14  f =      -124.42  |proj g|=        1.0348
At iterate    15  f =      -124.42  |proj g|=        1.0356
At iterate    16  f =      -124.42  |proj g|=        1.0368
At iterate    17  f =      -124.43  |proj g|=        1.0379
At iterate    18  f =      -124.43  |proj g|=        1.0385
At iterate    19  f =      -124.44  |proj g|=        1.0375
At iterate    20  f =      -124.46  |proj g|=        1.0336
At iterate    21  f =       -124.5  |proj g|=        1.0053
At iterate    22  f =      -124.56  |proj g|=       0.97365
At iterate    23  f =      -124.78  |proj g|=       0.95657
At iterate    24  f =      -126.95  |proj g|=       0.63675
At iterate    25  f =      -129.02  |proj g|=        0.4347
At iterate    26  f =      -130.32  |proj g|=       0.37473
At iterate    27  f =      -130.36  |proj g|=       0.40241
At iterate    28  f =      -130.38  |proj g|=       0.75941
At iterate    29  f =      -130.38  |proj g|=       0.80619
At iterate    30  f =      -130.38  |proj g|=        0.8025
At iterate    31  f =      -130.38  |proj g|=       0.42794
At iterate    32  f =      -130.38  |proj g|=       0.42678
At iterate    33  f =      -130.38  |proj g|=       0.42612
At iterate    34  f =      -130.38  |proj g|=       0.42599
At iterate    35  f =      -130.38  |proj g|=       0.42599

iterations 35
function evaluations 39
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.425989
final function value -130.384

F = -130.384
final  value -130.383626 
converged
 
INFO  [00:57:25.545] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:57:25.605] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:57:25.612] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:57:30.699] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:57:34.776] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:57:39.509] [mlr3]  Finished benchmark 
INFO  [00:57:39.576] [bbotk] Result of batch 14: 
INFO  [00:57:39.578] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:57:39.578] [bbotk]              9.428241                 3.229638                        0.368742 
INFO  [00:57:39.578] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:57:39.578] [bbotk]                     1697        0.504 -0.9724439         <NA>   0.9758121 
INFO  [00:57:39.578] [bbotk]                                 uhash 
INFO  [00:57:39.578] [bbotk]  9303488e-312f-4410-be22-a43544c2e231 
DEBUG [00:57:40.295] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.126683e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  4.126683e-05 0.005603195 
  - best initial criterion value(s) :  121.7402 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -121.74  |proj g|=      0.90359
At iterate     1  f =      -124.89  |proj g|=        1.0781
At iterate     2  f =      -125.09  |proj g|=        1.1092
At iterate     3  f =      -125.09  |proj g|=        1.1055
At iterate     4  f =      -125.09  |proj g|=        1.1039
At iterate     5  f =      -125.09  |proj g|=        1.1039
At iterate     6  f =      -125.09  |proj g|=        1.1038
At iterate     7  f =      -125.09  |proj g|=        1.1037

iterations 7
function evaluations 11
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.10375
final function value -125.094

F = -125.094
final  value -125.093921 
converged
 
INFO  [00:57:40.299] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:57:40.357] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:57:40.364] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:57:44.602] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:57:48.522] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:57:52.699] [mlr3]  Finished benchmark 
INFO  [00:57:52.767] [bbotk] Result of batch 15: 
INFO  [00:57:52.769] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:57:52.769] [bbotk]              8.367082                 5.444035                       0.2148237 
INFO  [00:57:52.769] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:57:52.769] [bbotk]                     1447        0.535 -0.9804047         <NA>   0.9734656 
INFO  [00:57:52.769] [bbotk]                                 uhash 
INFO  [00:57:52.769] [bbotk]  189e21f7-dbb2-4836-a83a-2ae96a60d7df 
DEBUG [00:57:53.452] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 4.041624e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  4.041624e-05 0.00538614 
  - best initial criterion value(s) :  126.9057 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -126.91  |proj g|=       1.3646
At iterate     1  f =      -129.02  |proj g|=       0.64861
At iterate     2  f =      -129.96  |proj g|=        0.7322
At iterate     3  f =      -131.05  |proj g|=       0.74771
At iterate     4  f =      -131.24  |proj g|=       0.72501
At iterate     5  f =       -132.6  |proj g|=       0.56544
At iterate     6  f =      -133.38  |proj g|=       0.71107
At iterate     7  f =      -133.99  |proj g|=       0.55196
At iterate     8  f =      -134.05  |proj g|=       0.54558
At iterate     9  f =      -134.07  |proj g|=       0.70353
At iterate    10  f =      -134.07  |proj g|=       0.54807
At iterate    11  f =      -134.07  |proj g|=       0.54775
At iterate    12  f =      -134.07  |proj g|=       0.54781
At iterate    13  f =      -134.07  |proj g|=       0.54781

iterations 13
function evaluations 20
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.547809
final function value -134.073

F = -134.073
final  value -134.073127 
converged
 
INFO  [00:57:53.457] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:57:53.512] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:57:53.519] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:58:04.216] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:58:15.413] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:58:26.387] [mlr3]  Finished benchmark 
INFO  [00:58:26.458] [bbotk] Result of batch 16: 
INFO  [00:58:26.460] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:58:26.460] [bbotk]              6.268128                  2.31025                       0.2868218 
INFO  [00:58:26.460] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:58:26.460] [bbotk]                     3716        0.498 -0.9760386         <NA>   0.9776685 
INFO  [00:58:26.460] [bbotk]                                 uhash 
INFO  [00:58:26.460] [bbotk]  2309ab4d-0f5a-4a85-b806-657112a96cd5 
DEBUG [00:58:27.144] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.973416e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  3.973416e-05 0.0053469 
  - best initial criterion value(s) :  142.2136 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -142.21  |proj g|=      0.41592
At iterate     1  f =       -143.3  |proj g|=       0.80692
At iterate     2  f =       -143.3  |proj g|=       0.80655
At iterate     3  f =       -143.3  |proj g|=       0.80622
At iterate     4  f =       -143.3  |proj g|=       0.80555
At iterate     5  f =      -143.31  |proj g|=        0.8038
At iterate     6  f =      -143.32  |proj g|=       0.79839
At iterate     7  f =      -143.32  |proj g|=       0.79362
At iterate     8  f =      -143.32  |proj g|=        0.7919
At iterate     9  f =      -143.32  |proj g|=       0.79187
At iterate    10  f =      -143.32  |proj g|=       0.79196
At iterate    11  f =      -143.32  |proj g|=       0.79199

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.791986
final function value -143.322

F = -143.322
final  value -143.321602 
converged
 
INFO  [00:58:27.148] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:58:27.232] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:58:27.244] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:58:33.808] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:58:40.523] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:58:47.180] [mlr3]  Finished benchmark 
INFO  [00:58:47.285] [bbotk] Result of batch 17: 
INFO  [00:58:47.287] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:58:47.287] [bbotk]               6.69422                 8.641125                       0.4616331 
INFO  [00:58:47.287] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:58:47.287] [bbotk]                     2350        0.496 -0.9714535         <NA>   0.9778734 
INFO  [00:58:47.287] [bbotk]                                 uhash 
INFO  [00:58:47.287] [bbotk]  882818ac-7fa3-487f-af3f-fd84493904b6 
DEBUG [00:58:48.036] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.908121e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  3.908121e-05 0.005304674 
  - best initial criterion value(s) :  144.1843 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -144.18  |proj g|=      0.56798
At iterate     1  f =      -145.16  |proj g|=       0.86405
At iterate     2  f =      -145.42  |proj g|=       0.86292
At iterate     3  f =       -145.5  |proj g|=       0.86132
At iterate     4  f =      -145.51  |proj g|=       0.86156
At iterate     5  f =      -145.55  |proj g|=       0.86056
At iterate     6  f =      -145.69  |proj g|=       0.85595
At iterate     7  f =      -145.97  |proj g|=       0.84301
At iterate     8  f =      -146.23  |proj g|=       0.82556
At iterate     9  f =      -146.38  |proj g|=       0.80968
At iterate    10  f =      -146.42  |proj g|=       0.80129
At iterate    11  f =      -146.42  |proj g|=       0.79953
At iterate    12  f =      -146.42  |proj g|=        0.7994
At iterate    13  f =      -146.42  |proj g|=       0.79938
At iterate    14  f =      -146.42  |proj g|=       0.79939
At iterate    15  f =      -146.42  |proj g|=       0.79927
At iterate    16  f =      -146.42  |proj g|=       0.79891
At iterate    17  f =      -146.42  |proj g|=        0.7982
At iterate    18  f =      -146.42  |proj g|=       0.79707
At iterate    19  f =      -146.43  |proj g|=       0.79342
At iterate    20  f =      -146.43  |proj g|=       0.79151
At iterate    21  f =      -146.44  |proj g|=       0.78671
At iterate    22  f =      -146.48  |proj g|=       0.75772
At iterate    23  f =      -146.57  |proj g|=       0.74935
At iterate    24  f =      -146.77  |proj g|=       0.71982
At iterate    25  f =      -147.12  |proj g|=       0.65541
At iterate    26  f =      -147.63  |proj g|=       0.57028
At iterate    27  f =      -147.75  |proj g|=       0.53275
At iterate    28  f =      -148.26  |proj g|=       0.33031
At iterate    29  f =      -148.99  |proj g|=       0.26125
At iterate    30  f =      -149.14  |proj g|=       0.77356
At iterate    31  f =      -149.22  |proj g|=       0.20402
At iterate    32  f =      -149.22  |proj g|=       0.17558
At iterate    33  f =      -149.22  |proj g|=       0.17588
At iterate    34  f =      -149.22  |proj g|=       0.17588
At iterate    35  f =      -149.22  |proj g|=       0.17588

iterations 35
function evaluations 42
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.175881
final function value -149.219

F = -149.219
final  value -149.218638 
converged
 
INFO  [00:58:48.040] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:58:48.096] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:58:48.103] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:58:49.799] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:58:51.713] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:58:53.335] [mlr3]  Finished benchmark 
INFO  [00:58:53.404] [bbotk] Result of batch 18: 
INFO  [00:58:53.406] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:58:53.406] [bbotk]              5.080232                 3.599728                       0.4371741 
INFO  [00:58:53.406] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:58:53.406] [bbotk]                      481         0.54 -0.9717943         <NA>   0.9697005 
INFO  [00:58:53.406] [bbotk]                                 uhash 
INFO  [00:58:53.406] [bbotk]  86c98f7e-9eea-4e78-aeea-d2bd7e6dd967 
DEBUG [00:58:54.125] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.827015e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  3.827015e-05 0.005098097 
  - best initial criterion value(s) :  136.2556 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -136.26  |proj g|=       1.4668
At iterate     1  f =      -138.77  |proj g|=        1.0338
At iterate     2  f =      -139.01  |proj g|=       0.92971
At iterate     3  f =      -139.01  |proj g|=       0.90434
At iterate     4  f =      -139.01  |proj g|=       0.91291
At iterate     5  f =      -139.01  |proj g|=       0.91277
At iterate     6  f =      -139.01  |proj g|=       0.91278
At iterate     7  f =      -139.01  |proj g|=       0.91258
At iterate     8  f =      -139.01  |proj g|=       0.91258
At iterate     9  f =      -139.01  |proj g|=       0.91251
At iterate    10  f =      -139.01  |proj g|=       0.91193
At iterate    11  f =      -139.01  |proj g|=       0.91186
At iterate    12  f =      -139.01  |proj g|=       0.91163
At iterate    13  f =      -139.01  |proj g|=       0.91069
At iterate    14  f =      -139.02  |proj g|=       0.90645
At iterate    15  f =      -139.03  |proj g|=       0.89756
At iterate    16  f =      -139.05  |proj g|=        0.8772
At iterate    17  f =      -139.06  |proj g|=       0.81896
At iterate    18  f =      -139.12  |proj g|=       0.77635
At iterate    19  f =      -139.32  |proj g|=       0.74034
At iterate    20  f =       -139.7  |proj g|=       0.74334
At iterate    21  f =       -140.1  |proj g|=       0.73484
At iterate    22  f =      -140.28  |proj g|=       0.47649
At iterate    23  f =      -140.38  |proj g|=       0.47247
At iterate    24  f =      -141.04  |proj g|=        0.8196
At iterate    25  f =      -141.14  |proj g|=       0.83071
At iterate    26  f =      -141.32  |proj g|=       0.79755
At iterate    27  f =       -141.5  |proj g|=       0.80637
At iterate    28  f =      -141.56  |proj g|=       0.81269
At iterate    29  f =      -141.58  |proj g|=       0.80664
At iterate    30  f =      -141.58  |proj g|=       0.37982
At iterate    31  f =      -141.58  |proj g|=       0.38016
At iterate    32  f =      -141.58  |proj g|=       0.38017

iterations 32
function evaluations 40
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.380165
final function value -141.584

F = -141.584
final  value -141.584330 
converged
 
INFO  [00:58:54.129] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:58:54.187] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:58:54.194] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:59:05.742] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:59:18.410] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:59:30.642] [mlr3]  Finished benchmark 
INFO  [00:59:30.755] [bbotk] Result of batch 19: 
INFO  [00:59:30.757] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:59:30.757] [bbotk]              8.896078                 5.345376                       0.2879847 
INFO  [00:59:30.757] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:59:30.757] [bbotk]                     4135        0.498 -0.9796526         <NA>   0.9779673 
INFO  [00:59:30.757] [bbotk]                                 uhash 
INFO  [00:59:30.757] [bbotk]  6d8d378b-3113-44f3-b4c5-71cdf6551a49 
DEBUG [00:59:31.495] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.766887e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  3.766887e-05 0.00506681 
  - best initial criterion value(s) :  143.801 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -143.8  |proj g|=       1.4188
At iterate     1  f =      -148.62  |proj g|=       0.75158
At iterate     2  f =      -149.02  |proj g|=       0.97009
At iterate     3  f =      -149.28  |proj g|=       0.89815
At iterate     4  f =      -149.59  |proj g|=       0.80225
At iterate     5  f =      -149.86  |proj g|=       0.66889
At iterate     6  f =      -149.88  |proj g|=       0.50284
At iterate     7  f =      -149.88  |proj g|=       0.50522
At iterate     8  f =      -149.88  |proj g|=       0.62518
At iterate     9  f =      -149.88  |proj g|=       0.62297
At iterate    10  f =      -149.88  |proj g|=       0.62278
At iterate    11  f =      -149.88  |proj g|=       0.62207
At iterate    12  f =      -149.88  |proj g|=       0.60034
At iterate    13  f =      -149.88  |proj g|=       0.51681
At iterate    14  f =      -149.88  |proj g|=       0.42129
At iterate    15  f =      -149.89  |proj g|=       0.42256
At iterate    16  f =      -149.89  |proj g|=        0.4466
At iterate    17  f =      -149.89  |proj g|=       0.44219
At iterate    18  f =      -149.92  |proj g|=       0.42368
At iterate    19  f =         -150  |proj g|=       0.44112
At iterate    20  f =      -150.24  |proj g|=       0.49651
At iterate    21  f =      -151.04  |proj g|=       0.66541
At iterate    22  f =      -151.38  |proj g|=         0.901
At iterate    23  f =       -152.6  |proj g|=        1.0606
At iterate    24  f =      -153.54  |proj g|=        0.8149
At iterate    25  f =      -153.79  |proj g|=       0.62593
At iterate    26  f =      -153.82  |proj g|=       0.60263
At iterate    27  f =      -153.82  |proj g|=       0.60935
At iterate    28  f =      -153.82  |proj g|=        0.6053
At iterate    29  f =      -153.82  |proj g|=       0.60606
At iterate    30  f =      -153.82  |proj g|=       0.60594

iterations 30
function evaluations 40
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.605938
final function value -153.822

F = -153.822
final  value -153.821769 
converged
 
INFO  [00:59:31.499] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:59:31.557] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:59:31.564] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:59:33.251] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:59:34.618] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:59:36.268] [mlr3]  Finished benchmark 
INFO  [00:59:36.337] [bbotk] Result of batch 20: 
INFO  [00:59:36.339] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:59:36.339] [bbotk]              9.011557                 7.520786                       0.1243876 
INFO  [00:59:36.339] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:59:36.339] [bbotk]                      452        0.514 -0.9729639         <NA>   0.9582224 
INFO  [00:59:36.339] [bbotk]                                 uhash 
INFO  [00:59:36.339] [bbotk]  bc344f48-982b-469a-af0b-5b4b4f6762d5 
DEBUG [00:59:37.120] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.71298e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  3.71298e-05 0.004796082 
  - best initial criterion value(s) :  148.3226 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -148.32  |proj g|=       1.1106
At iterate     1  f =      -151.36  |proj g|=        1.4613
At iterate     2  f =      -151.37  |proj g|=        1.4553
At iterate     3  f =      -151.38  |proj g|=        1.4477
At iterate     4  f =      -151.38  |proj g|=        1.4472
At iterate     5  f =       -151.4  |proj g|=        1.4522
At iterate     6  f =      -151.41  |proj g|=         1.466
At iterate     7  f =      -151.41  |proj g|=        1.4787
At iterate     8  f =      -151.41  |proj g|=        1.4814
At iterate     9  f =      -151.41  |proj g|=        1.4816
At iterate    10  f =      -151.41  |proj g|=        1.4816
At iterate    11  f =      -151.41  |proj g|=         1.482
At iterate    12  f =      -151.42  |proj g|=        1.4823
At iterate    13  f =      -151.42  |proj g|=        1.4827
At iterate    14  f =      -151.42  |proj g|=         1.483
At iterate    15  f =      -151.42  |proj g|=        1.4819
At iterate    16  f =      -151.42  |proj g|=        1.4777
At iterate    17  f =      -151.43  |proj g|=        1.4746
At iterate    18  f =      -151.45  |proj g|=        1.4593
At iterate    19  f =      -151.46  |proj g|=        1.4632
At iterate    20  f =      -151.55  |proj g|=        1.4242
At iterate    21  f =      -151.78  |proj g|=        1.3224
At iterate    22  f =       -152.2  |proj g|=        1.1939
At iterate    23  f =      -154.07  |proj g|=       0.84788
At iterate    24  f =      -156.29  |proj g|=       0.83707
At iterate    25  f =      -156.82  |proj g|=       0.91674
At iterate    26  f =      -156.88  |proj g|=       0.91767
At iterate    27  f =       -156.9  |proj g|=        1.0062
At iterate    28  f =      -156.92  |proj g|=       0.98213
At iterate    29  f =      -156.92  |proj g|=        0.9819
At iterate    30  f =      -156.92  |proj g|=       0.98229
At iterate    31  f =      -156.92  |proj g|=       0.98248
At iterate    32  f =      -156.92  |proj g|=       0.98265
At iterate    33  f =      -156.92  |proj g|=       0.98293
At iterate    34  f =      -156.92  |proj g|=       0.98334
At iterate    35  f =      -156.92  |proj g|=       0.98407
At iterate    36  f =      -156.92  |proj g|=       0.98489
At iterate    37  f =      -156.92  |proj g|=       0.98635
At iterate    38  f =      -156.92  |proj g|=        0.9867
At iterate    39  f =      -156.92  |proj g|=       0.99037
At iterate    40  f =      -156.92  |proj g|=       0.99052
At iterate    41  f =      -157.24  |proj g|=       0.88241
At iterate    42  f =      -158.49  |proj g|=       0.47136
At iterate    43  f =      -159.35  |proj g|=       0.29315
At iterate    44  f =      -160.03  |proj g|=       0.79012
At iterate    45  f =      -160.08  |proj g|=       0.17935
At iterate    46  f =       -160.2  |proj g|=       0.17807
At iterate    47  f =       -160.2  |proj g|=       0.17722
At iterate    48  f =      -160.21  |proj g|=       0.17362
At iterate    49  f =      -160.21  |proj g|=      0.073264
At iterate    50  f =      -160.21  |proj g|=     0.0033081
At iterate    51  f =      -160.21  |proj g|=    0.00097986

iterations 51
function evaluations 59
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000979862
final function value -160.206

F = -160.206
final  value -160.206447 
converged
 
INFO  [00:59:37.124] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:59:37.183] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:59:37.191] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [00:59:41.293] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [00:59:45.883] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:59:49.861] [mlr3]  Finished benchmark 
INFO  [00:59:49.932] [bbotk] Result of batch 21: 
INFO  [00:59:49.934] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [00:59:49.934] [bbotk]               6.18623                 2.973499                       0.2058374 
INFO  [00:59:49.934] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [00:59:49.934] [bbotk]                     1594        0.542 -0.9698228         <NA>   0.9736147 
INFO  [00:59:49.934] [bbotk]                                 uhash 
INFO  [00:59:49.934] [bbotk]  537dd549-94b6-4bff-a9b5-9c05f65343ff 
DEBUG [00:59:50.658] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.645262e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  3.645262e-05 0.004743318 
  - best initial criterion value(s) :  147.1997 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -147.2  |proj g|=      0.94374
At iterate     1  f =      -155.97  |proj g|=        1.0976
At iterate     2  f =       -157.3  |proj g|=        1.4482
At iterate     3  f =      -158.97  |proj g|=        1.3123
At iterate     4  f =      -159.17  |proj g|=        1.2639
At iterate     5  f =      -159.27  |proj g|=        1.2993
At iterate     6  f =       -159.3  |proj g|=         1.297
At iterate     7  f =      -159.31  |proj g|=         1.293
At iterate     8  f =      -159.31  |proj g|=         1.294
At iterate     9  f =      -159.31  |proj g|=        1.2939
At iterate    10  f =      -159.31  |proj g|=        1.2939

iterations 10
function evaluations 16
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.2939
final function value -159.306

F = -159.306
final  value -159.305513 
converged
 
INFO  [00:59:50.663] [bbotk] Evaluating 1 configuration(s) 
INFO  [00:59:50.721] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [00:59:50.924] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [00:59:57.203] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:00:02.896] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:00:11.024] [mlr3]  Finished benchmark 
INFO  [01:00:11.095] [bbotk] Result of batch 22: 
INFO  [01:00:11.097] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:00:11.097] [bbotk]              4.340732                 9.262948                        0.258415 
INFO  [01:00:11.097] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:00:11.097] [bbotk]                     2273        0.525 -0.9721334         <NA>   0.9742836 
INFO  [01:00:11.097] [bbotk]                                 uhash 
INFO  [01:00:11.097] [bbotk]  cea80250-dcb0-479d-8810-185e564a34e0 
DEBUG [01:00:11.847] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.581319e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  3.581319e-05 0.004710681 
  - best initial criterion value(s) :  145.8317 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -145.83  |proj g|=      0.35934
At iterate     1  f =       -148.8  |proj g|=       0.47749
At iterate     2  f =         -149  |proj g|=       0.43472
At iterate     3  f =      -149.13  |proj g|=       0.34168
At iterate     4  f =      -149.16  |proj g|=       0.36158
At iterate     5  f =      -149.42  |proj g|=       0.44415
At iterate     6  f =      -150.07  |proj g|=       0.77519
At iterate     7  f =      -150.72  |proj g|=       0.79162
At iterate     8  f =      -151.49  |proj g|=       0.82443
At iterate     9  f =       -151.5  |proj g|=       0.51018
At iterate    10  f =       -151.5  |proj g|=       0.51093
At iterate    11  f =       -151.5  |proj g|=       0.51058
At iterate    12  f =       -151.5  |proj g|=       0.51058

iterations 12
function evaluations 19
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.510577
final function value -151.5

F = -151.5
final  value -151.500278 
converged
 
INFO  [01:00:11.851] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:00:11.913] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:00:11.921] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:00:23.272] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:00:31.832] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:00:40.123] [mlr3]  Finished benchmark 
INFO  [01:00:40.194] [bbotk] Result of batch 23: 
INFO  [01:00:40.196] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:00:40.196] [bbotk]              8.122536                 8.073066                       0.3775299 
INFO  [01:00:40.196] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:00:40.196] [bbotk]                     3117        0.542 -0.9803884         <NA>   0.9778171 
INFO  [01:00:40.196] [bbotk]                                 uhash 
INFO  [01:00:40.196] [bbotk]  3927aa1a-fb75-4522-a462-6c0f076ea9d3 
DEBUG [01:00:40.913] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.529212e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  3.529212e-05 0.004691256 
  - best initial criterion value(s) :  159.6849 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -159.68  |proj g|=      0.56672
At iterate     1  f =      -166.22  |proj g|=        1.3955
At iterate     2  f =      -167.82  |proj g|=        1.3173
At iterate     3  f =      -170.58  |proj g|=       0.95673
At iterate     4  f =      -170.69  |proj g|=       0.85861
At iterate     5  f =      -170.75  |proj g|=       0.84544
At iterate     6  f =      -170.97  |proj g|=       0.83058
At iterate     7  f =      -171.01  |proj g|=       0.85109
At iterate     8  f =      -171.01  |proj g|=       0.83619
At iterate     9  f =      -171.01  |proj g|=       0.83381
At iterate    10  f =      -171.01  |proj g|=       0.83388
At iterate    11  f =      -171.01  |proj g|=       0.83396

iterations 11
function evaluations 16
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.833959
final function value -171.01

F = -171.01
final  value -171.010484 
converged
 
INFO  [01:00:40.917] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:00:41.410] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:00:41.417] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:00:53.152] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:01:04.390] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:01:14.648] [mlr3]  Finished benchmark 
INFO  [01:01:14.748] [bbotk] Result of batch 24: 
INFO  [01:01:14.750] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:01:14.750] [bbotk]              5.593526                 4.873715                      0.09908703 
INFO  [01:01:14.750] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:01:14.750] [bbotk]                     3138        0.523 -0.9721281         <NA>   0.9729764 
INFO  [01:01:14.750] [bbotk]                                 uhash 
INFO  [01:01:14.750] [bbotk]  ad7e0d63-65b5-4732-98d3-52983828e90f 
DEBUG [01:01:15.549] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.466955e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  3.466955e-05 0.004643927 
  - best initial criterion value(s) :  151.1298 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -151.13  |proj g|=      0.23476
At iterate     1  f =      -153.75  |proj g|=        3.1899
At iterate     2  f =      -161.21  |proj g|=        2.2604
At iterate     3  f =      -161.25  |proj g|=        2.3685
At iterate     4  f =      -161.25  |proj g|=        2.3679
At iterate     5  f =      -161.25  |proj g|=        2.3665
At iterate     6  f =      -161.25  |proj g|=        2.3653
At iterate     7  f =      -161.25  |proj g|=        2.3649
At iterate     8  f =      -161.25  |proj g|=        2.3664
At iterate     9  f =      -161.25  |proj g|=        2.3679
At iterate    10  f =      -161.25  |proj g|=        2.3686
At iterate    11  f =      -161.25  |proj g|=         2.369
At iterate    12  f =      -161.25  |proj g|=        2.3698
At iterate    13  f =      -161.25  |proj g|=        2.3711
At iterate    14  f =      -161.25  |proj g|=        2.3732
At iterate    15  f =      -161.25  |proj g|=        2.3765
At iterate    16  f =      -161.25  |proj g|=        2.3817
At iterate    17  f =      -161.25  |proj g|=        2.3899
At iterate    18  f =      -161.26  |proj g|=        2.4019
At iterate    19  f =      -161.27  |proj g|=         2.418
At iterate    20  f =       -161.3  |proj g|=         2.434
At iterate    21  f =      -161.38  |proj g|=        2.4323
At iterate    22  f =      -161.57  |proj g|=        2.3635
At iterate    23  f =      -161.94  |proj g|=        2.0757
At iterate    24  f =      -162.05  |proj g|=        1.8264
At iterate    25  f =      -162.06  |proj g|=        1.7785
At iterate    26  f =      -162.06  |proj g|=        1.7771
At iterate    27  f =      -162.06  |proj g|=        1.7784
At iterate    28  f =      -162.06  |proj g|=        1.7773
At iterate    29  f =      -162.06  |proj g|=        1.7748
At iterate    30  f =      -162.06  |proj g|=        1.7711
At iterate    31  f =      -162.07  |proj g|=        1.7636
At iterate    32  f =      -162.08  |proj g|=        1.7533
At iterate    33  f =      -162.13  |proj g|=        1.7454
At iterate    34  f =      -162.23  |proj g|=        1.7469
At iterate    35  f =      -162.48  |proj g|=        1.7377
At iterate    36  f =      -163.14  |proj g|=         1.477
At iterate    37  f =      -164.89  |proj g|=        1.1588
At iterate    38  f =      -167.93  |proj g|=       0.85169
At iterate    39  f =         -173  |proj g|=       0.84714
At iterate    40  f =      -174.93  |proj g|=       0.83511
At iterate    41  f =      -175.03  |proj g|=       0.83511
At iterate    42  f =      -175.15  |proj g|=       0.83511
At iterate    43  f =      -175.28  |proj g|=       0.83043
At iterate    44  f =      -175.55  |proj g|=       0.81069
At iterate    45  f =      -175.57  |proj g|=       0.62953
At iterate    46  f =      -175.57  |proj g|=       0.62936
At iterate    47  f =      -175.57  |proj g|=       0.62933
At iterate    48  f =      -175.57  |proj g|=       0.62932
At iterate    49  f =      -175.57  |proj g|=       0.62927
At iterate    50  f =      -175.57  |proj g|=       0.62896
At iterate    51  f =      -175.58  |proj g|=        0.6278
At iterate    52  f =      -175.58  |proj g|=       0.62494
At iterate    53  f =      -175.58  |proj g|=       0.61709
At iterate    54  f =      -175.59  |proj g|=       0.59694
At iterate    55  f =      -175.61  |proj g|=       0.54673
At iterate    56  f =      -175.65  |proj g|=       0.42452
At iterate    57  f =      -175.67  |proj g|=       0.67382
At iterate    58  f =      -175.77  |proj g|=        0.1948
At iterate    59  f =      -175.87  |proj g|=       0.19635
At iterate    60  f =      -175.97  |proj g|=       0.18616
At iterate    61  f =      -176.05  |proj g|=       0.17148
At iterate    62  f =      -176.07  |proj g|=       0.80183
At iterate    63  f =      -176.07  |proj g|=      0.031193
At iterate    64  f =      -176.07  |proj g|=     0.0029389
At iterate    65  f =      -176.07  |proj g|=     0.0029388

iterations 65
function evaluations 71
segments explored during Cauchy searches 67
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0029388
final function value -176.069

F = -176.069
final  value -176.068872 
converged
 
INFO  [01:01:15.553] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:01:15.608] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:01:15.615] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:01:29.268] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:01:40.248] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:01:49.379] [mlr3]  Finished benchmark 
INFO  [01:01:49.446] [bbotk] Result of batch 25: 
INFO  [01:01:49.448] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:01:49.448] [bbotk]              7.826885                 9.851822                      0.02014054 
INFO  [01:01:49.448] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:01:49.448] [bbotk]                     4563        0.522 -0.9708788         <NA>   0.9639439 
INFO  [01:01:49.448] [bbotk]                                 uhash 
INFO  [01:01:49.448] [bbotk]  2f51a70f-db5c-4eb3-b881-6f3d22905ada 
DEBUG [01:01:50.323] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.408346e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.22146 15.65764 0.9700868 9498 
  - variance bounds :  3.408346e-05 0.004585812 
  - best initial criterion value(s) :  158.9789 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -158.98  |proj g|=       6.8931
At iterate     1  f =      -161.06  |proj g|=         6.075
At iterate     2  f =      -164.61  |proj g|=        4.7757
At iterate     3  f =       -166.7  |proj g|=        2.4642
At iterate     4  f =       -168.8  |proj g|=        2.0935
At iterate     5  f =      -168.86  |proj g|=        1.9313
At iterate     6  f =      -168.87  |proj g|=        1.8701
At iterate     7  f =      -168.87  |proj g|=        1.8774
At iterate     8  f =      -168.87  |proj g|=         1.882
At iterate     9  f =      -168.88  |proj g|=        1.8912
At iterate    10  f =      -168.88  |proj g|=        1.9078
At iterate    11  f =      -168.89  |proj g|=         1.934
At iterate    12  f =       -168.9  |proj g|=        1.9783
At iterate    13  f =      -168.95  |proj g|=        2.0211
At iterate    14  f =      -169.07  |proj g|=        2.1559
At iterate    15  f =       -169.1  |proj g|=        2.0872
At iterate    16  f =      -169.36  |proj g|=        2.1442
At iterate    17  f =      -177.75  |proj g|=        1.2874
At iterate    18  f =       -177.8  |proj g|=        1.2948
At iterate    19  f =      -177.85  |proj g|=        1.3112
At iterate    20  f =      -177.87  |proj g|=        1.3246
At iterate    21  f =      -177.88  |proj g|=        1.3346
At iterate    22  f =      -177.88  |proj g|=        1.3354
At iterate    23  f =      -177.88  |proj g|=         1.336
At iterate    24  f =      -177.88  |proj g|=        1.3362
At iterate    25  f =      -177.88  |proj g|=        1.3362

iterations 25
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.3362
final function value -177.884

F = -177.884
final  value -177.884332 
converged
 
INFO  [01:01:50.327] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:01:50.383] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:01:50.389] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:01:52.684] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:01:55.020] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:01:57.330] [mlr3]  Finished benchmark 
INFO  [01:01:57.407] [bbotk] Result of batch 26: 
INFO  [01:01:57.409] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:01:57.409] [bbotk]              9.814036                 8.668519                       0.4947869 
INFO  [01:01:57.409] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:01:57.409] [bbotk]                     1082         0.63 -0.9713805         <NA>   0.9747633 
INFO  [01:01:57.409] [bbotk]                                 uhash 
INFO  [01:01:57.409] [bbotk]  830091e6-bfa7-4f86-b946-19eeb1d4bd98 
DEBUG [01:01:58.190] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.353651e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.65764 0.9865363 9498 
  - variance bounds :  3.353651e-05 0.004429801 
  - best initial criterion value(s) :  165.206 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -165.21  |proj g|=       2.1664
At iterate     1  f =      -165.61  |proj g|=        1.1595
At iterate     2  f =      -167.59  |proj g|=        2.2922
At iterate     3  f =      -169.01  |proj g|=         2.079
At iterate     4  f =      -169.27  |proj g|=          2.06
At iterate     5  f =       -169.6  |proj g|=        2.3118
At iterate     6  f =      -169.61  |proj g|=        2.3118
At iterate     7  f =      -169.62  |proj g|=        2.3054
At iterate     8  f =      -169.62  |proj g|=        2.3067
At iterate     9  f =      -169.62  |proj g|=        2.3033
At iterate    10  f =      -169.62  |proj g|=        2.2988
At iterate    11  f =      -169.62  |proj g|=        2.2845
At iterate    12  f =      -169.63  |proj g|=        2.2644
At iterate    13  f =      -169.66  |proj g|=        2.2279
At iterate    14  f =      -169.73  |proj g|=        2.1663
At iterate    15  f =       -169.9  |proj g|=        2.0709
At iterate    16  f =      -170.26  |proj g|=        1.9172
At iterate    17  f =      -171.12  |proj g|=        1.7235
At iterate    18  f =      -171.28  |proj g|=        1.6029
At iterate    19  f =      -172.86  |proj g|=         1.383
At iterate    20  f =      -182.29  |proj g|=       0.27059
At iterate    21  f =      -182.77  |proj g|=       0.82807
At iterate    22  f =      -182.83  |proj g|=       0.34826
At iterate    23  f =      -182.84  |proj g|=       0.34122
At iterate    24  f =      -182.84  |proj g|=       0.32924
At iterate    25  f =      -182.84  |proj g|=       0.33585
At iterate    26  f =      -182.84  |proj g|=       0.33577

iterations 26
function evaluations 35
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.33577
final function value -182.841

F = -182.841
final  value -182.840508 
converged
 
INFO  [01:01:58.194] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:01:58.256] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:01:58.264] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:02:06.305] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:02:14.369] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:02:22.482] [mlr3]  Finished benchmark 
INFO  [01:02:22.552] [bbotk] Result of batch 27: 
INFO  [01:02:22.554] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:02:22.554] [bbotk]              8.813718                 2.039425                      0.02694397 
INFO  [01:02:22.554] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:02:22.554] [bbotk]                     4152        0.543 -0.9718728         <NA>   0.9666531 
INFO  [01:02:22.554] [bbotk]                                 uhash 
INFO  [01:02:22.554] [bbotk]  c27d8b95-39c9-4b1e-a769-039610ac6ca8 
DEBUG [01:02:23.460] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.295715e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  3.295715e-05 0.004382017 
  - best initial criterion value(s) :  170.9303 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -170.93  |proj g|=        1.621
At iterate     1  f =      -172.29  |proj g|=        2.7188
At iterate     2  f =      -173.79  |proj g|=        2.6296
At iterate     3  f =      -175.22  |proj g|=        2.4044
At iterate     4  f =      -175.51  |proj g|=         2.218
At iterate     5  f =      -176.07  |proj g|=        2.2824
At iterate     6  f =      -177.23  |proj g|=        2.2914
At iterate     7  f =      -177.53  |proj g|=        2.2256
At iterate     8  f =      -177.53  |proj g|=        2.2148
At iterate     9  f =      -177.53  |proj g|=        2.2146
At iterate    10  f =      -177.54  |proj g|=        2.2125
At iterate    11  f =      -177.55  |proj g|=        2.2086
At iterate    12  f =      -177.59  |proj g|=        2.1951
At iterate    13  f =      -177.67  |proj g|=        2.1658
At iterate    14  f =      -177.91  |proj g|=        2.0985
At iterate    15  f =      -178.44  |proj g|=        1.9701
At iterate    16  f =      -179.38  |proj g|=        1.7728
At iterate    17  f =      -179.44  |proj g|=         1.704
At iterate    18  f =      -181.04  |proj g|=        1.4275
At iterate    19  f =      -188.08  |proj g|=       0.71905
At iterate    20  f =      -188.97  |proj g|=       0.69913
At iterate    21  f =      -188.97  |proj g|=       0.70253
At iterate    22  f =      -188.97  |proj g|=       0.70286
At iterate    23  f =      -188.97  |proj g|=       0.70399
At iterate    24  f =      -188.97  |proj g|=         0.704
At iterate    25  f =      -188.97  |proj g|=       0.70403
At iterate    26  f =      -188.97  |proj g|=       0.70419
At iterate    27  f =      -188.97  |proj g|=       0.70435
At iterate    28  f =      -188.97  |proj g|=       0.70449
At iterate    29  f =      -188.97  |proj g|=       0.70104
At iterate    30  f =      -188.98  |proj g|=        0.7078
At iterate    31  f =      -188.99  |proj g|=       0.68489
At iterate    32  f =      -189.07  |proj g|=       0.67303
At iterate    33  f =      -189.66  |proj g|=        0.5255
At iterate    34  f =      -190.36  |proj g|=       0.35588
At iterate    35  f =      -191.04  |proj g|=       0.19771
At iterate    36  f =      -191.35  |proj g|=       0.17305
At iterate    37  f =      -191.36  |proj g|=       0.82031
At iterate    38  f =      -191.37  |proj g|=       0.14205
At iterate    39  f =      -191.37  |proj g|=      0.010351
At iterate    40  f =      -191.37  |proj g|=    0.00082469

iterations 40
function evaluations 54
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000824687
final function value -191.374

F = -191.374
final  value -191.374221 
converged
 
INFO  [01:02:23.489] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:02:23.533] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:02:23.540] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:02:25.631] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:02:28.157] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:02:30.426] [mlr3]  Finished benchmark 
INFO  [01:02:30.517] [bbotk] Result of batch 28: 
INFO  [01:02:30.519] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:02:30.519] [bbotk]              3.896794                 3.346363                      0.08233709 
INFO  [01:02:30.519] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:02:30.519] [bbotk]                      971        0.623 -0.9696323         <NA>   0.9573011 
INFO  [01:02:30.519] [bbotk]                                 uhash 
INFO  [01:02:30.519] [bbotk]  bc7c121a-b6a7-442b-b067-97847b2e9305 
DEBUG [01:02:31.365] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.261689e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  3.261689e-05 0.004280579 
  - best initial criterion value(s) :  179.4691 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -179.47  |proj g|=       1.3488
At iterate     1  f =      -181.63  |proj g|=        1.5379
At iterate     2  f =      -181.68  |proj g|=        1.5277
At iterate     3  f =       -181.8  |proj g|=        1.4964
At iterate     4  f =      -181.91  |proj g|=        1.4778
At iterate     5  f =      -182.51  |proj g|=        1.3668
At iterate     6  f =      -183.08  |proj g|=        1.3176
At iterate     7  f =      -183.31  |proj g|=        1.3055
At iterate     8  f =      -183.33  |proj g|=        1.3126
At iterate     9  f =      -183.33  |proj g|=        1.3081
At iterate    10  f =      -183.33  |proj g|=        1.3091
At iterate    11  f =      -183.33  |proj g|=        1.3092
At iterate    12  f =      -183.33  |proj g|=        1.3102
At iterate    13  f =      -183.33  |proj g|=        1.3113
At iterate    14  f =      -183.33  |proj g|=        1.3133
At iterate    15  f =      -183.33  |proj g|=        1.3164
At iterate    16  f =      -183.33  |proj g|=        1.3215
At iterate    17  f =      -183.35  |proj g|=        1.3292
At iterate    18  f =      -183.37  |proj g|=        1.3392
At iterate    19  f =      -183.43  |proj g|=        1.3505
At iterate    20  f =      -183.54  |proj g|=        1.3635
At iterate    21  f =      -183.81  |proj g|=         1.358
At iterate    22  f =      -184.39  |proj g|=        1.3229
At iterate    23  f =      -185.52  |proj g|=        1.1979
At iterate    24  f =      -187.68  |proj g|=       0.88443
At iterate    25  f =       -188.2  |proj g|=       0.78969
At iterate    26  f =      -190.13  |proj g|=       0.58944
At iterate    27  f =      -191.23  |proj g|=         0.392
At iterate    28  f =      -193.25  |proj g|=       0.48758
At iterate    29  f =      -193.34  |proj g|=       0.82237
At iterate    30  f =      -193.48  |proj g|=       0.82746
At iterate    31  f =      -193.49  |proj g|=       0.59181
At iterate    32  f =      -193.49  |proj g|=       0.60253
At iterate    33  f =      -193.49  |proj g|=       0.60228
At iterate    34  f =      -193.49  |proj g|=       0.60194
At iterate    35  f =      -193.49  |proj g|=       0.60185

iterations 35
function evaluations 41
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.601851
final function value -193.492

F = -193.492
final  value -193.492341 
converged
 
INFO  [01:02:31.369] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:02:31.427] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:02:31.434] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:02:38.837] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:02:46.127] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:02:53.242] [mlr3]  Finished benchmark 
INFO  [01:02:53.310] [bbotk] Result of batch 29: 
INFO  [01:02:53.312] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:02:53.312] [bbotk]              6.398347                 7.722711                       0.4605759 
INFO  [01:02:53.312] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:02:53.312] [bbotk]                     3525        0.589 -0.9700035         <NA>   0.9788175 
INFO  [01:02:53.312] [bbotk]                                 uhash 
INFO  [01:02:53.312] [bbotk]  124d68ae-4430-4f10-abf1-665327a2fd7f 
DEBUG [01:02:54.072] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.22346e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  3.22346e-05 0.004262107 
  - best initial criterion value(s) :  189.7556 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -189.76  |proj g|=      0.75083
At iterate     1  f =      -191.68  |proj g|=        1.0876
At iterate     2  f =      -193.47  |proj g|=        1.0625
At iterate     3  f =      -194.65  |proj g|=       0.99942
At iterate     4  f =      -194.67  |proj g|=       0.99046
At iterate     5  f =      -194.74  |proj g|=        1.0053
At iterate     6  f =      -194.84  |proj g|=        1.0477
At iterate     7  f =      -194.85  |proj g|=        1.0571
At iterate     8  f =      -194.85  |proj g|=        1.0593
At iterate     9  f =      -194.85  |proj g|=        1.0594
At iterate    10  f =      -194.85  |proj g|=        1.0596
At iterate    11  f =      -194.85  |proj g|=        1.0598
At iterate    12  f =      -194.85  |proj g|=        1.0602
At iterate    13  f =      -194.85  |proj g|=        1.0607
At iterate    14  f =      -194.85  |proj g|=        1.0616
At iterate    15  f =      -194.85  |proj g|=        1.0632
At iterate    16  f =      -194.85  |proj g|=        1.0658
At iterate    17  f =      -194.85  |proj g|=        1.0694
At iterate    18  f =      -194.85  |proj g|=        1.0723
At iterate    19  f =      -194.86  |proj g|=         1.075
At iterate    20  f =      -194.86  |proj g|=        1.0719
At iterate    21  f =      -194.86  |proj g|=        1.0761
At iterate    22  f =      -194.89  |proj g|=        1.0788
At iterate    23  f =         -195  |proj g|=        1.0726
At iterate    24  f =      -195.22  |proj g|=        1.0368
At iterate    25  f =      -195.56  |proj g|=       0.95485
At iterate    26  f =      -195.58  |proj g|=       0.93448
At iterate    27  f =       -195.9  |proj g|=         0.842
At iterate    28  f =      -196.24  |proj g|=       0.82573
At iterate    29  f =      -196.54  |proj g|=       0.77016
At iterate    30  f =      -196.55  |proj g|=       0.82806
At iterate    31  f =      -196.55  |proj g|=       0.81006
At iterate    32  f =      -196.55  |proj g|=       0.80947
At iterate    33  f =      -196.55  |proj g|=       0.80947

iterations 33
function evaluations 39
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.809467
final function value -196.55

F = -196.55
final  value -196.550084 
converged
 
INFO  [01:02:54.076] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:02:54.138] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:02:54.146] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:03:04.160] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:03:16.655] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:03:27.329] [mlr3]  Finished benchmark 
INFO  [01:03:27.398] [bbotk] Result of batch 30: 
INFO  [01:03:27.400] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:03:27.400] [bbotk]              2.677588                 2.774228                       0.1794983 
INFO  [01:03:27.400] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:03:27.400] [bbotk]                     3872        0.542 -0.9715272         <NA>   0.9679823 
INFO  [01:03:27.400] [bbotk]                                 uhash 
INFO  [01:03:27.400] [bbotk]  f4efe09f-0fa0-44f8-a1c3-f69208bd503e 
DEBUG [01:03:28.157] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.169865e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  3.169865e-05 0.004214969 
  - best initial criterion value(s) :  196.6815 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -196.68  |proj g|=      0.92671
At iterate     1  f =       -201.1  |proj g|=       0.19083
At iterate     2  f =      -203.57  |proj g|=       0.83497
At iterate     3  f =      -203.62  |proj g|=       0.83209
At iterate     4  f =      -203.65  |proj g|=       0.54972
At iterate     5  f =      -203.65  |proj g|=       0.54975
At iterate     6  f =      -203.65  |proj g|=       0.54883
At iterate     7  f =      -203.65  |proj g|=       0.54853
At iterate     8  f =      -203.65  |proj g|=       0.54852

iterations 8
function evaluations 11
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.548518
final function value -203.649

F = -203.649
final  value -203.648991 
converged
 
INFO  [01:03:28.161] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:03:28.245] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:03:28.252] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:03:30.233] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:03:31.997] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:03:34.326] [mlr3]  Finished benchmark 
INFO  [01:03:34.395] [bbotk] Result of batch 31: 
INFO  [01:03:34.397] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:03:34.397] [bbotk]              9.212627                 9.316012                       0.1294408 
INFO  [01:03:34.397] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:03:34.397] [bbotk]                      634        0.558 -0.9695833         <NA>   0.9635747 
INFO  [01:03:34.397] [bbotk]                                 uhash 
INFO  [01:03:34.397] [bbotk]  7371537a-0812-420a-81cb-ef033e5d4d28 
DEBUG [01:03:35.161] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.122399e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  3.122399e-05 0.004103373 
  - best initial criterion value(s) :  199.4944 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -199.49  |proj g|=       0.9164
At iterate     1  f =      -201.05  |proj g|=        1.0646
At iterate     2  f =      -201.22  |proj g|=        1.1389
At iterate     3  f =      -202.86  |proj g|=        1.0829
At iterate     4  f =      -204.09  |proj g|=       0.96966
At iterate     5  f =       -204.7  |proj g|=       0.84381
At iterate     6  f =      -204.83  |proj g|=       0.89227
At iterate     7  f =      -204.84  |proj g|=       0.90622
At iterate     8  f =      -204.84  |proj g|=       0.90276
At iterate     9  f =      -204.84  |proj g|=       0.90268
At iterate    10  f =      -204.84  |proj g|=       0.90269

iterations 10
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.902689
final function value -204.841

F = -204.841
final  value -204.841488 
converged
 
INFO  [01:03:35.165] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:03:35.219] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:03:35.226] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:03:40.281] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:03:44.577] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:03:49.526] [mlr3]  Finished benchmark 
INFO  [01:03:49.595] [bbotk] Result of batch 32: 
INFO  [01:03:49.597] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:03:49.597] [bbotk]              5.531437                 6.060886                        0.234288 
INFO  [01:03:49.597] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:03:49.597] [bbotk]                     1664        0.563 -0.9709754         <NA>   0.9739461 
INFO  [01:03:49.597] [bbotk]                                 uhash 
INFO  [01:03:49.597] [bbotk]  c66717f1-e84b-4613-8b85-eeb169c61c2e 
DEBUG [01:03:50.459] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.076289e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  3.076289e-05 0.003978696 
  - best initial criterion value(s) :  197.8143 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -197.81  |proj g|=       2.7409
At iterate     1  f =      -198.36  |proj g|=         2.965
At iterate     2  f =      -198.61  |proj g|=        2.8382
At iterate     3  f =      -199.44  |proj g|=        2.1002
At iterate     4  f =      -199.83  |proj g|=        2.1348
At iterate     5  f =      -199.87  |proj g|=        2.0561
At iterate     6  f =      -199.88  |proj g|=        2.0887
At iterate     7  f =      -199.88  |proj g|=        2.0894
At iterate     8  f =      -199.88  |proj g|=        2.0923
At iterate     9  f =      -199.88  |proj g|=        2.0946
At iterate    10  f =      -199.88  |proj g|=        2.0988
At iterate    11  f =      -199.89  |proj g|=        2.1045
At iterate    12  f =       -199.9  |proj g|=        2.1098
At iterate    13  f =      -199.94  |proj g|=        2.1069
At iterate    14  f =      -200.03  |proj g|=        2.0714
At iterate    15  f =      -200.25  |proj g|=        1.9481
At iterate    16  f =      -200.66  |proj g|=        1.6727
At iterate    17  f =      -201.26  |proj g|=        1.1825
At iterate    18  f =      -201.31  |proj g|=        1.0717
At iterate    19  f =       -201.4  |proj g|=        1.1051
At iterate    20  f =      -201.92  |proj g|=        1.1266
At iterate    21  f =       -203.6  |proj g|=        1.1787
At iterate    22  f =       -206.8  |proj g|=        1.2328
At iterate    23  f =      -210.12  |proj g|=        1.1097
At iterate    24  f =      -211.91  |proj g|=        1.0894
At iterate    25  f =      -211.92  |proj g|=        1.0788
At iterate    26  f =      -211.93  |proj g|=        1.0706
At iterate    27  f =      -211.94  |proj g|=        1.0553
At iterate    28  f =      -211.94  |proj g|=        1.0567
At iterate    29  f =      -211.94  |proj g|=        1.0568
At iterate    30  f =      -211.94  |proj g|=        1.0574
At iterate    31  f =      -211.94  |proj g|=         1.058
At iterate    32  f =      -211.94  |proj g|=        1.0591
At iterate    33  f =      -211.94  |proj g|=        1.0609
At iterate    34  f =      -211.95  |proj g|=        1.0636
At iterate    35  f =      -211.95  |proj g|=        1.0676
At iterate    36  f =      -211.95  |proj g|=         1.073
At iterate    37  f =      -211.96  |proj g|=         1.078
At iterate    38  f =      -211.97  |proj g|=        1.0809
At iterate    39  f =      -212.03  |proj g|=        1.0837
At iterate    40  f =      -212.21  |proj g|=         1.074
At iterate    41  f =      -212.73  |proj g|=       0.87172
At iterate    42  f =      -213.25  |proj g|=       0.24161
At iterate    43  f =      -213.29  |proj g|=       0.23696
At iterate    44  f =      -213.65  |proj g|=       0.22065
At iterate    45  f =      -214.02  |proj g|=       0.81778
At iterate    46  f =      -214.08  |proj g|=       0.18649
At iterate    47  f =      -214.08  |proj g|=       0.18292
At iterate    48  f =      -214.08  |proj g|=       0.39482
At iterate    49  f =      -214.08  |proj g|=     0.0025757
At iterate    50  f =      -214.08  |proj g|=     0.0028606

iterations 50
function evaluations 58
segments explored during Cauchy searches 52
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0028606
final function value -214.082

F = -214.082
final  value -214.081619 
converged
 
INFO  [01:03:50.463] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:03:50.521] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:03:50.528] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:04:00.292] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:04:10.020] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:04:20.796] [mlr3]  Finished benchmark 
INFO  [01:04:20.865] [bbotk] Result of batch 33: 
INFO  [01:04:20.867] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:04:20.867] [bbotk]              3.472986                 5.324932                       0.3066384 
INFO  [01:04:20.867] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:04:20.867] [bbotk]                     3483        0.582 -0.9676843         <NA>   0.9748812 
INFO  [01:04:20.867] [bbotk]                                 uhash 
INFO  [01:04:20.867] [bbotk]  663fbc33-f09e-477a-8231-b356d56211f0 
DEBUG [01:04:21.741] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 3.033137e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  3.033137e-05 0.003950166 
  - best initial criterion value(s) :  201.841 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -201.84  |proj g|=       1.3399
At iterate     1  f =      -205.47  |proj g|=        1.6482
At iterate     2  f =      -205.51  |proj g|=        1.6394
At iterate     3  f =      -205.55  |proj g|=        1.6273
At iterate     4  f =      -205.58  |proj g|=        1.6294
At iterate     5  f =      -205.78  |proj g|=        1.6709
At iterate     6  f =      -205.97  |proj g|=        1.7424
At iterate     7  f =      -206.08  |proj g|=        1.8143
At iterate     8  f =      -206.09  |proj g|=        1.8368
At iterate     9  f =      -206.09  |proj g|=        1.8418
At iterate    10  f =      -206.09  |proj g|=        1.8422
At iterate    11  f =      -206.09  |proj g|=        1.8427
At iterate    12  f =      -206.09  |proj g|=        1.8435
At iterate    13  f =      -206.09  |proj g|=        1.8446
At iterate    14  f =      -206.09  |proj g|=        1.8461
At iterate    15  f =      -206.09  |proj g|=        1.8479
At iterate    16  f =      -206.09  |proj g|=        1.8494
At iterate    17  f =       -206.1  |proj g|=        1.8489
At iterate    18  f =      -206.12  |proj g|=        1.8404
At iterate    19  f =      -206.16  |proj g|=        1.8107
At iterate    20  f =      -206.25  |proj g|=         1.739
At iterate    21  f =       -206.3  |proj g|=         1.706
At iterate    22  f =      -206.32  |proj g|=        1.6448
At iterate    23  f =      -206.35  |proj g|=        1.6713
At iterate    24  f =      -206.51  |proj g|=        1.7086
At iterate    25  f =      -207.02  |proj g|=        1.7282
At iterate    26  f =      -208.07  |proj g|=        1.6371
At iterate    27  f =      -208.85  |proj g|=        1.4361
At iterate    28  f =      -210.21  |proj g|=         1.229
At iterate    29  f =      -210.69  |proj g|=        1.4423
At iterate    30  f =      -212.24  |proj g|=        1.6837
At iterate    31  f =      -212.37  |proj g|=        1.4707
At iterate    32  f =      -212.57  |proj g|=        1.6401
At iterate    33  f =      -212.57  |proj g|=        1.6711
At iterate    34  f =      -212.57  |proj g|=        1.6608
At iterate    35  f =      -212.57  |proj g|=        1.6604
At iterate    36  f =      -212.57  |proj g|=        1.6599
At iterate    37  f =      -212.57  |proj g|=        1.6553
At iterate    38  f =      -212.57  |proj g|=        1.6499
At iterate    39  f =      -212.58  |proj g|=         1.639
At iterate    40  f =      -212.58  |proj g|=        1.6212
At iterate    41  f =      -212.59  |proj g|=        1.5907
At iterate    42  f =      -212.63  |proj g|=        1.5431
At iterate    43  f =      -212.71  |proj g|=        1.4429
At iterate    44  f =      -212.94  |proj g|=        1.2819
At iterate    45  f =      -212.98  |proj g|=         1.175
At iterate    46  f =       -213.5  |proj g|=       0.92736
At iterate    47  f =      -216.18  |proj g|=       0.20533
At iterate    48  f =      -216.87  |proj g|=       0.18547
At iterate    49  f =      -217.12  |proj g|=       0.80486
At iterate    50  f =      -217.22  |proj g|=       0.80108
At iterate    51  f =      -217.22  |proj g|=       0.79671
At iterate    52  f =      -217.24  |proj g|=       0.79358
At iterate    53  f =      -217.24  |proj g|=      0.017792
At iterate    54  f =      -217.24  |proj g|=     0.0024797
At iterate    55  f =      -217.24  |proj g|=     0.0014402

iterations 55
function evaluations 68
segments explored during Cauchy searches 57
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0014402
final function value -217.236

F = -217.236
final  value -217.235665 
converged
 
INFO  [01:04:21.746] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:04:21.802] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:04:21.971] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:04:29.242] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:04:35.998] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:04:42.340] [mlr3]  Finished benchmark 
INFO  [01:04:42.410] [bbotk] Result of batch 34: 
INFO  [01:04:42.411] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:04:42.411] [bbotk]              8.727184                 3.750672                       0.3656113 
INFO  [01:04:42.411] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:04:42.411] [bbotk]                     2240        0.583 -0.9667937         <NA>   0.9770887 
INFO  [01:04:42.411] [bbotk]                                 uhash 
INFO  [01:04:42.411] [bbotk]  2fd5c37a-598b-42a0-8f7b-7a484d42748c 
DEBUG [01:04:43.198] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.995941e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  2.995941e-05 0.004008963 
  - best initial criterion value(s) :  204.2206 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -204.22  |proj g|=       2.5881
At iterate     1  f =      -206.13  |proj g|=        1.6011
At iterate     2  f =      -206.56  |proj g|=        1.7186
At iterate     3  f =      -206.59  |proj g|=        1.8503
At iterate     4  f =       -206.6  |proj g|=        1.8131
At iterate     5  f =      -206.72  |proj g|=        1.7385
At iterate     6  f =      -207.18  |proj g|=        1.5788
At iterate     7  f =      -208.74  |proj g|=        1.4857
At iterate     8  f =      -211.61  |proj g|=        1.1445
At iterate     9  f =      -219.85  |proj g|=       0.88213
At iterate    10  f =      -220.33  |proj g|=       0.87521
At iterate    11  f =      -221.61  |proj g|=       0.85951
At iterate    12  f =      -222.59  |proj g|=        0.9217
At iterate    13  f =      -222.74  |proj g|=       0.99895
At iterate    14  f =      -222.85  |proj g|=        1.0015
At iterate    15  f =      -222.86  |proj g|=         1.003
At iterate    16  f =      -222.87  |proj g|=        1.0042
At iterate    17  f =      -222.87  |proj g|=        1.0046
At iterate    18  f =      -222.87  |proj g|=        1.0046

iterations 18
function evaluations 24
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.0046
final function value -222.865

F = -222.865
final  value -222.865027 
converged
 
INFO  [01:04:43.202] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:04:43.259] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:04:43.266] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:04:50.672] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:04:57.017] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:05:04.169] [mlr3]  Finished benchmark 
INFO  [01:05:04.238] [bbotk] Result of batch 35: 
INFO  [01:05:04.240] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:05:04.240] [bbotk]               3.37877                 4.384132                      0.08333839 
INFO  [01:05:04.240] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:05:04.240] [bbotk]                     2586        0.566 -0.9670545         <NA>   0.9651554 
INFO  [01:05:04.240] [bbotk]                                 uhash 
INFO  [01:05:04.240] [bbotk]  c715a7e9-a787-4695-9bac-e76252dbc3fa 
DEBUG [01:05:05.060] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.952175e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  2.952175e-05 0.003968833 
  - best initial criterion value(s) :  192.0855 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -192.09  |proj g|=       2.9203
At iterate     1  f =      -211.53  |proj g|=        3.9859
At iterate     2  f =      -212.14  |proj g|=        4.7751
At iterate     3  f =      -212.76  |proj g|=        4.6325
At iterate     4  f =      -213.15  |proj g|=        4.4418
At iterate     5  f =      -213.19  |proj g|=        4.3022
At iterate     6  f =       -213.2  |proj g|=        4.3498
At iterate     7  f =       -213.2  |proj g|=        4.3469
At iterate     8  f =       -213.2  |proj g|=        4.3414
At iterate     9  f =       -213.2  |proj g|=        4.3418
At iterate    10  f =      -213.21  |proj g|=        4.3451
At iterate    11  f =      -213.21  |proj g|=        4.3477
At iterate    12  f =      -213.21  |proj g|=        4.3505
At iterate    13  f =      -213.22  |proj g|=        4.3519
At iterate    14  f =      -213.23  |proj g|=        4.3521
At iterate    15  f =      -213.27  |proj g|=        4.3211
At iterate    16  f =      -213.28  |proj g|=        4.3553
At iterate    17  f =      -213.37  |proj g|=        4.2734
At iterate    18  f =      -214.27  |proj g|=        3.8285
At iterate    19  f =       -220.4  |proj g|=        1.7952
At iterate    20  f =      -222.97  |proj g|=        1.0371
At iterate    21  f =      -224.95  |proj g|=        1.0118
At iterate    22  f =      -225.15  |proj g|=       0.94488
At iterate    23  f =      -225.98  |proj g|=       0.97721
At iterate    24  f =       -226.3  |proj g|=       0.84527
At iterate    25  f =       -226.3  |proj g|=       0.84534
At iterate    26  f =      -226.31  |proj g|=       0.84531
At iterate    27  f =      -226.31  |proj g|=       0.84531
At iterate    28  f =      -226.31  |proj g|=       0.84531
At iterate    29  f =      -226.31  |proj g|=       0.84531

iterations 29
function evaluations 35
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.845306
final function value -226.312

F = -226.312
final  value -226.311920 
converged
 
INFO  [01:05:05.064] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:05:05.121] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:05:05.128] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:05:08.018] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:05:11.649] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:05:14.472] [mlr3]  Finished benchmark 
INFO  [01:05:14.575] [bbotk] Result of batch 36: 
INFO  [01:05:14.577] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:05:14.577] [bbotk]              7.977386                 2.797781                       0.4024221 
INFO  [01:05:14.577] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [01:05:14.577] [bbotk]                      898        0.572 -0.966721         <NA>   0.9741337 
INFO  [01:05:14.577] [bbotk]                                 uhash 
INFO  [01:05:14.577] [bbotk]  b990c5ca-70ce-475a-aae6-b24161262b6b 
DEBUG [01:05:15.461] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.911358e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  2.911358e-05 0.003857007 
  - best initial criterion value(s) :  213.3307 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -213.33  |proj g|=       1.1211
At iterate     1  f =       -218.1  |proj g|=        3.2577
At iterate     2  f =      -219.74  |proj g|=        3.1508
At iterate     3  f =      -221.69  |proj g|=        2.7451
At iterate     4  f =      -221.85  |proj g|=        2.5866
At iterate     5  f =      -221.95  |proj g|=        2.5143
At iterate     6  f =      -222.26  |proj g|=        2.2681
At iterate     7  f =      -222.35  |proj g|=        2.3129
At iterate     8  f =      -222.36  |proj g|=         2.331
At iterate     9  f =      -222.36  |proj g|=        2.3309
At iterate    10  f =      -222.36  |proj g|=        2.3315
At iterate    11  f =      -222.36  |proj g|=        2.3335
At iterate    12  f =      -222.36  |proj g|=        2.3369
At iterate    13  f =      -222.36  |proj g|=        2.3427
At iterate    14  f =      -222.36  |proj g|=        2.3502
At iterate    15  f =      -222.38  |proj g|=         2.358
At iterate    16  f =      -222.42  |proj g|=        2.3562
At iterate    17  f =       -222.5  |proj g|=        2.3181
At iterate    18  f =      -222.67  |proj g|=        2.1942
At iterate    19  f =      -222.88  |proj g|=        1.9684
At iterate    20  f =      -223.03  |proj g|=        1.8107
At iterate    21  f =      -223.25  |proj g|=        1.5904
At iterate    22  f =      -223.53  |proj g|=        1.4252
At iterate    23  f =      -224.75  |proj g|=       0.90799
At iterate    24  f =      -227.06  |proj g|=       0.71096
At iterate    25  f =      -229.64  |proj g|=       0.86117
At iterate    26  f =      -230.21  |proj g|=       0.84996
At iterate    27  f =      -231.41  |proj g|=        0.8281
At iterate    28  f =      -231.61  |proj g|=       0.81406
At iterate    29  f =      -231.65  |proj g|=       0.39818
At iterate    30  f =      -231.65  |proj g|=       0.40785
At iterate    31  f =      -231.65  |proj g|=       0.41466
At iterate    32  f =      -231.65  |proj g|=       0.41421
At iterate    33  f =      -231.65  |proj g|=        0.4142
At iterate    34  f =      -231.65  |proj g|=       0.41417
At iterate    35  f =      -231.65  |proj g|=       0.41419
At iterate    36  f =      -231.65  |proj g|=       0.41436
At iterate    37  f =      -231.65  |proj g|=       0.41351
At iterate    38  f =      -231.65  |proj g|=       0.41372
At iterate    39  f =      -231.66  |proj g|=       0.41322
At iterate    40  f =      -231.72  |proj g|=       0.39805
At iterate    41  f =      -231.84  |proj g|=       0.35033
At iterate    42  f =      -232.05  |proj g|=       0.26396
At iterate    43  f =      -232.05  |proj g|=       0.27911
At iterate    44  f =      -232.32  |proj g|=       0.22002
At iterate    45  f =      -232.43  |proj g|=       0.21941
At iterate    46  f =      -232.54  |proj g|=       0.20758
At iterate    47  f =      -232.58  |proj g|=       0.79357
At iterate    48  f =      -232.58  |proj g|=      0.054091
At iterate    49  f =      -232.58  |proj g|=       0.14526
At iterate    50  f =      -232.58  |proj g|=     0.0033474
At iterate    51  f =      -232.58  |proj g|=     0.0008885

iterations 51
function evaluations 62
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000888501
final function value -232.578

F = -232.578
final  value -232.577670 
converged
 
INFO  [01:05:15.466] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:05:15.536] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:05:15.544] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:05:17.967] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:05:20.999] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:05:24.630] [mlr3]  Finished benchmark 
INFO  [01:05:24.698] [bbotk] Result of batch 37: 
INFO  [01:05:24.700] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:05:24.700] [bbotk]              4.947648                  6.56598                       0.2668423 
INFO  [01:05:24.700] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:05:24.700] [bbotk]                      646        0.583 -0.9656032         <NA>    0.967567 
INFO  [01:05:24.700] [bbotk]                                 uhash 
INFO  [01:05:24.700] [bbotk]  238b7602-81c5-45b2-aef8-6695d6c05b95 
DEBUG [01:05:25.696] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.868246e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  2.868246e-05 0.003752753 
  - best initial criterion value(s) :  214.9189 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -214.92  |proj g|=        1.528
At iterate     1  f =      -219.05  |proj g|=        2.0283
At iterate     2  f =      -219.83  |proj g|=        2.5294
At iterate     3  f =      -224.61  |proj g|=        2.0153
At iterate     4  f =       -224.7  |proj g|=        2.0934
At iterate     5  f =       -224.7  |proj g|=        2.0857
At iterate     6  f =       -224.7  |proj g|=        2.0866
At iterate     7  f =       -224.7  |proj g|=        2.0864
At iterate     8  f =       -224.7  |proj g|=        2.0859
At iterate     9  f =       -224.7  |proj g|=        2.0849
At iterate    10  f =       -224.7  |proj g|=        2.0833
At iterate    11  f =       -224.7  |proj g|=        2.0807
At iterate    12  f =       -224.7  |proj g|=        2.0772
At iterate    13  f =       -224.7  |proj g|=        2.0726
At iterate    14  f =       -224.7  |proj g|=        2.0647
At iterate    15  f =      -224.72  |proj g|=        2.0589
At iterate    16  f =      -224.72  |proj g|=        2.0422
At iterate    17  f =      -224.74  |proj g|=        2.0296
At iterate    18  f =      -225.27  |proj g|=        1.8898
At iterate    19  f =      -230.91  |proj g|=        1.2765
At iterate    20  f =      -235.95  |proj g|=         1.061
At iterate    21  f =      -237.63  |proj g|=       0.20905
At iterate    22  f =      -237.65  |proj g|=       0.21442
At iterate    23  f =      -237.68  |proj g|=       0.20649
At iterate    24  f =      -237.72  |proj g|=       0.35276
At iterate    25  f =      -237.72  |proj g|=       0.18886
At iterate    26  f =      -237.72  |proj g|=        0.1882
At iterate    27  f =      -237.72  |proj g|=        0.1882

iterations 27
function evaluations 37
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.188199
final function value -237.719

F = -237.719
final  value -237.719422 
converged
 
INFO  [01:05:25.701] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:05:25.757] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:05:25.764] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:05:33.530] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:05:41.409] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:05:49.520] [mlr3]  Finished benchmark 
INFO  [01:05:49.586] [bbotk] Result of batch 38: 
INFO  [01:05:49.588] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:05:49.588] [bbotk]              6.127959                 6.977401                       0.2813976 
INFO  [01:05:49.588] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:05:49.588] [bbotk]                     2888        0.741 -0.9653202         <NA>   0.9770159 
INFO  [01:05:49.588] [bbotk]                                 uhash 
INFO  [01:05:49.588] [bbotk]  ab7839ef-348a-4e2c-8558-d91d8df7083c 
DEBUG [01:05:50.340] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.835223e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  2.835223e-05 0.003736715 
  - best initial criterion value(s) :  238.0068 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -238.01  |proj g|=      0.99328
At iterate     1  f =      -238.37  |proj g|=        1.0041
At iterate     2  f =      -238.68  |proj g|=        1.0549
At iterate     3  f =      -238.69  |proj g|=        1.0656
At iterate     4  f =       -238.7  |proj g|=          1.07
At iterate     5  f =       -238.7  |proj g|=        1.0704
At iterate     6  f =       -238.7  |proj g|=        1.0705

iterations 6
function evaluations 9
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.07046
final function value -238.695

F = -238.695
final  value -238.695363 
converged
 
INFO  [01:05:50.344] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:05:50.399] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:05:50.406] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:06:01.323] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:06:11.965] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:06:23.616] [mlr3]  Finished benchmark 
INFO  [01:06:23.683] [bbotk] Result of batch 39: 
INFO  [01:06:23.685] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:06:23.685] [bbotk]              2.407999                 4.486156                        0.166555 
INFO  [01:06:23.685] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:06:23.685] [bbotk]                     3864         0.56 -0.9688614         <NA>   0.9637339 
INFO  [01:06:23.685] [bbotk]                                 uhash 
INFO  [01:06:23.685] [bbotk]  4a95073f-0c73-4c12-a2d7-147df9cba0d9 
DEBUG [01:06:24.543] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.798374e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  2.798374e-05 0.003702422 
  - best initial criterion value(s) :  220.4202 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -220.42  |proj g|=       1.7097
At iterate     1  f =       -228.1  |proj g|=        1.6038
At iterate     2  f =      -238.16  |proj g|=        1.4618
At iterate     3  f =      -238.21  |proj g|=        1.4264
At iterate     4  f =      -238.34  |proj g|=        1.4555
At iterate     5  f =      -238.52  |proj g|=        1.5005
At iterate     6  f =      -238.82  |proj g|=        1.5856
At iterate     7  f =      -238.97  |proj g|=        1.6429
At iterate     8  f =      -238.98  |proj g|=        1.6371
At iterate     9  f =      -238.98  |proj g|=        1.6541
At iterate    10  f =      -238.99  |proj g|=        1.6594
At iterate    11  f =      -238.99  |proj g|=        1.6597
At iterate    12  f =      -238.99  |proj g|=        1.6604
At iterate    13  f =      -238.99  |proj g|=        1.6611
At iterate    14  f =      -238.99  |proj g|=        1.6625
At iterate    15  f =      -238.99  |proj g|=        1.6639
At iterate    16  f =      -238.99  |proj g|=        1.6652
At iterate    17  f =      -238.99  |proj g|=        1.6693
At iterate    18  f =         -239  |proj g|=        1.6736
At iterate    19  f =      -239.06  |proj g|=         1.669
At iterate    20  f =      -239.26  |proj g|=        1.5858
At iterate    21  f =      -239.26  |proj g|=        1.5826
At iterate    22  f =      -239.33  |proj g|=        1.4959
At iterate    23  f =      -239.35  |proj g|=        1.4802
At iterate    24  f =      -239.35  |proj g|=        1.4787
At iterate    25  f =      -239.35  |proj g|=        1.4786
At iterate    26  f =      -239.35  |proj g|=        1.4786
At iterate    27  f =      -239.35  |proj g|=        1.4784
At iterate    28  f =      -239.35  |proj g|=        1.4786
At iterate    29  f =      -239.35  |proj g|=        1.4789
At iterate    30  f =      -239.35  |proj g|=        1.4801
At iterate    31  f =      -239.35  |proj g|=        1.4815
At iterate    32  f =      -239.35  |proj g|=        1.4825
At iterate    33  f =      -239.35  |proj g|=        1.4834
At iterate    34  f =      -239.35  |proj g|=         1.484
At iterate    35  f =      -239.35  |proj g|=        1.4855
At iterate    36  f =      -239.35  |proj g|=         1.485
At iterate    37  f =      -239.35  |proj g|=         1.484
At iterate    38  f =      -239.35  |proj g|=        1.4816
At iterate    39  f =      -239.35  |proj g|=        1.4788
At iterate    40  f =      -239.35  |proj g|=        1.4751
At iterate    41  f =      -239.35  |proj g|=        1.4684
At iterate    42  f =      -239.36  |proj g|=        1.4571
At iterate    43  f =      -239.36  |proj g|=        1.4434
At iterate    44  f =      -239.36  |proj g|=        1.4403
At iterate    45  f =      -239.37  |proj g|=        1.4221
At iterate    46  f =      -239.41  |proj g|=        1.4429
At iterate    47  f =      -239.42  |proj g|=        1.4233
At iterate    48  f =      -239.45  |proj g|=        1.4061
At iterate    49  f =      -240.13  |proj g|=        1.2345
At iterate    50  f =      -240.26  |proj g|=        1.2189
At iterate    51  f =      -242.44  |proj g|=        1.3665
At iterate    52  f =      -243.13  |proj g|=         1.304
At iterate    53  f =      -244.51  |proj g|=       0.74962
At iterate    54  f =      -245.98  |proj g|=       0.31742
At iterate    55  f =      -246.66  |proj g|=       0.80444
At iterate    56  f =      -246.87  |proj g|=       0.80459
At iterate    57  f =      -246.91  |proj g|=       0.80385
At iterate    58  f =      -246.96  |proj g|=       0.79976
At iterate    59  f =      -247.04  |proj g|=       0.78738
At iterate    60  f =      -247.05  |proj g|=       0.42071
At iterate    61  f =      -247.05  |proj g|=     0.0023523
At iterate    62  f =      -247.05  |proj g|=     0.0025339

iterations 62
function evaluations 73
segments explored during Cauchy searches 64
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00253386
final function value -247.051

F = -247.051
final  value -247.050597 
converged
 
INFO  [01:06:24.547] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:06:24.602] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:06:24.608] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:06:27.829] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:06:31.049] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:06:34.240] [mlr3]  Finished benchmark 
INFO  [01:06:34.334] [bbotk] Result of batch 40: 
INFO  [01:06:34.336] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:06:34.336] [bbotk]               2.85113                  6.62978                       0.1146991 
INFO  [01:06:34.336] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [01:06:34.336] [bbotk]                     1109        0.554  -0.96496         <NA>    0.952899 
INFO  [01:06:34.336] [bbotk]                                 uhash 
INFO  [01:06:34.336] [bbotk]  b7ef50c3-75bc-44be-8e85-70678258091d 
DEBUG [01:06:35.188] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.795386e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  2.795386e-05 0.003657077 
  - best initial criterion value(s) :  211.854 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -211.85  |proj g|=       1.8099
At iterate     1  f =      -231.89  |proj g|=        3.0281
At iterate     2  f =      -233.55  |proj g|=        2.8969
At iterate     3  f =      -237.86  |proj g|=        2.2541
At iterate     4  f =      -238.21  |proj g|=        2.0203
At iterate     5  f =      -238.31  |proj g|=        1.9775
At iterate     6  f =       -238.6  |proj g|=        1.9609
At iterate     7  f =      -238.71  |proj g|=        2.0994
At iterate     8  f =      -238.72  |proj g|=        2.1261
At iterate     9  f =      -238.72  |proj g|=        2.1263
At iterate    10  f =      -238.72  |proj g|=        2.1267
At iterate    11  f =      -238.72  |proj g|=        2.1294
At iterate    12  f =      -238.72  |proj g|=        2.1326
At iterate    13  f =      -238.72  |proj g|=        2.1379
At iterate    14  f =      -238.72  |proj g|=        2.1448
At iterate    15  f =      -238.73  |proj g|=        2.1514
At iterate    16  f =      -238.75  |proj g|=        2.1486
At iterate    17  f =       -238.8  |proj g|=        2.1101
At iterate    18  f =      -238.88  |proj g|=        1.9997
At iterate    19  f =       -238.9  |proj g|=        1.9404
At iterate    20  f =      -238.93  |proj g|=        1.8954
At iterate    21  f =      -239.18  |proj g|=         1.728
At iterate    22  f =      -239.95  |proj g|=        1.5716
At iterate    23  f =      -240.61  |proj g|=        1.8674
At iterate    24  f =      -240.68  |proj g|=        1.8525
At iterate    25  f =      -240.69  |proj g|=        1.8388
At iterate    26  f =      -240.69  |proj g|=        1.8417
At iterate    27  f =      -240.69  |proj g|=        1.8435
At iterate    28  f =      -240.69  |proj g|=        1.8429
At iterate    29  f =      -240.69  |proj g|=        1.8434
At iterate    30  f =      -240.69  |proj g|=        1.8399
At iterate    31  f =      -241.14  |proj g|=        1.8526
At iterate    32  f =      -245.53  |proj g|=        1.5552
At iterate    33  f =      -245.58  |proj g|=        1.5797
At iterate    34  f =      -247.96  |proj g|=        1.3432
At iterate    35  f =      -249.98  |proj g|=        1.1384
At iterate    36  f =      -251.87  |proj g|=       0.20242
At iterate    37  f =      -251.88  |proj g|=       0.20239
At iterate    38  f =      -251.88  |proj g|=       0.20237
At iterate    39  f =      -251.88  |proj g|=       0.20237
At iterate    40  f =      -251.88  |proj g|=       0.20237
At iterate    41  f =      -251.88  |proj g|=       0.20236
At iterate    42  f =      -251.88  |proj g|=       0.20234
At iterate    43  f =      -251.88  |proj g|=       0.20227
At iterate    44  f =      -251.88  |proj g|=       0.20212
At iterate    45  f =      -251.88  |proj g|=        0.2017
At iterate    46  f =      -251.88  |proj g|=       0.20068
At iterate    47  f =      -251.89  |proj g|=       0.78791
At iterate    48  f =      -251.89  |proj g|=       0.79081
At iterate    49  f =      -251.89  |proj g|=       0.16452
At iterate    50  f =      -251.89  |proj g|=      0.015904
At iterate    51  f =      -251.89  |proj g|=      0.001014

iterations 51
function evaluations 64
segments explored during Cauchy searches 54
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00101396
final function value -251.893

F = -251.893
final  value -251.892835 
converged
 
INFO  [01:06:35.193] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:06:35.247] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:06:35.254] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:06:43.113] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:06:51.347] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:06:58.661] [mlr3]  Finished benchmark 
INFO  [01:06:58.729] [bbotk] Result of batch 41: 
INFO  [01:06:58.731] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:06:58.731] [bbotk]              9.412063                 7.425663                      0.01219179 
INFO  [01:06:58.731] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:06:58.731] [bbotk]                     2783        0.561 -0.9650447         <NA>    0.951082 
INFO  [01:06:58.731] [bbotk]                                 uhash 
INFO  [01:06:58.731] [bbotk]  ebdf78ec-5b2a-4660-aef5-319ccfb1ffb0 
DEBUG [01:06:59.521] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.799992e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  2.799992e-05 0.003635713 
  - best initial criterion value(s) :  209.811 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -209.81  |proj g|=       1.0326
At iterate     1  f =       -228.9  |proj g|=        1.8417
At iterate     2  f =      -234.74  |proj g|=        1.6625
At iterate     3  f =      -235.71  |proj g|=        1.6001
At iterate     4  f =      -236.85  |proj g|=        1.5297
At iterate     5  f =      -238.64  |proj g|=        1.4225
At iterate     6  f =      -240.09  |proj g|=        1.3185
At iterate     7  f =      -240.27  |proj g|=        1.3247
At iterate     8  f =      -240.48  |proj g|=        1.3368
At iterate     9  f =      -240.49  |proj g|=        1.3139
At iterate    10  f =      -240.49  |proj g|=        1.3225
At iterate    11  f =      -240.49  |proj g|=        1.3219
At iterate    12  f =      -240.49  |proj g|=        1.3218

iterations 12
function evaluations 18
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.32183
final function value -240.49

F = -240.49
final  value -240.490225 
converged
 
INFO  [01:06:59.525] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:06:59.581] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:06:59.588] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:07:05.726] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:07:11.412] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:07:17.156] [mlr3]  Finished benchmark 
INFO  [01:07:17.236] [bbotk] Result of batch 42: 
INFO  [01:07:17.237] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:07:17.237] [bbotk]              3.851177                  2.74599                       0.1178528 
INFO  [01:07:17.237] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:07:17.237] [bbotk]                     1847        0.574 -0.9720635         <NA>   0.9672723 
INFO  [01:07:17.237] [bbotk]                                 uhash 
INFO  [01:07:17.237] [bbotk]  a1fa332a-999e-4b6d-a894-de8e71f7dd3c 
DEBUG [01:07:18.047] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.761355e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  2.761355e-05 0.003604937 
  - best initial criterion value(s) :  239.5291 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -239.53  |proj g|=       2.7748
At iterate     1  f =      -239.74  |proj g|=        2.7419
At iterate     2  f =      -239.93  |proj g|=        2.7943
At iterate     3  f =      -239.94  |proj g|=        2.7965
At iterate     4  f =      -239.94  |proj g|=        2.7974
At iterate     5  f =      -239.94  |proj g|=        2.7974
At iterate     6  f =      -239.94  |proj g|=        2.7977
At iterate     7  f =      -239.94  |proj g|=        2.7979
At iterate     8  f =      -239.94  |proj g|=        2.7982
At iterate     9  f =      -239.94  |proj g|=        2.8007
At iterate    10  f =      -239.94  |proj g|=        2.7997
At iterate    11  f =      -239.94  |proj g|=        2.7979
At iterate    12  f =      -239.94  |proj g|=         2.795
At iterate    13  f =      -239.95  |proj g|=        2.7896
At iterate    14  f =      -239.96  |proj g|=        2.7796
At iterate    15  f =      -240.01  |proj g|=        2.7555
At iterate    16  f =      -240.12  |proj g|=        2.7051
At iterate    17  f =      -240.41  |proj g|=        2.6005
At iterate    18  f =      -241.02  |proj g|=        2.3923
At iterate    19  f =      -242.25  |proj g|=        2.0548
At iterate    20  f =      -243.33  |proj g|=        1.4788
At iterate    21  f =      -245.03  |proj g|=        1.3283
At iterate    22  f =      -248.96  |proj g|=       0.99059
At iterate    23  f =      -250.71  |proj g|=       0.45983
At iterate    24  f =      -252.73  |proj g|=        0.6137
At iterate    25  f =       -253.4  |proj g|=        0.7913
At iterate    26  f =      -254.22  |proj g|=       0.80725
At iterate    27  f =      -255.18  |proj g|=       0.35592
At iterate    28  f =       -255.2  |proj g|=       0.82339
At iterate    29  f =      -255.23  |proj g|=       0.82687
At iterate    30  f =      -255.23  |proj g|=       0.39929
At iterate    31  f =      -255.23  |proj g|=        0.3983
At iterate    32  f =      -255.23  |proj g|=       0.39842

iterations 32
function evaluations 37
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.398418
final function value -255.227

F = -255.227
final  value -255.227427 
converged
 
INFO  [01:07:18.051] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:07:18.110] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:07:18.117] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:07:31.185] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:07:41.101] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:07:52.357] [mlr3]  Finished benchmark 
INFO  [01:07:52.486] [bbotk] Result of batch 43: 
INFO  [01:07:52.489] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:07:52.489] [bbotk]              9.246441                 3.953968                       0.2934935 
INFO  [01:07:52.489] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:07:52.489] [bbotk]                     4021        0.563 -0.9694613         <NA>   0.9777304 
INFO  [01:07:52.489] [bbotk]                                 uhash 
INFO  [01:07:52.489] [bbotk]  1f04f795-407d-409c-b4af-ead0cc2052ff 
DEBUG [01:07:53.316] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.734768e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  2.734768e-05 0.003593088 
  - best initial criterion value(s) :  247.0873 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -247.09  |proj g|=      0.96085
At iterate     1  f =       -255.3  |proj g|=        1.3577
At iterate     2  f =      -256.74  |proj g|=         1.344
At iterate     3  f =      -258.58  |proj g|=         1.273
At iterate     4  f =      -258.77  |proj g|=        1.2225
At iterate     5  f =      -259.04  |proj g|=        1.2196
At iterate     6  f =      -259.67  |proj g|=        1.0665
At iterate     7  f =      -259.85  |proj g|=        1.1476
At iterate     8  f =      -259.87  |proj g|=        1.1159
At iterate     9  f =      -259.89  |proj g|=        1.1223
At iterate    10  f =      -259.89  |proj g|=        1.1216
At iterate    11  f =      -259.89  |proj g|=        1.1216
At iterate    12  f =      -259.89  |proj g|=        1.1214
At iterate    13  f =      -259.89  |proj g|=        1.1211
At iterate    14  f =      -259.89  |proj g|=        1.1205
At iterate    15  f =      -259.89  |proj g|=        1.1196
At iterate    16  f =      -259.89  |proj g|=        1.1181
At iterate    17  f =      -259.89  |proj g|=        1.1162
At iterate    18  f =      -259.89  |proj g|=        1.1154
At iterate    19  f =      -259.89  |proj g|=        1.1138
At iterate    20  f =       -259.9  |proj g|=        1.1092
At iterate    21  f =      -259.99  |proj g|=        1.0788
At iterate    22  f =       -260.2  |proj g|=        1.0181
At iterate    23  f =      -260.84  |proj g|=       0.85298
At iterate    24  f =      -261.13  |proj g|=        0.8535
At iterate    25  f =      -261.65  |proj g|=       0.84424
At iterate    26  f =      -261.94  |proj g|=       0.82951
At iterate    27  f =      -261.99  |proj g|=       0.82184
At iterate    28  f =      -261.99  |proj g|=       0.69054
At iterate    29  f =      -261.99  |proj g|=       0.69169
At iterate    30  f =      -261.99  |proj g|=       0.69256
At iterate    31  f =      -261.99  |proj g|=       0.69262

iterations 31
function evaluations 35
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.692618
final function value -261.993

F = -261.993
final  value -261.992683 
converged
 
INFO  [01:07:53.321] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:07:53.375] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:07:53.383] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:07:59.151] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:08:04.972] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:08:10.920] [mlr3]  Finished benchmark 
INFO  [01:08:10.989] [bbotk] Result of batch 44: 
INFO  [01:08:10.991] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:08:10.991] [bbotk]              4.450842                 7.184623                       0.2832525 
INFO  [01:08:10.991] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [01:08:10.991] [bbotk]                     2913        0.573 -0.967744         <NA>    0.975871 
INFO  [01:08:10.991] [bbotk]                                 uhash 
INFO  [01:08:10.991] [bbotk]  08bde64c-6b17-41cc-865d-40de08fe0f7b 
DEBUG [01:08:11.878] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.704603e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9865363 9498 
  - variance bounds :  2.704603e-05 0.003577209 
  - best initial criterion value(s) :  248.7638 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -248.76  |proj g|=      0.79805
At iterate     1  f =      -261.44  |proj g|=        1.5231
At iterate     2  f =       -262.8  |proj g|=        1.5025
At iterate     3  f =      -264.53  |proj g|=        1.4017
At iterate     4  f =      -264.54  |proj g|=         1.379
At iterate     5  f =      -264.55  |proj g|=        1.3839
At iterate     6  f =      -264.57  |proj g|=        1.3845
At iterate     7  f =      -264.59  |proj g|=        1.3753
At iterate     8  f =      -264.61  |proj g|=        1.3604
At iterate     9  f =      -264.61  |proj g|=        1.3557
At iterate    10  f =      -264.61  |proj g|=        1.3558
At iterate    11  f =      -264.61  |proj g|=        1.3558
At iterate    12  f =      -264.61  |proj g|=        1.3558
At iterate    13  f =      -264.61  |proj g|=        1.3558
At iterate    14  f =      -264.61  |proj g|=        1.3557
At iterate    15  f =      -264.61  |proj g|=        1.3556
At iterate    16  f =      -264.61  |proj g|=        1.3557
At iterate    17  f =      -264.61  |proj g|=        1.3561
At iterate    18  f =      -264.62  |proj g|=        1.3558
At iterate    19  f =      -264.64  |proj g|=        1.3576
At iterate    20  f =      -264.65  |proj g|=        1.3486
At iterate    21  f =       -264.7  |proj g|=        1.3463
At iterate    22  f =      -265.43  |proj g|=        1.2586
At iterate    23  f =      -267.45  |proj g|=       0.90447
At iterate    24  f =      -267.58  |proj g|=       0.91279
At iterate    25  f =      -267.62  |proj g|=       0.90262
At iterate    26  f =      -267.62  |proj g|=       0.89827
At iterate    27  f =      -267.62  |proj g|=        0.9008
At iterate    28  f =      -267.62  |proj g|=       0.90054
At iterate    29  f =      -267.62  |proj g|=        0.9005
At iterate    30  f =      -267.62  |proj g|=       0.90042
At iterate    31  f =      -267.62  |proj g|=       0.90024
At iterate    32  f =      -267.62  |proj g|=       0.90008
At iterate    33  f =      -267.62  |proj g|=       0.89927
At iterate    34  f =      -267.62  |proj g|=       0.89922
At iterate    35  f =      -267.63  |proj g|=       0.89735
At iterate    36  f =      -267.67  |proj g|=       0.88611
At iterate    37  f =      -267.81  |proj g|=       0.84731
At iterate    38  f =      -268.17  |proj g|=       0.82757
At iterate    39  f =      -268.18  |proj g|=       0.82793
At iterate    40  f =      -268.97  |proj g|=       0.83555
At iterate    41  f =      -269.52  |proj g|=       0.83375
At iterate    42  f =       -269.9  |proj g|=       0.81843
At iterate    43  f =      -270.03  |proj g|=       0.80437
At iterate    44  f =      -270.04  |proj g|=       0.03587
At iterate    45  f =      -270.04  |proj g|=       0.54686
At iterate    46  f =      -270.04  |proj g|=      0.020136
At iterate    47  f =      -270.04  |proj g|=     0.0026979

iterations 47
function evaluations 58
segments explored during Cauchy searches 49
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0026979
final function value -270.043

F = -270.043
final  value -270.042815 
converged
 
INFO  [01:08:11.883] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:08:11.939] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:08:11.947] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:08:19.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:08:27.485] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:08:35.078] [mlr3]  Finished benchmark 
INFO  [01:08:35.158] [bbotk] Result of batch 45: 
INFO  [01:08:35.161] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:08:35.161] [bbotk]              8.249558                 2.414252                        0.499223 
INFO  [01:08:35.161] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:08:35.161] [bbotk]                     3778        0.584 -0.9648268         <NA>   0.9787134 
INFO  [01:08:35.161] [bbotk]                                 uhash 
INFO  [01:08:35.161] [bbotk]  f9495b7b-cd50-4127-aecc-6e6122a97696 
DEBUG [01:08:36.089] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.681397e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  2.681397e-05 0.003565058 
  - best initial criterion value(s) :  267.5659 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -267.57  |proj g|=      0.45667
At iterate     1  f =      -272.38  |proj g|=       0.85151
At iterate     2  f =      -272.41  |proj g|=       0.85089
At iterate     3  f =      -272.44  |proj g|=       0.84942
At iterate     4  f =      -272.46  |proj g|=       0.84836
At iterate     5  f =      -272.58  |proj g|=       0.84134
At iterate     6  f =      -272.71  |proj g|=       0.48375
At iterate     7  f =      -272.79  |proj g|=       0.82736
At iterate     8  f =       -272.8  |proj g|=        0.8254
At iterate     9  f =       -272.8  |proj g|=        0.8248
At iterate    10  f =       -272.8  |proj g|=       0.82478
At iterate    11  f =       -272.8  |proj g|=       0.82465
At iterate    12  f =       -272.8  |proj g|=       0.82459
At iterate    13  f =       -272.8  |proj g|=       0.82432
At iterate    14  f =       -272.8  |proj g|=       0.82399
At iterate    15  f =       -272.8  |proj g|=       0.82338
At iterate    16  f =       -272.8  |proj g|=       0.82229
At iterate    17  f =      -272.82  |proj g|=       0.82044
At iterate    18  f =      -272.84  |proj g|=       0.81691
At iterate    19  f =       -272.9  |proj g|=       0.58528
At iterate    20  f =      -273.02  |proj g|=       0.61023
At iterate    21  f =      -273.12  |proj g|=       0.57274
At iterate    22  f =      -273.18  |proj g|=       0.55004
At iterate    23  f =      -273.28  |proj g|=       0.51627
At iterate    24  f =      -273.29  |proj g|=       0.53534
At iterate    25  f =       -273.3  |proj g|=       0.53711
At iterate    26  f =       -273.3  |proj g|=       0.53726
At iterate    27  f =       -273.3  |proj g|=       0.53724

iterations 27
function evaluations 30
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.537243
final function value -273.295

F = -273.295
final  value -273.295040 
converged
 
INFO  [01:08:36.094] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:08:36.157] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:08:36.166] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:08:39.990] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:08:43.623] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:08:47.254] [mlr3]  Finished benchmark 
INFO  [01:08:47.427] [bbotk] Result of batch 46: 
INFO  [01:08:47.429] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:08:47.429] [bbotk]              8.696005                 8.043635                      0.02428771 
INFO  [01:08:47.429] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:08:47.429] [bbotk]                     1796        0.659 -0.9666221         <NA>   0.9548674 
INFO  [01:08:47.429] [bbotk]                                 uhash 
INFO  [01:08:47.429] [bbotk]  861604b7-ff5a-486b-91aa-84475c0790f0 
DEBUG [01:08:48.237] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.671905e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  2.671905e-05 0.00355244 
  - best initial criterion value(s) :  250.8412 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -250.84  |proj g|=      0.41506
At iterate     1  f =      -263.65  |proj g|=       0.91423
At iterate     2  f =      -264.34  |proj g|=       0.91335
At iterate     3  f =       -265.8  |proj g|=       0.90983
At iterate     4  f =      -265.92  |proj g|=       0.90864
At iterate     5  f =      -266.29  |proj g|=       0.90562
At iterate     6  f =      -267.96  |proj g|=       0.88955
At iterate     7  f =      -269.98  |proj g|=       0.86639
At iterate     8  f =      -271.84  |proj g|=       0.90845
At iterate     9  f =      -272.14  |proj g|=       0.93108
At iterate    10  f =      -272.21  |proj g|=       0.94662
At iterate    11  f =      -272.21  |proj g|=       0.95165
At iterate    12  f =      -272.21  |proj g|=       0.95398
At iterate    13  f =      -272.21  |proj g|=       0.95431
At iterate    14  f =      -272.21  |proj g|=       0.95429

iterations 14
function evaluations 18
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.954293
final function value -272.211

F = -272.211
final  value -272.211429 
converged
 
INFO  [01:08:48.242] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:08:48.298] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:08:48.306] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:08:56.929] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:09:08.627] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:09:20.861] [mlr3]  Finished benchmark 
INFO  [01:09:20.933] [bbotk] Result of batch 47: 
INFO  [01:09:20.935] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:09:20.935] [bbotk]              6.109067                 3.388727                       0.2866609 
INFO  [01:09:20.935] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:09:20.935] [bbotk]                     4203        0.582 -0.9686927         <NA>    0.978021 
INFO  [01:09:20.935] [bbotk]                                 uhash 
INFO  [01:09:20.935] [bbotk]  be341ab3-b3c9-42c9-be19-2daecf750d50 
DEBUG [01:09:21.819] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.648162e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  2.648162e-05 0.003543402 
  - best initial criterion value(s) :  257.3766 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -257.38  |proj g|=       2.3694
At iterate     1  f =      -261.19  |proj g|=        2.3051
At iterate     2  f =      -261.24  |proj g|=         2.667
At iterate     3  f =      -261.79  |proj g|=        2.5733
At iterate     4  f =      -261.95  |proj g|=        2.5067
At iterate     5  f =      -261.96  |proj g|=        2.4828
At iterate     6  f =      -261.96  |proj g|=        2.4891
At iterate     7  f =      -261.96  |proj g|=         2.489
At iterate     8  f =      -261.96  |proj g|=        2.4895
At iterate     9  f =      -261.96  |proj g|=        2.4894
At iterate    10  f =      -261.96  |proj g|=        2.4893
At iterate    11  f =      -261.96  |proj g|=        2.4891
At iterate    12  f =      -261.96  |proj g|=        2.4891
At iterate    13  f =      -261.96  |proj g|=        2.4881
At iterate    14  f =      -261.96  |proj g|=        2.4881
At iterate    15  f =      -261.96  |proj g|=         2.488
At iterate    16  f =      -261.97  |proj g|=        2.4862
At iterate    17  f =      -262.03  |proj g|=        2.4681
At iterate    18  f =      -262.17  |proj g|=        2.4189
At iterate    19  f =       -262.2  |proj g|=        2.3704
At iterate    20  f =      -262.59  |proj g|=        2.2462
At iterate    21  f =      -263.75  |proj g|=        1.8951
At iterate    22  f =      -266.38  |proj g|=        1.2948
At iterate    23  f =      -270.84  |proj g|=        0.8717
At iterate    24  f =      -271.67  |proj g|=       0.36904
At iterate    25  f =      -272.44  |proj g|=       0.52254
At iterate    26  f =      -272.63  |proj g|=       0.48781
At iterate    27  f =      -272.68  |proj g|=       0.43398
At iterate    28  f =      -272.69  |proj g|=       0.45474
At iterate    29  f =      -272.69  |proj g|=       0.45209
At iterate    30  f =      -272.69  |proj g|=        0.4519
At iterate    31  f =      -272.69  |proj g|=        0.4519

iterations 31
function evaluations 37
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.451901
final function value -272.686

F = -272.686
final  value -272.685778 
converged
 
INFO  [01:09:21.824] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:09:21.885] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:09:21.916] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:09:38.716] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:09:53.117] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:10:10.844] [mlr3]  Finished benchmark 
INFO  [01:10:10.943] [bbotk] Result of batch 48: 
INFO  [01:10:10.946] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:10:10.946] [bbotk]               6.46536                  5.16182                      0.04023698 
INFO  [01:10:10.946] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:10:10.946] [bbotk]                     4862        0.614 -0.9708163         <NA>   0.9703626 
INFO  [01:10:10.946] [bbotk]                                 uhash 
INFO  [01:10:10.946] [bbotk]  f31e8506-61ea-45f1-8ecb-89224c1f2890 
DEBUG [01:10:11.900] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.614484e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  2.614484e-05 0.003511942 
  - best initial criterion value(s) :  254.7906 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -254.79  |proj g|=       4.9655
At iterate     1  f =       -256.4  |proj g|=        5.6035
At iterate     2  f =      -257.23  |proj g|=        5.0525
At iterate     3  f =      -258.68  |proj g|=        3.7515
At iterate     4  f =      -259.51  |proj g|=        3.4686
At iterate     5  f =      -259.64  |proj g|=        3.3313
At iterate     6  f =      -259.64  |proj g|=        3.3432
At iterate     7  f =      -259.64  |proj g|=        3.3501
At iterate     8  f =      -259.64  |proj g|=        3.3561
At iterate     9  f =      -259.64  |proj g|=        3.3679
At iterate    10  f =      -259.65  |proj g|=        3.3857
At iterate    11  f =      -259.65  |proj g|=        3.4161
At iterate    12  f =      -259.67  |proj g|=        3.4657
At iterate    13  f =      -259.72  |proj g|=        3.5428
At iterate    14  f =      -259.81  |proj g|=        3.6451
At iterate    15  f =      -260.02  |proj g|=        3.7778
At iterate    16  f =      -260.04  |proj g|=        3.8184
At iterate    17  f =      -260.48  |proj g|=        3.9291
At iterate    18  f =      -277.79  |proj g|=        1.1778
At iterate    19  f =      -281.07  |proj g|=        1.1235
At iterate    20  f =      -281.86  |proj g|=        1.1102
At iterate    21  f =      -281.89  |proj g|=        1.1142
At iterate    22  f =       -281.9  |proj g|=        1.1074
At iterate    23  f =       -281.9  |proj g|=        1.1071
At iterate    24  f =       -281.9  |proj g|=        1.1074
At iterate    25  f =       -281.9  |proj g|=        1.1073
At iterate    26  f =       -281.9  |proj g|=        1.1074
At iterate    27  f =       -281.9  |proj g|=        1.1074
At iterate    28  f =       -281.9  |proj g|=        1.1075
At iterate    29  f =       -281.9  |proj g|=        1.1075
At iterate    30  f =       -281.9  |proj g|=        1.1072
At iterate    31  f =       -281.9  |proj g|=        1.1073
At iterate    32  f =      -281.91  |proj g|=        1.1039
At iterate    33  f =      -281.91  |proj g|=        1.1083
At iterate    34  f =      -281.92  |proj g|=        1.1023
At iterate    35  f =      -282.96  |proj g|=       0.81295
At iterate    36  f =       -283.3  |proj g|=       0.81243
At iterate    37  f =      -283.36  |proj g|=       0.80239
At iterate    38  f =      -283.36  |proj g|=      0.098401
At iterate    39  f =      -283.36  |proj g|=      0.017748
At iterate    40  f =      -283.36  |proj g|=     0.0026164

iterations 40
function evaluations 49
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00261637
final function value -283.365

F = -283.365
final  value -283.364664 
converged
 
INFO  [01:10:11.904] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:10:11.975] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:10:11.983] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:10:21.729] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:10:34.184] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:10:45.730] [mlr3]  Finished benchmark 
INFO  [01:10:45.798] [bbotk] Result of batch 49: 
INFO  [01:10:45.800] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:10:45.800] [bbotk]              5.347765                 6.210595                       0.3083115 
INFO  [01:10:45.800] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:10:45.800] [bbotk]                     3711        0.642 -0.9646522         <NA>    0.977548 
INFO  [01:10:45.800] [bbotk]                                 uhash 
INFO  [01:10:45.800] [bbotk]  6a60ae30-a1f2-4029-8760-7d4885568268 
DEBUG [01:10:46.646] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.59071e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  2.59071e-05 0.003497917 
  - best initial criterion value(s) :  262.629 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -262.63  |proj g|=      0.74874
At iterate     1  f =      -273.04  |proj g|=        1.9971
At iterate     2  f =      -274.61  |proj g|=        1.8533
At iterate     3  f =      -275.65  |proj g|=        1.0664
At iterate     4  f =      -276.35  |proj g|=        1.4927
At iterate     5  f =      -276.46  |proj g|=         1.421
At iterate     6  f =      -276.63  |proj g|=        1.3241
At iterate     7  f =      -276.95  |proj g|=        1.2324
At iterate     8  f =      -277.54  |proj g|=        1.2198
At iterate     9  f =      -277.68  |proj g|=        1.2598
At iterate    10  f =      -277.71  |proj g|=        1.3009
At iterate    11  f =      -277.71  |proj g|=        1.3201
At iterate    12  f =      -277.71  |proj g|=        1.3237
At iterate    13  f =      -277.71  |proj g|=        1.3238

iterations 13
function evaluations 15
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.32375
final function value -277.715

F = -277.715
final  value -277.714536 
converged
 
INFO  [01:10:46.650] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:10:46.705] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:10:46.711] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:10:59.285] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:11:14.057] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:11:28.612] [mlr3]  Finished benchmark 
INFO  [01:11:28.679] [bbotk] Result of batch 50: 
INFO  [01:11:28.681] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:11:28.681] [bbotk]              9.280033                 8.181079                      0.07288311 
INFO  [01:11:28.681] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:11:28.681] [bbotk]                     4507        0.622 -0.9614051         <NA>   0.9734649 
INFO  [01:11:28.681] [bbotk]                                 uhash 
INFO  [01:11:28.681] [bbotk]  12c68827-2e62-43a2-be18-567afc46a546 
DEBUG [01:11:29.598] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.560764e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  2.560764e-05 0.003469689 
  - best initial criterion value(s) :  274.1258 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -274.13  |proj g|=       1.8232
At iterate     1  f =      -274.26  |proj g|=        1.8488
At iterate     2  f =      -276.21  |proj g|=        1.7354
At iterate     3  f =       -277.7  |proj g|=        1.5565
At iterate     4  f =      -277.73  |proj g|=        1.4871
At iterate     5  f =      -277.78  |proj g|=         1.519
At iterate     6  f =      -277.78  |proj g|=         1.516
At iterate     7  f =      -277.78  |proj g|=        1.5162
At iterate     8  f =      -277.78  |proj g|=        1.5163
At iterate     9  f =      -277.78  |proj g|=        1.5174
At iterate    10  f =      -277.78  |proj g|=        1.5204
At iterate    11  f =      -277.78  |proj g|=        1.5255
At iterate    12  f =      -277.79  |proj g|=        1.5329
At iterate    13  f =      -277.82  |proj g|=        1.5426
At iterate    14  f =      -277.82  |proj g|=        1.5493
At iterate    15  f =      -277.89  |proj g|=        1.5568
At iterate    16  f =      -278.04  |proj g|=        1.5594
At iterate    17  f =       -278.4  |proj g|=        1.5408
At iterate    18  f =      -279.21  |proj g|=        1.4639
At iterate    19  f =      -280.72  |proj g|=        1.2885
At iterate    20  f =      -282.56  |proj g|=       0.98499
At iterate    21  f =      -284.81  |proj g|=       0.50512
At iterate    22  f =      -285.85  |proj g|=       0.55589
At iterate    23  f =      -287.63  |proj g|=       0.60466
At iterate    24  f =      -287.91  |proj g|=       0.84559
At iterate    25  f =      -288.22  |proj g|=       0.82359
At iterate    26  f =      -288.26  |proj g|=       0.50103
At iterate    27  f =      -288.26  |proj g|=       0.49589
At iterate    28  f =      -288.26  |proj g|=       0.49669
At iterate    29  f =      -288.26  |proj g|=       0.49668

iterations 29
function evaluations 39
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.496683
final function value -288.262

F = -288.262
final  value -288.262456 
converged
 
INFO  [01:11:29.600] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:11:29.645] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:11:29.651] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:11:37.379] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:11:44.125] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:11:50.212] [mlr3]  Finished benchmark 
INFO  [01:11:50.280] [bbotk] Result of batch 51: 
INFO  [01:11:50.282] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:11:50.282] [bbotk]              4.723646                 5.496495                       0.4674188 
INFO  [01:11:50.282] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:11:50.282] [bbotk]                     2462        0.636 -0.9699227         <NA>   0.9770395 
INFO  [01:11:50.282] [bbotk]                                 uhash 
INFO  [01:11:50.282] [bbotk]  1dfdcbd8-b736-49cd-8899-6cd48ceb5bb5 
DEBUG [01:11:51.382] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.536883e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  2.536883e-05 0.003457072 
  - best initial criterion value(s) :  270.2615 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -270.26  |proj g|=       2.8763
At iterate     1  f =      -277.97  |proj g|=        2.4004
At iterate     2  f =      -278.29  |proj g|=        2.7787
At iterate     3  f =      -281.09  |proj g|=        2.6201
At iterate     4  f =      -281.25  |proj g|=        2.5234
At iterate     5  f =      -281.26  |proj g|=        2.5782
At iterate     6  f =      -281.26  |proj g|=        2.5762
At iterate     7  f =      -281.26  |proj g|=        2.5767
At iterate     8  f =      -281.26  |proj g|=        2.5769
At iterate     9  f =      -281.26  |proj g|=        2.5775
At iterate    10  f =      -281.26  |proj g|=        2.5784
At iterate    11  f =      -281.26  |proj g|=          2.58
At iterate    12  f =      -281.26  |proj g|=        2.5818
At iterate    13  f =      -281.27  |proj g|=        2.5836
At iterate    14  f =      -281.27  |proj g|=        2.5864
At iterate    15  f =      -281.27  |proj g|=        2.5812
At iterate    16  f =      -281.27  |proj g|=        2.5985
At iterate    17  f =      -281.29  |proj g|=        2.5878
At iterate    18  f =      -293.79  |proj g|=        1.0365
At iterate    19  f =      -294.75  |proj g|=       0.89551
At iterate    20  f =      -294.97  |proj g|=       0.89248
At iterate    21  f =      -295.11  |proj g|=       0.83044
At iterate    22  f =      -295.12  |proj g|=        0.8316
At iterate    23  f =      -295.12  |proj g|=       0.84123
At iterate    24  f =      -295.12  |proj g|=       0.83471
At iterate    25  f =      -295.12  |proj g|=        0.8347

iterations 25
function evaluations 33
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.834696
final function value -295.124

F = -295.124
final  value -295.123590 
converged
 
INFO  [01:11:51.386] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:11:51.442] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:11:51.449] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:12:01.660] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:12:13.608] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:12:27.773] [mlr3]  Finished benchmark 
INFO  [01:12:27.841] [bbotk] Result of batch 52: 
INFO  [01:12:27.843] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:12:27.843] [bbotk]               5.51154                 2.808546                       0.4731164 
INFO  [01:12:27.843] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [01:12:27.843] [bbotk]                     3858        0.833 -0.964582         <NA>   0.9787528 
INFO  [01:12:27.843] [bbotk]                                 uhash 
INFO  [01:12:27.843] [bbotk]  21f9faef-bfcd-4f07-95de-c306f63a8ca3 
DEBUG [01:12:28.746] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.517002e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  2.517002e-05 0.003445983 
  - best initial criterion value(s) :  244.7949 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -244.79  |proj g|=      0.71958
At iterate     1  f =      -260.45  |proj g|=        3.5258
At iterate     2  f =      -270.76  |proj g|=        3.5035
At iterate     3  f =      -277.02  |proj g|=        3.2394
At iterate     4  f =      -278.05  |proj g|=        2.9324
At iterate     5  f =      -278.22  |proj g|=        3.0152
At iterate     6  f =      -278.39  |proj g|=        2.9997
At iterate     7  f =      -278.71  |proj g|=        2.8187
At iterate     8  f =      -278.78  |proj g|=        2.8938
At iterate     9  f =      -278.79  |proj g|=        2.8772
At iterate    10  f =      -278.79  |proj g|=        2.8751
At iterate    11  f =      -278.79  |proj g|=        2.8753
At iterate    12  f =      -278.79  |proj g|=        2.8758
At iterate    13  f =      -278.79  |proj g|=        2.8765
At iterate    14  f =      -278.79  |proj g|=        2.8776
At iterate    15  f =      -278.79  |proj g|=        2.8794
At iterate    16  f =      -278.79  |proj g|=        2.8823
At iterate    17  f =      -278.79  |proj g|=        2.8868
At iterate    18  f =       -278.8  |proj g|=        2.8941
At iterate    19  f =      -278.81  |proj g|=        2.9055
At iterate    20  f =      -278.85  |proj g|=        2.9217
At iterate    21  f =      -278.92  |proj g|=        2.9384
At iterate    22  f =      -279.06  |proj g|=         2.935
At iterate    23  f =      -279.15  |proj g|=        2.8748
At iterate    24  f =      -279.17  |proj g|=         2.874
At iterate    25  f =      -279.54  |proj g|=        2.7417
At iterate    26  f =      -280.62  |proj g|=        2.5278
At iterate    27  f =      -285.91  |proj g|=        1.7224
At iterate    28  f =       -292.7  |proj g|=        1.1098
At iterate    29  f =      -294.28  |proj g|=        1.5202
At iterate    30  f =      -295.09  |proj g|=        1.4544
At iterate    31  f =      -296.02  |proj g|=        1.3293
At iterate    32  f =       -296.4  |proj g|=        1.3164
At iterate    33  f =      -296.61  |proj g|=        1.4671
At iterate    34  f =      -296.64  |proj g|=        1.4394
At iterate    35  f =      -296.64  |proj g|=        1.4339
At iterate    36  f =      -296.64  |proj g|=        1.4344
At iterate    37  f =      -296.64  |proj g|=        1.4343

iterations 37
function evaluations 46
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.43434
final function value -296.641

F = -296.641
final  value -296.641203 
converged
 
INFO  [01:12:28.750] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:12:28.806] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:12:28.814] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:12:31.517] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:12:35.164] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:12:38.972] [mlr3]  Finished benchmark 
INFO  [01:12:39.040] [bbotk] Result of batch 53: 
INFO  [01:12:39.042] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:12:39.042] [bbotk]              4.940291                 4.497895                       0.4386198 
INFO  [01:12:39.042] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:12:39.042] [bbotk]                      911        0.639 -0.9678901         <NA>   0.9735409 
INFO  [01:12:39.042] [bbotk]                                 uhash 
INFO  [01:12:39.042] [bbotk]  d77edb0d-f493-45fc-b268-dcf012cf3da1 
DEBUG [01:12:39.922] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.48883e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  2.48883e-05 0.003368962 
  - best initial criterion value(s) :  251.6972 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -251.7  |proj g|=       14.461
At iterate     1  f =       -268.2  |proj g|=        3.5845
At iterate     2  f =      -269.89  |proj g|=        4.5029
At iterate     3  f =      -270.44  |proj g|=        4.0494
At iterate     4  f =      -270.99  |proj g|=        3.5591
At iterate     5  f =      -271.24  |proj g|=        3.3462
At iterate     6  f =       -271.5  |proj g|=        3.1022
At iterate     7  f =       -271.7  |proj g|=        2.8815
At iterate     8  f =      -271.85  |proj g|=        3.3487
At iterate     9  f =      -272.28  |proj g|=        2.7002
At iterate    10  f =      -272.34  |proj g|=        2.5256
At iterate    11  f =      -272.56  |proj g|=        2.4124
At iterate    12  f =      -273.16  |proj g|=        2.1859
At iterate    13  f =       -273.8  |proj g|=        1.9187
At iterate    14  f =      -274.06  |proj g|=         1.817
At iterate    15  f =      -275.17  |proj g|=        1.6311
At iterate    16  f =      -279.77  |proj g|=        1.3479
At iterate    17  f =      -283.09  |proj g|=         1.923
At iterate    18  f =      -298.75  |proj g|=        1.8717
At iterate    19  f =      -300.65  |proj g|=        1.4475
At iterate    20  f =      -301.03  |proj g|=         1.492
At iterate    21  f =      -301.04  |proj g|=        1.5234
At iterate    22  f =      -301.04  |proj g|=        1.5151
At iterate    23  f =      -301.04  |proj g|=        1.5148
At iterate    24  f =      -301.04  |proj g|=        1.5148

iterations 24
function evaluations 33
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.51478
final function value -301.041

F = -301.041
final  value -301.041226 
converged
 
INFO  [01:12:39.926] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:12:39.984] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:12:39.991] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:12:48.490] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:12:58.428] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:13:07.184] [mlr3]  Finished benchmark 
INFO  [01:13:07.253] [bbotk] Result of batch 54: 
INFO  [01:13:07.255] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:13:07.255] [bbotk]              8.543997                 6.519966                      0.08250231 
INFO  [01:13:07.255] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:13:07.255] [bbotk]                     3184        0.594 -0.9658027         <NA>   0.9727021 
INFO  [01:13:07.255] [bbotk]                                 uhash 
INFO  [01:13:07.255] [bbotk]  ca62ca7f-dc85-4bc5-a851-3a2621b564e6 
DEBUG [01:13:08.104] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.460531e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  2.460531e-05 0.003346172 
  - best initial criterion value(s) :  287.5233 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -287.52  |proj g|=       2.3157
At iterate     1  f =      -291.74  |proj g|=        2.0538
At iterate     2  f =      -294.35  |proj g|=        2.3878
At iterate     3  f =      -294.37  |proj g|=        2.3627
At iterate     4  f =      -294.38  |proj g|=        2.3378
At iterate     5  f =      -294.38  |proj g|=        2.3373
At iterate     6  f =      -294.38  |proj g|=        2.3368
At iterate     7  f =      -294.38  |proj g|=        2.3374
At iterate     8  f =      -294.38  |proj g|=        2.3365
At iterate     9  f =      -294.38  |proj g|=        2.3369
At iterate    10  f =      -294.39  |proj g|=         2.323
At iterate    11  f =       -294.4  |proj g|=        2.3266
At iterate    12  f =      -294.44  |proj g|=        2.3318
At iterate    13  f =      -294.53  |proj g|=        2.3289
At iterate    14  f =       -294.8  |proj g|=        2.2974
At iterate    15  f =      -295.51  |proj g|=        2.1796
At iterate    16  f =      -297.32  |proj g|=        1.8186
At iterate    17  f =      -297.47  |proj g|=        1.8674
At iterate    18  f =      -301.81  |proj g|=        1.2497
At iterate    19  f =      -309.94  |proj g|=       0.85869
At iterate    20  f =      -311.02  |proj g|=       0.83718
At iterate    21  f =      -311.42  |proj g|=       0.81767
At iterate    22  f =      -311.47  |proj g|=        0.2349
At iterate    23  f =      -311.47  |proj g|=       0.80917
At iterate    24  f =      -311.47  |proj g|=       0.23479
At iterate    25  f =      -311.47  |proj g|=       0.23479
At iterate    26  f =      -311.47  |proj g|=       0.23479

iterations 26
function evaluations 36
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.234787
final function value -311.469

F = -311.469
final  value -311.469134 
converged
 
INFO  [01:13:08.108] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:13:08.189] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:13:08.198] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:13:16.431] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:13:25.025] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:13:35.133] [mlr3]  Finished benchmark 
INFO  [01:13:35.201] [bbotk] Result of batch 55: 
INFO  [01:13:35.203] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:13:35.203] [bbotk]              6.739243                 7.254605                       0.4937173 
INFO  [01:13:35.203] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:13:35.203] [bbotk]                     3055        0.601 -0.9666679         <NA>   0.9785649 
INFO  [01:13:35.203] [bbotk]                                 uhash 
INFO  [01:13:35.203] [bbotk]  79c20058-0bd8-499f-b34d-dcbfe0da5a5a 
DEBUG [01:13:36.137] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.441396e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  2.441396e-05 0.003336793 
  - best initial criterion value(s) :  294.6831 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -294.68  |proj g|=       1.4473
At iterate     1  f =      -296.38  |proj g|=        3.7693
At iterate     2  f =      -299.23  |proj g|=        3.6194
At iterate     3  f =      -302.34  |proj g|=        2.9716
At iterate     4  f =       -302.4  |proj g|=        2.9395
At iterate     5  f =      -302.74  |proj g|=         2.818
At iterate     6  f =      -302.76  |proj g|=        2.8734
At iterate     7  f =      -302.76  |proj g|=        2.8599
At iterate     8  f =      -302.76  |proj g|=        2.8596
At iterate     9  f =      -302.76  |proj g|=        2.8578
At iterate    10  f =      -302.77  |proj g|=        2.8529
At iterate    11  f =      -302.77  |proj g|=        2.8432
At iterate    12  f =      -302.77  |proj g|=        2.8282
At iterate    13  f =      -302.78  |proj g|=        2.8018
At iterate    14  f =      -302.82  |proj g|=         2.755
At iterate    15  f =      -302.91  |proj g|=        2.6699
At iterate    16  f =      -303.16  |proj g|=        2.5156
At iterate    17  f =      -303.75  |proj g|=        2.2713
At iterate    18  f =      -304.49  |proj g|=        2.1843
At iterate    19  f =      -304.77  |proj g|=         2.285
At iterate    20  f =      -304.87  |proj g|=        2.3414
At iterate    21  f =      -304.94  |proj g|=        2.3807
At iterate    22  f =      -305.08  |proj g|=         2.428
At iterate    23  f =      -305.32  |proj g|=        2.4774
At iterate    24  f =       -305.8  |proj g|=        2.4821
At iterate    25  f =      -306.14  |proj g|=        2.3141
At iterate    26  f =      -306.27  |proj g|=        2.3042
At iterate    27  f =      -306.27  |proj g|=        2.2873
At iterate    28  f =      -306.27  |proj g|=        2.2945
At iterate    29  f =      -306.27  |proj g|=         2.295
At iterate    30  f =      -306.27  |proj g|=        2.2951
At iterate    31  f =      -306.27  |proj g|=        2.2956
At iterate    32  f =      -306.27  |proj g|=        2.2962
At iterate    33  f =      -306.27  |proj g|=        2.2981
At iterate    34  f =      -306.27  |proj g|=        2.2995
At iterate    35  f =      -306.27  |proj g|=         2.303
At iterate    36  f =      -306.28  |proj g|=        2.3044
At iterate    37  f =      -306.29  |proj g|=        2.3223
At iterate    38  f =       -306.3  |proj g|=        2.3211
At iterate    39  f =      -306.42  |proj g|=        2.3193
At iterate    40  f =      -306.63  |proj g|=        2.2548
At iterate    41  f =      -306.95  |proj g|=        2.2211
At iterate    42  f =      -307.52  |proj g|=        2.0133
At iterate    43  f =      -308.66  |proj g|=        1.6033
At iterate    44  f =       -310.2  |proj g|=        1.2067
At iterate    45  f =      -314.16  |proj g|=       0.27973
At iterate    46  f =      -315.41  |proj g|=       0.24881
At iterate    47  f =      -315.61  |proj g|=       0.24234
At iterate    48  f =      -316.41  |proj g|=       0.19872
At iterate    49  f =      -316.44  |proj g|=       0.80437
At iterate    50  f =      -316.45  |proj g|=       0.18003
At iterate    51  f =      -316.45  |proj g|=       0.04861
At iterate    52  f =      -316.45  |proj g|=     0.0026624
At iterate    53  f =      -316.45  |proj g|=    0.00064996

iterations 53
function evaluations 61
segments explored during Cauchy searches 56
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000649958
final function value -316.453

F = -316.453
final  value -316.453219 
converged
 
INFO  [01:13:36.141] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:13:36.197] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:13:36.204] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:13:47.446] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:13:55.188] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:14:02.660] [mlr3]  Finished benchmark 
INFO  [01:14:02.729] [bbotk] Result of batch 56: 
INFO  [01:14:02.731] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:14:02.731] [bbotk]              7.364798                 6.356667                       0.4878369 
INFO  [01:14:02.731] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:14:02.731] [bbotk]                     3632        0.602 -0.9659245         <NA>   0.9786999 
INFO  [01:14:02.731] [bbotk]                                 uhash 
INFO  [01:14:02.731] [bbotk]  41ed60b1-4922-4c56-ae05-1f4072dc88aa 
DEBUG [01:14:03.709] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.422767e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  2.422767e-05 0.003369619 
  - best initial criterion value(s) :  270.1995 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -270.2  |proj g|=       8.3551
At iterate     1  f =      -272.69  |proj g|=        1.5018
At iterate     2  f =      -274.34  |proj g|=         2.268
At iterate     3  f =      -275.41  |proj g|=        2.0513
At iterate     4  f =       -276.7  |proj g|=        1.8751
At iterate     5  f =       -278.3  |proj g|=        1.4897
At iterate     6  f =      -278.54  |proj g|=         1.844
At iterate     7  f =      -279.34  |proj g|=        0.9499
At iterate     8  f =      -279.34  |proj g|=       0.93481
At iterate     9  f =      -279.34  |proj g|=       0.93479
At iterate    10  f =      -279.34  |proj g|=       0.93636
At iterate    11  f =      -279.34  |proj g|=        0.9384
At iterate    12  f =      -279.34  |proj g|=       0.94107
At iterate    13  f =      -279.35  |proj g|=       0.94527
At iterate    14  f =      -279.36  |proj g|=       0.95275
At iterate    15  f =      -279.38  |proj g|=       0.96589
At iterate    16  f =      -279.44  |proj g|=       0.98803
At iterate    17  f =       -279.5  |proj g|=       0.99541
At iterate    18  f =      -279.52  |proj g|=       0.99541
At iterate    19  f =      -279.52  |proj g|=       0.99541
At iterate    20  f =      -279.52  |proj g|=       0.99541
At iterate    21  f =      -279.52  |proj g|=       0.99541
At iterate    22  f =      -279.52  |proj g|=       0.99541
At iterate    23  f =      -279.53  |proj g|=        0.9954
At iterate    24  f =      -279.53  |proj g|=       0.99539
At iterate    25  f =      -279.55  |proj g|=        0.9953
At iterate    26  f =      -279.59  |proj g|=        0.9951
At iterate    27  f =      -279.69  |proj g|=       0.99451
At iterate    28  f =      -279.93  |proj g|=       0.99303
At iterate    29  f =      -280.44  |proj g|=       0.98961
At iterate    30  f =      -281.39  |proj g|=       0.98336
At iterate    31  f =      -282.69  |proj g|=       0.98282
At iterate    32  f =      -282.91  |proj g|=       0.98157
At iterate    33  f =      -282.92  |proj g|=       0.98157
At iterate    34  f =      -282.92  |proj g|=       0.98156
At iterate    35  f =      -282.92  |proj g|=       0.98156
At iterate    36  f =      -282.92  |proj g|=       0.98154
At iterate    37  f =      -282.92  |proj g|=       0.98148
At iterate    38  f =      -282.92  |proj g|=       0.98133
At iterate    39  f =      -282.92  |proj g|=        0.9809
At iterate    40  f =      -282.93  |proj g|=       0.97973
At iterate    41  f =      -282.96  |proj g|=       0.97654
At iterate    42  f =      -283.04  |proj g|=       0.96778
At iterate    43  f =      -283.25  |proj g|=       0.94344
At iterate    44  f =      -283.85  |proj g|=       0.87487
At iterate    45  f =      -285.53  |proj g|=        0.6759
At iterate    46  f =      -288.47  |proj g|=        0.6339
At iterate    47  f =      -300.08  |proj g|=       0.23133
At iterate    48  f =      -301.17  |proj g|=       0.75182
At iterate    49  f =      -303.86  |proj g|=       0.82542
At iterate    50  f =      -305.97  |proj g|=       0.85206
At iterate    51  f =      -306.34  |proj g|=       0.19807
At iterate    52  f =      -306.34  |proj g|=       0.19804
At iterate    53  f =      -306.34  |proj g|=       0.19803
At iterate    54  f =      -306.34  |proj g|=       0.19803

iterations 54
function evaluations 69
segments explored during Cauchy searches 56
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.198031
final function value -306.345

F = -306.345
final  value -306.344544 
converged
 
INFO  [01:14:03.713] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:14:03.768] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:14:03.775] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:14:09.796] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:14:16.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:14:22.701] [mlr3]  Finished benchmark 
INFO  [01:14:22.814] [bbotk] Result of batch 57: 
INFO  [01:14:22.818] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:14:22.818] [bbotk]              4.542529                 8.219885                       0.1133295 
INFO  [01:14:22.818] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:14:22.818] [bbotk]                     3270        0.605 -0.9717541         <NA>   0.9726058 
INFO  [01:14:22.818] [bbotk]                                 uhash 
INFO  [01:14:22.818] [bbotk]  1d9eaf66-9d4e-4afe-a2da-cc694af1eb83 
DEBUG [01:14:23.739] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.395952e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  2.395952e-05 0.003344542 
  - best initial criterion value(s) :  283.8792 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -283.88  |proj g|=       5.4639
At iterate     1  f =       -300.2  |proj g|=        4.4819
At iterate     2  f =      -300.25  |proj g|=        4.4289
At iterate     3  f =      -300.29  |proj g|=        4.5063
At iterate     4  f =      -300.31  |proj g|=        4.5931
At iterate     5  f =      -300.31  |proj g|=         4.584
At iterate     6  f =      -300.31  |proj g|=        4.5841
At iterate     7  f =      -300.31  |proj g|=         4.585
At iterate     8  f =      -300.31  |proj g|=        4.5903
At iterate     9  f =      -300.32  |proj g|=        4.5973
At iterate    10  f =      -300.34  |proj g|=        4.6049
At iterate    11  f =       -300.4  |proj g|=        4.6059
At iterate    12  f =      -300.55  |proj g|=        4.5993
At iterate    13  f =       -300.6  |proj g|=        4.4761
At iterate    14  f =      -301.06  |proj g|=        4.3816
At iterate    15  f =      -303.01  |proj g|=         3.804
At iterate    16  f =      -309.18  |proj g|=        2.5109
At iterate    17  f =       -316.7  |proj g|=        1.1956
At iterate    18  f =      -320.31  |proj g|=       0.83211
At iterate    19  f =      -320.33  |proj g|=       0.83051
At iterate    20  f =      -321.17  |proj g|=       0.82682
At iterate    21  f =      -321.17  |proj g|=       0.82631
At iterate    22  f =      -321.17  |proj g|=       0.39346
At iterate    23  f =      -321.17  |proj g|=       0.32648
At iterate    24  f =      -321.17  |proj g|=       0.32648
At iterate    25  f =      -321.17  |proj g|=       0.32648
At iterate    26  f =      -321.17  |proj g|=       0.32647
At iterate    27  f =      -321.17  |proj g|=       0.32645
At iterate    28  f =      -321.17  |proj g|=        0.3264
At iterate    29  f =      -321.17  |proj g|=       0.32624
At iterate    30  f =      -321.17  |proj g|=        0.3259
At iterate    31  f =      -321.17  |proj g|=       0.32483
At iterate    32  f =      -321.18  |proj g|=       0.32243
At iterate    33  f =      -321.18  |proj g|=       0.30963
At iterate    34  f =       -321.2  |proj g|=       0.28097
At iterate    35  f =      -321.23  |proj g|=       0.19954
At iterate    36  f =      -321.27  |proj g|=       0.18778
At iterate    37  f =      -321.34  |proj g|=       0.18603
At iterate    38  f =      -321.43  |proj g|=       0.17749
At iterate    39  f =      -321.46  |proj g|=       0.17349
At iterate    40  f =      -321.46  |proj g|=       0.20826
At iterate    41  f =      -321.46  |proj g|=      0.009852
At iterate    42  f =      -321.46  |proj g|=     0.0098525

iterations 42
function evaluations 52
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00985248
final function value -321.464

F = -321.464
final  value -321.463812 
converged
 
INFO  [01:14:23.745] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:14:23.821] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:14:23.829] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:14:31.241] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:14:38.367] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:14:46.059] [mlr3]  Finished benchmark 
INFO  [01:14:46.130] [bbotk] Result of batch 58: 
INFO  [01:14:46.132] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:14:46.132] [bbotk]              6.097864                 7.191696                      0.02654475 
INFO  [01:14:46.132] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:14:46.132] [bbotk]                     3779        0.604 -0.9692396         <NA>   0.9635233 
INFO  [01:14:46.132] [bbotk]                                 uhash 
INFO  [01:14:46.132] [bbotk]  2bfa8227-000a-4339-81cf-0891c91bef34 
DEBUG [01:14:47.058] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.372909e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  2.372909e-05 0.00331539 
  - best initial criterion value(s) :  293.0921 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -293.09  |proj g|=       6.7321
At iterate     1  f =      -296.99  |proj g|=        5.1781
At iterate     2  f =      -297.23  |proj g|=        5.3389
At iterate     3  f =      -297.28  |proj g|=        5.2634
At iterate     4  f =      -297.29  |proj g|=        5.2289
At iterate     5  f =       -297.3  |proj g|=        5.2116
At iterate     6  f =      -297.67  |proj g|=        5.3125
At iterate     7  f =      -298.26  |proj g|=        5.1922
At iterate     8  f =      -301.85  |proj g|=        4.0147
At iterate     9  f =      -307.03  |proj g|=        2.7538
At iterate    10  f =      -308.35  |proj g|=         2.321
At iterate    11  f =      -312.39  |proj g|=        1.6058
At iterate    12  f =      -314.94  |proj g|=       0.85368
At iterate    13  f =      -328.47  |proj g|=       0.75363
At iterate    14  f =      -328.86  |proj g|=       0.80557
At iterate    15  f =      -328.87  |proj g|=       0.82812
At iterate    16  f =      -328.87  |proj g|=       0.83141
At iterate    17  f =      -328.87  |proj g|=       0.83095
At iterate    18  f =      -328.87  |proj g|=       0.83094

iterations 18
function evaluations 29
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.830937
final function value -328.87

F = -328.87
final  value -328.870331 
converged
 
INFO  [01:14:47.062] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:14:47.118] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:14:47.125] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:14:51.811] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:14:56.599] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:15:01.430] [mlr3]  Finished benchmark 
INFO  [01:15:01.544] [bbotk] Result of batch 59: 
INFO  [01:15:01.547] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:15:01.547] [bbotk]              9.234012                 8.408746                       0.4626125 
INFO  [01:15:01.547] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:15:01.547] [bbotk]                     2364        0.641 -0.9658008         <NA>     0.97757 
INFO  [01:15:01.547] [bbotk]                                 uhash 
INFO  [01:15:01.547] [bbotk]  25fc4ed5-bb77-4b76-8997-6ca98766bf82 
DEBUG [01:15:02.446] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.353381e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9498 
  - variance bounds :  2.353381e-05 0.003298749 
  - best initial criterion value(s) :  283.484 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -283.48  |proj g|=       8.9547
At iterate     1  f =      -293.79  |proj g|=        2.5994
At iterate     2  f =      -294.49  |proj g|=        4.1185
At iterate     3  f =      -294.61  |proj g|=        3.8193
At iterate     4  f =      -294.64  |proj g|=        3.6842
At iterate     5  f =      -294.67  |proj g|=        3.6634
At iterate     6  f =      -294.72  |proj g|=        3.7227
At iterate     7  f =      -294.74  |proj g|=        3.8767
At iterate     8  f =      -294.74  |proj g|=        3.9466
At iterate     9  f =      -294.74  |proj g|=        3.9395
At iterate    10  f =      -294.74  |proj g|=        3.9261
At iterate    11  f =      -294.76  |proj g|=        3.8796
At iterate    12  f =      -294.81  |proj g|=        3.7653
At iterate    13  f =      -294.91  |proj g|=        3.5773
At iterate    14  f =      -295.17  |proj g|=        3.4394
At iterate    15  f =      -295.42  |proj g|=        2.6173
At iterate    16  f =      -295.84  |proj g|=        2.7602
At iterate    17  f =       -298.2  |proj g|=        3.1847
At iterate    18  f =      -300.36  |proj g|=        2.9525
At iterate    19  f =      -302.69  |proj g|=        2.4796
At iterate    20  f =      -323.45  |proj g|=        1.6247
At iterate    21  f =      -323.94  |proj g|=        1.5032
At iterate    22  f =      -325.47  |proj g|=        1.6128
At iterate    23  f =      -326.19  |proj g|=        1.4555
At iterate    24  f =      -326.43  |proj g|=        1.5105
At iterate    25  f =       -326.5  |proj g|=        1.5369
At iterate    26  f =       -326.5  |proj g|=        1.5467
At iterate    27  f =       -326.5  |proj g|=        1.5492
At iterate    28  f =       -326.5  |proj g|=        1.5496
At iterate    29  f =       -326.5  |proj g|=        1.5497

iterations 29
function evaluations 36
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.54967
final function value -326.504

F = -326.504
final  value -326.503612 
converged
 
INFO  [01:15:02.452] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:15:02.520] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:15:02.529] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:15:13.937] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:15:30.276] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:15:47.503] [mlr3]  Finished benchmark 
INFO  [01:15:47.590] [bbotk] Result of batch 60: 
INFO  [01:15:47.592] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:15:47.592] [bbotk]              6.397045                  7.52717                       0.3767367 
INFO  [01:15:47.592] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:15:47.592] [bbotk]                     4971        0.623 -0.9597362         <NA>   0.9789687 
INFO  [01:15:47.592] [bbotk]                                 uhash 
INFO  [01:15:47.592] [bbotk]  5ca65c08-c07c-46dd-8b03-cee6402183bf 
DEBUG [01:15:48.461] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.336783e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9530 
  - variance bounds :  2.336783e-05 0.003288744 
  - best initial criterion value(s) :  289.8974 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -289.9  |proj g|=      0.55301
At iterate     1  f =      -290.42  |proj g|=       0.78535
At iterate     2  f =      -290.55  |proj g|=       0.58853
At iterate     3  f =      -290.57  |proj g|=       0.58389
At iterate     4  f =      -290.57  |proj g|=       0.58446
At iterate     5  f =      -290.57  |proj g|=       0.58499
At iterate     6  f =      -290.58  |proj g|=       0.58577
At iterate     7  f =      -290.59  |proj g|=       0.58615
At iterate     8  f =      -290.62  |proj g|=       0.58486
At iterate     9  f =      -290.66  |proj g|=       0.80409
At iterate    10  f =      -290.72  |proj g|=       0.81534
At iterate    11  f =      -290.72  |proj g|=       0.81387
At iterate    12  f =      -290.72  |proj g|=       0.81367
At iterate    13  f =      -290.72  |proj g|=        0.8137

iterations 13
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.813702
final function value -290.721

F = -290.721
final  value -290.720858 
converged
 
INFO  [01:15:48.465] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:15:48.522] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:15:48.530] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:15:56.282] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:16:05.250] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:16:14.600] [mlr3]  Finished benchmark 
INFO  [01:16:14.686] [bbotk] Result of batch 61: 
INFO  [01:16:14.688] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:16:14.688] [bbotk]               9.11316                 5.027485                       0.1326519 
INFO  [01:16:14.688] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:16:14.688] [bbotk]                     2853        0.639 -0.9784315         <NA>   0.9742149 
INFO  [01:16:14.688] [bbotk]                                 uhash 
INFO  [01:16:14.688] [bbotk]  43b71b48-089f-47d0-9103-21bf0b384416 
DEBUG [01:16:15.625] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.313273e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9530 
  - variance bounds :  2.313272e-05 0.003266525 
  - best initial criterion value(s) :  290.2561 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -290.26  |proj g|=       1.2049
At iterate     1  f =      -309.09  |proj g|=        1.9022
At iterate     2  f =      -309.31  |proj g|=        1.9482
At iterate     3  f =      -309.36  |proj g|=         1.934
At iterate     4  f =      -309.39  |proj g|=        1.9202
At iterate     5  f =      -309.39  |proj g|=        1.9173
At iterate     6  f =      -309.39  |proj g|=        1.9166
At iterate     7  f =      -309.39  |proj g|=        1.9168
At iterate     8  f =      -309.39  |proj g|=        1.9168
At iterate     9  f =      -309.39  |proj g|=         1.917
At iterate    10  f =      -309.39  |proj g|=        1.9173
At iterate    11  f =      -309.39  |proj g|=        1.9177
At iterate    12  f =       -309.4  |proj g|=        1.9184
At iterate    13  f =       -309.4  |proj g|=        1.9196
At iterate    14  f =       -309.4  |proj g|=        1.9214
At iterate    15  f =       -309.4  |proj g|=        1.9238
At iterate    16  f =      -309.41  |proj g|=        1.9261
At iterate    17  f =      -309.42  |proj g|=        1.9267
At iterate    18  f =      -309.44  |proj g|=        1.9277
At iterate    19  f =       -309.5  |proj g|=        1.9171
At iterate    20  f =      -309.68  |proj g|=        1.8822
At iterate    21  f =      -309.81  |proj g|=         1.827
At iterate    22  f =      -310.34  |proj g|=        1.7151
At iterate    23  f =      -311.72  |proj g|=        1.4225
At iterate    24  f =      -313.77  |proj g|=        1.0404
At iterate    25  f =       -317.5  |proj g|=       0.86335
At iterate    26  f =      -319.86  |proj g|=       0.83907
At iterate    27  f =      -320.08  |proj g|=       0.84637
At iterate    28  f =      -320.12  |proj g|=        0.6936
At iterate    29  f =      -320.12  |proj g|=       0.36774
At iterate    30  f =      -320.12  |proj g|=        0.3669
At iterate    31  f =      -320.12  |proj g|=       0.36689

iterations 31
function evaluations 41
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.366893
final function value -320.123

F = -320.123
final  value -320.122605 
converged
 
INFO  [01:16:15.629] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:16:15.683] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:16:15.689] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:16:18.620] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:16:21.632] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:16:24.433] [mlr3]  Finished benchmark 
INFO  [01:16:24.529] [bbotk] Result of batch 62: 
INFO  [01:16:24.531] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:16:24.531] [bbotk]              5.582578                  9.53657                        0.206717 
INFO  [01:16:24.531] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:16:24.531] [bbotk]                      976         0.64 -0.9730667         <NA>   0.9699443 
INFO  [01:16:24.531] [bbotk]                                 uhash 
INFO  [01:16:24.531] [bbotk]  407d2dbf-e608-43fb-9407-7b80ded1323b 
DEBUG [01:16:25.611] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.288131e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.31165 15.85569 0.9954084 9530 
  - variance bounds :  2.288131e-05 0.003200959 
  - best initial criterion value(s) :  315.7171 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -315.72  |proj g|=       1.2734
At iterate     1  f =      -319.19  |proj g|=       0.93905
At iterate     2  f =      -319.27  |proj g|=       0.94131
At iterate     3  f =      -319.63  |proj g|=        0.8601
At iterate     4  f =      -319.67  |proj g|=       0.86386
At iterate     5  f =      -319.69  |proj g|=       0.85888
At iterate     6  f =      -319.69  |proj g|=       0.85756
At iterate     7  f =      -319.69  |proj g|=       0.85786
At iterate     8  f =       -319.7  |proj g|=        0.8575
At iterate     9  f =       -319.7  |proj g|=       0.85667
At iterate    10  f =       -319.7  |proj g|=       0.85486
At iterate    11  f =       -319.7  |proj g|=       0.85204
At iterate    12  f =      -319.72  |proj g|=       0.85118
At iterate    13  f =      -319.76  |proj g|=       0.85312
At iterate    14  f =      -319.87  |proj g|=       0.85682
At iterate    15  f =      -320.14  |proj g|=       0.86345
At iterate    16  f =      -320.69  |proj g|=       0.87181
At iterate    17  f =      -321.42  |proj g|=       0.86653
At iterate    18  f =      -322.05  |proj g|=       0.85458
At iterate    19  f =      -322.34  |proj g|=       0.84335
At iterate    20  f =      -322.39  |proj g|=       0.43424
At iterate    21  f =      -322.39  |proj g|=       0.44447
At iterate    22  f =      -322.39  |proj g|=       0.44594
At iterate    23  f =      -322.39  |proj g|=         0.446

iterations 23
function evaluations 32
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.446004
final function value -322.391

F = -322.391
final  value -322.390854 
converged
 
INFO  [01:16:25.615] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:16:25.671] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:16:25.678] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:16:34.579] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:16:42.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:16:50.921] [mlr3]  Finished benchmark 
INFO  [01:16:50.988] [bbotk] Result of batch 63: 
INFO  [01:16:50.990] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:16:50.990] [bbotk]              9.930228                 2.282911                      0.01475592 
INFO  [01:16:50.990] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:16:50.990] [bbotk]                     3003        0.793 -0.9726272         <NA>    0.955848 
INFO  [01:16:50.990] [bbotk]                                 uhash 
INFO  [01:16:50.990] [bbotk]  976b65fc-39cd-4408-85d7-708c34173583 
DEBUG [01:16:51.892] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.284232e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.284232e-05 0.003180386 
  - best initial criterion value(s) :  305.9811 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -305.98  |proj g|=       2.3887
At iterate     1  f =      -309.62  |proj g|=        5.1738
At iterate     2  f =      -311.48  |proj g|=        5.0067
At iterate     3  f =      -313.28  |proj g|=        4.4717
At iterate     4  f =      -313.42  |proj g|=         4.169
At iterate     5  f =      -313.56  |proj g|=        4.2204
At iterate     6  f =      -314.02  |proj g|=        4.1897
At iterate     7  f =      -314.15  |proj g|=        4.0608
At iterate     8  f =      -314.17  |proj g|=        3.9759
At iterate     9  f =      -314.17  |proj g|=        3.9769
At iterate    10  f =      -314.17  |proj g|=        3.9783
At iterate    11  f =      -314.18  |proj g|=        3.9807
At iterate    12  f =      -314.18  |proj g|=        3.9852
At iterate    13  f =       -314.2  |proj g|=          3.99
At iterate    14  f =      -314.26  |proj g|=        3.9948
At iterate    15  f =      -314.39  |proj g|=        4.0222
At iterate    16  f =      -314.41  |proj g|=        3.9542
At iterate    17  f =      -314.71  |proj g|=        3.9564
At iterate    18  f =      -325.58  |proj g|=        2.7408
At iterate    19  f =      -345.55  |proj g|=        1.4504
At iterate    20  f =      -349.05  |proj g|=        1.0231
At iterate    21  f =      -349.05  |proj g|=        1.0231
At iterate    22  f =      -349.05  |proj g|=        1.0231
At iterate    23  f =      -349.05  |proj g|=        1.0231
At iterate    24  f =      -349.05  |proj g|=        1.0231

iterations 24
function evaluations 30
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.02309
final function value -349.054

F = -349.054
final  value -349.054030 
converged
 
INFO  [01:16:51.896] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:16:51.952] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:16:51.959] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:16:55.816] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:16:59.376] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:17:02.897] [mlr3]  Finished benchmark 
INFO  [01:17:02.965] [bbotk] Result of batch 64: 
INFO  [01:17:02.967] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:17:02.967] [bbotk]              6.586283                 6.420525                       0.3264121 
INFO  [01:17:02.967] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:17:02.967] [bbotk]                     1255        0.629 -0.9609096         <NA>   0.9746236 
INFO  [01:17:02.967] [bbotk]                                 uhash 
INFO  [01:17:02.967] [bbotk]  167120fb-c07e-4253-bb58-84602b716b92 
DEBUG [01:17:03.898] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.262535e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.262535e-05 0.003117931 
  - best initial criterion value(s) :  334.0049 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -334  |proj g|=       4.0426
At iterate     1  f =      -334.15  |proj g|=         4.304
At iterate     2  f =      -334.91  |proj g|=        4.0965
At iterate     3  f =      -334.98  |proj g|=        3.9279
At iterate     4  f =      -335.01  |proj g|=        3.9852
At iterate     5  f =      -335.01  |proj g|=        3.9778
At iterate     6  f =      -335.01  |proj g|=        3.9753
At iterate     7  f =      -335.01  |proj g|=         3.975
At iterate     8  f =      -335.01  |proj g|=        3.9751
At iterate     9  f =      -335.01  |proj g|=        3.9762
At iterate    10  f =      -335.01  |proj g|=        3.9772
At iterate    11  f =      -335.01  |proj g|=        3.9777
At iterate    12  f =      -335.01  |proj g|=        3.9795
At iterate    13  f =      -335.02  |proj g|=        3.9767
At iterate    14  f =      -335.03  |proj g|=        3.9737
At iterate    15  f =      -335.07  |proj g|=        3.9436
At iterate    16  f =      -335.09  |proj g|=         3.976
At iterate    17  f =      -335.18  |proj g|=        3.9075
At iterate    18  f =      -336.82  |proj g|=        3.4544
At iterate    19  f =       -340.6  |proj g|=        2.6914
At iterate    20  f =      -340.62  |proj g|=        2.6605
At iterate    21  f =      -340.63  |proj g|=        2.6731
At iterate    22  f =      -340.63  |proj g|=        2.6722
At iterate    23  f =      -340.63  |proj g|=        2.6664
At iterate    24  f =      -340.63  |proj g|=        2.6594
At iterate    25  f =      -340.65  |proj g|=        2.6438
At iterate    26  f =      -340.68  |proj g|=        2.6138
At iterate    27  f =      -340.76  |proj g|=        2.5543
At iterate    28  f =      -340.99  |proj g|=        2.4343
At iterate    29  f =      -341.58  |proj g|=        2.1818
At iterate    30  f =      -342.99  |proj g|=        1.5911
At iterate    31  f =      -346.12  |proj g|=       0.92931
At iterate    32  f =      -346.95  |proj g|=        0.2018
At iterate    33  f =      -350.11  |proj g|=       0.17824
At iterate    34  f =      -350.57  |proj g|=       0.17295
At iterate    35  f =      -350.65  |proj g|=       0.48185
At iterate    36  f =      -350.66  |proj g|=       0.82365
At iterate    37  f =      -350.66  |proj g|=       0.82228
At iterate    38  f =      -350.66  |proj g|=       0.82146
At iterate    39  f =      -350.66  |proj g|=        0.4198
At iterate    40  f =      -350.66  |proj g|=      0.012483
At iterate    41  f =      -350.66  |proj g|=      0.012483

iterations 41
function evaluations 46
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0124827
final function value -350.665

F = -350.665
final  value -350.664567 
converged
 
INFO  [01:17:03.902] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:17:03.958] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:17:03.966] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:17:16.746] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:17:28.831] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:17:44.148] [mlr3]  Finished benchmark 
INFO  [01:17:44.224] [bbotk] Result of batch 65: 
INFO  [01:17:44.226] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:17:44.226] [bbotk]              2.962483                 2.519988                       0.4334645 
INFO  [01:17:44.226] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:17:44.226] [bbotk]                     4650        0.615 -0.9686391         <NA>   0.9754223 
INFO  [01:17:44.226] [bbotk]                                 uhash 
INFO  [01:17:44.226] [bbotk]  512423b4-e37e-4d41-b579-d348fa895b06 
DEBUG [01:17:45.187] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.242126e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.242126e-05 0.00310052 
  - best initial criterion value(s) :  314.59 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -314.59  |proj g|=       2.7989
At iterate     1  f =      -319.22  |proj g|=         3.652
At iterate     2  f =      -331.82  |proj g|=        3.6695
At iterate     3  f =      -332.55  |proj g|=        3.3629
At iterate     4  f =      -337.19  |proj g|=        3.0214
At iterate     5  f =      -338.32  |proj g|=        2.7465
At iterate     6  f =      -338.36  |proj g|=        2.7038
At iterate     7  f =      -338.43  |proj g|=        2.7136
At iterate     8  f =      -338.43  |proj g|=        2.7124
At iterate     9  f =      -338.43  |proj g|=         2.713
At iterate    10  f =      -338.43  |proj g|=        2.7131
At iterate    11  f =      -338.43  |proj g|=        2.7133
At iterate    12  f =      -338.43  |proj g|=        2.7135
At iterate    13  f =      -338.43  |proj g|=        2.7137
At iterate    14  f =      -338.43  |proj g|=        2.7138
At iterate    15  f =      -338.43  |proj g|=        2.7131
At iterate    16  f =      -338.45  |proj g|=        2.7087
At iterate    17  f =      -338.48  |proj g|=        2.6927
At iterate    18  f =      -338.55  |proj g|=        2.6473
At iterate    19  f =      -338.68  |proj g|=        2.5525
At iterate    20  f =      -338.73  |proj g|=        2.5072
At iterate    21  f =      -338.76  |proj g|=        2.4694
At iterate    22  f =         -339  |proj g|=         2.391
At iterate    23  f =      -345.71  |proj g|=        1.3539
At iterate    24  f =      -351.23  |proj g|=       0.90273
At iterate    25  f =      -351.63  |proj g|=        0.8942
At iterate    26  f =      -351.81  |proj g|=       0.92228
At iterate    27  f =      -351.82  |proj g|=       0.93703
At iterate    28  f =      -351.82  |proj g|=       0.93838
At iterate    29  f =      -351.82  |proj g|=       0.93821
At iterate    30  f =      -351.82  |proj g|=       0.93819
At iterate    31  f =      -351.82  |proj g|=        0.9353
At iterate    32  f =      -351.82  |proj g|=       0.93338
At iterate    33  f =      -351.83  |proj g|=       0.92699
At iterate    34  f =      -351.85  |proj g|=       0.91605
At iterate    35  f =       -351.9  |proj g|=       0.88953
At iterate    36  f =         -352  |proj g|=       0.84335
At iterate    37  f =      -352.01  |proj g|=       0.81209
At iterate    38  f =      -352.23  |proj g|=       0.72179
At iterate    39  f =      -353.86  |proj g|=       0.83879
At iterate    40  f =      -354.08  |proj g|=       0.17739
At iterate    41  f =      -354.08  |proj g|=       0.17401
At iterate    42  f =      -354.08  |proj g|=      0.017753
At iterate    43  f =      -354.08  |proj g|=      0.013686
At iterate    44  f =      -354.08  |proj g|=      0.013686

iterations 44
function evaluations 52
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0136855
final function value -354.084

F = -354.084
final  value -354.084258 
converged
 
INFO  [01:17:45.191] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:17:45.246] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:17:45.253] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:17:48.901] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:17:53.356] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:17:57.236] [mlr3]  Finished benchmark 
INFO  [01:17:57.304] [bbotk] Result of batch 66: 
INFO  [01:17:57.306] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:17:57.306] [bbotk]              6.692205                  2.57393                       0.0481813 
INFO  [01:17:57.306] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [01:17:57.306] [bbotk]                     1317        0.623 -0.968964         <NA>   0.9588964 
INFO  [01:17:57.306] [bbotk]                                 uhash 
INFO  [01:17:57.306] [bbotk]  d1664783-e95a-4325-9dc7-bd2c54dd466d 
DEBUG [01:17:58.230] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.230943e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.230943e-05 0.003062745 
  - best initial criterion value(s) :  322.8702 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -322.87  |proj g|=       6.4107
At iterate     1  f =      -334.05  |proj g|=        4.1904
At iterate     2  f =      -341.88  |proj g|=        4.6737
At iterate     3  f =      -342.49  |proj g|=        4.4426
At iterate     4  f =      -342.64  |proj g|=         4.745
At iterate     5  f =       -343.1  |proj g|=        4.3739
At iterate     6  f =      -343.16  |proj g|=        4.2663
At iterate     7  f =      -343.92  |proj g|=        3.9946
At iterate     8  f =      -346.44  |proj g|=        3.3188
At iterate     9  f =      -351.01  |proj g|=        2.4137
At iterate    10  f =      -351.55  |proj g|=        1.9055
At iterate    11  f =      -357.46  |proj g|=         1.337
At iterate    12  f =      -358.36  |proj g|=        1.2072
At iterate    13  f =      -361.23  |proj g|=        1.0441
At iterate    14  f =      -362.86  |proj g|=       0.96026
At iterate    15  f =      -363.58  |proj g|=        1.1346
At iterate    16  f =      -363.58  |proj g|=         1.154
At iterate    17  f =      -363.58  |proj g|=        1.1506
At iterate    18  f =      -363.58  |proj g|=        1.1493
At iterate    19  f =      -363.58  |proj g|=        1.1495
At iterate    20  f =      -363.58  |proj g|=        1.1495

iterations 20
function evaluations 30
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.14954
final function value -363.58

F = -363.58
final  value -363.580149 
converged
 
INFO  [01:17:58.234] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:17:58.290] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:17:58.297] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:18:10.189] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:18:22.641] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:18:34.733] [mlr3]  Finished benchmark 
INFO  [01:18:34.802] [bbotk] Result of batch 67: 
INFO  [01:18:34.804] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:18:34.804] [bbotk]              2.338388                 2.913734                       0.3048316 
INFO  [01:18:34.804] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:18:34.804] [bbotk]                     4066        0.642 -0.9631303         <NA>   0.9676604 
INFO  [01:18:34.804] [bbotk]                                 uhash 
INFO  [01:18:34.804] [bbotk]  d9257107-7d54-4603-b688-0075a419f926 
DEBUG [01:18:35.814] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.208347e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.208347e-05 0.003039186 
  - best initial criterion value(s) :  309.2683 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -309.27  |proj g|=       4.2184
At iterate     1  f =      -315.22  |proj g|=         3.891
At iterate     2  f =      -315.68  |proj g|=        3.8618
At iterate     3  f =      -316.23  |proj g|=        4.0495
At iterate     4  f =      -316.26  |proj g|=        4.0778
At iterate     5  f =      -316.26  |proj g|=        4.0825
At iterate     6  f =      -316.26  |proj g|=        4.0827
At iterate     7  f =      -316.26  |proj g|=        4.0833
At iterate     8  f =      -316.26  |proj g|=         4.084
At iterate     9  f =      -316.26  |proj g|=        4.0853
At iterate    10  f =      -316.26  |proj g|=         4.087
At iterate    11  f =      -316.27  |proj g|=        4.0892
At iterate    12  f =      -316.28  |proj g|=        4.0912
At iterate    13  f =       -316.3  |proj g|=        4.0906
At iterate    14  f =      -316.37  |proj g|=        4.0788
At iterate    15  f =      -316.54  |proj g|=        4.0315
At iterate    16  f =         -317  |proj g|=        3.8862
At iterate    17  f =      -318.22  |proj g|=        3.4964
At iterate    18  f =      -321.73  |proj g|=         2.518
At iterate    19  f =      -326.09  |proj g|=        1.9002
At iterate    20  f =      -327.23  |proj g|=        1.7285
At iterate    21  f =      -327.52  |proj g|=        1.6024
At iterate    22  f =      -327.54  |proj g|=         1.547
At iterate    23  f =      -327.56  |proj g|=        1.5365
At iterate    24  f =      -327.56  |proj g|=        1.5417
At iterate    25  f =      -327.56  |proj g|=        1.5451
At iterate    26  f =      -327.56  |proj g|=        1.5522
At iterate    27  f =      -327.57  |proj g|=        1.5659
At iterate    28  f =      -327.59  |proj g|=        1.5871
At iterate    29  f =      -327.63  |proj g|=        1.6251
At iterate    30  f =       -327.7  |proj g|=        1.6871
At iterate    31  f =      -328.08  |proj g|=         1.746
At iterate    32  f =      -328.44  |proj g|=        1.7871
At iterate    33  f =      -332.69  |proj g|=         1.655
At iterate    34  f =      -335.87  |proj g|=        1.2386
At iterate    35  f =      -338.01  |proj g|=        1.2863
At iterate    36  f =      -339.44  |proj g|=          1.21
At iterate    37  f =      -339.78  |proj g|=        1.1681
At iterate    38  f =       -339.8  |proj g|=        1.1627
At iterate    39  f =      -339.81  |proj g|=        1.1652
At iterate    40  f =      -339.81  |proj g|=        1.1646
At iterate    41  f =      -339.81  |proj g|=        1.1648
At iterate    42  f =      -339.81  |proj g|=        1.1648

iterations 42
function evaluations 54
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.16476
final function value -339.806

F = -339.806
final  value -339.805626 
converged
 
INFO  [01:18:35.818] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:18:35.876] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:18:35.883] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:18:40.170] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:18:43.532] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:18:47.104] [mlr3]  Finished benchmark 
INFO  [01:18:47.172] [bbotk] Result of batch 68: 
INFO  [01:18:47.174] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:18:47.174] [bbotk]              6.647637                  8.63655                       0.1892745 
INFO  [01:18:47.174] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:18:47.174] [bbotk]                     1252        0.651 -0.9734727         <NA>   0.9718954 
INFO  [01:18:47.174] [bbotk]                                 uhash 
INFO  [01:18:47.174] [bbotk]  5e962de0-95ba-4eea-b8cb-9e5b513a49c7 
DEBUG [01:18:48.189] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.186331e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.186331e-05 0.002982172 
  - best initial criterion value(s) :  341.9782 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -341.98  |proj g|=       1.2373
At iterate     1  f =      -352.01  |proj g|=        1.6665
At iterate     2  f =      -354.43  |proj g|=        1.6582
At iterate     3  f =      -359.05  |proj g|=        1.5455
At iterate     4  f =      -359.61  |proj g|=        1.4775
At iterate     5  f =      -360.74  |proj g|=        1.4137
At iterate     6  f =      -362.82  |proj g|=        1.2706
At iterate     7  f =         -363  |proj g|=        1.2711
At iterate     8  f =      -363.02  |proj g|=        1.2505
At iterate     9  f =      -363.02  |proj g|=        1.2486
At iterate    10  f =      -363.02  |proj g|=        1.2488
At iterate    11  f =      -363.02  |proj g|=        1.2488
At iterate    12  f =      -363.02  |proj g|=         1.249
At iterate    13  f =      -363.02  |proj g|=        1.2493
At iterate    14  f =      -363.02  |proj g|=        1.2497
At iterate    15  f =      -363.02  |proj g|=        1.2504
At iterate    16  f =      -363.02  |proj g|=        1.2515
At iterate    17  f =      -363.02  |proj g|=        1.2534
At iterate    18  f =      -363.02  |proj g|=        1.2567
At iterate    19  f =      -363.03  |proj g|=         1.261
At iterate    20  f =      -363.04  |proj g|=        1.2636
At iterate    21  f =      -363.04  |proj g|=        1.2631
At iterate    22  f =      -363.04  |proj g|=         1.261
At iterate    23  f =      -363.04  |proj g|=         1.259
At iterate    24  f =      -363.05  |proj g|=        1.2545
At iterate    25  f =      -363.07  |proj g|=        1.2455
At iterate    26  f =      -363.11  |proj g|=         1.227
At iterate    27  f =      -363.22  |proj g|=        1.1858
At iterate    28  f =      -363.52  |proj g|=        1.0977
At iterate    29  f =      -364.26  |proj g|=       0.51389
At iterate    30  f =      -364.86  |proj g|=       0.58374
At iterate    31  f =      -365.14  |proj g|=       0.84004
At iterate    32  f =      -365.16  |proj g|=       0.84003
At iterate    33  f =      -365.16  |proj g|=       0.84003
At iterate    34  f =      -365.16  |proj g|=       0.84003
At iterate    35  f =      -365.16  |proj g|=       0.84003
At iterate    36  f =      -365.16  |proj g|=       0.84003
At iterate    37  f =      -365.16  |proj g|=       0.84003
At iterate    38  f =      -365.16  |proj g|=       0.84002
At iterate    39  f =      -365.16  |proj g|=       0.84001
At iterate    40  f =      -365.16  |proj g|=       0.83997
At iterate    41  f =      -365.17  |proj g|=       0.83986
At iterate    42  f =      -365.17  |proj g|=       0.83957
At iterate    43  f =      -365.18  |proj g|=       0.83882
At iterate    44  f =      -365.19  |proj g|=       0.83696
At iterate    45  f =      -365.23  |proj g|=       0.83308
At iterate    46  f =      -365.29  |proj g|=       0.82715
At iterate    47  f =      -365.29  |proj g|=       0.75127
At iterate    48  f =      -365.29  |proj g|=       0.75034
At iterate    49  f =      -365.29  |proj g|=       0.75022

iterations 49
function evaluations 57
segments explored during Cauchy searches 52
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.750222
final function value -365.295

F = -365.295
final  value -365.294992 
converged
 
INFO  [01:18:48.193] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:18:48.251] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:18:48.258] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:18:56.354] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:19:03.938] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:19:12.555] [mlr3]  Finished benchmark 
INFO  [01:19:12.625] [bbotk] Result of batch 69: 
INFO  [01:19:12.626] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:19:12.626] [bbotk]              2.200524                 4.631673                       0.4180582 
INFO  [01:19:12.626] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:19:12.626] [bbotk]                     3025        0.641 -0.9690076         <NA>   0.9653246 
INFO  [01:19:12.626] [bbotk]                                 uhash 
INFO  [01:19:12.626] [bbotk]  2fb71f3e-6585-4286-82a7-edcbfd22c001 
DEBUG [01:19:13.580] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.166121e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.166121e-05 0.002957979 
  - best initial criterion value(s) :  342.4279 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -342.43  |proj g|=       3.1422
At iterate     1  f =      -350.32  |proj g|=        4.1783
At iterate     2  f =      -357.01  |proj g|=        4.7418
At iterate     3  f =      -358.36  |proj g|=        4.1689
At iterate     4  f =      -358.47  |proj g|=        4.0983
At iterate     5  f =      -358.48  |proj g|=        4.1543
At iterate     6  f =      -358.48  |proj g|=        4.1564
At iterate     7  f =      -358.48  |proj g|=        4.1568
At iterate     8  f =      -358.48  |proj g|=        4.1589
At iterate     9  f =      -358.48  |proj g|=        4.1605
At iterate    10  f =       -358.5  |proj g|=        4.1618
At iterate    11  f =      -358.53  |proj g|=         4.072
At iterate    12  f =      -358.59  |proj g|=        4.1046
At iterate    13  f =      -358.94  |proj g|=        4.1443
At iterate    14  f =       -359.7  |proj g|=        4.0611
At iterate    15  f =      -361.53  |proj g|=        3.6823
At iterate    16  f =       -365.3  |proj g|=        2.8754
At iterate    17  f =      -370.82  |proj g|=        1.9112
At iterate    18  f =      -371.67  |proj g|=        1.7662
At iterate    19  f =      -373.21  |proj g|=         1.489
At iterate    20  f =      -373.97  |proj g|=        1.4031
At iterate    21  f =      -374.05  |proj g|=        1.4216
At iterate    22  f =      -374.05  |proj g|=        1.4185
At iterate    23  f =      -374.05  |proj g|=        1.4241
At iterate    24  f =      -374.05  |proj g|=         1.422
At iterate    25  f =      -374.05  |proj g|=        1.4221

iterations 25
function evaluations 36
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.42208
final function value -374.053

F = -374.053
final  value -374.053246 
converged
 
INFO  [01:19:13.584] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:19:13.643] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:19:13.650] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:19:23.098] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:19:33.077] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:19:45.128] [mlr3]  Finished benchmark 
INFO  [01:19:45.198] [bbotk] Result of batch 70: 
INFO  [01:19:45.200] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:19:45.200] [bbotk]              6.028058                 7.928256                       0.1200472 
INFO  [01:19:45.200] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:19:45.200] [bbotk]                     3644        0.638 -0.9659376         <NA>    0.974718 
INFO  [01:19:45.200] [bbotk]                                 uhash 
INFO  [01:19:45.200] [bbotk]  31985396-88bb-4cc4-ac5f-694dd29734e1 
DEBUG [01:19:46.218] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.147043e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.147043e-05 0.002941455 
  - best initial criterion value(s) :  351.6789 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -351.68  |proj g|=       1.9772
At iterate     1  f =      -358.61  |proj g|=        5.4685
At iterate     2  f =      -359.95  |proj g|=        5.2401
At iterate     3  f =      -361.75  |proj g|=          4.47
At iterate     4  f =      -362.28  |proj g|=        4.1828
At iterate     5  f =      -363.87  |proj g|=        3.6973
At iterate     6  f =      -364.25  |proj g|=        3.9901
At iterate     7  f =       -364.3  |proj g|=        3.9616
At iterate     8  f =       -364.3  |proj g|=         3.943
At iterate     9  f =       -364.3  |proj g|=        3.9454
At iterate    10  f =       -364.3  |proj g|=        3.9463
At iterate    11  f =       -364.3  |proj g|=        3.9481
At iterate    12  f =       -364.3  |proj g|=        3.9508
At iterate    13  f =       -364.3  |proj g|=        3.9552
At iterate    14  f =       -364.3  |proj g|=        3.9621
At iterate    15  f =       -364.3  |proj g|=        3.9732
At iterate    16  f =      -364.31  |proj g|=        3.9908
At iterate    17  f =      -364.32  |proj g|=        4.0173
At iterate    18  f =      -364.35  |proj g|=        4.0505
At iterate    19  f =       -364.4  |proj g|=        4.0677
At iterate    20  f =      -364.42  |proj g|=        4.0041
At iterate    21  f =      -364.44  |proj g|=        4.0177
At iterate    22  f =      -365.54  |proj g|=        3.7949
At iterate    23  f =      -375.23  |proj g|=        2.0365
At iterate    24  f =      -375.66  |proj g|=        2.1726
At iterate    25  f =      -375.82  |proj g|=        2.2853
At iterate    26  f =      -375.83  |proj g|=        2.2502
At iterate    27  f =      -375.83  |proj g|=        2.2447
At iterate    28  f =      -375.83  |proj g|=         2.245
At iterate    29  f =      -375.83  |proj g|=        2.2452
At iterate    30  f =      -375.83  |proj g|=        2.2459
At iterate    31  f =      -375.83  |proj g|=        2.2469
At iterate    32  f =      -375.83  |proj g|=        2.2426
At iterate    33  f =      -375.83  |proj g|=         2.253
At iterate    34  f =      -375.85  |proj g|=        2.2522
At iterate    35  f =      -375.85  |proj g|=        2.2734
At iterate    36  f =      -375.94  |proj g|=        2.2569
At iterate    37  f =      -382.34  |proj g|=        1.2076
At iterate    38  f =       -385.3  |proj g|=       0.79634
At iterate    39  f =      -385.31  |proj g|=       0.20388
At iterate    40  f =      -385.31  |proj g|=     0.0044974
At iterate    41  f =      -385.31  |proj g|=      0.021557
At iterate    42  f =      -385.31  |proj g|=    0.00067227

iterations 42
function evaluations 53
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000672271
final function value -385.308

F = -385.308
final  value -385.307751 
converged
 
INFO  [01:19:46.222] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:19:46.277] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:19:46.284] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:19:50.814] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:19:55.279] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:19:59.451] [mlr3]  Finished benchmark 
INFO  [01:19:59.544] [bbotk] Result of batch 71: 
INFO  [01:19:59.546] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:19:59.546] [bbotk]              8.726367                 8.179452                        0.334195 
INFO  [01:19:59.546] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:19:59.546] [bbotk]                     1533        0.656 -0.9627808         <NA>   0.9754846 
INFO  [01:19:59.546] [bbotk]                                 uhash 
INFO  [01:19:59.546] [bbotk]  c7feced8-a553-43f4-ae2d-2dab57638d9b 
DEBUG [01:20:00.596] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.129111e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.129111e-05 0.002888202 
  - best initial criterion value(s) :  344.1943 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -344.19  |proj g|=       1.3065
At iterate     1  f =      -344.23  |proj g|=         1.377
At iterate     2  f =      -344.57  |proj g|=        1.3566
At iterate     3  f =      -344.67  |proj g|=        1.3445
At iterate     4  f =       -344.7  |proj g|=        1.3504
At iterate     5  f =      -344.74  |proj g|=        1.3612
At iterate     6  f =      -344.74  |proj g|=        1.3615
At iterate     7  f =      -344.74  |proj g|=        1.3632
At iterate     8  f =      -344.74  |proj g|=        1.3641
At iterate     9  f =      -344.75  |proj g|=        1.3651
At iterate    10  f =      -344.76  |proj g|=        1.3657
At iterate    11  f =       -344.8  |proj g|=        1.3627
At iterate    12  f =      -344.81  |proj g|=        1.3608
At iterate    13  f =       -344.9  |proj g|=         1.347
At iterate    14  f =      -345.12  |proj g|=        1.3065
At iterate    15  f =      -345.55  |proj g|=        1.2117
At iterate    16  f =      -346.31  |proj g|=        1.0375
At iterate    17  f =      -347.73  |proj g|=       0.32729
At iterate    18  f =      -347.73  |proj g|=       0.32729
At iterate    19  f =      -347.76  |proj g|=       0.32786
At iterate    20  f =      -349.46  |proj g|=       0.23204
At iterate    21  f =      -350.15  |proj g|=       0.18324
At iterate    22  f =      -350.18  |proj g|=       0.84098
At iterate    23  f =      -350.53  |proj g|=       0.32818
At iterate    24  f =      -350.59  |proj g|=       0.29312
At iterate    25  f =      -350.59  |proj g|=       0.30377
At iterate    26  f =      -350.59  |proj g|=       0.30338
At iterate    27  f =      -350.59  |proj g|=        0.3034

iterations 27
function evaluations 38
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.303396
final function value -350.592

F = -350.592
final  value -350.591862 
converged
 
INFO  [01:20:00.600] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:20:00.655] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:20:00.663] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:20:04.521] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:20:09.005] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:20:12.643] [mlr3]  Finished benchmark 
INFO  [01:20:12.731] [bbotk] Result of batch 72: 
INFO  [01:20:12.732] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:20:12.732] [bbotk]              6.015121                 2.329491                       0.1103426 
INFO  [01:20:12.732] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:20:12.732] [bbotk]                     1282        0.679 -0.9738548         <NA>   0.9670535 
INFO  [01:20:12.732] [bbotk]                                 uhash 
INFO  [01:20:12.732] [bbotk]  c123579b-2fb4-4632-a968-352cb77bc443 
DEBUG [01:20:13.832] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.108927e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.108927e-05 0.002839531 
  - best initial criterion value(s) :  351.1168 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -351.12  |proj g|=       3.0786
At iterate     1  f =      -352.84  |proj g|=        2.3636
At iterate     2  f =      -353.09  |proj g|=        2.3799
At iterate     3  f =      -353.15  |proj g|=        2.5056
At iterate     4  f =      -353.16  |proj g|=         2.474
At iterate     5  f =      -353.16  |proj g|=         2.469
At iterate     6  f =      -353.16  |proj g|=        2.4672
At iterate     7  f =      -353.16  |proj g|=        2.4584
At iterate     8  f =      -353.16  |proj g|=        2.4438
At iterate     9  f =      -353.17  |proj g|=        2.4308
At iterate    10  f =      -353.19  |proj g|=        2.4149
At iterate    11  f =      -353.31  |proj g|=         2.345
At iterate    12  f =      -353.56  |proj g|=        2.2419
At iterate    13  f =      -354.27  |proj g|=        2.0305
At iterate    14  f =      -355.91  |proj g|=        1.6744
At iterate    15  f =      -359.53  |proj g|=        1.1579
At iterate    16  f =      -364.06  |proj g|=       0.87781
At iterate    17  f =      -365.32  |proj g|=       0.89053
At iterate    18  f =      -366.91  |proj g|=        0.8723
At iterate    19  f =      -367.81  |proj g|=        0.8511
At iterate    20  f =      -368.04  |proj g|=       0.83525
At iterate    21  f =      -368.06  |proj g|=         0.832
At iterate    22  f =      -368.06  |proj g|=       0.43477
At iterate    23  f =      -368.06  |proj g|=       0.43497
At iterate    24  f =      -368.06  |proj g|=       0.43507

iterations 24
function evaluations 28
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.435072
final function value -368.057

F = -368.057
final  value -368.056978 
converged
 
INFO  [01:20:13.834] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:20:13.878] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:20:13.884] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:20:24.335] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:20:34.294] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:20:46.655] [mlr3]  Finished benchmark 
INFO  [01:20:46.752] [bbotk] Result of batch 73: 
INFO  [01:20:46.754] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:20:46.754] [bbotk]               9.07457                 7.062129                      0.08219654 
INFO  [01:20:46.754] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:20:46.754] [bbotk]                     3387        0.642 -0.9712984         <NA>   0.9730422 
INFO  [01:20:46.754] [bbotk]                                 uhash 
INFO  [01:20:46.754] [bbotk]  56ef283c-75a9-486f-9e0f-103765777c6f 
DEBUG [01:20:47.725] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.089531e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.089531e-05 0.002822556 
  - best initial criterion value(s) :  363.3462 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -363.35  |proj g|=        7.491
At iterate     1  f =      -365.16  |proj g|=        7.7287
At iterate     2  f =      -367.63  |proj g|=         7.195
At iterate     3  f =       -371.9  |proj g|=        5.3336
At iterate     4  f =      -374.59  |proj g|=        4.3644
At iterate     5  f =      -376.09  |proj g|=        3.5029
At iterate     6  f =      -377.07  |proj g|=        3.5402
At iterate     7  f =      -377.09  |proj g|=        3.4396
At iterate     8  f =      -377.09  |proj g|=        3.4401
At iterate     9  f =      -377.09  |proj g|=         3.439
At iterate    10  f =      -377.09  |proj g|=        3.4343
At iterate    11  f =       -377.1  |proj g|=        3.4285
At iterate    12  f =       -377.1  |proj g|=        3.4175
At iterate    13  f =      -377.11  |proj g|=        3.3955
At iterate    14  f =      -377.15  |proj g|=        3.3523
At iterate    15  f =      -377.23  |proj g|=        3.2654
At iterate    16  f =      -377.47  |proj g|=        3.0873
At iterate    17  f =       -378.1  |proj g|=        2.7352
At iterate    18  f =      -379.69  |proj g|=         2.114
At iterate    19  f =      -382.54  |proj g|=        1.3776
At iterate    20  f =      -384.05  |proj g|=        1.1584
At iterate    21  f =      -384.28  |proj g|=         1.124
At iterate    22  f =      -384.41  |proj g|=        1.1289
At iterate    23  f =      -384.67  |proj g|=        1.1045
At iterate    24  f =      -385.41  |proj g|=        1.0101
At iterate    25  f =      -386.93  |proj g|=       0.90855
At iterate    26  f =      -388.06  |proj g|=       0.90674
At iterate    27  f =      -390.15  |proj g|=       0.90366
At iterate    28  f =      -390.44  |proj g|=       0.90271
At iterate    29  f =      -391.97  |proj g|=        0.8946
At iterate    30  f =      -395.46  |proj g|=       0.86689
At iterate    31  f =      -397.62  |proj g|=        0.8357
At iterate    32  f =      -398.48  |proj g|=       0.81218
At iterate    33  f =      -398.66  |proj g|=       0.80052
At iterate    34  f =      -398.69  |proj g|=       0.20478
At iterate    35  f =      -398.69  |proj g|=       0.20478
At iterate    36  f =      -398.69  |proj g|=       0.20478

iterations 36
function evaluations 39
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.204779
final function value -398.687

F = -398.687
final  value -398.687081 
converged
 
INFO  [01:20:47.729] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:20:47.784] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:20:47.790] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:20:54.348] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:21:01.395] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:21:07.261] [mlr3]  Finished benchmark 
INFO  [01:21:07.328] [bbotk] Result of batch 74: 
INFO  [01:21:07.330] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:21:07.330] [bbotk]              8.554056                 2.175259                       0.2780608 
INFO  [01:21:07.330] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:21:07.330] [bbotk]                     2398        0.655 -0.9620887         <NA>   0.9763699 
INFO  [01:21:07.330] [bbotk]                                 uhash 
INFO  [01:21:07.330] [bbotk]  22a1900f-0157-46e3-919b-a43f5a17c92e 
DEBUG [01:21:08.205] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.073647e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.073647e-05 0.002810212 
  - best initial criterion value(s) :  347.2481 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -347.25  |proj g|=      0.98459
At iterate     1  f =      -358.93  |proj g|=        1.1052
At iterate     2  f =      -359.09  |proj g|=        1.0811
At iterate     3  f =      -359.23  |proj g|=        1.0723
At iterate     4  f =      -359.29  |proj g|=        1.0634
At iterate     5  f =       -359.3  |proj g|=         1.068
At iterate     6  f =       -359.3  |proj g|=        1.0668
At iterate     7  f =       -359.3  |proj g|=        1.0669
At iterate     8  f =       -359.3  |proj g|=        1.0669

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.06691
final function value -359.3

F = -359.3
final  value -359.300434 
converged
 
INFO  [01:21:08.209] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:21:08.264] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:21:08.271] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:21:14.944] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:21:21.467] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:21:27.487] [mlr3]  Finished benchmark 
INFO  [01:21:27.556] [bbotk] Result of batch 75: 
INFO  [01:21:27.558] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:21:27.558] [bbotk]              6.556375                 9.622393                      0.03711395 
INFO  [01:21:27.558] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:21:27.558] [bbotk]                     2201        0.643 -0.9736427         <NA>   0.9619702 
INFO  [01:21:27.558] [bbotk]                                 uhash 
INFO  [01:21:27.558] [bbotk]  2afa144c-3f97-43d8-b944-0e61712a9455 
DEBUG [01:21:28.657] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.059662e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.059662e-05 0.00279543 
  - best initial criterion value(s) :  350.2036 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -350.2  |proj g|=       1.3111
At iterate     1  f =      -361.04  |proj g|=        2.4005
At iterate     2  f =      -363.08  |proj g|=        2.3006
At iterate     3  f =      -365.18  |proj g|=        2.0941
At iterate     4  f =      -365.53  |proj g|=        2.0401
At iterate     5  f =      -366.97  |proj g|=        2.0026
At iterate     6  f =      -369.85  |proj g|=         2.061
At iterate     7  f =      -371.29  |proj g|=        2.2217
At iterate     8  f =      -371.57  |proj g|=        2.3234
At iterate     9  f =      -371.64  |proj g|=        2.3896
At iterate    10  f =      -371.66  |proj g|=        2.4235
At iterate    11  f =      -371.66  |proj g|=        2.4287
At iterate    12  f =      -371.66  |proj g|=        2.4298
At iterate    13  f =      -371.66  |proj g|=        2.4354
At iterate    14  f =      -371.66  |proj g|=        2.4422
At iterate    15  f =      -371.66  |proj g|=        2.4524
At iterate    16  f =      -371.67  |proj g|=        2.4685
At iterate    17  f =       -371.7  |proj g|=        2.4929
At iterate    18  f =      -371.77  |proj g|=        2.5213
At iterate    19  f =      -371.93  |proj g|=        2.5708
At iterate    20  f =      -372.32  |proj g|=        2.5931
At iterate    21  f =      -372.37  |proj g|=        2.6986
At iterate    22  f =      -373.24  |proj g|=        2.6528
At iterate    23  f =      -376.37  |proj g|=        2.4804
At iterate    24  f =      -382.39  |proj g|=        1.9796
At iterate    25  f =       -384.1  |proj g|=        1.7378
At iterate    26  f =      -388.79  |proj g|=        1.3458
At iterate    27  f =      -389.66  |proj g|=        1.5327
At iterate    28  f =      -390.18  |proj g|=        1.8189
At iterate    29  f =      -390.97  |proj g|=        1.5634
At iterate    30  f =      -390.98  |proj g|=        1.6316
At iterate    31  f =      -390.99  |proj g|=        1.6012
At iterate    32  f =      -390.99  |proj g|=        1.5993
At iterate    33  f =      -390.99  |proj g|=        1.5992
At iterate    34  f =      -390.99  |proj g|=           1.6
At iterate    35  f =      -390.99  |proj g|=        1.5984
At iterate    36  f =      -390.99  |proj g|=        1.5946
At iterate    37  f =      -390.99  |proj g|=        1.5869
At iterate    38  f =      -390.99  |proj g|=        1.5749
At iterate    39  f =         -391  |proj g|=        1.5541
At iterate    40  f =      -391.02  |proj g|=        1.5194
At iterate    41  f =      -391.08  |proj g|=        1.4608
At iterate    42  f =      -391.22  |proj g|=        1.3714
At iterate    43  f =      -391.48  |proj g|=        1.2772
At iterate    44  f =      -391.82  |proj g|=         1.467
At iterate    45  f =      -391.87  |proj g|=        1.4232
At iterate    46  f =      -391.89  |proj g|=        1.3778
At iterate    47  f =      -391.89  |proj g|=        1.3701
At iterate    48  f =       -391.9  |proj g|=        1.3484
At iterate    49  f =       -391.9  |proj g|=        1.3346
At iterate    50  f =      -391.91  |proj g|=        1.3063
At iterate    51  f =      -391.94  |proj g|=        1.2684
At iterate    52  f =      -392.01  |proj g|=        1.1974
At iterate    53  f =      -392.18  |proj g|=        1.0807
At iterate    54  f =       -392.6  |proj g|=        0.8892
At iterate    55  f =      -393.59  |proj g|=       0.34302
At iterate    56  f =      -394.32  |proj g|=       0.33122
At iterate    57  f =      -395.67  |proj g|=       0.71631
At iterate    58  f =      -395.79  |proj g|=       0.65557
At iterate    59  f =       -395.9  |proj g|=       0.25263
At iterate    60  f =      -395.92  |proj g|=       0.17107
At iterate    61  f =      -395.92  |proj g|=      0.003281
At iterate    62  f =      -395.92  |proj g|=     0.0032862
At iterate    63  f =      -395.92  |proj g|=     0.0032861

iterations 63
function evaluations 71
segments explored during Cauchy searches 65
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00328609
final function value -395.924

F = -395.924
final  value -395.924134 
converged
 
INFO  [01:21:28.661] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:21:28.719] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:21:28.726] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:21:37.146] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:21:46.691] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:21:54.252] [mlr3]  Finished benchmark 
INFO  [01:21:54.324] [bbotk] Result of batch 76: 
INFO  [01:21:54.326] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:21:54.326] [bbotk]              6.114564                 2.042012                       0.1282617 
INFO  [01:21:54.326] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [01:21:54.326] [bbotk]                     2986        0.653 -0.949469         <NA>   0.9741945 
INFO  [01:21:54.326] [bbotk]                                 uhash 
INFO  [01:21:54.326] [bbotk]  4cb180ab-5cdb-4e8f-8e2f-0197a9cf6a8f 
DEBUG [01:21:55.275] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.042108e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.042108e-05 0.002780214 
  - best initial criterion value(s) :  360.3701 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -360.37  |proj g|=        1.552
At iterate     1  f =      -364.86  |proj g|=        4.2521
At iterate     2  f =      -366.46  |proj g|=        4.0171
At iterate     3  f =      -368.31  |proj g|=         3.418
At iterate     4  f =      -369.13  |proj g|=        3.2477
At iterate     5  f =       -372.5  |proj g|=        2.8185
At iterate     6  f =      -375.48  |proj g|=        2.4788
At iterate     7  f =      -377.65  |proj g|=        2.4498
At iterate     8  f =      -379.86  |proj g|=        2.6244
At iterate     9  f =      -379.97  |proj g|=        2.7828
At iterate    10  f =      -380.03  |proj g|=        2.7527
At iterate    11  f =      -380.03  |proj g|=        2.7438
At iterate    12  f =      -380.03  |proj g|=        2.7438
At iterate    13  f =      -380.03  |proj g|=        2.7437

iterations 13
function evaluations 22
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.74373
final function value -380.034

F = -380.034
final  value -380.034299 
converged
 
INFO  [01:21:55.279] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:21:55.589] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:21:55.596] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:21:57.667] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:21:59.640] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:22:01.929] [mlr3]  Finished benchmark 
INFO  [01:22:01.997] [bbotk] Result of batch 77: 
INFO  [01:22:01.999] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:22:01.999] [bbotk]                6.1822                  9.66275                       0.3603021 
INFO  [01:22:01.999] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [01:22:01.999] [bbotk]                      644        0.674 -0.971766         <NA>   0.9715632 
INFO  [01:22:01.999] [bbotk]                                 uhash 
INFO  [01:22:01.999] [bbotk]  2bbfbe87-07e2-4b82-8e22-dcbfb3414ba9 
DEBUG [01:22:02.996] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.023326e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.023326e-05 0.002730593 
  - best initial criterion value(s) :  376.9179 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -376.92  |proj g|=       1.6233
At iterate     1  f =         -386  |proj g|=        4.8564
At iterate     2  f =       -388.4  |proj g|=        4.6171
At iterate     3  f =      -392.23  |proj g|=        3.7946
At iterate     4  f =      -392.74  |proj g|=        3.4879
At iterate     5  f =      -393.59  |proj g|=        3.2849
At iterate     6  f =      -394.77  |proj g|=         3.139
At iterate     7  f =      -395.14  |proj g|=        3.5433
At iterate     8  f =      -395.18  |proj g|=        3.4726
At iterate     9  f =      -395.19  |proj g|=        3.4439
At iterate    10  f =      -395.19  |proj g|=        3.4464
At iterate    11  f =      -395.19  |proj g|=        3.4466
At iterate    12  f =      -395.19  |proj g|=        3.4467
At iterate    13  f =      -395.19  |proj g|=        3.4474
At iterate    14  f =      -395.19  |proj g|=        3.4482
At iterate    15  f =      -395.19  |proj g|=        3.4493
At iterate    16  f =      -395.19  |proj g|=        3.4526
At iterate    17  f =      -395.19  |proj g|=         3.452
At iterate    18  f =      -395.19  |proj g|=        3.4622
At iterate    19  f =      -395.19  |proj g|=        3.4602
At iterate    20  f =      -395.79  |proj g|=        3.3941
At iterate    21  f =      -398.63  |proj g|=          3.07
At iterate    22  f =      -403.49  |proj g|=        2.5835
At iterate    23  f =      -405.42  |proj g|=        2.5569
At iterate    24  f =       -405.5  |proj g|=        2.7096
At iterate    25  f =      -406.21  |proj g|=        2.5827
At iterate    26  f =      -406.26  |proj g|=        2.5609
At iterate    27  f =      -406.27  |proj g|=        2.5645
At iterate    28  f =      -406.27  |proj g|=        2.5661
At iterate    29  f =      -406.27  |proj g|=        2.5664

iterations 29
function evaluations 36
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.56639
final function value -406.266

F = -406.266
final  value -406.266103 
converged
 
INFO  [01:22:03.000] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:22:03.058] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:22:03.065] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:22:05.020] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:22:07.135] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:22:09.319] [mlr3]  Finished benchmark 
INFO  [01:22:09.388] [bbotk] Result of batch 78: 
INFO  [01:22:09.390] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:22:09.390] [bbotk]              9.000852                 7.286888                       0.4397165 
INFO  [01:22:09.390] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:22:09.390] [bbotk]                      681        0.667 -0.9653424         <NA>   0.9734042 
INFO  [01:22:09.390] [bbotk]                                 uhash 
INFO  [01:22:09.390] [bbotk]  bb73cef1-b89e-4829-8240-763ec69a0d89 
DEBUG [01:22:10.422] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 2.005802e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  2.005802e-05 0.002683534 
  - best initial criterion value(s) :  367.4301 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -367.43  |proj g|=      0.68995
At iterate     1  f =      -371.59  |proj g|=        6.4809
At iterate     2  f =      -374.72  |proj g|=        6.0117
At iterate     3  f =       -377.5  |proj g|=        4.8115
At iterate     4  f =      -377.67  |proj g|=        4.4662
At iterate     5  f =      -377.88  |proj g|=        4.4111
At iterate     6  f =      -379.44  |proj g|=        4.4884
At iterate     7  f =      -379.63  |proj g|=        4.7967
At iterate     8  f =      -379.65  |proj g|=        4.8816
At iterate     9  f =      -379.65  |proj g|=        4.8963
At iterate    10  f =      -379.65  |proj g|=        4.8977
At iterate    11  f =      -379.65  |proj g|=        4.9038
At iterate    12  f =      -379.65  |proj g|=        4.9111
At iterate    13  f =      -379.65  |proj g|=        4.9247
At iterate    14  f =      -379.65  |proj g|=        4.9454
At iterate    15  f =      -379.65  |proj g|=        4.9767
At iterate    16  f =      -379.66  |proj g|=        5.0175
At iterate    17  f =      -379.68  |proj g|=        5.0578
At iterate    18  f =      -379.73  |proj g|=        5.1205
At iterate    19  f =      -379.83  |proj g|=         5.083
At iterate    20  f =      -379.89  |proj g|=        5.3745
At iterate    21  f =       -380.1  |proj g|=        5.2613
At iterate    22  f =      -381.13  |proj g|=        4.8036
At iterate    23  f =       -383.1  |proj g|=        4.1472
At iterate    24  f =      -387.62  |proj g|=        3.2422
At iterate    25  f =      -395.15  |proj g|=        2.1941
At iterate    26  f =      -397.56  |proj g|=        1.6441
At iterate    27  f =      -409.45  |proj g|=       0.70476
At iterate    28  f =       -413.9  |proj g|=        1.0996
At iterate    29  f =      -414.12  |proj g|=         1.272
At iterate    30  f =      -414.26  |proj g|=        1.2168
At iterate    31  f =      -414.26  |proj g|=        1.2267
At iterate    32  f =      -414.26  |proj g|=        1.2293
At iterate    33  f =      -414.26  |proj g|=        1.2297
At iterate    34  f =      -414.26  |proj g|=        1.2297

iterations 34
function evaluations 39
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.22971
final function value -414.264

F = -414.264
final  value -414.263840 
converged
 
INFO  [01:22:10.426] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:22:10.484] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:22:10.491] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:22:15.984] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:22:22.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:22:28.047] [mlr3]  Finished benchmark 
INFO  [01:22:28.117] [bbotk] Result of batch 79: 
INFO  [01:22:28.119] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:22:28.119] [bbotk]               3.30103                 5.744414                       0.1217464 
INFO  [01:22:28.119] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:22:28.119] [bbotk]                     2097        0.687 -0.9550625         <NA>    0.966332 
INFO  [01:22:28.119] [bbotk]                                 uhash 
INFO  [01:22:28.119] [bbotk]  852a186f-d5e5-4e1d-b0f3-89a5c5a729df 
DEBUG [01:22:29.135] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.988496e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.988496e-05 0.002666953 
  - best initial criterion value(s) :  363.0204 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -363.02  |proj g|=        5.485
At iterate     1  f =       -364.1  |proj g|=        8.4053
At iterate     2  f =      -372.97  |proj g|=        7.4885
At iterate     3  f =      -375.37  |proj g|=         6.478
At iterate     4  f =      -384.71  |proj g|=        5.1307
At iterate     5  f =      -388.07  |proj g|=        4.3874
At iterate     6  f =      -388.12  |proj g|=        4.2726
At iterate     7  f =      -388.12  |proj g|=        4.2605
At iterate     8  f =      -388.17  |proj g|=         4.269
At iterate     9  f =      -388.58  |proj g|=        4.2828
At iterate    10  f =      -389.57  |proj g|=        4.2101
At iterate    11  f =      -391.98  |proj g|=        3.9036
At iterate    12  f =      -396.69  |proj g|=        3.2754
At iterate    13  f =      -397.23  |proj g|=         2.926
At iterate    14  f =      -403.59  |proj g|=        2.1055
At iterate    15  f =      -418.81  |proj g|=        1.0969
At iterate    16  f =      -418.88  |proj g|=        1.1372
At iterate    17  f =      -418.94  |proj g|=        1.1963
At iterate    18  f =      -418.94  |proj g|=        1.2074
At iterate    19  f =      -418.94  |proj g|=        1.2091
At iterate    20  f =      -418.94  |proj g|=        1.2091

iterations 20
function evaluations 31
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.20912
final function value -418.939

F = -418.939
final  value -418.939131 
converged
 
INFO  [01:22:29.139] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:22:29.197] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:22:29.205] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:22:41.043] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:22:50.959] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:23:01.032] [mlr3]  Finished benchmark 
INFO  [01:23:01.103] [bbotk] Result of batch 80: 
INFO  [01:23:01.105] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:23:01.105] [bbotk]              4.204196                 5.188462                      0.09580618 
INFO  [01:23:01.105] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:23:01.105] [bbotk]                     4705        0.699 -0.9656319         <NA>   0.9728721 
INFO  [01:23:01.105] [bbotk]                                 uhash 
INFO  [01:23:01.105] [bbotk]  47fa689b-91e9-4c63-959f-15196eee5b81 
DEBUG [01:23:02.291] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.971284e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.971284e-05 0.002651119 
  - best initial criterion value(s) :  385.6403 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -385.64  |proj g|=       4.1281
At iterate     1  f =      -390.23  |proj g|=        4.5894
At iterate     2  f =      -390.77  |proj g|=         4.177
At iterate     3  f =      -394.56  |proj g|=        4.2717
At iterate     4  f =      -395.13  |proj g|=        4.4006
At iterate     5  f =      -395.14  |proj g|=        4.4353
At iterate     6  f =      -395.14  |proj g|=        4.4306
At iterate     7  f =      -395.14  |proj g|=        4.4244
At iterate     8  f =      -395.15  |proj g|=        4.4118
At iterate     9  f =      -395.16  |proj g|=        4.3823
At iterate    10  f =      -395.19  |proj g|=        4.3371
At iterate    11  f =      -395.29  |proj g|=        4.2514
At iterate    12  f =      -395.54  |proj g|=        4.0971
At iterate    13  f =      -396.27  |proj g|=        3.8003
At iterate    14  f =       -398.4  |proj g|=        3.2407
At iterate    15  f =      -403.95  |proj g|=        2.3196
At iterate    16  f =      -412.89  |proj g|=        1.4998
At iterate    17  f =       -424.3  |proj g|=       0.56524
At iterate    18  f =      -426.77  |proj g|=       0.89419
At iterate    19  f =       -427.5  |proj g|=        1.1071
At iterate    20  f =       -427.6  |proj g|=        1.1308
At iterate    21  f =      -427.91  |proj g|=        1.1404
At iterate    22  f =      -428.17  |proj g|=        1.0645
At iterate    23  f =      -428.25  |proj g|=       0.89907
At iterate    24  f =      -428.28  |proj g|=       0.96791
At iterate    25  f =      -428.28  |proj g|=       0.95955
At iterate    26  f =      -428.28  |proj g|=       0.95837
At iterate    27  f =      -428.28  |proj g|=       0.95844

iterations 27
function evaluations 37
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.95844
final function value -428.279

F = -428.279
final  value -428.279260 
converged
 
INFO  [01:23:02.295] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:23:02.351] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:23:02.359] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:23:06.340] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:23:10.081] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:23:14.100] [mlr3]  Finished benchmark 
INFO  [01:23:14.170] [bbotk] Result of batch 81: 
INFO  [01:23:14.172] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:23:14.172] [bbotk]              3.662791                 4.213531                       0.3808409 
INFO  [01:23:14.172] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:23:14.172] [bbotk]                     2063         0.85 -0.9609434         <NA>   0.9741334 
INFO  [01:23:14.172] [bbotk]                                 uhash 
INFO  [01:23:14.172] [bbotk]  c06d242d-b88f-4ca7-8520-f72806251f5b 
DEBUG [01:23:15.291] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.9552e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.9552e-05 0.002634163 
  - best initial criterion value(s) :  356.3803 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -356.38  |proj g|=       1.3243
At iterate     1  f =       -376.7  |proj g|=        5.2579
At iterate     2  f =      -393.28  |proj g|=        4.9928
At iterate     3  f =      -404.56  |proj g|=        4.2914
At iterate     4  f =         -406  |proj g|=        3.8551
At iterate     5  f =      -406.44  |proj g|=        3.7863
At iterate     6  f =      -409.79  |proj g|=        3.5706
At iterate     7  f =      -411.77  |proj g|=        3.7022
At iterate     8  f =      -412.42  |proj g|=        3.7609
At iterate     9  f =      -412.65  |proj g|=         3.821
At iterate    10  f =      -412.71  |proj g|=        3.9148
At iterate    11  f =      -412.71  |proj g|=        3.9127
At iterate    12  f =      -412.72  |proj g|=        3.9534
At iterate    13  f =      -413.34  |proj g|=        3.8497
At iterate    14  f =      -414.23  |proj g|=        3.7173
At iterate    15  f =      -415.24  |proj g|=        3.6685
At iterate    16  f =      -416.15  |proj g|=         3.555
At iterate    17  f =      -416.29  |proj g|=        3.4825
At iterate    18  f =      -416.29  |proj g|=        3.5253
At iterate    19  f =      -416.33  |proj g|=        3.5317
At iterate    20  f =      -416.33  |proj g|=        3.5316
At iterate    21  f =      -416.33  |proj g|=        3.5315
At iterate    22  f =      -416.37  |proj g|=        3.5239
At iterate    23  f =      -416.68  |proj g|=        3.4664
At iterate    24  f =       -416.8  |proj g|=        3.3092
At iterate    25  f =      -417.67  |proj g|=        3.1903
At iterate    26  f =      -420.73  |proj g|=         2.725
At iterate    27  f =      -426.81  |proj g|=        1.9857
At iterate    28  f =       -433.3  |proj g|=       0.83174
At iterate    29  f =      -434.92  |proj g|=       0.80099
At iterate    30  f =      -435.17  |proj g|=       0.78139
At iterate    31  f =      -435.18  |proj g|=       0.78182
At iterate    32  f =      -435.19  |proj g|=       0.63363
At iterate    33  f =      -435.19  |proj g|=      0.012789
At iterate    34  f =      -435.19  |proj g|=     0.0018401

iterations 34
function evaluations 51
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00184011
final function value -435.192

F = -435.192
final  value -435.191585 
converged
 
INFO  [01:23:15.295] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:23:15.352] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:23:15.359] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:23:21.005] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:23:26.534] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:23:32.034] [mlr3]  Finished benchmark 
INFO  [01:23:32.140] [bbotk] Result of batch 82: 
INFO  [01:23:32.143] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:23:32.143] [bbotk]              3.759483                 6.559617                       0.3486302 
INFO  [01:23:32.143] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:23:32.143] [bbotk]                     2749        0.701 -0.9589169         <NA>   0.9751706 
INFO  [01:23:32.143] [bbotk]                                 uhash 
INFO  [01:23:32.143] [bbotk]  188c272b-7daf-4d7b-9041-27dbfab2d956 
DEBUG [01:23:33.338] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.940258e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.940258e-05 0.002623014 
  - best initial criterion value(s) :  408.6561 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -408.66  |proj g|=       1.2279
At iterate     1  f =      -422.11  |proj g|=        1.8843
At iterate     2  f =      -422.31  |proj g|=        1.8678
At iterate     3  f =      -422.78  |proj g|=        1.8073
At iterate     4  f =      -423.91  |proj g|=           1.8
At iterate     5  f =      -428.17  |proj g|=        1.9001
At iterate     6  f =      -429.02  |proj g|=        2.0994
At iterate     7  f =      -430.55  |proj g|=        2.1771
At iterate     8  f =      -430.84  |proj g|=        2.2379
At iterate     9  f =      -430.87  |proj g|=         2.254
At iterate    10  f =       -430.9  |proj g|=        2.2849
At iterate    11  f =      -430.92  |proj g|=           2.3
At iterate    12  f =      -430.99  |proj g|=        2.3252
At iterate    13  f =      -431.15  |proj g|=        2.3536
At iterate    14  f =      -431.29  |proj g|=        2.3549
At iterate    15  f =      -431.36  |proj g|=        2.3101
At iterate    16  f =      -431.36  |proj g|=        2.3017
At iterate    17  f =      -431.36  |proj g|=        2.3019
At iterate    18  f =      -431.36  |proj g|=        2.3019

iterations 18
function evaluations 24
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.30187
final function value -431.358

F = -431.358
final  value -431.357528 
converged
 
INFO  [01:23:33.343] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:23:33.404] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:23:33.411] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:23:39.443] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:23:45.392] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:23:51.173] [mlr3]  Finished benchmark 
INFO  [01:23:51.283] [bbotk] Result of batch 83: 
INFO  [01:23:51.286] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:23:51.286] [bbotk]              3.054833                 4.612583                      0.05808403 
INFO  [01:23:51.286] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:23:51.286] [bbotk]                     2892        0.899 -0.9612123         <NA>   0.9592468 
INFO  [01:23:51.286] [bbotk]                                 uhash 
INFO  [01:23:51.286] [bbotk]  bc67397c-b14e-4004-8f2c-572970a0576a 
DEBUG [01:23:52.452] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.933019e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.933019e-05 0.00260932 
  - best initial criterion value(s) :  388.8467 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -388.85  |proj g|=       1.5284
At iterate     1  f =      -398.44  |proj g|=        2.2258
At iterate     2  f =         -404  |proj g|=        2.1925
At iterate     3  f =      -405.56  |proj g|=        2.1245
At iterate     4  f =      -405.65  |proj g|=        2.0984
At iterate     5  f =      -405.76  |proj g|=        2.0878
At iterate     6  f =      -405.89  |proj g|=         2.056
At iterate     7  f =      -405.91  |proj g|=        2.0704
At iterate     8  f =      -405.91  |proj g|=        2.0694
At iterate     9  f =      -405.91  |proj g|=        2.0671
At iterate    10  f =      -408.66  |proj g|=        1.7487
At iterate    11  f =      -415.76  |proj g|=       0.82295
At iterate    12  f =      -415.96  |proj g|=        0.8238
At iterate    13  f =      -416.04  |proj g|=       0.45867
At iterate    14  f =      -416.06  |proj g|=       0.48981
At iterate    15  f =      -416.06  |proj g|=       0.48549
At iterate    16  f =      -416.06  |proj g|=       0.48519
At iterate    17  f =      -416.06  |proj g|=       0.48491
At iterate    18  f =      -416.06  |proj g|=       0.48556
At iterate    19  f =      -416.06  |proj g|=       0.48528
At iterate    20  f =      -416.06  |proj g|=       0.48527

iterations 20
function evaluations 27
segments explored during Cauchy searches 22
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.485272
final function value -416.056

F = -416.056
final  value -416.056380 
converged
 
INFO  [01:23:52.456] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:23:52.516] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:23:52.524] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:24:06.275] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:24:20.614] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:24:33.704] [mlr3]  Finished benchmark 
INFO  [01:24:33.773] [bbotk] Result of batch 84: 
INFO  [01:24:33.774] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:24:33.774] [bbotk]              7.609836                 9.314655                       0.3973934 
INFO  [01:24:33.774] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:24:33.774] [bbotk]                     4616        0.817 -0.9707292         <NA>   0.9786606 
INFO  [01:24:33.774] [bbotk]                                 uhash 
INFO  [01:24:33.774] [bbotk]  cdd36b78-0a79-4de6-9397-cd284e7319a2 
DEBUG [01:24:35.087] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.922899e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.922899e-05 0.002603758 
  - best initial criterion value(s) :  388.2852 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -388.29  |proj g|=       13.009
At iterate     1  f =      -398.01  |proj g|=        5.5801
At iterate     2  f =       -405.9  |proj g|=        6.4015
At iterate     3  f =      -407.48  |proj g|=        5.8832
At iterate     4  f =      -409.31  |proj g|=        5.1683
At iterate     5  f =      -410.23  |proj g|=        4.8531
At iterate     6  f =      -410.74  |proj g|=        4.5283
At iterate     7  f =      -410.82  |proj g|=        5.1285
At iterate     8  f =       -411.2  |proj g|=        4.4628
At iterate     9  f =      -411.22  |proj g|=        4.3536
At iterate    10  f =      -411.22  |proj g|=        4.3148
At iterate    11  f =      -411.22  |proj g|=        4.3052
At iterate    12  f =      -411.22  |proj g|=        4.2989
At iterate    13  f =      -411.23  |proj g|=        4.2839
At iterate    14  f =      -411.24  |proj g|=        4.2349
At iterate    15  f =      -411.26  |proj g|=        4.2697
At iterate    16  f =      -411.29  |proj g|=         4.187
At iterate    17  f =       -411.5  |proj g|=        3.8692
At iterate    18  f =      -411.88  |proj g|=        3.5261
At iterate    19  f =      -412.97  |proj g|=        3.0154
At iterate    20  f =      -417.09  |proj g|=        2.4073
At iterate    21  f =      -417.72  |proj g|=        2.2592
At iterate    22  f =      -431.93  |proj g|=        1.3162
At iterate    23  f =      -442.88  |proj g|=       0.52746
At iterate    24  f =         -444  |proj g|=       0.65009
At iterate    25  f =      -445.04  |proj g|=       0.72084
At iterate    26  f =      -445.08  |proj g|=        1.5442
At iterate    27  f =      -446.07  |proj g|=        1.3273
At iterate    28  f =      -446.28  |proj g|=        1.1089
At iterate    29  f =      -446.31  |proj g|=        1.1744
At iterate    30  f =      -446.31  |proj g|=        1.1658
At iterate    31  f =      -446.31  |proj g|=        1.1649
At iterate    32  f =      -446.31  |proj g|=        1.1649

iterations 32
function evaluations 41
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.16487
final function value -446.311

F = -446.311
final  value -446.311351 
converged
 
INFO  [01:24:35.091] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:24:35.145] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:24:35.152] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:24:45.271] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:24:56.206] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:25:05.238] [mlr3]  Finished benchmark 
INFO  [01:25:05.308] [bbotk] Result of batch 85: 
INFO  [01:25:05.310] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:25:05.310] [bbotk]              9.767083                 7.286868                       0.4963832 
INFO  [01:25:05.310] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:25:05.310] [bbotk]                     3342        0.871 -0.9608166         <NA>   0.9779373 
INFO  [01:25:05.310] [bbotk]                                 uhash 
INFO  [01:25:05.310] [bbotk]  643d5e83-86a7-400c-8946-421bc5730d94 
DEBUG [01:25:06.575] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.911787e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.911787e-05 0.002596555 
  - best initial criterion value(s) :  401.7566 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -401.76  |proj g|=       5.5298
At iterate     1  f =      -410.64  |proj g|=        3.7011
At iterate     2  f =      -415.91  |proj g|=         4.861
At iterate     3  f =      -416.36  |proj g|=        4.8225
At iterate     4  f =      -416.62  |proj g|=        4.8239
At iterate     5  f =      -416.66  |proj g|=        4.8485
At iterate     6  f =      -416.67  |proj g|=        4.8804
At iterate     7  f =      -416.67  |proj g|=        4.9121
At iterate     8  f =      -416.67  |proj g|=        4.9186
At iterate     9  f =      -416.67  |proj g|=        4.9193
At iterate    10  f =      -416.67  |proj g|=        4.9253
At iterate    11  f =      -416.67  |proj g|=        4.9316
At iterate    12  f =      -416.67  |proj g|=        4.9421
At iterate    13  f =      -416.68  |proj g|=        4.9553
At iterate    14  f =      -416.68  |proj g|=        4.9714
At iterate    15  f =       -416.7  |proj g|=        4.9753
At iterate    16  f =      -416.72  |proj g|=        4.9226
At iterate    17  f =      -416.72  |proj g|=        4.8949
At iterate    18  f =      -416.73  |proj g|=        4.8509
At iterate    19  f =      -416.74  |proj g|=        4.8159
At iterate    20  f =      -416.77  |proj g|=         4.746
At iterate    21  f =      -416.85  |proj g|=         4.635
At iterate    22  f =      -417.04  |proj g|=        4.4418
At iterate    23  f =      -417.55  |proj g|=         4.114
At iterate    24  f =      -418.76  |proj g|=        3.6008
At iterate    25  f =      -420.62  |proj g|=        3.0257
At iterate    26  f =      -420.68  |proj g|=        3.1591
At iterate    27  f =       -422.2  |proj g|=        2.6231
At iterate    28  f =      -439.11  |proj g|=        2.2565
At iterate    29  f =      -449.07  |proj g|=        1.4432
At iterate    30  f =      -451.16  |proj g|=        1.2055
At iterate    31  f =      -451.55  |proj g|=        1.1818
At iterate    32  f =      -451.59  |proj g|=        1.1114
At iterate    33  f =      -451.65  |proj g|=        1.0888
At iterate    34  f =      -451.66  |proj g|=        1.1054
At iterate    35  f =      -451.66  |proj g|=        1.1018
At iterate    36  f =      -451.66  |proj g|=        1.1021

iterations 36
function evaluations 44
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.10206
final function value -451.663

F = -451.663
final  value -451.662529 
converged
 
INFO  [01:25:06.580] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:25:06.655] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:25:06.662] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:25:10.696] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:25:14.844] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:25:18.538] [mlr3]  Finished benchmark 
INFO  [01:25:18.626] [bbotk] Result of batch 86: 
INFO  [01:25:18.628] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:25:18.628] [bbotk]              4.991092                 7.018955                       0.1468576 
INFO  [01:25:18.628] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:25:18.628] [bbotk]                     1463        0.812 -0.9578038         <NA>   0.9697292 
INFO  [01:25:18.628] [bbotk]                                 uhash 
INFO  [01:25:18.628] [bbotk]  7ba86ec2-517e-4908-9537-8c465f37767e 
DEBUG [01:25:19.841] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.89531e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.89531e-05 0.002557659 
  - best initial criterion value(s) :  440.6871 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -440.69  |proj g|=       1.4183
At iterate     1  f =      -444.22  |proj g|=        2.0218
At iterate     2  f =      -447.62  |proj g|=        2.2104
At iterate     3  f =      -449.75  |proj g|=        2.0439
At iterate     4  f =      -450.23  |proj g|=        1.9074
At iterate     5  f =      -450.24  |proj g|=        1.8988
At iterate     6  f =      -450.24  |proj g|=         1.902
At iterate     7  f =      -450.24  |proj g|=        1.9023
At iterate     8  f =      -450.24  |proj g|=        1.9033
At iterate     9  f =      -450.24  |proj g|=        1.9048
At iterate    10  f =      -450.24  |proj g|=        1.9071
At iterate    11  f =      -450.24  |proj g|=        1.9105
At iterate    12  f =      -450.25  |proj g|=        1.9143
At iterate    13  f =      -450.28  |proj g|=        1.9154
At iterate    14  f =      -450.34  |proj g|=        1.9047
At iterate    15  f =      -450.45  |proj g|=        1.8678
At iterate    16  f =       -450.6  |proj g|=        1.8472
At iterate    17  f =      -450.97  |proj g|=        1.7751
At iterate    18  f =      -454.57  |proj g|=       0.82631
At iterate    19  f =      -455.22  |proj g|=       0.81213
At iterate    20  f =      -455.69  |proj g|=       0.79294
At iterate    21  f =      -455.76  |proj g|=       0.78329
At iterate    22  f =      -455.76  |proj g|=       0.49512
At iterate    23  f =      -455.76  |proj g|=       0.49809
At iterate    24  f =      -455.76  |proj g|=       0.49849
At iterate    25  f =      -455.76  |proj g|=       0.49852

iterations 25
function evaluations 30
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.498516
final function value -455.762

F = -455.762
final  value -455.761856 
converged
 
INFO  [01:25:19.843] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:25:19.888] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:25:19.895] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:25:22.282] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:25:24.568] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:25:27.136] [mlr3]  Finished benchmark 
INFO  [01:25:27.205] [bbotk] Result of batch 87: 
INFO  [01:25:27.206] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:25:27.206] [bbotk]              7.699272                 4.397298                       0.1864965 
INFO  [01:25:27.206] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:25:27.206] [bbotk]                      548        0.851 -0.9610297         <NA>   0.9651882 
INFO  [01:25:27.206] [bbotk]                                 uhash 
INFO  [01:25:27.206] [bbotk]  e83ceb76-3aa7-46ef-8374-bd676d7a0e0b 
DEBUG [01:25:28.307] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.881023e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.881023e-05 0.002521898 
  - best initial criterion value(s) :  437.7218 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -437.72  |proj g|=       2.1485
At iterate     1  f =      -440.16  |proj g|=        2.4951
At iterate     2  f =      -440.28  |proj g|=        2.4631
At iterate     3  f =       -440.3  |proj g|=        2.4366
At iterate     4  f =       -440.3  |proj g|=        2.4401
At iterate     5  f =       -440.3  |proj g|=         2.444
At iterate     6  f =      -440.31  |proj g|=        2.4548
At iterate     7  f =      -440.32  |proj g|=        2.4711
At iterate     8  f =      -440.33  |proj g|=        2.4906
At iterate     9  f =      -440.34  |proj g|=        2.4986
At iterate    10  f =      -440.34  |proj g|=        2.4958
At iterate    11  f =      -440.34  |proj g|=        2.4933
At iterate    12  f =      -440.34  |proj g|=        2.4928
At iterate    13  f =      -440.34  |proj g|=        2.4917
At iterate    14  f =      -440.34  |proj g|=        2.4895
At iterate    15  f =      -440.34  |proj g|=        2.4859
At iterate    16  f =      -440.34  |proj g|=        2.4798
At iterate    17  f =      -440.34  |proj g|=        2.4691
At iterate    18  f =      -440.36  |proj g|=          2.45
At iterate    19  f =      -440.38  |proj g|=        2.4215
At iterate    20  f =      -440.42  |proj g|=        2.3776
At iterate    21  f =      -440.54  |proj g|=        2.3045
At iterate    22  f =      -440.56  |proj g|=        2.2644
At iterate    23  f =      -440.83  |proj g|=        2.1666
At iterate    24  f =      -442.61  |proj g|=        1.8192
At iterate    25  f =      -448.15  |proj g|=       0.87403
At iterate    26  f =      -449.44  |proj g|=       0.87109
At iterate    27  f =      -451.19  |proj g|=       0.84873
At iterate    28  f =      -451.23  |proj g|=       0.84751
At iterate    29  f =      -451.95  |proj g|=       0.82629
At iterate    30  f =      -452.06  |proj g|=       0.81551
At iterate    31  f =      -452.07  |proj g|=        0.4786
At iterate    32  f =      -452.07  |proj g|=       0.48182
At iterate    33  f =      -452.07  |proj g|=       0.48241
At iterate    34  f =      -452.07  |proj g|=        0.4825

iterations 34
function evaluations 41
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.482503
final function value -452.071

F = -452.071
final  value -452.070869 
converged
 
INFO  [01:25:28.311] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:25:28.367] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:25:28.374] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:25:30.447] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:25:32.326] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:25:33.812] [mlr3]  Finished benchmark 
INFO  [01:25:33.902] [bbotk] Result of batch 88: 
INFO  [01:25:33.904] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:25:33.904] [bbotk]              2.739331                 3.384635                       0.3964326 
INFO  [01:25:33.904] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:25:33.904] [bbotk]                      526        0.716 -0.9664331         <NA>   0.9573826 
INFO  [01:25:33.904] [bbotk]                                 uhash 
INFO  [01:25:33.904] [bbotk]  240d842e-93fc-4e32-9598-fb924a6f9787 
DEBUG [01:25:35.144] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.878246e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.878246e-05 0.002508571 
  - best initial criterion value(s) :  434.7084 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -434.71  |proj g|=       1.8753
At iterate     1  f =       -442.7  |proj g|=        2.5221
At iterate     2  f =      -444.43  |proj g|=        2.5998
At iterate     3  f =      -448.01  |proj g|=        2.6013
At iterate     4  f =       -450.5  |proj g|=        2.4258
At iterate     5  f =      -450.93  |proj g|=        2.3294
At iterate     6  f =      -450.99  |proj g|=        2.3245
At iterate     7  f =      -451.01  |proj g|=        2.3195
At iterate     8  f =      -451.01  |proj g|=        2.3216
At iterate     9  f =      -451.01  |proj g|=        2.3214
At iterate    10  f =      -451.02  |proj g|=        2.3188
At iterate    11  f =      -451.07  |proj g|=         2.307
At iterate    12  f =      -451.26  |proj g|=        2.2602
At iterate    13  f =      -451.69  |proj g|=        2.1658
At iterate    14  f =       -451.7  |proj g|=        2.1556
At iterate    15  f =      -452.93  |proj g|=        1.9211
At iterate    16  f =      -460.76  |proj g|=       0.85888
At iterate    17  f =      -461.19  |proj g|=       0.89482
At iterate    18  f =      -461.24  |proj g|=       0.94054
At iterate    19  f =      -461.25  |proj g|=       0.96237
At iterate    20  f =      -461.25  |proj g|=       0.97184
At iterate    21  f =      -461.25  |proj g|=       0.96925
At iterate    22  f =      -461.25  |proj g|=       0.96927

iterations 22
function evaluations 32
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.969267
final function value -461.247

F = -461.247
final  value -461.247000 
converged
 
INFO  [01:25:35.149] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:25:35.205] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:25:35.212] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:25:38.160] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:25:41.411] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:25:44.878] [mlr3]  Finished benchmark 
INFO  [01:25:44.977] [bbotk] Result of batch 89: 
INFO  [01:25:44.979] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:25:44.979] [bbotk]               4.57451                 9.962332                      0.09402271 
INFO  [01:25:44.979] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:25:44.979] [bbotk]                      936        0.711 -0.9616816         <NA>   0.9602896 
INFO  [01:25:44.979] [bbotk]                                 uhash 
INFO  [01:25:44.979] [bbotk]  bb4adf57-4da9-4fd7-9c53-0cd7a3ff968b 
DEBUG [01:25:45.996] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.869989e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.869989e-05 0.002484087 
  - best initial criterion value(s) :  401.4289 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -401.43  |proj g|=       12.573
At iterate     1  f =      -434.35  |proj g|=        3.6644
At iterate     2  f =      -435.62  |proj g|=        5.0773
At iterate     3  f =      -435.83  |proj g|=        4.7515
At iterate     4  f =      -435.87  |proj g|=        4.6011
At iterate     5  f =       -435.9  |proj g|=        4.5117
At iterate     6  f =      -435.96  |proj g|=        4.3574
At iterate     7  f =      -436.01  |proj g|=        4.4709
At iterate     8  f =      -436.02  |proj g|=        4.3751
At iterate     9  f =      -436.03  |proj g|=        4.3461
At iterate    10  f =      -450.11  |proj g|=        3.5357
At iterate    11  f =      -457.73  |proj g|=        2.7823
At iterate    12  f =       -468.2  |proj g|=        1.5608
At iterate    13  f =      -468.83  |proj g|=        1.3334
At iterate    14  f =      -468.99  |proj g|=        1.2108
At iterate    15  f =         -469  |proj g|=        1.1842
At iterate    16  f =         -469  |proj g|=        1.1918
At iterate    17  f =         -469  |proj g|=         1.191
At iterate    18  f =         -469  |proj g|=        1.1909

iterations 18
function evaluations 27
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.19091
final function value -469.002

F = -469.002
final  value -469.002060 
converged
 
INFO  [01:25:46.000] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:25:46.059] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:25:46.066] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:25:58.985] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:26:08.272] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:26:18.582] [mlr3]  Finished benchmark 
INFO  [01:26:18.653] [bbotk] Result of batch 90: 
INFO  [01:26:18.655] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:26:18.655] [bbotk]              7.560759                 3.798969                       0.2314651 
INFO  [01:26:18.655] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:26:18.655] [bbotk]                     3627        0.695 -0.9541201         <NA>   0.9770571 
INFO  [01:26:18.655] [bbotk]                                 uhash 
INFO  [01:26:18.655] [bbotk]  acba7f4b-5369-445b-b3ba-73d032aa2ab3 
DEBUG [01:26:19.732] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.858862e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.858862e-05 0.002477761 
  - best initial criterion value(s) :  424.2058 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -424.21  |proj g|=       6.8399
At iterate     1  f =      -431.87  |proj g|=        5.5569
At iterate     2  f =      -432.07  |proj g|=        6.0905
At iterate     3  f =      -432.76  |proj g|=        6.3468
At iterate     4  f =      -432.85  |proj g|=         6.385
At iterate     5  f =      -432.86  |proj g|=        6.5613
At iterate     6  f =      -432.86  |proj g|=        6.5016
At iterate     7  f =      -432.86  |proj g|=        6.5026
At iterate     8  f =      -432.86  |proj g|=        6.5053
At iterate     9  f =      -432.86  |proj g|=        6.5113
At iterate    10  f =      -432.87  |proj g|=        6.5187
At iterate    11  f =      -432.87  |proj g|=        6.5294
At iterate    12  f =      -432.88  |proj g|=        6.5376
At iterate    13  f =       -432.9  |proj g|=         6.523
At iterate    14  f =      -432.95  |proj g|=        6.4811
At iterate    15  f =      -433.05  |proj g|=        6.3447
At iterate    16  f =      -433.05  |proj g|=        6.4125
At iterate    17  f =      -433.24  |proj g|=        6.1747
At iterate    18  f =      -447.01  |proj g|=        4.0352
At iterate    19  f =      -458.07  |proj g|=        3.3629
At iterate    20  f =      -468.99  |proj g|=         1.821
At iterate    21  f =       -473.5  |proj g|=        1.5351
At iterate    22  f =      -474.96  |proj g|=       0.95452
At iterate    23  f =      -474.96  |proj g|=        1.1084
At iterate    24  f =      -474.99  |proj g|=        1.0414
At iterate    25  f =      -474.99  |proj g|=        1.0342
At iterate    26  f =      -474.99  |proj g|=        1.0347
At iterate    27  f =      -474.99  |proj g|=        1.0348

iterations 27
function evaluations 37
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.03476
final function value -474.987

F = -474.987
final  value -474.987404 
converged
 
INFO  [01:26:19.736] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:26:19.796] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:26:19.803] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:26:23.763] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:26:27.198] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:26:30.909] [mlr3]  Finished benchmark 
INFO  [01:26:30.981] [bbotk] Result of batch 91: 
INFO  [01:26:30.983] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:26:30.983] [bbotk]              8.547236                 2.255517                      0.09544336 
INFO  [01:26:30.983] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:26:30.983] [bbotk]                     1299        0.699 -0.9554759         <NA>   0.9674717 
INFO  [01:26:30.983] [bbotk]                                 uhash 
INFO  [01:26:30.983] [bbotk]  05a42b20-69f7-4c11-9e64-acca24220d5f 
DEBUG [01:26:31.961] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.843935e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.843934e-05 0.002443119 
  - best initial criterion value(s) :  448.0907 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -448.09  |proj g|=       1.3845
At iterate     1  f =      -464.45  |proj g|=        1.4798
At iterate     2  f =      -470.68  |proj g|=        2.2723
At iterate     3  f =      -471.11  |proj g|=        2.3735
At iterate     4  f =      -471.42  |proj g|=        2.2814
At iterate     5  f =      -471.77  |proj g|=        2.0871
At iterate     6  f =       -471.8  |proj g|=        1.9496
At iterate     7  f =       -471.8  |proj g|=        1.9989
At iterate     8  f =       -471.8  |proj g|=        1.9943
At iterate     9  f =       -471.8  |proj g|=         1.994

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.99403
final function value -471.804

F = -471.804
final  value -471.803721 
converged
 
INFO  [01:26:31.965] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:26:32.023] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:26:32.053] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:26:44.468] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:26:58.536] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:27:09.710] [mlr3]  Finished benchmark 
INFO  [01:27:09.781] [bbotk] Result of batch 92: 
INFO  [01:27:09.783] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:27:09.783] [bbotk]              6.355163                 2.312423                       0.1392456 
INFO  [01:27:09.783] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:27:09.783] [bbotk]                     4296        0.708 -0.9570581         <NA>   0.9760981 
INFO  [01:27:09.783] [bbotk]                                 uhash 
INFO  [01:27:09.783] [bbotk]  a82852b6-aa99-4480-bff8-ce276f8cf0f4 
DEBUG [01:27:11.072] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.83209e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.83209e-05 0.002435849 
  - best initial criterion value(s) :  394.0664 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -394.07  |proj g|=       4.9456
At iterate     1  f =      -401.19  |proj g|=        5.3741
At iterate     2  f =      -401.73  |proj g|=        5.3646
At iterate     3  f =      -402.17  |proj g|=        5.2347
At iterate     4  f =      -402.32  |proj g|=        5.2531
At iterate     5  f =      -402.75  |proj g|=        5.0549
At iterate     6  f =      -404.75  |proj g|=        3.6142
At iterate     7  f =      -405.21  |proj g|=        3.3046
At iterate     8  f =      -405.28  |proj g|=        3.1761
At iterate     9  f =       -405.3  |proj g|=        3.1939
At iterate    10  f =       -405.3  |proj g|=        3.1952
At iterate    11  f =       -405.3  |proj g|=        3.1938
At iterate    12  f =       -405.3  |proj g|=        3.1888
At iterate    13  f =      -405.31  |proj g|=        3.1764
At iterate    14  f =      -405.32  |proj g|=        3.1456
At iterate    15  f =      -405.35  |proj g|=        3.0821
At iterate    16  f =      -405.42  |proj g|=        2.9591
At iterate    17  f =      -405.53  |proj g|=        2.8008
At iterate    18  f =      -405.59  |proj g|=        2.7365
At iterate    19  f =       -405.6  |proj g|=        2.7476
At iterate    20  f =      -405.63  |proj g|=        2.7642
At iterate    21  f =      -405.69  |proj g|=        2.7767
At iterate    22  f =      -405.87  |proj g|=        2.7856
At iterate    23  f =       -406.3  |proj g|=        2.7812
At iterate    24  f =      -407.46  |proj g|=        2.7305
At iterate    25  f =      -411.28  |proj g|=        2.5518
At iterate    26  f =      -433.41  |proj g|=        2.0981
At iterate    27  f =      -446.56  |proj g|=        1.4773
At iterate    28  f =      -447.57  |proj g|=        1.2098
At iterate    29  f =      -448.51  |proj g|=        1.0608
At iterate    30  f =      -452.33  |proj g|=        0.9553
At iterate    31  f =      -466.92  |proj g|=        1.1494
At iterate    32  f =      -472.42  |proj g|=          1.28
At iterate    33  f =      -474.83  |proj g|=        1.3368
At iterate    34  f =      -476.29  |proj g|=        1.5332
At iterate    35  f =      -476.87  |proj g|=        1.6895
At iterate    36  f =      -477.05  |proj g|=        1.7844
At iterate    37  f =      -477.07  |proj g|=        1.8346
At iterate    38  f =      -477.08  |proj g|=        1.8362
At iterate    39  f =      -477.08  |proj g|=        1.8469
At iterate    40  f =      -477.08  |proj g|=         1.844
At iterate    41  f =      -477.08  |proj g|=        1.8439
At iterate    42  f =      -477.08  |proj g|=        1.8436
At iterate    43  f =      -477.08  |proj g|=        1.8433
At iterate    44  f =      -477.08  |proj g|=        1.8427
At iterate    45  f =      -477.08  |proj g|=        1.8394
At iterate    46  f =      -477.08  |proj g|=        1.8394
At iterate    47  f =      -477.08  |proj g|=        1.8317
At iterate    48  f =      -477.08  |proj g|=        1.8314
At iterate    49  f =      -477.09  |proj g|=        1.8293
At iterate    50  f =      -477.13  |proj g|=        1.8211
At iterate    51  f =      -477.33  |proj g|=        1.7792
At iterate    52  f =      -478.15  |proj g|=         1.572
At iterate    53  f =      -478.36  |proj g|=        1.3421
At iterate    54  f =      -479.86  |proj g|=        1.0855
At iterate    55  f =      -481.54  |proj g|=       0.78878
At iterate    56  f =      -482.39  |proj g|=       0.75856
At iterate    57  f =      -482.58  |proj g|=        0.7394
At iterate    58  f =      -482.59  |proj g|=       0.73864
At iterate    59  f =       -482.6  |proj g|=       0.45724
At iterate    60  f =       -482.6  |proj g|=     0.0064146
At iterate    61  f =       -482.6  |proj g|=      0.003162

iterations 61
function evaluations 75
segments explored during Cauchy searches 65
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00316204
final function value -482.598

F = -482.598
final  value -482.598446 
converged
 
INFO  [01:27:11.076] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:27:11.132] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:27:11.139] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:27:23.733] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:27:36.509] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:27:49.849] [mlr3]  Finished benchmark 
INFO  [01:27:49.924] [bbotk] Result of batch 93: 
INFO  [01:27:49.926] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:27:49.926] [bbotk]               3.33397                 3.153258                       0.1070548 
INFO  [01:27:49.926] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:27:49.926] [bbotk]                     4386        0.707 -0.9451954         <NA>   0.9707978 
INFO  [01:27:49.926] [bbotk]                                 uhash 
INFO  [01:27:49.926] [bbotk]  648cd930-ecd3-425d-a69d-1732746fb9f5 
DEBUG [01:27:51.155] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.817275e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.817274e-05 0.002422811 
  - best initial criterion value(s) :  457.9939 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -457.99  |proj g|=       3.2866
At iterate     1  f =      -468.45  |proj g|=        2.4346
At iterate     2  f =      -472.73  |proj g|=        3.5258
At iterate     3  f =      -472.86  |proj g|=        3.4489
At iterate     4  f =      -472.92  |proj g|=        3.3446
At iterate     5  f =      -472.92  |proj g|=        3.3428
At iterate     6  f =      -472.92  |proj g|=        3.3404
At iterate     7  f =      -472.92  |proj g|=        3.3414
At iterate     8  f =      -472.92  |proj g|=        3.3438
At iterate     9  f =      -472.92  |proj g|=         3.348
At iterate    10  f =      -472.92  |proj g|=        3.3545
At iterate    11  f =      -472.93  |proj g|=        3.3644
At iterate    12  f =      -472.93  |proj g|=        3.3777
At iterate    13  f =      -472.95  |proj g|=        3.3898
At iterate    14  f =         -473  |proj g|=        3.3892
At iterate    15  f =      -473.09  |proj g|=        3.3719
At iterate    16  f =       -473.3  |proj g|=        3.2423
At iterate    17  f =      -473.39  |proj g|=        3.3081
At iterate    18  f =      -473.89  |proj g|=         3.101
At iterate    19  f =      -476.66  |proj g|=        2.0966
At iterate    20  f =      -479.53  |proj g|=          1.49
At iterate    21  f =      -481.06  |proj g|=         1.857
At iterate    22  f =      -481.12  |proj g|=        1.7769
At iterate    23  f =      -481.13  |proj g|=        1.7322
At iterate    24  f =      -481.13  |proj g|=         1.738
At iterate    25  f =      -481.13  |proj g|=        1.7378
At iterate    26  f =      -481.13  |proj g|=        1.7373
At iterate    27  f =      -481.13  |proj g|=        1.7352
At iterate    28  f =      -481.13  |proj g|=         1.732
At iterate    29  f =      -481.13  |proj g|=        1.7266
At iterate    30  f =      -481.13  |proj g|=        1.7176
At iterate    31  f =      -481.13  |proj g|=        1.7022
At iterate    32  f =      -481.14  |proj g|=        1.6757
At iterate    33  f =      -481.17  |proj g|=        1.6301
At iterate    34  f =      -481.22  |proj g|=        1.5631
At iterate    35  f =       -481.3  |proj g|=        1.5114
At iterate    36  f =      -481.34  |proj g|=        1.5039
At iterate    37  f =      -481.39  |proj g|=        1.5316
At iterate    38  f =      -481.43  |proj g|=        1.5575
At iterate    39  f =      -481.51  |proj g|=        1.5817
At iterate    40  f =      -481.74  |proj g|=        1.5758
At iterate    41  f =      -482.26  |proj g|=        1.4758
At iterate    42  f =      -483.25  |proj g|=        1.1882
At iterate    43  f =      -485.34  |proj g|=        0.7866
At iterate    44  f =      -486.06  |proj g|=       0.78341
At iterate    45  f =      -486.11  |proj g|=       0.78351
At iterate    46  f =      -486.12  |proj g|=       0.78348
At iterate    47  f =      -486.12  |proj g|=       0.78347
At iterate    48  f =      -486.12  |proj g|=       0.78346
At iterate    49  f =      -486.12  |proj g|=       0.78342
At iterate    50  f =      -486.12  |proj g|=       0.78329
At iterate    51  f =      -486.12  |proj g|=       0.78295
At iterate    52  f =      -486.13  |proj g|=       0.78204
At iterate    53  f =      -486.14  |proj g|=       0.77993
At iterate    54  f =      -486.16  |proj g|=       0.21971
At iterate    55  f =       -486.2  |proj g|=       0.22548
At iterate    56  f =       -486.2  |proj g|=       0.22678
At iterate    57  f =       -486.2  |proj g|=      0.053308
At iterate    58  f =       -486.2  |proj g|=     0.0097904

iterations 58
function evaluations 65
segments explored during Cauchy searches 61
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00979041
final function value -486.203

F = -486.203
final  value -486.202953 
converged
 
INFO  [01:27:51.160] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:27:51.254] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:27:51.263] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:28:05.062] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:28:17.290] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:28:30.102] [mlr3]  Finished benchmark 
INFO  [01:28:30.185] [bbotk] Result of batch 94: 
INFO  [01:28:30.187] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:28:30.187] [bbotk]              3.928256                  6.97976                       0.2859697 
INFO  [01:28:30.187] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:28:30.187] [bbotk]                     4488        0.724 -0.9597594         <NA>   0.9763107 
INFO  [01:28:30.187] [bbotk]                                 uhash 
INFO  [01:28:30.187] [bbotk]  da651fc2-951e-444f-bb96-9e9469e0c189 
DEBUG [01:28:31.649] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.805994e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.805994e-05 0.002416048 
  - best initial criterion value(s) :  410.6306 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -410.63  |proj g|=       2.2639
At iterate     1  f =      -427.84  |proj g|=        10.486
At iterate     2  f =      -428.06  |proj g|=        9.9342
At iterate     3  f =      -428.23  |proj g|=        8.5598
At iterate     4  f =      -428.24  |proj g|=        8.7628
At iterate     5  f =      -428.25  |proj g|=        8.7849
At iterate     6  f =      -428.29  |proj g|=        8.7505
At iterate     7  f =      -428.32  |proj g|=        8.4822
At iterate     8  f =      -428.34  |proj g|=         8.006
At iterate     9  f =      -428.34  |proj g|=          7.96
At iterate    10  f =      -428.34  |proj g|=        7.9575
At iterate    11  f =      -428.34  |proj g|=        7.9556
At iterate    12  f =      -428.34  |proj g|=        7.9524
At iterate    13  f =      -428.34  |proj g|=        7.9469
At iterate    14  f =      -428.34  |proj g|=          7.94
At iterate    15  f =      -428.34  |proj g|=        7.9333
At iterate    16  f =      -428.34  |proj g|=        7.9372
At iterate    17  f =      -428.35  |proj g|=        7.9843
At iterate    18  f =      -428.35  |proj g|=        8.1201
At iterate    19  f =      -428.35  |proj g|=        8.0816
At iterate    20  f =      -428.36  |proj g|=        8.2076
At iterate    21  f =      -435.25  |proj g|=        10.377
At iterate    22  f =      -439.66  |proj g|=        7.3854
At iterate    23  f =      -441.26  |proj g|=        6.4622
At iterate    24  f =      -445.99  |proj g|=        5.8752
At iterate    25  f =      -446.36  |proj g|=        5.7259
At iterate    26  f =      -447.26  |proj g|=        5.4655
At iterate    27  f =      -447.46  |proj g|=        5.8011
At iterate    28  f =      -447.48  |proj g|=        5.8315
At iterate    29  f =      -447.48  |proj g|=        5.8494
At iterate    30  f =      -447.48  |proj g|=        5.8469
At iterate    31  f =      -447.48  |proj g|=         5.831
At iterate    32  f =      -447.49  |proj g|=        5.8126
At iterate    33  f =       -447.5  |proj g|=        5.7918
At iterate    34  f =      -447.54  |proj g|=        5.7775
At iterate    35  f =      -447.62  |proj g|=        5.7868
At iterate    36  f =       -447.8  |proj g|=        5.8918
At iterate    37  f =      -447.81  |proj g|=        5.8827
At iterate    38  f =      -448.03  |proj g|=        6.1016
At iterate    39  f =      -448.21  |proj g|=        6.4106
At iterate    40  f =      -448.23  |proj g|=        6.5064
At iterate    41  f =      -448.24  |proj g|=         6.536
At iterate    42  f =      -448.25  |proj g|=        6.5667
At iterate    43  f =      -448.28  |proj g|=        6.6149
At iterate    44  f =      -448.29  |proj g|=        6.6583
At iterate    45  f =      -448.33  |proj g|=        6.6568
At iterate    46  f =      -448.62  |proj g|=        6.5541
At iterate    47  f =      -449.04  |proj g|=        6.3237
At iterate    48  f =       -449.8  |proj g|=        5.8321
At iterate    49  f =       -450.9  |proj g|=        5.3259
At iterate    50  f =      -453.26  |proj g|=        4.5728
At iterate    51  f =      -455.03  |proj g|=        3.1762
At iterate    52  f =      -458.84  |proj g|=        3.6375
At iterate    53  f =      -466.85  |proj g|=        3.7674
At iterate    54  f =      -481.76  |proj g|=        3.0319
At iterate    55  f =      -488.24  |proj g|=        2.0462
At iterate    56  f =      -491.79  |proj g|=       0.59746
At iterate    57  f =      -492.44  |proj g|=       0.31477
At iterate    58  f =      -494.31  |proj g|=       0.23941
At iterate    59  f =      -494.47  |proj g|=       0.73904
At iterate    60  f =      -494.73  |proj g|=       0.62161
At iterate    61  f =      -494.76  |proj g|=       0.23566
At iterate    62  f =      -494.76  |proj g|=       0.17028
At iterate    63  f =      -494.76  |proj g|=      0.089204
At iterate    64  f =      -494.76  |proj g|=      0.036433
At iterate    65  f =      -494.76  |proj g|=      0.012973

iterations 65
function evaluations 80
segments explored during Cauchy searches 68
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0129734
final function value -494.762

F = -494.762
final  value -494.762464 
converged
 
INFO  [01:28:31.654] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:28:31.709] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:28:31.715] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:28:38.679] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:28:47.034] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:28:54.969] [mlr3]  Finished benchmark 
INFO  [01:28:55.036] [bbotk] Result of batch 95: 
INFO  [01:28:55.038] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:28:55.038] [bbotk]              5.353551                 6.086644                       0.2543432 
INFO  [01:28:55.038] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [01:28:55.038] [bbotk]                     2761        0.715 -0.956631         <NA>   0.9761217 
INFO  [01:28:55.038] [bbotk]                                 uhash 
INFO  [01:28:55.038] [bbotk]  fa55137b-a012-4318-8440-546c231a4821 
DEBUG [01:28:56.307] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.794651e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.794651e-05 0.002407562 
  - best initial criterion value(s) :  458.5723 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -458.57  |proj g|=       3.0657
At iterate     1  f =      -472.62  |proj g|=        3.0603
At iterate     2  f =      -473.85  |proj g|=        3.4899
At iterate     3  f =      -476.01  |proj g|=        3.2759
At iterate     4  f =      -476.01  |proj g|=        3.2841
At iterate     5  f =      -476.01  |proj g|=        3.2799
At iterate     6  f =      -476.01  |proj g|=         3.281
At iterate     7  f =      -476.01  |proj g|=        3.2807
At iterate     8  f =      -476.01  |proj g|=        3.2803
At iterate     9  f =      -476.01  |proj g|=        3.2798
At iterate    10  f =      -476.01  |proj g|=        3.2776
At iterate    11  f =      -476.02  |proj g|=        3.2634
At iterate    12  f =      -476.03  |proj g|=        3.2645
At iterate    13  f =      -476.06  |proj g|=        3.2649
At iterate    14  f =      -476.15  |proj g|=        3.2601
At iterate    15  f =      -476.37  |proj g|=        3.2393
At iterate    16  f =      -476.94  |proj g|=        3.1755
At iterate    17  f =      -478.38  |proj g|=        2.9403
At iterate    18  f =      -478.66  |proj g|=        3.0328
At iterate    19  f =      -482.25  |proj g|=        2.5975
At iterate    20  f =      -494.36  |proj g|=        1.2201
At iterate    21  f =      -496.07  |proj g|=        1.0428
At iterate    22  f =       -498.3  |proj g|=        1.0376
At iterate    23  f =       -499.3  |proj g|=        1.1277
At iterate    24  f =      -499.49  |proj g|=        1.2217
At iterate    25  f =      -499.51  |proj g|=         1.254
At iterate    26  f =      -499.51  |proj g|=        1.2627
At iterate    27  f =      -499.51  |proj g|=        1.2643
At iterate    28  f =      -499.51  |proj g|=        1.2639
At iterate    29  f =      -499.51  |proj g|=        1.2639

iterations 29
function evaluations 38
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.26387
final function value -499.508

F = -499.508
final  value -499.507670 
converged
 
INFO  [01:28:56.311] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:28:56.367] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:28:56.374] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:28:58.239] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:29:00.467] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:29:02.498] [mlr3]  Finished benchmark 
INFO  [01:29:02.564] [bbotk] Result of batch 96: 
INFO  [01:29:02.566] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:29:02.566] [bbotk]              2.628067                 2.815358                       0.2468353 
INFO  [01:29:02.566] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:29:02.566] [bbotk]                      669        0.877 -0.9520538         <NA>   0.9520805 
INFO  [01:29:02.566] [bbotk]                                 uhash 
INFO  [01:29:02.566] [bbotk]  cb34307c-e2bc-477c-9e9b-ae78683c8219 
DEBUG [01:29:03.652] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.805458e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.805458e-05 0.002393405 
  - best initial criterion value(s) :  398.8548 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -398.85  |proj g|=       3.2484
At iterate     1  f =      -451.12  |proj g|=        6.3814
At iterate     2  f =      -463.81  |proj g|=        5.8674
At iterate     3  f =      -466.43  |proj g|=        5.3395
At iterate     4  f =      -466.51  |proj g|=        5.1594
At iterate     5  f =      -466.57  |proj g|=        5.2155
At iterate     6  f =       -466.7  |proj g|=        5.2656
At iterate     7  f =      -466.86  |proj g|=        5.2618
At iterate     8  f =       -466.9  |proj g|=        5.1946
At iterate     9  f =      -466.91  |proj g|=        5.1719
At iterate    10  f =      -466.91  |proj g|=        5.1721
At iterate    11  f =      -466.91  |proj g|=        5.1652
At iterate    12  f =      -466.92  |proj g|=        5.1519
At iterate    13  f =      -466.94  |proj g|=        5.1203
At iterate    14  f =         -467  |proj g|=        5.0741
At iterate    15  f =      -467.16  |proj g|=         4.993
At iterate    16  f =      -467.63  |proj g|=        4.8591
At iterate    17  f =      -468.91  |proj g|=         4.657
At iterate    18  f =      -472.25  |proj g|=        4.3897
At iterate    19  f =       -473.4  |proj g|=        3.9308
At iterate    20  f =      -480.43  |proj g|=        3.6552
At iterate    21  f =      -482.52  |proj g|=        3.7154
At iterate    22  f =      -482.93  |proj g|=        3.8944
At iterate    23  f =      -483.52  |proj g|=        4.0363
At iterate    24  f =      -483.61  |proj g|=        4.1211
At iterate    25  f =      -483.62  |proj g|=        4.1446
At iterate    26  f =      -483.62  |proj g|=         4.148
At iterate    27  f =      -483.62  |proj g|=        4.1483
At iterate    28  f =      -483.62  |proj g|=        4.1485

iterations 28
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 4.14847
final function value -483.62

F = -483.62
final  value -483.619721 
converged
 
INFO  [01:29:03.656] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:29:03.711] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:29:03.718] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:29:16.524] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:29:30.830] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:29:44.149] [mlr3]  Finished benchmark 
INFO  [01:29:44.220] [bbotk] Result of batch 97: 
INFO  [01:29:44.221] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:29:44.221] [bbotk]              3.539809                 4.039525                       0.3510912 
INFO  [01:29:44.221] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:29:44.221] [bbotk]                     4930        0.716 -0.9620353         <NA>   0.9764344 
INFO  [01:29:44.221] [bbotk]                                 uhash 
INFO  [01:29:44.221] [bbotk]  580ef7a1-caa6-464b-aa18-88dfded243f7 
DEBUG [01:29:45.296] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.794705e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.794705e-05 0.002385757 
  - best initial criterion value(s) :  449.08 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -449.08  |proj g|=       4.7029
At iterate     1  f =      -461.22  |proj g|=        10.315
At iterate     2  f =      -465.71  |proj g|=        8.1699
At iterate     3  f =       -467.6  |proj g|=        5.0839
At iterate     4  f =      -470.71  |proj g|=        6.0577
At iterate     5  f =      -470.92  |proj g|=        5.7753
At iterate     6  f =      -470.94  |proj g|=        5.7604
At iterate     7  f =      -470.94  |proj g|=        5.7631
At iterate     8  f =      -470.94  |proj g|=        5.7782
At iterate     9  f =      -470.96  |proj g|=          5.79
At iterate    10  f =      -470.99  |proj g|=        5.8866
At iterate    11  f =      -471.05  |proj g|=        5.7618
At iterate    12  f =      -471.17  |proj g|=        5.8409
At iterate    13  f =      -472.58  |proj g|=        6.1727
At iterate    14  f =      -475.97  |proj g|=        6.1679
At iterate    15  f =      -484.26  |proj g|=        5.0287
At iterate    16  f =      -484.43  |proj g|=        4.9859
At iterate    17  f =      -499.33  |proj g|=        2.5399
At iterate    18  f =      -505.23  |proj g|=        1.8053
At iterate    19  f =      -508.03  |proj g|=       0.83881
At iterate    20  f =      -508.87  |proj g|=        1.3269
At iterate    21  f =      -508.94  |proj g|=         1.261
At iterate    22  f =      -508.94  |proj g|=         1.221
At iterate    23  f =      -508.94  |proj g|=        1.2241
At iterate    24  f =      -508.94  |proj g|=        1.2237
At iterate    25  f =      -508.94  |proj g|=        1.2235

iterations 25
function evaluations 30
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.22354
final function value -508.945

F = -508.945
final  value -508.944641 
converged
 
INFO  [01:29:45.300] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:29:45.553] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:29:45.559] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:29:54.717] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:30:01.277] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:30:07.802] [mlr3]  Finished benchmark 
INFO  [01:30:07.873] [bbotk] Result of batch 98: 
INFO  [01:30:07.875] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:30:07.875] [bbotk]              9.816971                 9.959625                       0.2648916 
INFO  [01:30:07.875] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:30:07.875] [bbotk]                     2441         0.72 -0.9530435         <NA>   0.9753389 
INFO  [01:30:07.875] [bbotk]                                 uhash 
INFO  [01:30:07.875] [bbotk]  f34bc77f-3fca-47db-a78f-83fef1919b1d 
DEBUG [01:30:09.095] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.783037e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.783037e-05 0.002376588 
  - best initial criterion value(s) :  486.7289 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -486.73  |proj g|=       2.3378
At iterate     1  f =      -496.41  |proj g|=        2.1278
At iterate     2  f =      -500.52  |proj g|=        2.8047
At iterate     3  f =       -500.8  |proj g|=        2.7727
At iterate     4  f =      -501.38  |proj g|=        2.6452
At iterate     5  f =       -501.4  |proj g|=        2.6561
At iterate     6  f =       -501.4  |proj g|=        2.6599
At iterate     7  f =       -501.4  |proj g|=        2.6577
At iterate     8  f =       -501.4  |proj g|=         2.658
At iterate     9  f =       -501.4  |proj g|=        2.6584
At iterate    10  f =       -501.4  |proj g|=        2.6587
At iterate    11  f =       -501.4  |proj g|=          2.66
At iterate    12  f =       -501.4  |proj g|=        2.6615
At iterate    13  f =       -501.4  |proj g|=        2.6643
At iterate    14  f =       -501.4  |proj g|=        2.6684
At iterate    15  f =      -501.41  |proj g|=        2.6741
At iterate    16  f =      -501.41  |proj g|=        2.6799
At iterate    17  f =      -501.43  |proj g|=        2.6804
At iterate    18  f =      -501.45  |proj g|=        2.6798
At iterate    19  f =       -501.5  |proj g|=        2.6306
At iterate    20  f =      -501.72  |proj g|=         2.631
At iterate    21  f =      -502.84  |proj g|=        2.5322
At iterate    22  f =      -506.25  |proj g|=         2.151
At iterate    23  f =      -511.12  |proj g|=        1.6846
At iterate    24  f =      -512.48  |proj g|=        1.2745
At iterate    25  f =      -512.94  |proj g|=         1.342
At iterate    26  f =      -513.07  |proj g|=        1.3218
At iterate    27  f =      -513.09  |proj g|=         1.381
At iterate    28  f =      -513.09  |proj g|=        1.3835
At iterate    29  f =      -513.09  |proj g|=        1.3838
At iterate    30  f =      -513.09  |proj g|=        1.3849
At iterate    31  f =      -513.09  |proj g|=        1.3861
At iterate    32  f =      -513.09  |proj g|=        1.3884
At iterate    33  f =      -513.09  |proj g|=        1.3917
At iterate    34  f =      -513.09  |proj g|=        1.3962
At iterate    35  f =       -513.1  |proj g|=        1.4064
At iterate    36  f =       -513.1  |proj g|=         1.412
At iterate    37  f =      -513.11  |proj g|=        1.4299
At iterate    38  f =      -513.12  |proj g|=        1.4319
At iterate    39  f =      -516.44  |proj g|=       0.73347
At iterate    40  f =      -516.45  |proj g|=       0.39146
At iterate    41  f =      -516.45  |proj g|=      0.046414
At iterate    42  f =      -516.45  |proj g|=      0.003457
At iterate    43  f =      -516.45  |proj g|=     0.0010053

iterations 43
function evaluations 52
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00100527
final function value -516.447

F = -516.447
final  value -516.447166 
converged
 
INFO  [01:30:09.099] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:30:09.153] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:30:09.160] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:30:17.721] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:30:26.837] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:30:34.335] [mlr3]  Finished benchmark 
INFO  [01:30:34.430] [bbotk] Result of batch 99: 
INFO  [01:30:34.432] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:30:34.432] [bbotk]              4.484732                 3.906863                      0.07343297 
INFO  [01:30:34.432] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:30:34.432] [bbotk]                     2944        0.746 -0.9491984         <NA>   0.9687392 
INFO  [01:30:34.432] [bbotk]                                 uhash 
INFO  [01:30:34.432] [bbotk]  3ee2daf9-52a7-471c-9249-568b97eda98d 
DEBUG [01:30:35.478] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.769314e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.769314e-05 0.002363456 
  - best initial criterion value(s) :  469.492 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -469.49  |proj g|=      0.90531
At iterate     1  f =      -471.83  |proj g|=       0.88633
At iterate     2  f =      -474.93  |proj g|=       0.68893
At iterate     3  f =      -476.65  |proj g|=       0.31696
At iterate     4  f =       -476.7  |proj g|=       0.31662
At iterate     5  f =       -476.9  |proj g|=       0.30513
At iterate     6  f =       -477.8  |proj g|=       0.23899
At iterate     7  f =      -478.05  |proj g|=       0.20526
At iterate     8  f =       -478.1  |proj g|=       0.79022
At iterate     9  f =      -478.11  |proj g|=       0.78944
At iterate    10  f =      -478.11  |proj g|=       0.79015
At iterate    11  f =      -478.11  |proj g|=       0.78996
At iterate    12  f =      -478.11  |proj g|=       0.78996

iterations 12
function evaluations 18
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.78996
final function value -478.11

F = -478.11
final  value -478.109861 
converged
 
INFO  [01:30:35.482] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:30:35.537] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:30:35.544] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:30:43.472] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:30:52.410] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:31:01.357] [mlr3]  Finished benchmark 
INFO  [01:31:01.427] [bbotk] Result of batch 100: 
INFO  [01:31:01.429] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:31:01.429] [bbotk]                6.7421                 6.563678                      0.09629295 
INFO  [01:31:01.429] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:31:01.429] [bbotk]                     2839        0.746 -0.9690672         <NA>   0.9728612 
INFO  [01:31:01.429] [bbotk]                                 uhash 
INFO  [01:31:01.429] [bbotk]  1cf42358-e946-4f44-8668-a5820e555fbb 
DEBUG [01:31:02.815] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.75639e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.75639e-05 0.002371702 
  - best initial criterion value(s) :  462.2818 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -462.28  |proj g|=       1.7661
At iterate     1  f =      -468.94  |proj g|=        8.2835
At iterate     2  f =      -482.69  |proj g|=        5.8379
At iterate     3  f =      -483.19  |proj g|=        6.4333
At iterate     4  f =      -483.52  |proj g|=        6.3519
At iterate     5  f =      -484.49  |proj g|=        5.6033
At iterate     6  f =      -484.64  |proj g|=        5.9432
At iterate     7  f =      -484.65  |proj g|=        5.8704
At iterate     8  f =      -484.65  |proj g|=         5.862
At iterate     9  f =      -484.65  |proj g|=        5.8611
At iterate    10  f =      -484.65  |proj g|=        5.8579
At iterate    11  f =      -484.66  |proj g|=        5.8502
At iterate    12  f =      -484.66  |proj g|=        5.8381
At iterate    13  f =      -484.68  |proj g|=        5.8172
At iterate    14  f =      -484.72  |proj g|=        5.7905
At iterate    15  f =      -484.82  |proj g|=         5.757
At iterate    16  f =      -485.06  |proj g|=        5.6645
At iterate    17  f =      -485.64  |proj g|=        5.6308
At iterate    18  f =      -485.76  |proj g|=        5.3181
At iterate    19  f =       -486.9  |proj g|=        5.1216
At iterate    20  f =      -513.54  |proj g|=        2.4764
At iterate    21  f =      -519.22  |proj g|=        2.0609
At iterate    22  f =      -519.25  |proj g|=        2.1136
At iterate    23  f =      -519.27  |proj g|=        2.1548
At iterate    24  f =      -519.28  |proj g|=        2.1885
At iterate    25  f =      -519.28  |proj g|=        2.1912
At iterate    26  f =      -519.28  |proj g|=         2.191
At iterate    27  f =      -519.28  |proj g|=        2.1908
At iterate    28  f =      -519.28  |proj g|=        2.1906
At iterate    29  f =      -519.28  |proj g|=        2.1906
At iterate    30  f =      -519.28  |proj g|=        2.1888
At iterate    31  f =      -519.28  |proj g|=         2.189
At iterate    32  f =      -519.28  |proj g|=        2.1813
At iterate    33  f =      -519.28  |proj g|=        2.1823
At iterate    34  f =      -519.48  |proj g|=        2.1636
At iterate    35  f =      -520.56  |proj g|=        1.9504
At iterate    36  f =      -524.05  |proj g|=        1.2877
At iterate    37  f =       -526.5  |proj g|=       0.28332
At iterate    38  f =      -526.52  |proj g|=       0.28307
At iterate    39  f =      -526.75  |proj g|=         0.267
At iterate    40  f =      -526.83  |proj g|=       0.74624
At iterate    41  f =      -526.83  |proj g|=      0.093044
At iterate    42  f =      -526.83  |proj g|=      0.068594
At iterate    43  f =      -526.83  |proj g|=     0.0087917
At iterate    44  f =      -526.83  |proj g|=     0.0018095

iterations 44
function evaluations 56
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00180949
final function value -526.832

F = -526.832
final  value -526.832170 
converged
 
INFO  [01:31:02.819] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:31:02.876] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:31:02.883] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:31:10.643] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:31:18.051] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:31:24.266] [mlr3]  Finished benchmark 
INFO  [01:31:24.338] [bbotk] Result of batch 101: 
INFO  [01:31:24.340] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:31:24.340] [bbotk]              2.876689                  5.86999                        0.195115 
INFO  [01:31:24.340] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:31:24.340] [bbotk]                     2727        0.888 -0.9530645         <NA>   0.9685456 
INFO  [01:31:24.340] [bbotk]                                 uhash 
INFO  [01:31:24.340] [bbotk]  1271c183-a166-4524-9b7f-024b89478ed1 
DEBUG [01:31:25.330] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.743119e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.743119e-05 0.002357836 
  - best initial criterion value(s) :  498.2504 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -498.25  |proj g|=       1.7107
At iterate     1  f =      -500.94  |proj g|=        2.3453
At iterate     2  f =      -501.17  |proj g|=        2.2322
At iterate     3  f =      -501.63  |proj g|=        1.9894
At iterate     4  f =      -502.37  |proj g|=        1.7008
At iterate     5  f =      -503.37  |proj g|=        1.3864
At iterate     6  f =      -503.54  |proj g|=        1.6016
At iterate     7  f =      -503.54  |proj g|=        1.5805
At iterate     8  f =      -503.54  |proj g|=        1.5768
At iterate     9  f =      -503.54  |proj g|=        1.5768

iterations 9
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.57676
final function value -503.543

F = -503.543
final  value -503.543150 
converged
 
INFO  [01:31:25.334] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:31:25.445] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:31:25.453] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:31:26.609] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:31:27.738] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:31:29.166] [mlr3]  Finished benchmark 
INFO  [01:31:29.241] [bbotk] Result of batch 102: 
INFO  [01:31:29.243] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:31:29.243] [bbotk]              5.983336                 6.868454                       0.1245065 
INFO  [01:31:29.243] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:31:29.243] [bbotk]                      356        0.727 -0.9666773         <NA>   0.9535488 
INFO  [01:31:29.243] [bbotk]                                 uhash 
INFO  [01:31:29.243] [bbotk]  4aa96059-480a-4c65-b6f1-6e06c4bc1a5f 
DEBUG [01:31:30.277] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.749955e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.749955e-05 0.002343138 
  - best initial criterion value(s) :  484.5583 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -484.56  |proj g|=      0.82499
At iterate     1  f =      -490.01  |proj g|=        3.6783
At iterate     2  f =      -514.38  |proj g|=        2.7716
At iterate     3  f =       -515.8  |proj g|=        2.4425
At iterate     4  f =      -515.91  |proj g|=        2.1715
At iterate     5  f =      -515.97  |proj g|=        2.2861
At iterate     6  f =      -515.98  |proj g|=        2.2754
At iterate     7  f =      -516.03  |proj g|=        2.2098
At iterate     8  f =      -516.03  |proj g|=        2.2216
At iterate     9  f =      -516.03  |proj g|=        2.2288
At iterate    10  f =      -516.03  |proj g|=        2.2288

iterations 10
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.2288
final function value -516.029

F = -516.029
final  value -516.029475 
converged
 
INFO  [01:31:30.281] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:31:30.338] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:31:30.345] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:31:40.482] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:31:50.383] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:32:00.436] [mlr3]  Finished benchmark 
INFO  [01:32:00.531] [bbotk] Result of batch 103: 
INFO  [01:32:00.534] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:32:00.534] [bbotk]              4.172295                 6.840531                       0.1381873 
INFO  [01:32:00.534] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:32:00.534] [bbotk]                     4781         0.74 -0.9640684         <NA>   0.9745528 
INFO  [01:32:00.534] [bbotk]                                 uhash 
INFO  [01:32:00.534] [bbotk]  f432eb9f-6134-44e7-9976-7143d3e25cf1 
DEBUG [01:32:02.025] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.738517e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.738517e-05 0.002333725 
  - best initial criterion value(s) :  462.5543 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -462.55  |proj g|=       9.4462
At iterate     1  f =      -464.23  |proj g|=        10.245
At iterate     2  f =      -470.75  |proj g|=        8.3512
At iterate     3  f =      -481.89  |proj g|=        4.2355
At iterate     4  f =      -486.49  |proj g|=        2.2967
At iterate     5  f =      -487.73  |proj g|=        2.9248
At iterate     6  f =      -487.79  |proj g|=        2.7911
At iterate     7  f =      -487.79  |proj g|=        2.7515
At iterate     8  f =      -487.79  |proj g|=         2.753
At iterate     9  f =      -487.79  |proj g|=        2.7538
At iterate    10  f =      -487.79  |proj g|=        2.7555
At iterate    11  f =      -487.79  |proj g|=        2.7575
At iterate    12  f =      -487.79  |proj g|=        2.7603
At iterate    13  f =      -487.79  |proj g|=        2.7632
At iterate    14  f =       -487.8  |proj g|=        2.7646
At iterate    15  f =       -487.8  |proj g|=        2.7597
At iterate    16  f =      -487.82  |proj g|=        2.7353
At iterate    17  f =      -487.85  |proj g|=        2.6673
At iterate    18  f =      -487.91  |proj g|=        2.5262
At iterate    19  f =      -487.94  |proj g|=        2.4091
At iterate    20  f =      -487.94  |proj g|=        2.4352
At iterate    21  f =      -487.97  |proj g|=         2.477
At iterate    22  f =      -488.07  |proj g|=        2.5872
At iterate    23  f =      -488.31  |proj g|=         2.703
At iterate    24  f =      -488.93  |proj g|=        2.8069
At iterate    25  f =      -490.32  |proj g|=        2.8381
At iterate    26  f =      -492.85  |proj g|=        2.4696
At iterate    27  f =      -493.47  |proj g|=        2.6277
At iterate    28  f =      -496.73  |proj g|=        1.7909
At iterate    29  f =      -499.75  |proj g|=        1.5767
At iterate    30  f =      -501.16  |proj g|=        1.4481
At iterate    31  f =      -501.37  |proj g|=        1.3045
At iterate    32  f =       -501.4  |proj g|=        1.2428
At iterate    33  f =       -501.4  |proj g|=         1.249
At iterate    34  f =      -501.41  |proj g|=        1.2287
At iterate    35  f =      -501.41  |proj g|=        1.2289
At iterate    36  f =      -501.41  |proj g|=        1.2277
At iterate    37  f =      -501.41  |proj g|=        1.2258
At iterate    38  f =      -501.41  |proj g|=        1.2153
At iterate    39  f =      -501.41  |proj g|=        1.2153
At iterate    40  f =      -501.41  |proj g|=        1.2153
At iterate    41  f =      -501.41  |proj g|=        1.2153

iterations 41
function evaluations 53
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.21531
final function value -501.408

F = -501.408
final  value -501.407864 
converged
 
INFO  [01:32:02.030] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:32:02.214] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:32:02.221] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:32:10.894] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:32:19.386] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:32:27.942] [mlr3]  Finished benchmark 
INFO  [01:32:28.013] [bbotk] Result of batch 104: 
INFO  [01:32:28.015] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:32:28.015] [bbotk]              3.036477                 2.535546                       0.2283527 
INFO  [01:32:28.015] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:32:28.015] [bbotk]                     4161        0.926 -0.9673259         <NA>   0.9727824 
INFO  [01:32:28.015] [bbotk]                                 uhash 
INFO  [01:32:28.015] [bbotk]  ec283918-7bd8-4341-a9be-ee0c49e74e6d 
DEBUG [01:32:29.378] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.726207e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.726207e-05 0.002323301 
  - best initial criterion value(s) :  508.34 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -508.34  |proj g|=       1.7393
At iterate     1  f =      -514.88  |proj g|=        3.1313
At iterate     2  f =      -520.34  |proj g|=          3.08
At iterate     3  f =      -527.26  |proj g|=        2.7738
At iterate     4  f =      -527.65  |proj g|=        2.6397
At iterate     5  f =      -528.08  |proj g|=        2.6925
At iterate     6  f =      -530.42  |proj g|=        2.9311
At iterate     7  f =      -531.69  |proj g|=        3.1136
At iterate     8  f =      -531.96  |proj g|=        3.1643
At iterate     9  f =      -531.97  |proj g|=        3.1977
At iterate    10  f =      -531.98  |proj g|=        3.2245
At iterate    11  f =      -531.98  |proj g|=         3.227
At iterate    12  f =      -531.98  |proj g|=        3.2272
At iterate    13  f =      -531.98  |proj g|=        3.2279
At iterate    14  f =      -531.98  |proj g|=        3.2286
At iterate    15  f =      -531.98  |proj g|=        3.2299
At iterate    16  f =      -531.98  |proj g|=        3.2316
At iterate    17  f =      -531.98  |proj g|=        3.2333
At iterate    18  f =      -531.98  |proj g|=        3.2331
At iterate    19  f =      -531.99  |proj g|=        3.2259
At iterate    20  f =      -531.99  |proj g|=        3.2038
At iterate    21  f =         -532  |proj g|=        3.1892
At iterate    22  f =         -532  |proj g|=        3.1883
At iterate    23  f =         -532  |proj g|=         3.188
At iterate    24  f =         -532  |proj g|=        3.1879
At iterate    25  f =         -532  |proj g|=        3.1879
At iterate    26  f =         -532  |proj g|=        3.1893
At iterate    27  f =         -532  |proj g|=        3.1914
At iterate    28  f =      -532.02  |proj g|=        3.1946
At iterate    29  f =      -532.05  |proj g|=        3.2049
At iterate    30  f =      -532.09  |proj g|=        3.1431
At iterate    31  f =       -532.2  |proj g|=        3.1622
At iterate    32  f =      -532.84  |proj g|=        3.1443
At iterate    33  f =       -533.9  |proj g|=        2.9758
At iterate    34  f =      -535.01  |proj g|=        2.6693
At iterate    35  f =       -535.7  |proj g|=        2.4186
At iterate    36  f =       -535.8  |proj g|=        2.3041
At iterate    37  f =      -536.36  |proj g|=        2.1231
At iterate    38  f =      -536.57  |proj g|=         2.097
At iterate    39  f =      -536.61  |proj g|=        2.0777
At iterate    40  f =      -536.61  |proj g|=        2.0697
At iterate    41  f =      -536.61  |proj g|=        2.0711
At iterate    42  f =      -536.61  |proj g|=         2.071

iterations 42
function evaluations 47
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.07097
final function value -536.613

F = -536.613
final  value -536.613448 
converged
 
INFO  [01:32:29.382] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:32:29.540] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:32:29.548] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:32:32.133] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:32:34.640] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:32:38.076] [mlr3]  Finished benchmark 
INFO  [01:32:38.147] [bbotk] Result of batch 105: 
INFO  [01:32:38.149] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:32:38.149] [bbotk]              3.171212                 9.883633                       0.4000165 
INFO  [01:32:38.149] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:32:38.149] [bbotk]                     1195         0.83 -0.9560831         <NA>   0.9701698 
INFO  [01:32:38.149] [bbotk]                                 uhash 
INFO  [01:32:38.149] [bbotk]  57cbdf1c-4bbe-4252-a5ff-ca740202641f 
DEBUG [01:32:39.348] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.71343e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.71343e-05 0.00229172 
  - best initial criterion value(s) :  502.5735 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -502.57  |proj g|=       2.3498
At iterate     1  f =      -526.02  |proj g|=        2.5775
At iterate     2  f =      -533.99  |proj g|=        3.9482
At iterate     3  f =      -534.66  |proj g|=        3.6914
At iterate     4  f =      -534.69  |proj g|=        3.7086
At iterate     5  f =      -534.72  |proj g|=        3.7072
At iterate     6  f =      -534.74  |proj g|=        3.6501
At iterate     7  f =      -534.75  |proj g|=        3.6477
At iterate     8  f =      -534.75  |proj g|=        3.6489
At iterate     9  f =      -534.75  |proj g|=        3.6555
At iterate    10  f =      -534.75  |proj g|=        3.6634
At iterate    11  f =      -534.76  |proj g|=         3.677
At iterate    12  f =      -534.77  |proj g|=        3.6951
At iterate    13  f =      -534.81  |proj g|=        3.7183
At iterate    14  f =      -534.92  |proj g|=        3.7338
At iterate    15  f =      -535.13  |proj g|=        3.7051
At iterate    16  f =      -535.37  |proj g|=        3.5894
At iterate    17  f =       -535.5  |proj g|=        3.5022
At iterate    18  f =      -535.66  |proj g|=        3.3569
At iterate    19  f =      -535.76  |proj g|=         3.277
At iterate    20  f =      -535.99  |proj g|=        3.1366
At iterate    21  f =       -536.6  |proj g|=        2.8594
At iterate    22  f =      -538.15  |proj g|=        2.3715
At iterate    23  f =      -541.46  |proj g|=        1.6221
At iterate    24  f =      -544.04  |proj g|=        1.3543
At iterate    25  f =      -544.26  |proj g|=        1.4745
At iterate    26  f =      -544.45  |proj g|=        1.6065
At iterate    27  f =      -544.58  |proj g|=        1.6833
At iterate    28  f =      -544.88  |proj g|=        1.7978
At iterate    29  f =      -545.36  |proj g|=        1.9048
At iterate    30  f =      -546.17  |proj g|=        1.9595
At iterate    31  f =      -547.53  |proj g|=        1.7971
At iterate    32  f =      -548.27  |proj g|=        1.4786
At iterate    33  f =      -548.35  |proj g|=        1.3439
At iterate    34  f =      -548.36  |proj g|=         1.401
At iterate    35  f =      -548.36  |proj g|=        1.3895
At iterate    36  f =      -548.36  |proj g|=        1.3883
At iterate    37  f =      -548.36  |proj g|=        1.3885

iterations 37
function evaluations 41
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.3885
final function value -548.357

F = -548.357
final  value -548.357246 
converged
 
INFO  [01:32:39.353] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:32:39.790] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:32:39.797] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:32:41.882] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:32:43.864] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:32:45.973] [mlr3]  Finished benchmark 
INFO  [01:32:46.058] [bbotk] Result of batch 106: 
INFO  [01:32:46.060] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:32:46.060] [bbotk]              9.900474                 5.221029                        0.333958 
INFO  [01:32:46.060] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:32:46.060] [bbotk]                      742        0.753 -0.9515912         <NA>   0.9717819 
INFO  [01:32:46.060] [bbotk]                                 uhash 
INFO  [01:32:46.060] [bbotk]  d218e7df-36fe-4f2d-9d95-5ab6d7e501b6 
DEBUG [01:32:47.548] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.701114e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.701114e-05 0.002259745 
  - best initial criterion value(s) :  497.8153 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -497.82  |proj g|=        3.973
At iterate     1  f =      -519.77  |proj g|=        2.8837
At iterate     2  f =      -522.45  |proj g|=        4.1262
At iterate     3  f =      -522.88  |proj g|=        3.9756
At iterate     4  f =      -523.28  |proj g|=        3.7698
At iterate     5  f =      -523.46  |proj g|=         3.683
At iterate     6  f =      -523.56  |proj g|=        3.7838
At iterate     7  f =      -523.56  |proj g|=        3.8146
At iterate     8  f =      -523.56  |proj g|=        3.8135
At iterate     9  f =      -523.56  |proj g|=        3.8127
At iterate    10  f =      -523.56  |proj g|=        3.8108
At iterate    11  f =      -523.56  |proj g|=        3.8082
At iterate    12  f =      -523.56  |proj g|=        3.8036
At iterate    13  f =      -523.56  |proj g|=        3.7965
At iterate    14  f =      -523.56  |proj g|=         3.785
At iterate    15  f =      -523.57  |proj g|=        3.7674
At iterate    16  f =      -523.58  |proj g|=        3.7437
At iterate    17  f =      -523.61  |proj g|=        3.7258
At iterate    18  f =      -523.64  |proj g|=        3.7573
At iterate    19  f =      -523.65  |proj g|=        3.7889
At iterate    20  f =      -523.65  |proj g|=        3.7949
At iterate    21  f =      -523.65  |proj g|=        3.8002
At iterate    22  f =      -523.65  |proj g|=        3.8085
At iterate    23  f =      -523.65  |proj g|=        3.8209
At iterate    24  f =      -523.66  |proj g|=        3.8341
At iterate    25  f =      -523.69  |proj g|=        3.8558
At iterate    26  f =      -523.75  |proj g|=        3.8804
At iterate    27  f =      -523.89  |proj g|=        3.8925
At iterate    28  f =      -524.17  |proj g|=        3.9859
At iterate    29  f =      -524.81  |proj g|=        3.8486
At iterate    30  f =      -526.17  |proj g|=        3.6358
At iterate    31  f =      -526.76  |proj g|=         2.119
At iterate    32  f =      -530.87  |proj g|=         2.508
At iterate    33  f =       -535.3  |proj g|=        2.7294
At iterate    34  f =      -543.21  |proj g|=        1.9597
At iterate    35  f =      -547.61  |proj g|=        1.6099
At iterate    36  f =      -550.98  |proj g|=        1.3844
At iterate    37  f =      -551.54  |proj g|=        1.5401
At iterate    38  f =      -551.56  |proj g|=        1.4822
At iterate    39  f =      -551.56  |proj g|=         1.482
At iterate    40  f =      -551.56  |proj g|=        1.4819
At iterate    41  f =      -551.56  |proj g|=        1.4818
At iterate    42  f =      -551.56  |proj g|=        1.4817
At iterate    43  f =      -551.56  |proj g|=        1.4817
At iterate    44  f =      -551.56  |proj g|=        1.4797
At iterate    45  f =      -551.56  |proj g|=        1.4802
At iterate    46  f =      -551.56  |proj g|=         1.481
At iterate    47  f =      -551.57  |proj g|=        1.4684
At iterate    48  f =      -551.57  |proj g|=        1.4701
At iterate    49  f =      -551.59  |proj g|=        1.4714
At iterate    50  f =      -552.79  |proj g|=        1.2763
At iterate    51  f =      -554.82  |proj g|=       0.73411
At iterate    52  f =      -554.83  |proj g|=        0.1747
At iterate    53  f =      -554.83  |proj g|=      0.064578
At iterate    54  f =      -554.83  |proj g|=     0.0025128
At iterate    55  f =      -554.83  |proj g|=     0.0025128

iterations 55
function evaluations 66
segments explored during Cauchy searches 59
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00251284
final function value -554.827

F = -554.827
final  value -554.827274 
converged
 
INFO  [01:32:47.552] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:32:47.609] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:32:47.615] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:32:50.832] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:32:53.700] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:32:57.499] [mlr3]  Finished benchmark 
INFO  [01:32:57.582] [bbotk] Result of batch 107: 
INFO  [01:32:57.584] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:32:57.584] [bbotk]              5.472411                 5.972361                       0.3813578 
INFO  [01:32:57.584] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:32:57.584] [bbotk]                      858        0.736 -0.9465877         <NA>   0.9731314 
INFO  [01:32:57.584] [bbotk]                                 uhash 
INFO  [01:32:57.584] [bbotk]  53aba219-3d26-4488-9279-2bd8bdea0436 
DEBUG [01:32:58.785] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.689488e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.689488e-05 0.002229823 
  - best initial criterion value(s) :  508.1656 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -508.17  |proj g|=       4.5227
At iterate     1  f =      -509.22  |proj g|=        5.9445
At iterate     2  f =      -511.49  |proj g|=        5.6586
At iterate     3  f =      -514.06  |proj g|=        4.8698
At iterate     4  f =      -516.29  |proj g|=        4.3752
At iterate     5  f =      -523.69  |proj g|=        2.8678
At iterate     6  f =      -525.26  |proj g|=        2.5957
At iterate     7  f =      -525.29  |proj g|=        2.7862
At iterate     8  f =       -525.3  |proj g|=        2.7153
At iterate     9  f =       -525.3  |proj g|=        2.7121
At iterate    10  f =       -525.3  |proj g|=        2.7122
At iterate    11  f =       -525.3  |proj g|=        2.7124
At iterate    12  f =       -525.3  |proj g|=        2.7128
At iterate    13  f =       -525.3  |proj g|=        2.7133
At iterate    14  f =       -525.3  |proj g|=         2.714
At iterate    15  f =       -525.3  |proj g|=         2.715
At iterate    16  f =       -525.3  |proj g|=        2.7153
At iterate    17  f =       -525.3  |proj g|=        2.7121
At iterate    18  f =      -525.31  |proj g|=        2.6987
At iterate    19  f =      -525.31  |proj g|=        2.6739
At iterate    20  f =      -525.31  |proj g|=        2.6815
At iterate    21  f =      -525.33  |proj g|=          2.65
At iterate    22  f =       -525.4  |proj g|=        2.5816
At iterate    23  f =      -525.88  |proj g|=        2.2701
At iterate    24  f =      -527.05  |proj g|=        1.7622
At iterate    25  f =       -530.1  |proj g|=        1.0531
At iterate    26  f =      -530.44  |proj g|=       0.96702
At iterate    27  f =      -534.43  |proj g|=       0.85347
At iterate    28  f =      -535.76  |proj g|=        0.8397
At iterate    29  f =      -537.42  |proj g|=       0.80672
At iterate    30  f =      -537.73  |proj g|=       0.79013
At iterate    31  f =      -537.79  |proj g|=       0.46481
At iterate    32  f =      -537.79  |proj g|=       0.78108
At iterate    33  f =      -537.79  |proj g|=       0.49868
At iterate    34  f =      -537.79  |proj g|=       0.49956
At iterate    35  f =      -537.79  |proj g|=       0.49959

iterations 35
function evaluations 44
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.499586
final function value -537.792

F = -537.792
final  value -537.792436 
converged
 
INFO  [01:32:58.790] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:32:58.844] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:32:58.851] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:33:04.824] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:33:09.298] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:33:15.379] [mlr3]  Finished benchmark 
INFO  [01:33:15.446] [bbotk] Result of batch 108: 
INFO  [01:33:15.448] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:33:15.448] [bbotk]              3.916012                 2.158965                     0.008275701 
INFO  [01:33:15.448] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:33:15.448] [bbotk]                     1779        0.736 -0.9638281         <NA>   0.9161936 
INFO  [01:33:15.448] [bbotk]                                 uhash 
INFO  [01:33:15.448] [bbotk]  d9e2ee20-422c-4ae7-807a-ede51acf5e74 
DEBUG [01:33:16.507] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.884381e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.884381e-05 0.002384928 
  - best initial criterion value(s) :  519.2218 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -519.22  |proj g|=       1.0694
At iterate     1  f =      -528.45  |proj g|=        2.9853
At iterate     2  f =      -531.77  |proj g|=        2.6227
At iterate     3  f =      -534.34  |proj g|=        1.9693
At iterate     4  f =      -534.35  |proj g|=        1.9369
At iterate     5  f =      -534.36  |proj g|=        1.9468
At iterate     6  f =      -534.36  |proj g|=        1.9514
At iterate     7  f =      -534.38  |proj g|=        1.9661
At iterate     8  f =      -534.39  |proj g|=        1.9765
At iterate     9  f =       -534.4  |proj g|=        1.9749
At iterate    10  f =       -534.4  |proj g|=        1.9716
At iterate    11  f =       -534.4  |proj g|=        1.9705
At iterate    12  f =       -534.4  |proj g|=        1.9703

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.97033
final function value -534.402

F = -534.402
final  value -534.401648 
converged
 
INFO  [01:33:16.511] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:33:16.566] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:33:16.572] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:33:19.536] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:33:24.195] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:33:30.093] [mlr3]  Finished benchmark 
INFO  [01:33:30.179] [bbotk] Result of batch 109: 
INFO  [01:33:30.181] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:33:30.181] [bbotk]                8.5767                 9.112853                       0.3825437 
INFO  [01:33:30.181] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:33:30.181] [bbotk]                     1191        0.758 -0.9591406         <NA>   0.9749938 
INFO  [01:33:30.181] [bbotk]                                 uhash 
INFO  [01:33:30.181] [bbotk]  2e5ba4c1-3784-4cae-98f1-b1445094f541 
DEBUG [01:33:31.361] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.873007e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.873007e-05 0.002353426 
  - best initial criterion value(s) :  501.8687 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -501.87  |proj g|=       7.5408
At iterate     1  f =       -512.2  |proj g|=        4.3559
At iterate     2  f =      -513.53  |proj g|=        6.0232
At iterate     3  f =      -514.06  |proj g|=        5.8128
At iterate     4  f =      -514.48  |proj g|=        5.5801
At iterate     5  f =      -514.68  |proj g|=        5.6692
At iterate     6  f =      -514.84  |proj g|=        6.1701
At iterate     7  f =      -514.85  |proj g|=        6.0777
At iterate     8  f =      -514.85  |proj g|=        6.0816
At iterate     9  f =      -514.86  |proj g|=           6.1
At iterate    10  f =      -514.88  |proj g|=        6.1348
At iterate    11  f =      -514.88  |proj g|=        6.1559
At iterate    12  f =      -514.93  |proj g|=        6.1986
At iterate    13  f =      -522.08  |proj g|=        5.1684
At iterate    14  f =      -536.53  |proj g|=        3.2905
At iterate    15  f =       -549.7  |proj g|=        1.3282
At iterate    16  f =       -550.9  |proj g|=        1.2838
At iterate    17  f =      -551.17  |proj g|=         1.073
At iterate    18  f =      -551.42  |proj g|=         1.194
At iterate    19  f =      -551.42  |proj g|=        1.2111
At iterate    20  f =      -551.42  |proj g|=        1.2073
At iterate    21  f =      -551.42  |proj g|=        1.2072

iterations 21
function evaluations 30
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.20721
final function value -551.425

F = -551.425
final  value -551.424939 
converged
 
INFO  [01:33:31.365] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:33:31.422] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:33:31.429] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:33:43.306] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:33:55.711] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:34:06.223] [mlr3]  Finished benchmark 
INFO  [01:34:06.324] [bbotk] Result of batch 110: 
INFO  [01:34:06.326] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:34:06.326] [bbotk]              8.857217                 8.842659                       0.4971045 
INFO  [01:34:06.326] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:34:06.326] [bbotk]                     3581        0.786 -0.9534244         <NA>   0.9786883 
INFO  [01:34:06.326] [bbotk]                                 uhash 
INFO  [01:34:06.326] [bbotk]  d38e9fe3-7665-47b8-a6f1-d0f0f44eb131 
DEBUG [01:34:07.356] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.865609e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.865609e-05 0.002360458 
  - best initial criterion value(s) :  513.1571 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -513.16  |proj g|=       1.8127
At iterate     1  f =      -518.18  |proj g|=        1.8123
At iterate     2  f =      -519.42  |proj g|=        2.0046
At iterate     3  f =      -519.45  |proj g|=        1.9989
At iterate     4  f =      -519.46  |proj g|=        1.9957
At iterate     5  f =      -519.46  |proj g|=         1.997
At iterate     6  f =      -519.46  |proj g|=        1.9984
At iterate     7  f =      -519.46  |proj g|=        1.9984

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.9984
final function value -519.464

F = -519.464
final  value -519.463670 
converged
 
INFO  [01:34:07.360] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:34:07.418] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:34:07.425] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:34:13.147] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:34:19.583] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:34:25.211] [mlr3]  Finished benchmark 
INFO  [01:34:25.279] [bbotk] Result of batch 111: 
INFO  [01:34:25.280] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:34:25.280] [bbotk]              3.850563                 6.152004                        0.405485 
INFO  [01:34:25.280] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:34:25.280] [bbotk]                     2080        0.767 -0.9674287         <NA>   0.9749192 
INFO  [01:34:25.280] [bbotk]                                 uhash 
INFO  [01:34:25.280] [bbotk]  5ae20209-3583-4bf9-9e26-c392bcb5cc2e 
DEBUG [01:34:26.738] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.854393e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.854393e-05 0.002349226 
  - best initial criterion value(s) :  468.3839 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -468.38  |proj g|=       9.2513
At iterate     1  f =      -521.86  |proj g|=        5.0385
At iterate     2  f =      -523.78  |proj g|=         7.152
At iterate     3  f =      -525.96  |proj g|=        6.5692
At iterate     4  f =      -527.67  |proj g|=        4.2432
At iterate     5  f =      -528.16  |proj g|=        5.2594
At iterate     6  f =      -528.21  |proj g|=        5.0535
At iterate     7  f =      -528.22  |proj g|=        5.0048
At iterate     8  f =      -528.22  |proj g|=         5.002
At iterate     9  f =      -528.22  |proj g|=         4.996
At iterate    10  f =      -528.22  |proj g|=        4.9879
At iterate    11  f =      -528.22  |proj g|=        4.9788
At iterate    12  f =      -528.23  |proj g|=        4.9466
At iterate    13  f =      -528.26  |proj g|=         4.888
At iterate    14  f =      -528.26  |proj g|=        4.9347
At iterate    15  f =      -528.32  |proj g|=        4.8105
At iterate    16  f =       -528.8  |proj g|=        4.5521
At iterate    17  f =      -537.18  |proj g|=        2.9932
At iterate    18  f =      -546.49  |proj g|=        2.8149
At iterate    19  f =      -551.55  |proj g|=        2.4984
At iterate    20  f =      -552.85  |proj g|=         2.185
At iterate    21  f =      -552.96  |proj g|=        2.2611
At iterate    22  f =      -552.96  |proj g|=        2.2499
At iterate    23  f =      -552.96  |proj g|=        2.2484
At iterate    24  f =      -552.96  |proj g|=        2.2483
At iterate    25  f =      -552.96  |proj g|=        2.2485
At iterate    26  f =      -552.96  |proj g|=        2.2496
At iterate    27  f =      -552.96  |proj g|=        2.2515
At iterate    28  f =      -552.96  |proj g|=        2.2533
At iterate    29  f =      -552.97  |proj g|=        2.2543
At iterate    30  f =      -552.99  |proj g|=        2.2631
At iterate    31  f =      -553.03  |proj g|=        2.2561
At iterate    32  f =      -553.15  |proj g|=        2.2751
At iterate    33  f =      -553.39  |proj g|=        2.2317
At iterate    34  f =      -554.72  |proj g|=        2.0482
At iterate    35  f =      -557.07  |proj g|=        0.8443
At iterate    36  f =      -558.84  |proj g|=       0.84342
At iterate    37  f =      -559.61  |proj g|=       0.82759
At iterate    38  f =      -560.09  |proj g|=       0.80434
At iterate    39  f =      -560.11  |proj g|=       0.19679
At iterate    40  f =      -560.12  |proj g|=       0.19745
At iterate    41  f =      -560.12  |proj g|=     0.0069588
At iterate    42  f =      -560.12  |proj g|=     0.0069596

iterations 42
function evaluations 50
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00695957
final function value -560.117

F = -560.117
final  value -560.116706 
converged
 
INFO  [01:34:26.742] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:34:26.800] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:34:26.807] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:34:31.116] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:34:35.553] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:34:41.307] [mlr3]  Finished benchmark 
INFO  [01:34:41.399] [bbotk] Result of batch 112: 
INFO  [01:34:41.401] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:34:41.401] [bbotk]              6.218995                 6.443133                       0.3638469 
INFO  [01:34:41.401] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:34:41.401] [bbotk]                     1505        0.935 -0.9550897         <NA>   0.9757307 
INFO  [01:34:41.401] [bbotk]                                 uhash 
INFO  [01:34:41.401] [bbotk]  b74c2017-6205-4697-bc4b-c79c7a300808 
DEBUG [01:34:42.548] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.843956e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.843956e-05 0.002318829 
  - best initial criterion value(s) :  533.3878 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -533.39  |proj g|=       4.0142
At iterate     1  f =      -535.31  |proj g|=        4.1415
At iterate     2  f =      -535.55  |proj g|=         3.985
At iterate     3  f =      -535.57  |proj g|=        3.9667
At iterate     4  f =      -535.58  |proj g|=          3.97
At iterate     5  f =      -535.58  |proj g|=        3.9711
At iterate     6  f =      -535.58  |proj g|=        3.9755
At iterate     7  f =      -535.58  |proj g|=        3.9801
At iterate     8  f =      -535.59  |proj g|=        3.9877
At iterate     9  f =      -535.61  |proj g|=        3.9943
At iterate    10  f =      -535.67  |proj g|=        3.9951
At iterate    11  f =      -535.78  |proj g|=        3.9801
At iterate    12  f =      -536.05  |proj g|=        3.9021
At iterate    13  f =      -536.05  |proj g|=        3.9759
At iterate    14  f =      -536.61  |proj g|=        3.7739
At iterate    15  f =      -537.94  |proj g|=        3.3808
At iterate    16  f =       -542.3  |proj g|=         2.553
At iterate    17  f =      -553.51  |proj g|=        1.1783
At iterate    18  f =      -557.59  |proj g|=        1.3103
At iterate    19  f =      -560.68  |proj g|=       0.23247
At iterate    20  f =      -561.25  |proj g|=       0.81671
At iterate    21  f =      -561.36  |proj g|=       0.66851
At iterate    22  f =      -561.39  |proj g|=       0.56084
At iterate    23  f =       -561.4  |proj g|=       0.61264
At iterate    24  f =       -561.4  |proj g|=       0.60729
At iterate    25  f =       -561.4  |proj g|=       0.60704

iterations 25
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.607036
final function value -561.402

F = -561.402
final  value -561.401983 
converged
 
INFO  [01:34:42.553] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:34:42.612] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:34:42.619] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:34:44.062] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:34:45.396] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:34:47.199] [mlr3]  Finished benchmark 
INFO  [01:34:47.269] [bbotk] Result of batch 113: 
INFO  [01:34:47.270] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:34:47.270] [bbotk]              2.655459                 6.835425                       0.2365679 
INFO  [01:34:47.270] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:34:47.270] [bbotk]                      361         0.75 -0.9575628         <NA>   0.9433031 
INFO  [01:34:47.270] [bbotk]                                 uhash 
INFO  [01:34:47.270] [bbotk]  a4467b1f-5079-491d-9987-019b050d893a 
DEBUG [01:34:48.607] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.879269e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.879269e-05 0.002367909 
  - best initial criterion value(s) :  488.1819 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -488.18  |proj g|=       12.415
At iterate     1  f =       -492.9  |proj g|=        9.0276
At iterate     2  f =      -507.72  |proj g|=        6.7981
At iterate     3  f =      -517.43  |proj g|=        4.9897
At iterate     4  f =      -526.36  |proj g|=         2.652
At iterate     5  f =      -526.99  |proj g|=        2.6119
At iterate     6  f =         -527  |proj g|=        2.5467
At iterate     7  f =         -527  |proj g|=        2.5589
At iterate     8  f =         -527  |proj g|=        2.5618
At iterate     9  f =      -527.02  |proj g|=        2.5756
At iterate    10  f =      -527.06  |proj g|=        2.5906
At iterate    11  f =      -527.18  |proj g|=        2.6184
At iterate    12  f =      -527.47  |proj g|=        2.6414
At iterate    13  f =       -528.2  |proj g|=        2.6596
At iterate    14  f =      -529.72  |proj g|=        2.5294
At iterate    15  f =       -532.6  |proj g|=        2.3556
At iterate    16  f =      -534.83  |proj g|=        1.4557
At iterate    17  f =      -537.91  |proj g|=       0.98079
At iterate    18  f =      -540.38  |proj g|=       0.59269
At iterate    19  f =      -541.58  |proj g|=       0.79373
At iterate    20  f =      -542.05  |proj g|=       0.81283
At iterate    21  f =      -542.22  |proj g|=       0.82189
At iterate    22  f =      -542.38  |proj g|=       0.83154
At iterate    23  f =      -542.39  |proj g|=       0.82763
At iterate    24  f =      -542.39  |proj g|=       0.52319
At iterate    25  f =      -542.39  |proj g|=       0.52317
At iterate    26  f =      -542.39  |proj g|=       0.52317

iterations 26
function evaluations 33
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.523174
final function value -542.391

F = -542.391
final  value -542.390958 
converged
 
INFO  [01:34:48.611] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:34:48.705] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:34:48.713] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:34:55.886] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:35:03.257] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:35:09.666] [mlr3]  Finished benchmark 
INFO  [01:35:09.735] [bbotk] Result of batch 114: 
INFO  [01:35:09.737] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:35:09.737] [bbotk]               7.77422                 3.867173                      0.01226994 
INFO  [01:35:09.737] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:35:09.737] [bbotk]                     2278        0.888 -0.9653346         <NA>   0.9470578 
INFO  [01:35:09.737] [bbotk]                                 uhash 
INFO  [01:35:09.737] [bbotk]  367ecf53-9105-4cbc-8910-14d207fb1fd0 
DEBUG [01:35:10.940] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.900853e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.900853e-05 0.002379382 
  - best initial criterion value(s) :  520.9849 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -520.98  |proj g|=       4.4889
At iterate     1  f =       -521.7  |proj g|=        4.6248
At iterate     2  f =       -522.7  |proj g|=        4.4665
At iterate     3  f =      -525.85  |proj g|=        3.7068
At iterate     4  f =       -528.8  |proj g|=        3.4721
At iterate     5  f =       -529.5  |proj g|=        3.2318
At iterate     6  f =      -529.55  |proj g|=        3.3434
At iterate     7  f =      -529.56  |proj g|=        3.3228
At iterate     8  f =      -529.56  |proj g|=        3.3216
At iterate     9  f =      -529.56  |proj g|=        3.3198
At iterate    10  f =      -529.56  |proj g|=        3.3171
At iterate    11  f =      -529.56  |proj g|=        3.3124
At iterate    12  f =      -529.56  |proj g|=        3.3049
At iterate    13  f =      -529.56  |proj g|=        3.2917
At iterate    14  f =      -529.57  |proj g|=        3.2717
At iterate    15  f =       -529.6  |proj g|=        3.2355
At iterate    16  f =      -529.64  |proj g|=        3.1671
At iterate    17  f =      -529.76  |proj g|=        3.1456
At iterate    18  f =       -530.3  |proj g|=        3.0406
At iterate    19  f =      -531.43  |proj g|=        2.8632
At iterate    20  f =      -534.32  |proj g|=        2.5186
At iterate    21  f =      -540.42  |proj g|=        1.9574
At iterate    22  f =      -549.04  |proj g|=        1.3117
At iterate    23  f =      -551.22  |proj g|=        1.0984
At iterate    24  f =      -555.12  |proj g|=       0.26009
At iterate    25  f =      -555.16  |proj g|=       0.18147
At iterate    26  f =      -555.18  |proj g|=       0.17796
At iterate    27  f =      -555.18  |proj g|=       0.15665
At iterate    28  f =      -555.18  |proj g|=       0.15645
At iterate    29  f =      -555.18  |proj g|=       0.15645

iterations 29
function evaluations 35
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.156453
final function value -555.183

F = -555.183
final  value -555.183381 
converged
 
INFO  [01:35:10.944] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:35:11.151] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:35:11.158] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:35:13.788] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:35:16.181] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:35:18.768] [mlr3]  Finished benchmark 
INFO  [01:35:18.838] [bbotk] Result of batch 115: 
INFO  [01:35:18.840] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:35:18.840] [bbotk]              7.357351                 9.529769                      0.03784967 
INFO  [01:35:18.840] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:35:18.840] [bbotk]                      936        0.765 -0.9628665         <NA>   0.9514822 
INFO  [01:35:18.840] [bbotk]                                 uhash 
INFO  [01:35:18.840] [bbotk]  f755f78a-887d-479b-a523-cc3aec420a7c 
DEBUG [01:35:19.966] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.909521e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.909521e-05 0.002383949 
  - best initial criterion value(s) :  516.6728 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -516.67  |proj g|=       3.5672
At iterate     1  f =       -547.9  |proj g|=        2.6237
At iterate     2  f =      -548.41  |proj g|=         2.459
At iterate     3  f =      -549.14  |proj g|=        2.2501
At iterate     4  f =      -549.28  |proj g|=        2.3037
At iterate     5  f =      -549.31  |proj g|=        2.3007
At iterate     6  f =      -549.59  |proj g|=        2.2917
At iterate     7  f =      -549.93  |proj g|=        2.3094
At iterate     8  f =      -550.44  |proj g|=         2.377
At iterate     9  f =      -550.64  |proj g|=        2.4353
At iterate    10  f =      -550.69  |proj g|=        2.4731
At iterate    11  f =      -550.69  |proj g|=        2.4861
At iterate    12  f =       -550.7  |proj g|=        2.4879
At iterate    13  f =       -550.7  |proj g|=         2.488

iterations 13
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.48802
final function value -550.695

F = -550.695
final  value -550.695016 
converged
 
INFO  [01:35:19.970] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:35:20.027] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:35:20.034] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:35:32.875] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:35:45.067] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:35:57.931] [mlr3]  Finished benchmark 
INFO  [01:35:58.002] [bbotk] Result of batch 116: 
INFO  [01:35:58.004] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:35:58.004] [bbotk]              8.288028                 4.600445                       0.2349061 
INFO  [01:35:58.004] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:35:58.004] [bbotk]                     4215        0.796 -0.9608164         <NA>   0.9773913 
INFO  [01:35:58.004] [bbotk]                                 uhash 
INFO  [01:35:58.004] [bbotk]  3ce7cd63-8f92-4d7a-b8ac-d955f3e238b1 
DEBUG [01:35:59.491] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.901016e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.901016e-05 0.002380197 
  - best initial criterion value(s) :  532.2533 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -532.25  |proj g|=       2.4332
At iterate     1  f =      -537.56  |proj g|=        2.4459
At iterate     2  f =      -542.12  |proj g|=        2.7207
At iterate     3  f =      -542.22  |proj g|=        2.7157
At iterate     4  f =      -542.26  |proj g|=        2.7088
At iterate     5  f =      -542.26  |proj g|=        2.7095
At iterate     6  f =      -542.26  |proj g|=        2.7108
At iterate     7  f =      -542.26  |proj g|=        2.7116
At iterate     8  f =      -542.26  |proj g|=        2.7118
At iterate     9  f =      -542.26  |proj g|=        2.7119
At iterate    10  f =      -542.26  |proj g|=        2.7122
At iterate    11  f =      -542.26  |proj g|=        2.7126
At iterate    12  f =      -542.26  |proj g|=        2.7133
At iterate    13  f =      -542.26  |proj g|=        2.7144
At iterate    14  f =      -542.26  |proj g|=        2.7162
At iterate    15  f =      -542.27  |proj g|=        2.7189
At iterate    16  f =      -542.27  |proj g|=        2.7231
At iterate    17  f =      -542.28  |proj g|=        2.7291
At iterate    18  f =      -542.32  |proj g|=        2.7367
At iterate    19  f =      -542.41  |proj g|=        2.7424
At iterate    20  f =      -542.65  |proj g|=        2.7334
At iterate    21  f =      -543.26  |proj g|=        2.6733
At iterate    22  f =      -544.57  |proj g|=        2.4943
At iterate    23  f =      -546.98  |proj g|=        2.1489
At iterate    24  f =      -550.63  |proj g|=        1.7639
At iterate    25  f =      -550.91  |proj g|=        1.2979
At iterate    26  f =      -550.92  |proj g|=        1.3354
At iterate    27  f =      -550.93  |proj g|=         1.381
At iterate    28  f =      -550.93  |proj g|=        1.3728
At iterate    29  f =      -550.94  |proj g|=         1.318
At iterate    30  f =      -550.96  |proj g|=        1.2474
At iterate    31  f =      -551.03  |proj g|=        1.0869
At iterate    32  f =      -551.18  |proj g|=       0.87732
At iterate    33  f =       -551.6  |proj g|=       0.88116
At iterate    34  f =      -551.87  |proj g|=       0.88165
At iterate    35  f =      -552.26  |proj g|=       0.87954
At iterate    36  f =      -553.24  |proj g|=       0.87142
At iterate    37  f =      -554.64  |proj g|=       0.85447
At iterate    38  f =      -555.79  |proj g|=       0.83267
At iterate    39  f =       -556.5  |proj g|=       0.81349
At iterate    40  f =       -557.1  |proj g|=        0.8061
At iterate    41  f =       -557.1  |proj g|=       0.79952
At iterate    42  f =       -557.1  |proj g|=       0.46911
At iterate    43  f =       -557.1  |proj g|=        0.4649
At iterate    44  f =       -557.1  |proj g|=       0.46577
At iterate    45  f =       -557.1  |proj g|=       0.46577

iterations 45
function evaluations 50
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.465769
final function value -557.103

F = -557.103
final  value -557.103498 
converged
 
INFO  [01:35:59.495] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:35:59.921] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:35:59.928] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:36:06.851] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:36:13.529] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:36:19.217] [mlr3]  Finished benchmark 
INFO  [01:36:19.304] [bbotk] Result of batch 117: 
INFO  [01:36:19.306] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:36:19.306] [bbotk]              7.537927                 3.884744                       0.4974358 
INFO  [01:36:19.306] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:36:19.306] [bbotk]                     2367        0.786 -0.9625147         <NA>   0.9778777 
INFO  [01:36:19.306] [bbotk]                                 uhash 
INFO  [01:36:19.306] [bbotk]  5e3ce5e4-8cf6-41b4-bc59-59a59575130d 
DEBUG [01:36:20.553] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.893118e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.893117e-05 0.002376173 
  - best initial criterion value(s) :  501.4284 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -501.43  |proj g|=       10.107
At iterate     1  f =      -505.33  |proj g|=        2.5136
At iterate     2  f =      -506.75  |proj g|=        2.8288
At iterate     3  f =      -520.58  |proj g|=        6.2612
At iterate     4  f =      -520.75  |proj g|=        6.2572
At iterate     5  f =      -520.84  |proj g|=        5.8107
At iterate     6  f =      -520.84  |proj g|=        5.8064
At iterate     7  f =      -520.84  |proj g|=        5.8031
At iterate     8  f =      -520.84  |proj g|=        5.8026
At iterate     9  f =      -520.84  |proj g|=        5.7985
At iterate    10  f =      -520.84  |proj g|=        5.7938
At iterate    11  f =      -520.84  |proj g|=        5.7824
At iterate    12  f =      -520.85  |proj g|=          5.76
At iterate    13  f =      -520.86  |proj g|=        5.7056
At iterate    14  f =      -520.88  |proj g|=        5.6046
At iterate    15  f =      -520.94  |proj g|=        5.4693
At iterate    16  f =      -521.04  |proj g|=        5.1198
At iterate    17  f =      -521.18  |proj g|=        4.8904
At iterate    18  f =      -521.46  |proj g|=        4.6794
At iterate    19  f =      -524.37  |proj g|=        3.5432
At iterate    20  f =      -530.99  |proj g|=        2.4852
At iterate    21  f =      -554.44  |proj g|=       0.95641
At iterate    22  f =      -557.56  |proj g|=       0.63172
At iterate    23  f =      -557.95  |proj g|=        1.0574
At iterate    24  f =      -558.11  |proj g|=       0.81871
At iterate    25  f =      -558.16  |proj g|=        0.8202
At iterate    26  f =      -558.16  |proj g|=       0.81652
At iterate    27  f =      -558.16  |proj g|=       0.81334
At iterate    28  f =      -558.16  |proj g|=       0.81405
At iterate    29  f =      -558.16  |proj g|=       0.81404

iterations 29
function evaluations 39
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.814037
final function value -558.163

F = -558.163
final  value -558.162548 
converged
 
INFO  [01:36:20.557] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:36:20.614] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:36:20.620] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:36:32.049] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:36:41.540] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:36:51.682] [mlr3]  Finished benchmark 
INFO  [01:36:51.780] [bbotk] Result of batch 118: 
INFO  [01:36:51.782] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:36:51.782] [bbotk]              9.320088                 3.924283                         0.27259 
INFO  [01:36:51.782] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:36:51.782] [bbotk]                     3538        0.777 -0.9639836         <NA>   0.9771755 
INFO  [01:36:51.782] [bbotk]                                 uhash 
INFO  [01:36:51.782] [bbotk]  03a18102-1aad-4c08-bf50-8def9b8951fe 
DEBUG [01:36:53.141] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.884483e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.884483e-05 0.002373242 
  - best initial criterion value(s) :  528.1015 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -528.1  |proj g|=       2.4935
At iterate     1  f =      -555.87  |proj g|=        1.5511
At iterate     2  f =      -577.94  |proj g|=        2.6198
At iterate     3  f =      -579.17  |proj g|=        2.6382
At iterate     4  f =      -582.12  |proj g|=        2.6584
At iterate     5  f =      -582.78  |proj g|=         2.701
At iterate     6  f =      -582.98  |proj g|=        2.7245
At iterate     7  f =      -583.02  |proj g|=        2.7885
At iterate     8  f =      -583.03  |proj g|=        2.7759
At iterate     9  f =      -583.03  |proj g|=        2.7772
At iterate    10  f =      -583.03  |proj g|=        2.7773
At iterate    11  f =      -583.03  |proj g|=        2.7783
At iterate    12  f =      -583.03  |proj g|=        2.7794
At iterate    13  f =      -583.03  |proj g|=        2.7814
At iterate    14  f =      -583.03  |proj g|=        2.7846
At iterate    15  f =      -583.03  |proj g|=        2.7878
At iterate    16  f =      -583.03  |proj g|=        2.8045
At iterate    17  f =      -583.04  |proj g|=        2.8063
At iterate    18  f =      -583.14  |proj g|=        2.8429
At iterate    19  f =      -583.31  |proj g|=        2.8355
At iterate    20  f =      -583.96  |proj g|=        2.8006
At iterate    21  f =      -585.38  |proj g|=        2.6282
At iterate    22  f =      -589.19  |proj g|=         1.254
At iterate    23  f =      -591.83  |proj g|=       0.89924
At iterate    24  f =      -593.56  |proj g|=       0.78634
At iterate    25  f =      -593.85  |proj g|=       0.76392
At iterate    26  f =      -593.86  |proj g|=       0.69143
At iterate    27  f =      -593.86  |proj g|=       0.69223
At iterate    28  f =      -593.86  |proj g|=       0.69315
At iterate    29  f =      -593.86  |proj g|=       0.69358
At iterate    30  f =      -593.86  |proj g|=       0.69384
At iterate    31  f =      -593.86  |proj g|=       0.69453
At iterate    32  f =      -593.86  |proj g|=        0.6954
At iterate    33  f =      -593.86  |proj g|=       0.69678
At iterate    34  f =      -593.86  |proj g|=       0.69845
At iterate    35  f =      -593.86  |proj g|=       0.70032
At iterate    36  f =      -593.86  |proj g|=       0.70296
At iterate    37  f =      -593.86  |proj g|=       0.70084
At iterate    38  f =      -593.87  |proj g|=       0.71519
At iterate    39  f =      -593.87  |proj g|=       0.71103
At iterate    40  f =      -593.89  |proj g|=       0.69213
At iterate    41  f =      -593.94  |proj g|=       0.65915
At iterate    42  f =      -594.08  |proj g|=       0.56798
At iterate    43  f =      -594.29  |proj g|=       0.26883
At iterate    44  f =       -594.3  |proj g|=       0.26607
At iterate    45  f =      -594.43  |proj g|=       0.25868
At iterate    46  f =      -594.57  |proj g|=       0.75955
At iterate    47  f =      -594.58  |proj g|=       0.18103
At iterate    48  f =      -594.58  |proj g|=      0.027216
At iterate    49  f =      -594.58  |proj g|=     0.0049765

iterations 49
function evaluations 54
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00497649
final function value -594.577

F = -594.577
final  value -594.577333 
converged
 
INFO  [01:36:53.145] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:36:53.200] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:36:53.206] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:36:59.523] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:37:07.555] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:37:12.837] [mlr3]  Finished benchmark 
INFO  [01:37:12.904] [bbotk] Result of batch 119: 
INFO  [01:37:12.907] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:37:12.907] [bbotk]              2.768529                 5.578161                       0.1230313 
INFO  [01:37:12.907] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:37:12.907] [bbotk]                     2153        0.788 -0.9451316         <NA>   0.9608767 
INFO  [01:37:12.907] [bbotk]                                 uhash 
INFO  [01:37:12.907] [bbotk]  6f4bb692-4a7c-41fa-be69-a1eaeaf57688 
DEBUG [01:37:14.297] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.876631e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.876631e-05 0.0023637 
  - best initial criterion value(s) :  524.232 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -524.23  |proj g|=       5.0651
At iterate     1  f =      -527.66  |proj g|=        11.607
At iterate     2  f =      -565.92  |proj g|=        5.0663
At iterate     3  f =      -566.49  |proj g|=        4.1827
At iterate     4  f =      -567.04  |proj g|=        3.6353
At iterate     5  f =      -568.51  |proj g|=        2.7668
At iterate     6  f =      -569.07  |proj g|=        3.5114
At iterate     7  f =       -569.7  |proj g|=        3.1557
At iterate     8  f =      -569.75  |proj g|=         3.107
At iterate     9  f =      -569.75  |proj g|=        3.1037
At iterate    10  f =      -569.75  |proj g|=        3.1019
At iterate    11  f =      -569.75  |proj g|=        3.1014
At iterate    12  f =      -569.75  |proj g|=        3.0912
At iterate    13  f =      -569.76  |proj g|=         3.083
At iterate    14  f =      -569.79  |proj g|=        3.0593
At iterate    15  f =      -569.94  |proj g|=        3.0089
At iterate    16  f =       -570.3  |proj g|=        2.9508
At iterate    17  f =      -571.24  |proj g|=        2.9301
At iterate    18  f =      -573.12  |proj g|=        3.0863
At iterate    19  f =      -573.52  |proj g|=        3.0453
At iterate    20  f =       -574.8  |proj g|=        3.3684
At iterate    21  f =      -574.92  |proj g|=        3.4533
At iterate    22  f =      -574.94  |proj g|=        3.4914
At iterate    23  f =      -574.94  |proj g|=        3.5026
At iterate    24  f =      -574.94  |proj g|=        3.5051
At iterate    25  f =      -574.94  |proj g|=        3.5049
At iterate    26  f =      -574.94  |proj g|=        3.5049
At iterate    27  f =      -574.94  |proj g|=        3.5046
At iterate    28  f =      -574.94  |proj g|=        3.5043

iterations 28
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.5043
final function value -574.944

F = -574.944
final  value -574.944391 
converged
 
INFO  [01:37:14.301] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:37:14.356] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:37:14.363] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:37:16.332] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:37:18.938] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:37:21.352] [mlr3]  Finished benchmark 
INFO  [01:37:21.420] [bbotk] Result of batch 120: 
INFO  [01:37:21.422] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:37:21.422] [bbotk]              5.655499                 3.715758                       0.2566273 
INFO  [01:37:21.422] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:37:21.422] [bbotk]                      715        0.896 -0.9565957         <NA>   0.9692427 
INFO  [01:37:21.422] [bbotk]                                 uhash 
INFO  [01:37:21.422] [bbotk]  6da17b9a-dd2e-40ec-9d4c-380bd174b7b8 
DEBUG [01:37:23.074] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.864121e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.864121e-05 0.002335771 
  - best initial criterion value(s) :  532.5044 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -532.5  |proj g|=       3.1331
At iterate     1  f =      -568.36  |proj g|=        2.3102
At iterate     2  f =      -588.36  |proj g|=         3.814
At iterate     3  f =      -588.87  |proj g|=        3.7241
At iterate     4  f =      -590.26  |proj g|=        3.3051
At iterate     5  f =       -590.5  |proj g|=        3.1537
At iterate     6  f =      -590.86  |proj g|=        3.2335
At iterate     7  f =      -591.01  |proj g|=        3.3901
At iterate     8  f =      -591.01  |proj g|=        3.3592
At iterate     9  f =      -591.01  |proj g|=        3.3626
At iterate    10  f =      -591.01  |proj g|=        3.3624
At iterate    11  f =      -591.01  |proj g|=        3.3619
At iterate    12  f =      -591.01  |proj g|=        3.3574
At iterate    13  f =      -591.01  |proj g|=        3.3522
At iterate    14  f =      -591.01  |proj g|=        3.3421
At iterate    15  f =      -591.02  |proj g|=        3.3264
At iterate    16  f =      -591.03  |proj g|=        3.2993
At iterate    17  f =      -591.07  |proj g|=        3.2543
At iterate    18  f =      -591.18  |proj g|=        3.1786
At iterate    19  f =      -591.45  |proj g|=        3.0626
At iterate    20  f =      -592.07  |proj g|=        2.9302
At iterate    21  f =      -592.99  |proj g|=        2.9088
At iterate    22  f =      -593.33  |proj g|=        3.0106
At iterate    23  f =      -593.41  |proj g|=        3.0778
At iterate    24  f =      -593.48  |proj g|=        3.1089
At iterate    25  f =      -593.66  |proj g|=        3.1556
At iterate    26  f =      -594.08  |proj g|=        3.1855
At iterate    27  f =      -595.16  |proj g|=        3.1387
At iterate    28  f =      -597.98  |proj g|=        1.9037
At iterate    29  f =      -598.54  |proj g|=        2.3615
At iterate    30  f =       -601.1  |proj g|=        1.6278
At iterate    31  f =       -603.4  |proj g|=       0.91734
At iterate    32  f =      -604.23  |proj g|=       0.82534
At iterate    33  f =      -604.58  |proj g|=        1.0203
At iterate    34  f =      -604.59  |proj g|=       0.90624
At iterate    35  f =       -604.6  |proj g|=       0.95789
At iterate    36  f =       -604.6  |proj g|=       0.95345
At iterate    37  f =       -604.6  |proj g|=        0.9532

iterations 37
function evaluations 43
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.953203
final function value -604.599

F = -604.599
final  value -604.599028 
converged
 
INFO  [01:37:23.078] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:37:23.133] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:37:23.140] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:37:32.005] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:37:39.843] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:37:47.426] [mlr3]  Finished benchmark 
INFO  [01:37:47.497] [bbotk] Result of batch 121: 
INFO  [01:37:47.499] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:37:47.499] [bbotk]              4.710918                 2.085523                      0.03571436 
INFO  [01:37:47.499] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:37:47.499] [bbotk]                     2916        1.105 -0.9457279         <NA>   0.9621504 
INFO  [01:37:47.499] [bbotk]                                 uhash 
INFO  [01:37:47.499] [bbotk]  f31b4c57-b90c-4d60-8b15-4a67bc960812 
DEBUG [01:37:49.068] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.855139e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.855139e-05 0.002323784 
  - best initial criterion value(s) :  486.3942 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -486.39  |proj g|=       6.2129
At iterate     1  f =      -533.52  |proj g|=        10.052
At iterate     2  f =      -564.83  |proj g|=        6.5892
At iterate     3  f =      -573.24  |proj g|=        4.1078
At iterate     4  f =      -574.91  |proj g|=        3.4693
At iterate     5  f =      -584.24  |proj g|=        1.6049
At iterate     6  f =      -594.52  |proj g|=        1.6767
At iterate     7  f =      -599.57  |proj g|=        1.7334
At iterate     8  f =      -602.78  |proj g|=        1.7863
At iterate     9  f =       -605.1  |proj g|=        1.8147
At iterate    10  f =      -605.67  |proj g|=         1.823
At iterate    11  f =      -605.75  |proj g|=         1.823
At iterate    12  f =      -605.75  |proj g|=         1.823
At iterate    13  f =      -605.75  |proj g|=         1.823
At iterate    14  f =      -605.75  |proj g|=         1.823
At iterate    15  f =      -605.75  |proj g|=         1.823
At iterate    16  f =      -605.75  |proj g|=         1.823
At iterate    17  f =      -605.75  |proj g|=         1.823
At iterate    18  f =      -605.76  |proj g|=        1.8229
At iterate    19  f =      -605.76  |proj g|=        1.8228
At iterate    20  f =      -605.76  |proj g|=        1.8226
At iterate    21  f =      -605.78  |proj g|=        1.8221
At iterate    22  f =       -605.8  |proj g|=        1.8211
At iterate    23  f =      -605.82  |proj g|=        1.8206
At iterate    24  f =      -605.83  |proj g|=          1.82
At iterate    25  f =      -605.83  |proj g|=          1.82
At iterate    26  f =      -605.83  |proj g|=        1.8199
At iterate    27  f =      -605.83  |proj g|=        1.8199
At iterate    28  f =      -605.83  |proj g|=        1.8199
At iterate    29  f =      -605.83  |proj g|=        1.8197
At iterate    30  f =      -605.83  |proj g|=        1.8197
At iterate    31  f =      -605.83  |proj g|=        1.8194
At iterate    32  f =       -605.9  |proj g|=        1.7873
At iterate    33  f =      -606.72  |proj g|=        1.3685
At iterate    34  f =      -608.49  |proj g|=       0.30369
At iterate    35  f =      -609.38  |proj g|=       0.29764
At iterate    36  f =      -610.27  |proj g|=       0.25972
At iterate    37  f =      -610.35  |proj g|=       0.74664
At iterate    38  f =      -610.36  |proj g|=       0.24265
At iterate    39  f =      -610.36  |proj g|=       0.14567
At iterate    40  f =      -610.36  |proj g|=     0.0056761
At iterate    41  f =      -610.36  |proj g|=     0.0013645

iterations 41
function evaluations 50
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00136451
final function value -610.362

F = -610.362
final  value -610.362307 
converged
 
INFO  [01:37:49.073] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:37:49.136] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:37:49.143] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:37:55.756] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:38:00.970] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:38:09.882] [mlr3]  Finished benchmark 
INFO  [01:38:09.952] [bbotk] Result of batch 122: 
INFO  [01:38:09.954] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:38:09.954] [bbotk]              3.482589                 7.161135                       0.4761261 
INFO  [01:38:09.954] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:38:09.954] [bbotk]                     1976        0.939 -0.9419144         <NA>   0.9743636 
INFO  [01:38:09.954] [bbotk]                                 uhash 
INFO  [01:38:09.954] [bbotk]  3e6fe760-480c-472f-8918-8411f74bf1ce 
DEBUG [01:38:11.706] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.844641e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.844641e-05 0.002312047 
  - best initial criterion value(s) :  543.2105 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -543.21  |proj g|=       3.1868
At iterate     1  f =      -556.19  |proj g|=        9.5734
At iterate     2  f =       -577.3  |proj g|=         3.887
At iterate     3  f =      -578.18  |proj g|=        4.9765
At iterate     4  f =      -578.18  |proj g|=        4.9693
At iterate     5  f =      -578.18  |proj g|=        4.9673
At iterate     6  f =      -578.18  |proj g|=        4.9654
At iterate     7  f =      -578.18  |proj g|=        4.9622
At iterate     8  f =      -578.18  |proj g|=         4.959
At iterate     9  f =      -578.18  |proj g|=        4.9578
At iterate    10  f =      -578.18  |proj g|=        4.9634
At iterate    11  f =      -578.18  |proj g|=        4.9807
At iterate    12  f =      -578.18  |proj g|=        5.0185
At iterate    13  f =      -578.18  |proj g|=        5.0309
At iterate    14  f =      -578.18  |proj g|=        5.0509
At iterate    15  f =      -578.19  |proj g|=        5.0877
At iterate    16  f =       -578.2  |proj g|=        5.1452
At iterate    17  f =      -578.22  |proj g|=        5.2302
At iterate    18  f =      -578.27  |proj g|=        5.3344
At iterate    19  f =      -578.36  |proj g|=        5.3963
At iterate    20  f =      -578.38  |proj g|=        5.4833
At iterate    21  f =      -578.56  |proj g|=        5.4697
At iterate    22  f =      -584.84  |proj g|=        3.0548
At iterate    23  f =      -585.32  |proj g|=        3.2136
At iterate    24  f =      -585.42  |proj g|=        3.3193
At iterate    25  f =      -585.42  |proj g|=         3.327
At iterate    26  f =      -585.42  |proj g|=        3.3245
At iterate    27  f =      -585.42  |proj g|=        3.3313
At iterate    28  f =      -585.42  |proj g|=        3.3327
At iterate    29  f =      -585.43  |proj g|=         3.342
At iterate    30  f =      -585.45  |proj g|=        3.3538
At iterate    31  f =      -585.48  |proj g|=        3.3747
At iterate    32  f =      -585.48  |proj g|=        3.3775
At iterate    33  f =      -585.58  |proj g|=        3.4077
At iterate    34  f =      -585.79  |proj g|=        3.4486
At iterate    35  f =      -586.22  |proj g|=        3.4957
At iterate    36  f =      -586.91  |proj g|=        3.5156
At iterate    37  f =      -587.62  |proj g|=        3.4741
At iterate    38  f =      -587.64  |proj g|=        3.5372
At iterate    39  f =      -588.18  |proj g|=        3.4116
At iterate    40  f =      -588.45  |proj g|=        3.3004
At iterate    41  f =      -588.56  |proj g|=        3.2302
At iterate    42  f =      -588.59  |proj g|=        3.2117
At iterate    43  f =      -588.59  |proj g|=        3.2156
At iterate    44  f =       -588.6  |proj g|=        3.2166
At iterate    45  f =       -588.6  |proj g|=        3.2202
At iterate    46  f =       -588.6  |proj g|=        3.2208
At iterate    47  f =       -588.6  |proj g|=        3.2212
At iterate    48  f =       -588.6  |proj g|=        3.2218
At iterate    49  f =       -588.6  |proj g|=        3.2224
At iterate    50  f =       -588.6  |proj g|=        3.2235
At iterate    51  f =       -588.6  |proj g|=        3.2274
At iterate    52  f =      -588.61  |proj g|=         3.233
At iterate    53  f =      -588.62  |proj g|=        3.2409
At iterate    54  f =      -588.65  |proj g|=        3.2567
At iterate    55  f =      -588.65  |proj g|=        3.2393
At iterate    56  f =      -588.69  |proj g|=        3.2423
At iterate    57  f =      -588.75  |proj g|=        3.2117
At iterate    58  f =      -588.78  |proj g|=        3.1715
At iterate    59  f =      -588.78  |proj g|=        3.1628
At iterate    60  f =      -588.78  |proj g|=        3.1613
At iterate    61  f =      -588.78  |proj g|=        3.1594
At iterate    62  f =      -588.78  |proj g|=        3.1593
At iterate    63  f =      -588.78  |proj g|=        3.1555
At iterate    64  f =      -588.79  |proj g|=        3.1517
At iterate    65  f =      -588.79  |proj g|=         3.134
At iterate    66  f =       -588.8  |proj g|=        3.1498
At iterate    67  f =       -588.8  |proj g|=        3.1472
At iterate    68  f =      -588.81  |proj g|=        3.1568
At iterate    69  f =      -588.81  |proj g|=        3.1605
At iterate    70  f =      -588.83  |proj g|=        3.1406
At iterate    71  f =      -588.86  |proj g|=         3.159
At iterate    72  f =      -589.09  |proj g|=        3.2241
At iterate    73  f =      -589.49  |proj g|=        3.3006
At iterate    74  f =      -590.24  |proj g|=        3.2627
At iterate    75  f =      -593.16  |proj g|=        2.8658
At iterate    76  f =      -597.47  |proj g|=        1.0691
At iterate    77  f =      -599.63  |proj g|=       0.81466
At iterate    78  f =      -600.92  |proj g|=        0.8119
At iterate    79  f =      -601.11  |proj g|=       0.23795
At iterate    80  f =      -601.45  |proj g|=       0.77659
At iterate    81  f =      -601.49  |proj g|=       0.78553
At iterate    82  f =       -601.5  |proj g|=       0.78261
At iterate    83  f =       -601.5  |proj g|=       0.78307
At iterate    84  f =       -601.5  |proj g|=       0.78291
At iterate    85  f =      -601.51  |proj g|=       0.78406
At iterate    86  f =      -601.52  |proj g|=       0.78368
At iterate    87  f =      -601.54  |proj g|=       0.78132
At iterate    88  f =      -601.54  |proj g|=      0.066943
At iterate    89  f =      -601.54  |proj g|=      0.013355
At iterate    90  f =      -601.54  |proj g|=      0.013355

iterations 90
function evaluations 109
segments explored during Cauchy searches 93
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0133548
final function value -601.537

F = -601.537
final  value -601.537277 
converged
 
INFO  [01:38:11.710] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:38:11.767] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:38:11.774] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:38:19.094] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:38:26.535] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:38:33.181] [mlr3]  Finished benchmark 
INFO  [01:38:33.296] [bbotk] Result of batch 123: 
INFO  [01:38:33.298] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:38:33.298] [bbotk]              3.177685                 9.462254                       0.4206763 
INFO  [01:38:33.298] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:38:33.298] [bbotk]                     2485        0.784 -0.9542468         <NA>   0.9738255 
INFO  [01:38:33.298] [bbotk]                                 uhash 
INFO  [01:38:33.298] [bbotk]  eafb5f2d-3dd4-4cd8-9b49-ce86623f5a9e 
DEBUG [01:38:34.606] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.833922e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.833922e-05 0.002316617 
  - best initial criterion value(s) :  537.7849 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -537.78  |proj g|=       3.7367
At iterate     1  f =      -540.67  |proj g|=        4.7016
At iterate     2  f =      -544.09  |proj g|=         4.635
At iterate     3  f =      -547.27  |proj g|=        4.3239
At iterate     4  f =      -548.27  |proj g|=        4.0145
At iterate     5  f =      -550.43  |proj g|=        3.7838
At iterate     6  f =      -554.89  |proj g|=        3.2969
At iterate     7  f =      -555.14  |proj g|=        3.1757
At iterate     8  f =      -555.14  |proj g|=        3.1682
At iterate     9  f =      -555.15  |proj g|=        3.1613
At iterate    10  f =      -555.15  |proj g|=        3.1644
At iterate    11  f =      -555.15  |proj g|=        3.1641
At iterate    12  f =      -555.15  |proj g|=        3.1633
At iterate    13  f =      -555.15  |proj g|=        3.1614
At iterate    14  f =      -555.15  |proj g|=        3.1586
At iterate    15  f =      -555.15  |proj g|=        3.1537
At iterate    16  f =      -555.15  |proj g|=        3.1524
At iterate    17  f =      -555.15  |proj g|=        3.1456
At iterate    18  f =      -555.16  |proj g|=        3.1322
At iterate    19  f =      -555.19  |proj g|=        3.0996
At iterate    20  f =      -555.37  |proj g|=        3.0099
At iterate    21  f =      -555.92  |proj g|=        2.7862
At iterate    22  f =      -556.12  |proj g|=        2.7345
At iterate    23  f =      -557.47  |proj g|=        2.3903
At iterate    24  f =      -562.18  |proj g|=         1.624
At iterate    25  f =      -566.06  |proj g|=       0.97047
At iterate    26  f =      -567.49  |proj g|=        1.0441
At iterate    27  f =      -568.23  |proj g|=        1.2522
At iterate    28  f =      -568.29  |proj g|=        1.2388
At iterate    29  f =      -568.31  |proj g|=        1.4508
At iterate    30  f =      -568.33  |proj g|=        1.3688
At iterate    31  f =      -568.33  |proj g|=        1.3598
At iterate    32  f =      -568.33  |proj g|=        1.3604

iterations 32
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.36044
final function value -568.333

F = -568.333
final  value -568.332716 
converged
 
INFO  [01:38:34.611] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:38:34.667] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:38:34.674] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:38:36.095] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:38:37.414] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:38:38.521] [mlr3]  Finished benchmark 
INFO  [01:38:38.592] [bbotk] Result of batch 124: 
INFO  [01:38:38.594] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:38:38.594] [bbotk]              4.656108                 2.409589                       0.3429239 
INFO  [01:38:38.594] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:38:38.594] [bbotk]                      321        0.805 -0.9674837         <NA>   0.9625643 
INFO  [01:38:38.594] [bbotk]                                 uhash 
INFO  [01:38:38.594] [bbotk]  0151dcdf-bc13-4cef-bc54-ad7ad5479e2b 
DEBUG [01:38:39.867] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.824955e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.824955e-05 0.00228496 
  - best initial criterion value(s) :  513.5745 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -513.57  |proj g|=       2.1937
At iterate     1  f =      -516.54  |proj g|=        2.1759
At iterate     2  f =      -517.71  |proj g|=        2.0991
At iterate     3  f =       -518.1  |proj g|=        2.0453
At iterate     4  f =      -518.12  |proj g|=        2.0488
At iterate     5  f =      -518.12  |proj g|=        2.0479
At iterate     6  f =      -518.12  |proj g|=        2.0476
At iterate     7  f =      -518.12  |proj g|=        2.0476

iterations 7
function evaluations 11
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.04764
final function value -518.121

F = -518.121
final  value -518.120952 
converged
 
INFO  [01:38:39.871] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:38:39.928] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:38:39.935] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:38:47.919] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:38:55.140] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:39:04.271] [mlr3]  Finished benchmark 
INFO  [01:39:04.343] [bbotk] Result of batch 125: 
INFO  [01:39:04.344] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:39:04.344] [bbotk]                4.4944                 7.743315                       0.1156186 
INFO  [01:39:04.344] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:39:04.344] [bbotk]                     2884        0.962 -0.9751231         <NA>    0.971922 
INFO  [01:39:04.344] [bbotk]                                 uhash 
INFO  [01:39:04.344] [bbotk]  9826b22d-3dc0-4ec1-9fb1-5544d9913ddd 
DEBUG [01:39:05.619] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.813631e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.813631e-05 0.002287389 
  - best initial criterion value(s) :  565.5544 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -565.55  |proj g|=       1.4664
At iterate     1  f =      -565.84  |proj g|=        1.7418
At iterate     2  f =      -565.84  |proj g|=        1.7246
At iterate     3  f =      -565.84  |proj g|=        1.7115
At iterate     4  f =      -565.85  |proj g|=        1.6864
At iterate     5  f =      -565.87  |proj g|=        1.6446
At iterate     6  f =       -565.9  |proj g|=        1.5852
At iterate     7  f =      -565.94  |proj g|=        1.5398
At iterate     8  f =      -565.96  |proj g|=        1.6012
At iterate     9  f =      -565.96  |proj g|=        1.5791
At iterate    10  f =      -565.96  |proj g|=        1.5795
At iterate    11  f =      -565.96  |proj g|=        1.5803
At iterate    12  f =      -565.96  |proj g|=        1.5811
At iterate    13  f =      -565.96  |proj g|=        1.5827
At iterate    14  f =      -565.96  |proj g|=        1.5923
At iterate    15  f =      -565.96  |proj g|=        1.5828
At iterate    16  f =      -565.96  |proj g|=        1.5885
At iterate    17  f =      -565.99  |proj g|=        1.6306
At iterate    18  f =      -566.05  |proj g|=         1.669
At iterate    19  f =      -566.22  |proj g|=        1.7104
At iterate    20  f =      -566.59  |proj g|=        1.7043
At iterate    21  f =      -567.34  |proj g|=         1.547
At iterate    22  f =      -568.04  |proj g|=        1.4425
At iterate    23  f =      -568.77  |proj g|=        1.1667
At iterate    24  f =      -569.23  |proj g|=       0.90812
At iterate    25  f =      -569.58  |proj g|=       0.75248
At iterate    26  f =      -569.68  |proj g|=       0.83441
At iterate    27  f =      -569.68  |proj g|=       0.83812
At iterate    28  f =      -569.68  |proj g|=       0.83451
At iterate    29  f =      -569.68  |proj g|=       0.83487

iterations 29
function evaluations 34
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.834871
final function value -569.68

F = -569.68
final  value -569.680155 
converged
 
INFO  [01:39:05.623] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:39:05.718] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:39:05.726] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:39:16.320] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:39:29.463] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:39:41.610] [mlr3]  Finished benchmark 
INFO  [01:39:41.684] [bbotk] Result of batch 126: 
INFO  [01:39:41.686] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:39:41.686] [bbotk]              8.130864                 7.499709                      0.06205979 
INFO  [01:39:41.686] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:39:41.686] [bbotk]                     4040          0.8 -0.9690584         <NA>   0.9725224 
INFO  [01:39:41.686] [bbotk]                                 uhash 
INFO  [01:39:41.686] [bbotk]  c2d5c1c0-d564-433f-a522-0ec5533f9f4e 
DEBUG [01:39:43.018] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.80267e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.80267e-05 0.002280268 
  - best initial criterion value(s) :  530.0436 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -530.04  |proj g|=       10.907
At iterate     1  f =      -565.13  |proj g|=        4.5176
At iterate     2  f =      -589.61  |proj g|=        6.2597
At iterate     3  f =      -592.05  |proj g|=        5.7459
At iterate     4  f =      -596.34  |proj g|=        5.5289
At iterate     5  f =      -597.49  |proj g|=        5.0461
At iterate     6  f =      -598.05  |proj g|=        4.7625
At iterate     7  f =      -598.14  |proj g|=        5.0734
At iterate     8  f =      -598.24  |proj g|=        4.8022
At iterate     9  f =      -598.25  |proj g|=        4.7622
At iterate    10  f =      -598.25  |proj g|=        4.7598
At iterate    11  f =      -598.25  |proj g|=        4.7621
At iterate    12  f =      -598.26  |proj g|=        4.7653
At iterate    13  f =      -598.27  |proj g|=        4.7376
At iterate    14  f =      -598.28  |proj g|=        4.8817
At iterate    15  f =      -598.32  |proj g|=        4.7738
At iterate    16  f =      -598.47  |proj g|=        4.4853
At iterate    17  f =      -598.76  |proj g|=        4.1302
At iterate    18  f =      -599.66  |proj g|=        3.5839
At iterate    19  f =      -602.58  |proj g|=        3.5617
At iterate    20  f =      -603.56  |proj g|=        3.3542
At iterate    21  f =      -614.97  |proj g|=        3.1994
At iterate    22  f =      -625.99  |proj g|=        3.3479
At iterate    23  f =      -626.93  |proj g|=        3.2711
At iterate    24  f =      -627.11  |proj g|=        3.2075
At iterate    25  f =      -627.12  |proj g|=        3.2422
At iterate    26  f =      -627.12  |proj g|=        3.2346
At iterate    27  f =      -627.12  |proj g|=        3.2344

iterations 27
function evaluations 33
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 3.23436
final function value -627.123

F = -627.123
final  value -627.123045 
converged
 
INFO  [01:39:43.022] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:39:43.220] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:39:43.227] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:39:55.789] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:40:07.132] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:40:16.239] [mlr3]  Finished benchmark 
INFO  [01:40:16.311] [bbotk] Result of batch 127: 
INFO  [01:40:16.313] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:40:16.313] [bbotk]              7.403329                 5.855512                       0.3303794 
INFO  [01:40:16.313] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:40:16.313] [bbotk]                     4386        0.822 -0.9444774         <NA>   0.9783167 
INFO  [01:40:16.313] [bbotk]                                 uhash 
INFO  [01:40:16.313] [bbotk]  0dfc4d2b-30a1-42ce-8b81-db6d306d4eed 
DEBUG [01:40:18.014] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.796322e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.796322e-05 0.002267952 
  - best initial criterion value(s) :  594.7459 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -594.75  |proj g|=       4.2561
At iterate     1  f =      -601.29  |proj g|=          8.31
At iterate     2  f =      -603.39  |proj g|=        7.9972
At iterate     3  f =      -605.72  |proj g|=        6.7732
At iterate     4  f =       -606.3  |proj g|=        6.2218
At iterate     5  f =      -608.03  |proj g|=        4.9362
At iterate     6  f =      -608.28  |proj g|=        4.8606
At iterate     7  f =       -608.3  |proj g|=        4.8548
At iterate     8  f =       -608.3  |proj g|=        4.8454
At iterate     9  f =       -608.3  |proj g|=        4.8417
At iterate    10  f =       -608.3  |proj g|=        4.8119
At iterate    11  f =      -608.31  |proj g|=        4.7759
At iterate    12  f =      -608.32  |proj g|=        4.7062
At iterate    13  f =      -608.36  |proj g|=        4.5703
At iterate    14  f =      -608.45  |proj g|=        4.4117
At iterate    15  f =      -608.51  |proj g|=        4.1504
At iterate    16  f =      -608.75  |proj g|=        4.0081
At iterate    17  f =       -611.1  |proj g|=        3.0536
At iterate    18  f =      -615.44  |proj g|=        2.2244
At iterate    19  f =      -628.69  |proj g|=       0.86123
At iterate    20  f =      -633.06  |proj g|=       0.84412
At iterate    21  f =      -633.68  |proj g|=       0.83931
At iterate    22  f =      -635.74  |proj g|=       0.81902
At iterate    23  f =      -637.25  |proj g|=       0.78631
At iterate    24  f =       -637.4  |proj g|=       0.77412
At iterate    25  f =      -637.42  |proj g|=       0.60045
At iterate    26  f =      -637.43  |proj g|=       0.62138
At iterate    27  f =      -637.43  |proj g|=       0.63308
At iterate    28  f =      -637.43  |proj g|=       0.63275
At iterate    29  f =      -637.43  |proj g|=       0.63277

iterations 29
function evaluations 35
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.632766
final function value -637.426

F = -637.426
final  value -637.426396 
converged
 
INFO  [01:40:18.019] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:40:18.222] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:40:18.232] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:40:20.880] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:40:23.307] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:40:25.836] [mlr3]  Finished benchmark 
INFO  [01:40:25.909] [bbotk] Result of batch 128: 
INFO  [01:40:25.911] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:40:25.911] [bbotk]              6.136816                 2.385351                      0.08178742 
INFO  [01:40:25.911] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:40:25.911] [bbotk]                     1194        1.119 -0.9486726         <NA>   0.9632213 
INFO  [01:40:25.911] [bbotk]                                 uhash 
INFO  [01:40:25.911] [bbotk]  455a9883-5edc-4128-8138-9f52e3a8b4c9 
DEBUG [01:40:27.417] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.787329e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.787329e-05 0.002248108 
  - best initial criterion value(s) :  567.1965 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -567.2  |proj g|=       2.2895
At iterate     1  f =      -604.79  |proj g|=       0.61952
At iterate     2  f =      -624.16  |proj g|=        4.0729
At iterate     3  f =      -624.75  |proj g|=        3.9394
At iterate     4  f =      -626.06  |proj g|=        3.1485
At iterate     5  f =      -626.06  |proj g|=        3.1652
At iterate     6  f =      -626.06  |proj g|=         3.168
At iterate     7  f =      -626.06  |proj g|=        3.1455
At iterate     8  f =      -626.06  |proj g|=        3.1421
At iterate     9  f =      -626.06  |proj g|=        3.1419

iterations 9
function evaluations 12
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.14195
final function value -626.061

F = -626.061
final  value -626.060834 
converged
 
INFO  [01:40:27.421] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:40:27.867] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:40:27.874] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:40:30.266] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:40:32.717] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:40:35.362] [mlr3]  Finished benchmark 
INFO  [01:40:35.495] [bbotk] Result of batch 129: 
INFO  [01:40:35.497] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:40:35.497] [bbotk]              3.583337                 5.237205                       0.2706909 
INFO  [01:40:35.497] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:40:35.497] [bbotk]                     1203        1.114 -0.9584944         <NA>   0.9696174 
INFO  [01:40:35.497] [bbotk]                                 uhash 
INFO  [01:40:35.497] [bbotk]  dc68e8ca-4a95-4130-bfae-28f474f5ee75 
DEBUG [01:40:36.873] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.776093e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.776093e-05 0.002222753 
  - best initial criterion value(s) :  583.924 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -583.92  |proj g|=        12.64
At iterate     1  f =      -592.45  |proj g|=        7.6192
At iterate     2  f =      -602.03  |proj g|=        6.6756
At iterate     3  f =      -605.17  |proj g|=        5.5147
At iterate     4  f =      -607.23  |proj g|=         4.714
At iterate     5  f =      -608.25  |proj g|=        4.4082
At iterate     6  f =      -608.86  |proj g|=        4.3441
At iterate     7  f =      -609.03  |proj g|=        5.2038
At iterate     8  f =      -609.24  |proj g|=        4.4865
At iterate     9  f =      -609.24  |proj g|=        4.5027
At iterate    10  f =      -609.24  |proj g|=        4.5046
At iterate    11  f =      -609.24  |proj g|=        4.5047
At iterate    12  f =      -609.24  |proj g|=         4.505
At iterate    13  f =      -609.24  |proj g|=        4.5044
At iterate    14  f =      -609.25  |proj g|=        4.4971
At iterate    15  f =      -609.26  |proj g|=         4.477
At iterate    16  f =      -609.29  |proj g|=        4.4107
At iterate    17  f =      -609.36  |proj g|=        4.3629
At iterate    18  f =      -609.52  |proj g|=        4.0595
At iterate    19  f =      -609.55  |proj g|=        4.3247
At iterate    20  f =      -609.86  |proj g|=        3.8759
At iterate    21  f =      -610.59  |proj g|=           3.7
At iterate    22  f =      -612.77  |proj g|=        3.5973
At iterate    23  f =      -622.92  |proj g|=        3.5574
At iterate    24  f =      -628.83  |proj g|=        3.9402
At iterate    25  f =       -636.3  |proj g|=        3.5532
At iterate    26  f =      -637.09  |proj g|=        2.9933
At iterate    27  f =      -638.78  |proj g|=        3.3512
At iterate    28  f =      -638.81  |proj g|=        3.3468
At iterate    29  f =      -638.81  |proj g|=        3.3354
At iterate    30  f =      -638.81  |proj g|=        3.3309
At iterate    31  f =      -638.81  |proj g|=         3.331

iterations 31
function evaluations 40
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 3.33099
final function value -638.809

F = -638.809
final  value -638.808891 
converged
 
INFO  [01:40:36.875] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:40:36.919] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:40:36.926] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:40:40.823] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:40:44.695] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:40:48.345] [mlr3]  Finished benchmark 
INFO  [01:40:48.447] [bbotk] Result of batch 130: 
INFO  [01:40:48.449] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:40:48.449] [bbotk]              4.858438                 9.571842                       0.3823265 
INFO  [01:40:48.449] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:40:48.449] [bbotk]                     1936        0.812 -0.9486497         <NA>   0.9759785 
INFO  [01:40:48.449] [bbotk]                                 uhash 
INFO  [01:40:48.449] [bbotk]  1705d23c-6679-42dd-b476-f915ae646865 
DEBUG [01:40:50.114] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.767737e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.767737e-05 0.002225353 
  - best initial criterion value(s) :  576.7773 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -576.78  |proj g|=       5.1649
At iterate     1  f =      -616.89  |proj g|=         4.065
At iterate     2  f =      -619.52  |proj g|=        3.5693
At iterate     3  f =      -622.53  |proj g|=        3.2734
At iterate     4  f =      -622.76  |proj g|=        3.1068
At iterate     5  f =      -622.85  |proj g|=        3.1634
At iterate     6  f =      -622.91  |proj g|=        3.1696
At iterate     7  f =       -623.3  |proj g|=        3.1452
At iterate     8  f =      -623.37  |proj g|=        3.0892
At iterate     9  f =      -623.38  |proj g|=        3.0835
At iterate    10  f =      -623.38  |proj g|=         3.084
At iterate    11  f =      -623.38  |proj g|=        3.0839
At iterate    12  f =      -623.38  |proj g|=        3.0834
At iterate    13  f =      -623.39  |proj g|=         3.083
At iterate    14  f =      -623.42  |proj g|=        3.0835
At iterate    15  f =      -623.49  |proj g|=        3.0949
At iterate    16  f =      -623.55  |proj g|=        3.0591
At iterate    17  f =      -623.76  |proj g|=        3.0969
At iterate    18  f =      -624.47  |proj g|=        3.2049
At iterate    19  f =      -625.72  |proj g|=        3.4012
At iterate    20  f =      -626.59  |proj g|=        3.5955
At iterate    21  f =      -626.67  |proj g|=         3.579
At iterate    22  f =      -626.67  |proj g|=        3.5744
At iterate    23  f =      -626.68  |proj g|=         3.548
At iterate    24  f =      -626.68  |proj g|=        3.5422
At iterate    25  f =      -626.68  |proj g|=        3.5419
At iterate    26  f =      -626.68  |proj g|=        3.5411
At iterate    27  f =      -626.68  |proj g|=          3.54
At iterate    28  f =      -626.68  |proj g|=        3.5387
At iterate    29  f =      -626.68  |proj g|=        3.5362
At iterate    30  f =      -626.68  |proj g|=        3.5363
At iterate    31  f =      -626.68  |proj g|=        3.5327
At iterate    32  f =      -626.78  |proj g|=        3.4852
At iterate    33  f =      -627.22  |proj g|=        3.3505
At iterate    34  f =      -627.24  |proj g|=        3.3756
At iterate    35  f =      -628.64  |proj g|=        3.0119
At iterate    36  f =      -631.92  |proj g|=        2.3356
At iterate    37  f =      -637.01  |proj g|=        2.1437
At iterate    38  f =      -637.07  |proj g|=        2.0008
At iterate    39  f =       -639.4  |proj g|=        1.1762
At iterate    40  f =      -639.48  |proj g|=         1.317
At iterate    41  f =       -641.3  |proj g|=       0.78931
At iterate    42  f =      -641.58  |proj g|=       0.21435
At iterate    43  f =      -641.61  |proj g|=       0.21773
At iterate    44  f =      -641.61  |proj g|=       0.21926
At iterate    45  f =      -641.62  |proj g|=       0.21942
At iterate    46  f =      -641.62  |proj g|=       0.07344
At iterate    47  f =      -641.62  |proj g|=      0.052952

iterations 47
function evaluations 63
segments explored during Cauchy searches 49
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.052952
final function value -641.615

F = -641.615
final  value -641.615183 
converged
 
INFO  [01:40:50.118] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:40:50.171] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:40:50.178] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:40:51.843] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:40:53.600] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:40:55.383] [mlr3]  Finished benchmark 
INFO  [01:40:55.450] [bbotk] Result of batch 131: 
INFO  [01:40:55.451] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:40:55.451] [bbotk]              4.205219                 3.663271                       0.3907521 
INFO  [01:40:55.451] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:40:55.451] [bbotk]                      771        0.881 -0.9535796         <NA>   0.9707951 
INFO  [01:40:55.451] [bbotk]                                 uhash 
INFO  [01:40:55.451] [bbotk]  99c92eed-7d7a-436e-9c38-1004a96d2dc1 
DEBUG [01:40:57.048] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.756882e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.756882e-05 0.002188456 
  - best initial criterion value(s) :  568.7436 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -568.74  |proj g|=       1.7737
At iterate     1  f =      -607.91  |proj g|=        11.799
At iterate     2  f =      -612.22  |proj g|=        11.729
At iterate     3  f =      -617.47  |proj g|=        8.2616
At iterate     4  f =      -619.78  |proj g|=        10.836
At iterate     5  f =      -620.37  |proj g|=        10.519
At iterate     6  f =      -624.46  |proj g|=          8.45
At iterate     7  f =       -627.2  |proj g|=        7.6353
At iterate     8  f =       -629.2  |proj g|=        7.3942
At iterate     9  f =      -630.19  |proj g|=        7.2154
At iterate    10  f =      -630.71  |proj g|=        7.4296
At iterate    11  f =      -630.87  |proj g|=        7.0884
At iterate    12  f =      -630.89  |proj g|=        7.3337
At iterate    13  f =      -630.91  |proj g|=        7.2063
At iterate    14  f =      -631.08  |proj g|=        7.0745
At iterate    15  f =      -632.43  |proj g|=        6.3558
At iterate    16  f =      -634.08  |proj g|=        5.7544
At iterate    17  f =      -636.05  |proj g|=        4.8357
At iterate    18  f =      -652.57  |proj g|=        2.6886
At iterate    19  f =      -655.55  |proj g|=        1.1281
At iterate    20  f =      -659.21  |proj g|=       0.80553
At iterate    21  f =      -662.37  |proj g|=       0.73428
At iterate    22  f =      -662.94  |proj g|=       0.24681
At iterate    23  f =      -662.96  |proj g|=       0.73949
At iterate    24  f =      -662.96  |proj g|=        0.2886
At iterate    25  f =      -662.96  |proj g|=       0.14613
At iterate    26  f =      -662.96  |proj g|=       0.12865
At iterate    27  f =      -662.96  |proj g|=       0.12865
At iterate    28  f =      -662.96  |proj g|=       0.15952
At iterate    29  f =      -662.96  |proj g|=       0.25364
At iterate    30  f =      -662.96  |proj g|=       0.25376
At iterate    31  f =      -662.96  |proj g|=       0.25404
At iterate    32  f =      -662.96  |proj g|=       0.25457
At iterate    33  f =      -662.97  |proj g|=       0.25553
At iterate    34  f =      -662.97  |proj g|=       0.25674
At iterate    35  f =      -662.98  |proj g|=       0.25928
At iterate    36  f =      -662.98  |proj g|=       0.26292
At iterate    37  f =         -663  |proj g|=       0.26325
At iterate    38  f =      -663.07  |proj g|=       0.26393
At iterate    39  f =       -663.2  |proj g|=      0.063415
At iterate    40  f =      -663.25  |proj g|=        0.7372
At iterate    41  f =      -663.28  |proj g|=       0.25548
At iterate    42  f =      -663.28  |proj g|=       0.11397
At iterate    43  f =      -663.28  |proj g|=      0.010788
At iterate    44  f =      -663.28  |proj g|=     0.0013243

iterations 44
function evaluations 51
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00132431
final function value -663.281

F = -663.281
final  value -663.281394 
converged
 
INFO  [01:40:57.052] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:40:57.107] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:40:57.113] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:41:02.901] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:41:08.686] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:41:14.370] [mlr3]  Finished benchmark 
INFO  [01:41:14.441] [bbotk] Result of batch 132: 
INFO  [01:41:14.443] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:41:14.443] [bbotk]              8.905257                 3.980334                       0.4218809 
INFO  [01:41:14.443] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:41:14.443] [bbotk]                     2973        0.975 -0.9391873         <NA>   0.9780842 
INFO  [01:41:14.443] [bbotk]                                 uhash 
INFO  [01:41:14.443] [bbotk]  aed6cacd-2054-45bc-ad39-5521d3107a70 
DEBUG [01:41:15.730] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.750684e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.750684e-05 0.002184303 
  - best initial criterion value(s) :  552.6691 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -552.67  |proj g|=       14.078
At iterate     1  f =      -565.47  |proj g|=        9.4236
At iterate     2  f =      -604.93  |proj g|=        3.6776
At iterate     3  f =      -605.56  |proj g|=         4.117
At iterate     4  f =      -607.48  |proj g|=        3.0399
At iterate     5  f =      -608.36  |proj g|=        1.9095
At iterate     6  f =      -608.36  |proj g|=        1.8923
At iterate     7  f =      -608.36  |proj g|=        1.8905
At iterate     8  f =      -608.36  |proj g|=        1.8885
At iterate     9  f =      -608.36  |proj g|=        1.8815
At iterate    10  f =      -608.36  |proj g|=        1.8845
At iterate    11  f =      -608.36  |proj g|=        1.8764
At iterate    12  f =      -608.37  |proj g|=        1.8445
At iterate    13  f =      -608.39  |proj g|=        1.7951
At iterate    14  f =      -608.44  |proj g|=        1.7136
At iterate    15  f =      -608.58  |proj g|=        1.5251
At iterate    16  f =      -608.62  |proj g|=        1.6306
At iterate    17  f =      -608.97  |proj g|=        1.3145
At iterate    18  f =      -610.83  |proj g|=       0.86121
At iterate    19  f =       -614.3  |proj g|=       0.83245
At iterate    20  f =      -615.42  |proj g|=       0.80901
At iterate    21  f =      -615.82  |proj g|=       0.79187
At iterate    22  f =      -615.83  |proj g|=       0.79156
At iterate    23  f =      -615.92  |proj g|=       0.78184
At iterate    24  f =      -615.93  |proj g|=       0.21569
At iterate    25  f =      -615.93  |proj g|=       0.18424
At iterate    26  f =      -615.93  |proj g|=       0.10627
At iterate    27  f =      -615.93  |proj g|=       0.10628

iterations 27
function evaluations 33
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.106283
final function value -615.933

F = -615.933
final  value -615.933342 
converged
 
INFO  [01:41:15.735] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:41:15.813] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:41:15.820] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:41:18.326] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:41:21.290] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:41:24.510] [mlr3]  Finished benchmark 
INFO  [01:41:24.578] [bbotk] Result of batch 133: 
INFO  [01:41:24.579] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:41:24.579] [bbotk]              7.254321                 2.052663                      0.02562556 
INFO  [01:41:24.579] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [01:41:24.579] [bbotk]                     1038        0.815 -0.964914         <NA>   0.9459043 
INFO  [01:41:24.579] [bbotk]                                 uhash 
INFO  [01:41:24.579] [bbotk]  2326d985-61bc-45e5-ab37-49d82b5a8481 
DEBUG [01:41:25.750] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.773704e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.773704e-05 0.002205962 
  - best initial criterion value(s) :  605.9007 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -605.9  |proj g|=       3.8183
At iterate     1  f =      -634.07  |proj g|=         1.974
At iterate     2  f =      -641.56  |proj g|=        3.3555
At iterate     3  f =      -641.93  |proj g|=        3.2018
At iterate     4  f =      -642.13  |proj g|=         2.986
At iterate     5  f =      -642.13  |proj g|=        2.9724
At iterate     6  f =      -642.14  |proj g|=        2.9798
At iterate     7  f =      -642.14  |proj g|=        2.9966
At iterate     8  f =      -642.14  |proj g|=        3.0042
At iterate     9  f =      -642.14  |proj g|=        3.0044

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.0044
final function value -642.136

F = -642.136
final  value -642.135784 
converged
 
INFO  [01:41:25.754] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:41:25.810] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:41:25.817] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:41:33.537] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:41:42.207] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:41:51.021] [mlr3]  Finished benchmark 
INFO  [01:41:51.089] [bbotk] Result of batch 134: 
INFO  [01:41:51.091] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:41:51.091] [bbotk]              8.454522                 6.407805                       0.4425737 
INFO  [01:41:51.091] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:41:51.091] [bbotk]                     2746        0.832 -0.9592192         <NA>   0.9779005 
INFO  [01:41:51.091] [bbotk]                                 uhash 
INFO  [01:41:51.091] [bbotk]  8fd4f93c-a1b9-470a-a664-682dd3d5f264 
DEBUG [01:41:52.689] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.767381e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.767381e-05 0.002213699 
  - best initial criterion value(s) :  609.9617 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -609.96  |proj g|=       3.2257
At iterate     1  f =      -617.33  |proj g|=        4.7803
At iterate     2  f =      -625.55  |proj g|=        4.2474
At iterate     3  f =      -638.19  |proj g|=        2.4869
At iterate     4  f =      -638.93  |proj g|=        2.3186
At iterate     5  f =      -639.97  |proj g|=        2.3935
At iterate     6  f =      -644.14  |proj g|=        2.5808
At iterate     7  f =      -651.46  |proj g|=        2.9034
At iterate     8  f =       -655.9  |proj g|=        3.1813
At iterate     9  f =      -656.66  |proj g|=        3.3649
At iterate    10  f =      -656.67  |proj g|=        3.4535
At iterate    11  f =      -656.75  |proj g|=        3.4862
At iterate    12  f =      -656.75  |proj g|=        3.4971
At iterate    13  f =      -656.81  |proj g|=        3.5363
At iterate    14  f =      -656.97  |proj g|=        3.5564
At iterate    15  f =      -657.28  |proj g|=        3.5051
At iterate    16  f =      -657.41  |proj g|=        3.3127
At iterate    17  f =      -657.59  |proj g|=        3.2646
At iterate    18  f =      -657.61  |proj g|=        3.2336
At iterate    19  f =      -657.62  |proj g|=        3.2074
At iterate    20  f =      -657.62  |proj g|=        3.2026
At iterate    21  f =      -657.62  |proj g|=        3.2024
At iterate    22  f =      -657.62  |proj g|=        3.2022
At iterate    23  f =      -657.62  |proj g|=        3.2017
At iterate    24  f =      -657.62  |proj g|=        3.2006
At iterate    25  f =      -657.62  |proj g|=        3.2026
At iterate    26  f =      -657.62  |proj g|=        3.1946
At iterate    27  f =      -657.62  |proj g|=        3.1851
At iterate    28  f =      -657.63  |proj g|=        3.1572
At iterate    29  f =      -657.64  |proj g|=        3.1351
At iterate    30  f =      -657.68  |proj g|=        3.1041
At iterate    31  f =      -657.77  |proj g|=        3.0683
At iterate    32  f =      -658.06  |proj g|=        2.9739
At iterate    33  f =       -658.7  |proj g|=        2.8268
At iterate    34  f =      -660.15  |proj g|=        2.1269
At iterate    35  f =      -662.96  |proj g|=        1.2412
At iterate    36  f =       -663.9  |proj g|=        1.6833
At iterate    37  f =      -665.43  |proj g|=        2.0314
At iterate    38  f =      -666.68  |proj g|=         2.247
At iterate    39  f =      -667.03  |proj g|=         2.032
At iterate    40  f =      -667.14  |proj g|=         1.589
At iterate    41  f =      -667.19  |proj g|=        1.7725
At iterate    42  f =      -667.19  |proj g|=        1.7504
At iterate    43  f =      -667.23  |proj g|=        1.6548
At iterate    44  f =      -667.28  |proj g|=        1.5669
At iterate    45  f =      -667.49  |proj g|=        1.3332
At iterate    46  f =      -667.98  |proj g|=       0.97541
At iterate    47  f =      -669.22  |proj g|=       0.42272
At iterate    48  f =      -671.02  |proj g|=       0.21783
At iterate    49  f =      -671.55  |proj g|=       0.22221
At iterate    50  f =      -672.16  |proj g|=       0.75911
At iterate    51  f =      -672.29  |proj g|=       0.74979
At iterate    52  f =      -672.31  |proj g|=       0.74461
At iterate    53  f =      -672.31  |proj g|=       0.74297
At iterate    54  f =      -672.31  |proj g|=       0.38409
At iterate    55  f =      -672.31  |proj g|=     0.0018575
At iterate    56  f =      -672.31  |proj g|=    0.00069443

iterations 56
function evaluations 64
segments explored during Cauchy searches 60
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000694429
final function value -672.31

F = -672.31
final  value -672.310323 
converged
 
INFO  [01:41:52.693] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:41:52.750] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:41:52.757] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:42:02.475] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:42:12.159] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:42:20.124] [mlr3]  Finished benchmark 
INFO  [01:42:20.192] [bbotk] Result of batch 135: 
INFO  [01:42:20.194] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:42:20.194] [bbotk]              2.276917                 4.252933                       0.1951843 
INFO  [01:42:20.194] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:42:20.194] [bbotk]                     3228         0.85 -0.9429338         <NA>   0.9615506 
INFO  [01:42:20.194] [bbotk]                                 uhash 
INFO  [01:42:20.194] [bbotk]  7632ed4c-6ee2-4667-8ce8-97fda9ffa6c9 
DEBUG [01:42:22.004] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.760328e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.760328e-05 0.002204948 
  - best initial criterion value(s) :  595.654 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -595.65  |proj g|=       1.9619
At iterate     1  f =      -613.96  |proj g|=        11.339
At iterate     2  f =      -618.16  |proj g|=        11.411
At iterate     3  f =         -625  |proj g|=         10.92
At iterate     4  f =      -625.29  |proj g|=        10.483
At iterate     5  f =      -625.38  |proj g|=         10.48
At iterate     6  f =      -625.98  |proj g|=        10.982
At iterate     7  f =      -626.13  |proj g|=        11.818
At iterate     8  f =      -626.14  |proj g|=        11.711
At iterate     9  f =      -626.14  |proj g|=        11.695
At iterate    10  f =      -626.14  |proj g|=        11.696
At iterate    11  f =      -626.14  |proj g|=          11.7
At iterate    12  f =      -626.14  |proj g|=        11.709
At iterate    13  f =      -626.15  |proj g|=        11.744
At iterate    14  f =      -626.17  |proj g|=        11.744
At iterate    15  f =      -626.24  |proj g|=        11.837
At iterate    16  f =      -626.29  |proj g|=        11.289
At iterate    17  f =      -626.52  |proj g|=        11.665
At iterate    18  f =      -627.18  |proj g|=         12.04
At iterate    19  f =      -628.97  |proj g|=        12.024
At iterate    20  f =      -633.27  |proj g|=        11.803
At iterate    21  f =      -642.51  |proj g|=        10.392
At iterate    22  f =      -648.93  |proj g|=        8.5171
At iterate    23  f =      -651.88  |proj g|=        7.1448
At iterate    24  f =       -652.3  |proj g|=        6.5633
At iterate    25  f =      -652.48  |proj g|=         6.226
At iterate    26  f =      -652.52  |proj g|=        6.4297
At iterate    27  f =      -652.52  |proj g|=        6.4206
At iterate    28  f =      -652.52  |proj g|=        6.3972
At iterate    29  f =      -652.52  |proj g|=        6.3696
At iterate    30  f =      -652.53  |proj g|=        6.3161
At iterate    31  f =      -652.55  |proj g|=        6.2328
At iterate    32  f =       -652.6  |proj g|=        6.1001
At iterate    33  f =      -652.74  |proj g|=        5.8965
At iterate    34  f =      -653.05  |proj g|=        5.6309
At iterate    35  f =      -653.77  |proj g|=        4.9732
At iterate    36  f =      -655.76  |proj g|=        4.2196
At iterate    37  f =      -656.36  |proj g|=        3.1443
At iterate    38  f =       -661.2  |proj g|=         2.256
At iterate    39  f =       -668.9  |proj g|=        1.0283
At iterate    40  f =      -673.71  |proj g|=        0.2782
At iterate    41  f =      -674.02  |proj g|=       0.80013
At iterate    42  f =      -675.15  |proj g|=       0.22397
At iterate    43  f =      -676.19  |proj g|=       0.73195
At iterate    44  f =      -676.28  |proj g|=       0.73287
At iterate    45  f =       -676.3  |proj g|=       0.25989
At iterate    46  f =       -676.3  |proj g|=       0.14581
At iterate    47  f =       -676.3  |proj g|=      0.036795
At iterate    48  f =       -676.3  |proj g|=     0.0019952

iterations 48
function evaluations 54
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0019952
final function value -676.298

F = -676.298
final  value -676.297848 
converged
 
INFO  [01:42:22.005] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:42:22.052] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:42:22.059] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:42:30.213] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:42:39.420] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:42:48.579] [mlr3]  Finished benchmark 
INFO  [01:42:48.648] [bbotk] Result of batch 136: 
INFO  [01:42:48.650] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:42:48.650] [bbotk]              4.358394                 6.520888                      0.02701907 
INFO  [01:42:48.650] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:42:48.650] [bbotk]                     3246        1.121 -0.9393442         <NA>   0.9597798 
INFO  [01:42:48.650] [bbotk]                                 uhash 
INFO  [01:42:48.650] [bbotk]  a1a43afa-932b-4008-b4ba-0e288ffd3f62 
DEBUG [01:42:50.666] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.755146e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.755146e-05 0.002196278 
  - best initial criterion value(s) :  587.8478 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -587.85  |proj g|=       2.0813
At iterate     1  f =      -593.44  |proj g|=        8.8055
At iterate     2  f =       -616.1  |proj g|=        7.0235
At iterate     3  f =      -616.26  |proj g|=        7.2997
At iterate     4  f =      -616.27  |proj g|=        7.3093
At iterate     5  f =      -616.35  |proj g|=        7.4777
At iterate     6  f =      -616.36  |proj g|=         7.553
At iterate     7  f =      -616.36  |proj g|=        7.5701
At iterate     8  f =      -616.38  |proj g|=        7.6094
At iterate     9  f =      -621.18  |proj g|=        6.8299
At iterate    10  f =      -633.16  |proj g|=        6.8541
At iterate    11  f =      -639.92  |proj g|=        8.8223
At iterate    12  f =      -640.09  |proj g|=        8.4064
At iterate    13  f =      -643.02  |proj g|=        10.443
At iterate    14  f =      -643.81  |proj g|=         11.64
At iterate    15  f =       -644.1  |proj g|=        11.796
At iterate    16  f =      -644.16  |proj g|=        11.799
At iterate    17  f =      -644.17  |proj g|=        11.792
At iterate    18  f =      -644.17  |proj g|=        11.786
At iterate    19  f =      -644.17  |proj g|=        11.786
At iterate    20  f =      -644.17  |proj g|=        11.786
At iterate    21  f =      -644.17  |proj g|=        11.786
At iterate    22  f =      -644.17  |proj g|=        11.786
At iterate    23  f =      -644.17  |proj g|=        11.786
At iterate    24  f =      -644.17  |proj g|=        11.786
At iterate    25  f =      -644.17  |proj g|=        11.786
At iterate    26  f =      -644.17  |proj g|=        11.786
At iterate    27  f =      -644.17  |proj g|=        11.768
At iterate    28  f =      -644.17  |proj g|=        11.739
At iterate    29  f =      -644.18  |proj g|=        11.647
At iterate    30  f =      -644.19  |proj g|=        11.541
At iterate    31  f =       -644.2  |proj g|=        11.443
At iterate    32  f =      -644.23  |proj g|=        11.273
At iterate    33  f =      -644.31  |proj g|=        11.034
At iterate    34  f =      -644.31  |proj g|=        11.031
At iterate    35  f =      -644.31  |proj g|=        11.045
At iterate    36  f =      -644.31  |proj g|=        11.047
At iterate    37  f =      -644.31  |proj g|=        11.055
At iterate    38  f =      -644.31  |proj g|=        11.069
At iterate    39  f =      -644.31  |proj g|=        11.086
At iterate    40  f =      -644.31  |proj g|=        11.118
At iterate    41  f =      -644.32  |proj g|=        11.162
At iterate    42  f =      -644.33  |proj g|=        11.229
At iterate    43  f =      -644.36  |proj g|=        11.313
At iterate    44  f =      -644.37  |proj g|=         11.63
At iterate    45  f =      -644.47  |proj g|=        11.548
At iterate    46  f =       -644.7  |proj g|=        11.297
At iterate    47  f =      -645.23  |proj g|=        10.768
At iterate    48  f =      -646.42  |proj g|=        9.6073
At iterate    49  f =       -648.3  |proj g|=        7.9277
At iterate    50  f =      -648.76  |proj g|=        6.9016
At iterate    51  f =         -651  |proj g|=        5.4427
At iterate    52  f =      -652.38  |proj g|=        5.2021
At iterate    53  f =      -652.49  |proj g|=        5.1542
At iterate    54  f =       -652.5  |proj g|=        5.1043
At iterate    55  f =       -652.5  |proj g|=        5.1588
At iterate    56  f =      -652.51  |proj g|=        5.2044
At iterate    57  f =      -652.52  |proj g|=        5.2637
At iterate    58  f =      -652.55  |proj g|=         5.356
At iterate    59  f =      -652.62  |proj g|=         5.482
At iterate    60  f =      -652.78  |proj g|=        5.5943
At iterate    61  f =      -653.07  |proj g|=        5.5612
At iterate    62  f =      -653.08  |proj g|=        5.6254
At iterate    63  f =      -653.49  |proj g|=        5.3051
At iterate    64  f =      -654.54  |proj g|=        4.3103
At iterate    65  f =      -655.47  |proj g|=         3.266
At iterate    66  f =      -655.57  |proj g|=        3.3239
At iterate    67  f =      -655.58  |proj g|=        3.3407
At iterate    68  f =      -655.58  |proj g|=        3.3717
At iterate    69  f =      -655.59  |proj g|=        3.3654
At iterate    70  f =       -655.6  |proj g|=        3.3792
At iterate    71  f =      -655.66  |proj g|=        3.4081
At iterate    72  f =       -655.8  |proj g|=        3.4515
At iterate    73  f =      -656.06  |proj g|=        3.5029
At iterate    74  f =      -656.48  |proj g|=        3.6566
At iterate    75  f =      -657.33  |proj g|=        4.1484
At iterate    76  f =      -659.43  |proj g|=        4.9373
At iterate    77  f =      -664.02  |proj g|=        5.7485
At iterate    78  f =      -665.22  |proj g|=        5.0105
At iterate    79  f =      -665.98  |proj g|=         4.503
At iterate    80  f =       -666.1  |proj g|=        4.6639
At iterate    81  f =      -666.21  |proj g|=        4.6057
At iterate    82  f =      -666.25  |proj g|=         4.486
At iterate    83  f =      -666.27  |proj g|=        4.4358
At iterate    84  f =      -666.35  |proj g|=        4.2323
At iterate    85  f =      -666.47  |proj g|=        4.0367
At iterate    86  f =      -666.86  |proj g|=        3.6674
At iterate    87  f =      -666.94  |proj g|=        3.3635
At iterate    88  f =      -667.71  |proj g|=        2.8996
At iterate    89  f =      -672.97  |proj g|=         1.931
At iterate    90  f =       -679.4  |proj g|=        1.2259
At iterate    91  f =      -681.33  |proj g|=       0.79406
At iterate    92  f =      -682.19  |proj g|=       0.26294
At iterate    93  f =      -682.21  |proj g|=       0.25873
At iterate    94  f =      -682.21  |proj g|=        0.2571
At iterate    95  f =      -682.21  |proj g|=     0.0043658
At iterate    96  f =      -682.21  |proj g|=     0.0014637

iterations 96
function evaluations 115
segments explored during Cauchy searches 98
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00146365
final function value -682.211

F = -682.211
final  value -682.211104 
converged
 
INFO  [01:42:50.670] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:42:50.725] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:42:50.732] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:43:01.370] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:43:10.777] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:43:19.896] [mlr3]  Finished benchmark 
INFO  [01:43:19.969] [bbotk] Result of batch 137: 
INFO  [01:43:19.971] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:43:19.971] [bbotk]              6.271235                 5.360839                      0.04818941 
INFO  [01:43:19.971] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:43:19.971] [bbotk]                     3213        0.854 -0.9425747         <NA>    0.968164 
INFO  [01:43:19.971] [bbotk]                                 uhash 
INFO  [01:43:19.971] [bbotk]  d2402490-6483-45f5-8f11-7c6b447a2a6f 
DEBUG [01:43:21.385] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.744705e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.744705e-05 0.002187799 
  - best initial criterion value(s) :  574.9046 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -574.9  |proj g|=       8.0195
At iterate     1  f =      -626.38  |proj g|=        2.3378
At iterate     2  f =      -641.19  |proj g|=         7.966
At iterate     3  f =      -641.34  |proj g|=        7.6475
At iterate     4  f =      -641.45  |proj g|=        7.3992
At iterate     5  f =      -641.58  |proj g|=        7.2178
At iterate     6  f =      -641.75  |proj g|=        7.1433
At iterate     7  f =      -641.86  |proj g|=        7.2804
At iterate     8  f =      -641.88  |proj g|=        7.3688
At iterate     9  f =      -641.88  |proj g|=         7.383
At iterate    10  f =      -641.88  |proj g|=        7.3822
At iterate    11  f =      -641.88  |proj g|=        7.3966
At iterate    12  f =      -641.88  |proj g|=        7.4046
At iterate    13  f =      -641.89  |proj g|=        7.4189
At iterate    14  f =      -641.91  |proj g|=        7.4279
At iterate    15  f =      -641.96  |proj g|=        7.4172
At iterate    16  f =      -642.08  |proj g|=        7.3036
At iterate    17  f =      -642.25  |proj g|=        7.4043
At iterate    18  f =       -642.6  |proj g|=        7.0538
At iterate    19  f =      -643.37  |proj g|=        6.5012
At iterate    20  f =      -644.42  |proj g|=         5.735
At iterate    21  f =      -644.95  |proj g|=        5.4391
At iterate    22  f =      -648.43  |proj g|=        4.1292
At iterate    23  f =      -654.09  |proj g|=         3.072
At iterate    24  f =      -669.54  |proj g|=       0.45496
At iterate    25  f =       -674.1  |proj g|=       0.93401
At iterate    26  f =      -679.41  |proj g|=        2.5165
At iterate    27  f =      -682.52  |proj g|=        1.9973
At iterate    28  f =      -684.09  |proj g|=        0.9612
At iterate    29  f =      -684.37  |proj g|=        1.4898
At iterate    30  f =      -684.44  |proj g|=        1.3111
At iterate    31  f =      -684.44  |proj g|=        1.3005
At iterate    32  f =      -684.44  |proj g|=        1.3033
At iterate    33  f =      -684.44  |proj g|=        1.3033

iterations 33
function evaluations 38
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.30334
final function value -684.44

F = -684.44
final  value -684.440469 
converged
 
INFO  [01:43:21.389] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:43:21.478] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:43:21.489] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:43:23.510] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:43:25.199] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:43:27.057] [mlr3]  Finished benchmark 
INFO  [01:43:27.127] [bbotk] Result of batch 138: 
INFO  [01:43:27.129] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:43:27.129] [bbotk]              6.626781                 8.603435                       0.2489467 
INFO  [01:43:27.129] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:43:27.129] [bbotk]                      553         0.84 -0.9466326         <NA>   0.9672836 
INFO  [01:43:27.129] [bbotk]                                 uhash 
INFO  [01:43:27.129] [bbotk]  7ccd7f05-7ac2-41e0-8abc-404009e33207 
DEBUG [01:43:28.735] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.734545e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.734545e-05 0.00216565 
  - best initial criterion value(s) :  634.8697 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -634.87  |proj g|=       4.9496
At iterate     1  f =      -638.56  |proj g|=         5.604
At iterate     2  f =      -638.61  |proj g|=         5.572
At iterate     3  f =      -638.83  |proj g|=        5.4099
At iterate     4  f =      -639.04  |proj g|=         5.279
At iterate     5  f =      -639.73  |proj g|=        4.8605
At iterate     6  f =      -640.09  |proj g|=        4.6723
At iterate     7  f =      -640.13  |proj g|=        4.6999
At iterate     8  f =      -640.13  |proj g|=        4.7148
At iterate     9  f =      -640.13  |proj g|=        4.7154
At iterate    10  f =      -640.13  |proj g|=        4.7169
At iterate    11  f =      -640.13  |proj g|=        4.7188
At iterate    12  f =      -640.13  |proj g|=        4.7216
At iterate    13  f =      -640.14  |proj g|=        4.7248
At iterate    14  f =      -640.14  |proj g|=        4.7274
At iterate    15  f =      -640.15  |proj g|=        4.7255
At iterate    16  f =      -640.16  |proj g|=        4.7091
At iterate    17  f =      -640.21  |proj g|=        4.6565
At iterate    18  f =      -640.28  |proj g|=        4.5407
At iterate    19  f =      -640.33  |proj g|=        4.4584
At iterate    20  f =      -640.34  |proj g|=        4.4144
At iterate    21  f =      -642.09  |proj g|=        4.1962
At iterate    22  f =      -652.46  |proj g|=        2.9691
At iterate    23  f =      -662.46  |proj g|=        4.1781
At iterate    24  f =      -663.83  |proj g|=        3.9574
At iterate    25  f =      -664.82  |proj g|=         2.138
At iterate    26  f =      -665.53  |proj g|=        3.1813
At iterate    27  f =      -665.62  |proj g|=        3.0402
At iterate    28  f =      -665.68  |proj g|=        2.9179
At iterate    29  f =      -665.72  |proj g|=        2.8955
At iterate    30  f =      -665.79  |proj g|=        2.9503
At iterate    31  f =      -665.81  |proj g|=        3.0336
At iterate    32  f =      -665.81  |proj g|=        3.0841
At iterate    33  f =      -665.81  |proj g|=        3.0944
At iterate    34  f =      -665.81  |proj g|=        3.0947
At iterate    35  f =      -665.81  |proj g|=        3.0947

iterations 35
function evaluations 41
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 3.09469
final function value -665.815

F = -665.815
final  value -665.814669 
converged
 
INFO  [01:43:28.739] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:43:28.797] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:43:29.207] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:43:36.223] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:43:43.228] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:43:50.082] [mlr3]  Finished benchmark 
INFO  [01:43:50.167] [bbotk] Result of batch 139: 
INFO  [01:43:50.168] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:43:50.168] [bbotk]              5.588171                 8.824493                      0.02998237 
INFO  [01:43:50.168] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:43:50.168] [bbotk]                     2284        1.019 -0.9607279         <NA>   0.9586791 
INFO  [01:43:50.168] [bbotk]                                 uhash 
INFO  [01:43:50.168] [bbotk]  91804fff-20e3-4a1e-bed3-ff9c738a4ada 
DEBUG [01:43:51.459] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.730819e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.730819e-05 0.00215897 
  - best initial criterion value(s) :  580.1959 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -580.2  |proj g|=       1.3663
At iterate     1  f =      -649.28  |proj g|=        5.0434
At iterate     2  f =      -683.27  |proj g|=         1.829
At iterate     3  f =      -686.68  |proj g|=         1.797
At iterate     4  f =      -688.08  |proj g|=        1.7625
At iterate     5  f =      -688.09  |proj g|=         1.759
At iterate     6  f =       -688.1  |proj g|=        1.7582
At iterate     7  f =       -688.1  |proj g|=        1.7549
At iterate     8  f =       -688.1  |proj g|=         1.755
At iterate     9  f =       -688.1  |proj g|=        1.7542
At iterate    10  f =      -690.01  |proj g|=        1.0656
At iterate    11  f =      -692.77  |proj g|=       0.36048
At iterate    12  f =      -692.88  |proj g|=       0.33733
At iterate    13  f =      -692.89  |proj g|=       0.75895
At iterate    14  f =      -692.89  |proj g|=       0.28357
At iterate    15  f =      -692.89  |proj g|=       0.28587
At iterate    16  f =      -692.89  |proj g|=       0.28577

iterations 16
function evaluations 26
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.285766
final function value -692.893

F = -692.893
final  value -692.892778 
converged
 
INFO  [01:43:51.463] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:43:51.517] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:43:51.524] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:44:00.422] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:44:11.136] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:44:19.738] [mlr3]  Finished benchmark 
INFO  [01:44:19.805] [bbotk] Result of batch 140: 
INFO  [01:44:19.807] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:44:19.807] [bbotk]              3.612884                 2.288213                       0.1577497 
INFO  [01:44:19.807] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:44:19.807] [bbotk]                     3129        0.827 -0.9491149         <NA>   0.9718767 
INFO  [01:44:19.807] [bbotk]                                 uhash 
INFO  [01:44:19.807] [bbotk]  de69870b-2ad8-4846-a9f2-69072e76eebd 
DEBUG [01:44:21.389] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.721069e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.721069e-05 0.002150579 
  - best initial criterion value(s) :  635.75 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -635.75  |proj g|=       5.5808
At iterate     1  f =      -642.83  |proj g|=        8.7944
At iterate     2  f =      -644.43  |proj g|=        8.5946
At iterate     3  f =       -645.2  |proj g|=        7.5131
At iterate     4  f =       -645.6  |proj g|=        7.9784
At iterate     5  f =      -645.71  |proj g|=         7.853
At iterate     6  f =      -646.19  |proj g|=        7.1254
At iterate     7  f =      -646.31  |proj g|=        6.9984
At iterate     8  f =      -646.33  |proj g|=        6.9786
At iterate     9  f =      -646.33  |proj g|=        6.9835
At iterate    10  f =      -646.34  |proj g|=        7.0163
At iterate    11  f =      -646.34  |proj g|=        7.0507
At iterate    12  f =      -646.36  |proj g|=        7.1195
At iterate    13  f =      -646.41  |proj g|=        7.2263
At iterate    14  f =      -646.53  |proj g|=        7.3955
At iterate    15  f =      -646.83  |proj g|=        7.6348
At iterate    16  f =      -647.55  |proj g|=        7.9577
At iterate    17  f =      -649.16  |proj g|=        8.2804
At iterate    18  f =      -652.64  |proj g|=         8.292
At iterate    19  f =      -659.53  |proj g|=        7.2348
At iterate    20  f =      -667.66  |proj g|=        5.7094
At iterate    21  f =      -674.93  |proj g|=        4.1573
At iterate    22  f =      -681.74  |proj g|=        2.7505
At iterate    23  f =      -686.84  |proj g|=        4.0808
At iterate    24  f =      -687.57  |proj g|=         4.378
At iterate    25  f =      -687.81  |proj g|=        4.0875
At iterate    26  f =      -687.84  |proj g|=        4.6848
At iterate    27  f =      -687.95  |proj g|=        4.4207
At iterate    28  f =      -687.95  |proj g|=        4.4068
At iterate    29  f =      -687.95  |proj g|=        4.4087
At iterate    30  f =      -687.95  |proj g|=        4.4089

iterations 30
function evaluations 33
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 4.40889
final function value -687.954

F = -687.954
final  value -687.953778 
converged
 
INFO  [01:44:21.393] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:44:21.447] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:44:21.453] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:44:35.561] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:44:48.654] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:45:00.809] [mlr3]  Finished benchmark 
INFO  [01:45:00.877] [bbotk] Result of batch 141: 
INFO  [01:45:00.879] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:45:00.879] [bbotk]              9.376227                 4.755636                       0.2025684 
INFO  [01:45:00.879] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:45:00.879] [bbotk]                     4710         0.99 -0.9541217         <NA>   0.9770882 
INFO  [01:45:00.879] [bbotk]                                 uhash 
INFO  [01:45:00.879] [bbotk]  f9e409f7-3ea1-4157-ab9d-67de9afd4adb 
DEBUG [01:45:02.702] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.714645e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.714645e-05 0.002149104 
  - best initial criterion value(s) :  629.4759 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -629.48  |proj g|=       3.5543
At iterate     1  f =      -666.14  |proj g|=        1.8872
At iterate     2  f =       -678.2  |proj g|=        3.7775
At iterate     3  f =      -679.28  |proj g|=          3.65
At iterate     4  f =      -679.48  |proj g|=        3.5861
At iterate     5  f =      -679.52  |proj g|=        3.6244
At iterate     6  f =      -679.52  |proj g|=        3.6417
At iterate     7  f =      -679.52  |proj g|=        3.6404
At iterate     8  f =      -679.52  |proj g|=        3.6401
At iterate     9  f =      -679.52  |proj g|=         3.638
At iterate    10  f =      -679.52  |proj g|=        3.6357
At iterate    11  f =      -679.52  |proj g|=        3.6312
At iterate    12  f =      -679.52  |proj g|=        3.6243
At iterate    13  f =      -679.53  |proj g|=        3.6126
At iterate    14  f =      -679.54  |proj g|=        3.5934
At iterate    15  f =      -679.56  |proj g|=        3.5609
At iterate    16  f =      -679.63  |proj g|=        3.5072
At iterate    17  f =      -679.79  |proj g|=        3.4243
At iterate    18  f =      -680.17  |proj g|=        3.3252
At iterate    19  f =      -680.75  |proj g|=        3.3056
At iterate    20  f =      -680.95  |proj g|=        3.4406
At iterate    21  f =      -680.96  |proj g|=        3.4428
At iterate    22  f =      -680.98  |proj g|=        3.4363
At iterate    23  f =      -681.03  |proj g|=        3.4288
At iterate    24  f =      -681.16  |proj g|=        3.4181
At iterate    25  f =      -681.48  |proj g|=        3.3996
At iterate    26  f =      -681.72  |proj g|=         3.192
At iterate    27  f =      -682.63  |proj g|=        3.1794
At iterate    28  f =      -685.48  |proj g|=        2.9808
At iterate    29  f =      -701.48  |proj g|=        1.1654
At iterate    30  f =      -702.36  |proj g|=        1.2879
At iterate    31  f =      -703.33  |proj g|=        1.6372
At iterate    32  f =      -703.49  |proj g|=         1.601
At iterate    33  f =      -703.51  |proj g|=        1.5072
At iterate    34  f =      -703.51  |proj g|=        1.5109
At iterate    35  f =      -703.51  |proj g|=        1.5104
At iterate    36  f =      -703.51  |proj g|=        1.5097
At iterate    37  f =      -703.51  |proj g|=        1.5089
At iterate    38  f =      -703.51  |proj g|=        1.5072
At iterate    39  f =      -703.51  |proj g|=        1.5049
At iterate    40  f =      -703.51  |proj g|=        1.5015
At iterate    41  f =      -703.51  |proj g|=        1.4978
At iterate    42  f =      -703.51  |proj g|=        1.4923
At iterate    43  f =      -703.51  |proj g|=        1.4909
At iterate    44  f =      -703.51  |proj g|=        1.4754
At iterate    45  f =      -703.52  |proj g|=        1.4737
At iterate    46  f =      -703.55  |proj g|=        1.4645
At iterate    47  f =      -703.69  |proj g|=        1.4167
At iterate    48  f =      -704.06  |proj g|=         1.293
At iterate    49  f =      -704.92  |proj g|=        1.0053
At iterate    50  f =      -705.41  |proj g|=       0.78622
At iterate    51  f =      -706.62  |proj g|=       0.77953
At iterate    52  f =      -707.28  |proj g|=       0.75982
At iterate    53  f =       -707.5  |proj g|=       0.74254
At iterate    54  f =      -707.51  |proj g|=       0.19353
At iterate    55  f =      -707.51  |proj g|=      0.046567
At iterate    56  f =      -707.51  |proj g|=     0.0088861

iterations 56
function evaluations 64
segments explored during Cauchy searches 59
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00888607
final function value -707.508

F = -707.508
final  value -707.508399 
converged
 
INFO  [01:45:02.704] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:45:02.749] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:45:02.756] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:45:08.459] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:45:17.045] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:45:22.533] [mlr3]  Finished benchmark 
INFO  [01:45:22.632] [bbotk] Result of batch 142: 
INFO  [01:45:22.634] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:45:22.634] [bbotk]              9.323015                 8.850419                      0.01615584 
INFO  [01:45:22.634] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:45:22.634] [bbotk]                     1798        1.023 -0.9408868         <NA>   0.9478712 
INFO  [01:45:22.634] [bbotk]                                 uhash 
INFO  [01:45:22.634] [bbotk]  292df951-9cbf-4834-859a-7209b555e80b 
DEBUG [01:45:24.306] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.731024e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.731024e-05 0.002161568 
  - best initial criterion value(s) :  603.4619 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -603.46  |proj g|=       1.0891
At iterate     1  f =      -616.87  |proj g|=        11.915
At iterate     2  f =      -642.07  |proj g|=         12.08
At iterate     3  f =      -648.27  |proj g|=        11.634
At iterate     4  f =       -648.7  |proj g|=        10.701
At iterate     5  f =      -649.42  |proj g|=        10.459
At iterate     6  f =       -649.5  |proj g|=        10.384
At iterate     7  f =       -649.5  |proj g|=        10.411
At iterate     8  f =       -649.5  |proj g|=        10.406
At iterate     9  f =       -649.5  |proj g|=         10.38
At iterate    10  f =      -649.51  |proj g|=        10.352
At iterate    11  f =      -649.51  |proj g|=        10.293
At iterate    12  f =      -649.53  |proj g|=        10.202
At iterate    13  f =      -649.58  |proj g|=        9.9879
At iterate    14  f =      -649.69  |proj g|=        9.7738
At iterate    15  f =      -650.13  |proj g|=        8.9862
At iterate    16  f =      -651.09  |proj g|=         8.158
At iterate    17  f =      -651.99  |proj g|=        6.6407
At iterate    18  f =      -656.45  |proj g|=        4.9728
At iterate    19  f =      -669.28  |proj g|=        2.7571
At iterate    20  f =      -684.22  |proj g|=         2.498
At iterate    21  f =      -684.35  |proj g|=         2.528
At iterate    22  f =      -701.69  |proj g|=        1.1022
At iterate    23  f =      -702.28  |proj g|=       0.78856
At iterate    24  f =      -702.33  |proj g|=       0.78856
At iterate    25  f =      -702.33  |proj g|=       0.78856
At iterate    26  f =      -702.33  |proj g|=       0.78856
At iterate    27  f =      -702.33  |proj g|=       0.78856
At iterate    28  f =      -702.33  |proj g|=       0.78855
At iterate    29  f =      -702.34  |proj g|=       0.78852
At iterate    30  f =      -702.34  |proj g|=       0.78845
At iterate    31  f =      -702.35  |proj g|=       0.78821
At iterate    32  f =      -702.37  |proj g|=       0.78759
At iterate    33  f =      -702.43  |proj g|=       0.78594
At iterate    34  f =      -702.59  |proj g|=       0.80552
At iterate    35  f =      -702.92  |proj g|=       0.82145
At iterate    36  f =      -703.46  |proj g|=       0.66951
At iterate    37  f =      -703.82  |proj g|=       0.37101
At iterate    38  f =      -703.85  |proj g|=       0.30991
At iterate    39  f =      -703.85  |proj g|=       0.30986
At iterate    40  f =      -703.85  |proj g|=       0.30985
At iterate    41  f =      -703.85  |proj g|=       0.30985

iterations 41
function evaluations 47
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.309852
final function value -703.85

F = -703.85
final  value -703.850342 
converged
 
INFO  [01:45:24.310] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:45:24.365] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:45:24.372] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:45:26.608] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:45:29.160] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:45:31.709] [mlr3]  Finished benchmark 
INFO  [01:45:31.778] [bbotk] Result of batch 143: 
INFO  [01:45:31.780] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:45:31.780] [bbotk]                8.0144                 4.734739                       0.1055921 
INFO  [01:45:31.780] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:45:31.780] [bbotk]                      819        0.843 -0.9485032         <NA>   0.9633756 
INFO  [01:45:31.780] [bbotk]                                 uhash 
INFO  [01:45:31.780] [bbotk]  f1639f13-28d2-4ded-82f4-3ce82d2a93ae 
DEBUG [01:45:33.467] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.7229e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.7229e-05 0.002144366 
  - best initial criterion value(s) :  631.6906 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -631.69  |proj g|=       5.2893
At iterate     1  f =      -659.42  |proj g|=        11.244
At iterate     2  f =      -667.51  |proj g|=        10.491
At iterate     3  f =      -675.39  |proj g|=        3.3205
At iterate     4  f =      -677.88  |proj g|=        5.4054
At iterate     5  f =       -679.2  |proj g|=        5.2954
At iterate     6  f =      -686.48  |proj g|=        3.2012
At iterate     7  f =      -688.93  |proj g|=        3.0177
At iterate     8  f =      -690.08  |proj g|=        2.8585
At iterate     9  f =      -690.42  |proj g|=         2.895
At iterate    10  f =      -690.46  |proj g|=        2.9919
At iterate    11  f =      -690.53  |proj g|=        2.9919
At iterate    12  f =      -690.56  |proj g|=        3.0022
At iterate    13  f =      -690.63  |proj g|=        3.0282
At iterate    14  f =      -690.73  |proj g|=        3.0555
At iterate    15  f =      -690.92  |proj g|=        3.0829
At iterate    16  f =      -691.05  |proj g|=        2.9166
At iterate    17  f =      -694.21  |proj g|=         3.009
At iterate    18  f =      -702.88  |proj g|=        2.7296
At iterate    19  f =      -704.93  |proj g|=        2.7323
At iterate    20  f =      -705.28  |proj g|=        2.6801
At iterate    21  f =       -705.3  |proj g|=        2.7312
At iterate    22  f =       -705.3  |proj g|=        2.7312
At iterate    23  f =       -705.3  |proj g|=        2.7312
At iterate    24  f =       -705.3  |proj g|=        2.7308
At iterate    25  f =      -705.32  |proj g|=        2.7245
At iterate    26  f =      -705.34  |proj g|=        2.7086
At iterate    27  f =      -705.41  |proj g|=        2.6622
At iterate    28  f =      -705.59  |proj g|=        2.5379
At iterate    29  f =      -706.07  |proj g|=        2.1979
At iterate    30  f =      -707.26  |proj g|=        1.3019
At iterate    31  f =      -708.53  |proj g|=       0.73612
At iterate    32  f =      -711.86  |proj g|=       0.74207
At iterate    33  f =      -711.88  |proj g|=        0.2512
At iterate    34  f =       -711.9  |proj g|=       0.74316
At iterate    35  f =       -711.9  |proj g|=       0.74311
At iterate    36  f =      -711.91  |proj g|=       0.74261
At iterate    37  f =      -711.91  |proj g|=       0.74147
At iterate    38  f =      -711.92  |proj g|=       0.25628
At iterate    39  f =      -711.92  |proj g|=       0.25841
At iterate    40  f =      -711.92  |proj g|=       0.25882
At iterate    41  f =      -711.92  |proj g|=      0.041248
At iterate    42  f =      -711.92  |proj g|=     0.0017478

iterations 42
function evaluations 49
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00174783
final function value -711.921

F = -711.921
final  value -711.920694 
converged
 
INFO  [01:45:33.471] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:45:33.527] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:45:33.534] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:45:39.288] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:45:45.153] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:45:50.517] [mlr3]  Finished benchmark 
INFO  [01:45:50.608] [bbotk] Result of batch 144: 
INFO  [01:45:50.611] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:45:50.611] [bbotk]              5.982841                 9.559146                      0.09342199 
INFO  [01:45:50.611] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:45:50.611] [bbotk]                     2003        0.843 -0.9431139         <NA>    0.969687 
INFO  [01:45:50.611] [bbotk]                                 uhash 
INFO  [01:45:50.611] [bbotk]  120e3ee4-4604-4986-9d83-33d691e32de8 
DEBUG [01:45:52.148] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.71302e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.71302e-05 0.002134217 
  - best initial criterion value(s) :  659.8595 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -659.86  |proj g|=       1.9487
At iterate     1  f =       -660.3  |proj g|=        5.5026
At iterate     2  f =       -667.8  |proj g|=        4.8779
At iterate     3  f =      -676.07  |proj g|=         3.082
At iterate     4  f =      -676.27  |proj g|=        2.7638
At iterate     5  f =      -676.54  |proj g|=        2.7159
At iterate     6  f =      -676.85  |proj g|=        2.6306
At iterate     7  f =      -676.87  |proj g|=        2.7321
At iterate     8  f =      -676.87  |proj g|=        2.6943
At iterate     9  f =      -676.87  |proj g|=        2.6945
At iterate    10  f =      -676.87  |proj g|=        2.6936
At iterate    11  f =      -676.87  |proj g|=        2.6912
At iterate    12  f =      -676.87  |proj g|=         2.687
At iterate    13  f =      -676.87  |proj g|=        2.6808
At iterate    14  f =      -676.87  |proj g|=         2.671
At iterate    15  f =      -676.87  |proj g|=        2.6565
At iterate    16  f =      -676.88  |proj g|=        2.6449
At iterate    17  f =      -676.89  |proj g|=        2.6357
At iterate    18  f =      -676.92  |proj g|=        2.6347
At iterate    19  f =      -676.95  |proj g|=        2.7286
At iterate    20  f =      -676.96  |proj g|=        2.7914
At iterate    21  f =      -676.96  |proj g|=        2.8308
At iterate    22  f =      -676.96  |proj g|=        2.8497
At iterate    23  f =      -676.97  |proj g|=        2.8784
At iterate    24  f =      -676.98  |proj g|=        2.9243
At iterate    25  f =         -677  |proj g|=        2.9923
At iterate    26  f =      -677.05  |proj g|=        3.1055
At iterate    27  f =      -677.15  |proj g|=        3.2418
At iterate    28  f =      -677.28  |proj g|=        3.2381
At iterate    29  f =      -677.31  |proj g|=        3.1684
At iterate    30  f =      -677.33  |proj g|=         3.099
At iterate    31  f =      -677.34  |proj g|=        3.0687
At iterate    32  f =       -677.4  |proj g|=        3.0628
At iterate    33  f =      -677.49  |proj g|=        3.1676
At iterate    34  f =       -677.6  |proj g|=        3.4657
At iterate    35  f =      -677.61  |proj g|=        3.7914
At iterate    36  f =      -677.65  |proj g|=        3.7485
At iterate    37  f =      -677.66  |proj g|=         3.759
At iterate    38  f =      -677.66  |proj g|=         3.778
At iterate    39  f =      -677.66  |proj g|=        3.8247
At iterate    40  f =      -677.66  |proj g|=        3.8275
At iterate    41  f =      -677.66  |proj g|=        3.8272

iterations 41
function evaluations 47
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.82717
final function value -677.66

F = -677.66
final  value -677.660260 
converged
 
INFO  [01:45:52.153] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:45:52.213] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:45:52.220] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:45:53.624] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:45:55.026] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:45:56.496] [mlr3]  Finished benchmark 
INFO  [01:45:56.565] [bbotk] Result of batch 145: 
INFO  [01:45:56.567] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:45:56.567] [bbotk]              4.961703                 6.179916                      0.09761274 
INFO  [01:45:56.567] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:45:56.567] [bbotk]                      422         0.87 -0.9639533         <NA>   0.9504748 
INFO  [01:45:56.567] [bbotk]                                 uhash 
INFO  [01:45:56.567] [bbotk]  0d773971-c8f3-4dc2-a296-204262abb7b5 
DEBUG [01:45:58.337] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.722875e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.722875e-05 0.002146643 
  - best initial criterion value(s) :  663.5779 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -663.58  |proj g|=       4.3609
At iterate     1  f =      -683.71  |proj g|=        2.6706
At iterate     2  f =      -689.09  |proj g|=        2.4954
At iterate     3  f =      -693.27  |proj g|=        1.3277
At iterate     4  f =      -696.48  |proj g|=        2.0382
At iterate     5  f =      -697.33  |proj g|=        1.9729
At iterate     6  f =      -701.76  |proj g|=        1.7348
At iterate     7  f =      -706.19  |proj g|=        1.7678
At iterate     8  f =      -707.77  |proj g|=        2.7138
At iterate     9  f =      -714.28  |proj g|=        2.6077
At iterate    10  f =      -714.82  |proj g|=        2.5837
At iterate    11  f =      -714.84  |proj g|=        2.5837
At iterate    12  f =      -714.86  |proj g|=        2.5837
At iterate    13  f =      -714.86  |proj g|=        2.5837
At iterate    14  f =      -714.86  |proj g|=        2.5837
At iterate    15  f =      -714.86  |proj g|=        2.5837
At iterate    16  f =      -714.86  |proj g|=        2.5837
At iterate    17  f =      -714.86  |proj g|=        2.5837
At iterate    18  f =      -714.87  |proj g|=        2.5837
At iterate    19  f =      -714.87  |proj g|=        2.5836
At iterate    20  f =      -714.89  |proj g|=        2.5836
At iterate    21  f =      -714.93  |proj g|=        2.5834
At iterate    22  f =      -715.03  |proj g|=        2.5829
At iterate    23  f =      -715.21  |proj g|=        2.5821
At iterate    24  f =      -715.32  |proj g|=        2.5819
At iterate    25  f =      -715.34  |proj g|=        2.5815
At iterate    26  f =      -715.34  |proj g|=        2.5814
At iterate    27  f =      -715.34  |proj g|=        2.5814
At iterate    28  f =      -715.34  |proj g|=        2.5814
At iterate    29  f =      -715.34  |proj g|=        2.5814
At iterate    30  f =      -715.34  |proj g|=        2.5814
At iterate    31  f =      -715.34  |proj g|=        2.5814
At iterate    32  f =      -715.34  |proj g|=        2.5813
At iterate    33  f =      -715.34  |proj g|=        2.5809
At iterate    34  f =      -715.35  |proj g|=        2.5765
At iterate    35  f =      -715.42  |proj g|=        2.5405
At iterate    36  f =      -715.74  |proj g|=        2.3682
At iterate    37  f =      -715.75  |proj g|=        2.3651
At iterate    38  f =      -716.58  |proj g|=        1.8318
At iterate    39  f =      -718.26  |proj g|=       0.63847
At iterate    40  f =      -719.22  |proj g|=       0.33237
At iterate    41  f =      -720.87  |proj g|=        0.2949
At iterate    42  f =      -721.39  |proj g|=       0.77123
At iterate    43  f =      -721.49  |proj g|=       0.76752
At iterate    44  f =      -721.74  |proj g|=       0.25132
At iterate    45  f =      -721.75  |proj g|=       0.24907
At iterate    46  f =      -721.75  |proj g|=     0.0097933
At iterate    47  f =      -721.75  |proj g|=    0.00098051

iterations 47
function evaluations 54
segments explored during Cauchy searches 50
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00098051
final function value -721.75

F = -721.75
final  value -721.749913 
converged
 
INFO  [01:45:58.341] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:45:58.406] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:45:58.416] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:46:02.511] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:46:06.579] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:46:09.749] [mlr3]  Finished benchmark 
INFO  [01:46:09.820] [bbotk] Result of batch 146: 
INFO  [01:46:09.822] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:46:09.822] [bbotk]              6.707869                 2.883959                       0.3270354 
INFO  [01:46:09.822] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:46:09.822] [bbotk]                     1129        1.029 -0.9441084         <NA>    0.974232 
INFO  [01:46:09.822] [bbotk]                                 uhash 
INFO  [01:46:09.822] [bbotk]  6bbe9d4b-2414-4c3b-bdf8-172667b4c146 
DEBUG [01:46:11.243] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.714654e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.714654e-05 0.002124519 
  - best initial criterion value(s) :  660.2235 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -660.22  |proj g|=       2.6689
At iterate     1  f =      -685.34  |proj g|=          5.88
At iterate     2  f =      -685.79  |proj g|=        5.5673
At iterate     3  f =      -686.31  |proj g|=         4.538
At iterate     4  f =      -686.39  |proj g|=        4.6969
At iterate     5  f =      -686.63  |proj g|=        4.8738
At iterate     6  f =      -687.24  |proj g|=        4.9773
At iterate     7  f =      -688.03  |proj g|=        4.7194
At iterate     8  f =      -688.62  |proj g|=         3.972
At iterate     9  f =      -688.63  |proj g|=        3.9833
At iterate    10  f =      -688.63  |proj g|=        3.9907
At iterate    11  f =      -688.63  |proj g|=        3.9942
At iterate    12  f =      -688.63  |proj g|=        3.9937
At iterate    13  f =      -688.63  |proj g|=        3.9936
At iterate    14  f =      -688.63  |proj g|=        3.9932
At iterate    15  f =      -688.63  |proj g|=        3.9926
At iterate    16  f =      -688.63  |proj g|=        3.9919
At iterate    17  f =      -688.63  |proj g|=        3.9909
At iterate    18  f =      -688.63  |proj g|=        3.9903
At iterate    19  f =      -688.63  |proj g|=        3.9924
At iterate    20  f =      -688.64  |proj g|=        4.0015
At iterate    21  f =      -688.65  |proj g|=        3.9963
At iterate    22  f =      -688.67  |proj g|=          4.01
At iterate    23  f =      -688.77  |proj g|=        4.0691
At iterate    24  f =      -688.92  |proj g|=        4.1864
At iterate    25  f =      -689.02  |proj g|=        4.1547
At iterate    26  f =      -689.31  |proj g|=        4.3368
At iterate    27  f =      -689.62  |proj g|=        4.5118
At iterate    28  f =      -689.69  |proj g|=         4.478
At iterate    29  f =      -689.69  |proj g|=        4.4093
At iterate    30  f =      -689.69  |proj g|=        4.4148
At iterate    31  f =      -689.69  |proj g|=        4.4147

iterations 31
function evaluations 35
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.41473
final function value -689.694

F = -689.694
final  value -689.694392 
converged
 
INFO  [01:46:11.247] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:46:11.363] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:46:11.373] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:46:14.113] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:46:15.430] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:46:16.877] [mlr3]  Finished benchmark 
INFO  [01:46:16.950] [bbotk] Result of batch 147: 
INFO  [01:46:16.952] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:46:16.952] [bbotk]              8.668418                  4.78811                       0.3242536 
INFO  [01:46:16.952] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:46:16.952] [bbotk]                      403        0.859 -0.9611191         <NA>   0.9679838 
INFO  [01:46:16.952] [bbotk]                                 uhash 
INFO  [01:46:16.952] [bbotk]  06149594-9b61-4ac2-b152-200b6d975a74 
DEBUG [01:46:18.423] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.705024e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.705024e-05 0.002103617 
  - best initial criterion value(s) :  638.9391 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -638.94  |proj g|=        7.032
At iterate     1  f =      -662.03  |proj g|=        2.8606
At iterate     2  f =      -687.11  |proj g|=        2.7482
At iterate     3  f =      -687.19  |proj g|=        2.7172
At iterate     4  f =      -687.19  |proj g|=        2.7166
At iterate     5  f =      -687.19  |proj g|=        2.7165
At iterate     6  f =       -687.2  |proj g|=          2.72
At iterate     7  f =       -687.2  |proj g|=        2.7297
At iterate     8  f =       -687.2  |proj g|=        2.7361
At iterate     9  f =       -687.2  |proj g|=        2.7374
At iterate    10  f =       -687.2  |proj g|=        2.7374
At iterate    11  f =       -687.2  |proj g|=        2.7375
At iterate    12  f =       -687.2  |proj g|=        2.7377
At iterate    13  f =       -687.2  |proj g|=        2.7381
At iterate    14  f =       -687.2  |proj g|=        2.7384
At iterate    15  f =       -687.2  |proj g|=        2.7384
At iterate    16  f =      -687.21  |proj g|=        2.7365
At iterate    17  f =      -687.22  |proj g|=        2.7299
At iterate    18  f =      -687.23  |proj g|=        2.7229
At iterate    19  f =      -687.27  |proj g|=        2.6955
At iterate    20  f =       -687.3  |proj g|=        2.6951
At iterate    21  f =      -687.41  |proj g|=        2.6665
At iterate    22  f =      -688.16  |proj g|=        2.4924
At iterate    23  f =       -689.2  |proj g|=        2.3766
At iterate    24  f =      -691.28  |proj g|=        2.0688
At iterate    25  f =      -692.04  |proj g|=         2.277
At iterate    26  f =      -692.08  |proj g|=        2.3019
At iterate    27  f =      -692.19  |proj g|=        2.3019
At iterate    28  f =      -692.19  |proj g|=        2.3014
At iterate    29  f =      -692.19  |proj g|=        2.3031
At iterate    30  f =      -692.19  |proj g|=        2.3022
At iterate    31  f =      -692.19  |proj g|=         2.302

iterations 31
function evaluations 38
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.302
final function value -692.192

F = -692.192
final  value -692.191988 
converged
 
INFO  [01:46:18.427] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:46:18.499] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:46:18.506] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:46:29.015] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:46:41.450] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:46:51.779] [mlr3]  Finished benchmark 
INFO  [01:46:51.848] [bbotk] Result of batch 148: 
INFO  [01:46:51.850] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:46:51.850] [bbotk]              5.378878                  5.60356                      0.04506777 
INFO  [01:46:51.850] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:46:51.850] [bbotk]                     3704        0.864 -0.9619084         <NA>   0.9679234 
INFO  [01:46:51.850] [bbotk]                                 uhash 
INFO  [01:46:51.850] [bbotk]  1cdc540a-c13a-4b5c-baf8-98c25a92472e 
DEBUG [01:46:53.533] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.695509e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.695509e-05 0.002095727 
  - best initial criterion value(s) :  700.7721 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -700.77  |proj g|=       5.0186
At iterate     1  f =      -701.53  |proj g|=        5.8039
At iterate     2  f =      -702.11  |proj g|=        5.4671
At iterate     3  f =      -704.23  |proj g|=        3.2186
At iterate     4  f =      -704.31  |proj g|=        3.6658
At iterate     5  f =      -704.31  |proj g|=        3.6069
At iterate     6  f =      -704.31  |proj g|=        3.6032
At iterate     7  f =      -704.31  |proj g|=        3.6013
At iterate     8  f =      -704.31  |proj g|=        3.5971
At iterate     9  f =      -704.31  |proj g|=        3.5915
At iterate    10  f =      -704.31  |proj g|=        3.5826
At iterate    11  f =      -704.31  |proj g|=        3.5691
At iterate    12  f =      -704.31  |proj g|=        3.5493
At iterate    13  f =      -704.32  |proj g|=        3.5222
At iterate    14  f =      -704.34  |proj g|=        3.4928
At iterate    15  f =      -704.38  |proj g|=        3.4876
At iterate    16  f =      -704.47  |proj g|=        3.5786
At iterate    17  f =       -704.6  |proj g|=        4.0118
At iterate    18  f =       -704.6  |proj g|=        4.0253
At iterate    19  f =      -704.61  |proj g|=        3.9563
At iterate    20  f =      -704.75  |proj g|=        3.9929
At iterate    21  f =      -705.33  |proj g|=        3.9105
At iterate    22  f =      -707.04  |proj g|=        3.3581
At iterate    23  f =      -709.49  |proj g|=        2.3667
At iterate    24  f =      -712.29  |proj g|=        1.2892
At iterate    25  f =      -712.33  |proj g|=        1.4635
At iterate    26  f =      -714.45  |proj g|=       0.60337
At iterate    27  f =      -715.25  |proj g|=       0.57181
At iterate    28  f =      -715.26  |proj g|=       0.73268
At iterate    29  f =      -715.26  |proj g|=       0.59929
At iterate    30  f =      -715.26  |proj g|=        0.6014
At iterate    31  f =      -715.26  |proj g|=       0.60161

iterations 31
function evaluations 41
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.601605
final function value -715.26

F = -715.26
final  value -715.259796 
converged
 
INFO  [01:46:53.537] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:46:53.644] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:46:53.650] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:47:09.030] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:47:24.396] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:47:38.055] [mlr3]  Finished benchmark 
INFO  [01:47:38.142] [bbotk] Result of batch 149: 
INFO  [01:47:38.144] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:47:38.144] [bbotk]              9.145589                 9.302014                       0.4436233 
INFO  [01:47:38.144] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:47:38.144] [bbotk]                     4968        1.044 -0.9590612         <NA>   0.9781438 
INFO  [01:47:38.144] [bbotk]                                 uhash 
INFO  [01:47:38.144] [bbotk]  6cfc3e70-2661-4da5-81b1-d5594dde7b00 
DEBUG [01:47:39.678] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.690701e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.690701e-05 0.002085676 
  - best initial criterion value(s) :  644.4279 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -644.43  |proj g|=       6.7894
At iterate     1  f =      -665.07  |proj g|=        4.8204
At iterate     2  f =      -666.19  |proj g|=        5.5134
At iterate     3  f =      -666.53  |proj g|=        5.2509
At iterate     4  f =      -666.65  |proj g|=        4.9919
At iterate     5  f =      -666.66  |proj g|=        4.9996
At iterate     6  f =      -666.67  |proj g|=        5.0127
At iterate     7  f =      -666.67  |proj g|=        5.0141
At iterate     8  f =      -666.67  |proj g|=        5.0148
At iterate     9  f =      -666.67  |proj g|=         5.016
At iterate    10  f =      -666.67  |proj g|=        5.0174
At iterate    11  f =      -666.67  |proj g|=        5.0228
At iterate    12  f =      -666.67  |proj g|=        5.0264
At iterate    13  f =      -666.67  |proj g|=        5.0325
At iterate    14  f =      -666.68  |proj g|=        5.0344
At iterate    15  f =      -666.69  |proj g|=        5.0777
At iterate    16  f =      -666.71  |proj g|=        5.0772
At iterate    17  f =      -666.87  |proj g|=        5.0635
At iterate    18  f =      -667.16  |proj g|=        4.9065
At iterate    19  f =      -667.21  |proj g|=        5.0435
At iterate    20  f =      -667.82  |proj g|=        4.6962
At iterate    21  f =      -671.36  |proj g|=        4.2389
At iterate    22  f =      -686.81  |proj g|=        3.3818
At iterate    23  f =      -688.21  |proj g|=        3.4279
At iterate    24  f =       -694.9  |proj g|=        2.7256
At iterate    25  f =       -697.1  |proj g|=        1.2164
At iterate    26  f =      -697.57  |proj g|=        1.2164
At iterate    27  f =      -697.57  |proj g|=        1.2164
At iterate    28  f =      -697.57  |proj g|=        1.2164
At iterate    29  f =      -697.57  |proj g|=        1.2164
At iterate    30  f =      -697.57  |proj g|=        1.2164
At iterate    31  f =      -697.62  |proj g|=        1.2158
At iterate    32  f =      -697.75  |proj g|=        1.2136
At iterate    33  f =      -697.77  |proj g|=         1.213
At iterate    34  f =      -697.77  |proj g|=         1.213
At iterate    35  f =      -697.77  |proj g|=         1.213

iterations 35
function evaluations 45
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.213
final function value -697.773

F = -697.773
final  value -697.773018 
converged
 
INFO  [01:47:39.682] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:47:39.739] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:47:39.746] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:47:42.302] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:47:44.916] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:47:47.225] [mlr3]  Finished benchmark 
INFO  [01:47:47.291] [bbotk] Result of batch 150: 
INFO  [01:47:47.293] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:47:47.293] [bbotk]              4.542345                 9.008088                        0.133637 
INFO  [01:47:47.293] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:47:47.293] [bbotk]                      856        0.862 -0.9600576         <NA>   0.9628084 
INFO  [01:47:47.293] [bbotk]                                 uhash 
INFO  [01:47:47.293] [bbotk]  a267e868-31d4-487b-80c7-b678ec9867fc 
DEBUG [01:47:48.762] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.683448e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.85569 0.9954084 9530 
  - variance bounds :  1.683448e-05 0.002070482 
  - best initial criterion value(s) :  643.9724 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -643.97  |proj g|=       7.8071
At iterate     1  f =      -674.78  |proj g|=        6.4425
At iterate     2  f =      -675.32  |proj g|=        6.6186
At iterate     3  f =      -675.65  |proj g|=         6.435
At iterate     4  f =      -675.76  |proj g|=        6.2332
At iterate     5  f =      -675.77  |proj g|=        6.1999
At iterate     6  f =      -675.78  |proj g|=         6.183
At iterate     7  f =      -675.78  |proj g|=        6.1826
At iterate     8  f =      -675.78  |proj g|=        6.1827
At iterate     9  f =      -675.78  |proj g|=        6.1827
At iterate    10  f =      -675.78  |proj g|=        6.1823
At iterate    11  f =      -675.78  |proj g|=        6.1816
At iterate    12  f =      -675.78  |proj g|=        6.1789
At iterate    13  f =      -675.78  |proj g|=        6.1704
At iterate    14  f =      -675.78  |proj g|=        6.1513
At iterate    15  f =      -675.79  |proj g|=        6.1611
At iterate    16  f =       -675.8  |proj g|=        6.1318
At iterate    17  f =       -675.9  |proj g|=        5.9752
At iterate    18  f =      -676.07  |proj g|=        5.7944
At iterate    19  f =      -676.54  |proj g|=        5.4204
At iterate    20  f =      -677.55  |proj g|=        4.8323
At iterate    21  f =      -679.44  |proj g|=        3.8983
At iterate    22  f =      -682.94  |proj g|=        3.1743
At iterate    23  f =       -685.8  |proj g|=        2.4623
At iterate    24  f =      -705.47  |proj g|=       0.80874
At iterate    25  f =      -710.72  |proj g|=       0.27764
At iterate    26  f =      -713.89  |proj g|=       0.77981
At iterate    27  f =       -713.9  |proj g|=       0.12652
At iterate    28  f =       -713.9  |proj g|=       0.11374
At iterate    29  f =       -713.9  |proj g|=       0.11484
At iterate    30  f =       -713.9  |proj g|=       0.11484

iterations 30
function evaluations 34
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.114836
final function value -713.896

F = -713.896
final  value -713.896157 
converged
 
INFO  [01:47:48.766] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:47:48.821] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:47:48.828] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:47:51.860] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:47:55.176] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:47:58.096] [mlr3]  Finished benchmark 
INFO  [01:47:58.164] [bbotk] Result of batch 151: 
INFO  [01:47:58.166] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:47:58.166] [bbotk]              2.708858                 9.973318                       0.1434687 
INFO  [01:47:58.166] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:47:58.166] [bbotk]                     1165        0.881 -0.9604805         <NA>   0.9538804 
INFO  [01:47:58.166] [bbotk]                                 uhash 
INFO  [01:47:58.166] [bbotk]  cba59075-d73b-45f1-ba14-a5c4d3f4daf8 
DEBUG [01:47:59.660] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.686704e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.686704e-05 0.002069412 
  - best initial criterion value(s) :  658.7447 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -658.74  |proj g|=       9.9652
At iterate     1  f =      -671.66  |proj g|=        9.9922
At iterate     2  f =      -686.48  |proj g|=        7.5518
At iterate     3  f =      -692.26  |proj g|=        6.7395
At iterate     4  f =      -699.64  |proj g|=         4.721
At iterate     5  f =      -701.57  |proj g|=        4.3833
At iterate     6  f =      -701.58  |proj g|=        4.2663
At iterate     7  f =      -701.59  |proj g|=         4.301
At iterate     8  f =      -701.61  |proj g|=         4.265
At iterate     9  f =      -701.71  |proj g|=        4.2012
At iterate    10  f =      -702.13  |proj g|=        4.0024
At iterate    11  f =      -703.05  |proj g|=        3.7091
At iterate    12  f =       -705.9  |proj g|=        3.1012
At iterate    13  f =      -713.49  |proj g|=        2.1679
At iterate    14  f =      -722.79  |proj g|=       0.81582
At iterate    15  f =      -724.61  |proj g|=        1.5532
At iterate    16  f =      -725.52  |proj g|=        2.2008
At iterate    17  f =      -725.71  |proj g|=        2.4936
At iterate    18  f =      -725.76  |proj g|=        2.6474
At iterate    19  f =      -725.79  |proj g|=        2.7262
At iterate    20  f =      -725.86  |proj g|=        2.8463
At iterate    21  f =      -726.06  |proj g|=        3.0263
At iterate    22  f =      -726.55  |proj g|=        3.1938
At iterate    23  f =      -727.12  |proj g|=        2.6186
At iterate    24  f =      -727.28  |proj g|=        2.7966
At iterate    25  f =      -727.29  |proj g|=        2.7951
At iterate    26  f =      -727.29  |proj g|=        2.7994
At iterate    27  f =      -727.29  |proj g|=        2.7998

iterations 27
function evaluations 36
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.79979
final function value -727.291

F = -727.291
final  value -727.290709 
converged
 
INFO  [01:47:59.664] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:47:59.720] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:47:59.727] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:48:14.240] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:48:28.662] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:48:42.673] [mlr3]  Finished benchmark 
INFO  [01:48:42.771] [bbotk] Result of batch 152: 
INFO  [01:48:42.773] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:48:42.773] [bbotk]              9.745615                 9.012359                      0.08517581 
INFO  [01:48:42.773] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:48:42.773] [bbotk]                     4835         0.88 -0.9615542         <NA>   0.9738866 
INFO  [01:48:42.773] [bbotk]                                 uhash 
INFO  [01:48:42.773] [bbotk]  3649b187-6fdf-4d8b-aaf5-de6ae5b14b77 
DEBUG [01:48:44.231] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.678787e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.678787e-05 0.002062685 
  - best initial criterion value(s) :  724.3082 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -724.31  |proj g|=       1.6426
At iterate     1  f =      -730.25  |proj g|=        2.1055
At iterate     2  f =      -738.01  |proj g|=        2.6359
At iterate     3  f =      -740.81  |proj g|=        2.5071
At iterate     4  f =      -740.84  |proj g|=        2.5131
At iterate     5  f =      -740.84  |proj g|=        2.5136
At iterate     6  f =      -740.84  |proj g|=        2.5135
At iterate     7  f =      -740.84  |proj g|=        2.5134

iterations 7
function evaluations 12
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.51342
final function value -740.838

F = -740.838
final  value -740.838008 
converged
 
INFO  [01:48:44.235] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:48:44.290] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:48:44.297] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:48:59.500] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:49:14.220] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:49:28.518] [mlr3]  Finished benchmark 
INFO  [01:49:28.588] [bbotk] Result of batch 153: 
INFO  [01:49:28.589] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:49:28.589] [bbotk]              2.265092                  4.02248                       0.3462603 
INFO  [01:49:28.589] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:49:28.589] [bbotk]                     4817        1.059 -0.9569547         <NA>   0.9686006 
INFO  [01:49:28.589] [bbotk]                                 uhash 
INFO  [01:49:28.589] [bbotk]  a1f28f32-6a00-4c37-a1dc-612d0fc6b6c8 
DEBUG [01:49:30.039] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.66962e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.66962e-05 0.002051528 
  - best initial criterion value(s) :  682.9777 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -682.98  |proj g|=       10.806
At iterate     1  f =      -710.18  |proj g|=        4.2059
At iterate     2  f =      -712.34  |proj g|=        6.4729
At iterate     3  f =      -712.71  |proj g|=        6.0335
At iterate     4  f =      -712.78  |proj g|=        5.8752
At iterate     5  f =      -712.82  |proj g|=        5.8998
At iterate     6  f =      -712.88  |proj g|=        6.0994
At iterate     7  f =       -712.9  |proj g|=        6.2364
At iterate     8  f =      -713.21  |proj g|=        6.3141
At iterate     9  f =      -715.63  |proj g|=        6.2176
At iterate    10  f =       -719.9  |proj g|=        6.4097
At iterate    11  f =      -733.64  |proj g|=        4.2688
At iterate    12  f =      -747.22  |proj g|=        2.7675
At iterate    13  f =      -748.92  |proj g|=        2.4925
At iterate    14  f =      -751.51  |proj g|=          1.58
At iterate    15  f =      -752.35  |proj g|=        1.1005
At iterate    16  f =      -752.81  |proj g|=        1.5512
At iterate    17  f =      -752.83  |proj g|=         1.511
At iterate    18  f =      -752.83  |proj g|=        1.4967
At iterate    19  f =      -752.83  |proj g|=        1.5011
At iterate    20  f =      -752.83  |proj g|=        1.5008

iterations 20
function evaluations 28
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.50076
final function value -752.831

F = -752.831
final  value -752.830625 
converged
 
INFO  [01:49:30.043] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:49:30.103] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:49:30.110] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:49:37.382] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:49:45.609] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:49:53.885] [mlr3]  Finished benchmark 
INFO  [01:49:53.956] [bbotk] Result of batch 154: 
INFO  [01:49:53.958] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:49:53.958] [bbotk]              7.641846                 2.241686                       0.1025486 
INFO  [01:49:53.958] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [01:49:53.958] [bbotk]                     2818        0.891 -0.955275         <NA>   0.9733215 
INFO  [01:49:53.958] [bbotk]                                 uhash 
INFO  [01:49:53.958] [bbotk]  dfdc1b37-8df4-4159-bc52-7571d01bfd90 
DEBUG [01:49:55.925] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.661583e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.661583e-05 0.002044768 
  - best initial criterion value(s) :  684.3614 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -684.36  |proj g|=       3.4027
At iterate     1  f =      -698.87  |proj g|=        6.9624
At iterate     2  f =      -702.36  |proj g|=        6.8276
At iterate     3  f =      -707.31  |proj g|=        6.1458
At iterate     4  f =      -708.16  |proj g|=        5.3574
At iterate     5  f =      -710.06  |proj g|=        5.5677
At iterate     6  f =      -713.58  |proj g|=         5.243
At iterate     7  f =      -714.15  |proj g|=        4.8684
At iterate     8  f =      -714.22  |proj g|=        4.8698
At iterate     9  f =      -714.22  |proj g|=        4.8872
At iterate    10  f =      -714.22  |proj g|=          4.88
At iterate    11  f =      -714.22  |proj g|=        4.8812
At iterate    12  f =      -714.25  |proj g|=        4.8941
At iterate    13  f =      -714.46  |proj g|=         4.922
At iterate    14  f =      -714.92  |proj g|=        4.8748
At iterate    15  f =      -715.67  |proj g|=         4.526
At iterate    16  f =      -716.42  |proj g|=        4.9164
At iterate    17  f =      -717.23  |proj g|=        4.5073
At iterate    18  f =      -718.24  |proj g|=         4.133
At iterate    19  f =      -718.81  |proj g|=        4.5362
At iterate    20  f =      -718.97  |proj g|=         5.501
At iterate    21  f =      -718.97  |proj g|=        5.3394
At iterate    22  f =      -718.97  |proj g|=        5.3315
At iterate    23  f =      -718.97  |proj g|=         5.336
At iterate    24  f =      -718.97  |proj g|=        5.3319
At iterate    25  f =      -718.97  |proj g|=        5.3312
At iterate    26  f =      -718.97  |proj g|=        5.3267
At iterate    27  f =      -718.97  |proj g|=        5.3092
At iterate    28  f =      -718.97  |proj g|=        5.2898
At iterate    29  f =      -718.98  |proj g|=        5.2584
At iterate    30  f =      -718.98  |proj g|=        5.2231
At iterate    31  f =      -718.98  |proj g|=        5.1929
At iterate    32  f =      -718.99  |proj g|=        5.1089
At iterate    33  f =      -719.02  |proj g|=        5.0181
At iterate    34  f =      -719.07  |proj g|=        4.9403
At iterate    35  f =      -719.11  |proj g|=        4.9663
At iterate    36  f =      -719.11  |proj g|=        4.9622
At iterate    37  f =      -719.13  |proj g|=        5.0782
At iterate    38  f =      -719.14  |proj g|=        5.1702
At iterate    39  f =      -719.14  |proj g|=        5.1768
At iterate    40  f =      -719.14  |proj g|=        5.1902
At iterate    41  f =      -719.14  |proj g|=        5.2072
At iterate    42  f =      -719.14  |proj g|=        5.2856
At iterate    43  f =      -719.15  |proj g|=        5.2783
At iterate    44  f =      -719.15  |proj g|=        5.2635
At iterate    45  f =      -719.22  |proj g|=        5.1426
At iterate    46  f =      -719.29  |proj g|=        5.0024
At iterate    47  f =      -719.41  |proj g|=        4.9361
At iterate    48  f =       -719.7  |proj g|=        4.6103
At iterate    49  f =      -720.69  |proj g|=        4.2371
At iterate    50  f =      -720.81  |proj g|=        3.7568
At iterate    51  f =      -722.59  |proj g|=        3.2463
At iterate    52  f =      -725.03  |proj g|=        3.7741
At iterate    53  f =      -729.66  |proj g|=        3.1832
At iterate    54  f =      -736.01  |proj g|=        2.4405
At iterate    55  f =      -743.92  |proj g|=       0.26291
At iterate    56  f =      -745.05  |proj g|=       0.42518
At iterate    57  f =      -745.38  |proj g|=       0.22657
At iterate    58  f =      -745.43  |proj g|=       0.77812
At iterate    59  f =      -745.44  |proj g|=       0.14661
At iterate    60  f =      -745.44  |proj g|=      0.023749
At iterate    61  f =      -745.44  |proj g|=      0.023744
At iterate    62  f =      -745.44  |proj g|=      0.023744

iterations 62
function evaluations 80
segments explored during Cauchy searches 64
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.023744
final function value -745.436

F = -745.436
final  value -745.436315 
converged
 
INFO  [01:49:55.929] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:49:56.006] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:49:56.017] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:50:11.783] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:50:24.395] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:50:35.717] [mlr3]  Finished benchmark 
INFO  [01:50:35.787] [bbotk] Result of batch 155: 
INFO  [01:50:35.789] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:50:35.789] [bbotk]              9.752756                 5.541068                       0.3864533 
INFO  [01:50:35.789] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:50:35.789] [bbotk]                     4275        0.891 -0.9575618         <NA>    0.977966 
INFO  [01:50:35.789] [bbotk]                                 uhash 
INFO  [01:50:35.789] [bbotk]  cf85ca43-c3dd-424d-9564-d603409805f8 
DEBUG [01:50:37.397] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.656959e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.656959e-05 0.002045854 
  - best initial criterion value(s) :  607.7036 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -607.7  |proj g|=       14.877
At iterate     1  f =      -645.14  |proj g|=        12.891
At iterate     2  f =      -671.92  |proj g|=        9.8232
At iterate     3  f =      -676.27  |proj g|=        7.6859
At iterate     4  f =      -680.05  |proj g|=        5.7356
At iterate     5  f =      -681.11  |proj g|=        4.8604
At iterate     6  f =      -681.51  |proj g|=        4.4165
At iterate     7  f =      -681.78  |proj g|=        4.8494
At iterate     8  f =      -681.87  |proj g|=        4.5362
At iterate     9  f =      -682.54  |proj g|=        4.1862
At iterate    10  f =      -684.81  |proj g|=        3.6813
At iterate    11  f =      -690.77  |proj g|=        3.0019
At iterate    12  f =      -699.06  |proj g|=        2.0779
At iterate    13  f =      -706.96  |proj g|=        1.2906
At iterate    14  f =      -712.92  |proj g|=       0.39742
At iterate    15  f =      -717.49  |proj g|=       0.67584
At iterate    16  f =      -721.86  |proj g|=       0.86244
At iterate    17  f =      -722.35  |proj g|=       0.37912
At iterate    18  f =      -722.36  |proj g|=       0.77165
At iterate    19  f =      -722.36  |proj g|=       0.41439
At iterate    20  f =      -722.36  |proj g|=       0.41605
At iterate    21  f =      -722.36  |proj g|=        0.4163

iterations 21
function evaluations 30
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.416303
final function value -722.364

F = -722.364
final  value -722.364464 
converged
 
INFO  [01:50:37.401] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:50:37.460] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:50:37.467] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:50:41.597] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:50:44.717] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:50:48.481] [mlr3]  Finished benchmark 
INFO  [01:50:48.553] [bbotk] Result of batch 156: 
INFO  [01:50:48.555] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:50:48.555] [bbotk]              2.165184                 9.236065                       0.3791461 
INFO  [01:50:48.555] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [01:50:48.555] [bbotk]                     1243        0.869 -0.961966         <NA>   0.9586481 
INFO  [01:50:48.555] [bbotk]                                 uhash 
INFO  [01:50:48.555] [bbotk]  48653389-c317-40b3-9f32-200542846d6a 
DEBUG [01:50:50.118] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.653795e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.653794e-05 0.002036759 
  - best initial criterion value(s) :  704.8524 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -704.85  |proj g|=       12.039
At iterate     1  f =      -725.15  |proj g|=        10.135
At iterate     2  f =      -728.78  |proj g|=        8.7271
At iterate     3  f =      -737.91  |proj g|=        3.1147
At iterate     4  f =      -738.24  |proj g|=        3.5446
At iterate     5  f =      -738.31  |proj g|=        3.3101
At iterate     6  f =      -738.32  |proj g|=        3.2926
At iterate     7  f =      -738.33  |proj g|=         3.285
At iterate     8  f =      -738.34  |proj g|=        3.2771
At iterate     9  f =      -738.38  |proj g|=        3.2518
At iterate    10  f =      -738.49  |proj g|=         3.233
At iterate    11  f =      -738.53  |proj g|=        3.1409
At iterate    12  f =      -738.85  |proj g|=        3.1389
At iterate    13  f =      -743.92  |proj g|=        3.4462
At iterate    14  f =      -755.17  |proj g|=        3.5689
At iterate    15  f =      -760.29  |proj g|=        3.4659
At iterate    16  f =      -760.87  |proj g|=        3.4905
At iterate    17  f =      -761.32  |proj g|=        3.8487
At iterate    18  f =      -761.59  |proj g|=        3.8182
At iterate    19  f =       -761.6  |proj g|=        3.8065
At iterate    20  f =       -761.6  |proj g|=        3.7965
At iterate    21  f =       -761.6  |proj g|=        3.8012
At iterate    22  f =       -761.6  |proj g|=        3.7971
At iterate    23  f =       -761.6  |proj g|=        3.7931
At iterate    24  f =       -761.6  |proj g|=        3.7794
At iterate    25  f =      -761.62  |proj g|=        3.7598
At iterate    26  f =      -761.67  |proj g|=        3.7202
At iterate    27  f =      -761.76  |proj g|=        3.6909
At iterate    28  f =      -761.92  |proj g|=        3.7003
At iterate    29  f =      -762.09  |proj g|=        3.9005
At iterate    30  f =       -762.1  |proj g|=        3.8844
At iterate    31  f =       -762.1  |proj g|=        3.8812
At iterate    32  f =       -762.1  |proj g|=        3.8813

iterations 32
function evaluations 38
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.88126
final function value -762.098

F = -762.098
final  value -762.098269 
converged
 
INFO  [01:50:50.122] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:50:50.212] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:50:50.220] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:50:53.219] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:50:55.853] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:50:59.016] [mlr3]  Finished benchmark 
INFO  [01:50:59.084] [bbotk] Result of batch 157: 
INFO  [01:50:59.086] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:50:59.086] [bbotk]              3.169636                 2.717118                       0.1671004 
INFO  [01:50:59.086] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:50:59.086] [bbotk]                      889        0.905 -0.9493218         <NA>   0.9593942 
INFO  [01:50:59.086] [bbotk]                                 uhash 
INFO  [01:50:59.086] [bbotk]  32c35376-7ac7-41d9-a1e7-6433ebbdf64a 
DEBUG [01:51:00.886] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.649814e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.649814e-05 0.002027194 
  - best initial criterion value(s) :  672.2435 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -672.24  |proj g|=       1.4943
At iterate     1  f =      -740.68  |proj g|=         4.246
At iterate     2  f =      -760.84  |proj g|=        5.3624
At iterate     3  f =      -763.81  |proj g|=        4.8236
At iterate     4  f =      -767.83  |proj g|=        3.0957
At iterate     5  f =      -768.14  |proj g|=        2.6577
At iterate     6  f =      -768.74  |proj g|=        2.4746
At iterate     7  f =      -769.72  |proj g|=        2.4504
At iterate     8  f =      -769.84  |proj g|=        2.9738
At iterate     9  f =      -769.87  |proj g|=        2.8139
At iterate    10  f =      -769.87  |proj g|=        2.7895
At iterate    11  f =      -769.87  |proj g|=        2.7918
At iterate    12  f =      -769.87  |proj g|=        2.7947
At iterate    13  f =      -769.87  |proj g|=        2.8044
At iterate    14  f =      -769.87  |proj g|=        2.8156
At iterate    15  f =      -769.87  |proj g|=         2.835
At iterate    16  f =      -769.88  |proj g|=        2.8664
At iterate    17  f =      -769.89  |proj g|=        2.9149
At iterate    18  f =      -769.93  |proj g|=        2.9818
At iterate    19  f =         -770  |proj g|=         3.053
At iterate    20  f =      -770.15  |proj g|=        3.0591
At iterate    21  f =      -770.32  |proj g|=        2.8815
At iterate    22  f =      -770.42  |proj g|=         2.729
At iterate    23  f =      -770.57  |proj g|=        2.4727
At iterate    24  f =      -770.78  |proj g|=         2.253
At iterate    25  f =       -771.6  |proj g|=        1.7051
At iterate    26  f =      -773.58  |proj g|=       0.87528
At iterate    27  f =      -775.15  |proj g|=         1.028
At iterate    28  f =      -776.29  |proj g|=        1.8033
At iterate    29  f =      -776.38  |proj g|=        2.0291
At iterate    30  f =      -776.39  |proj g|=         2.088
At iterate    31  f =      -776.39  |proj g|=        2.0988
At iterate    32  f =      -776.41  |proj g|=        2.1659
At iterate    33  f =      -776.44  |proj g|=        2.2171
At iterate    34  f =      -776.49  |proj g|=         2.248
At iterate    35  f =      -776.52  |proj g|=        2.2035
At iterate    36  f =      -776.53  |proj g|=         2.143
At iterate    37  f =      -776.53  |proj g|=        2.1203
At iterate    38  f =      -776.53  |proj g|=        2.1182
At iterate    39  f =      -776.53  |proj g|=        2.1184

iterations 39
function evaluations 44
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.11835
final function value -776.527

F = -776.527
final  value -776.527267 
converged
 
INFO  [01:51:00.890] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:51:00.946] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:51:00.953] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:51:14.844] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:51:28.537] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:51:42.305] [mlr3]  Finished benchmark 
INFO  [01:51:42.372] [bbotk] Result of batch 158: 
INFO  [01:51:42.374] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:51:42.374] [bbotk]              7.941337                 9.677668                       0.1542591 
INFO  [01:51:42.374] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:51:42.374] [bbotk]                     4559        0.908 -0.9481461         <NA>   0.9765567 
INFO  [01:51:42.374] [bbotk]                                 uhash 
INFO  [01:51:42.374] [bbotk]  2adb1289-4100-42ee-9ead-dcf5aeecff72 
DEBUG [01:51:43.802] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.644136e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.644136e-05 0.002025326 
  - best initial criterion value(s) :  676.4181 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -676.42  |proj g|=       8.7847
At iterate     1  f =      -702.91  |proj g|=          4.17
At iterate     2  f =      -729.79  |proj g|=        4.1279
At iterate     3  f =         -730  |proj g|=        4.0695
At iterate     4  f =         -730  |proj g|=        4.0666
At iterate     5  f =         -730  |proj g|=        4.0684
At iterate     6  f =         -730  |proj g|=        4.0885
At iterate     7  f =      -730.02  |proj g|=        4.0933
At iterate     8  f =      -730.11  |proj g|=        4.1005
At iterate     9  f =      -730.33  |proj g|=        4.1022
At iterate    10  f =      -730.94  |proj g|=        4.1094
At iterate    11  f =      -732.42  |proj g|=        4.0532
At iterate    12  f =      -735.44  |proj g|=        3.8574
At iterate    13  f =      -737.75  |proj g|=        3.1193
At iterate    14  f =      -740.85  |proj g|=        3.1977
At iterate    15  f =      -741.69  |proj g|=        3.2858
At iterate    16  f =      -742.48  |proj g|=        3.2762
At iterate    17  f =      -742.57  |proj g|=        3.2373
At iterate    18  f =       -742.6  |proj g|=        3.1869
At iterate    19  f =       -742.6  |proj g|=        3.1993
At iterate    20  f =       -742.6  |proj g|=        3.1986
At iterate    21  f =       -742.6  |proj g|=        3.1985

iterations 21
function evaluations 27
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.19849
final function value -742.597

F = -742.597
final  value -742.596814 
converged
 
INFO  [01:51:43.806] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:51:43.864] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:51:43.871] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:51:51.673] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:51:58.447] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:52:07.755] [mlr3]  Finished benchmark 
INFO  [01:52:07.824] [bbotk] Result of batch 159: 
INFO  [01:52:07.826] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:52:07.826] [bbotk]              6.553035                 9.247519                       0.2298357 
INFO  [01:52:07.826] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:52:07.826] [bbotk]                     2803        0.889 -0.9615147         <NA>   0.9764145 
INFO  [01:52:07.826] [bbotk]                                 uhash 
INFO  [01:52:07.826] [bbotk]  d220b677-6536-427a-87b2-57e0ea4f6b44 
DEBUG [01:52:09.385] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.638373e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.638373e-05 0.002021783 
  - best initial criterion value(s) :  737.6926 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -737.69  |proj g|=       3.1444
At iterate     1  f =      -749.75  |proj g|=        9.0178
At iterate     2  f =      -750.39  |proj g|=        8.6816
At iterate     3  f =      -750.79  |proj g|=        7.7247
At iterate     4  f =      -750.85  |proj g|=         8.044
At iterate     5  f =      -750.86  |proj g|=        7.9943
At iterate     6  f =      -750.86  |proj g|=        7.9261
At iterate     7  f =      -750.88  |proj g|=        7.7974
At iterate     8  f =      -750.91  |proj g|=         7.612
At iterate     9  f =      -750.94  |proj g|=        7.4703
At iterate    10  f =      -750.95  |proj g|=        7.4696
At iterate    11  f =      -750.95  |proj g|=        7.5057
At iterate    12  f =      -750.95  |proj g|=        7.5175
At iterate    13  f =      -750.95  |proj g|=        7.5232
At iterate    14  f =      -750.95  |proj g|=        7.5437
At iterate    15  f =      -750.96  |proj g|=        7.5691
At iterate    16  f =      -750.96  |proj g|=        7.6132
At iterate    17  f =      -750.97  |proj g|=        7.6837
At iterate    18  f =      -750.99  |proj g|=        7.8037
At iterate    19  f =      -751.04  |proj g|=        7.9887
At iterate    20  f =      -751.13  |proj g|=        8.2132
At iterate    21  f =      -751.26  |proj g|=         8.415
At iterate    22  f =      -751.27  |proj g|=        8.2563
At iterate    23  f =      -751.48  |proj g|=        8.5434
At iterate    24  f =      -752.08  |proj g|=        8.7346
At iterate    25  f =      -755.04  |proj g|=        8.3949
At iterate    26  f =      -762.79  |proj g|=         5.906
At iterate    27  f =      -771.34  |proj g|=        3.2787
At iterate    28  f =      -771.38  |proj g|=        2.9454
At iterate    29  f =      -771.64  |proj g|=        2.9861
At iterate    30  f =      -771.87  |proj g|=        2.7725
At iterate    31  f =      -771.88  |proj g|=        2.8337
At iterate    32  f =      -771.88  |proj g|=        2.8201
At iterate    33  f =      -771.88  |proj g|=          2.82

iterations 33
function evaluations 38
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.82
final function value -771.878

F = -771.878
final  value -771.878045 
converged
 
INFO  [01:52:09.389] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:52:09.461] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:52:09.468] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:52:24.790] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:52:38.416] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:52:52.430] [mlr3]  Finished benchmark 
INFO  [01:52:52.498] [bbotk] Result of batch 160: 
INFO  [01:52:52.500] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:52:52.500] [bbotk]              3.291204                 6.246543                       0.2603515 
INFO  [01:52:52.500] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:52:52.500] [bbotk]                     4930        0.891 -0.9593571         <NA>   0.9750018 
INFO  [01:52:52.500] [bbotk]                                 uhash 
INFO  [01:52:52.500] [bbotk]  ed92ac58-d6ad-4c85-b020-dfff5ab06e75 
DEBUG [01:52:54.397] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.631645e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.631645e-05 0.002014355 
  - best initial criterion value(s) :  676.0096 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -676.01  |proj g|=       3.0267
At iterate     1  f =       -676.8  |proj g|=        4.5116
At iterate     2  f =       -680.5  |proj g|=        4.2596
At iterate     3  f =      -682.08  |proj g|=        3.9537
At iterate     4  f =      -682.67  |proj g|=        3.6296
At iterate     5  f =      -685.36  |proj g|=        3.1897
At iterate     6  f =      -687.87  |proj g|=        2.8859
At iterate     7  f =      -687.88  |proj g|=        2.8677
At iterate     8  f =      -687.88  |proj g|=        2.8753
At iterate     9  f =      -687.88  |proj g|=        2.8737
At iterate    10  f =      -687.88  |proj g|=         2.874
At iterate    11  f =      -687.88  |proj g|=        2.8743
At iterate    12  f =      -687.88  |proj g|=        2.8748
At iterate    13  f =      -687.88  |proj g|=        2.8756
At iterate    14  f =      -687.88  |proj g|=        2.8769
At iterate    15  f =      -687.89  |proj g|=        2.8789
At iterate    16  f =      -687.89  |proj g|=         2.882
At iterate    17  f =      -687.89  |proj g|=         2.887
At iterate    18  f =      -687.89  |proj g|=         2.895
At iterate    19  f =       -687.9  |proj g|=         2.908
At iterate    20  f =      -687.93  |proj g|=        2.9285
At iterate    21  f =      -687.99  |proj g|=        2.9579
At iterate    22  f =      -688.14  |proj g|=        2.9889
At iterate    23  f =      -688.38  |proj g|=        2.9815
At iterate    24  f =      -688.53  |proj g|=        2.8682
At iterate    25  f =      -688.53  |proj g|=         2.887
At iterate    26  f =      -688.54  |proj g|=         2.888
At iterate    27  f =      -688.54  |proj g|=        2.8994
At iterate    28  f =      -688.57  |proj g|=        2.9128
At iterate    29  f =      -688.66  |proj g|=        2.9281
At iterate    30  f =      -688.87  |proj g|=        2.9237
At iterate    31  f =      -689.38  |proj g|=        2.8459
At iterate    32  f =      -690.33  |proj g|=         2.621
At iterate    33  f =      -691.48  |proj g|=        2.3244
At iterate    34  f =      -691.54  |proj g|=        2.2827
At iterate    35  f =      -692.95  |proj g|=        1.9733
At iterate    36  f =      -697.48  |proj g|=        1.5572
At iterate    37  f =      -699.41  |proj g|=        1.5479
At iterate    38  f =      -699.59  |proj g|=        2.3713
At iterate    39  f =      -700.08  |proj g|=        1.8956
At iterate    40  f =      -700.14  |proj g|=        1.8363
At iterate    41  f =      -700.14  |proj g|=        1.8952
At iterate    42  f =      -700.15  |proj g|=         1.868
At iterate    43  f =      -700.15  |proj g|=        1.8698
At iterate    44  f =      -700.15  |proj g|=        1.8698

iterations 44
function evaluations 52
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.86979
final function value -700.146

F = -700.146
final  value -700.145787 
converged
 
INFO  [01:52:54.406] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:52:54.459] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:52:54.466] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:53:07.538] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:53:23.346] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:53:38.899] [mlr3]  Finished benchmark 
INFO  [01:53:38.974] [bbotk] Result of batch 161: 
INFO  [01:53:38.975] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:53:38.975] [bbotk]              3.963349                 3.206786                       0.3174305 
INFO  [01:53:38.975] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:53:38.975] [bbotk]                     4800        1.062 -0.9683547         <NA>    0.976783 
INFO  [01:53:38.975] [bbotk]                                 uhash 
INFO  [01:53:38.975] [bbotk]  228267e0-f316-4dee-a2ed-ce903a8f73ca 
DEBUG [01:53:40.316] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.626244e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.626244e-05 0.002012558 
  - best initial criterion value(s) :  714.8303 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -714.83  |proj g|=       3.7867
At iterate     1  f =      -731.72  |proj g|=         4.245
At iterate     2  f =      -737.99  |proj g|=        3.6709
At iterate     3  f =      -746.43  |proj g|=        2.6987
At iterate     4  f =      -746.68  |proj g|=        2.6054
At iterate     5  f =      -747.13  |proj g|=        2.5692
At iterate     6  f =      -747.57  |proj g|=        2.5371
At iterate     7  f =      -747.62  |proj g|=        2.5729
At iterate     8  f =      -747.64  |proj g|=        2.5649
At iterate     9  f =      -747.64  |proj g|=        2.5667
At iterate    10  f =      -747.64  |proj g|=        2.5667

iterations 10
function evaluations 16
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.56668
final function value -747.639

F = -747.639
final  value -747.639448 
converged
 
INFO  [01:53:40.320] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:53:40.377] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:53:40.384] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:53:51.762] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:54:03.756] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:54:17.159] [mlr3]  Finished benchmark 
INFO  [01:54:17.228] [bbotk] Result of batch 162: 
INFO  [01:54:17.229] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:54:17.229] [bbotk]              7.366654                 9.294099                       0.2027881 
INFO  [01:54:17.229] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:54:17.229] [bbotk]                     4296        0.898 -0.9627945         <NA>   0.9772689 
INFO  [01:54:17.229] [bbotk]                                 uhash 
INFO  [01:54:17.229] [bbotk]  d04399b3-a6ba-400c-8abe-ff21ab932c34 
DEBUG [01:54:18.556] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.621267e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.621267e-05 0.00201182 
  - best initial criterion value(s) :  719.6301 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -719.63  |proj g|=       3.3272
At iterate     1  f =      -751.83  |proj g|=        3.5571
At iterate     2  f =      -756.28  |proj g|=        4.0798
At iterate     3  f =       -757.3  |proj g|=        3.9886
At iterate     4  f =      -757.97  |proj g|=        3.7292
At iterate     5  f =      -758.07  |proj g|=        3.8096
At iterate     6  f =      -758.07  |proj g|=        3.7959
At iterate     7  f =      -758.07  |proj g|=        3.7894
At iterate     8  f =      -758.07  |proj g|=        3.7872
At iterate     9  f =      -758.07  |proj g|=        3.7894
At iterate    10  f =      -758.07  |proj g|=        3.7887
At iterate    11  f =      -758.07  |proj g|=        3.7887

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.78865
final function value -758.075

F = -758.075
final  value -758.074750 
converged
 
INFO  [01:54:18.560] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:54:18.615] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:54:18.622] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:54:26.941] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:54:35.190] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:54:43.517] [mlr3]  Finished benchmark 
INFO  [01:54:43.597] [bbotk] Result of batch 163: 
INFO  [01:54:43.599] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:54:43.599] [bbotk]              6.409005                 3.086526                        0.202517 
INFO  [01:54:43.599] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [01:54:43.599] [bbotk]                     4085        0.903 -0.960769         <NA>   0.9771448 
INFO  [01:54:43.599] [bbotk]                                 uhash 
INFO  [01:54:43.599] [bbotk]  586f339c-de65-4cb0-9380-4fb2d4f5d827 
DEBUG [01:54:45.295] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.616203e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.616203e-05 0.002011917 
  - best initial criterion value(s) :  693.8796 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -693.88  |proj g|=       4.9321
At iterate     1  f =      -735.89  |proj g|=        2.1591
At iterate     2  f =      -763.02  |proj g|=        3.6804
At iterate     3  f =      -766.18  |proj g|=        5.2388
At iterate     4  f =      -767.32  |proj g|=        5.8764
At iterate     5  f =      -768.51  |proj g|=        6.2008
At iterate     6  f =      -769.62  |proj g|=        6.1572
At iterate     7  f =      -770.02  |proj g|=         5.837
At iterate     8  f =      -770.06  |proj g|=        6.0559
At iterate     9  f =      -770.09  |proj g|=        5.9271
At iterate    10  f =      -770.09  |proj g|=        5.9106
At iterate    11  f =      -770.46  |proj g|=        5.8268
At iterate    12  f =      -772.64  |proj g|=        5.2965
At iterate    13  f =      -773.68  |proj g|=        4.6583
At iterate    14  f =      -782.42  |proj g|=        2.8275
At iterate    15  f =      -804.63  |proj g|=         1.416
At iterate    16  f =      -808.08  |proj g|=        1.0133
At iterate    17  f =      -808.15  |proj g|=        1.0133
At iterate    18  f =      -808.23  |proj g|=        1.0134
At iterate    19  f =      -808.28  |proj g|=        1.0135
At iterate    20  f =      -808.28  |proj g|=        1.0135
At iterate    21  f =      -808.28  |proj g|=        1.0135

iterations 21
function evaluations 30
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 1.01345
final function value -808.28

F = -808.28
final  value -808.280465 
converged
 
INFO  [01:54:45.300] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:54:45.365] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:54:45.374] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:54:49.710] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:54:54.118] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:54:58.405] [mlr3]  Finished benchmark 
INFO  [01:54:58.477] [bbotk] Result of batch 164: 
INFO  [01:54:58.479] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:54:58.479] [bbotk]              2.442554                 5.908458                       0.0273995 
INFO  [01:54:58.479] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:54:58.479] [bbotk]                     2244         1.08 -0.9388332         <NA>   0.9317849 
INFO  [01:54:58.479] [bbotk]                                 uhash 
INFO  [01:54:58.479] [bbotk]  bd720250-e0db-469f-a890-321fd26de03c 
DEBUG [01:55:00.546] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.679436e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.679436e-05 0.002060013 
  - best initial criterion value(s) :  702.4735 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -702.47  |proj g|=       11.861
At iterate     1  f =      -741.78  |proj g|=        6.8265
At iterate     2  f =       -744.6  |proj g|=         6.789
At iterate     3  f =      -746.58  |proj g|=        6.1016
At iterate     4  f =       -747.3  |proj g|=        5.5722
At iterate     5  f =      -747.52  |proj g|=        5.3728
At iterate     6  f =       -747.7  |proj g|=        5.2689
At iterate     7  f =      -747.78  |proj g|=        5.2889
At iterate     8  f =      -747.79  |proj g|=        5.2644
At iterate     9  f =      -747.79  |proj g|=        5.2562
At iterate    10  f =      -747.79  |proj g|=        5.2533
At iterate    11  f =      -747.79  |proj g|=         5.252
At iterate    12  f =      -747.79  |proj g|=        5.2498
At iterate    13  f =       -747.8  |proj g|=        5.2434
At iterate    14  f =       -747.8  |proj g|=        5.2292
At iterate    15  f =      -747.82  |proj g|=         5.199
At iterate    16  f =      -747.85  |proj g|=        5.1265
At iterate    17  f =      -747.91  |proj g|=        5.0834
At iterate    18  f =      -748.05  |proj g|=        4.8627
At iterate    19  f =      -748.12  |proj g|=        4.9135
At iterate    20  f =      -748.43  |proj g|=        4.5216
At iterate    21  f =      -748.97  |proj g|=        4.0558
At iterate    22  f =      -750.51  |proj g|=        3.5898
At iterate    23  f =      -762.17  |proj g|=        3.3054
At iterate    24  f =      -775.93  |proj g|=        2.9191
At iterate    25  f =      -780.97  |proj g|=        2.5955
At iterate    26  f =      -784.08  |proj g|=        2.4058
At iterate    27  f =      -784.96  |proj g|=          2.02
At iterate    28  f =      -785.12  |proj g|=          2.02
At iterate    29  f =      -785.14  |proj g|=          2.02
At iterate    30  f =      -785.14  |proj g|=          2.02
At iterate    31  f =      -785.14  |proj g|=          2.02
At iterate    32  f =      -785.14  |proj g|=          2.02
At iterate    33  f =      -785.14  |proj g|=          2.02
At iterate    34  f =      -785.14  |proj g|=          2.02
At iterate    35  f =      -785.14  |proj g|=          2.02
At iterate    36  f =      -785.14  |proj g|=          2.02
At iterate    37  f =      -785.14  |proj g|=          2.02
At iterate    38  f =      -785.15  |proj g|=        2.0199
At iterate    39  f =      -785.16  |proj g|=        2.0197
At iterate    40  f =      -785.18  |proj g|=        2.0192
At iterate    41  f =      -785.23  |proj g|=        2.0182
At iterate    42  f =      -785.31  |proj g|=        2.0164
At iterate    43  f =      -785.36  |proj g|=        2.0163
At iterate    44  f =      -785.37  |proj g|=        2.0154
At iterate    45  f =      -785.37  |proj g|=        2.0155
At iterate    46  f =      -785.37  |proj g|=        2.0155

iterations 46
function evaluations 54
segments explored during Cauchy searches 50
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.01552
final function value -785.369

F = -785.369
final  value -785.369452 
converged
 
INFO  [01:55:00.551] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:55:00.606] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:55:00.613] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:55:07.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:55:13.443] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:55:20.202] [mlr3]  Finished benchmark 
INFO  [01:55:20.296] [bbotk] Result of batch 165: 
INFO  [01:55:20.299] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:55:20.299] [bbotk]               9.71018                  6.51786                       0.4899493 
INFO  [01:55:20.299] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:55:20.299] [bbotk]                     3554        1.165 -0.9534495         <NA>   0.9777579 
INFO  [01:55:20.299] [bbotk]                                 uhash 
INFO  [01:55:20.299] [bbotk]  9e029b15-ac59-490a-aa88-6a431ffbce98 
DEBUG [01:55:21.982] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.674782e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.674782e-05 0.002059553 
  - best initial criterion value(s) :  765.9627 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -765.96  |proj g|=       3.6185
At iterate     1  f =       -778.4  |proj g|=        3.9513
At iterate     2  f =       -780.4  |proj g|=         5.001
At iterate     3  f =      -782.68  |proj g|=         4.321
At iterate     4  f =      -783.01  |proj g|=        4.8822
At iterate     5  f =      -783.11  |proj g|=        4.6721
At iterate     6  f =      -783.12  |proj g|=         4.651
At iterate     7  f =      -783.12  |proj g|=        4.6589
At iterate     8  f =      -783.12  |proj g|=        4.6584
At iterate     9  f =      -783.12  |proj g|=        4.6574
At iterate    10  f =      -783.12  |proj g|=        4.6557
At iterate    11  f =      -783.12  |proj g|=        4.6544
At iterate    12  f =      -783.12  |proj g|=        4.6481
At iterate    13  f =      -783.12  |proj g|=        4.6462
At iterate    14  f =      -783.12  |proj g|=        4.6311
At iterate    15  f =      -783.13  |proj g|=        4.6295
At iterate    16  f =      -791.54  |proj g|=        4.0125
At iterate    17  f =      -811.96  |proj g|=        2.4434
At iterate    18  f =      -820.01  |proj g|=       0.24023
At iterate    19  f =       -820.1  |proj g|=       0.25382
At iterate    20  f =      -820.18  |proj g|=        0.7421
At iterate    21  f =       -820.2  |proj g|=       0.31189
At iterate    22  f =       -820.2  |proj g|=       0.29798
At iterate    23  f =       -820.2  |proj g|=       0.29895
At iterate    24  f =       -820.2  |proj g|=       0.29896

iterations 24
function evaluations 31
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.298961
final function value -820.201

F = -820.201
final  value -820.200869 
converged
 
INFO  [01:55:21.984] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:55:22.058] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:55:22.069] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:55:23.577] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:55:25.550] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:55:27.016] [mlr3]  Finished benchmark 
INFO  [01:55:27.086] [bbotk] Result of batch 166: 
INFO  [01:55:27.088] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:55:27.088] [bbotk]              2.904799                 5.964793                      0.09039085 
INFO  [01:55:27.088] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:55:27.088] [bbotk]                      578        0.955 -0.9469432         <NA>   0.9374238 
INFO  [01:55:27.088] [bbotk]                                 uhash 
INFO  [01:55:27.088] [bbotk]  e082ece1-d5ca-4bac-b752-310f2bf51802 
DEBUG [01:55:29.074] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.716832e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.716832e-05 0.002116884 
  - best initial criterion value(s) :  740.1064 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -740.11  |proj g|=       12.969
At iterate     1  f =      -758.27  |proj g|=        11.234
At iterate     2  f =      -765.34  |proj g|=        10.264
At iterate     3  f =      -774.78  |proj g|=        4.6357
At iterate     4  f =      -776.03  |proj g|=         5.617
At iterate     5  f =       -776.4  |proj g|=        5.1438
At iterate     6  f =      -776.44  |proj g|=        4.9004
At iterate     7  f =      -776.44  |proj g|=        4.9213
At iterate     8  f =      -776.44  |proj g|=        4.9211
At iterate     9  f =      -776.44  |proj g|=        4.9136
At iterate    10  f =      -776.44  |proj g|=        4.9093
At iterate    11  f =      -776.45  |proj g|=        4.8949
At iterate    12  f =      -776.47  |proj g|=        4.8695
At iterate    13  f =      -776.51  |proj g|=        4.8072
At iterate    14  f =      -776.61  |proj g|=        4.7306
At iterate    15  f =      -776.88  |proj g|=         4.503
At iterate    16  f =      -777.46  |proj g|=        4.3967
At iterate    17  f =      -778.77  |proj g|=        4.0063
At iterate    18  f =      -783.95  |proj g|=        3.2794
At iterate    19  f =       -794.4  |proj g|=        3.8022
At iterate    20  f =      -804.04  |proj g|=          1.14
At iterate    21  f =      -813.35  |proj g|=        2.0119
At iterate    22  f =      -815.18  |proj g|=        2.0892
At iterate    23  f =      -817.51  |proj g|=        2.6203
At iterate    24  f =       -817.8  |proj g|=        2.6844
At iterate    25  f =      -817.84  |proj g|=        2.7425
At iterate    26  f =      -817.84  |proj g|=        2.7488
At iterate    27  f =      -817.84  |proj g|=        2.7467
At iterate    28  f =      -817.84  |proj g|=         2.747

iterations 28
function evaluations 32
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.74701
final function value -817.838

F = -817.838
final  value -817.837850 
converged
 
INFO  [01:55:29.078] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:55:29.134] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:55:29.141] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:55:33.577] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:55:38.694] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:55:43.954] [mlr3]  Finished benchmark 
INFO  [01:55:44.068] [bbotk] Result of batch 167: 
INFO  [01:55:44.069] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:55:44.069] [bbotk]              3.211264                 3.510451                       0.3295725 
INFO  [01:55:44.069] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:55:44.069] [bbotk]                     1828         1.02 -0.9515393         <NA>   0.9714202 
INFO  [01:55:44.069] [bbotk]                                 uhash 
INFO  [01:55:44.069] [bbotk]  9a71f2f5-377b-4ffb-809c-e97f1bf9a4c5 
DEBUG [01:55:45.636] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.708455e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.708455e-05 0.002107384 
  - best initial criterion value(s) :  692.9983 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -693  |proj g|=       6.1803
At iterate     1  f =       -759.3  |proj g|=        2.7945
At iterate     2  f =      -769.09  |proj g|=        6.5565
At iterate     3  f =      -769.62  |proj g|=        7.4518
At iterate     4  f =      -769.64  |proj g|=        7.4039
At iterate     5  f =      -769.69  |proj g|=        7.3384
At iterate     6  f =      -769.74  |proj g|=        7.3791
At iterate     7  f =      -769.77  |proj g|=        7.5258
At iterate     8  f =      -769.77  |proj g|=        7.5377
At iterate     9  f =      -769.77  |proj g|=        7.5373
At iterate    10  f =      -769.77  |proj g|=        7.5726
At iterate    11  f =      -769.78  |proj g|=        7.5511
At iterate    12  f =      -769.82  |proj g|=        7.4893
At iterate    13  f =      -769.93  |proj g|=        7.3727
At iterate    14  f =       -770.2  |proj g|=        7.1725
At iterate    15  f =      -770.84  |proj g|=        6.8387
At iterate    16  f =      -772.13  |proj g|=        5.8392
At iterate    17  f =      -774.92  |proj g|=        5.1324
At iterate    18  f =      -776.16  |proj g|=        3.9435
At iterate    19  f =      -785.75  |proj g|=        2.7611
At iterate    20  f =      -814.87  |proj g|=        5.8979
At iterate    21  f =      -815.36  |proj g|=        5.1158
At iterate    22  f =       -815.6  |proj g|=        5.0454
At iterate    23  f =      -815.64  |proj g|=        4.7573
At iterate    24  f =      -815.65  |proj g|=        4.9134
At iterate    25  f =      -815.65  |proj g|=        4.8983
At iterate    26  f =      -815.65  |proj g|=        4.8976

iterations 26
function evaluations 31
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 4.89761
final function value -815.653

F = -815.653
final  value -815.652700 
converged
 
INFO  [01:55:45.640] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:55:45.698] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:55:45.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:55:51.807] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:55:58.975] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:56:06.356] [mlr3]  Finished benchmark 
INFO  [01:56:06.428] [bbotk] Result of batch 168: 
INFO  [01:56:06.430] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:56:06.430] [bbotk]              2.944544                  2.20978                      0.08557872 
INFO  [01:56:06.430] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:56:06.430] [bbotk]                     2421        0.918 -0.9470379         <NA>   0.9604465 
INFO  [01:56:06.430] [bbotk]                                 uhash 
INFO  [01:56:06.430] [bbotk]  dfb232c4-504a-429f-adc0-ee86b9b10c62 
DEBUG [01:56:08.467] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.703373e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.54404 15.86778 0.9954084 9530 
  - variance bounds :  1.703373e-05 0.002101324 
  - best initial criterion value(s) :  756.8753 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -756.88  |proj g|=       5.5756
At iterate     1  f =      -783.11  |proj g|=        8.8127
At iterate     2  f =      -791.27  |proj g|=        7.3163
At iterate     3  f =      -798.05  |proj g|=        2.4621
At iterate     4  f =      -801.17  |proj g|=        3.7716
At iterate     5  f =      -804.89  |proj g|=        3.3595
At iterate     6  f =      -809.51  |proj g|=        3.2788
At iterate     7  f =       -810.5  |proj g|=        4.4975
At iterate     8  f =      -813.57  |proj g|=         4.103
At iterate     9  f =      -814.13  |proj g|=        4.0013
At iterate    10  f =      -814.32  |proj g|=        4.0225
At iterate    11  f =      -814.61  |proj g|=        4.0896
At iterate    12  f =      -815.18  |proj g|=        4.2525
At iterate    13  f =      -815.79  |proj g|=        4.2982
At iterate    14  f =      -815.81  |proj g|=        4.7677
At iterate    15  f =      -816.69  |proj g|=        4.5647
At iterate    16  f =      -817.89  |proj g|=        4.1786
At iterate    17  f =      -817.99  |proj g|=        4.1371
At iterate    18  f =      -818.78  |proj g|=        4.0922
At iterate    19  f =      -819.79  |proj g|=        4.5316
At iterate    20  f =      -821.18  |proj g|=        4.2782
At iterate    21  f =      -821.95  |proj g|=         3.952
At iterate    22  f =      -821.95  |proj g|=        3.9362
At iterate    23  f =      -821.95  |proj g|=        3.9408
At iterate    24  f =      -821.97  |proj g|=        3.9105
At iterate    25  f =      -821.98  |proj g|=        3.9221
At iterate    26  f =      -821.98  |proj g|=        3.9201
At iterate    27  f =      -821.98  |proj g|=        3.9183
At iterate    28  f =      -821.99  |proj g|=        3.9119
At iterate    29  f =         -822  |proj g|=        3.9186
At iterate    30  f =         -822  |proj g|=        3.8853
At iterate    31  f =      -822.04  |proj g|=        3.8879
At iterate    32  f =      -828.98  |proj g|=        2.3433
At iterate    33  f =      -835.23  |proj g|=       0.32403
At iterate    34  f =      -835.71  |proj g|=       0.32405
At iterate    35  f =      -836.53  |proj g|=       0.29182
At iterate    36  f =      -836.61  |proj g|=       0.28576
At iterate    37  f =      -836.67  |proj g|=        0.7224
At iterate    38  f =      -836.67  |proj g|=       0.14527
At iterate    39  f =      -836.67  |proj g|=        0.1438
At iterate    40  f =      -836.67  |proj g|=       0.14402

iterations 40
function evaluations 51
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.144024
final function value -836.674

F = -836.674
final  value -836.673904 
converged
 
INFO  [01:56:08.471] [bbotk] Evaluating 1 configuration(s) 
INFO  [01:56:08.527] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [01:56:08.535] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:56:12.494] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:56:17.246] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:56:20.943] [mlr3]  Finished benchmark 
INFO  [01:56:21.013] [bbotk] Result of batch 169: 
INFO  [01:56:21.015] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:56:21.015] [bbotk]              2.204289                  9.43306                       0.1041324 
INFO  [01:56:21.015] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [01:56:21.015] [bbotk]                     1401        0.933 -0.9404808         <NA>    0.944625 
INFO  [01:56:21.015] [bbotk]                                 uhash 
INFO  [01:56:21.015] [bbotk]  5fc8a9ff-762d-459a-9e6f-663b48145d81 
DEBUG [01:56:21.086] [bbotk]  
INFO  [01:56:21.098] [bbotk] Finished optimizing after 200 evaluation(s) 
INFO  [01:56:21.099] [bbotk] Result: 
INFO  [01:56:21.102] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [01:56:21.102] [bbotk]              6.397045                  7.52717                       0.3767367 
INFO  [01:56:21.102] [bbotk]  ps_cboost_anneal1.mstop learner_param_vals  x_domain classif.auc 
INFO  [01:56:21.102] [bbotk]                     4971         <list[18]> <list[4]>   0.9789687 
INFO  [01:56:37.743] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1.tuned' on task 'spam' (iter 2/5) 
INFO  [01:56:38.031] [bbotk] Starting to optimize 4 parameter(s) with '<OptimizerInterMBO>' and '<TerminatorEvals> [n_evals=200]' 
DEBUG [01:56:38.102] [bbotk]  
INFO  [01:56:38.108] [bbotk] Evaluating 32 configuration(s) 
INFO  [01:56:39.531] [mlr3]  Running benchmark with 96 resampling iterations 
INFO  [01:56:39.538] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:56:51.966] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:57:00.001] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:57:02.917] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:57:07.532] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:57:09.423] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:57:21.744] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:57:31.966] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:57:37.980] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:57:48.949] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:57:54.252] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:58:02.118] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:58:08.252] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:58:19.763] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:58:23.382] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:58:34.546] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:58:41.903] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:58:44.591] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:58:45.817] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:58:51.026] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:58:59.511] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:59:02.776] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:59:04.786] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:59:14.525] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [01:59:27.393] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:59:34.586] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [01:59:43.391] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:59:45.239] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:59:47.516] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [01:59:49.875] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:00:03.580] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:00:07.196] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:00:15.585] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:00:17.781] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:00:21.844] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:00:28.024] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:00:30.253] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:00:45.216] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:00:58.811] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:01:12.120] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:01:22.298] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:01:36.097] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:01:42.830] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:01:44.972] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:01:49.295] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:01:54.384] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:02:00.619] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:02:07.946] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:02:17.011] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:02:28.809] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:02:31.656] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:02:33.803] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:02:41.315] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:02:45.906] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:02:51.525] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:02:55.359] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:03:05.113] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:03:12.550] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:03:23.353] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:03:27.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:03:37.278] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:03:47.146] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:03:52.184] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:04:04.955] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:04:12.735] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:04:14.981] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:04:26.024] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:04:34.240] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:04:48.278] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:04:52.464] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:04:55.859] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:04:57.487] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:05:05.552] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:05:16.702] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:05:22.466] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:05:24.298] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:05:29.969] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:05:38.661] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:05:52.243] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:05:58.640] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:06:05.651] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:06:16.294] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:06:23.977] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:06:30.723] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:06:38.234] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:06:51.150] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:06:52.297] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:07:04.492] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:07:16.306] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:07:28.063] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:07:36.271] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:07:49.642] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:08:03.375] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:08:13.146] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:08:22.033] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:08:27.968] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:08:35.830] [mlr3]  Finished benchmark 
INFO  [02:08:37.412] [bbotk] Result of batch 1: 
INFO  [02:08:37.415] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:08:37.415] [bbotk]              7.382588                 7.360463                      0.42052506 
INFO  [02:08:37.415] [bbotk]              7.075744                 4.194041                      0.29938892 
INFO  [02:08:37.415] [bbotk]              2.698429                 3.806669                      0.11327982 
INFO  [02:08:37.415] [bbotk]              8.537928                 8.421579                      0.35194404 
INFO  [02:08:37.415] [bbotk]              7.995831                 7.553623                      0.24205185 
INFO  [02:08:37.415] [bbotk]              4.414902                 3.398832                      0.23090601 
INFO  [02:08:37.415] [bbotk]              6.524168                 5.732777                      0.40030396 
INFO  [02:08:37.415] [bbotk]              4.625839                 2.504424                      0.42577178 
INFO  [02:08:37.415] [bbotk]              6.901985                 4.860892                      0.36031671 
INFO  [02:08:37.415] [bbotk]              5.852156                 6.223421                      0.33974574 
INFO  [02:08:37.415] [bbotk]              9.199641                 6.457382                      0.06479632 
INFO  [02:08:37.415] [bbotk]              3.536887                 6.666414                      0.19683793 
INFO  [02:08:37.415] [bbotk]              2.778027                 7.054083                      0.14560324 
INFO  [02:08:37.415] [bbotk]              8.078688                 7.920386                      0.46450949 
INFO  [02:08:37.415] [bbotk]              5.652236                 9.514397                      0.18437821 
INFO  [02:08:37.415] [bbotk]              7.704495                 4.280221                      0.25606016 
INFO  [02:08:37.415] [bbotk]              4.007327                 4.591169                      0.44662503 
INFO  [02:08:37.415] [bbotk]              8.774511                 8.142801                      0.10775924 
INFO  [02:08:37.415] [bbotk]              3.987978                 9.315324                      0.27234077 
INFO  [02:08:37.415] [bbotk]              5.306477                 5.816083                      0.08872164 
INFO  [02:08:37.415] [bbotk]              4.936174                 2.389755                      0.29300508 
INFO  [02:08:37.415] [bbotk]              2.111496                 3.652846                      0.06043182 
INFO  [02:08:37.415] [bbotk]              2.311346                 9.135144                      0.14091672 
INFO  [02:08:37.415] [bbotk]              8.483072                 2.916731                      0.01405946 
INFO  [02:08:37.415] [bbotk]              9.459723                 5.424768                      0.31929852 
INFO  [02:08:37.415] [bbotk]              9.677967                 8.739087                      0.17226956 
INFO  [02:08:37.415] [bbotk]              6.252171                 8.960882                      0.38640020 
INFO  [02:08:37.415] [bbotk]              3.359823                 6.793270                      0.48781428 
INFO  [02:08:37.415] [bbotk]              3.106875                 2.092543                      0.20932618 
INFO  [02:08:37.415] [bbotk]              6.021814                 5.162673                      0.01786507 
INFO  [02:08:37.415] [bbotk]              5.190354                 9.978139                      0.04155143 
INFO  [02:08:37.415] [bbotk]              9.822385                 3.171916                      0.47733021 
INFO  [02:08:37.415] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:08:37.415] [bbotk]  ps_cboost_anneal1.mstop classif.auc                                uhash 
INFO  [02:08:37.415] [bbotk]                     2108   0.9773659 db54a309-28d1-4a01-ab57-22e0cfcc1f61 
INFO  [02:08:37.415] [bbotk]                     3313   0.9776211 f0695f83-34c3-4f61-b786-185584129e20 
INFO  [02:08:37.415] [bbotk]                     1981   0.9561362 902b18d7-6262-4c30-bbcb-87f3810a4ba9 
INFO  [02:08:37.415] [bbotk]                      735   0.9717021 d2b39075-5c72-451b-90db-b7f16e64683d 
INFO  [02:08:37.415] [bbotk]                     3652   0.9775044 b1b4d5e2-f0d7-4c5c-a263-5f99b95a408c 
INFO  [02:08:37.415] [bbotk]                     2931   0.9745246 1789bffe-c341-4b77-9acd-42160d7250f5 
INFO  [02:08:37.415] [bbotk]                      858   0.9728215 c6120fac-9706-4e0c-b406-6099ef321bc9 
INFO  [02:08:37.415] [bbotk]                      553   0.9686499 51ecbebd-a4c7-4a8b-98d6-b6a8b680068d 
INFO  [02:08:37.415] [bbotk]                     4460   0.9790076 687b8e78-be66-4e71-974e-7f4b809260ce 
INFO  [02:08:37.415] [bbotk]                     2335   0.9762688 baca040b-7954-44df-b8ef-41d0bccf4aea 
INFO  [02:08:37.415] [bbotk]                     3162   0.9704129 0a1b896e-b82c-476f-863b-fc5cee650e75 
INFO  [02:08:37.415] [bbotk]                     4750   0.9738047 b25c2ed8-1e50-4477-9098-615e8786ab03 
INFO  [02:08:37.415] [bbotk]                     2201   0.9614105 355397f3-1fc3-4f75-8ef0-66f85998323a 
INFO  [02:08:37.415] [bbotk]                     2640   0.9784977 d5ec8f3a-569d-4c34-952d-2b48c07704f0 
INFO  [02:08:37.415] [bbotk]                     3992   0.9759217 78a8ec94-dd33-4796-9b33-2d0ab3afedca 
INFO  [02:08:37.415] [bbotk]                     2834   0.9766996 b26e09da-006a-47a7-96f7-eb08b277aa44 
INFO  [02:08:37.415] [bbotk]                     1254   0.9727941 c86a6dbb-40c7-42c3-83c2-073cd048a864 
INFO  [02:08:37.415] [bbotk]                     1518   0.9683746 e9bc10c9-9b5b-4575-a5c8-78e196aa2c7f 
INFO  [02:08:37.415] [bbotk]                     1744   0.9719177 b52cc366-9182-4cda-a798-be1f1ad0643a 
INFO  [02:08:37.415] [bbotk]                     1600   0.9650743 c44789ec-fb37-4c2e-9f68-97c44e003808 
INFO  [02:08:37.415] [bbotk]                     4625   0.9775646 dabdbd04-2758-4e0c-9d73-8e47914c1345 
INFO  [02:08:37.415] [bbotk]                     3515   0.9503230 bde09a6d-cb7a-455b-9b37-9bc2c8623df6 
INFO  [02:08:37.415] [bbotk]                     3897   0.9595901 c8d0c3a4-a0ac-499f-a842-c7754266cac1 
INFO  [02:08:37.415] [bbotk]                     2517   0.9489733 eea2359c-c010-4498-b36c-2cbbd1f527bb 
INFO  [02:08:37.415] [bbotk]                     1061   0.9735836 1b9a6bee-b304-42df-9bb4-c9c530eeef58 
INFO  [02:08:37.415] [bbotk]                     4101   0.9750722 5364b475-28fd-4352-b97e-234e24916036 
INFO  [02:08:37.415] [bbotk]                      245   0.9617081 af400de5-9879-4b67-a5e1-d8dfe204704f 
INFO  [02:08:37.415] [bbotk]                     4264   0.9761962 56cd6a33-b841-44a1-a515-869bb405a526 
INFO  [02:08:37.415] [bbotk]                     1222   0.9626599 f79838cd-bd1f-4820-b89c-9f4020d20204 
INFO  [02:08:37.415] [bbotk]                     4877   0.9605770 75ea0960-8933-4b0d-84fb-49d39d9e5ca0 
INFO  [02:08:37.415] [bbotk]                      476   0.9304151 9421629d-fb13-4958-910d-e6f43547ce22 
INFO  [02:08:37.415] [bbotk]                     3427   0.9776180 41a70a6f-b0ee-41c6-a313-df23aaa95d73 
INFO  [02:08:37.415] [bbotk]  ps_cboost_anneal1.mstop classif.auc                                uhash 
DEBUG [02:08:38.155] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.178601e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.178601e-05 0.001323815 
  - best initial criterion value(s) :  109.9835 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -109.98  |proj g|=      0.86695
At iterate     1  f =      -115.24  |proj g|=       0.76394
At iterate     2  f =      -115.33  |proj g|=       0.76249
At iterate     3  f =      -115.44  |proj g|=       0.75649
At iterate     4  f =      -115.46  |proj g|=       0.75735
At iterate     5  f =       -115.5  |proj g|=       0.75423
At iterate     6  f =      -115.74  |proj g|=       0.72572
At iterate     7  f =         -116  |proj g|=       0.67867
At iterate     8  f =      -116.12  |proj g|=       0.44617
At iterate     9  f =       -116.2  |proj g|=       0.55189
At iterate    10  f =      -116.21  |proj g|=       0.56404
At iterate    11  f =      -116.21  |proj g|=       0.56813
At iterate    12  f =      -116.21  |proj g|=       0.56868
At iterate    13  f =      -116.21  |proj g|=       0.56872

iterations 13
function evaluations 17
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.568721
final function value -116.213

F = -116.213
final  value -116.213179 
converged
 
INFO  [02:08:38.160] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:08:38.215] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:08:38.222] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:08:42.597] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:08:46.856] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:08:51.175] [mlr3]  Finished benchmark 
INFO  [02:08:51.262] [bbotk] Result of batch 2: 
INFO  [02:08:51.264] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:08:51.264] [bbotk]              5.987591                 5.864937                       0.1672679 
INFO  [02:08:51.264] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:08:51.264] [bbotk]                     2240        0.477 -0.9672814         <NA>   0.9729996 
INFO  [02:08:51.264] [bbotk]                                 uhash 
INFO  [02:08:51.264] [bbotk]  cba14aae-fbd6-4cb7-ac10-ded65f4021cf 
DEBUG [02:08:51.984] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.147179e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.147179e-05 0.001296587 
  - best initial criterion value(s) :  115.3398 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -115.34  |proj g|=       1.1821
At iterate     1  f =      -115.53  |proj g|=       0.48472
At iterate     2  f =      -118.11  |proj g|=        1.1635
At iterate     3  f =      -118.12  |proj g|=        1.1627
At iterate     4  f =      -118.13  |proj g|=        1.1466
At iterate     5  f =      -118.13  |proj g|=        1.1286
At iterate     6  f =      -118.13  |proj g|=        1.1273
At iterate     7  f =      -118.13  |proj g|=        1.1274

iterations 7
function evaluations 9
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.12736
final function value -118.134

F = -118.134
final  value -118.134476 
converged
 
INFO  [02:08:51.988] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:08:52.077] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:08:52.084] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:08:56.323] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:09:00.626] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:09:04.902] [mlr3]  Finished benchmark 
INFO  [02:09:04.971] [bbotk] Result of batch 3: 
INFO  [02:09:04.973] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:09:04.973] [bbotk]              2.992231                 3.671332                       0.2327327 
INFO  [02:09:04.973] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:09:04.973] [bbotk]                     2177        0.522 -0.970912         <NA>   0.9675695 
INFO  [02:09:04.973] [bbotk]                                 uhash 
INFO  [02:09:04.973] [bbotk]  aea42c4d-2795-44ee-b43c-05414c55f1ec 
DEBUG [02:09:05.630] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.112938e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.112938e-05 0.001261331 
  - best initial criterion value(s) :  123.0076 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -123.01  |proj g|=      0.47228
At iterate     1  f =      -124.34  |proj g|=       0.65881
At iterate     2  f =      -125.24  |proj g|=       0.64238
At iterate     3  f =      -125.94  |proj g|=       0.61917
At iterate     4  f =      -125.96  |proj g|=        0.6131
At iterate     5  f =      -126.06  |proj g|=       0.59027
At iterate     6  f =      -126.26  |proj g|=       0.42821
At iterate     7  f =       -126.3  |proj g|=       0.45175
At iterate     8  f =      -126.31  |proj g|=       0.40346
At iterate     9  f =      -126.31  |proj g|=       0.35055
At iterate    10  f =      -126.31  |proj g|=       0.33428
At iterate    11  f =      -126.31  |proj g|=       0.33344

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.333444
final function value -126.305

F = -126.305
final  value -126.305132 
converged
 
INFO  [02:09:05.634] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:09:05.718] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:09:05.725] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:09:08.284] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:09:10.806] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:09:13.217] [mlr3]  Finished benchmark 
INFO  [02:09:13.285] [bbotk] Result of batch 4: 
INFO  [02:09:13.287] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:09:13.287] [bbotk]              6.916132                 8.252588                       0.4126776 
INFO  [02:09:13.287] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:09:13.287] [bbotk]                     1224        0.454 -0.9663839         <NA>   0.9749269 
INFO  [02:09:13.287] [bbotk]                                 uhash 
INFO  [02:09:13.287] [bbotk]  8ae9d0ef-fd32-498d-bb68-4667d7ceb17a 
DEBUG [02:09:13.925] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.090709e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.090709e-05 0.001220495 
  - best initial criterion value(s) :  128.1335 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -128.13  |proj g|=      0.79602
At iterate     1  f =      -129.19  |proj g|=       0.71846
At iterate     2  f =      -130.33  |proj g|=       0.65315
At iterate     3  f =      -130.57  |proj g|=       0.60791
At iterate     4  f =      -130.63  |proj g|=       0.35092
At iterate     5  f =      -130.63  |proj g|=       0.37805
At iterate     6  f =      -130.63  |proj g|=       0.36887
At iterate     7  f =      -130.63  |proj g|=       0.37129
At iterate     8  f =      -130.63  |proj g|=       0.37138
At iterate     9  f =      -130.63  |proj g|=       0.37141

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.371408
final function value -130.632

F = -130.632
final  value -130.631697 
converged
 
INFO  [02:09:13.929] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:09:13.984] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:09:13.991] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:09:14.936] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:09:15.948] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:09:16.946] [mlr3]  Finished benchmark 
INFO  [02:09:17.022] [bbotk] Result of batch 5: 
INFO  [02:09:17.023] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:09:17.023] [bbotk]              8.613352                 9.491209                       0.1228651 
INFO  [02:09:17.023] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:09:17.023] [bbotk]                      247        0.459 -0.9669163         <NA>   0.9464256 
INFO  [02:09:17.023] [bbotk]                                 uhash 
INFO  [02:09:17.023] [bbotk]  24409021-12fa-4ace-b7b2-fab07789c23c 
DEBUG [02:09:17.683] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.201564e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.201564e-05 0.001387096 
  - best initial criterion value(s) :  127.1246 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -127.12  |proj g|=      0.75473
At iterate     1  f =      -127.31  |proj g|=       0.99864
At iterate     2  f =       -127.5  |proj g|=       0.93383
At iterate     3  f =      -127.61  |proj g|=       0.82393
At iterate     4  f =      -127.67  |proj g|=       0.85832
At iterate     5  f =      -127.79  |proj g|=       0.89884
At iterate     6  f =      -127.87  |proj g|=       0.91605
At iterate     7  f =      -127.89  |proj g|=       0.91524
At iterate     8  f =      -127.89  |proj g|=       0.91391
At iterate     9  f =      -127.89  |proj g|=       0.91332
At iterate    10  f =      -127.89  |proj g|=       0.91309
At iterate    11  f =      -127.89  |proj g|=       0.91309

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.913086
final function value -127.887

F = -127.887
final  value -127.887181 
converged
 
INFO  [02:09:17.688] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:09:17.743] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:09:17.750] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:09:19.482] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:09:21.111] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:09:22.613] [mlr3]  Finished benchmark 
INFO  [02:09:22.682] [bbotk] Result of batch 6: 
INFO  [02:09:22.684] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:09:22.684] [bbotk]              4.833293                 9.608076                       0.4218734 
INFO  [02:09:22.684] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:09:22.684] [bbotk]                      633        0.479 -0.9728916         <NA>   0.9699167 
INFO  [02:09:22.684] [bbotk]                                 uhash 
INFO  [02:09:22.684] [bbotk]  8a94e309-7184-4544-943b-9d26fe862402 
DEBUG [02:09:23.330] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.168801e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.168801e-05 0.001335944 
  - best initial criterion value(s) :  133.0418 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -133.04  |proj g|=      0.61156
At iterate     1  f =      -133.15  |proj g|=       0.95852
At iterate     2  f =      -133.84  |proj g|=        0.8697
At iterate     3  f =      -134.29  |proj g|=       0.76962
At iterate     4  f =      -134.69  |proj g|=        0.5258
At iterate     5  f =       -135.3  |proj g|=       0.55639
At iterate     6  f =      -136.45  |proj g|=       0.44959
At iterate     7  f =       -136.5  |proj g|=       0.64444
At iterate     8  f =      -136.52  |proj g|=       0.51301
At iterate     9  f =      -136.52  |proj g|=       0.61998
At iterate    10  f =      -136.52  |proj g|=       0.62633
At iterate    11  f =      -136.52  |proj g|=       0.62633

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.626326
final function value -136.519

F = -136.519
final  value -136.519252 
converged
 
INFO  [02:09:23.334] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:09:23.392] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:09:23.399] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:09:30.810] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:09:41.265] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:09:51.964] [mlr3]  Finished benchmark 
INFO  [02:09:52.070] [bbotk] Result of batch 7: 
INFO  [02:09:52.072] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:09:52.072] [bbotk]              7.509672                 8.648715                       0.4622157 
INFO  [02:09:52.072] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:09:52.072] [bbotk]                     3697        0.466 -0.9697507         <NA>   0.9793807 
INFO  [02:09:52.072] [bbotk]                                 uhash 
INFO  [02:09:52.072] [bbotk]  f65be5af-166b-4516-b8ae-93dffa3bb578 
DEBUG [02:09:52.729] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.168657e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.168657e-05 0.001345022 
  - best initial criterion value(s) :  137.0533 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -137.05  |proj g|=      0.56892
At iterate     1  f =       -140.1  |proj g|=        1.1487
At iterate     2  f =      -140.29  |proj g|=        1.0816
At iterate     3  f =      -140.43  |proj g|=        0.8469
At iterate     4  f =      -140.47  |proj g|=       0.94458
At iterate     5  f =      -140.47  |proj g|=       0.93361
At iterate     6  f =       -140.5  |proj g|=       0.90396
At iterate     7  f =      -140.54  |proj g|=       0.88469
At iterate     8  f =      -140.66  |proj g|=       0.88919
At iterate     9  f =      -140.78  |proj g|=       0.95646
At iterate    10  f =      -140.84  |proj g|=        1.0462
At iterate    11  f =      -140.85  |proj g|=        1.0785
At iterate    12  f =      -140.85  |proj g|=        1.0858
At iterate    13  f =      -140.85  |proj g|=        1.0862
At iterate    14  f =      -140.85  |proj g|=        1.0862

iterations 14
function evaluations 17
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.08625
final function value -140.848

F = -140.848
final  value -140.847516 
converged
 
INFO  [02:09:52.733] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:09:52.791] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:09:52.799] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:09:55.463] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:09:58.450] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:10:01.123] [mlr3]  Finished benchmark 
INFO  [02:10:01.209] [bbotk] Result of batch 8: 
INFO  [02:10:01.211] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:10:01.211] [bbotk]              3.712777                 3.838873                      0.09007092 
INFO  [02:10:01.211] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:10:01.211] [bbotk]                      946        0.474 -0.9707458         <NA>    0.954396 
INFO  [02:10:01.211] [bbotk]                                 uhash 
INFO  [02:10:01.211] [bbotk]  65c1aa6c-a73e-46b6-9e38-4d7c1a611521 
DEBUG [02:10:01.892] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.190638e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.190638e-05 0.001376424 
  - best initial criterion value(s) :  144.4271 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -144.43  |proj g|=      0.74185
At iterate     1  f =      -145.16  |proj g|=       0.69054
At iterate     2  f =      -145.49  |proj g|=       0.69506
At iterate     3  f =      -145.87  |proj g|=       0.69595
At iterate     4  f =      -145.97  |proj g|=       0.68597
At iterate     5  f =      -146.26  |proj g|=       0.62847
At iterate     6  f =      -146.26  |proj g|=         0.401
At iterate     7  f =      -146.27  |proj g|=       0.41144
At iterate     8  f =      -146.27  |proj g|=       0.41384
At iterate     9  f =      -146.27  |proj g|=       0.41395

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.413947
final function value -146.265

F = -146.265
final  value -146.265496 
converged
 
INFO  [02:10:01.896] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:10:01.954] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:10:01.961] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:10:10.120] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:10:18.273] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:10:26.763] [mlr3]  Finished benchmark 
INFO  [02:10:26.834] [bbotk] Result of batch 9: 
INFO  [02:10:26.836] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:10:26.836] [bbotk]              7.616054                  6.10287                      0.06649949 
INFO  [02:10:26.836] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:10:26.836] [bbotk]                     2861        0.492 -0.9686138         <NA>   0.9693163 
INFO  [02:10:26.836] [bbotk]                                 uhash 
INFO  [02:10:26.836] [bbotk]  c23b3f99-a6a6-4a99-92b2-8b4eedf21a6d 
DEBUG [02:10:27.506] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.160333e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.160333e-05 0.001342885 
  - best initial criterion value(s) :  150.5276 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -150.53  |proj g|=      0.73396
At iterate     1  f =      -152.17  |proj g|=       0.63705
At iterate     2  f =      -152.66  |proj g|=       0.58526
At iterate     3  f =      -152.72  |proj g|=       0.55898
At iterate     4  f =      -152.73  |proj g|=       0.32736
At iterate     5  f =      -152.73  |proj g|=       0.37093
At iterate     6  f =      -152.73  |proj g|=       0.36864
At iterate     7  f =      -152.73  |proj g|=       0.36321

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.36321
final function value -152.727

F = -152.727
final  value -152.727441 
converged
 
INFO  [02:10:27.511] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:10:27.569] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:10:27.576] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:10:39.987] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:10:50.275] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:11:01.677] [mlr3]  Finished benchmark 
INFO  [02:11:01.745] [bbotk] Result of batch 10: 
INFO  [02:11:01.747] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:11:01.747] [bbotk]              7.703171                 3.686009                       0.3165135 
INFO  [02:11:01.747] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:11:01.747] [bbotk]                     3716        0.488 -0.9676064         <NA>   0.9783351 
INFO  [02:11:01.747] [bbotk]                                 uhash 
INFO  [02:11:01.747] [bbotk]  26821d67-0421-4162-81ef-60f090d8cda8 
DEBUG [02:11:02.433] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.155433e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.155433e-05 0.001349995 
  - best initial criterion value(s) :  155.6583 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -155.66  |proj g|=      0.34379
At iterate     1  f =      -156.97  |proj g|=       0.78149
At iterate     2  f =      -156.98  |proj g|=       0.76308
At iterate     3  f =      -157.04  |proj g|=       0.68586
At iterate     4  f =      -157.11  |proj g|=       0.65555
At iterate     5  f =      -157.34  |proj g|=       0.65544
At iterate     6  f =      -157.57  |proj g|=       0.78442
At iterate     7  f =      -157.64  |proj g|=       0.90082
At iterate     8  f =      -157.65  |proj g|=       0.95444
At iterate     9  f =      -157.65  |proj g|=       0.96943
At iterate    10  f =      -157.65  |proj g|=       0.97082
At iterate    11  f =      -157.65  |proj g|=       0.97085

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.970847
final function value -157.654

F = -157.654
final  value -157.654358 
converged
 
INFO  [02:11:02.437] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:11:02.495] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:11:02.502] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:11:14.921] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:11:27.404] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:11:40.290] [mlr3]  Finished benchmark 
INFO  [02:11:40.359] [bbotk] Result of batch 11: 
INFO  [02:11:40.361] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:11:40.361] [bbotk]              2.199508                 4.686905                       0.3600102 
INFO  [02:11:40.361] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:11:40.361] [bbotk]                     4144        0.487 -0.9677226         <NA>   0.9653798 
INFO  [02:11:40.361] [bbotk]                                 uhash 
INFO  [02:11:40.361] [bbotk]  1ecd2706-9dc8-4a14-b64b-b6a401fd33e0 
DEBUG [02:11:41.238] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.129776e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.129776e-05 0.001319894 
  - best initial criterion value(s) :  156.6761 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -156.68  |proj g|=      0.84144
At iterate     1  f =      -157.44  |proj g|=        1.1526
At iterate     2  f =      -158.99  |proj g|=         1.084
At iterate     3  f =      -160.43  |proj g|=       0.75122
At iterate     4  f =      -160.69  |proj g|=       0.91427
At iterate     5  f =      -160.73  |proj g|=       0.91676
At iterate     6  f =      -160.73  |proj g|=       0.91815
At iterate     7  f =      -160.73  |proj g|=       0.91886
At iterate     8  f =      -160.73  |proj g|=       0.91903
At iterate     9  f =      -160.73  |proj g|=       0.91933
At iterate    10  f =      -160.73  |proj g|=       0.91955
At iterate    11  f =      -160.73  |proj g|=       0.92009
At iterate    12  f =      -160.73  |proj g|=       0.92086
At iterate    13  f =      -160.73  |proj g|=       0.92195
At iterate    14  f =      -160.73  |proj g|=       0.92298
At iterate    15  f =      -160.73  |proj g|=       0.92954
At iterate    16  f =      -160.74  |proj g|=       0.92792
At iterate    17  f =      -160.74  |proj g|=       0.92065
At iterate    18  f =      -160.75  |proj g|=       0.91094
At iterate    19  f =      -160.76  |proj g|=       0.88759
At iterate    20  f =      -160.81  |proj g|=       0.84468
At iterate    21  f =      -160.89  |proj g|=       0.68572
At iterate    22  f =      -161.04  |proj g|=       0.60533
At iterate    23  f =       -161.2  |proj g|=       0.50427
At iterate    24  f =      -161.96  |proj g|=       0.52934
At iterate    25  f =      -162.46  |proj g|=       0.50341
At iterate    26  f =      -162.66  |proj g|=       0.37656
At iterate    27  f =      -162.72  |proj g|=       0.51087
At iterate    28  f =      -162.73  |proj g|=       0.35358
At iterate    29  f =      -162.74  |proj g|=       0.23061
At iterate    30  f =      -162.74  |proj g|=       0.22926
At iterate    31  f =      -162.74  |proj g|=        0.2327
At iterate    32  f =      -162.74  |proj g|=        0.2332
At iterate    33  f =       -162.8  |proj g|=       0.45118
At iterate    34  f =      -162.91  |proj g|=       0.43155
At iterate    35  f =      -163.24  |proj g|=       0.50432
At iterate    36  f =      -163.39  |proj g|=       0.28764
At iterate    37  f =      -163.44  |proj g|=       0.45792
At iterate    38  f =      -163.45  |proj g|=       0.37731
At iterate    39  f =      -163.45  |proj g|=     0.0025067
At iterate    40  f =      -163.45  |proj g|=      0.024196
At iterate    41  f =      -163.45  |proj g|=     0.0039973
At iterate    42  f =      -163.45  |proj g|=     0.0039515

iterations 42
function evaluations 53
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00395147
final function value -163.453

F = -163.453
final  value -163.453015 
converged
 
INFO  [02:11:41.243] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:11:41.319] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:11:41.325] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:11:57.346] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:12:11.049] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:12:23.996] [mlr3]  Finished benchmark 
INFO  [02:12:24.084] [bbotk] Result of batch 12: 
INFO  [02:12:24.086] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:12:24.086] [bbotk]              2.255571                 8.294278                       0.1683241 
INFO  [02:12:24.086] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:12:24.086] [bbotk]                     4370        0.647 -0.9606693         <NA>   0.9608555 
INFO  [02:12:24.086] [bbotk]                                 uhash 
INFO  [02:12:24.086] [bbotk]  0bab1996-4b62-4461-bbda-aff47e0f2f8f 
DEBUG [02:12:24.785] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.116674e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.116674e-05 0.001288989 
  - best initial criterion value(s) :  160.5762 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -160.58  |proj g|=       2.3205
At iterate     1  f =      -160.73  |proj g|=        2.5026
At iterate     2  f =      -160.94  |proj g|=        2.3476
At iterate     3  f =      -161.47  |proj g|=        1.5149
At iterate     4  f =      -161.48  |proj g|=        1.6456
At iterate     5  f =      -161.48  |proj g|=        1.6281
At iterate     6  f =      -161.48  |proj g|=        1.6275
At iterate     7  f =      -161.48  |proj g|=         1.627
At iterate     8  f =      -161.48  |proj g|=         1.626
At iterate     9  f =      -161.48  |proj g|=        1.6225
At iterate    10  f =      -161.48  |proj g|=         1.617
At iterate    11  f =      -161.48  |proj g|=         1.608
At iterate    12  f =      -161.48  |proj g|=        1.5935
At iterate    13  f =      -161.48  |proj g|=        1.5709
At iterate    14  f =      -161.49  |proj g|=        1.5376
At iterate    15  f =      -161.49  |proj g|=        1.5216
At iterate    16  f =      -161.51  |proj g|=        1.4749
At iterate    17  f =      -161.71  |proj g|=        1.3413
At iterate    18  f =      -164.75  |proj g|=       0.49698
At iterate    19  f =      -165.07  |proj g|=       0.49202
At iterate    20  f =      -165.61  |proj g|=       0.46341
At iterate    21  f =      -166.08  |proj g|=       0.42203
At iterate    22  f =      -166.23  |proj g|=       0.57308
At iterate    23  f =      -166.28  |proj g|=       0.36507
At iterate    24  f =      -166.29  |proj g|=       0.37858
At iterate    25  f =      -166.29  |proj g|=       0.37785
At iterate    26  f =      -166.29  |proj g|=       0.11128
At iterate    27  f =      -166.29  |proj g|=       0.12101
At iterate    28  f =       -166.3  |proj g|=      0.046143
At iterate    29  f =       -166.3  |proj g|=      0.046802
At iterate    30  f =       -166.3  |proj g|=      0.046814

iterations 30
function evaluations 37
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0468141
final function value -166.295

F = -166.295
final  value -166.295060 
converged
 
INFO  [02:12:24.790] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:12:24.860] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:12:24.868] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:12:27.224] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:12:28.803] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:12:30.582] [mlr3]  Finished benchmark 
INFO  [02:12:30.649] [bbotk] Result of batch 13: 
INFO  [02:12:30.651] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:12:30.651] [bbotk]              7.872955                 8.994652                       0.3659785 
INFO  [02:12:30.651] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:12:30.651] [bbotk]                      547        0.495 -0.963977         <NA>   0.9698752 
INFO  [02:12:30.651] [bbotk]                                 uhash 
INFO  [02:12:30.651] [bbotk]  747adf09-6793-4d09-b113-844e8ddd06d2 
DEBUG [02:12:31.359] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.091214e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.091214e-05 0.001241998 
  - best initial criterion value(s) :  167.5515 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -167.55  |proj g|=      0.86695
At iterate     1  f =      -168.94  |proj g|=       0.64766
At iterate     2  f =       -169.5  |proj g|=       0.77869
At iterate     3  f =      -169.55  |proj g|=       0.79705
At iterate     4  f =      -169.56  |proj g|=       0.80766
At iterate     5  f =      -169.56  |proj g|=        0.8101
At iterate     6  f =      -169.56  |proj g|=       0.81079
At iterate     7  f =      -169.56  |proj g|=       0.81111
At iterate     8  f =      -169.56  |proj g|=       0.81113

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.811131
final function value -169.563

F = -169.563
final  value -169.562935 
converged
 
INFO  [02:12:31.363] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:12:31.418] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:12:31.425] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:12:32.562] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:12:33.597] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:12:35.476] [mlr3]  Finished benchmark 
INFO  [02:12:35.544] [bbotk] Result of batch 14: 
INFO  [02:12:35.546] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:12:35.546] [bbotk]              9.770236                  8.80219                       0.1055842 
INFO  [02:12:35.546] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:12:35.546] [bbotk]                      265        0.526 -0.966543         <NA>   0.9447727 
INFO  [02:12:35.546] [bbotk]                                 uhash 
INFO  [02:12:35.546] [bbotk]  fadd5e97-df3a-4c2c-aac4-134dcba7580f 
DEBUG [02:12:36.313] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.190604e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9264 
  - variance bounds :  1.190604e-05 0.001384324 
  - best initial criterion value(s) :  169.6086 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -169.61  |proj g|=      0.89258
At iterate     1  f =      -174.06  |proj g|=       0.66154
At iterate     2  f =       -174.1  |proj g|=       0.65983
At iterate     3  f =      -174.16  |proj g|=       0.65439
At iterate     4  f =      -174.25  |proj g|=       0.64384
At iterate     5  f =      -174.62  |proj g|=       0.59512
At iterate     6  f =      -174.83  |proj g|=       0.24907
At iterate     7  f =      -174.86  |proj g|=       0.41068
At iterate     8  f =      -174.86  |proj g|=       0.41633
At iterate     9  f =      -174.86  |proj g|=       0.41667
At iterate    10  f =      -174.86  |proj g|=       0.41674

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.416738
final function value -174.86

F = -174.86
final  value -174.859765 
converged
 
INFO  [02:12:36.316] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:12:36.366] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:12:36.390] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:12:37.397] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:12:38.638] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:12:39.702] [mlr3]  Finished benchmark 
INFO  [02:12:39.770] [bbotk] Result of batch 15: 
INFO  [02:12:39.772] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:12:39.772] [bbotk]              6.169472                  5.60687                       0.0677412 
INFO  [02:12:39.772] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:12:39.772] [bbotk]                      203        0.572 -0.9641924         <NA>   0.9240553 
INFO  [02:12:39.772] [bbotk]                                 uhash 
INFO  [02:12:39.772] [bbotk]  f74a26d9-523c-47cd-a25e-111d636bfdb6 
DEBUG [02:12:40.458] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.581813e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9348 
  - variance bounds :  1.581813e-05 0.001935152 
  - best initial criterion value(s) :  163.6495 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -163.65  |proj g|=      0.73059
At iterate     1  f =       -164.5  |proj g|=       0.45119
At iterate     2  f =      -165.78  |proj g|=         0.348
At iterate     3  f =      -165.93  |proj g|=       0.33312
At iterate     4  f =      -166.17  |proj g|=       0.28944
At iterate     5  f =       -166.2  |proj g|=       0.48995
At iterate     6  f =      -166.21  |proj g|=       0.26653
At iterate     7  f =      -166.21  |proj g|=       0.21159
At iterate     8  f =      -166.21  |proj g|=       0.19334
At iterate     9  f =      -166.21  |proj g|=       0.19391

iterations 9
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.193909
final function value -166.213

F = -166.213
final  value -166.213174 
converged
 
INFO  [02:12:40.462] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:12:40.548] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:12:40.557] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:12:51.882] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:13:02.529] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:13:12.361] [mlr3]  Finished benchmark 
INFO  [02:13:12.434] [bbotk] Result of batch 16: 
INFO  [02:13:12.436] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:13:12.436] [bbotk]              2.212588                 4.137776                       0.2084466 
INFO  [02:13:12.436] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:13:12.436] [bbotk]                     3676        0.503 -0.9717054         <NA>   0.9608402 
INFO  [02:13:12.436] [bbotk]                                 uhash 
INFO  [02:13:12.436] [bbotk]  77ba55f9-c7c7-48f2-8905-6687281499cf 
DEBUG [02:13:13.134] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.555329e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9348 
  - variance bounds :  1.555329e-05 0.001901737 
  - best initial criterion value(s) :  172.8929 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -172.89  |proj g|=      0.78956
At iterate     1  f =      -174.36  |proj g|=       0.51168
At iterate     2  f =      -175.17  |proj g|=       0.50952
At iterate     3  f =      -176.52  |proj g|=       0.53449
At iterate     4  f =      -176.52  |proj g|=       0.26753
At iterate     5  f =      -176.53  |proj g|=       0.26028
At iterate     6  f =      -176.53  |proj g|=       0.25948
At iterate     7  f =      -176.53  |proj g|=       0.25751
At iterate     8  f =      -176.53  |proj g|=       0.28625
At iterate     9  f =      -176.53  |proj g|=       0.28867

iterations 9
function evaluations 12
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.288674
final function value -176.527

F = -176.527
final  value -176.527137 
converged
 
INFO  [02:13:13.139] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:13:13.195] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:13:13.202] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:13:23.372] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:13:32.941] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:13:43.135] [mlr3]  Finished benchmark 
INFO  [02:13:43.202] [bbotk] Result of batch 17: 
INFO  [02:13:43.204] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:13:43.204] [bbotk]              5.580936                 3.853637                      0.06793677 
INFO  [02:13:43.204] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:13:43.204] [bbotk]                     3235        0.513 -0.9648818         <NA>   0.9692837 
INFO  [02:13:43.204] [bbotk]                                 uhash 
INFO  [02:13:43.204] [bbotk]  1bd38780-64b6-463a-a4c8-d7da321dac74 
DEBUG [02:13:43.919] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.523517e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9348 
  - variance bounds :  1.523517e-05 0.001875534 
  - best initial criterion value(s) :  175.7227 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -175.72  |proj g|=      0.56399
At iterate     1  f =      -176.88  |proj g|=       0.53858
At iterate     2  f =      -176.96  |proj g|=       0.53105
At iterate     3  f =      -177.36  |proj g|=       0.42542
At iterate     4  f =      -177.69  |proj g|=       0.46052
At iterate     5  f =       -177.9  |proj g|=       0.59794
At iterate     6  f =       -177.9  |proj g|=       0.52269
At iterate     7  f =       -177.9  |proj g|=       0.52223
At iterate     8  f =       -177.9  |proj g|=       0.52219

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.522186
final function value -177.901

F = -177.901
final  value -177.900934 
converged
 
INFO  [02:13:43.923] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:13:43.979] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:13:43.986] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:13:55.674] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:14:05.664] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:14:16.248] [mlr3]  Finished benchmark 
INFO  [02:14:16.535] [bbotk] Result of batch 18: 
INFO  [02:14:16.537] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:14:16.537] [bbotk]              4.661103                 6.390652                       0.2812383 
INFO  [02:14:16.537] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:14:16.537] [bbotk]                     3922         0.53 -0.9685046         <NA>    0.976719 
INFO  [02:14:16.537] [bbotk]                                 uhash 
INFO  [02:14:16.537] [bbotk]  7c74dcf4-11ec-419d-b554-1d4da135e2b2 
DEBUG [02:14:17.289] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.511627e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9348 
  - variance bounds :  1.511627e-05 0.001875415 
  - best initial criterion value(s) :  175.1286 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -175.13  |proj g|=       1.3287
At iterate     1  f =      -177.31  |proj g|=        1.5583
At iterate     2  f =      -179.96  |proj g|=         1.364
At iterate     3  f =      -179.98  |proj g|=         1.335
At iterate     4  f =      -180.01  |proj g|=         1.326
At iterate     5  f =      -180.02  |proj g|=        1.3124
At iterate     6  f =      -180.02  |proj g|=        1.3114
At iterate     7  f =      -180.02  |proj g|=        1.3113
At iterate     8  f =      -180.02  |proj g|=        1.3113
At iterate     9  f =      -180.02  |proj g|=         1.311
At iterate    10  f =      -180.02  |proj g|=        1.3112
At iterate    11  f =      -180.02  |proj g|=         1.311
At iterate    12  f =      -180.02  |proj g|=        1.3103
At iterate    13  f =      -180.02  |proj g|=        1.3092
At iterate    14  f =      -180.02  |proj g|=        1.3069
At iterate    15  f =      -180.02  |proj g|=        1.3023
At iterate    16  f =      -180.02  |proj g|=        1.2875
At iterate    17  f =      -180.03  |proj g|=        1.2858
At iterate    18  f =      -180.06  |proj g|=        1.2788
At iterate    19  f =      -180.12  |proj g|=        1.2581
At iterate    20  f =      -180.26  |proj g|=        1.2094
At iterate    21  f =      -180.53  |proj g|=        1.1119
At iterate    22  f =      -180.95  |proj g|=       0.98389
At iterate    23  f =       -181.5  |proj g|=        1.2176
At iterate    24  f =      -181.77  |proj g|=        2.1972
At iterate    25  f =      -182.79  |proj g|=        1.5175
At iterate    26  f =      -182.98  |proj g|=         1.249
At iterate    27  f =      -182.99  |proj g|=        1.1844
At iterate    28  f =         -183  |proj g|=        1.2115
At iterate    29  f =         -183  |proj g|=        1.2128
At iterate    30  f =         -183  |proj g|=        1.2124

iterations 30
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.2124
final function value -183.002

F = -183.002
final  value -183.001871 
converged
 
INFO  [02:14:17.293] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:14:17.352] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:14:17.359] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:14:33.336] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:14:49.006] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:15:03.970] [mlr3]  Finished benchmark 
INFO  [02:15:04.078] [bbotk] Result of batch 19: 
INFO  [02:15:04.079] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:15:04.079] [bbotk]                4.7342                 5.480481                      0.08036977 
INFO  [02:15:04.079] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:15:04.079] [bbotk]                     4998        0.519 -0.9656552         <NA>    0.972365 
INFO  [02:15:04.079] [bbotk]                                 uhash 
INFO  [02:15:04.079] [bbotk]  2d0bbe2b-d495-4115-b091-8e7ef056ef92 
DEBUG [02:15:04.844] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.486411e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9590 
  - variance bounds :  1.48641e-05 0.001845027 
  - best initial criterion value(s) :  173.8516 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -173.85  |proj g|=       1.1642
At iterate     1  f =      -178.44  |proj g|=       0.65095
At iterate     2  f =      -179.55  |proj g|=        0.6257
At iterate     3  f =       -181.9  |proj g|=       0.65356
At iterate     4  f =      -182.27  |proj g|=       0.62862
At iterate     5  f =      -183.08  |proj g|=         0.551
At iterate     6  f =      -184.82  |proj g|=       0.68328
At iterate     7  f =      -184.95  |proj g|=       0.64652
At iterate     8  f =      -184.95  |proj g|=       0.44964
At iterate     9  f =      -184.95  |proj g|=       0.44966
At iterate    10  f =      -184.95  |proj g|=       0.44967
At iterate    11  f =      -184.95  |proj g|=       0.44967

iterations 11
function evaluations 22
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.449671
final function value -184.949

F = -184.949
final  value -184.948992 
converged
 
INFO  [02:15:04.849] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:15:04.904] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:15:04.912] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:15:11.989] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:15:17.734] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:15:25.317] [mlr3]  Finished benchmark 
INFO  [02:15:25.386] [bbotk] Result of batch 20: 
INFO  [02:15:25.388] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:15:25.388] [bbotk]              9.113906                 6.932357                        0.183599 
INFO  [02:15:25.388] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:15:25.388] [bbotk]                     2302        0.563 -0.9699218         <NA>   0.9747254 
INFO  [02:15:25.388] [bbotk]                                 uhash 
INFO  [02:15:25.388] [bbotk]  6cb41e4c-90f2-4452-911c-10ccf212609e 
DEBUG [02:15:26.143] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.467893e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9475096 9590 
  - variance bounds :  1.467893e-05 0.001837613 
  - best initial criterion value(s) :  188.3823 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -188.38  |proj g|=       1.8151
At iterate     1  f =      -193.43  |proj g|=       0.69203
At iterate     2  f =      -193.59  |proj g|=       0.68979
At iterate     3  f =      -193.74  |proj g|=       0.68288
At iterate     4  f =      -193.76  |proj g|=       0.68317
At iterate     5  f =      -193.81  |proj g|=       0.68125
At iterate     6  f =         -194  |proj g|=       0.66915
At iterate     7  f =      -194.28  |proj g|=       0.64288
At iterate     8  f =      -194.58  |proj g|=        0.6021
At iterate     9  f =      -194.69  |proj g|=       0.57416
At iterate    10  f =      -194.71  |proj g|=       0.48561
At iterate    11  f =      -194.71  |proj g|=       0.48049
At iterate    12  f =      -194.71  |proj g|=       0.48025
At iterate    13  f =      -194.71  |proj g|=       0.48044
At iterate    14  f =      -194.71  |proj g|=       0.48038

iterations 14
function evaluations 17
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.480378
final function value -194.713

F = -194.713
final  value -194.712872 
converged
 
INFO  [02:15:26.147] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:15:26.207] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:15:26.235] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:15:32.121] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:15:37.368] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:15:44.119] [mlr3]  Finished benchmark 
INFO  [02:15:44.235] [bbotk] Result of batch 21: 
INFO  [02:15:44.237] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:15:44.237] [bbotk]              9.263302                 8.162353                       0.4962336 
INFO  [02:15:44.237] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:15:44.237] [bbotk]                     1989        0.531 -0.964571         <NA>   0.9764798 
INFO  [02:15:44.237] [bbotk]                                 uhash 
INFO  [02:15:44.237] [bbotk]  d5e3a7cb-b6a1-4cba-a49f-ab947cc1ed54 
DEBUG [02:15:44.958] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.455273e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.455273e-05 0.001834944 
  - best initial criterion value(s) :  188.9631 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -188.96  |proj g|=      0.67885
At iterate     1  f =      -188.98  |proj g|=       0.29642
At iterate     2  f =         -189  |proj g|=       0.28696
At iterate     3  f =      -189.01  |proj g|=       0.27272
At iterate     4  f =      -189.01  |proj g|=       0.27268
At iterate     5  f =      -189.01  |proj g|=       0.27268

iterations 5
function evaluations 8
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.272684
final function value -189.009

F = -189.009
final  value -189.009439 
converged
 
INFO  [02:15:44.963] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:15:45.019] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:15:45.026] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:15:52.016] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:15:58.801] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:16:04.877] [mlr3]  Finished benchmark 
INFO  [02:16:04.948] [bbotk] Result of batch 22: 
INFO  [02:16:04.950] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:16:04.950] [bbotk]              7.156222                 3.271565                       0.2019465 
INFO  [02:16:04.950] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:16:04.950] [bbotk]                     2073        0.536 -0.9725587         <NA>    0.974058 
INFO  [02:16:04.950] [bbotk]                                 uhash 
INFO  [02:16:04.950] [bbotk]  906ca8bf-3cfe-4bf1-bc9b-14627eb02bda 
DEBUG [02:16:05.686] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.43543e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.43543e-05 0.001824735 
  - best initial criterion value(s) :  192.9088 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -192.91  |proj g|=       1.7644
At iterate     1  f =      -193.24  |proj g|=        1.9971
At iterate     2  f =      -196.75  |proj g|=        1.7335
At iterate     3  f =      -196.84  |proj g|=        1.7716
At iterate     4  f =      -196.84  |proj g|=        1.7644
At iterate     5  f =      -196.86  |proj g|=        1.7373
At iterate     6  f =      -196.86  |proj g|=        1.7362
At iterate     7  f =      -196.86  |proj g|=        1.7362
At iterate     8  f =      -196.86  |proj g|=        1.7363

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.73627
final function value -196.863

F = -196.863
final  value -196.863472 
converged
 
INFO  [02:16:05.690] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:16:05.773] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:16:05.785] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:16:08.712] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:16:11.730] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:16:15.406] [mlr3]  Finished benchmark 
INFO  [02:16:15.520] [bbotk] Result of batch 23: 
INFO  [02:16:15.522] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:16:15.522] [bbotk]              8.428872                 4.642203                       0.4442623 
INFO  [02:16:15.522] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:16:15.522] [bbotk]                     1010        0.544 -0.9651978         <NA>   0.9748248 
INFO  [02:16:15.522] [bbotk]                                 uhash 
INFO  [02:16:15.522] [bbotk]  73731e0b-3e97-4358-bab9-3efd0c5d739b 
DEBUG [02:16:16.311] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.417979e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.417979e-05 0.001774996 
  - best initial criterion value(s) :  190.2112 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -190.21  |proj g|=      0.82661
At iterate     1  f =      -195.41  |proj g|=       0.91802
At iterate     2  f =      -197.31  |proj g|=       0.49281
At iterate     3  f =       -197.5  |proj g|=         0.479
At iterate     4  f =      -197.64  |proj g|=       0.56136
At iterate     5  f =      -197.73  |proj g|=       0.46386
At iterate     6  f =      -197.75  |proj g|=       0.46417
At iterate     7  f =      -197.75  |proj g|=       0.46904
At iterate     8  f =      -197.75  |proj g|=       0.46683
At iterate     9  f =      -197.75  |proj g|=       0.46669
At iterate    10  f =      -197.75  |proj g|=       0.46683
At iterate    11  f =      -197.75  |proj g|=       0.46782
At iterate    12  f =      -197.76  |proj g|=       0.50532
At iterate    13  f =      -197.77  |proj g|=       0.63543
At iterate    14  f =      -197.77  |proj g|=       0.63705
At iterate    15  f =       -197.8  |proj g|=       0.64763
At iterate    16  f =      -197.89  |proj g|=       0.66542
At iterate    17  f =       -198.1  |proj g|=       0.69036
At iterate    18  f =      -198.68  |proj g|=       0.72287
At iterate    19  f =       -199.3  |proj g|=       0.73348
At iterate    20  f =      -199.71  |proj g|=        0.6909
At iterate    21  f =      -199.87  |proj g|=       0.67363
At iterate    22  f =      -199.89  |proj g|=       0.66135
At iterate    23  f =       -199.9  |proj g|=       0.35958
At iterate    24  f =       -199.9  |proj g|=       0.35782
At iterate    25  f =       -199.9  |proj g|=       0.35773

iterations 25
function evaluations 32
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.357726
final function value -199.898

F = -199.898
final  value -199.898423 
converged
 
INFO  [02:16:16.314] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:16:16.365] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:16:16.372] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:16:29.096] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:16:41.484] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:16:53.802] [mlr3]  Finished benchmark 
INFO  [02:16:53.871] [bbotk] Result of batch 24: 
INFO  [02:16:53.872] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:16:53.872] [bbotk]              6.336593                 3.491461                       0.1580893 
INFO  [02:16:53.872] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:16:53.872] [bbotk]                     3788        0.562 -0.971876         <NA>   0.9754178 
INFO  [02:16:53.872] [bbotk]                                 uhash 
INFO  [02:16:53.872] [bbotk]  364b4a8c-2683-4aa5-b201-14c5bf8e08d9 
DEBUG [02:16:54.814] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.402421e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.40242e-05 0.001765565 
  - best initial criterion value(s) :  206.4536 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -206.45  |proj g|=      0.46438
At iterate     1  f =      -209.09  |proj g|=        2.0448
At iterate     2  f =      -209.18  |proj g|=        1.9435
At iterate     3  f =      -209.27  |proj g|=        1.7306
At iterate     4  f =      -209.48  |proj g|=        1.6203
At iterate     5  f =      -210.08  |proj g|=       0.92897
At iterate     6  f =      -210.39  |proj g|=        1.5152
At iterate     7  f =      -210.43  |proj g|=        1.4301
At iterate     8  f =      -210.43  |proj g|=        1.3747
At iterate     9  f =      -210.43  |proj g|=        1.3825
At iterate    10  f =      -210.43  |proj g|=        1.3822

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.38222
final function value -210.433

F = -210.433
final  value -210.433138 
converged
 
INFO  [02:16:54.819] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:16:54.874] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:16:54.898] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:17:03.202] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:17:10.439] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:17:17.582] [mlr3]  Finished benchmark 
INFO  [02:17:17.665] [bbotk] Result of batch 25: 
INFO  [02:17:17.667] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:17:17.667] [bbotk]              9.157503                 4.163937                      0.01991887 
INFO  [02:17:17.667] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:17:17.667] [bbotk]                     2648        0.738 -0.9668772         <NA>   0.9552592 
INFO  [02:17:17.667] [bbotk]                                 uhash 
INFO  [02:17:17.667] [bbotk]  83fd515a-80cc-425a-94ee-ad6b6c2e37a1 
DEBUG [02:17:18.367] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.405391e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.405391e-05 0.001754403 
  - best initial criterion value(s) :  207.5076 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -207.51  |proj g|=      0.85327
At iterate     1  f =      -214.54  |proj g|=       0.74107
At iterate     2  f =      -216.46  |proj g|=       0.63354
At iterate     3  f =       -216.8  |proj g|=       0.62449
At iterate     4  f =      -217.07  |proj g|=       0.38899
At iterate     5  f =      -217.12  |proj g|=       0.60319
At iterate     6  f =      -217.12  |proj g|=       0.59359
At iterate     7  f =      -217.12  |proj g|=       0.41212
At iterate     8  f =      -217.12  |proj g|=       0.41265
At iterate     9  f =      -217.12  |proj g|=        0.4128
At iterate    10  f =      -217.12  |proj g|=       0.41282

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.412817
final function value -217.121

F = -217.121
final  value -217.121476 
converged
 
INFO  [02:17:18.371] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:17:18.428] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:17:18.435] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:17:24.880] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:17:32.447] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:17:39.125] [mlr3]  Finished benchmark 
INFO  [02:17:39.193] [bbotk] Result of batch 26: 
INFO  [02:17:39.194] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:17:39.194] [bbotk]              5.339034                 2.638189                       0.2047654 
INFO  [02:17:39.194] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:17:39.194] [bbotk]                     2468        0.512 -0.9652194         <NA>   0.9741757 
INFO  [02:17:39.194] [bbotk]                                 uhash 
INFO  [02:17:39.194] [bbotk]  e158cf24-1fef-4de4-aac2-ae4a3c724d09 
DEBUG [02:17:39.897] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.387743e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.387743e-05 0.001742878 
  - best initial criterion value(s) :  219.6737 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -219.67  |proj g|=      0.67468
At iterate     1  f =      -219.97  |proj g|=       0.77451
At iterate     2  f =      -219.98  |proj g|=       0.76942
At iterate     3  f =      -219.99  |proj g|=       0.76344
At iterate     4  f =         -220  |proj g|=       0.75894
At iterate     5  f =      -220.01  |proj g|=       0.76748
At iterate     6  f =      -220.01  |proj g|=       0.77105
At iterate     7  f =      -220.01  |proj g|=       0.77173
At iterate     8  f =      -220.01  |proj g|=        0.7718

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.7718
final function value -220.014

F = -220.014
final  value -220.013911 
converged
 
INFO  [02:17:39.901] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:17:39.956] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:17:39.963] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:17:43.768] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:17:49.555] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:17:52.214] [mlr3]  Finished benchmark 
INFO  [02:17:52.282] [bbotk] Result of batch 27: 
INFO  [02:17:52.284] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:17:52.284] [bbotk]              7.632305                 9.113243                       0.1727899 
INFO  [02:17:52.284] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:17:52.284] [bbotk]                      991        0.516 -0.9652623         <NA>   0.9684494 
INFO  [02:17:52.284] [bbotk]                                 uhash 
INFO  [02:17:52.284] [bbotk]  69b673b2-1baf-4f5b-9da4-761a45556773 
DEBUG [02:17:52.984] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.363475e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.363475e-05 0.001694502 
  - best initial criterion value(s) :  218.2565 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -218.26  |proj g|=      0.96775
At iterate     1  f =      -219.96  |proj g|=        1.8657
At iterate     2  f =      -221.37  |proj g|=        1.5696
At iterate     3  f =      -222.17  |proj g|=        1.1915
At iterate     4  f =      -222.29  |proj g|=        1.1447
At iterate     5  f =      -222.33  |proj g|=        1.1519
At iterate     6  f =       -222.5  |proj g|=        1.1765
At iterate     7  f =      -222.68  |proj g|=        1.2811
At iterate     8  f =      -222.76  |proj g|=        1.2992
At iterate     9  f =      -222.77  |proj g|=        1.2482
At iterate    10  f =      -222.77  |proj g|=         1.261
At iterate    11  f =      -222.77  |proj g|=        1.2644
At iterate    12  f =      -222.77  |proj g|=        1.2644

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.2644
final function value -222.771

F = -222.771
final  value -222.770760 
converged
 
INFO  [02:17:52.988] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:17:53.043] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:17:53.050] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:17:59.558] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:18:06.520] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:18:12.929] [mlr3]  Finished benchmark 
INFO  [02:18:12.995] [bbotk] Result of batch 28: 
INFO  [02:18:12.997] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:18:12.997] [bbotk]              7.490481                 4.179333                       0.4887853 
INFO  [02:18:12.997] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:18:12.997] [bbotk]                     2450        0.516 -0.9632134         <NA>   0.9783295 
INFO  [02:18:12.997] [bbotk]                                 uhash 
INFO  [02:18:12.997] [bbotk]  88cd03dc-1ff1-41f1-8447-d5b3f25b0a08 
DEBUG [02:18:13.713] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.358808e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.358808e-05 0.001701741 
  - best initial criterion value(s) :  223.4629 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -223.46  |proj g|=       1.4513
At iterate     1  f =      -223.81  |proj g|=        1.3853
At iterate     2  f =      -223.85  |proj g|=        1.3892
At iterate     3  f =      -223.86  |proj g|=        1.3879
At iterate     4  f =      -223.86  |proj g|=        1.3879
At iterate     5  f =      -223.86  |proj g|=        1.3879

iterations 5
function evaluations 8
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.38789
final function value -223.862

F = -223.862
final  value -223.862005 
converged
 
INFO  [02:18:13.717] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:18:13.771] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:18:13.778] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:18:18.140] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:18:22.896] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:18:26.756] [mlr3]  Finished benchmark 
INFO  [02:18:26.823] [bbotk] Result of batch 29: 
INFO  [02:18:26.824] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:18:26.824] [bbotk]               3.85524                 6.655068                       0.1490753 
INFO  [02:18:26.824] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:18:26.824] [bbotk]                     1544        0.524 -0.9686703         <NA>     0.96625 
INFO  [02:18:26.824] [bbotk]                                 uhash 
INFO  [02:18:26.824] [bbotk]  d4218581-8d3c-4f11-ae6e-50b3ed51b088 
DEBUG [02:18:27.760] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.336267e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.336267e-05 0.001663481 
  - best initial criterion value(s) :  222.1968 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -222.2  |proj g|=       2.2234
At iterate     1  f =      -226.66  |proj g|=        1.0614
At iterate     2  f =      -234.02  |proj g|=       0.71848
At iterate     3  f =      -234.12  |proj g|=       0.77229
At iterate     4  f =      -234.13  |proj g|=        0.7699
At iterate     5  f =      -234.18  |proj g|=       0.75898
At iterate     6  f =      -234.18  |proj g|=       0.76907
At iterate     7  f =      -234.19  |proj g|=       0.76331
At iterate     8  f =      -234.19  |proj g|=       0.76295
At iterate     9  f =      -234.19  |proj g|=       0.76307
At iterate    10  f =      -234.19  |proj g|=       0.76388
At iterate    11  f =      -234.19  |proj g|=       0.76502
At iterate    12  f =      -234.19  |proj g|=       0.76621
At iterate    13  f =       -234.2  |proj g|=       0.76739
At iterate    14  f =      -234.21  |proj g|=       0.76814
At iterate    15  f =      -234.25  |proj g|=       0.76405
At iterate    16  f =      -234.32  |proj g|=       0.76779
At iterate    17  f =      -234.47  |proj g|=       0.73331
At iterate    18  f =      -234.52  |proj g|=       0.75342
At iterate    19  f =      -234.76  |proj g|=       0.71099
At iterate    20  f =      -235.02  |proj g|=        0.5964
At iterate    21  f =      -235.15  |proj g|=       0.66303
At iterate    22  f =      -235.19  |proj g|=       0.65729
At iterate    23  f =      -235.19  |proj g|=       0.65276
At iterate    24  f =      -235.19  |proj g|=       0.65281
At iterate    25  f =      -235.19  |proj g|=       0.65336
At iterate    26  f =      -235.19  |proj g|=       0.65322
At iterate    27  f =      -235.19  |proj g|=        0.6532

iterations 27
function evaluations 37
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.653198
final function value -235.193

F = -235.193
final  value -235.193061 
converged
 
INFO  [02:18:27.764] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:18:27.820] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:18:27.827] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:18:35.853] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:18:47.059] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:18:55.893] [mlr3]  Finished benchmark 
INFO  [02:18:55.992] [bbotk] Result of batch 30: 
INFO  [02:18:55.994] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:18:55.994] [bbotk]              6.078503                 5.860577                      0.08537591 
INFO  [02:18:55.994] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:18:55.994] [bbotk]                     2907        0.668 -0.9655504         <NA>   0.9705663 
INFO  [02:18:55.994] [bbotk]                                 uhash 
INFO  [02:18:55.994] [bbotk]  92b238b0-5344-4819-b51c-c33bc7c05d76 
DEBUG [02:18:56.749] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.31513e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.31513e-05 0.00164403 
  - best initial criterion value(s) :  230.0477 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -230.05  |proj g|=       0.5524
At iterate     1  f =      -231.44  |proj g|=       0.85922
At iterate     2  f =      -231.54  |proj g|=       0.76286
At iterate     3  f =      -231.63  |proj g|=       0.69305
At iterate     4  f =      -231.72  |proj g|=       0.68264
At iterate     5  f =      -232.43  |proj g|=       0.60086
At iterate     6  f =      -233.27  |proj g|=       0.59134
At iterate     7  f =      -234.07  |proj g|=       0.62257
At iterate     8  f =       -234.1  |proj g|=       0.66759
At iterate     9  f =       -234.1  |proj g|=       0.63195
At iterate    10  f =       -234.1  |proj g|=       0.63104
At iterate    11  f =       -234.1  |proj g|=       0.63117
At iterate    12  f =       -234.1  |proj g|=       0.63116

iterations 12
function evaluations 16
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.631164
final function value -234.099

F = -234.099
final  value -234.099221 
converged
 
INFO  [02:18:56.753] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:18:56.807] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:18:56.814] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:18:59.071] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:19:01.325] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:19:03.588] [mlr3]  Finished benchmark 
INFO  [02:19:03.670] [bbotk] Result of batch 31: 
INFO  [02:19:03.672] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:19:03.672] [bbotk]              4.926145                 6.034627                      0.05404664 
INFO  [02:19:03.672] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:19:03.672] [bbotk]                      674         0.56 -0.969991         <NA>   0.9448023 
INFO  [02:19:03.672] [bbotk]                                 uhash 
INFO  [02:19:03.672] [bbotk]  ffb24d3a-1f84-4734-9516-3b8fe0d9ba75 
DEBUG [02:19:04.464] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.380212e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.380212e-05 0.00173142 
  - best initial criterion value(s) :  234.3853 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -234.39  |proj g|=        3.196
At iterate     1  f =      -234.73  |proj g|=        4.5196
At iterate     2  f =      -236.36  |proj g|=        4.3982
At iterate     3  f =      -238.49  |proj g|=        3.3518
At iterate     4  f =      -238.95  |proj g|=        2.7711
At iterate     5  f =      -239.32  |proj g|=         1.753
At iterate     6  f =      -239.49  |proj g|=        1.9971
At iterate     7  f =      -239.49  |proj g|=        1.9566
At iterate     8  f =      -239.49  |proj g|=         1.959
At iterate     9  f =      -239.49  |proj g|=        1.9661
At iterate    10  f =      -239.49  |proj g|=        1.9745
At iterate    11  f =      -239.49  |proj g|=         1.989
At iterate    12  f =       -239.5  |proj g|=          2.01
At iterate    13  f =      -239.51  |proj g|=        2.0398
At iterate    14  f =      -239.53  |proj g|=        2.0728
At iterate    15  f =      -239.61  |proj g|=        2.0861
At iterate    16  f =      -239.79  |proj g|=        2.0078
At iterate    17  f =       -240.2  |proj g|=        1.7013
At iterate    18  f =      -241.06  |proj g|=        1.0316
At iterate    19  f =      -241.71  |proj g|=       0.86773
At iterate    20  f =      -241.88  |proj g|=        0.8721
At iterate    21  f =      -241.93  |proj g|=       0.84442
At iterate    22  f =      -242.05  |proj g|=       0.97006
At iterate    23  f =      -242.56  |proj g|=       0.88472
At iterate    24  f =      -243.24  |proj g|=        0.7678
At iterate    25  f =      -244.11  |proj g|=       0.62079
At iterate    26  f =      -244.91  |proj g|=       0.51203
At iterate    27  f =      -245.27  |proj g|=       0.64766
At iterate    28  f =      -245.34  |proj g|=       0.54579
At iterate    29  f =      -245.36  |proj g|=       0.54723
At iterate    30  f =      -245.36  |proj g|=       0.54834
At iterate    31  f =      -245.36  |proj g|=       0.54798
At iterate    32  f =      -245.36  |proj g|=       0.54798

iterations 32
function evaluations 36
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.54798
final function value -245.358

F = -245.358
final  value -245.357733 
converged
 
INFO  [02:19:04.468] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:19:04.523] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:19:04.530] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:19:06.930] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:19:09.118] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:19:12.041] [mlr3]  Finished benchmark 
INFO  [02:19:12.109] [bbotk] Result of batch 32: 
INFO  [02:19:12.111] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:19:12.111] [bbotk]              3.163408                 3.615194                       0.1954965 
INFO  [02:19:12.111] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:19:12.111] [bbotk]                      727        0.562 -0.9576914         <NA>   0.9565661 
INFO  [02:19:12.111] [bbotk]                                 uhash 
INFO  [02:19:12.111] [bbotk]  e9c57c6b-475e-45e5-9ed6-fcf8d3766a32 
DEBUG [02:19:12.848] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.377294e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.377294e-05 0.001722156 
  - best initial criterion value(s) :  240.2586 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -240.26  |proj g|=      0.68015
At iterate     1  f =      -241.12  |proj g|=       0.63032
At iterate     2  f =      -241.18  |proj g|=       0.62874
At iterate     3  f =      -241.19  |proj g|=        0.5757
At iterate     4  f =      -241.19  |proj g|=       0.57748
At iterate     5  f =      -241.19  |proj g|=       0.57776
At iterate     6  f =       -241.2  |proj g|=       0.63304
At iterate     7  f =       -241.2  |proj g|=       0.63362
At iterate     8  f =       -241.2  |proj g|=       0.63357
At iterate     9  f =       -241.2  |proj g|=       0.63357

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.633572
final function value -241.195

F = -241.195
final  value -241.195398 
converged
 
INFO  [02:19:12.852] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:19:12.911] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:19:12.918] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:19:24.879] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:19:36.884] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:19:49.924] [mlr3]  Finished benchmark 
INFO  [02:19:49.995] [bbotk] Result of batch 33: 
INFO  [02:19:49.997] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:19:49.997] [bbotk]              7.562574                 7.776588                       0.1520432 
INFO  [02:19:49.997] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:19:49.997] [bbotk]                     4180        0.544 -0.9694756         <NA>   0.9760647 
INFO  [02:19:49.997] [bbotk]                                 uhash 
INFO  [02:19:49.997] [bbotk]  89ad0e4f-3910-4f85-806c-d7f97a802de3 
DEBUG [02:19:50.775] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.367081e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.367081e-05 0.001718672 
  - best initial criterion value(s) :  229.9577 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -229.96  |proj g|=      0.90774
At iterate     1  f =      -231.03  |proj g|=        1.6199
At iterate     2  f =      -232.95  |proj g|=         1.388
At iterate     3  f =      -236.09  |proj g|=       0.96807
At iterate     4  f =      -237.03  |proj g|=       0.83893
At iterate     5  f =      -239.63  |proj g|=       0.73305
At iterate     6  f =      -242.22  |proj g|=       0.69216
At iterate     7  f =      -242.62  |proj g|=       0.92176
At iterate     8  f =      -243.14  |proj g|=        0.8772
At iterate     9  f =      -243.38  |proj g|=       0.80662
At iterate    10  f =      -243.41  |proj g|=       0.82558
At iterate    11  f =      -243.41  |proj g|=        0.8217
At iterate    12  f =      -243.41  |proj g|=       0.82155
At iterate    13  f =      -243.41  |proj g|=       0.82155

iterations 13
function evaluations 19
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.821547
final function value -243.409

F = -243.409
final  value -243.409361 
converged
 
INFO  [02:19:50.779] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:19:50.836] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:19:50.844] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:20:03.010] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:20:19.847] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:20:33.113] [mlr3]  Finished benchmark 
INFO  [02:20:33.201] [bbotk] Result of batch 34: 
INFO  [02:20:33.203] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:20:33.203] [bbotk]              8.755937                 9.546277                      0.08913087 
INFO  [02:20:33.203] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:20:33.203] [bbotk]                     4241        0.585 -0.9700751         <NA>   0.9739483 
INFO  [02:20:33.203] [bbotk]                                 uhash 
INFO  [02:20:33.203] [bbotk]  ce154ca4-ce75-4fe6-81f9-91c8f08ba800 
DEBUG [02:20:33.951] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.351989e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.351989e-05 0.001707531 
  - best initial criterion value(s) :  248.6102 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -248.61  |proj g|=       2.0093
At iterate     1  f =      -250.49  |proj g|=        0.8338
At iterate     2  f =      -252.79  |proj g|=       0.59462
At iterate     3  f =      -255.51  |proj g|=       0.54284
At iterate     4  f =      -255.57  |proj g|=       0.41902
At iterate     5  f =      -255.58  |proj g|=        0.4154
At iterate     6  f =      -255.62  |proj g|=       0.57683
At iterate     7  f =      -255.62  |proj g|=        0.5754
At iterate     8  f =      -255.62  |proj g|=       0.57545
At iterate     9  f =      -255.62  |proj g|=        0.5755

iterations 9
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.575504
final function value -255.621

F = -255.621
final  value -255.621284 
converged
 
INFO  [02:20:33.955] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:20:34.013] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:20:34.020] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:20:48.846] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:21:03.997] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:21:17.572] [mlr3]  Finished benchmark 
INFO  [02:21:17.642] [bbotk] Result of batch 35: 
INFO  [02:21:17.644] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:21:17.644] [bbotk]              5.480533                 2.596944                       0.4921247 
INFO  [02:21:17.644] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:21:17.644] [bbotk]                     4743        0.555 -0.9663845         <NA>   0.9793469 
INFO  [02:21:17.644] [bbotk]                                 uhash 
INFO  [02:21:17.644] [bbotk]  133ff591-b677-4bc3-a0ec-874220bc2990 
DEBUG [02:21:18.439] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.351872e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.351872e-05 0.001721073 
  - best initial criterion value(s) :  248.8561 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -248.86  |proj g|=        8.473
At iterate     1  f =       -254.3  |proj g|=        5.3311
At iterate     2  f =      -261.13  |proj g|=        2.7543
At iterate     3  f =      -262.06  |proj g|=        1.5024
At iterate     4  f =       -262.3  |proj g|=        1.2933
At iterate     5  f =      -262.41  |proj g|=       0.89145
At iterate     6  f =      -262.41  |proj g|=       0.95646
At iterate     7  f =      -262.41  |proj g|=        0.9443
At iterate     8  f =      -262.41  |proj g|=       0.94316
At iterate     9  f =      -262.41  |proj g|=       0.93333
At iterate    10  f =      -262.41  |proj g|=       0.92249
At iterate    11  f =      -262.41  |proj g|=       0.90165
At iterate    12  f =      -262.42  |proj g|=       0.86989
At iterate    13  f =      -262.43  |proj g|=       0.81779
At iterate    14  f =      -262.46  |proj g|=       0.73898
At iterate    15  f =      -262.55  |proj g|=       0.66916
At iterate    16  f =      -262.74  |proj g|=       0.65916
At iterate    17  f =      -263.07  |proj g|=       0.66415
At iterate    18  f =      -263.26  |proj g|=        1.0495
At iterate    19  f =      -263.35  |proj g|=        1.0053
At iterate    20  f =      -263.39  |proj g|=       0.99192
At iterate    21  f =      -264.57  |proj g|=       0.60431
At iterate    22  f =      -264.72  |proj g|=       0.58922
At iterate    23  f =      -264.82  |proj g|=       0.57896
At iterate    24  f =      -264.83  |proj g|=       0.59954
At iterate    25  f =      -264.84  |proj g|=       0.58885
At iterate    26  f =      -264.84  |proj g|=       0.58734
At iterate    27  f =      -264.84  |proj g|=       0.58748
At iterate    28  f =      -264.84  |proj g|=       0.58765
At iterate    29  f =      -264.84  |proj g|=       0.58764

iterations 29
function evaluations 36
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.587642
final function value -264.839

F = -264.839
final  value -264.838609 
converged
 
INFO  [02:21:18.443] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:21:18.643] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:21:18.651] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:21:27.915] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:21:36.902] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:21:46.440] [mlr3]  Finished benchmark 
INFO  [02:21:46.509] [bbotk] Result of batch 36: 
INFO  [02:21:46.510] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:21:46.510] [bbotk]              7.734727                 7.982693                       0.3382609 
INFO  [02:21:46.510] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:21:46.510] [bbotk]                     3253        0.557 -0.9600649         <NA>   0.9781328 
INFO  [02:21:46.510] [bbotk]                                 uhash 
INFO  [02:21:46.510] [bbotk]  405ba7b1-a36e-4deb-afc4-bb10418f8588 
DEBUG [02:21:47.278] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.3472e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.3472e-05 0.001721768 
  - best initial criterion value(s) :  255.1113 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -255.11  |proj g|=       2.0083
At iterate     1  f =      -260.61  |proj g|=       0.63216
At iterate     2  f =      -260.85  |proj g|=       0.60032
At iterate     3  f =      -261.01  |proj g|=       0.50909
At iterate     4  f =      -261.04  |proj g|=       0.53849
At iterate     5  f =      -261.04  |proj g|=       0.53556
At iterate     6  f =      -261.07  |proj g|=       0.51975
At iterate     7  f =      -261.11  |proj g|=       0.50762
At iterate     8  f =      -261.18  |proj g|=       0.49791
At iterate     9  f =      -261.24  |proj g|=       0.51037
At iterate    10  f =      -261.26  |proj g|=       0.60685
At iterate    11  f =      -261.26  |proj g|=       0.60569
At iterate    12  f =      -261.26  |proj g|=       0.60566
At iterate    13  f =      -261.26  |proj g|=       0.60566

iterations 13
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.605656
final function value -261.258

F = -261.258
final  value -261.257702 
converged
 
INFO  [02:21:47.282] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:21:47.364] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:21:47.376] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:21:53.567] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:21:59.499] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:22:04.989] [mlr3]  Finished benchmark 
INFO  [02:22:05.057] [bbotk] Result of batch 37: 
INFO  [02:22:05.059] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:22:05.059] [bbotk]              5.955996                 9.964204                       0.1374349 
INFO  [02:22:05.059] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:22:05.059] [bbotk]                     1971         0.56 -0.9683516         <NA>   0.9710986 
INFO  [02:22:05.059] [bbotk]                                 uhash 
INFO  [02:22:05.059] [bbotk]  d3ffd4d2-1802-42c8-862b-1344aa1965bf 
DEBUG [02:22:05.942] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.328509e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.328509e-05 0.001704898 
  - best initial criterion value(s) :  262.7033 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -262.7  |proj g|=       1.7399
At iterate     1  f =      -267.26  |proj g|=       0.78004
At iterate     2  f =      -267.37  |proj g|=       0.74807
At iterate     3  f =      -267.45  |proj g|=       0.68663
At iterate     4  f =      -267.52  |proj g|=       0.70452
At iterate     5  f =      -267.87  |proj g|=       0.73358
At iterate     6  f =      -268.12  |proj g|=        0.7275
At iterate     7  f =      -268.14  |proj g|=        0.6924
At iterate     8  f =      -268.19  |proj g|=       0.68863
At iterate     9  f =      -268.19  |proj g|=       0.68693
At iterate    10  f =      -268.19  |proj g|=       0.68699
At iterate    11  f =      -268.19  |proj g|=       0.68701
At iterate    12  f =      -268.19  |proj g|=       0.68704
At iterate    13  f =      -268.19  |proj g|=       0.68657
At iterate    14  f =      -268.19  |proj g|=       0.68695
At iterate    15  f =      -268.19  |proj g|=       0.68743
At iterate    16  f =      -268.19  |proj g|=       0.68852
At iterate    17  f =      -268.19  |proj g|=       0.69006
At iterate    18  f =      -268.19  |proj g|=       0.69258
At iterate    19  f =      -268.19  |proj g|=       0.69638
At iterate    20  f =       -268.2  |proj g|=       0.70209
At iterate    21  f =       -268.2  |proj g|=       0.70936
At iterate    22  f =      -268.22  |proj g|=       0.71465
At iterate    23  f =      -268.24  |proj g|=       0.70583
At iterate    24  f =      -268.25  |proj g|=       0.68465
At iterate    25  f =      -268.26  |proj g|=       0.68014
At iterate    26  f =      -268.27  |proj g|=        0.6665
At iterate    27  f =       -268.3  |proj g|=        0.6479
At iterate    28  f =       -268.4  |proj g|=       0.61573
At iterate    29  f =      -268.61  |proj g|=       0.57823
At iterate    30  f =      -269.11  |proj g|=        0.5705
At iterate    31  f =      -269.44  |proj g|=       0.62008
At iterate    32  f =      -269.57  |proj g|=       0.68943
At iterate    33  f =      -269.58  |proj g|=       0.68327
At iterate    34  f =      -269.59  |proj g|=       0.67525
At iterate    35  f =      -269.59  |proj g|=        0.6786
At iterate    36  f =      -269.59  |proj g|=       0.67915
At iterate    37  f =      -269.59  |proj g|=        0.6792

iterations 37
function evaluations 46
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.679198
final function value -269.591

F = -269.591
final  value -269.590818 
converged
 
INFO  [02:22:05.947] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:22:06.002] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:22:06.009] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:22:15.442] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:22:24.694] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:22:32.076] [mlr3]  Finished benchmark 
INFO  [02:22:32.143] [bbotk] Result of batch 38: 
INFO  [02:22:32.145] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:22:32.145] [bbotk]              9.328738                 2.525699                       0.1186217 
INFO  [02:22:32.145] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:22:32.145] [bbotk]                     3238        0.621 -0.9662674         <NA>   0.9742854 
INFO  [02:22:32.145] [bbotk]                                 uhash 
INFO  [02:22:32.145] [bbotk]  e421a66a-1477-4b31-b15f-87e971f6c124 
DEBUG [02:22:33.099] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.314626e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.314626e-05 0.001698014 
  - best initial criterion value(s) :  258.1906 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -258.19  |proj g|=       1.3859
At iterate     1  f =      -263.45  |proj g|=        3.0552
At iterate     2  f =      -264.78  |proj g|=        2.9726
At iterate     3  f =      -266.09  |proj g|=        2.6947
At iterate     4  f =       -266.1  |proj g|=        2.6212
At iterate     5  f =      -266.11  |proj g|=        2.6489
At iterate     6  f =      -266.11  |proj g|=        2.6418
At iterate     7  f =      -266.12  |proj g|=        2.6177
At iterate     8  f =      -266.12  |proj g|=        2.6187
At iterate     9  f =      -266.12  |proj g|=        2.6197
At iterate    10  f =      -266.12  |proj g|=        2.6208
At iterate    11  f =      -266.12  |proj g|=        2.6222
At iterate    12  f =      -266.12  |proj g|=        2.6252
At iterate    13  f =      -266.12  |proj g|=        2.6263
At iterate    14  f =      -266.12  |proj g|=        2.6297
At iterate    15  f =      -266.12  |proj g|=        2.6337
At iterate    16  f =      -266.14  |proj g|=        2.6392
At iterate    17  f =      -266.17  |proj g|=        2.6424
At iterate    18  f =      -266.24  |proj g|=        2.6014
At iterate    19  f =      -266.41  |proj g|=        2.6148
At iterate    20  f =      -266.65  |proj g|=        2.2408
At iterate    21  f =       -267.1  |proj g|=        2.2222
At iterate    22  f =       -269.7  |proj g|=        1.7799
At iterate    23  f =      -271.97  |proj g|=        1.3502
At iterate    24  f =      -273.28  |proj g|=        1.0787
At iterate    25  f =      -274.48  |proj g|=        1.1602
At iterate    26  f =      -275.69  |proj g|=        1.0851
At iterate    27  f =      -276.03  |proj g|=       0.94771
At iterate    28  f =      -276.42  |proj g|=       0.83663
At iterate    29  f =      -276.46  |proj g|=        0.6032
At iterate    30  f =      -276.47  |proj g|=         0.605
At iterate    31  f =      -276.49  |proj g|=       0.68247
At iterate    32  f =      -276.49  |proj g|=       0.68096
At iterate    33  f =      -276.49  |proj g|=       0.67993
At iterate    34  f =      -276.49  |proj g|=       0.68037
At iterate    35  f =      -276.49  |proj g|=       0.68036

iterations 35
function evaluations 44
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.680362
final function value -276.491

F = -276.491
final  value -276.490968 
converged
 
INFO  [02:22:33.103] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:22:33.175] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:22:33.181] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:22:38.752] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:22:44.369] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:22:49.909] [mlr3]  Finished benchmark 
INFO  [02:22:50.000] [bbotk] Result of batch 39: 
INFO  [02:22:50.002] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:22:50.002] [bbotk]              7.124694                 7.732655                       0.3079442 
INFO  [02:22:50.002] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:22:50.002] [bbotk]                     2796        0.651 -0.965459         <NA>   0.9771812 
INFO  [02:22:50.002] [bbotk]                                 uhash 
INFO  [02:22:50.002] [bbotk]  5f8a2af1-9875-4023-9074-2859a840ef25 
DEBUG [02:22:50.871] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.307276e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.307276e-05 0.001696712 
  - best initial criterion value(s) :  266.2656 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -266.27  |proj g|=      0.79222
At iterate     1  f =      -267.62  |proj g|=        1.2804
At iterate     2  f =      -271.81  |proj g|=       0.72251
At iterate     3  f =       -271.9  |proj g|=       0.71629
At iterate     4  f =      -272.05  |proj g|=       0.68062
At iterate     5  f =      -272.08  |proj g|=       0.69701
At iterate     6  f =      -272.08  |proj g|=       0.69343
At iterate     7  f =      -272.08  |proj g|=       0.69301
At iterate     8  f =      -272.08  |proj g|=       0.69303

iterations 8
function evaluations 10
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.693026
final function value -272.079

F = -272.079
final  value -272.079472 
converged
 
INFO  [02:22:50.875] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:22:50.930] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:22:50.937] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:22:54.634] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:22:58.030] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:23:01.619] [mlr3]  Finished benchmark 
INFO  [02:23:01.697] [bbotk] Result of batch 40: 
INFO  [02:23:01.699] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:23:01.699] [bbotk]              5.516436                 3.128689                       0.1673998 
INFO  [02:23:01.699] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:23:01.699] [bbotk]                     1990        0.636 -0.9699595         <NA>   0.9720434 
INFO  [02:23:01.699] [bbotk]                                 uhash 
INFO  [02:23:01.699] [bbotk]  91f5d7aa-a28d-4146-9511-1aacb56981af 
DEBUG [02:23:02.533] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.290618e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.42178 15.77119 0.9643483 9590 
  - variance bounds :  1.290617e-05 0.001682999 
  - best initial criterion value(s) :  265.2784 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -265.28  |proj g|=       1.0942
At iterate     1  f =      -265.79  |proj g|=        1.0555
At iterate     2  f =      -265.81  |proj g|=        1.0418
At iterate     3  f =      -265.83  |proj g|=        1.0501
At iterate     4  f =      -265.84  |proj g|=        1.0434
At iterate     5  f =      -265.84  |proj g|=        1.0446
At iterate     6  f =      -265.84  |proj g|=         1.045
At iterate     7  f =      -265.84  |proj g|=        1.0456
At iterate     8  f =      -265.84  |proj g|=        1.0432
At iterate     9  f =      -265.84  |proj g|=        1.0462
At iterate    10  f =      -265.84  |proj g|=          1.05
At iterate    11  f =      -265.84  |proj g|=        1.0576
At iterate    12  f =      -265.84  |proj g|=        1.0689
At iterate    13  f =      -265.85  |proj g|=        1.0874
At iterate    14  f =      -265.86  |proj g|=        1.1164
At iterate    15  f =      -265.91  |proj g|=        1.1632
At iterate    16  f =      -266.03  |proj g|=        1.2326
At iterate    17  f =      -266.31  |proj g|=        1.3122
At iterate    18  f =      -266.76  |proj g|=        1.3018
At iterate    19  f =      -266.89  |proj g|=        1.0995
At iterate    20  f =      -266.92  |proj g|=        1.1281
At iterate    21  f =      -266.97  |proj g|=        1.1629
At iterate    22  f =       -267.1  |proj g|=        1.2161
At iterate    23  f =      -267.42  |proj g|=        1.2698
At iterate    24  f =      -268.21  |proj g|=        1.2779
At iterate    25  f =       -269.7  |proj g|=        1.1106
At iterate    26  f =      -269.89  |proj g|=        1.2308
At iterate    27  f =      -271.87  |proj g|=       0.91409
At iterate    28  f =      -272.56  |proj g|=       0.69584
At iterate    29  f =      -272.87  |proj g|=       0.54109
At iterate    30  f =      -272.88  |proj g|=       0.55864
At iterate    31  f =      -272.88  |proj g|=       0.57463
At iterate    32  f =      -272.88  |proj g|=       0.57399
At iterate    33  f =      -272.88  |proj g|=       0.57398

iterations 33
function evaluations 38
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.573984
final function value -272.879

F = -272.879
final  value -272.879201 
converged
 
INFO  [02:23:02.538] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:23:02.631] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:23:02.646] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:23:05.780] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:23:09.037] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:23:12.143] [mlr3]  Finished benchmark 
INFO  [02:23:12.264] [bbotk] Result of batch 41: 
INFO  [02:23:12.266] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:23:12.266] [bbotk]              9.907933                 4.612394                         0.37294 
INFO  [02:23:12.266] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:23:12.266] [bbotk]                     1578        0.576 -0.971458         <NA>   0.9744298 
INFO  [02:23:12.266] [bbotk]                                 uhash 
INFO  [02:23:12.266] [bbotk]  6edc0f3e-a90f-4eae-958d-71d8f988ea96 
DEBUG [02:23:13.094] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.277637e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.277637e-05 0.001646221 
  - best initial criterion value(s) :  269.3789 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -269.38  |proj g|=       5.7772
At iterate     1  f =      -279.47  |proj g|=       0.64273
At iterate     2  f =      -282.08  |proj g|=        2.2687
At iterate     3  f =      -282.27  |proj g|=        2.0418
At iterate     4  f =      -282.34  |proj g|=        1.7855
At iterate     5  f =      -282.35  |proj g|=        1.8488
At iterate     6  f =      -282.36  |proj g|=        1.8999
At iterate     7  f =      -282.36  |proj g|=        1.9046
At iterate     8  f =      -282.36  |proj g|=        1.9015
At iterate     9  f =      -282.36  |proj g|=        1.9008

iterations 9
function evaluations 11
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.90082
final function value -282.356

F = -282.356
final  value -282.355802 
converged
 
INFO  [02:23:13.099] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:23:13.160] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:23:13.168] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:23:14.647] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:23:16.057] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:23:17.397] [mlr3]  Finished benchmark 
INFO  [02:23:17.465] [bbotk] Result of batch 42: 
INFO  [02:23:17.467] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:23:17.467] [bbotk]              8.958287                 5.516148                       0.2981967 
INFO  [02:23:17.467] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:23:17.467] [bbotk]                      521        0.594 -0.9693123         <NA>   0.9680044 
INFO  [02:23:17.467] [bbotk]                                 uhash 
INFO  [02:23:17.467] [bbotk]  c30ed000-c023-4e61-acd4-d566e8f11f61 
DEBUG [02:23:18.285] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.259913e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.259913e-05 0.001605224 
  - best initial criterion value(s) :  277.5802 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -277.58  |proj g|=       4.4181
At iterate     1  f =      -287.78  |proj g|=        2.6959
At iterate     2  f =      -289.91  |proj g|=        2.0296
At iterate     3  f =      -291.88  |proj g|=       0.79364
At iterate     4  f =      -292.43  |proj g|=       0.86719
At iterate     5  f =      -292.84  |proj g|=       0.89273
At iterate     6  f =      -294.39  |proj g|=       0.96565
At iterate     7  f =      -295.04  |proj g|=       0.98816
At iterate     8  f =      -295.24  |proj g|=        1.0661
At iterate     9  f =      -295.27  |proj g|=        1.0601
At iterate    10  f =      -295.28  |proj g|=        1.0559
At iterate    11  f =      -295.28  |proj g|=        1.0557
At iterate    12  f =      -295.28  |proj g|=        1.0557
At iterate    13  f =      -295.28  |proj g|=        1.0557
At iterate    14  f =      -295.28  |proj g|=        1.0556
At iterate    15  f =      -295.28  |proj g|=        1.0555
At iterate    16  f =      -295.28  |proj g|=        1.0553
At iterate    17  f =      -295.28  |proj g|=        1.0553
At iterate    18  f =      -295.28  |proj g|=        1.0549
At iterate    19  f =      -295.28  |proj g|=        1.0556
At iterate    20  f =      -295.29  |proj g|=        1.0522
At iterate    21  f =       -295.3  |proj g|=        1.0534
At iterate    22  f =      -295.31  |proj g|=        1.0373
At iterate    23  f =      -295.34  |proj g|=        1.0471
At iterate    24  f =      -295.39  |proj g|=        1.0562
At iterate    25  f =      -295.41  |proj g|=        1.0597
At iterate    26  f =      -295.41  |proj g|=        1.0575
At iterate    27  f =      -295.41  |proj g|=        1.0551
At iterate    28  f =      -295.41  |proj g|=        1.0551

iterations 28
function evaluations 33
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.05507
final function value -295.409

F = -295.409
final  value -295.408761 
converged
 
INFO  [02:23:18.289] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:23:18.345] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:23:18.352] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:23:19.737] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:23:21.143] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:23:22.458] [mlr3]  Finished benchmark 
INFO  [02:23:22.527] [bbotk] Result of batch 43: 
INFO  [02:23:22.528] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:23:22.528] [bbotk]              8.945124                 8.991219                        0.405852 
INFO  [02:23:22.528] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:23:22.528] [bbotk]                      510        0.586 -0.9595796         <NA>   0.9705197 
INFO  [02:23:22.528] [bbotk]                                 uhash 
INFO  [02:23:22.528] [bbotk]  272ab11c-e4ed-40bb-bebe-8fad7e601e70 
DEBUG [02:23:23.374] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.243265e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.243265e-05 0.001569925 
  - best initial criterion value(s) :  293.5605 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -293.56  |proj g|=       1.2151
At iterate     1  f =      -293.57  |proj g|=        1.2369
At iterate     2  f =      -293.68  |proj g|=        1.2193
At iterate     3  f =      -293.79  |proj g|=        1.1619
At iterate     4  f =       -293.8  |proj g|=        1.1758
At iterate     5  f =       -293.8  |proj g|=        1.1737
At iterate     6  f =       -293.8  |proj g|=        1.1737

iterations 6
function evaluations 11
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.17373
final function value -293.799

F = -293.799
final  value -293.799436 
converged
 
INFO  [02:23:23.378] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:23:23.460] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:23:23.467] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:23:28.863] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:23:34.081] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:23:39.818] [mlr3]  Finished benchmark 
INFO  [02:23:39.900] [bbotk] Result of batch 44: 
INFO  [02:23:39.901] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:23:39.901] [bbotk]              7.106932                 6.452558                        0.290749 
INFO  [02:23:39.901] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:23:39.901] [bbotk]                     2786        0.626 -0.9673719         <NA>    0.976963 
INFO  [02:23:39.901] [bbotk]                                 uhash 
INFO  [02:23:39.901] [bbotk]  7f268d22-3e34-4a90-a8e9-d029ab1beb22 
DEBUG [02:23:41.058] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.236193e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.236193e-05 0.001568425 
  - best initial criterion value(s) :  299.6105 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -299.61  |proj g|=      0.79252
At iterate     1  f =      -305.63  |proj g|=         1.549
At iterate     2  f =      -309.01  |proj g|=       0.58409
At iterate     3  f =      -309.12  |proj g|=       0.56995
At iterate     4  f =      -309.16  |proj g|=       0.53503
At iterate     5  f =      -309.17  |proj g|=       0.53493
At iterate     6  f =      -309.17  |proj g|=       0.53522
At iterate     7  f =      -309.17  |proj g|=        0.5354
At iterate     8  f =      -309.17  |proj g|=       0.53542

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.535425
final function value -309.165

F = -309.165
final  value -309.165199 
converged
 
INFO  [02:23:41.062] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:23:41.116] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:23:41.123] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:23:46.461] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:23:53.238] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:24:01.856] [mlr3]  Finished benchmark 
INFO  [02:24:01.923] [bbotk] Result of batch 45: 
INFO  [02:24:01.925] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:24:01.925] [bbotk]              4.513519                 9.585363                      0.06129873 
INFO  [02:24:01.925] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:24:01.925] [bbotk]                     2644        0.885 -0.9645991         <NA>   0.9649528 
INFO  [02:24:01.925] [bbotk]                                 uhash 
INFO  [02:24:01.925] [bbotk]  1a3ca1d5-7324-45fd-b2a1-30f0e7619e38 
DEBUG [02:24:02.730] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.221399e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.221399e-05 0.001552186 
  - best initial criterion value(s) :  296.3775 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -296.38  |proj g|=       11.742
At iterate     1  f =      -306.41  |proj g|=         2.538
At iterate     2  f =      -312.03  |proj g|=        2.0336
At iterate     3  f =      -312.67  |proj g|=        1.4306
At iterate     4  f =      -313.16  |proj g|=       0.94172
At iterate     5  f =      -313.25  |proj g|=        0.9388
At iterate     6  f =       -313.3  |proj g|=       0.94368
At iterate     7  f =      -313.36  |proj g|=       0.97712
At iterate     8  f =      -313.37  |proj g|=       0.97687
At iterate     9  f =      -313.37  |proj g|=        0.9777
At iterate    10  f =      -313.37  |proj g|=       0.97784
At iterate    11  f =      -313.37  |proj g|=       0.97798
At iterate    12  f =      -313.37  |proj g|=       0.97828
At iterate    13  f =      -313.37  |proj g|=       0.97777
At iterate    14  f =      -313.37  |proj g|=       0.98013
At iterate    15  f =      -313.37  |proj g|=       0.97814
At iterate    16  f =      -313.38  |proj g|=       0.97444
At iterate    17  f =      -313.42  |proj g|=       0.96476
At iterate    18  f =      -313.52  |proj g|=       0.94922
At iterate    19  f =      -313.72  |proj g|=       0.92286
At iterate    20  f =      -314.03  |proj g|=       0.91659
At iterate    21  f =      -314.16  |proj g|=       0.86398
At iterate    22  f =      -314.32  |proj g|=       0.88117
At iterate    23  f =      -314.37  |proj g|=       0.89375
At iterate    24  f =      -314.39  |proj g|=        0.9054
At iterate    25  f =       -314.4  |proj g|=       0.90586
At iterate    26  f =       -314.4  |proj g|=       0.90501
At iterate    27  f =       -314.4  |proj g|=       0.90489
At iterate    28  f =       -314.4  |proj g|=       0.90489

iterations 28
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.904894
final function value -314.397

F = -314.397
final  value -314.396798 
converged
 
INFO  [02:24:02.735] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:24:02.791] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:24:02.798] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:24:06.508] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:24:09.899] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:24:12.480] [mlr3]  Finished benchmark 
INFO  [02:24:12.722] [bbotk] Result of batch 46: 
INFO  [02:24:12.724] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:24:12.724] [bbotk]              5.084667                 2.140417                       0.3335027 
INFO  [02:24:12.724] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:24:12.724] [bbotk]                      906        0.561 -0.961344         <NA>   0.9710327 
INFO  [02:24:12.724] [bbotk]                                 uhash 
INFO  [02:24:12.724] [bbotk]  26cb01cb-3637-4b2e-b52b-cdb357e8c5b7 
DEBUG [02:24:13.520] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.206169e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.206169e-05 0.001517041 
  - best initial criterion value(s) :  305.8573 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -305.86  |proj g|=       3.3587
At iterate     1  f =      -308.55  |proj g|=        1.2494
At iterate     2  f =       -311.3  |proj g|=        1.1859
At iterate     3  f =      -313.56  |proj g|=        1.0209
At iterate     4  f =      -313.79  |proj g|=        1.0047
At iterate     5  f =      -314.94  |proj g|=        1.0144
At iterate     6  f =      -316.07  |proj g|=        1.1016
At iterate     7  f =      -316.43  |proj g|=        1.1639
At iterate     8  f =      -316.54  |proj g|=        1.2074
At iterate     9  f =      -316.56  |proj g|=        1.2319
At iterate    10  f =      -316.56  |proj g|=         1.239
At iterate    11  f =      -316.56  |proj g|=        1.2398
At iterate    12  f =      -316.56  |proj g|=        1.2399

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.23989
final function value -316.559

F = -316.559
final  value -316.558734 
converged
 
INFO  [02:24:13.524] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:24:13.581] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:24:13.588] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:24:23.958] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:24:34.180] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:24:45.127] [mlr3]  Finished benchmark 
INFO  [02:24:45.229] [bbotk] Result of batch 47: 
INFO  [02:24:45.231] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:24:45.231] [bbotk]              3.696904                 5.891861                       0.1937482 
INFO  [02:24:45.231] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:24:45.231] [bbotk]                     3703        0.583 -0.9610941         <NA>   0.9730904 
INFO  [02:24:45.231] [bbotk]                                 uhash 
INFO  [02:24:45.231] [bbotk]  652ce100-17d9-45d3-b2a7-afb8161a9144 
DEBUG [02:24:46.084] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.193181e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.193181e-05 0.001509261 
  - best initial criterion value(s) :  310.8058 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -310.81  |proj g|=       1.3916
At iterate     1  f =      -311.95  |proj g|=        1.3492
At iterate     2  f =       -312.1  |proj g|=        1.3168
At iterate     3  f =       -312.4  |proj g|=        1.2104
At iterate     4  f =      -312.55  |proj g|=        1.2156
At iterate     5  f =      -312.77  |proj g|=        1.2464
At iterate     6  f =      -312.78  |proj g|=        1.2459
At iterate     7  f =      -312.78  |proj g|=        1.2466
At iterate     8  f =      -312.78  |proj g|=        1.2467
At iterate     9  f =      -312.78  |proj g|=        1.2466
At iterate    10  f =      -312.78  |proj g|=         1.247
At iterate    11  f =      -312.78  |proj g|=        1.2467
At iterate    12  f =      -312.78  |proj g|=        1.2464
At iterate    13  f =      -312.78  |proj g|=        1.2455
At iterate    14  f =      -312.78  |proj g|=        1.2442
At iterate    15  f =      -312.78  |proj g|=        1.2419
At iterate    16  f =      -312.79  |proj g|=        1.2393
At iterate    17  f =      -312.79  |proj g|=        1.2244
At iterate    18  f =      -312.81  |proj g|=        1.2241
At iterate    19  f =      -312.86  |proj g|=        1.2191
At iterate    20  f =         -313  |proj g|=         1.205
At iterate    21  f =      -313.42  |proj g|=        1.1587
At iterate    22  f =      -314.55  |proj g|=        1.0462
At iterate    23  f =      -315.33  |proj g|=       0.73468
At iterate    24  f =      -316.91  |proj g|=        1.4067
At iterate    25  f =      -318.94  |proj g|=       0.82176
At iterate    26  f =      -319.63  |proj g|=       0.70673
At iterate    27  f =      -319.68  |proj g|=       0.51345
At iterate    28  f =      -319.75  |proj g|=       0.60649
At iterate    29  f =      -319.75  |proj g|=       0.60148
At iterate    30  f =      -319.75  |proj g|=       0.53647
At iterate    31  f =      -319.75  |proj g|=        0.5396
At iterate    32  f =      -319.75  |proj g|=       0.53824
At iterate    33  f =      -319.75  |proj g|=       0.53801

iterations 33
function evaluations 41
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.538014
final function value -319.754

F = -319.754
final  value -319.753754 
converged
 
INFO  [02:24:46.090] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:24:46.151] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:24:46.158] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:25:00.517] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:25:13.973] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:25:27.927] [mlr3]  Finished benchmark 
INFO  [02:25:28.038] [bbotk] Result of batch 48: 
INFO  [02:25:28.040] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:25:28.040] [bbotk]              6.444082                 9.334605                      0.01917498 
INFO  [02:25:28.040] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:25:28.040] [bbotk]                     4433        0.584 -0.9666709         <NA>   0.9606077 
INFO  [02:25:28.040] [bbotk]                                 uhash 
INFO  [02:25:28.040] [bbotk]  7e649a72-fd5f-4395-8377-aee292812645 
DEBUG [02:25:28.916] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.185928e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.185928e-05 0.001494006 
  - best initial criterion value(s) :  309.2562 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -309.26  |proj g|=       2.5663
At iterate     1  f =      -316.52  |proj g|=        2.4411
At iterate     2  f =      -317.52  |proj g|=        2.3733
At iterate     3  f =      -317.99  |proj g|=        2.0637
At iterate     4  f =      -318.25  |proj g|=        2.2308
At iterate     5  f =      -318.28  |proj g|=        2.1991
At iterate     6  f =      -318.29  |proj g|=        2.1841
At iterate     7  f =      -318.31  |proj g|=        2.1618
At iterate     8  f =      -318.34  |proj g|=         2.131
At iterate     9  f =      -318.35  |proj g|=        2.1211
At iterate    10  f =      -318.36  |proj g|=        2.1279
At iterate    11  f =      -318.36  |proj g|=        2.1304
At iterate    12  f =      -318.36  |proj g|=        2.1307
At iterate    13  f =      -318.36  |proj g|=        2.1309
At iterate    14  f =      -318.36  |proj g|=        2.1313
At iterate    15  f =      -318.36  |proj g|=        2.1322
At iterate    16  f =      -318.36  |proj g|=        2.1335
At iterate    17  f =      -318.36  |proj g|=        2.1357
At iterate    18  f =      -318.36  |proj g|=        2.1389
At iterate    19  f =      -318.36  |proj g|=        2.1437
At iterate    20  f =      -318.36  |proj g|=          2.15
At iterate    21  f =      -318.36  |proj g|=        2.1573
At iterate    22  f =      -318.37  |proj g|=        2.1634
At iterate    23  f =      -321.61  |proj g|=        1.8118
At iterate    24  f =      -324.17  |proj g|=        1.4356
At iterate    25  f =      -324.37  |proj g|=        1.3363
At iterate    26  f =      -324.37  |proj g|=        1.3379
At iterate    27  f =      -324.37  |proj g|=        1.3326
At iterate    28  f =      -324.37  |proj g|=        1.3339
At iterate    29  f =      -324.37  |proj g|=        1.3339

iterations 29
function evaluations 36
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.33386
final function value -324.373

F = -324.373
final  value -324.373162 
converged
 
INFO  [02:25:28.921] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:25:28.980] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:25:28.987] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:25:43.883] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:25:57.499] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:26:11.812] [mlr3]  Finished benchmark 
INFO  [02:26:11.883] [bbotk] Result of batch 49: 
INFO  [02:26:11.885] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:26:11.885] [bbotk]              3.117737                  3.95658                      0.02216859 
INFO  [02:26:11.885] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:26:11.885] [bbotk]                     4541        0.606 -0.9654313         <NA>   0.9514904 
INFO  [02:26:11.885] [bbotk]                                 uhash 
INFO  [02:26:11.885] [bbotk]  28ffb8a8-b0d6-4507-8aae-9a385b36c5d0 
DEBUG [02:26:12.904] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.206991e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.206991e-05 0.001509084 
  - best initial criterion value(s) :  305.2217 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -305.22  |proj g|=       1.9658
At iterate     1  f =      -322.43  |proj g|=        4.2272
At iterate     2  f =      -322.76  |proj g|=         4.066
At iterate     3  f =      -323.24  |proj g|=        2.9006
At iterate     4  f =      -323.44  |proj g|=        3.4746
At iterate     5  f =      -323.49  |proj g|=        3.3876
At iterate     6  f =      -323.63  |proj g|=        3.1842
At iterate     7  f =      -323.82  |proj g|=        3.0481
At iterate     8  f =      -324.33  |proj g|=        2.8874
At iterate     9  f =      -324.88  |proj g|=        3.2066
At iterate    10  f =      -325.05  |proj g|=        3.6945
At iterate    11  f =      -325.05  |proj g|=        3.6316
At iterate    12  f =      -325.05  |proj g|=        3.6264
At iterate    13  f =      -325.05  |proj g|=        3.6266
At iterate    14  f =      -325.05  |proj g|=        3.6269
At iterate    15  f =      -325.05  |proj g|=        3.6289
At iterate    16  f =      -325.05  |proj g|=        3.6311
At iterate    17  f =      -325.05  |proj g|=        3.6351
At iterate    18  f =      -325.05  |proj g|=        3.6409
At iterate    19  f =      -325.06  |proj g|=        3.6506
At iterate    20  f =      -325.06  |proj g|=        3.6646
At iterate    21  f =      -325.06  |proj g|=        3.6818
At iterate    22  f =      -325.06  |proj g|=        3.6908
At iterate    23  f =      -325.07  |proj g|=        3.6892
At iterate    24  f =      -325.07  |proj g|=        3.6609
At iterate    25  f =      -325.08  |proj g|=         3.662
At iterate    26  f =      -325.16  |proj g|=        3.6014
At iterate    27  f =      -326.47  |proj g|=        2.3917
At iterate    28  f =      -327.97  |proj g|=        1.1637
At iterate    29  f =      -328.09  |proj g|=        1.1343
At iterate    30  f =      -328.28  |proj g|=        1.3224
At iterate    31  f =         -329  |proj g|=       0.80756
At iterate    32  f =       -329.1  |proj g|=       0.77916
At iterate    33  f =      -329.11  |proj g|=       0.78798
At iterate    34  f =      -329.11  |proj g|=       0.79063
At iterate    35  f =      -329.11  |proj g|=        0.7908
At iterate    36  f =      -329.11  |proj g|=       0.79077

iterations 36
function evaluations 43
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.790771
final function value -329.108

F = -329.108
final  value -329.108225 
converged
 
INFO  [02:26:12.909] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:26:12.982] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:26:12.989] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:26:25.715] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:26:36.347] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:26:48.695] [mlr3]  Finished benchmark 
INFO  [02:26:48.782] [bbotk] Result of batch 50: 
INFO  [02:26:48.784] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:26:48.784] [bbotk]              8.612959                 5.376888                       0.3614943 
INFO  [02:26:48.784] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:26:48.784] [bbotk]                     4109        0.706 -0.9655631         <NA>   0.9793661 
INFO  [02:26:48.784] [bbotk]                                 uhash 
INFO  [02:26:48.784] [bbotk]  50421539-0057-46e4-9a31-9c08a554f230 
DEBUG [02:26:49.791] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.207115e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.207115e-05 0.001516788 
  - best initial criterion value(s) :  325.4021 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -325.4  |proj g|=      0.95049
At iterate     1  f =         -326  |proj g|=         1.049
At iterate     2  f =      -326.01  |proj g|=        1.0417
At iterate     3  f =      -326.03  |proj g|=        1.0322
At iterate     4  f =      -326.06  |proj g|=         1.021
At iterate     5  f =      -326.15  |proj g|=       0.99789
At iterate     6  f =       -326.3  |proj g|=       0.97094
At iterate     7  f =      -326.47  |proj g|=       0.95475
At iterate     8  f =      -326.51  |proj g|=       0.96679
At iterate     9  f =      -326.51  |proj g|=       0.97233
At iterate    10  f =      -326.51  |proj g|=       0.97278
At iterate    11  f =      -326.51  |proj g|=        0.9728

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.972796
final function value -326.514

F = -326.514
final  value -326.514404 
converged
 
INFO  [02:26:49.795] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:26:49.851] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:26:49.858] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:26:52.075] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:26:54.316] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:26:56.232] [mlr3]  Finished benchmark 
INFO  [02:26:56.298] [bbotk] Result of batch 51: 
INFO  [02:26:56.300] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:26:56.300] [bbotk]              2.504419                 5.625366                       0.1223926 
INFO  [02:26:56.300] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:26:56.300] [bbotk]                      663        0.728 -0.9678319         <NA>   0.9397255 
INFO  [02:26:56.300] [bbotk]                                 uhash 
INFO  [02:26:56.300] [bbotk]  9cbfda0a-f6ce-4ed9-ad79-fc3df3726aac 
DEBUG [02:26:57.278] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.292507e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.292507e-05 0.00162917 
  - best initial criterion value(s) :  330.8839 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -330.88  |proj g|=       1.5877
At iterate     1  f =      -333.45  |proj g|=        2.0878
At iterate     2  f =      -333.69  |proj g|=        2.0531
At iterate     3  f =      -334.07  |proj g|=        1.9118
At iterate     4  f =      -334.21  |proj g|=        1.9616
At iterate     5  f =      -334.34  |proj g|=        1.9868
At iterate     6  f =       -334.4  |proj g|=        1.9859
At iterate     7  f =       -334.4  |proj g|=         1.986
At iterate     8  f =       -334.4  |proj g|=        1.9862
At iterate     9  f =       -334.4  |proj g|=        1.9863

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.9863
final function value -334.401

F = -334.401
final  value -334.401182 
converged
 
INFO  [02:26:57.282] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:26:57.341] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:26:57.356] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:27:03.792] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:27:08.582] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:27:13.451] [mlr3]  Finished benchmark 
INFO  [02:27:13.520] [bbotk] Result of batch 52: 
INFO  [02:27:13.522] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:27:13.522] [bbotk]               6.48925                 7.146924                       0.4684058 
INFO  [02:27:13.522] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:27:13.522] [bbotk]                     1797        0.728  -0.96358         <NA>   0.9768236 
INFO  [02:27:13.522] [bbotk]                                 uhash 
INFO  [02:27:13.522] [bbotk]  27ada769-d746-44f7-b03f-a1971abdb64f 
DEBUG [02:27:14.365] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.286012e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.286011e-05 0.001616541 
  - best initial criterion value(s) :  339.8626 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -339.86  |proj g|=       1.8288
At iterate     1  f =      -340.08  |proj g|=        2.2561
At iterate     2  f =      -340.93  |proj g|=        1.6659
At iterate     3  f =       -341.4  |proj g|=       0.99731
At iterate     4  f =      -341.45  |proj g|=        1.1953
At iterate     5  f =      -341.45  |proj g|=        1.1296
At iterate     6  f =      -341.45  |proj g|=        1.1251
At iterate     7  f =      -341.45  |proj g|=        1.1249

iterations 7
function evaluations 12
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.12486
final function value -341.453

F = -341.453
final  value -341.453194 
converged
 
INFO  [02:27:14.369] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:27:14.425] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:27:14.432] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:27:19.840] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:27:25.595] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:27:31.254] [mlr3]  Finished benchmark 
INFO  [02:27:31.322] [bbotk] Result of batch 53: 
INFO  [02:27:31.324] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:27:31.324] [bbotk]              7.860242                  4.32178                       0.1692348 
INFO  [02:27:31.324] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:27:31.324] [bbotk]                     1948        0.616 -0.9646148         <NA>   0.9729567 
INFO  [02:27:31.324] [bbotk]                                 uhash 
INFO  [02:27:31.324] [bbotk]  423c218e-7131-4606-bdcc-0758f96f3d67 
DEBUG [02:27:32.188] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.273257e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.59288 15.77119 0.9643483 9590 
  - variance bounds :  1.273257e-05 0.00160882 
  - best initial criterion value(s) :  341.4917 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -341.49  |proj g|=      0.60514
At iterate     1  f =      -342.04  |proj g|=        2.5009
At iterate     2  f =      -343.46  |proj g|=        2.0621
At iterate     3  f =      -344.19  |proj g|=        1.5732
At iterate     4  f =      -344.56  |proj g|=        1.1504
At iterate     5  f =       -345.2  |proj g|=       0.82716
At iterate     6  f =       -346.5  |proj g|=       0.35591
At iterate     7  f =      -346.98  |proj g|=       0.67987
At iterate     8  f =      -347.01  |proj g|=       0.57777
At iterate     9  f =      -347.01  |proj g|=       0.57965
At iterate    10  f =      -347.02  |proj g|=       0.57974
At iterate    11  f =      -347.02  |proj g|=       0.57971

iterations 11
function evaluations 14
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.579707
final function value -347.015

F = -347.015
final  value -347.015043 
converged
 
INFO  [02:27:32.193] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:27:32.250] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:27:32.257] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:27:40.087] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:27:46.255] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:27:53.683] [mlr3]  Finished benchmark 
INFO  [02:27:53.752] [bbotk] Result of batch 54: 
INFO  [02:27:53.754] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:27:53.754] [bbotk]              9.991253                 7.069468                      0.06578129 
INFO  [02:27:53.754] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:27:53.754] [bbotk]                     2435        0.608 -0.9645801         <NA>   0.9686663 
INFO  [02:27:53.754] [bbotk]                                 uhash 
INFO  [02:27:53.754] [bbotk]  10e6feb5-63d5-4859-bc3f-165cf13cecbf 
DEBUG [02:27:54.568] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.258123e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.258123e-05 0.001594846 
  - best initial criterion value(s) :  322.6451 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -322.65  |proj g|=       1.4084
At iterate     1  f =      -327.94  |proj g|=         4.348
At iterate     2  f =      -345.91  |proj g|=        1.7807
At iterate     3  f =      -346.12  |proj g|=        1.7936
At iterate     4  f =      -346.45  |proj g|=        1.8216
At iterate     5  f =      -346.48  |proj g|=        1.8143
At iterate     6  f =      -346.49  |proj g|=        1.8088
At iterate     7  f =       -346.5  |proj g|=        1.7884
At iterate     8  f =       -346.5  |proj g|=        1.7903
At iterate     9  f =       -346.5  |proj g|=        1.7902

iterations 9
function evaluations 11
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.79016
final function value -346.501

F = -346.501
final  value -346.501028 
converged
 
INFO  [02:27:54.572] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:27:54.651] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:27:54.662] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:28:07.327] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:28:18.542] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:28:29.751] [mlr3]  Finished benchmark 
INFO  [02:28:29.824] [bbotk] Result of batch 55: 
INFO  [02:28:29.826] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:28:29.826] [bbotk]              7.029702                 3.713035                       0.1769499 
INFO  [02:28:29.826] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:28:29.826] [bbotk]                     3998        0.608 -0.965907         <NA>    0.976356 
INFO  [02:28:29.826] [bbotk]                                 uhash 
INFO  [02:28:29.826] [bbotk]  6bbc8c50-e4ad-4759-bd22-ed2434f04c89 
DEBUG [02:28:30.718] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.251016e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.251016e-05 0.001592268 
  - best initial criterion value(s) :  342.4102 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -342.41  |proj g|=       2.5861
At iterate     1  f =      -345.66  |proj g|=        3.0882
At iterate     2  f =      -348.04  |proj g|=        3.0064
At iterate     3  f =      -349.87  |proj g|=        2.7652
At iterate     4  f =      -349.89  |proj g|=        2.6964
At iterate     5  f =      -349.91  |proj g|=        2.7249
At iterate     6  f =      -349.91  |proj g|=        2.7339
At iterate     7  f =      -349.96  |proj g|=        2.8005
At iterate     8  f =      -349.98  |proj g|=        2.8377
At iterate     9  f =      -349.98  |proj g|=         2.808
At iterate    10  f =      -349.98  |proj g|=        2.8391
At iterate    11  f =      -349.98  |proj g|=        2.8395
At iterate    12  f =      -349.98  |proj g|=        2.8396
At iterate    13  f =      -349.98  |proj g|=        2.8402
At iterate    14  f =      -349.98  |proj g|=        2.8408
At iterate    15  f =      -349.98  |proj g|=        2.8423
At iterate    16  f =      -349.98  |proj g|=        2.8418
At iterate    17  f =      -349.98  |proj g|=        2.8458
At iterate    18  f =      -349.99  |proj g|=        2.8338
At iterate    19  f =      -349.99  |proj g|=        2.8438
At iterate    20  f =      -350.03  |proj g|=        2.8821
At iterate    21  f =      -350.12  |proj g|=         2.924
At iterate    22  f =      -350.31  |proj g|=        2.9609
At iterate    23  f =      -350.76  |proj g|=        2.9481
At iterate    24  f =      -351.28  |proj g|=        2.9016
At iterate    25  f =      -352.23  |proj g|=        2.6452
At iterate    26  f =      -353.23  |proj g|=        2.3659
At iterate    27  f =      -354.99  |proj g|=        1.7352
At iterate    28  f =      -355.53  |proj g|=        2.0617
At iterate    29  f =      -355.96  |proj g|=        1.6365
At iterate    30  f =      -356.01  |proj g|=        1.6918
At iterate    31  f =      -356.02  |proj g|=        1.6515
At iterate    32  f =      -356.02  |proj g|=        1.6615
At iterate    33  f =      -356.02  |proj g|=        1.6606
At iterate    34  f =      -356.02  |proj g|=        1.6606

iterations 34
function evaluations 38
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.66057
final function value -356.02

F = -356.02
final  value -356.019620 
converged
 
INFO  [02:28:30.722] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:28:30.780] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:28:30.787] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:28:42.760] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:28:54.025] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:29:07.300] [mlr3]  Finished benchmark 
INFO  [02:29:07.382] [bbotk] Result of batch 56: 
INFO  [02:29:07.384] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:29:07.384] [bbotk]               3.16315                 6.873478                       0.4932785 
INFO  [02:29:07.384] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:29:07.384] [bbotk]                     4159        0.616 -0.9644497         <NA>   0.9753153 
INFO  [02:29:07.384] [bbotk]                                 uhash 
INFO  [02:29:07.384] [bbotk]  8ed75512-52ff-4070-9157-44e748916360 
DEBUG [02:29:08.304] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.2421e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.2421e-05 0.001586588 
  - best initial criterion value(s) :  346.0188 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -346.02  |proj g|=       4.9512
At iterate     1  f =      -346.38  |proj g|=        4.9603
At iterate     2  f =      -347.84  |proj g|=        4.7698
At iterate     3  f =      -350.83  |proj g|=        3.8413
At iterate     4  f =      -351.84  |proj g|=        3.6253
At iterate     5  f =      -352.19  |proj g|=        3.3542
At iterate     6  f =      -352.25  |proj g|=        3.2391
At iterate     7  f =      -352.26  |proj g|=        3.2108
At iterate     8  f =      -352.26  |proj g|=        3.2102
At iterate     9  f =      -352.26  |proj g|=        3.2136
At iterate    10  f =      -352.26  |proj g|=        3.2141
At iterate    11  f =      -352.26  |proj g|=        3.2148
At iterate    12  f =      -352.26  |proj g|=        3.2166
At iterate    13  f =      -352.26  |proj g|=         3.219
At iterate    14  f =      -352.26  |proj g|=        3.2232
At iterate    15  f =      -352.26  |proj g|=        3.2303
At iterate    16  f =      -352.26  |proj g|=        3.2431
At iterate    17  f =      -352.27  |proj g|=        3.2634
At iterate    18  f =      -352.27  |proj g|=        3.2911
At iterate    19  f =      -352.29  |proj g|=        3.3302
At iterate    20  f =      -352.29  |proj g|=        3.3353
At iterate    21  f =      -352.31  |proj g|=        3.3832
At iterate    22  f =      -360.33  |proj g|=        1.1886
At iterate    23  f =       -368.3  |proj g|=       0.88689
At iterate    24  f =      -368.67  |proj g|=       0.65289
At iterate    25  f =      -368.83  |proj g|=      0.018813
At iterate    26  f =      -368.89  |proj g|=       0.54272
At iterate    27  f =       -368.9  |proj g|=       0.28843
At iterate    28  f =       -368.9  |proj g|=       0.27513
At iterate    29  f =       -368.9  |proj g|=       0.27371
At iterate    30  f =       -368.9  |proj g|=       0.27361

iterations 30
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.273608
final function value -368.905

F = -368.905
final  value -368.904818 
converged
 
INFO  [02:29:08.309] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:29:08.363] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:29:08.370] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:29:11.989] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:29:15.602] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:29:18.516] [mlr3]  Finished benchmark 
INFO  [02:29:18.586] [bbotk] Result of batch 57: 
INFO  [02:29:18.588] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:29:18.588] [bbotk]              4.684902                  2.84836                       0.0911296 
INFO  [02:29:18.588] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:29:18.588] [bbotk]                     1128        0.629 -0.9622819         <NA>   0.9603536 
INFO  [02:29:18.588] [bbotk]                                 uhash 
INFO  [02:29:18.588] [bbotk]  048d0136-364e-4299-b087-b541b683d3c3 
DEBUG [02:29:19.664] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.235174e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.235174e-05 0.00157115 
  - best initial criterion value(s) :  368.3418 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -368.34  |proj g|=      0.77547
At iterate     1  f =      -369.25  |proj g|=        3.4377
At iterate     2  f =      -370.61  |proj g|=          2.84
At iterate     3  f =      -370.85  |proj g|=        1.7934
At iterate     4  f =      -371.01  |proj g|=        2.3151
At iterate     5  f =      -371.02  |proj g|=        2.2445
At iterate     6  f =      -371.02  |proj g|=        2.2259
At iterate     7  f =      -371.03  |proj g|=        2.2106
At iterate     8  f =      -371.04  |proj g|=        2.2422
At iterate     9  f =      -371.05  |proj g|=        2.3491
At iterate    10  f =      -371.05  |proj g|=        2.3629
At iterate    11  f =      -371.05  |proj g|=        2.3642
At iterate    12  f =      -371.05  |proj g|=        2.3677
At iterate    13  f =      -371.05  |proj g|=        2.3836
At iterate    14  f =      -371.06  |proj g|=        2.4055
At iterate    15  f =      -371.06  |proj g|=        2.3305
At iterate    16  f =      -371.09  |proj g|=        2.4261
At iterate    17  f =      -371.13  |proj g|=        2.5139
At iterate    18  f =      -371.29  |proj g|=         2.667
At iterate    19  f =      -371.64  |proj g|=        2.7854
At iterate    20  f =      -372.49  |proj g|=        2.7513
At iterate    21  f =      -373.64  |proj g|=        2.4494
At iterate    22  f =       -373.9  |proj g|=        1.8966
At iterate    23  f =      -374.03  |proj g|=        2.0282
At iterate    24  f =      -374.36  |proj g|=        2.0023
At iterate    25  f =      -374.91  |proj g|=        1.4855
At iterate    26  f =      -374.94  |proj g|=        1.1297
At iterate    27  f =      -374.95  |proj g|=        1.2843
At iterate    28  f =      -374.95  |proj g|=        1.2689
At iterate    29  f =      -374.95  |proj g|=        1.2678
At iterate    30  f =      -374.95  |proj g|=        1.2679

iterations 30
function evaluations 38
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.26788
final function value -374.95

F = -374.95
final  value -374.950500 
converged
 
INFO  [02:29:19.668] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:29:19.724] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:29:19.731] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:29:22.882] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:29:25.759] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:29:28.998] [mlr3]  Finished benchmark 
INFO  [02:29:29.233] [bbotk] Result of batch 58: 
INFO  [02:29:29.235] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:29:29.235] [bbotk]              2.896692                 9.728196                       0.2186503 
INFO  [02:29:29.235] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:29:29.235] [bbotk]                      971        0.791 -0.9617947         <NA>   0.9583726 
INFO  [02:29:29.235] [bbotk]                                 uhash 
INFO  [02:29:29.235] [bbotk]  f468effb-0906-463d-a47e-782c34b84f28 
DEBUG [02:29:30.157] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.232223e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.232223e-05 0.001563692 
  - best initial criterion value(s) :  369.4729 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -369.47  |proj g|=       2.8973
At iterate     1  f =      -375.95  |proj g|=        1.8088
At iterate     2  f =       -378.8  |proj g|=        1.1061
At iterate     3  f =      -378.91  |proj g|=        1.1241
At iterate     4  f =      -378.91  |proj g|=         1.117
At iterate     5  f =      -378.91  |proj g|=        1.1164
At iterate     6  f =      -378.91  |proj g|=        1.1164
At iterate     7  f =      -378.91  |proj g|=        1.1164
At iterate     8  f =      -378.91  |proj g|=        1.1163
At iterate     9  f =      -378.91  |proj g|=        1.1163
At iterate    10  f =      -378.91  |proj g|=        1.1159
At iterate    11  f =      -378.91  |proj g|=        1.1164
At iterate    12  f =      -378.91  |proj g|=         1.115
At iterate    13  f =      -378.91  |proj g|=        1.1132
At iterate    14  f =      -378.91  |proj g|=        1.1075
At iterate    15  f =      -378.92  |proj g|=        1.0997
At iterate    16  f =      -378.94  |proj g|=        1.0849
At iterate    17  f =      -378.99  |proj g|=        1.0625
At iterate    18  f =       -379.1  |proj g|=        1.0155
At iterate    19  f =      -379.33  |proj g|=       0.97429
At iterate    20  f =      -379.45  |proj g|=       0.88288
At iterate    21  f =       -379.7  |proj g|=       0.87751
At iterate    22  f =      -379.95  |proj g|=       0.87429
At iterate    23  f =      -380.06  |proj g|=       0.75522
At iterate    24  f =      -380.08  |proj g|=       0.69048
At iterate    25  f =      -380.08  |proj g|=       0.66649
At iterate    26  f =      -380.08  |proj g|=       0.65513
At iterate    27  f =      -380.08  |proj g|=       0.65584
At iterate    28  f =      -380.08  |proj g|=       0.65086
At iterate    29  f =      -380.08  |proj g|=       0.65355
At iterate    30  f =      -380.08  |proj g|=       0.64384
At iterate    31  f =      -380.12  |proj g|=       0.53487
At iterate    32  f =      -380.32  |proj g|=        0.5421
At iterate    33  f =      -380.35  |proj g|=       0.43014
At iterate    34  f =      -380.61  |proj g|=       0.44757
At iterate    35  f =      -381.12  |proj g|=       0.21661
At iterate    36  f =      -381.17  |proj g|=       0.50389
At iterate    37  f =      -381.19  |proj g|=       0.49221
At iterate    38  f =      -381.19  |proj g|=       0.47915
At iterate    39  f =      -381.19  |proj g|=       0.47881
At iterate    40  f =      -381.19  |proj g|=      0.014338
At iterate    41  f =      -381.19  |proj g|=    0.00078886

iterations 41
function evaluations 57
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.000788857
final function value -381.193

F = -381.193
final  value -381.192854 
converged
 
INFO  [02:29:30.161] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:29:30.218] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:29:30.225] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:29:39.863] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:29:48.900] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:29:59.131] [mlr3]  Finished benchmark 
INFO  [02:29:59.309] [bbotk] Result of batch 59: 
INFO  [02:29:59.312] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:29:59.312] [bbotk]              8.083747                 3.147346                       0.2087425 
INFO  [02:29:59.312] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:29:59.312] [bbotk]                     3347        0.607 -0.9598143         <NA>   0.9766589 
INFO  [02:29:59.312] [bbotk]                                 uhash 
INFO  [02:29:59.312] [bbotk]  ad83d065-2fe4-4d9c-971e-339d33e95477 
DEBUG [02:30:00.172] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.22634e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.22634e-05 0.00156205 
  - best initial criterion value(s) :  359.0242 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -359.02  |proj g|=       2.2886
At iterate     1  f =      -363.35  |proj g|=        2.2501
At iterate     2  f =      -366.02  |proj g|=        1.8142
At iterate     3  f =      -366.44  |proj g|=         1.955
At iterate     4  f =       -367.1  |proj g|=        1.9613
At iterate     5  f =      -367.82  |proj g|=        1.9055
At iterate     6  f =      -367.87  |proj g|=        1.8959
At iterate     7  f =      -367.87  |proj g|=        1.8971
At iterate     8  f =      -367.87  |proj g|=        1.9003
At iterate     9  f =      -367.87  |proj g|=        1.8987
At iterate    10  f =      -367.87  |proj g|=        1.8987

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.89873
final function value -367.868

F = -367.868
final  value -367.868376 
converged
 
INFO  [02:30:00.176] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:30:00.234] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:30:00.241] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:30:04.118] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:30:07.999] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:30:11.209] [mlr3]  Finished benchmark 
INFO  [02:30:11.279] [bbotk] Result of batch 60: 
INFO  [02:30:11.281] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:30:11.281] [bbotk]              9.569572                 7.391537                      0.07175263 
INFO  [02:30:11.281] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:30:11.281] [bbotk]                     1075        0.636 -0.9663075         <NA>   0.9605599 
INFO  [02:30:11.281] [bbotk]                                 uhash 
INFO  [02:30:11.281] [bbotk]  78b2dfe8-2684-4a07-b990-8faa3f47c7b4 
DEBUG [02:30:12.128] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.219277e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.219277e-05 0.001547847 
  - best initial criterion value(s) :  385.3937 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -385.39  |proj g|=       1.1271
At iterate     1  f =      -385.48  |proj g|=        2.6105
At iterate     2  f =      -386.01  |proj g|=        2.1384
At iterate     3  f =      -386.05  |proj g|=        1.8843
At iterate     4  f =      -386.05  |proj g|=        1.9504
At iterate     5  f =      -386.05  |proj g|=        1.9458
At iterate     6  f =      -386.05  |proj g|=        1.9288
At iterate     7  f =      -386.06  |proj g|=        1.9138
At iterate     8  f =      -386.06  |proj g|=        1.9056
At iterate     9  f =      -386.06  |proj g|=         1.918
At iterate    10  f =      -386.06  |proj g|=        1.9133
At iterate    11  f =      -386.06  |proj g|=        1.9131

iterations 11
function evaluations 13
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.91314
final function value -386.056

F = -386.056
final  value -386.056139 
converged
 
INFO  [02:30:12.132] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:30:12.190] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:30:12.218] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:30:18.213] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:30:25.508] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:30:32.358] [mlr3]  Finished benchmark 
INFO  [02:30:32.428] [bbotk] Result of batch 61: 
INFO  [02:30:32.430] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:30:32.430] [bbotk]              6.349453                 2.193027                       0.3910405 
INFO  [02:30:32.430] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:30:32.430] [bbotk]                     2290         0.63 -0.963274         <NA>   0.9770036 
INFO  [02:30:32.430] [bbotk]                                 uhash 
INFO  [02:30:32.430] [bbotk]  1f95dd45-5ec5-4142-8155-41d61ce50bc5 
DEBUG [02:30:33.373] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.214297e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.214297e-05 0.001547434 
  - best initial criterion value(s) :  371.2394 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -371.24  |proj g|=       2.9316
At iterate     1  f =      -375.56  |proj g|=        3.8599
At iterate     2  f =       -378.4  |proj g|=        3.6467
At iterate     3  f =      -381.71  |proj g|=        3.2044
At iterate     4  f =      -381.92  |proj g|=        3.0653
At iterate     5  f =      -381.93  |proj g|=        3.0618
At iterate     6  f =      -381.95  |proj g|=        3.0836
At iterate     7  f =      -381.95  |proj g|=        3.1016
At iterate     8  f =      -381.95  |proj g|=        3.0962
At iterate     9  f =      -381.95  |proj g|=         3.096
At iterate    10  f =      -381.95  |proj g|=        3.0944
At iterate    11  f =      -381.95  |proj g|=        3.0925
At iterate    12  f =      -381.95  |proj g|=         3.089
At iterate    13  f =      -381.95  |proj g|=        3.0842
At iterate    14  f =      -381.95  |proj g|=        3.0774
At iterate    15  f =      -381.96  |proj g|=        3.0704
At iterate    16  f =      -381.97  |proj g|=         3.069
At iterate    17  f =         -382  |proj g|=        3.0885
At iterate    18  f =      -382.01  |proj g|=        3.1301
At iterate    19  f =      -382.01  |proj g|=        3.1287
At iterate    20  f =      -382.01  |proj g|=         3.124
At iterate    21  f =      -382.01  |proj g|=        3.1181
At iterate    22  f =      -382.02  |proj g|=        3.1067
At iterate    23  f =      -382.03  |proj g|=        3.0895
At iterate    24  f =      -382.05  |proj g|=        3.0649
At iterate    25  f =      -382.09  |proj g|=        3.0364
At iterate    26  f =      -382.16  |proj g|=        3.0261
At iterate    27  f =      -382.22  |proj g|=         3.188
At iterate    28  f =      -382.53  |proj g|=        3.1178
At iterate    29  f =      -382.75  |proj g|=        2.9958
At iterate    30  f =      -383.16  |proj g|=        2.8559
At iterate    31  f =      -386.37  |proj g|=        1.9178
At iterate    32  f =      -390.35  |proj g|=         1.323
At iterate    33  f =      -392.15  |proj g|=        2.1294
At iterate    34  f =      -392.25  |proj g|=        2.3142
At iterate    35  f =      -392.29  |proj g|=        2.4196
At iterate    36  f =      -392.37  |proj g|=        2.3495
At iterate    37  f =      -392.42  |proj g|=          2.17
At iterate    38  f =      -392.42  |proj g|=        2.1949
At iterate    39  f =      -392.42  |proj g|=        2.1917
At iterate    40  f =      -392.42  |proj g|=        2.1916

iterations 40
function evaluations 46
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.19165
final function value -392.416

F = -392.416
final  value -392.415636 
converged
 
INFO  [02:30:33.377] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:30:33.478] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:30:33.486] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:30:43.399] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:30:52.479] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:30:58.940] [mlr3]  Finished benchmark 
INFO  [02:30:59.008] [bbotk] Result of batch 62: 
INFO  [02:30:59.010] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:30:59.010] [bbotk]              3.839743                 6.810533                       0.2492224 
INFO  [02:30:59.010] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:30:59.010] [bbotk]                     3044        0.614 -0.9623875         <NA>   0.9738314 
INFO  [02:30:59.010] [bbotk]                                 uhash 
INFO  [02:30:59.010] [bbotk]  1c373798-b21b-4fc0-bd67-8b5bc6b2f0d6 
DEBUG [02:30:59.982] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.20439e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.20439e-05 0.001541182 
  - best initial criterion value(s) :  387.3647 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -387.36  |proj g|=       1.8789
At iterate     1  f =      -388.48  |proj g|=         2.181
At iterate     2  f =      -388.48  |proj g|=        2.1785
At iterate     3  f =      -388.49  |proj g|=        2.1559
At iterate     4  f =      -388.49  |proj g|=        2.1414
At iterate     5  f =       -388.5  |proj g|=        2.1244
At iterate     6  f =      -388.51  |proj g|=        2.1416
At iterate     7  f =      -388.51  |proj g|=        2.1323
At iterate     8  f =      -388.51  |proj g|=        2.1324
At iterate     9  f =      -388.51  |proj g|=        2.1324
At iterate    10  f =      -388.51  |proj g|=        2.1326
At iterate    11  f =      -388.51  |proj g|=        2.1328
At iterate    12  f =      -388.51  |proj g|=        2.1337
At iterate    13  f =      -388.51  |proj g|=        2.1326
At iterate    14  f =      -388.51  |proj g|=        2.1336
At iterate    15  f =      -388.58  |proj g|=         2.136
At iterate    16  f =      -389.52  |proj g|=        2.0324
At iterate    17  f =      -390.95  |proj g|=        1.7591
At iterate    18  f =       -392.8  |proj g|=        1.3967
At iterate    19  f =      -392.88  |proj g|=        1.3361
At iterate    20  f =      -394.64  |proj g|=        1.2604
At iterate    21  f =      -395.74  |proj g|=        1.5712
At iterate    22  f =      -396.56  |proj g|=        1.2257
At iterate    23  f =      -396.73  |proj g|=        1.1501
At iterate    24  f =      -396.83  |proj g|=        1.1811
At iterate    25  f =      -396.83  |proj g|=        1.1523
At iterate    26  f =      -396.83  |proj g|=          1.17
At iterate    27  f =      -396.83  |proj g|=        1.1687
At iterate    28  f =      -396.83  |proj g|=        1.1687

iterations 28
function evaluations 37
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.16871
final function value -396.832

F = -396.832
final  value -396.831826 
converged
 
INFO  [02:30:59.986] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:31:00.059] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:31:00.065] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:31:07.601] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:31:15.309] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:31:22.923] [mlr3]  Finished benchmark 
INFO  [02:31:23.011] [bbotk] Result of batch 63: 
INFO  [02:31:23.013] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:31:23.013] [bbotk]              6.368455                 2.377164                        0.387376 
INFO  [02:31:23.013] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:31:23.013] [bbotk]                     3662        0.662 -0.9635577         <NA>   0.9784146 
INFO  [02:31:23.013] [bbotk]                                 uhash 
INFO  [02:31:23.013] [bbotk]  bc3cc620-636a-4f1d-9c25-29449d61414c 
DEBUG [02:31:23.877] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.202199e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.202199e-05 0.001543074 
  - best initial criterion value(s) :  376.7353 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -376.74  |proj g|=       1.3574
At iterate     1  f =      -384.89  |proj g|=        4.9217
At iterate     2  f =      -385.86  |proj g|=        4.6005
At iterate     3  f =      -387.09  |proj g|=        3.6482
At iterate     4  f =      -387.12  |proj g|=        3.4585
At iterate     5  f =       -387.2  |proj g|=        3.5626
At iterate     6  f =      -387.51  |proj g|=         3.725
At iterate     7  f =      -387.79  |proj g|=        3.6519
At iterate     8  f =      -387.88  |proj g|=        3.2146
At iterate     9  f =      -387.89  |proj g|=        3.3494
At iterate    10  f =      -387.89  |proj g|=        3.3311
At iterate    11  f =      -387.89  |proj g|=        3.3299
At iterate    12  f =      -387.89  |proj g|=        3.3299

iterations 12
function evaluations 17
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.32991
final function value -387.892

F = -387.892
final  value -387.891623 
converged
 
INFO  [02:31:23.881] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:31:23.937] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:31:23.944] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:31:25.441] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:31:26.983] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:31:28.453] [mlr3]  Finished benchmark 
INFO  [02:31:28.528] [bbotk] Result of batch 64: 
INFO  [02:31:28.530] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:31:28.530] [bbotk]              5.000514                 7.292445                      0.07721008 
INFO  [02:31:28.530] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:31:28.530] [bbotk]                      601        0.623 -0.9670629         <NA>   0.9498684 
INFO  [02:31:28.530] [bbotk]                                 uhash 
INFO  [02:31:28.530] [bbotk]  b90c619b-4360-4e3a-b963-6d76c2223482 
DEBUG [02:31:29.478] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.225813e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.225813e-05 0.001577928 
  - best initial criterion value(s) :  378.3925 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -378.39  |proj g|=       2.3482
At iterate     1  f =      -387.23  |proj g|=        2.1482
At iterate     2  f =       -388.7  |proj g|=        1.9183
At iterate     3  f =      -389.77  |proj g|=        1.5255
At iterate     4  f =      -389.83  |proj g|=        1.3385
At iterate     5  f =      -389.85  |proj g|=        1.3934
At iterate     6  f =      -389.86  |proj g|=        1.4207
At iterate     7  f =       -389.9  |proj g|=        1.4226
At iterate     8  f =      -389.91  |proj g|=         1.377
At iterate     9  f =      -389.91  |proj g|=        1.3779
At iterate    10  f =      -389.91  |proj g|=        1.3784
At iterate    11  f =      -389.91  |proj g|=        1.3784
At iterate    12  f =      -389.91  |proj g|=        1.3785
At iterate    13  f =      -389.91  |proj g|=        1.3786
At iterate    14  f =      -389.91  |proj g|=        1.3769
At iterate    15  f =      -389.91  |proj g|=        1.3778
At iterate    16  f =      -389.91  |proj g|=        1.3794
At iterate    17  f =      -389.91  |proj g|=         1.382
At iterate    18  f =      -389.91  |proj g|=        1.3857
At iterate    19  f =      -389.91  |proj g|=        1.3909
At iterate    20  f =      -389.92  |proj g|=        1.3924
At iterate    21  f =      -389.92  |proj g|=        1.4637
At iterate    22  f =      -389.96  |proj g|=        1.4145
At iterate    23  f =      -390.01  |proj g|=        1.3505
At iterate    24  f =      -390.13  |proj g|=        1.2304
At iterate    25  f =      -390.34  |proj g|=        1.0763
At iterate    26  f =      -390.61  |proj g|=       0.96502
At iterate    27  f =      -390.65  |proj g|=       0.92078
At iterate    28  f =      -390.79  |proj g|=       0.92478
At iterate    29  f =       -390.8  |proj g|=       0.95668
At iterate    30  f =       -390.8  |proj g|=       0.96373
At iterate    31  f =       -390.8  |proj g|=        0.9638
At iterate    32  f =       -390.8  |proj g|=       0.96374

iterations 32
function evaluations 40
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.963743
final function value -390.8

F = -390.8
final  value -390.799915 
converged
 
INFO  [02:31:29.482] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:31:29.545] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:31:29.553] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:31:38.490] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:31:47.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:31:55.752] [mlr3]  Finished benchmark 
INFO  [02:31:55.829] [bbotk] Result of batch 65: 
INFO  [02:31:55.831] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:31:55.831] [bbotk]              2.868393                 6.035142                      0.06820346 
INFO  [02:31:55.831] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:31:55.831] [bbotk]                     4328         0.64 -0.9592926         <NA>   0.9617037 
INFO  [02:31:55.831] [bbotk]                                 uhash 
INFO  [02:31:55.831] [bbotk]  8fbfbf12-90bf-43de-86c5-e6161ed72a69 
DEBUG [02:31:56.761] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.2174e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.217399e-05 0.001563828 
  - best initial criterion value(s) :  389.1413 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -389.14  |proj g|=        2.832
At iterate     1  f =       -391.8  |proj g|=        4.6701
At iterate     2  f =      -391.84  |proj g|=        4.5713
At iterate     3  f =      -391.87  |proj g|=        4.4117
At iterate     4  f =      -391.88  |proj g|=        4.3266
At iterate     5  f =      -391.96  |proj g|=        3.8951
At iterate     6  f =      -392.01  |proj g|=         3.671
At iterate     7  f =      -392.02  |proj g|=        3.6591
At iterate     8  f =      -392.02  |proj g|=        3.6773
At iterate     9  f =      -392.02  |proj g|=        3.6814
At iterate    10  f =      -392.02  |proj g|=        3.6821
At iterate    11  f =      -392.02  |proj g|=        3.6882
At iterate    12  f =      -392.02  |proj g|=        3.6952
At iterate    13  f =      -392.02  |proj g|=        3.7083
At iterate    14  f =      -392.02  |proj g|=        3.7284
At iterate    15  f =      -392.02  |proj g|=        3.7616
At iterate    16  f =      -392.02  |proj g|=        3.8101
At iterate    17  f =      -392.03  |proj g|=         3.883
At iterate    18  f =      -392.04  |proj g|=        4.0249
At iterate    19  f =      -392.07  |proj g|=        4.1251
At iterate    20  f =      -392.11  |proj g|=        4.3556
At iterate    21  f =      -392.29  |proj g|=        4.5699
At iterate    22  f =      -392.85  |proj g|=        4.7869
At iterate    23  f =      -394.45  |proj g|=        4.5783
At iterate    24  f =      -398.22  |proj g|=         3.125
At iterate    25  f =      -401.91  |proj g|=        1.7761
At iterate    26  f =      -402.45  |proj g|=        1.7756
At iterate    27  f =      -405.49  |proj g|=       0.95591
At iterate    28  f =      -407.37  |proj g|=         0.592
At iterate    29  f =      -408.63  |proj g|=       0.72951
At iterate    30  f =      -409.77  |proj g|=        0.8269
At iterate    31  f =      -410.01  |proj g|=       0.85974
At iterate    32  f =      -410.02  |proj g|=       0.87397
At iterate    33  f =      -410.03  |proj g|=       0.89446
At iterate    34  f =      -410.03  |proj g|=       0.89529
At iterate    35  f =      -410.03  |proj g|=       0.89533

iterations 35
function evaluations 39
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.895328
final function value -410.025

F = -410.025
final  value -410.025392 
converged
 
INFO  [02:31:56.765] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:31:56.823] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:31:56.829] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:31:58.814] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:32:01.599] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:32:05.290] [mlr3]  Finished benchmark 
INFO  [02:32:05.358] [bbotk] Result of batch 66: 
INFO  [02:32:05.360] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:32:05.360] [bbotk]              5.478709                 8.047706                       0.4435069 
INFO  [02:32:05.360] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:32:05.360] [bbotk]                      914         0.63 -0.9511745         <NA>    0.973227 
INFO  [02:32:05.360] [bbotk]                                 uhash 
INFO  [02:32:05.360] [bbotk]  c1e2a91a-e936-4cc8-b94a-aa6ce468d796 
DEBUG [02:32:06.271] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.207323e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.75951 15.77119 0.9643483 9590 
  - variance bounds :  1.207323e-05 0.00153683 
  - best initial criterion value(s) :  384.959 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -384.96  |proj g|=       2.6595
At iterate     1  f =      -391.81  |proj g|=        3.2569
At iterate     2  f =      -398.09  |proj g|=        2.6278
At iterate     3  f =      -400.71  |proj g|=        1.6453
At iterate     4  f =      -400.74  |proj g|=        1.7576
At iterate     5  f =      -400.74  |proj g|=         1.759
At iterate     6  f =      -400.74  |proj g|=        1.7589

iterations 6
function evaluations 11
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.75887
final function value -400.741

F = -400.741
final  value -400.741249 
converged
 
INFO  [02:32:06.275] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:32:06.327] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:32:06.334] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:32:16.099] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:32:24.972] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:32:33.351] [mlr3]  Finished benchmark 
INFO  [02:32:33.419] [bbotk] Result of batch 67: 
INFO  [02:32:33.421] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:32:33.421] [bbotk]              2.088346                 3.904088                       0.3702055 
INFO  [02:32:33.421] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:32:33.421] [bbotk]                     3056        0.684 -0.9617073         <NA>   0.9630739 
INFO  [02:32:33.421] [bbotk]                                 uhash 
INFO  [02:32:33.421] [bbotk]  311cd67b-b389-4eea-a1ba-1163ccfa82f0 
DEBUG [02:32:34.337] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.197613e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.197613e-05 0.001522636 
  - best initial criterion value(s) :  385.4095 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -385.41  |proj g|=       5.4102
At iterate     1  f =      -387.39  |proj g|=        4.7352
At iterate     2  f =      -396.18  |proj g|=        2.7766
At iterate     3  f =      -397.63  |proj g|=        1.2203
At iterate     4  f =      -397.88  |proj g|=         1.862
At iterate     5  f =      -397.94  |proj g|=        1.7465
At iterate     6  f =      -397.96  |proj g|=        1.7324
At iterate     7  f =      -397.96  |proj g|=         1.765
At iterate     8  f =      -397.96  |proj g|=        1.7866
At iterate     9  f =      -397.96  |proj g|=        1.8055
At iterate    10  f =      -398.27  |proj g|=        1.6158
At iterate    11  f =      -400.48  |proj g|=       0.73827
At iterate    12  f =       -404.3  |proj g|=       0.64379
At iterate    13  f =      -407.52  |proj g|=       0.56397
At iterate    14  f =      -407.77  |proj g|=       0.48527
At iterate    15  f =      -408.02  |proj g|=        0.5133
At iterate    16  f =      -408.08  |proj g|=        0.5322
At iterate    17  f =      -408.08  |proj g|=       0.41323
At iterate    18  f =      -408.08  |proj g|=       0.41921
At iterate    19  f =      -408.08  |proj g|=       0.41924

iterations 19
function evaluations 27
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.419244
final function value -408.081

F = -408.081
final  value -408.081328 
converged
 
INFO  [02:32:34.341] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:32:34.397] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:32:34.404] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:32:42.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:32:47.226] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:32:52.592] [mlr3]  Finished benchmark 
INFO  [02:32:52.688] [bbotk] Result of batch 68: 
INFO  [02:32:52.690] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:32:52.690] [bbotk]              8.092162                 8.073931                       0.3390861 
INFO  [02:32:52.690] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:32:52.690] [bbotk]                     1769        0.641  -0.95604         <NA>   0.9760054 
INFO  [02:32:52.690] [bbotk]                                 uhash 
INFO  [02:32:52.690] [bbotk]  d8ac9afa-a4cb-41d2-9c2c-c15febf40dd6 
DEBUG [02:32:53.737] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.191547e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.191547e-05 0.001509583 
  - best initial criterion value(s) :  403.5815 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -403.58  |proj g|=       1.5761
At iterate     1  f =      -404.63  |proj g|=        1.0972
At iterate     2  f =       -405.2  |proj g|=        1.2169
At iterate     3  f =      -405.39  |proj g|=        1.3766
At iterate     4  f =      -405.41  |proj g|=        1.4443
At iterate     5  f =      -405.41  |proj g|=        1.4642
At iterate     6  f =      -405.41  |proj g|=        1.4674
At iterate     7  f =      -405.41  |proj g|=        1.4679
At iterate     8  f =      -405.41  |proj g|=        1.4679

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.46793
final function value -405.413

F = -405.413
final  value -405.413208 
converged
 
INFO  [02:32:53.741] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:32:53.795] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:32:53.802] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:33:04.964] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:33:16.832] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:33:27.569] [mlr3]  Finished benchmark 
INFO  [02:33:27.655] [bbotk] Result of batch 69: 
INFO  [02:33:27.657] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:33:27.657] [bbotk]              4.798426                 9.094798                      0.03256753 
INFO  [02:33:27.657] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:33:27.657] [bbotk]                     3814        0.813 -0.9639798         <NA>     0.96293 
INFO  [02:33:27.657] [bbotk]                                 uhash 
INFO  [02:33:27.657] [bbotk]  3827fe0f-0169-4496-b4dc-8f294dd9f3ce 
DEBUG [02:33:28.526] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.182372e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.182372e-05 0.001494332 
  - best initial criterion value(s) :  401.9187 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -401.92  |proj g|=       2.3853
At iterate     1  f =      -403.74  |proj g|=        2.7985
At iterate     2  f =      -411.51  |proj g|=        1.7348
At iterate     3  f =      -411.97  |proj g|=        1.4325
At iterate     4  f =      -412.06  |proj g|=        1.2927
At iterate     5  f =      -412.13  |proj g|=        1.2776
At iterate     6  f =      -412.18  |proj g|=          1.33
At iterate     7  f =      -412.18  |proj g|=        1.3128
At iterate     8  f =      -412.18  |proj g|=        1.3102
At iterate     9  f =      -412.18  |proj g|=        1.3102

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.31023
final function value -412.178

F = -412.178
final  value -412.178481 
converged
 
INFO  [02:33:28.530] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:33:28.585] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:33:28.592] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:33:36.995] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:33:44.620] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:33:53.125] [mlr3]  Finished benchmark 
INFO  [02:33:53.191] [bbotk] Result of batch 70: 
INFO  [02:33:53.193] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:33:53.193] [bbotk]              5.700827                 4.248341                       0.2617126 
INFO  [02:33:53.193] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:33:53.193] [bbotk]                     2933         0.63 -0.961578         <NA>    0.976086 
INFO  [02:33:53.193] [bbotk]                                 uhash 
INFO  [02:33:53.193] [bbotk]  57767787-e1b3-4537-825d-ef1c59231412 
DEBUG [02:33:54.138] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.176666e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.176666e-05 0.001497445 
  - best initial criterion value(s) :  411.6488 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -411.65  |proj g|=       7.0373
At iterate     1  f =      -414.52  |proj g|=        4.3117
At iterate     2  f =      -415.58  |proj g|=        4.0276
At iterate     3  f =      -416.92  |proj g|=        3.1898
At iterate     4  f =      -417.36  |proj g|=        2.9053
At iterate     5  f =      -417.54  |proj g|=        2.7341
At iterate     6  f =      -417.59  |proj g|=        2.6786
At iterate     7  f =      -417.59  |proj g|=        2.8399
At iterate     8  f =       -417.6  |proj g|=         2.705
At iterate     9  f =       -417.6  |proj g|=        2.7044
At iterate    10  f =       -417.6  |proj g|=         2.699
At iterate    11  f =       -417.6  |proj g|=        2.6888
At iterate    12  f =      -417.61  |proj g|=        2.6717
At iterate    13  f =      -417.61  |proj g|=        2.6442
At iterate    14  f =      -417.61  |proj g|=        2.6074
At iterate    15  f =      -417.62  |proj g|=        2.5632
At iterate    16  f =      -417.63  |proj g|=        2.5205
At iterate    17  f =      -417.71  |proj g|=        2.4046
At iterate    18  f =      -418.11  |proj g|=        2.1588
At iterate    19  f =      -419.88  |proj g|=        1.6362
At iterate    20  f =      -423.56  |proj g|=       0.93754
At iterate    21  f =      -424.08  |proj g|=       0.63108
At iterate    22  f =      -426.34  |proj g|=       0.78252
At iterate    23  f =      -426.47  |proj g|=        0.7317
At iterate    24  f =      -426.55  |proj g|=       0.69147
At iterate    25  f =      -426.57  |proj g|=       0.73526
At iterate    26  f =      -426.57  |proj g|=       0.73847
At iterate    27  f =      -426.57  |proj g|=       0.73849
At iterate    28  f =      -426.57  |proj g|=       0.73809
At iterate    29  f =      -426.57  |proj g|=       0.73807

iterations 29
function evaluations 35
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.738069
final function value -426.572

F = -426.572
final  value -426.572193 
converged
 
INFO  [02:33:54.142] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:33:54.198] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:33:54.205] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:34:05.538] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:34:16.751] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:34:28.172] [mlr3]  Finished benchmark 
INFO  [02:34:28.239] [bbotk] Result of batch 71: 
INFO  [02:34:28.241] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:34:28.241] [bbotk]              2.368412                 4.029089                       0.3360768 
INFO  [02:34:28.241] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:34:28.241] [bbotk]                     3928        0.645 -0.956339         <NA>   0.9670582 
INFO  [02:34:28.241] [bbotk]                                 uhash 
INFO  [02:34:28.241] [bbotk]  aab6fca5-5770-4ff3-bf61-a73c14f6de7d 
DEBUG [02:34:29.231] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.165168e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.165168e-05 0.001481894 
  - best initial criterion value(s) :  404.3809 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -404.38  |proj g|=       1.2344
At iterate     1  f =      -422.62  |proj g|=        6.7789
At iterate     2  f =      -428.82  |proj g|=        4.2387
At iterate     3  f =      -429.28  |proj g|=        5.5222
At iterate     4  f =      -430.08  |proj g|=        4.8689
At iterate     5  f =      -430.38  |proj g|=         3.567
At iterate     6  f =      -430.58  |proj g|=        4.0353
At iterate     7  f =       -430.6  |proj g|=        3.9272
At iterate     8  f =      -430.61  |proj g|=        3.8533
At iterate     9  f =      -430.61  |proj g|=        3.8619
At iterate    10  f =      -430.61  |proj g|=        3.8627
At iterate    11  f =      -430.61  |proj g|=        3.8653
At iterate    12  f =      -430.61  |proj g|=        3.8687
At iterate    13  f =      -430.61  |proj g|=        3.8744
At iterate    14  f =      -430.61  |proj g|=         3.881
At iterate    15  f =      -430.61  |proj g|=         3.887
At iterate    16  f =      -430.61  |proj g|=        3.8838
At iterate    17  f =      -430.61  |proj g|=        3.8501
At iterate    18  f =      -430.62  |proj g|=        3.7943
At iterate    19  f =      -430.62  |proj g|=        3.7847
At iterate    20  f =      -430.62  |proj g|=        3.7717
At iterate    21  f =      -430.65  |proj g|=        3.7199
At iterate    22  f =      -430.72  |proj g|=        3.6125
At iterate    23  f =      -430.95  |proj g|=        3.3814
At iterate    24  f =      -431.45  |proj g|=        2.7034
At iterate    25  f =      -431.69  |proj g|=        3.0517
At iterate    26  f =      -432.82  |proj g|=        2.3815
At iterate    27  f =      -436.57  |proj g|=        1.2845
At iterate    28  f =      -439.12  |proj g|=        1.3635
At iterate    29  f =      -439.64  |proj g|=        1.4372
At iterate    30  f =      -439.68  |proj g|=        1.4773
At iterate    31  f =      -439.69  |proj g|=        1.5373
At iterate    32  f =      -439.69  |proj g|=        1.5348
At iterate    33  f =       -439.7  |proj g|=        1.5357
At iterate    34  f =       -439.7  |proj g|=        1.5376
At iterate    35  f =       -439.7  |proj g|=         1.539
At iterate    36  f =       -439.7  |proj g|=        1.5392
At iterate    37  f =       -439.7  |proj g|=        1.5393

iterations 37
function evaluations 44
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.53933
final function value -439.7

F = -439.7
final  value -439.700474 
converged
 
INFO  [02:34:29.235] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:34:29.290] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:34:29.296] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:34:42.699] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:34:56.963] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:35:11.346] [mlr3]  Finished benchmark 
INFO  [02:35:11.414] [bbotk] Result of batch 72: 
INFO  [02:35:11.416] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:35:11.416] [bbotk]              9.955244                 7.945011                       0.1255296 
INFO  [02:35:11.416] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:35:11.416] [bbotk]                     4981        0.658 -0.9545621         <NA>   0.9746786 
INFO  [02:35:11.416] [bbotk]                                 uhash 
INFO  [02:35:11.416] [bbotk]  ffbc5cb1-55a5-49f8-b055-ccdb01225f54 
DEBUG [02:35:12.463] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.157706e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.157706e-05 0.001473804 
  - best initial criterion value(s) :  428.5244 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -428.52  |proj g|=         3.26
At iterate     1  f =      -434.58  |proj g|=        2.4855
At iterate     2  f =      -437.74  |proj g|=         1.872
At iterate     3  f =      -440.14  |proj g|=       0.86985
At iterate     4  f =      -440.59  |proj g|=        0.7283
At iterate     5  f =      -441.03  |proj g|=       0.70654
At iterate     6  f =      -443.25  |proj g|=       0.70118
At iterate     7  f =      -444.08  |proj g|=        1.0464
At iterate     8  f =      -444.29  |proj g|=        1.0145
At iterate     9  f =      -444.35  |proj g|=        1.0254
At iterate    10  f =      -444.35  |proj g|=        1.0462
At iterate    11  f =      -444.35  |proj g|=        1.0359
At iterate    12  f =      -444.35  |proj g|=        1.0343
At iterate    13  f =      -444.35  |proj g|=        1.0337
At iterate    14  f =      -444.35  |proj g|=        1.0321
At iterate    15  f =      -444.35  |proj g|=        1.0291
At iterate    16  f =      -444.35  |proj g|=         1.022
At iterate    17  f =      -444.35  |proj g|=        1.0181
At iterate    18  f =      -444.35  |proj g|=        1.0023
At iterate    19  f =      -444.36  |proj g|=        0.9966
At iterate    20  f =       -444.4  |proj g|=       0.97247
At iterate    21  f =      -444.64  |proj g|=       0.83988
At iterate    22  f =      -445.28  |proj g|=       0.81335
At iterate    23  f =      -446.49  |proj g|=       0.82718
At iterate    24  f =      -446.49  |proj g|=       0.77507
At iterate    25  f =      -446.57  |proj g|=       0.80875
At iterate    26  f =      -446.57  |proj g|=       0.80879
At iterate    27  f =      -446.57  |proj g|=       0.80913
At iterate    28  f =      -446.57  |proj g|=       0.80894
At iterate    29  f =      -446.57  |proj g|=       0.80786
At iterate    30  f =      -446.57  |proj g|=       0.80818
At iterate    31  f =      -446.57  |proj g|=       0.80801
At iterate    32  f =      -446.57  |proj g|=       0.80756
At iterate    33  f =      -446.57  |proj g|=       0.80674
At iterate    34  f =      -446.57  |proj g|=       0.80547
At iterate    35  f =      -446.58  |proj g|=       0.80332
At iterate    36  f =      -446.58  |proj g|=       0.80115
At iterate    37  f =      -446.58  |proj g|=       0.77993
At iterate    38  f =      -446.58  |proj g|=       0.78892
At iterate    39  f =       -446.6  |proj g|=       0.80291
At iterate    40  f =      -446.63  |proj g|=       0.82059
At iterate    41  f =      -446.72  |proj g|=       0.84169
At iterate    42  f =      -446.94  |proj g|=       0.46166
At iterate    43  f =      -447.21  |proj g|=        0.4654
At iterate    44  f =       -447.4  |proj g|=       0.44712
At iterate    45  f =      -447.45  |proj g|=       0.53636
At iterate    46  f =      -447.46  |proj g|=       0.54151
At iterate    47  f =      -447.46  |proj g|=       0.54201
At iterate    48  f =      -447.46  |proj g|=       0.54396
At iterate    49  f =      -447.46  |proj g|=       0.54407
At iterate    50  f =      -447.46  |proj g|=       0.54377
At iterate    51  f =      -447.47  |proj g|=     0.0038052
At iterate    52  f =      -447.47  |proj g|=     0.0038066
At iterate    53  f =      -447.47  |proj g|=     0.0038066

iterations 53
function evaluations 66
segments explored during Cauchy searches 55
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00380661
final function value -447.469

F = -447.469
final  value -447.468827 
converged
 
INFO  [02:35:12.468] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:35:12.525] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:35:12.532] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:35:19.824] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:35:27.844] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:35:35.369] [mlr3]  Finished benchmark 
INFO  [02:35:35.438] [bbotk] Result of batch 73: 
INFO  [02:35:35.440] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:35:35.440] [bbotk]              2.598731                 5.261964                      0.02371887 
INFO  [02:35:35.440] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:35:35.440] [bbotk]                     2705        0.644 -0.9500681         <NA>    0.936497 
INFO  [02:35:35.440] [bbotk]                                 uhash 
INFO  [02:35:35.440] [bbotk]  85a0d0b2-0d82-49ef-bebf-d35322dae96e 
DEBUG [02:35:36.344] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.244042e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.244042e-05 0.001521567 
  - best initial criterion value(s) :  418.1532 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -418.15  |proj g|=       1.2073
At iterate     1  f =      -420.29  |proj g|=       0.95513
At iterate     2  f =      -420.43  |proj g|=       0.91387
At iterate     3  f =      -420.48  |proj g|=       0.87553
At iterate     4  f =      -420.75  |proj g|=       0.83819
At iterate     5  f =      -421.34  |proj g|=       0.79352
At iterate     6  f =      -421.47  |proj g|=        0.8048
At iterate     7  f =      -421.49  |proj g|=       0.80869
At iterate     8  f =      -421.49  |proj g|=       0.81015
At iterate     9  f =      -421.49  |proj g|=       0.81079
At iterate    10  f =      -421.49  |proj g|=       0.81068

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.810675
final function value -421.49

F = -421.49
final  value -421.489604 
converged
 
INFO  [02:35:36.348] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:35:36.407] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:35:36.433] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:35:46.126] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:35:57.284] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:36:06.526] [mlr3]  Finished benchmark 
INFO  [02:36:06.593] [bbotk] Result of batch 74: 
INFO  [02:36:06.594] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:36:06.594] [bbotk]              6.474885                 8.970507                       0.3445566 
INFO  [02:36:06.594] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:36:06.594] [bbotk]                     3462        0.662 -0.9626012         <NA>   0.9780183 
INFO  [02:36:06.594] [bbotk]                                 uhash 
INFO  [02:36:06.594] [bbotk]  0e621c2f-2292-490d-971b-d9f9a99348ee 
DEBUG [02:36:07.580] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.24155e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.24155e-05 0.001523579 
  - best initial criterion value(s) :  405.8048 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -405.8  |proj g|=        4.655
At iterate     1  f =      -414.71  |proj g|=        7.1349
At iterate     2  f =      -420.06  |proj g|=        6.2665
At iterate     3  f =      -421.28  |proj g|=        6.3287
At iterate     4  f =      -422.76  |proj g|=        5.6976
At iterate     5  f =      -425.34  |proj g|=        4.1492
At iterate     6  f =      -425.81  |proj g|=        3.1262
At iterate     7  f =      -425.87  |proj g|=        3.4295
At iterate     8  f =      -425.87  |proj g|=        3.3772
At iterate     9  f =      -425.87  |proj g|=        3.3787
At iterate    10  f =      -425.87  |proj g|=        3.3777
At iterate    11  f =      -425.87  |proj g|=        3.3751
At iterate    12  f =      -425.87  |proj g|=         3.371
At iterate    13  f =      -425.87  |proj g|=        3.3369
At iterate    14  f =      -425.88  |proj g|=        3.3019
At iterate    15  f =      -425.88  |proj g|=        3.2933
At iterate    16  f =       -425.9  |proj g|=        3.2234
At iterate    17  f =      -427.64  |proj g|=        2.7629
At iterate    18  f =      -434.74  |proj g|=        1.4293
At iterate    19  f =      -436.68  |proj g|=        1.1755
At iterate    20  f =      -437.84  |proj g|=        1.7377
At iterate    21  f =       -438.2  |proj g|=        1.5451
At iterate    22  f =      -438.58  |proj g|=        2.0602
At iterate    23  f =      -438.89  |proj g|=        2.1208
At iterate    24  f =      -439.03  |proj g|=        1.7321
At iterate    25  f =      -439.05  |proj g|=        1.8893
At iterate    26  f =      -439.05  |proj g|=        1.8512
At iterate    27  f =      -439.05  |proj g|=        1.8539
At iterate    28  f =      -439.05  |proj g|=        1.8537

iterations 28
function evaluations 36
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.85369
final function value -439.048

F = -439.048
final  value -439.048297 
converged
 
INFO  [02:36:07.584] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:36:07.642] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:36:07.649] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:36:14.995] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:36:21.883] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:36:29.165] [mlr3]  Finished benchmark 
INFO  [02:36:29.233] [bbotk] Result of batch 75: 
INFO  [02:36:29.235] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:36:29.235] [bbotk]              4.220881                 9.080643                       0.2331466 
INFO  [02:36:29.235] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:36:29.235] [bbotk]                     2486        0.661 -0.9607101         <NA>   0.9733797 
INFO  [02:36:29.235] [bbotk]                                 uhash 
INFO  [02:36:29.235] [bbotk]  0ac4d74d-db9f-47db-a30a-44afaf0f191f 
DEBUG [02:36:30.153] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.232315e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.232315e-05 0.001517915 
  - best initial criterion value(s) :  442.7101 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -442.71  |proj g|=       1.1191
At iterate     1  f =      -443.16  |proj g|=        2.2712
At iterate     2  f =      -445.54  |proj g|=        1.9211
At iterate     3  f =      -448.03  |proj g|=        1.0323
At iterate     4  f =      -448.19  |proj g|=        1.1721
At iterate     5  f =      -448.28  |proj g|=        1.1463
At iterate     6  f =      -448.29  |proj g|=        1.1338
At iterate     7  f =      -448.29  |proj g|=        1.1361
At iterate     8  f =      -448.29  |proj g|=         1.136

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.13596
final function value -448.286

F = -448.286
final  value -448.286090 
converged
 
INFO  [02:36:30.157] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:36:30.239] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:36:30.247] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:36:38.957] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:36:48.330] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:36:59.498] [mlr3]  Finished benchmark 
INFO  [02:36:59.567] [bbotk] Result of batch 76: 
INFO  [02:36:59.569] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:36:59.569] [bbotk]              4.169855                 4.097354                      0.02616335 
INFO  [02:36:59.569] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:36:59.569] [bbotk]                     3709        0.676 -0.9579945         <NA>   0.9580697 
INFO  [02:36:59.569] [bbotk]                                 uhash 
INFO  [02:36:59.569] [bbotk]  af4f84e0-9685-41f2-b42f-f744ab37c641 
DEBUG [02:37:00.600] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.230263e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.230263e-05 0.001509792 
  - best initial criterion value(s) :  432.1042 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -432.1  |proj g|=       6.0918
At iterate     1  f =      -436.57  |proj g|=        3.9616
At iterate     2  f =      -439.18  |proj g|=         3.544
At iterate     3  f =       -441.2  |proj g|=        2.7474
At iterate     4  f =         -442  |proj g|=         2.471
At iterate     5  f =      -442.34  |proj g|=        2.5099
At iterate     6  f =      -442.45  |proj g|=        2.6015
At iterate     7  f =      -442.46  |proj g|=         2.769
At iterate     8  f =      -442.48  |proj g|=        2.7066
At iterate     9  f =      -442.48  |proj g|=        2.7077
At iterate    10  f =      -442.48  |proj g|=        2.7086
At iterate    11  f =      -442.48  |proj g|=        2.7103
At iterate    12  f =      -442.48  |proj g|=         2.713
At iterate    13  f =      -442.48  |proj g|=        2.7172
At iterate    14  f =      -442.49  |proj g|=        2.7229
At iterate    15  f =      -442.49  |proj g|=          2.73
At iterate    16  f =       -442.5  |proj g|=        2.7391
At iterate    17  f =      -442.51  |proj g|=        2.7426
At iterate    18  f =      -442.52  |proj g|=        2.8048
At iterate    19  f =      -442.57  |proj g|=        2.7851
At iterate    20  f =      -442.78  |proj g|=        2.6883
At iterate    21  f =      -443.27  |proj g|=        2.8102
At iterate    22  f =      -445.01  |proj g|=        2.8439
At iterate    23  f =      -451.05  |proj g|=        2.0773
At iterate    24  f =      -452.98  |proj g|=        1.3034
At iterate    25  f =      -462.12  |proj g|=       0.52052
At iterate    26  f =      -462.51  |proj g|=       0.52008
At iterate    27  f =      -463.02  |proj g|=       0.48084
At iterate    28  f =      -463.04  |proj g|=       0.44888
At iterate    29  f =      -463.04  |proj g|=       0.41798
At iterate    30  f =      -463.04  |proj g|=       0.40235
At iterate    31  f =      -463.04  |proj g|=       0.40272

iterations 31
function evaluations 37
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.40272
final function value -463.045

F = -463.045
final  value -463.044664 
converged
 
INFO  [02:37:00.604] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:37:00.661] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:37:00.668] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:37:09.948] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:37:22.419] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:37:32.751] [mlr3]  Finished benchmark 
INFO  [02:37:32.820] [bbotk] Result of batch 77: 
INFO  [02:37:32.822] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:37:32.822] [bbotk]              5.634947                 3.938453                      0.02536417 
INFO  [02:37:32.822] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:37:32.822] [bbotk]                     3777        0.703 -0.9531543         <NA>    0.961245 
INFO  [02:37:32.822] [bbotk]                                 uhash 
INFO  [02:37:32.822] [bbotk]  e919475a-8af4-4ac2-969b-01c25ed5f5f4 
DEBUG [02:37:33.845] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.223111e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.223111e-05 0.001502721 
  - best initial criterion value(s) :  423.6367 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -423.64  |proj g|=       2.0131
At iterate     1  f =      -435.14  |proj g|=        5.0055
At iterate     2  f =      -435.55  |proj g|=         4.891
At iterate     3  f =      -436.08  |proj g|=        4.2421
At iterate     4  f =       -436.3  |proj g|=        4.4966
At iterate     5  f =      -436.88  |proj g|=        4.3958
At iterate     6  f =      -438.14  |proj g|=        3.3232
At iterate     7  f =      -438.71  |proj g|=        3.7943
At iterate     8  f =      -438.78  |proj g|=        3.6766
At iterate     9  f =      -438.78  |proj g|=        3.6531
At iterate    10  f =      -438.78  |proj g|=        3.6526
At iterate    11  f =      -438.78  |proj g|=        3.6544
At iterate    12  f =      -438.78  |proj g|=        3.6525
At iterate    13  f =      -438.78  |proj g|=        3.6417
At iterate    14  f =      -438.79  |proj g|=        3.6264
At iterate    15  f =      -438.79  |proj g|=         3.599
At iterate    16  f =      -438.81  |proj g|=        3.5534
At iterate    17  f =      -438.86  |proj g|=        3.4805
At iterate    18  f =       -438.9  |proj g|=        3.3592
At iterate    19  f =      -439.05  |proj g|=        3.2704
At iterate    20  f =      -439.75  |proj g|=        2.9408
At iterate    21  f =      -442.27  |proj g|=        2.4506
At iterate    22  f =      -451.44  |proj g|=        1.5012
At iterate    23  f =      -458.25  |proj g|=       0.50964
At iterate    24  f =      -461.08  |proj g|=        1.6716
At iterate    25  f =      -462.57  |proj g|=        1.3828
At iterate    26  f =      -463.58  |proj g|=       0.68643
At iterate    27  f =      -463.73  |proj g|=       0.59018
At iterate    28  f =      -463.73  |proj g|=       0.68951
At iterate    29  f =      -463.73  |proj g|=       0.65455
At iterate    30  f =      -463.73  |proj g|=       0.65305
At iterate    31  f =      -463.73  |proj g|=        0.6531

iterations 31
function evaluations 41
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.653104
final function value -463.731

F = -463.731
final  value -463.731320 
converged
 
INFO  [02:37:33.849] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:37:33.905] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:37:33.912] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:37:38.554] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:37:43.128] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:37:46.844] [mlr3]  Finished benchmark 
INFO  [02:37:46.914] [bbotk] Result of batch 78: 
INFO  [02:37:46.916] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:37:46.916] [bbotk]              4.842601                 2.132967                       0.4059775 
INFO  [02:37:46.916] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:37:46.916] [bbotk]                     1418        0.666 -0.9557395         <NA>   0.9743335 
INFO  [02:37:46.916] [bbotk]                                 uhash 
INFO  [02:37:46.916] [bbotk]  c8529c73-3352-409e-ae4d-aac61de31ea4 
DEBUG [02:37:48.070] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.215428e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.215428e-05 0.001481819 
  - best initial criterion value(s) :  446.1327 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -446.13  |proj g|=       7.3005
At iterate     1  f =      -454.76  |proj g|=        3.4407
At iterate     2  f =      -458.85  |proj g|=        4.0705
At iterate     3  f =      -460.77  |proj g|=        3.6684
At iterate     4  f =      -461.69  |proj g|=        3.3604
At iterate     5  f =      -462.01  |proj g|=        3.2426
At iterate     6  f =      -462.18  |proj g|=         3.235
At iterate     7  f =      -462.27  |proj g|=        3.5519
At iterate     8  f =      -462.29  |proj g|=        3.4332
At iterate     9  f =      -462.29  |proj g|=        3.4334
At iterate    10  f =      -462.29  |proj g|=        3.4336
At iterate    11  f =      -462.29  |proj g|=        3.4337
At iterate    12  f =      -462.29  |proj g|=        3.4341
At iterate    13  f =      -462.29  |proj g|=        3.4339
At iterate    14  f =      -462.29  |proj g|=        3.4334
At iterate    15  f =      -462.29  |proj g|=        3.4303
At iterate    16  f =      -462.29  |proj g|=        3.4228
At iterate    17  f =       -462.3  |proj g|=        3.4067
At iterate    18  f =      -462.31  |proj g|=        3.3934
At iterate    19  f =      -462.33  |proj g|=        3.2815
At iterate    20  f =      -462.35  |proj g|=        3.3272
At iterate    21  f =      -462.41  |proj g|=        3.2453
At iterate    22  f =      -462.93  |proj g|=        2.7088
At iterate    23  f =      -463.84  |proj g|=        2.1128
At iterate    24  f =      -466.13  |proj g|=        1.1986
At iterate    25  f =      -469.74  |proj g|=       0.55672
At iterate    26  f =      -470.06  |proj g|=       0.58001
At iterate    27  f =      -471.46  |proj g|=       0.50355
At iterate    28  f =      -471.55  |proj g|=       0.14877
At iterate    29  f =      -471.55  |proj g|=       0.10023
At iterate    30  f =      -471.55  |proj g|=       0.10467
At iterate    31  f =      -471.55  |proj g|=       0.10483

iterations 31
function evaluations 36
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.104835
final function value -471.553

F = -471.553
final  value -471.553018 
converged
 
INFO  [02:37:48.075] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:37:48.170] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:37:48.178] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:37:54.157] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:38:00.952] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:38:07.109] [mlr3]  Finished benchmark 
INFO  [02:38:07.179] [bbotk] Result of batch 79: 
INFO  [02:38:07.181] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:38:07.181] [bbotk]              9.121798                 6.641675                       0.2093228 
INFO  [02:38:07.181] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:38:07.181] [bbotk]                     2169        0.653 -0.9522066         <NA>   0.9750347 
INFO  [02:38:07.181] [bbotk]                                 uhash 
INFO  [02:38:07.181] [bbotk]  e297edaa-1f20-408f-acb7-0f12498b1e97 
DEBUG [02:38:08.088] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.208661e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.208661e-05 0.001476599 
  - best initial criterion value(s) :  454.0795 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -454.08  |proj g|=      0.77884
At iterate     1  f =      -454.35  |proj g|=       0.99945
At iterate     2  f =      -454.38  |proj g|=       0.99001
At iterate     3  f =      -454.41  |proj g|=        1.0015
At iterate     4  f =      -454.41  |proj g|=        1.0136
At iterate     5  f =      -454.41  |proj g|=        1.0128
At iterate     6  f =      -454.41  |proj g|=        1.0128

iterations 6
function evaluations 11
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.0128
final function value -454.414

F = -454.414
final  value -454.414364 
converged
 
INFO  [02:38:08.092] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:38:08.151] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:38:08.158] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:38:15.922] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:38:23.032] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:38:29.282] [mlr3]  Finished benchmark 
INFO  [02:38:29.352] [bbotk] Result of batch 80: 
INFO  [02:38:29.354] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:38:29.354] [bbotk]              3.042527                 5.926115                       0.1991132 
INFO  [02:38:29.354] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:38:29.354] [bbotk]                     2449        0.663 -0.9619955         <NA>   0.9677013 
INFO  [02:38:29.354] [bbotk]                                 uhash 
INFO  [02:38:29.354] [bbotk]  2fa5b664-9bdf-473e-adee-88b444b845fb 
DEBUG [02:38:30.342] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.197692e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.197692e-05 0.001466798 
  - best initial criterion value(s) :  446.1589 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -446.16  |proj g|=       3.1101
At iterate     1  f =      -468.96  |proj g|=         7.773
At iterate     2  f =      -471.65  |proj g|=        7.2251
At iterate     3  f =      -474.52  |proj g|=        5.0368
At iterate     4  f =      -474.88  |proj g|=        4.2591
At iterate     5  f =      -474.97  |proj g|=        4.1988
At iterate     6  f =      -475.03  |proj g|=        4.1198
At iterate     7  f =      -475.03  |proj g|=        4.1132
At iterate     8  f =      -475.04  |proj g|=        4.1334
At iterate     9  f =      -475.05  |proj g|=        4.2226
At iterate    10  f =      -475.08  |proj g|=        4.3521
At iterate    11  f =      -475.15  |proj g|=        4.5323
At iterate    12  f =      -475.34  |proj g|=        4.7534
At iterate    13  f =      -475.79  |proj g|=        4.9427
At iterate    14  f =      -476.64  |proj g|=        4.8567
At iterate    15  f =      -476.65  |proj g|=        4.8949
At iterate    16  f =      -478.07  |proj g|=        4.2283
At iterate    17  f =      -480.45  |proj g|=        2.9525
At iterate    18  f =      -483.88  |proj g|=        1.6737
At iterate    19  f =      -485.55  |proj g|=       0.75741
At iterate    20  f =      -486.08  |proj g|=        1.1189
At iterate    21  f =      -486.25  |proj g|=        1.1871
At iterate    22  f =      -486.58  |proj g|=         1.187
At iterate    23  f =      -486.64  |proj g|=        1.1678
At iterate    24  f =      -486.65  |proj g|=        1.1868
At iterate    25  f =      -486.65  |proj g|=        1.1883
At iterate    26  f =      -486.65  |proj g|=        1.1885

iterations 26
function evaluations 32
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.18849
final function value -486.654

F = -486.654
final  value -486.654000 
converged
 
INFO  [02:38:30.347] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:38:30.405] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:38:30.412] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:38:36.672] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:38:44.319] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:38:49.962] [mlr3]  Finished benchmark 
INFO  [02:38:50.046] [bbotk] Result of batch 81: 
INFO  [02:38:50.048] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:38:50.048] [bbotk]              4.525404                 7.380989                       0.4224508 
INFO  [02:38:50.048] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:38:50.048] [bbotk]                     2088        0.674 -0.9479363         <NA>   0.9758102 
INFO  [02:38:50.048] [bbotk]                                 uhash 
INFO  [02:38:50.048] [bbotk]  2cf51919-452b-4a4c-b8b3-3a01b411a021 
DEBUG [02:38:50.989] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.192141e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.192141e-05 0.001463452 
  - best initial criterion value(s) :  454.7609 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -454.76  |proj g|=       4.9691
At iterate     1  f =      -475.18  |proj g|=        1.7379
At iterate     2  f =      -477.43  |proj g|=        1.5973
At iterate     3  f =       -480.4  |proj g|=        1.1734
At iterate     4  f =      -481.23  |proj g|=         1.154
At iterate     5  f =      -482.69  |proj g|=        1.2881
At iterate     6  f =      -485.39  |proj g|=        1.3772
At iterate     7  f =      -486.74  |proj g|=        1.2903
At iterate     8  f =      -487.13  |proj g|=        1.4134
At iterate     9  f =      -487.15  |proj g|=        1.3799
At iterate    10  f =      -487.16  |proj g|=        1.3551
At iterate    11  f =      -487.16  |proj g|=        1.3561
At iterate    12  f =      -487.16  |proj g|=         1.356

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.35595
final function value -487.158

F = -487.158
final  value -487.157625 
converged
 
INFO  [02:38:50.993] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:38:51.049] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:38:51.056] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:38:53.259] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:38:55.317] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:38:57.248] [mlr3]  Finished benchmark 
INFO  [02:38:57.323] [bbotk] Result of batch 82: 
INFO  [02:38:57.325] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:38:57.325] [bbotk]              9.052303                 4.518518                       0.4513256 
INFO  [02:38:57.325] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:38:57.325] [bbotk]                      683        0.683  -0.95067         <NA>    0.972929 
INFO  [02:38:57.325] [bbotk]                                 uhash 
INFO  [02:38:57.325] [bbotk]  63ac9c26-7918-4ef3-ac80-943c879fee4b 
DEBUG [02:38:58.326] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.183461e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.183461e-05 0.001443067 
  - best initial criterion value(s) :  450.9785 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -450.98  |proj g|=       2.6264
At iterate     1  f =      -468.87  |proj g|=        7.0381
At iterate     2  f =      -469.36  |proj g|=        6.8886
At iterate     3  f =      -470.15  |proj g|=        5.9819
At iterate     4  f =      -470.39  |proj g|=          6.12
At iterate     5  f =      -470.83  |proj g|=        5.9695
At iterate     6  f =      -471.11  |proj g|=        5.4865
At iterate     7  f =      -471.12  |proj g|=        5.4176
At iterate     8  f =      -471.12  |proj g|=        5.4284
At iterate     9  f =      -471.12  |proj g|=         5.427
At iterate    10  f =      -471.12  |proj g|=        5.4258
At iterate    11  f =      -471.12  |proj g|=        5.4211
At iterate    12  f =      -471.12  |proj g|=         5.414
At iterate    13  f =      -471.12  |proj g|=        5.4025
At iterate    14  f =      -471.12  |proj g|=        5.3837
At iterate    15  f =      -471.13  |proj g|=        5.3514
At iterate    16  f =      -471.13  |proj g|=        5.2981
At iterate    17  f =      -471.16  |proj g|=        5.2171
At iterate    18  f =      -471.19  |proj g|=        5.1231
At iterate    19  f =       -471.2  |proj g|=        5.0633
At iterate    20  f =      -471.28  |proj g|=        4.9479
At iterate    21  f =      -480.21  |proj g|=        2.5416
At iterate    22  f =      -480.53  |proj g|=        2.3714
At iterate    23  f =      -480.72  |proj g|=        2.1605
At iterate    24  f =      -480.72  |proj g|=        2.1318
At iterate    25  f =      -480.72  |proj g|=        2.1375
At iterate    26  f =      -480.72  |proj g|=        2.1377
At iterate    27  f =      -480.72  |proj g|=        2.1376

iterations 27
function evaluations 32
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.1376
final function value -480.72

F = -480.72
final  value -480.720184 
converged
 
INFO  [02:38:58.330] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:38:58.387] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:38:58.394] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:39:06.323] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:39:13.713] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:39:21.087] [mlr3]  Finished benchmark 
INFO  [02:39:21.210] [bbotk] Result of batch 83: 
INFO  [02:39:21.212] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:39:21.212] [bbotk]              5.191452                 8.102437                       0.1271477 
INFO  [02:39:21.212] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:39:21.212] [bbotk]                     3590        0.677 -0.9605567         <NA>   0.9735741 
INFO  [02:39:21.212] [bbotk]                                 uhash 
INFO  [02:39:21.212] [bbotk]  383fd557-df8a-47a4-893f-2cd2345c9450 
DEBUG [02:39:22.194] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.175465e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.175465e-05 0.00143674 
  - best initial criterion value(s) :  473.7826 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -473.78  |proj g|=        2.341
At iterate     1  f =      -483.33  |proj g|=        1.6112
At iterate     2  f =      -486.34  |proj g|=        1.3791
At iterate     3  f =      -487.86  |proj g|=        1.1028
At iterate     4  f =      -488.27  |proj g|=        1.0094
At iterate     5  f =       -488.6  |proj g|=        1.0787
At iterate     6  f =       -488.6  |proj g|=        1.1014
At iterate     7  f =       -488.6  |proj g|=        1.0965
At iterate     8  f =       -488.6  |proj g|=        1.0963

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.09627
final function value -488.602

F = -488.602
final  value -488.601835 
converged
 
INFO  [02:39:22.198] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:39:22.260] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:39:22.267] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:39:23.644] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:39:25.032] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:39:26.519] [mlr3]  Finished benchmark 
INFO  [02:39:26.674] [bbotk] Result of batch 84: 
INFO  [02:39:26.678] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:39:26.678] [bbotk]              2.705236                 8.128193                       0.1008035 
INFO  [02:39:26.678] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:39:26.678] [bbotk]                      517        0.752 -0.956619         <NA>   0.9328373 
INFO  [02:39:26.678] [bbotk]                                 uhash 
INFO  [02:39:26.678] [bbotk]  231eb931-a0e8-4bd7-9716-7408a6ff3675 
DEBUG [02:39:27.728] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.274551e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.274551e-05 0.001584422 
  - best initial criterion value(s) :  463.8411 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -463.84  |proj g|=       4.2072
At iterate     1  f =      -493.28  |proj g|=        4.4396
At iterate     2  f =         -495  |proj g|=        3.9752
At iterate     3  f =      -496.55  |proj g|=        2.3116
At iterate     4  f =      -496.81  |proj g|=        2.8577
At iterate     5  f =      -496.85  |proj g|=        2.8092
At iterate     6  f =      -497.09  |proj g|=         2.602
At iterate     7  f =      -497.27  |proj g|=        2.5998
At iterate     8  f =      -497.34  |proj g|=        2.6867
At iterate     9  f =      -497.35  |proj g|=        2.7284
At iterate    10  f =      -497.35  |proj g|=        2.7413
At iterate    11  f =      -497.35  |proj g|=        2.7425
At iterate    12  f =      -497.35  |proj g|=        2.7432
At iterate    13  f =      -497.35  |proj g|=        2.7448
At iterate    14  f =      -497.35  |proj g|=        2.7471
At iterate    15  f =      -497.35  |proj g|=        2.7508
At iterate    16  f =      -497.36  |proj g|=        2.7558
At iterate    17  f =      -497.36  |proj g|=        2.7604
At iterate    18  f =      -497.36  |proj g|=        2.7594
At iterate    19  f =      -497.36  |proj g|=        2.7529
At iterate    20  f =      -497.37  |proj g|=        2.7268
At iterate    21  f =      -497.38  |proj g|=        2.7534
At iterate    22  f =       -497.4  |proj g|=        2.7085
At iterate    23  f =      -497.48  |proj g|=         2.614
At iterate    24  f =      -497.84  |proj g|=        2.3505
At iterate    25  f =      -498.76  |proj g|=        1.8645
At iterate    26  f =      -500.65  |proj g|=        1.1997
At iterate    27  f =      -500.86  |proj g|=       0.90877
At iterate    28  f =      -503.88  |proj g|=       0.66112
At iterate    29  f =      -506.47  |proj g|=       0.53529
At iterate    30  f =      -506.49  |proj g|=       0.53715
At iterate    31  f =      -506.49  |proj g|=      0.092679
At iterate    32  f =      -506.49  |proj g|=      0.091203
At iterate    33  f =      -506.49  |proj g|=      0.091185

iterations 33
function evaluations 38
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0911846
final function value -506.493

F = -506.493
final  value -506.492595 
converged
 
INFO  [02:39:27.734] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:39:27.805] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:39:27.814] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:39:37.711] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:39:47.141] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:39:56.829] [mlr3]  Finished benchmark 
INFO  [02:39:56.951] [bbotk] Result of batch 85: 
INFO  [02:39:56.953] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:39:56.953] [bbotk]              5.891103                 3.821024                      0.01811299 
INFO  [02:39:56.953] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:39:56.953] [bbotk]                     4641        0.693 -0.948821         <NA>   0.9599359 
INFO  [02:39:56.953] [bbotk]                                 uhash 
INFO  [02:39:56.953] [bbotk]  7f377111-3aeb-420a-ac84-bb23c27f9972 
DEBUG [02:39:57.899] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.269071e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.269071e-05 0.001567943 
  - best initial criterion value(s) :  456.0167 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -456.02  |proj g|=       6.8591
At iterate     1  f =      -475.25  |proj g|=        2.5177
At iterate     2  f =      -494.76  |proj g|=        1.6662
At iterate     3  f =      -495.18  |proj g|=        1.3522
At iterate     4  f =      -495.99  |proj g|=        1.4292
At iterate     5  f =       -496.9  |proj g|=        1.5222
At iterate     6  f =      -499.14  |proj g|=        1.5958
At iterate     7  f =      -500.21  |proj g|=        1.5122
At iterate     8  f =      -500.41  |proj g|=         1.589
At iterate     9  f =      -500.44  |proj g|=        1.5542
At iterate    10  f =      -500.45  |proj g|=        1.5275
At iterate    11  f =      -500.45  |proj g|=        1.5267
At iterate    12  f =      -500.45  |proj g|=        1.5265

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.52655
final function value -500.446

F = -500.446
final  value -500.446341 
converged
 
INFO  [02:39:57.903] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:39:57.972] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:39:57.982] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:40:02.861] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:40:07.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:40:12.398] [mlr3]  Finished benchmark 
INFO  [02:40:12.471] [bbotk] Result of batch 86: 
INFO  [02:40:12.473] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:40:12.473] [bbotk]              8.936399                 9.021053                       0.2117297 
INFO  [02:40:12.473] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:40:12.473] [bbotk]                     2456        0.699 -0.9535239         <NA>   0.9756249 
INFO  [02:40:12.473] [bbotk]                                 uhash 
INFO  [02:40:12.473] [bbotk]  9fe19ef0-29ed-4f8e-a22e-122b55121506 
DEBUG [02:40:13.432] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.263193e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.263193e-05 0.00156832 
  - best initial criterion value(s) :  461.3515 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -461.35  |proj g|=       4.5866
At iterate     1  f =      -482.98  |proj g|=        8.5798
At iterate     2  f =      -488.06  |proj g|=        7.6727
At iterate     3  f =      -490.84  |proj g|=        5.9061
At iterate     4  f =       -495.3  |proj g|=        3.1709
At iterate     5  f =      -495.37  |proj g|=        3.3866
At iterate     6  f =      -495.94  |proj g|=        3.2811
At iterate     7  f =      -495.95  |proj g|=        3.0825
At iterate     8  f =      -495.95  |proj g|=        3.1433
At iterate     9  f =      -495.95  |proj g|=        3.1411
At iterate    10  f =      -495.95  |proj g|=        3.1409

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.14092
final function value -495.951

F = -495.951
final  value -495.951486 
converged
 
INFO  [02:40:13.436] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:40:13.495] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:40:13.503] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:40:24.935] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:40:38.103] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:40:50.480] [mlr3]  Finished benchmark 
INFO  [02:40:50.549] [bbotk] Result of batch 87: 
INFO  [02:40:50.551] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:40:50.551] [bbotk]               4.95092                 6.683156                       0.3345097 
INFO  [02:40:50.551] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:40:50.551] [bbotk]                     4247        0.692 -0.9619585         <NA>   0.9776862 
INFO  [02:40:50.551] [bbotk]                                 uhash 
INFO  [02:40:50.551] [bbotk]  72dd2a68-74ad-44ca-b087-7b46bd9950c6 
DEBUG [02:40:51.764] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.260357e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.260357e-05 0.001569227 
  - best initial criterion value(s) :  477.4403 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -477.44  |proj g|=       1.5588
At iterate     1  f =      -478.67  |proj g|=       0.83689
At iterate     2  f =      -478.67  |proj g|=       0.83209
At iterate     3  f =      -478.68  |proj g|=       0.82553
At iterate     4  f =      -478.68  |proj g|=       0.84669
At iterate     5  f =       -478.7  |proj g|=       0.89362
At iterate     6  f =      -478.71  |proj g|=       0.93938
At iterate     7  f =      -478.73  |proj g|=       0.94941
At iterate     8  f =      -478.73  |proj g|=       0.92242
At iterate     9  f =      -478.73  |proj g|=        0.9104
At iterate    10  f =      -478.73  |proj g|=       0.90923
At iterate    11  f =      -478.73  |proj g|=       0.90914

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.909136
final function value -478.733

F = -478.733
final  value -478.733302 
converged
 
INFO  [02:40:51.768] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:40:51.824] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:40:51.831] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:41:00.341] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:41:10.080] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:41:19.716] [mlr3]  Finished benchmark 
INFO  [02:41:19.783] [bbotk] Result of batch 88: 
INFO  [02:41:19.785] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:41:19.785] [bbotk]              2.132032                 3.891517                       0.1009782 
INFO  [02:41:19.785] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:41:19.785] [bbotk]                     3195        0.919 -0.9637304         <NA>   0.9551721 
INFO  [02:41:19.785] [bbotk]                                 uhash 
INFO  [02:41:19.785] [bbotk]  4b511d2e-2210-4595-b5d5-53afe3d74334 
DEBUG [02:41:20.773] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.26367e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.26367e-05 0.001565856 
  - best initial criterion value(s) :  478.6407 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -478.64  |proj g|=       3.0671
At iterate     1  f =      -481.35  |proj g|=        2.7733
At iterate     2  f =      -486.38  |proj g|=        2.5539
At iterate     3  f =      -492.81  |proj g|=         1.817
At iterate     4  f =      -493.03  |proj g|=        1.6329
At iterate     5  f =      -493.04  |proj g|=        1.6188
At iterate     6  f =      -493.06  |proj g|=        1.5997
At iterate     7  f =      -493.09  |proj g|=        1.6056
At iterate     8  f =       -493.1  |proj g|=        1.6354
At iterate     9  f =       -493.1  |proj g|=        1.6485
At iterate    10  f =       -493.1  |proj g|=        1.6497
At iterate    11  f =       -493.1  |proj g|=        1.6497

iterations 11
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.64967
final function value -493.099

F = -493.099
final  value -493.098691 
converged
 
INFO  [02:41:20.777] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:41:20.835] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:41:20.842] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:41:26.471] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:41:32.248] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:41:38.429] [mlr3]  Finished benchmark 
INFO  [02:41:38.532] [bbotk] Result of batch 89: 
INFO  [02:41:38.534] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:41:38.534] [bbotk]              2.736981                 4.001983                       0.4587444 
INFO  [02:41:38.534] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:41:38.534] [bbotk]                     1865        0.702 -0.9620449         <NA>   0.9684259 
INFO  [02:41:38.534] [bbotk]                                 uhash 
INFO  [02:41:38.534] [bbotk]  aac1c270-6c05-4211-8d20-27fdb3fc286f 
DEBUG [02:41:39.612] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.253068e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.253068e-05 0.001552334 
  - best initial criterion value(s) :  477.5595 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -477.56  |proj g|=       6.7484
At iterate     1  f =      -498.23  |proj g|=        8.7091
At iterate     2  f =      -506.48  |proj g|=        7.1102
At iterate     3  f =      -513.13  |proj g|=        4.1834
At iterate     4  f =      -515.47  |proj g|=        1.4466
At iterate     5  f =      -515.52  |proj g|=        1.8352
At iterate     6  f =      -515.99  |proj g|=        2.3838
At iterate     7  f =      -516.01  |proj g|=        2.2883
At iterate     8  f =      -516.01  |proj g|=        2.2778
At iterate     9  f =      -516.01  |proj g|=         2.274
At iterate    10  f =      -516.01  |proj g|=        2.2635
At iterate    11  f =      -516.01  |proj g|=        2.2461
At iterate    12  f =      -516.01  |proj g|=        2.2136
At iterate    13  f =      -516.01  |proj g|=        2.1769
At iterate    14  f =      -516.03  |proj g|=         2.091
At iterate    15  f =      -516.06  |proj g|=        1.9695
At iterate    16  f =      -516.14  |proj g|=        1.7452
At iterate    17  f =      -516.34  |proj g|=        1.4268
At iterate    18  f =      -516.88  |proj g|=        1.3135
At iterate    19  f =      -517.92  |proj g|=        1.3617
At iterate    20  f =      -518.73  |proj g|=        1.2673
At iterate    21  f =      -520.16  |proj g|=        1.2015
At iterate    22  f =      -521.39  |proj g|=        1.3035
At iterate    23  f =      -522.32  |proj g|=         1.346
At iterate    24  f =      -522.55  |proj g|=        1.3513
At iterate    25  f =      -522.56  |proj g|=         1.364
At iterate    26  f =      -522.58  |proj g|=        1.3641
At iterate    27  f =      -522.58  |proj g|=        1.3775
At iterate    28  f =      -522.58  |proj g|=        1.3759
At iterate    29  f =      -522.58  |proj g|=        1.3761
At iterate    30  f =      -522.58  |proj g|=        1.3761

iterations 30
function evaluations 38
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.3761
final function value -522.584

F = -522.584
final  value -522.584488 
converged
 
INFO  [02:41:39.616] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:41:39.671] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:41:39.678] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:41:52.510] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:42:05.055] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:42:18.938] [mlr3]  Finished benchmark 
INFO  [02:42:19.008] [bbotk] Result of batch 90: 
INFO  [02:42:19.010] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:42:19.010] [bbotk]              4.763078                 9.259301                       0.4852427 
INFO  [02:42:19.010] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:42:19.010] [bbotk]                     4207        0.695 -0.9544903         <NA>   0.9784408 
INFO  [02:42:19.010] [bbotk]                                 uhash 
INFO  [02:42:19.010] [bbotk]  3d6030aa-ee6f-4411-aecc-78389d7dd998 
DEBUG [02:42:20.095] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.251684e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.251684e-05 0.001553542 
  - best initial criterion value(s) :  502.8092 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -502.81  |proj g|=       1.9064
At iterate     1  f =      -506.16  |proj g|=        7.2143
At iterate     2  f =      -512.14  |proj g|=        5.1099
At iterate     3  f =      -512.41  |proj g|=        4.9315
At iterate     4  f =      -512.58  |proj g|=        4.9736
At iterate     5  f =      -512.62  |proj g|=        4.7565
At iterate     6  f =      -512.62  |proj g|=        4.7514
At iterate     7  f =      -512.62  |proj g|=        4.7616
At iterate     8  f =      -512.62  |proj g|=        4.7786
At iterate     9  f =      -512.64  |proj g|=        4.8177
At iterate    10  f =      -512.68  |proj g|=        4.9054
At iterate    11  f =      -512.73  |proj g|=        4.7895
At iterate    12  f =      -512.87  |proj g|=        4.9183
At iterate    13  f =      -513.41  |proj g|=        5.1067
At iterate    14  f =      -514.81  |proj g|=        5.1712
At iterate    15  f =      -518.01  |proj g|=        4.7424
At iterate    16  f =      -527.63  |proj g|=        2.5861
At iterate    17  f =      -528.96  |proj g|=         3.343
At iterate    18  f =      -535.28  |proj g|=        2.5689
At iterate    19  f =      -536.36  |proj g|=        1.7587
At iterate    20  f =      -536.46  |proj g|=        1.4378
At iterate    21  f =      -536.48  |proj g|=        1.5714
At iterate    22  f =      -536.48  |proj g|=        1.5561
At iterate    23  f =      -536.48  |proj g|=        1.5551

iterations 23
function evaluations 33
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.55512
final function value -536.485

F = -536.485
final  value -536.484829 
converged
 
INFO  [02:42:20.099] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:42:20.157] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:42:20.164] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:42:35.163] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:42:50.474] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:43:04.461] [mlr3]  Finished benchmark 
INFO  [02:43:04.551] [bbotk] Result of batch 91: 
INFO  [02:43:04.554] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:43:04.554] [bbotk]              6.512087                 2.482351                       0.2488358 
INFO  [02:43:04.554] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:43:04.554] [bbotk]                     4974        0.721 -0.9537261         <NA>   0.9781231 
INFO  [02:43:04.554] [bbotk]                                 uhash 
INFO  [02:43:04.554] [bbotk]  042010bf-f1e8-474c-a857-82cb3d0cca5d 
DEBUG [02:43:05.628] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.249643e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.249643e-05 0.001548874 
  - best initial criterion value(s) :  486.4688 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -486.47  |proj g|=       1.5523
At iterate     1  f =      -487.41  |proj g|=        3.5229
At iterate     2  f =      -489.23  |proj g|=        3.1245
At iterate     3  f =      -490.53  |proj g|=        2.5925
At iterate     4  f =      -491.58  |proj g|=         2.037
At iterate     5  f =      -494.08  |proj g|=        1.4034
At iterate     6  f =      -498.14  |proj g|=        1.2433
At iterate     7  f =      -499.69  |proj g|=        1.7438
At iterate     8  f =      -499.86  |proj g|=        1.9053
At iterate     9  f =      -499.89  |proj g|=        1.9097
At iterate    10  f =      -499.89  |proj g|=        1.8977
At iterate    11  f =      -499.89  |proj g|=        1.8978

iterations 11
function evaluations 16
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.89781
final function value -499.893

F = -499.893
final  value -499.892715 
converged
 
INFO  [02:43:05.632] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:43:05.689] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:43:05.696] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:43:06.809] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:43:08.856] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:43:10.617] [mlr3]  Finished benchmark 
INFO  [02:43:10.685] [bbotk] Result of batch 92: 
INFO  [02:43:10.687] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:43:10.687] [bbotk]              5.172129                 8.352702                       0.1922267 
INFO  [02:43:10.687] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:43:10.687] [bbotk]                      308        0.782 -0.9646509         <NA>   0.9540822 
INFO  [02:43:10.687] [bbotk]                                 uhash 
INFO  [02:43:10.687] [bbotk]  ad8ef442-d03a-49ee-840a-f5f5d90a2e12 
DEBUG [02:43:11.780] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.255468e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.255468e-05 0.001557592 
  - best initial criterion value(s) :  497.0331 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -497.03  |proj g|=        12.43
At iterate     1  f =      -507.67  |proj g|=        3.6505
At iterate     2  f =      -518.43  |proj g|=        2.9313
At iterate     3  f =      -522.66  |proj g|=        2.6788
At iterate     4  f =      -526.03  |proj g|=        2.3593
At iterate     5  f =      -527.56  |proj g|=        2.1518
At iterate     6  f =      -528.65  |proj g|=        2.0397
At iterate     7  f =       -529.8  |proj g|=        2.8147
At iterate     8  f =      -530.76  |proj g|=        2.5442
At iterate     9  f =      -531.31  |proj g|=        2.3821
At iterate    10  f =      -531.55  |proj g|=         2.343
At iterate    11  f =       -531.7  |proj g|=        2.3642
At iterate    12  f =      -531.76  |proj g|=        2.4027
At iterate    13  f =      -531.77  |proj g|=        2.4312
At iterate    14  f =      -531.77  |proj g|=        2.4108
At iterate    15  f =      -531.77  |proj g|=        2.4312
At iterate    16  f =      -531.77  |proj g|=        2.4357
At iterate    17  f =       -531.8  |proj g|=        2.4647
At iterate    18  f =      -531.92  |proj g|=         2.506
At iterate    19  f =      -532.32  |proj g|=        2.5722
At iterate    20  f =      -533.23  |proj g|=        2.7255
At iterate    21  f =      -533.58  |proj g|=        2.4254
At iterate    22  f =      -537.33  |proj g|=        2.3413
At iterate    23  f =      -539.71  |proj g|=        2.0037
At iterate    24  f =      -539.73  |proj g|=        2.1296
At iterate    25  f =      -539.76  |proj g|=        2.0884
At iterate    26  f =      -539.76  |proj g|=        2.0853
At iterate    27  f =      -539.76  |proj g|=        2.0854

iterations 27
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.08545
final function value -539.763

F = -539.763
final  value -539.763133 
converged
 
INFO  [02:43:11.784] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:43:11.844] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:43:11.851] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:43:19.539] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:43:27.264] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:43:34.683] [mlr3]  Finished benchmark 
INFO  [02:43:34.752] [bbotk] Result of batch 93: 
INFO  [02:43:34.754] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:43:34.754] [bbotk]              2.131984                 5.799201                       0.1715721 
INFO  [02:43:34.754] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:43:34.754] [bbotk]                     2906        0.724 -0.950757         <NA>   0.9584356 
INFO  [02:43:34.754] [bbotk]                                 uhash 
INFO  [02:43:34.754] [bbotk]  f505ac1d-8797-40e5-a29f-47c4103b1a6c 
DEBUG [02:43:35.866] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.252679e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.252679e-05 0.001548371 
  - best initial criterion value(s) :  519.6307 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -519.63  |proj g|=       3.3302
At iterate     1  f =      -530.34  |proj g|=        6.8194
At iterate     2  f =      -530.53  |proj g|=        6.6923
At iterate     3  f =      -531.35  |proj g|=        5.5653
At iterate     4  f =      -533.45  |proj g|=        4.8429
At iterate     5  f =      -534.35  |proj g|=        2.8391
At iterate     6  f =      -534.49  |proj g|=        3.5759
At iterate     7  f =      -534.49  |proj g|=        3.4537
At iterate     8  f =      -534.49  |proj g|=        3.4429
At iterate     9  f =      -534.49  |proj g|=        3.4439
At iterate    10  f =      -534.49  |proj g|=        3.4458
At iterate    11  f =      -534.49  |proj g|=        3.4478
At iterate    12  f =      -534.49  |proj g|=        3.4518
At iterate    13  f =      -534.49  |proj g|=        3.4618
At iterate    14  f =      -534.49  |proj g|=        3.4524
At iterate    15  f =       -534.5  |proj g|=        3.4676
At iterate    16  f =       -534.5  |proj g|=        3.4953
At iterate    17  f =      -534.57  |proj g|=        3.5971
At iterate    18  f =      -534.83  |proj g|=        3.7266
At iterate    19  f =       -535.7  |proj g|=        3.7181
At iterate    20  f =      -535.71  |proj g|=        4.1504
At iterate    21  f =      -537.32  |proj g|=        3.4259
At iterate    22  f =      -539.04  |proj g|=        2.4646
At iterate    23  f =      -539.97  |proj g|=        2.0946
At iterate    24  f =      -540.91  |proj g|=        1.8615
At iterate    25  f =      -541.13  |proj g|=        1.6212
At iterate    26  f =      -541.13  |proj g|=        1.7141
At iterate    27  f =      -541.15  |proj g|=        1.7401
At iterate    28  f =      -541.15  |proj g|=        1.7393
At iterate    29  f =      -541.15  |proj g|=        1.7392

iterations 29
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.73923
final function value -541.148

F = -541.148
final  value -541.148450 
converged
 
INFO  [02:43:35.870] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:43:35.929] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:43:35.935] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:43:42.465] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:43:48.612] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:43:55.061] [mlr3]  Finished benchmark 
INFO  [02:43:55.156] [bbotk] Result of batch 94: 
INFO  [02:43:55.158] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:43:55.158] [bbotk]              4.663004                 8.505378                       0.4291585 
INFO  [02:43:55.158] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:43:55.158] [bbotk]                     2497        0.738 -0.957669         <NA>   0.9765947 
INFO  [02:43:55.158] [bbotk]                                 uhash 
INFO  [02:43:55.158] [bbotk]  93177871-cf83-42d3-83fb-85086649a834 
DEBUG [02:43:56.208] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.248557e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.248557e-05 0.001547504 
  - best initial criterion value(s) :  502.1183 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -502.12  |proj g|=       5.3406
At iterate     1  f =      -535.98  |proj g|=        2.2168
At iterate     2  f =      -536.02  |proj g|=        2.3787
At iterate     3  f =      -536.24  |proj g|=        2.5306
At iterate     4  f =      -537.13  |proj g|=        2.7737
At iterate     5  f =      -541.28  |proj g|=        3.0547
At iterate     6  f =      -544.29  |proj g|=        2.8268
At iterate     7  f =      -546.85  |proj g|=        2.2339
At iterate     8  f =       -551.3  |proj g|=         1.821
At iterate     9  f =      -557.54  |proj g|=       0.40874
At iterate    10  f =      -557.72  |proj g|=       0.59901
At iterate    11  f =      -557.74  |proj g|=       0.14341
At iterate    12  f =      -557.74  |proj g|=       0.14154
At iterate    13  f =      -557.74  |proj g|=       0.14157

iterations 13
function evaluations 22
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.141566
final function value -557.741

F = -557.741
final  value -557.740608 
converged
 
INFO  [02:43:56.212] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:43:56.268] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:43:56.275] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:44:01.678] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:44:06.940] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:44:12.697] [mlr3]  Finished benchmark 
INFO  [02:44:12.768] [bbotk] Result of batch 95: 
INFO  [02:44:12.770] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:44:12.770] [bbotk]              9.151274                 3.658953                       0.1137725 
INFO  [02:44:12.770] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:44:12.770] [bbotk]                     1848        0.736 -0.9460791         <NA>   0.9706265 
INFO  [02:44:12.770] [bbotk]                                 uhash 
INFO  [02:44:12.770] [bbotk]  1dc5bef9-3852-4e36-86bf-ca807f2f0a3f 
DEBUG [02:44:14.227] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.239108e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.239108e-05 0.001539204 
  - best initial criterion value(s) :  498.561 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -498.56  |proj g|=       3.9055
At iterate     1  f =      -510.84  |proj g|=        7.3464
At iterate     2  f =       -511.3  |proj g|=        7.2662
At iterate     3  f =      -511.68  |proj g|=        6.5559
At iterate     4  f =      -511.73  |proj g|=        6.6887
At iterate     5  f =      -511.74  |proj g|=        6.5919
At iterate     6  f =      -511.76  |proj g|=         6.292
At iterate     7  f =      -511.76  |proj g|=         6.283
At iterate     8  f =      -511.76  |proj g|=        6.2817
At iterate     9  f =      -511.76  |proj g|=        6.2793
At iterate    10  f =      -511.76  |proj g|=        6.2763
At iterate    11  f =      -511.76  |proj g|=        6.2698
At iterate    12  f =      -511.76  |proj g|=        6.2548
At iterate    13  f =      -511.77  |proj g|=        6.2116
At iterate    14  f =      -511.79  |proj g|=        6.1252
At iterate    15  f =      -511.83  |proj g|=        5.9608
At iterate    16  f =      -511.94  |proj g|=        5.7039
At iterate    17  f =      -512.18  |proj g|=        4.9705
At iterate    18  f =      -512.35  |proj g|=        5.1495
At iterate    19  f =      -512.94  |proj g|=        4.5494
At iterate    20  f =      -516.96  |proj g|=        2.8387
At iterate    21  f =      -523.75  |proj g|=        2.3201
At iterate    22  f =       -536.2  |proj g|=        1.5348
At iterate    23  f =      -545.37  |proj g|=        1.2081
At iterate    24  f =      -547.49  |proj g|=         1.058
At iterate    25  f =      -548.77  |proj g|=        1.4217
At iterate    26  f =      -549.18  |proj g|=        1.6634
At iterate    27  f =      -549.33  |proj g|=        1.6991
At iterate    28  f =      -550.04  |proj g|=        1.6366
At iterate    29  f =      -552.08  |proj g|=        1.2585
At iterate    30  f =      -552.13  |proj g|=        1.1907
At iterate    31  f =      -552.13  |proj g|=        1.1803
At iterate    32  f =      -552.13  |proj g|=        1.1801
At iterate    33  f =      -552.13  |proj g|=        1.1794
At iterate    34  f =      -552.13  |proj g|=        1.1785
At iterate    35  f =      -552.13  |proj g|=        1.1772
At iterate    36  f =      -552.13  |proj g|=        1.1753
At iterate    37  f =      -552.13  |proj g|=        1.1728
At iterate    38  f =      -552.13  |proj g|=        1.1705
At iterate    39  f =      -552.13  |proj g|=        1.1707
At iterate    40  f =      -552.14  |proj g|=        1.1803
At iterate    41  f =      -552.15  |proj g|=        1.2114
At iterate    42  f =      -552.16  |proj g|=        1.2673
At iterate    43  f =      -552.17  |proj g|=        1.3115
At iterate    44  f =      -552.18  |proj g|=        1.3237
At iterate    45  f =      -552.18  |proj g|=        1.3213
At iterate    46  f =      -552.18  |proj g|=        1.3163
At iterate    47  f =      -552.18  |proj g|=        1.3003
At iterate    48  f =      -552.18  |proj g|=        1.2756
At iterate    49  f =       -552.2  |proj g|=         1.234
At iterate    50  f =      -552.23  |proj g|=        1.1662
At iterate    51  f =      -552.28  |proj g|=        1.0982
At iterate    52  f =       -552.3  |proj g|=        1.1175
At iterate    53  f =      -552.31  |proj g|=        1.1519
At iterate    54  f =      -552.33  |proj g|=        1.1217
At iterate    55  f =      -552.34  |proj g|=        1.1436
At iterate    56  f =      -552.36  |proj g|=         1.115
At iterate    57  f =      -553.32  |proj g|=        0.9587
At iterate    58  f =       -555.2  |proj g|=        1.3377
At iterate    59  f =      -555.41  |proj g|=        1.1904
At iterate    60  f =      -555.43  |proj g|=        1.1268
At iterate    61  f =      -555.43  |proj g|=        1.1294
At iterate    62  f =      -555.43  |proj g|=        1.1294

iterations 62
function evaluations 71
segments explored during Cauchy searches 65
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 1.12941
final function value -555.428

F = -555.428
final  value -555.427738 
converged
 
INFO  [02:44:14.231] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:44:14.286] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:44:14.294] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:44:27.616] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:44:40.924] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:44:54.272] [mlr3]  Finished benchmark 
INFO  [02:44:54.383] [bbotk] Result of batch 96: 
INFO  [02:44:54.385] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:44:54.385] [bbotk]              5.372354                 8.379452                       0.4478073 
INFO  [02:44:54.385] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:44:54.385] [bbotk]                     4430        0.913 -0.9419922         <NA>    0.978894 
INFO  [02:44:54.385] [bbotk]                                 uhash 
INFO  [02:44:54.385] [bbotk]  384920c9-2725-4c80-8e56-d69effca09b5 
DEBUG [02:44:55.461] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.238552e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.238552e-05 0.001537422 
  - best initial criterion value(s) :  514.551 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -514.55  |proj g|=       3.6782
At iterate     1  f =      -515.12  |proj g|=        5.4769
At iterate     2  f =      -517.57  |proj g|=        5.2126
At iterate     3  f =      -518.64  |proj g|=        4.7235
At iterate     4  f =      -518.74  |proj g|=        4.6113
At iterate     5  f =      -519.18  |proj g|=        4.1014
At iterate     6  f =      -519.41  |proj g|=        3.8649
At iterate     7  f =      -519.43  |proj g|=        3.9037
At iterate     8  f =      -519.43  |proj g|=        3.9074
At iterate     9  f =      -519.56  |proj g|=        3.9802
At iterate    10  f =       -520.2  |proj g|=        4.3243
At iterate    11  f =      -521.45  |proj g|=        4.2953
At iterate    12  f =      -521.71  |proj g|=        4.3949
At iterate    13  f =      -526.27  |proj g|=        3.5568
At iterate    14  f =      -529.67  |proj g|=        2.5897
At iterate    15  f =      -532.25  |proj g|=        1.9265
At iterate    16  f =      -539.86  |proj g|=        1.3636
At iterate    17  f =      -541.86  |proj g|=        1.9733
At iterate    18  f =      -541.98  |proj g|=        1.7406
At iterate    19  f =      -542.09  |proj g|=        1.4747
At iterate    20  f =      -542.09  |proj g|=        1.4956
At iterate    21  f =      -542.09  |proj g|=        1.4911
At iterate    22  f =      -542.09  |proj g|=        1.4911

iterations 22
function evaluations 34
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.49114
final function value -542.089

F = -542.089
final  value -542.089045 
converged
 
INFO  [02:44:55.466] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:44:55.522] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:44:55.529] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:45:08.287] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:45:23.516] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:45:35.415] [mlr3]  Finished benchmark 
INFO  [02:45:35.486] [bbotk] Result of batch 97: 
INFO  [02:45:35.488] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:45:35.488] [bbotk]              9.767084                 7.117299                      0.04994094 
INFO  [02:45:35.488] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:45:35.488] [bbotk]                     4471        0.711 -0.9606305         <NA>   0.9711159 
INFO  [02:45:35.488] [bbotk]                                 uhash 
INFO  [02:45:35.488] [bbotk]  81fdba03-5a7a-4869-993a-36cdcfb10cbb 
DEBUG [02:45:36.679] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.229499e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9643483 9590 
  - variance bounds :  1.229499e-05 0.001525412 
  - best initial criterion value(s) :  507.095 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -507.09  |proj g|=       13.431
At iterate     1  f =      -525.48  |proj g|=        4.4525
At iterate     2  f =      -542.26  |proj g|=        3.2965
At iterate     3  f =      -546.86  |proj g|=        2.9535
At iterate     4  f =      -551.78  |proj g|=        2.3747
At iterate     5  f =       -553.8  |proj g|=        1.9802
At iterate     6  f =      -555.15  |proj g|=        1.7129
At iterate     7  f =      -557.54  |proj g|=        3.0838
At iterate     8  f =      -559.62  |proj g|=        2.4381
At iterate     9  f =      -560.66  |proj g|=        2.0776
At iterate    10  f =      -560.86  |proj g|=        2.1942
At iterate    11  f =      -560.93  |proj g|=        2.3911
At iterate    12  f =      -560.93  |proj g|=        2.3957
At iterate    13  f =      -560.93  |proj g|=        2.4032
At iterate    14  f =      -560.93  |proj g|=        2.4217
At iterate    15  f =      -560.93  |proj g|=        2.4491
At iterate    16  f =      -560.95  |proj g|=         2.494
At iterate    17  f =      -560.98  |proj g|=        2.5617
At iterate    18  f =      -561.07  |proj g|=        2.6662
At iterate    19  f =      -561.29  |proj g|=        2.8132
At iterate    20  f =      -563.03  |proj g|=        2.6815
At iterate    21  f =      -563.15  |proj g|=        2.5735
At iterate    22  f =      -566.05  |proj g|=        2.2587
At iterate    23  f =      -566.55  |proj g|=         2.212
At iterate    24  f =      -566.83  |proj g|=         2.441
At iterate    25  f =      -566.97  |proj g|=        2.3078
At iterate    26  f =         -567  |proj g|=        2.1961
At iterate    27  f =         -567  |proj g|=        2.2219
At iterate    28  f =         -567  |proj g|=        2.2196
At iterate    29  f =         -567  |proj g|=        2.2194
At iterate    30  f =         -567  |proj g|=        2.2178
At iterate    31  f =         -567  |proj g|=        2.2156
At iterate    32  f =         -567  |proj g|=        2.2119
At iterate    33  f =         -567  |proj g|=        2.2058
At iterate    34  f =         -567  |proj g|=        2.1959
At iterate    35  f =      -567.01  |proj g|=        2.1803
At iterate    36  f =      -567.01  |proj g|=        2.1569
At iterate    37  f =      -567.03  |proj g|=         2.129
At iterate    38  f =      -567.06  |proj g|=        2.1159
At iterate    39  f =      -567.06  |proj g|=        2.0821
At iterate    40  f =       -567.1  |proj g|=        2.0678
At iterate    41  f =      -568.35  |proj g|=        1.9132
At iterate    42  f =       -573.6  |proj g|=        1.4319
At iterate    43  f =      -574.94  |proj g|=       0.49625
At iterate    44  f =      -575.56  |proj g|=       0.37297
At iterate    45  f =      -575.58  |proj g|=       0.36561
At iterate    46  f =      -575.58  |proj g|=       0.15543
At iterate    47  f =      -575.58  |proj g|=       0.15553

iterations 47
function evaluations 58
segments explored during Cauchy searches 52
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.155529
final function value -575.578

F = -575.578
final  value -575.578248 
converged
 
INFO  [02:45:36.684] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:45:36.780] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:45:36.788] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:45:41.395] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:45:45.356] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:45:49.349] [mlr3]  Finished benchmark 
INFO  [02:45:49.419] [bbotk] Result of batch 98: 
INFO  [02:45:49.421] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:45:49.421] [bbotk]              6.203594                 3.483024                     0.005895457 
INFO  [02:45:49.421] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:45:49.421] [bbotk]                     1494        0.708 -0.9440747         <NA>   0.9111995 
INFO  [02:45:49.421] [bbotk]                                 uhash 
INFO  [02:45:49.421] [bbotk]  d0ba002b-f528-42d9-92ad-d5d36b32f1cf 
DEBUG [02:45:50.538] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.471298e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.471298e-05 0.001751798 
  - best initial criterion value(s) :  497.1924 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -497.19  |proj g|=       6.7121
At iterate     1  f =      -536.52  |proj g|=        5.7645
At iterate     2  f =      -540.01  |proj g|=        4.4038
At iterate     3  f =      -542.72  |proj g|=        1.2052
At iterate     4  f =      -543.17  |proj g|=        1.6133
At iterate     5  f =      -543.23  |proj g|=        1.4544
At iterate     6  f =      -543.46  |proj g|=        1.1932
At iterate     7  f =      -543.69  |proj g|=        1.1707
At iterate     8  f =      -543.84  |proj g|=        1.1706
At iterate     9  f =      -543.85  |proj g|=        1.1492
At iterate    10  f =      -543.85  |proj g|=        1.1473
At iterate    11  f =      -543.86  |proj g|=        1.1464
At iterate    12  f =      -543.87  |proj g|=         1.145
At iterate    13  f =      -543.91  |proj g|=        1.2081
At iterate    14  f =      -543.99  |proj g|=        1.2542
At iterate    15  f =      -544.18  |proj g|=        1.1843
At iterate    16  f =      -544.46  |proj g|=        1.0598
At iterate    17  f =      -544.54  |proj g|=        1.0516
At iterate    18  f =       -544.7  |proj g|=        1.0047
At iterate    19  f =      -545.08  |proj g|=        1.0281
At iterate    20  f =      -545.12  |proj g|=        1.0002
At iterate    21  f =      -545.12  |proj g|=       0.99518
At iterate    22  f =      -545.12  |proj g|=       0.99356
At iterate    23  f =      -545.12  |proj g|=       0.99363
At iterate    24  f =      -545.12  |proj g|=       0.99368

iterations 24
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.993676
final function value -545.12

F = -545.12
final  value -545.119776 
converged
 
INFO  [02:45:50.542] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:45:50.632] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:45:50.644] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:46:02.502] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:46:13.916] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:46:25.140] [mlr3]  Finished benchmark 
INFO  [02:46:25.225] [bbotk] Result of batch 99: 
INFO  [02:46:25.227] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:46:25.227] [bbotk]              2.857166                 2.815197                       0.1537216 
INFO  [02:46:25.227] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:46:25.227] [bbotk]                     4038        0.756 -0.9582401         <NA>   0.9676367 
INFO  [02:46:25.227] [bbotk]                                 uhash 
INFO  [02:46:25.227] [bbotk]  93655333-e572-4022-9c4c-5312406fcb8c 
DEBUG [02:46:26.492] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.459893e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.459893e-05 0.001740317 
  - best initial criterion value(s) :  467.9975 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -468  |proj g|=       14.165
At iterate     1  f =      -494.99  |proj g|=        8.1159
At iterate     2  f =      -501.46  |proj g|=        6.4352
At iterate     3  f =      -509.14  |proj g|=        4.0765
At iterate     4  f =      -509.79  |proj g|=        3.5016
At iterate     5  f =      -510.22  |proj g|=        3.3554
At iterate     6  f =      -510.23  |proj g|=        3.3523
At iterate     7  f =      -510.23  |proj g|=        3.3492
At iterate     8  f =      -510.23  |proj g|=        3.3466
At iterate     9  f =      -510.23  |proj g|=        3.3415
At iterate    10  f =      -510.23  |proj g|=        3.3333
At iterate    11  f =      -510.23  |proj g|=        3.3189
At iterate    12  f =      -510.24  |proj g|=        3.2939
At iterate    13  f =      -510.25  |proj g|=        3.2502
At iterate    14  f =      -510.28  |proj g|=        3.1848
At iterate    15  f =      -510.32  |proj g|=         3.128
At iterate    16  f =      -510.35  |proj g|=        3.0979
At iterate    17  f =      -510.41  |proj g|=        3.0752
At iterate    18  f =       -510.5  |proj g|=        3.0621
At iterate    19  f =      -510.74  |proj g|=        3.0235
At iterate    20  f =      -511.35  |proj g|=        2.9412
At iterate    21  f =      -512.87  |proj g|=        2.7404
At iterate    22  f =      -516.34  |proj g|=        2.3405
At iterate    23  f =      -522.92  |proj g|=       0.82783
At iterate    24  f =      -525.31  |proj g|=        1.3715
At iterate    25  f =         -536  |proj g|=       0.78674
At iterate    26  f =      -537.69  |proj g|=        1.1271
At iterate    27  f =      -542.46  |proj g|=       0.58756
At iterate    28  f =      -542.94  |proj g|=        0.6991
At iterate    29  f =      -543.09  |proj g|=       0.94383
At iterate    30  f =      -543.11  |proj g|=       0.86002
At iterate    31  f =      -543.11  |proj g|=       0.87364
At iterate    32  f =      -543.11  |proj g|=         0.875
At iterate    33  f =      -543.11  |proj g|=       0.87541
At iterate    34  f =      -543.11  |proj g|=       0.87309
At iterate    35  f =      -543.11  |proj g|=       0.86838
At iterate    36  f =      -543.11  |proj g|=       0.85772
At iterate    37  f =      -543.12  |proj g|=       0.84192
At iterate    38  f =      -543.13  |proj g|=       0.82848
At iterate    39  f =      -543.13  |proj g|=       0.79166
At iterate    40  f =      -543.16  |proj g|=       0.77249
At iterate    41  f =      -543.78  |proj g|=       0.67844
At iterate    42  f =      -545.41  |proj g|=       0.73469
At iterate    43  f =      -545.88  |proj g|=       0.28076
At iterate    44  f =      -545.89  |proj g|=       0.69942
At iterate    45  f =      -545.89  |proj g|=       0.23622
At iterate    46  f =      -545.89  |proj g|=        0.0826
At iterate    47  f =      -545.89  |proj g|=      0.040892
At iterate    48  f =      -545.89  |proj g|=     0.0080527
At iterate    49  f =      -545.89  |proj g|=     0.0080525

iterations 49
function evaluations 67
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00805249
final function value -545.888

F = -545.888
final  value -545.887961 
converged
 
INFO  [02:46:26.496] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:46:26.897] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:46:26.908] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:46:32.063] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:46:38.391] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:46:43.210] [mlr3]  Finished benchmark 
INFO  [02:46:43.280] [bbotk] Result of batch 100: 
INFO  [02:46:43.282] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:46:43.282] [bbotk]               6.80787                 3.242113                       0.2161218 
INFO  [02:46:43.282] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:46:43.282] [bbotk]                     1763        0.718 -0.9601277         <NA>   0.9735084 
INFO  [02:46:43.282] [bbotk]                                 uhash 
INFO  [02:46:43.282] [bbotk]  fad81421-2659-4454-bd7b-177f692f9bd1 
DEBUG [02:46:44.282] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.451233e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.451233e-05 0.001727212 
  - best initial criterion value(s) :  534.5569 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -534.56  |proj g|=       6.3162
At iterate     1  f =       -539.3  |proj g|=        3.6307
At iterate     2  f =      -539.39  |proj g|=        3.6959
At iterate     3  f =      -539.42  |proj g|=        3.6761
At iterate     4  f =      -539.42  |proj g|=        3.7264
At iterate     5  f =      -539.42  |proj g|=        3.7014
At iterate     6  f =      -539.42  |proj g|=        3.7008

iterations 6
function evaluations 9
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.70077
final function value -539.424

F = -539.424
final  value -539.424217 
converged
 
INFO  [02:46:44.286] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:46:44.345] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:46:44.353] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:46:48.559] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:46:53.249] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:46:58.519] [mlr3]  Finished benchmark 
INFO  [02:46:58.592] [bbotk] Result of batch 101: 
INFO  [02:46:58.594] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:46:58.594] [bbotk]               2.64364                 8.426112                       0.1105067 
INFO  [02:46:58.594] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:46:58.594] [bbotk]                     1565        0.739 -0.9641849         <NA>   0.9520647 
INFO  [02:46:58.594] [bbotk]                                 uhash 
INFO  [02:46:58.594] [bbotk]  88321ef9-4512-4b44-8c4b-2b12eb65c1af 
DEBUG [02:46:59.899] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.458794e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.458794e-05 0.001733027 
  - best initial criterion value(s) :  503.4749 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -503.47  |proj g|=       4.4995
At iterate     1  f =      -521.49  |proj g|=        7.5053
At iterate     2  f =      -522.63  |proj g|=        7.4045
At iterate     3  f =      -524.83  |proj g|=        6.8718
At iterate     4  f =      -526.41  |proj g|=        5.9683
At iterate     5  f =      -527.67  |proj g|=        5.4444
At iterate     6  f =      -528.64  |proj g|=        4.7491
At iterate     7  f =      -528.96  |proj g|=        4.9739
At iterate     8  f =      -528.97  |proj g|=        4.9247
At iterate     9  f =      -528.97  |proj g|=        4.9281
At iterate    10  f =      -528.97  |proj g|=        4.9281
At iterate    11  f =      -528.97  |proj g|=        4.9279
At iterate    12  f =      -528.97  |proj g|=        4.9278
At iterate    13  f =      -528.98  |proj g|=        4.9267
At iterate    14  f =      -528.99  |proj g|=        4.9182
At iterate    15  f =      -529.02  |proj g|=         4.887
At iterate    16  f =      -529.08  |proj g|=        4.8164
At iterate    17  f =      -529.23  |proj g|=         4.696
At iterate    18  f =      -529.57  |proj g|=        4.4103
At iterate    19  f =      -529.67  |proj g|=        4.4604
At iterate    20  f =      -530.45  |proj g|=        4.1282
At iterate    21  f =      -533.88  |proj g|=        3.1731
At iterate    22  f =      -537.35  |proj g|=        3.8548
At iterate    23  f =      -540.79  |proj g|=        2.6839
At iterate    24  f =      -543.02  |proj g|=        2.8628
At iterate    25  f =      -543.13  |proj g|=         2.776
At iterate    26  f =      -543.23  |proj g|=        3.0185
At iterate    27  f =      -543.25  |proj g|=        2.9581
At iterate    28  f =      -543.25  |proj g|=        2.9564
At iterate    29  f =      -543.25  |proj g|=         2.951
At iterate    30  f =      -543.25  |proj g|=        2.9512

iterations 30
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.9512
final function value -543.248

F = -543.248
final  value -543.247510 
converged
 
INFO  [02:46:59.903] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:46:59.960] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:46:59.968] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:47:02.631] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:47:05.465] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:47:08.120] [mlr3]  Finished benchmark 
INFO  [02:47:08.193] [bbotk] Result of batch 102: 
INFO  [02:47:08.195] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:47:08.195] [bbotk]              5.832251                 2.606451                      0.01949599 
INFO  [02:47:08.195] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:47:08.195] [bbotk]                      922          0.9 -0.9640438         <NA>   0.9316585 
INFO  [02:47:08.195] [bbotk]                                 uhash 
INFO  [02:47:08.195] [bbotk]  97b52c9f-aff2-48b4-86f3-8083944c0bc1 
DEBUG [02:47:09.331] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.545038e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.545038e-05 0.001835555 
  - best initial criterion value(s) :  495.199 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -495.2  |proj g|=       2.7599
At iterate     1  f =      -506.06  |proj g|=        4.4929
At iterate     2  f =      -516.01  |proj g|=        3.6329
At iterate     3  f =      -517.62  |proj g|=        3.2574
At iterate     4  f =      -520.09  |proj g|=        3.1745
At iterate     5  f =      -522.99  |proj g|=        3.3477
At iterate     6  f =      -523.72  |proj g|=        3.6074
At iterate     7  f =      -523.72  |proj g|=        3.6041
At iterate     8  f =      -523.72  |proj g|=        3.6046
At iterate     9  f =      -523.72  |proj g|=         3.604
At iterate    10  f =      -523.72  |proj g|=        3.6004
At iterate    11  f =      -523.72  |proj g|=        3.5955
At iterate    12  f =      -523.72  |proj g|=        3.5866
At iterate    13  f =      -523.73  |proj g|=        3.5721
At iterate    14  f =      -523.75  |proj g|=        3.5456
At iterate    15  f =       -523.8  |proj g|=        3.4982
At iterate    16  f =      -523.94  |proj g|=         3.409
At iterate    17  f =      -524.26  |proj g|=        3.2508
At iterate    18  f =      -524.81  |proj g|=        3.0388
At iterate    19  f =      -524.88  |proj g|=         3.139
At iterate    20  f =      -525.13  |proj g|=        2.9417
At iterate    21  f =      -533.87  |proj g|=         1.901
At iterate    22  f =      -534.74  |proj g|=        2.6786
At iterate    23  f =      -534.84  |proj g|=        1.9926
At iterate    24  f =      -534.89  |proj g|=        2.1279
At iterate    25  f =       -534.9  |proj g|=        2.1603
At iterate    26  f =       -534.9  |proj g|=        2.1452
At iterate    27  f =       -534.9  |proj g|=        2.1463

iterations 27
function evaluations 37
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.14629
final function value -534.895

F = -534.895
final  value -534.895211 
converged
 
INFO  [02:47:09.336] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:47:09.392] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:47:09.400] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:47:11.247] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:47:12.621] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:47:14.953] [mlr3]  Finished benchmark 
INFO  [02:47:15.077] [bbotk] Result of batch 103: 
INFO  [02:47:15.080] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:47:15.080] [bbotk]              5.563889                   2.2771                        0.182917 
INFO  [02:47:15.080] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:47:15.080] [bbotk]                      347        0.733 -0.9654706         <NA>   0.9556694 
INFO  [02:47:15.080] [bbotk]                                 uhash 
INFO  [02:47:15.080] [bbotk]  66afbedf-b34d-4a67-bbfe-8c1c4f9f18c7 
DEBUG [02:47:16.173] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.543622e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.543622e-05 0.001823722 
  - best initial criterion value(s) :  517.8395 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -517.84  |proj g|=       4.1362
At iterate     1  f =      -522.83  |proj g|=        5.8698
At iterate     2  f =      -524.06  |proj g|=        5.6746
At iterate     3  f =      -525.31  |proj g|=        4.5146
At iterate     4  f =      -526.39  |proj g|=        4.9329
At iterate     5  f =      -527.42  |proj g|=        4.7344
At iterate     6  f =      -529.17  |proj g|=        3.6543
At iterate     7  f =      -529.35  |proj g|=        3.8562
At iterate     8  f =      -529.36  |proj g|=         3.805
At iterate     9  f =      -529.36  |proj g|=        3.8045
At iterate    10  f =      -529.36  |proj g|=        3.8015
At iterate    11  f =      -529.36  |proj g|=        3.8027
At iterate    12  f =      -529.36  |proj g|=        3.7993
At iterate    13  f =      -529.37  |proj g|=        3.7892
At iterate    14  f =      -529.38  |proj g|=        3.7738
At iterate    15  f =      -529.41  |proj g|=        3.7385
At iterate    16  f =      -529.49  |proj g|=         3.689
At iterate    17  f =      -529.67  |proj g|=        3.4685
At iterate    18  f =      -529.84  |proj g|=        3.4345
At iterate    19  f =       -530.5  |proj g|=        3.3755
At iterate    20  f =      -533.86  |proj g|=         2.794
At iterate    21  f =      -538.41  |proj g|=        2.3398
At iterate    22  f =      -546.87  |proj g|=        1.3268
At iterate    23  f =      -548.15  |proj g|=        1.7126
At iterate    24  f =      -548.17  |proj g|=        1.8104
At iterate    25  f =      -548.17  |proj g|=        1.8329
At iterate    26  f =      -548.17  |proj g|=        1.8333

iterations 26
function evaluations 28
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.8333
final function value -548.167

F = -548.167
final  value -548.166602 
converged
 
INFO  [02:47:16.178] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:47:16.237] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:47:16.245] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:47:18.139] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:47:20.084] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:47:22.740] [mlr3]  Finished benchmark 
INFO  [02:47:22.845] [bbotk] Result of batch 104: 
INFO  [02:47:22.847] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:47:22.847] [bbotk]               2.20138                 2.293439                      0.02936738 
INFO  [02:47:22.847] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:47:22.847] [bbotk]                      639        0.733 -0.9643423         <NA>   0.9009869 
INFO  [02:47:22.847] [bbotk]                                 uhash 
INFO  [02:47:22.847] [bbotk]  cd6be081-af41-4653-883c-1d13f6f98557 
DEBUG [02:47:23.910] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.857578e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.857578e-05 0.002248206 
  - best initial criterion value(s) :  466.6361 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -466.64  |proj g|=       5.9988
At iterate     1  f =      -496.12  |proj g|=        9.5322
At iterate     2  f =      -502.15  |proj g|=        8.0329
At iterate     3  f =      -507.96  |proj g|=        2.6833
At iterate     4  f =         -510  |proj g|=        4.6814
At iterate     5  f =      -513.09  |proj g|=        4.2387
At iterate     6  f =      -521.44  |proj g|=        3.3472
At iterate     7  f =      -522.37  |proj g|=        3.6931
At iterate     8  f =      -523.24  |proj g|=        4.2511
At iterate     9  f =      -523.34  |proj g|=        4.4354
At iterate    10  f =      -523.35  |proj g|=        4.4952
At iterate    11  f =      -523.35  |proj g|=        4.5017
At iterate    12  f =      -523.35  |proj g|=        4.5019

iterations 12
function evaluations 15
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.50194
final function value -523.345

F = -523.345
final  value -523.345499 
converged
 
INFO  [02:47:23.914] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:47:23.976] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:47:23.984] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:47:30.176] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:47:34.311] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:47:38.931] [mlr3]  Finished benchmark 
INFO  [02:47:38.998] [bbotk] Result of batch 105: 
INFO  [02:47:39.000] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:47:39.000] [bbotk]              8.724073                 7.855664                       0.0898389 
INFO  [02:47:39.000] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:47:39.000] [bbotk]                     2020         0.76 -0.9550548         <NA>   0.9692555 
INFO  [02:47:39.000] [bbotk]                                 uhash 
INFO  [02:47:39.000] [bbotk]  e36028e8-96a9-4791-b11c-ef85b8870265 
DEBUG [02:47:40.298] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.844268e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.844268e-05 0.002227875 
  - best initial criterion value(s) :  514.2483 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -514.25  |proj g|=       5.6707
At iterate     1  f =      -522.78  |proj g|=        2.8486
At iterate     2  f =      -529.03  |proj g|=        2.8628
At iterate     3  f =      -539.33  |proj g|=        2.7091
At iterate     4  f =         -540  |proj g|=        2.6303
At iterate     5  f =      -540.96  |proj g|=        2.6595
At iterate     6  f =      -542.58  |proj g|=         2.818
At iterate     7  f =      -542.78  |proj g|=        2.8866
At iterate     8  f =      -542.82  |proj g|=        2.9239
At iterate     9  f =      -542.82  |proj g|=        2.9341
At iterate    10  f =      -542.82  |proj g|=         2.936
At iterate    11  f =      -542.82  |proj g|=        2.9361
At iterate    12  f =      -542.82  |proj g|=        2.9342
At iterate    13  f =      -542.82  |proj g|=        2.9329
At iterate    14  f =      -542.83  |proj g|=        2.9279
At iterate    15  f =      -542.84  |proj g|=        2.9208
At iterate    16  f =      -542.87  |proj g|=        2.9068
At iterate    17  f =      -542.94  |proj g|=        2.8843
At iterate    18  f =      -543.12  |proj g|=        2.8505
At iterate    19  f =       -543.5  |proj g|=         2.813
At iterate    20  f =      -544.04  |proj g|=        2.7221
At iterate    21  f =      -544.78  |proj g|=        2.7712
At iterate    22  f =      -545.19  |proj g|=        2.6854
At iterate    23  f =      -547.52  |proj g|=        2.0082
At iterate    24  f =      -547.88  |proj g|=        2.2154
At iterate    25  f =         -548  |proj g|=        2.1865
At iterate    26  f =         -548  |proj g|=        2.1549
At iterate    27  f =         -548  |proj g|=        2.1624
At iterate    28  f =         -548  |proj g|=        2.1622

iterations 28
function evaluations 33
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.16222
final function value -548.001

F = -548.001
final  value -548.000562 
converged
 
INFO  [02:47:40.303] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:47:40.360] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:47:40.366] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:47:41.815] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:47:43.282] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:47:44.757] [mlr3]  Finished benchmark 
INFO  [02:47:44.835] [bbotk] Result of batch 106: 
INFO  [02:47:44.837] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:47:44.837] [bbotk]              7.494112                  5.21626                      0.09001407 
INFO  [02:47:44.837] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:47:44.837] [bbotk]                      509        0.858 -0.9597975         <NA>   0.9532599 
INFO  [02:47:44.837] [bbotk]                                 uhash 
INFO  [02:47:44.837] [bbotk]  88f8f316-cbab-499d-bc0f-dba4564e1a53 
DEBUG [02:47:46.292] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.844091e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.844091e-05 0.002228098 
  - best initial criterion value(s) :  523.7565 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -523.76  |proj g|=       2.3496
At iterate     1  f =      -527.25  |proj g|=        6.5723
At iterate     2  f =      -531.05  |proj g|=         5.377
At iterate     3  f =      -533.15  |proj g|=        3.7651
At iterate     4  f =      -533.72  |proj g|=        2.4813
At iterate     5  f =      -534.23  |proj g|=        3.0375
At iterate     6  f =      -534.23  |proj g|=        2.9183
At iterate     7  f =      -534.23  |proj g|=        2.9072
At iterate     8  f =      -534.23  |proj g|=         2.907
At iterate     9  f =      -534.23  |proj g|=        2.9081
At iterate    10  f =      -534.23  |proj g|=        2.9127
At iterate    11  f =      -534.23  |proj g|=        2.9187
At iterate    12  f =      -534.23  |proj g|=        2.9289
At iterate    13  f =      -534.23  |proj g|=        2.9444
At iterate    14  f =      -534.23  |proj g|=        2.9708
At iterate    15  f =      -534.24  |proj g|=        3.0087
At iterate    16  f =      -534.24  |proj g|=        3.0554
At iterate    17  f =      -534.25  |proj g|=        3.1193
At iterate    18  f =      -534.28  |proj g|=        3.1459
At iterate    19  f =      -534.32  |proj g|=        3.3456
At iterate    20  f =      -534.41  |proj g|=         3.412
At iterate    21  f =      -534.93  |proj g|=        4.0017
At iterate    22  f =      -535.83  |proj g|=        4.1749
At iterate    23  f =      -537.95  |proj g|=        4.6133
At iterate    24  f =      -538.43  |proj g|=        7.3309
At iterate    25  f =      -542.34  |proj g|=        5.5594
At iterate    26  f =      -543.66  |proj g|=        4.0831
At iterate    27  f =      -544.75  |proj g|=        3.1816
At iterate    28  f =      -545.32  |proj g|=        3.5902
At iterate    29  f =      -545.41  |proj g|=        3.5637
At iterate    30  f =      -545.41  |proj g|=        3.5147
At iterate    31  f =      -545.41  |proj g|=        3.5248
At iterate    32  f =      -545.41  |proj g|=        3.5238

iterations 32
function evaluations 37
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 3.52381
final function value -545.414

F = -545.414
final  value -545.414134 
converged
 
INFO  [02:47:46.296] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:47:46.383] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:47:46.391] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:47:56.474] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:48:06.410] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:48:16.112] [mlr3]  Finished benchmark 
INFO  [02:48:16.198] [bbotk] Result of batch 107: 
INFO  [02:48:16.200] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:48:16.200] [bbotk]              9.711815                 8.833421                       0.2245312 
INFO  [02:48:16.200] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:48:16.200] [bbotk]                     4644        0.729 -0.9633071         <NA>   0.9764077 
INFO  [02:48:16.200] [bbotk]                                 uhash 
INFO  [02:48:16.200] [bbotk]  57ffc3ff-ec2e-4c9c-aad9-27e1b135c506 
DEBUG [02:48:17.443] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.837457e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.837457e-05 0.002227455 
  - best initial criterion value(s) :  503.1217 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -503.12  |proj g|=       3.1569
At iterate     1  f =      -517.07  |proj g|=        1.3521
At iterate     2  f =      -528.91  |proj g|=         2.675
At iterate     3  f =      -536.32  |proj g|=        3.4302
At iterate     4  f =      -537.51  |proj g|=        3.3442
At iterate     5  f =      -540.89  |proj g|=        3.1165
At iterate     6  f =      -542.71  |proj g|=        2.7472
At iterate     7  f =      -542.96  |proj g|=        2.6193
At iterate     8  f =      -542.97  |proj g|=        2.5666
At iterate     9  f =      -542.97  |proj g|=        2.5802
At iterate    10  f =      -542.97  |proj g|=        2.5801

iterations 10
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.58012
final function value -542.97

F = -542.97
final  value -542.970118 
converged
 
INFO  [02:48:17.447] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:48:17.504] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:48:17.511] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:48:20.865] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:48:24.350] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:48:27.795] [mlr3]  Finished benchmark 
INFO  [02:48:27.864] [bbotk] Result of batch 108: 
INFO  [02:48:27.866] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:48:27.866] [bbotk]              2.626361                 8.313686                       0.3071141 
INFO  [02:48:27.866] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:48:27.866] [bbotk]                     1700        0.733 -0.9598464         <NA>    0.963745 
INFO  [02:48:27.866] [bbotk]                                 uhash 
INFO  [02:48:27.866] [bbotk]  1bb648fd-9101-44c1-bb59-cfb600095d92 
DEBUG [02:48:29.007] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.824801e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.824801e-05 0.002205996 
  - best initial criterion value(s) :  487.2952 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -487.3  |proj g|=       8.7496
At iterate     1  f =      -511.43  |proj g|=        4.7479
At iterate     2  f =      -523.99  |proj g|=        5.6777
At iterate     3  f =      -526.33  |proj g|=        5.0999
At iterate     4  f =      -528.35  |proj g|=        4.1061
At iterate     5  f =      -528.61  |proj g|=        3.8464
At iterate     6  f =      -528.82  |proj g|=        3.7058
At iterate     7  f =      -529.17  |proj g|=        4.0226
At iterate     8  f =      -529.21  |proj g|=        3.8795
At iterate     9  f =      -529.22  |proj g|=        3.8528
At iterate    10  f =      -529.22  |proj g|=        3.8531
At iterate    11  f =      -529.22  |proj g|=        3.8546
At iterate    12  f =      -529.22  |proj g|=        3.8564
At iterate    13  f =      -529.22  |proj g|=        3.8583
At iterate    14  f =      -529.22  |proj g|=        3.8608
At iterate    15  f =      -529.22  |proj g|=        3.8617
At iterate    16  f =      -529.23  |proj g|=         3.854
At iterate    17  f =      -529.24  |proj g|=        3.8487
At iterate    18  f =      -529.25  |proj g|=        3.8845
At iterate    19  f =      -529.26  |proj g|=        3.7185
At iterate    20  f =      -529.28  |proj g|=        3.7573
At iterate    21  f =      -543.82  |proj g|=        3.2222
At iterate    22  f =      -560.59  |proj g|=         2.806
At iterate    23  f =         -561  |proj g|=        2.3797
At iterate    24  f =      -561.22  |proj g|=         1.892
At iterate    25  f =      -561.23  |proj g|=        2.0461
At iterate    26  f =      -561.23  |proj g|=        2.0202
At iterate    27  f =      -561.23  |proj g|=        2.0189
At iterate    28  f =      -561.23  |proj g|=        2.0189

iterations 28
function evaluations 34
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.01892
final function value -561.233

F = -561.233
final  value -561.232593 
converged
 
INFO  [02:48:29.011] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:48:29.066] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:48:29.073] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:48:34.009] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:48:38.861] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:48:43.662] [mlr3]  Finished benchmark 
INFO  [02:48:43.731] [bbotk] Result of batch 109: 
INFO  [02:48:43.733] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:48:43.733] [bbotk]              5.651706                 7.141582                       0.3085188 
INFO  [02:48:43.733] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:48:43.733] [bbotk]                     2460        0.736 -0.9606767         <NA>    0.976021 
INFO  [02:48:43.733] [bbotk]                                 uhash 
INFO  [02:48:43.733] [bbotk]  9c738853-008f-49b9-a0a9-eafcb90bd1ce 
DEBUG [02:48:44.933] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.817812e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.817812e-05 0.002202026 
  - best initial criterion value(s) :  512.9332 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -512.93  |proj g|=       2.7355
At iterate     1  f =      -531.39  |proj g|=        3.2515
At iterate     2  f =      -533.38  |proj g|=         3.153
At iterate     3  f =      -537.27  |proj g|=        2.7818
At iterate     4  f =      -538.37  |proj g|=        2.4446
At iterate     5  f =      -541.16  |proj g|=        2.5765
At iterate     6  f =      -544.05  |proj g|=        2.5572
At iterate     7  f =      -544.14  |proj g|=        2.6092
At iterate     8  f =       -544.2  |proj g|=        2.5753
At iterate     9  f =      -544.24  |proj g|=        2.5912
At iterate    10  f =      -544.24  |proj g|=        2.5893
At iterate    11  f =      -544.24  |proj g|=        2.5888
At iterate    12  f =      -544.24  |proj g|=        2.5885
At iterate    13  f =      -544.24  |proj g|=        2.5887
At iterate    14  f =      -544.24  |proj g|=        2.5838
At iterate    15  f =      -544.24  |proj g|=        2.5858
At iterate    16  f =      -544.25  |proj g|=          2.59
At iterate    17  f =      -544.25  |proj g|=        2.5957
At iterate    18  f =      -544.27  |proj g|=        2.6043
At iterate    19  f =      -544.31  |proj g|=        2.6149
At iterate    20  f =       -544.4  |proj g|=        2.6248
At iterate    21  f =      -544.63  |proj g|=        2.6227
At iterate    22  f =      -545.13  |proj g|=         2.578
At iterate    23  f =      -545.94  |proj g|=        2.4476
At iterate    24  f =      -546.16  |proj g|=        2.4002
At iterate    25  f =      -546.48  |proj g|=        2.3067
At iterate    26  f =      -548.02  |proj g|=        2.0239
At iterate    27  f =      -548.27  |proj g|=        2.0096
At iterate    28  f =      -548.31  |proj g|=        2.0012
At iterate    29  f =      -548.31  |proj g|=        2.0038
At iterate    30  f =      -548.31  |proj g|=        2.0039

iterations 30
function evaluations 39
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.00392
final function value -548.314

F = -548.314
final  value -548.314237 
converged
 
INFO  [02:48:44.937] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:48:44.992] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:48:44.999] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:48:49.670] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:48:56.542] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:49:01.956] [mlr3]  Finished benchmark 
INFO  [02:49:02.024] [bbotk] Result of batch 110: 
INFO  [02:49:02.025] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:49:02.025] [bbotk]              7.046372                 2.879808                       0.4794665 
INFO  [02:49:02.025] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:49:02.025] [bbotk]                     2016        0.743 -0.9638002         <NA>   0.9775552 
INFO  [02:49:02.025] [bbotk]                                 uhash 
INFO  [02:49:02.025] [bbotk]  6a4cfe99-4e83-4c75-9318-a4d387e17eac 
DEBUG [02:49:03.189] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.813006e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.813006e-05 0.002188686 
  - best initial criterion value(s) :  475.115 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -475.11  |proj g|=       2.9599
At iterate     1  f =         -495  |proj g|=        13.644
At iterate     2  f =       -504.9  |proj g|=        13.478
At iterate     3  f =      -520.43  |proj g|=        7.8712
At iterate     4  f =      -522.71  |proj g|=        2.6344
At iterate     5  f =      -526.56  |proj g|=        1.1061
At iterate     6  f =      -534.31  |proj g|=        1.7843
At iterate     7  f =      -536.21  |proj g|=       0.76555
At iterate     8  f =      -536.67  |proj g|=       0.86155
At iterate     9  f =      -536.74  |proj g|=        1.4501
At iterate    10  f =      -536.75  |proj g|=        1.5877
At iterate    11  f =      -536.75  |proj g|=        1.6023
At iterate    12  f =      -536.75  |proj g|=        1.6249
At iterate    13  f =      -536.75  |proj g|=        1.6613
At iterate    14  f =      -536.75  |proj g|=        1.7198
At iterate    15  f =      -536.75  |proj g|=        1.8142
At iterate    16  f =      -536.77  |proj g|=        1.9657
At iterate    17  f =       -536.8  |proj g|=        2.2079
At iterate    18  f =       -536.9  |proj g|=        2.5941
At iterate    19  f =      -537.14  |proj g|=        3.1893
At iterate    20  f =      -537.77  |proj g|=        4.0204
At iterate    21  f =      -539.17  |proj g|=         4.837
At iterate    22  f =      -542.37  |proj g|=       0.34608
At iterate    23  f =      -543.03  |proj g|=        2.2481
At iterate    24  f =      -543.05  |proj g|=        2.0203
At iterate    25  f =      -543.05  |proj g|=        1.8951
At iterate    26  f =      -543.05  |proj g|=        1.8956

iterations 26
function evaluations 29
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.89555
final function value -543.048

F = -543.048
final  value -543.047872 
converged
 
INFO  [02:49:03.193] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:49:03.251] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:49:03.258] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:49:13.573] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:49:26.181] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:49:36.189] [mlr3]  Finished benchmark 
INFO  [02:49:36.256] [bbotk] Result of batch 111: 
INFO  [02:49:36.258] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:49:36.258] [bbotk]              4.690478                 4.706498                       0.2010609 
INFO  [02:49:36.258] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:49:36.258] [bbotk]                     3996        0.776 -0.9633008         <NA>   0.9756125 
INFO  [02:49:36.258] [bbotk]                                 uhash 
INFO  [02:49:36.258] [bbotk]  f061736e-f826-4cd7-becf-af8f1fd391ed 
DEBUG [02:49:37.700] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.805502e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.805502e-05 0.002186803 
  - best initial criterion value(s) :  540.78 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -540.78  |proj g|=       2.3603
At iterate     1  f =      -545.42  |proj g|=        6.8539
At iterate     2  f =      -545.83  |proj g|=        5.6507
At iterate     3  f =      -546.91  |proj g|=        3.2615
At iterate     4  f =      -548.03  |proj g|=         2.015
At iterate     5  f =      -548.89  |proj g|=        5.2102
At iterate     6  f =      -549.86  |proj g|=        3.5302
At iterate     7  f =      -550.15  |proj g|=        3.0537
At iterate     8  f =       -550.6  |proj g|=        2.8752
At iterate     9  f =      -552.09  |proj g|=         2.532
At iterate    10  f =      -553.25  |proj g|=        2.3106
At iterate    11  f =      -553.87  |proj g|=        1.8936
At iterate    12  f =      -555.92  |proj g|=        2.4557
At iterate    13  f =      -556.86  |proj g|=        2.9197
At iterate    14  f =      -556.94  |proj g|=        2.9304
At iterate    15  f =      -557.35  |proj g|=        3.2705
At iterate    16  f =      -557.35  |proj g|=        3.2662
At iterate    17  f =      -557.36  |proj g|=        3.2217
At iterate    18  f =      -557.36  |proj g|=        3.2229
At iterate    19  f =      -557.36  |proj g|=        3.2228
At iterate    20  f =      -557.36  |proj g|=        3.2222
At iterate    21  f =      -557.36  |proj g|=         3.221
At iterate    22  f =      -557.36  |proj g|=        3.2184
At iterate    23  f =      -557.36  |proj g|=         3.202
At iterate    24  f =      -557.37  |proj g|=        3.2143
At iterate    25  f =      -557.37  |proj g|=        3.1909
At iterate    26  f =      -557.39  |proj g|=        3.1287
At iterate    27  f =       -557.4  |proj g|=        3.0923
At iterate    28  f =       -557.4  |proj g|=        3.0931
At iterate    29  f =      -557.41  |proj g|=           3.1
At iterate    30  f =      -557.41  |proj g|=        3.1037
At iterate    31  f =      -557.41  |proj g|=        3.1199
At iterate    32  f =      -557.41  |proj g|=        3.1139
At iterate    33  f =      -557.41  |proj g|=        3.1074
At iterate    34  f =      -557.41  |proj g|=        3.1043
At iterate    35  f =      -557.41  |proj g|=        3.1095
At iterate    36  f =      -557.41  |proj g|=        3.1205
At iterate    37  f =      -557.41  |proj g|=         3.164
At iterate    38  f =      -557.41  |proj g|=        3.1441
At iterate    39  f =      -557.41  |proj g|=         3.142
At iterate    40  f =      -557.41  |proj g|=        3.1267
At iterate    41  f =      -557.42  |proj g|=        3.1106
At iterate    42  f =      -557.42  |proj g|=         3.091
At iterate    43  f =      -557.43  |proj g|=        3.0781
At iterate    44  f =      -557.45  |proj g|=        3.0764
At iterate    45  f =      -557.47  |proj g|=        3.0205
At iterate    46  f =      -557.47  |proj g|=        3.0375
At iterate    47  f =      -557.47  |proj g|=        3.0607
At iterate    48  f =      -557.47  |proj g|=        3.0717
At iterate    49  f =      -557.48  |proj g|=        3.0784
At iterate    50  f =       -557.5  |proj g|=        3.0568
At iterate    51  f =      -557.63  |proj g|=        3.0334
At iterate    52  f =      -557.94  |proj g|=        3.0483
At iterate    53  f =      -558.29  |proj g|=        3.1915
At iterate    54  f =      -559.19  |proj g|=        3.3329
At iterate    55  f =       -560.3  |proj g|=        3.3628
At iterate    56  f =      -564.13  |proj g|=        3.0592
At iterate    57  f =      -566.21  |proj g|=        2.8008
At iterate    58  f =       -574.3  |proj g|=       0.64691
At iterate    59  f =         -575  |proj g|=       0.62778
At iterate    60  f =         -575  |proj g|=       0.11418
At iterate    61  f =         -575  |proj g|=      0.005383
At iterate    62  f =         -575  |proj g|=      0.005383

iterations 62
function evaluations 78
segments explored during Cauchy searches 64
BFGS updates skipped 0
active bounds at final generalized Cauchy point 3
norm of the final projected gradient 0.00538303
final function value -575.002

F = -575.002
final  value -575.002216 
converged
 
INFO  [02:49:37.704] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:49:37.758] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:49:37.765] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:49:50.477] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:50:04.588] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:50:18.329] [mlr3]  Finished benchmark 
INFO  [02:50:18.399] [bbotk] Result of batch 112: 
INFO  [02:50:18.400] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:50:18.400] [bbotk]              4.254423                 6.181935                       0.1110323 
INFO  [02:50:18.400] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:50:18.400] [bbotk]                     4383        0.768 -0.9474512         <NA>   0.9726231 
INFO  [02:50:18.400] [bbotk]                                 uhash 
INFO  [02:50:18.400] [bbotk]  932a8df1-f2e3-4255-8b2e-a2133fe26d05 
DEBUG [02:50:19.910] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.795035e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.795035e-05 0.00218 
  - best initial criterion value(s) :  539.7952 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -539.8  |proj g|=       14.079
At iterate     1  f =      -559.74  |proj g|=        1.7325
At iterate     2  f =      -561.08  |proj g|=        4.5356
At iterate     3  f =      -563.13  |proj g|=         3.932
At iterate     4  f =      -564.53  |proj g|=        2.6889
At iterate     5  f =      -564.67  |proj g|=        2.2308
At iterate     6  f =      -564.82  |proj g|=        2.2527
At iterate     7  f =      -564.85  |proj g|=        2.2957
At iterate     8  f =      -564.88  |proj g|=        2.2965
At iterate     9  f =      -564.88  |proj g|=        2.2957
At iterate    10  f =      -564.88  |proj g|=        2.2956
At iterate    11  f =      -564.88  |proj g|=        2.2953
At iterate    12  f =      -564.89  |proj g|=        2.2948
At iterate    13  f =      -564.89  |proj g|=        2.2912
At iterate    14  f =      -564.91  |proj g|=        2.2884
At iterate    15  f =      -564.95  |proj g|=        2.2892
At iterate    16  f =      -565.05  |proj g|=        2.2959
At iterate    17  f =       -565.3  |proj g|=        2.3219
At iterate    18  f =      -565.85  |proj g|=        2.3811
At iterate    19  f =         -566  |proj g|=        2.3304
At iterate    20  f =      -567.22  |proj g|=        2.4323
At iterate    21  f =      -571.48  |proj g|=         2.544
At iterate    22  f =      -579.67  |proj g|=        2.4671
At iterate    23  f =      -579.96  |proj g|=        2.4409
At iterate    24  f =      -582.67  |proj g|=        2.3522
At iterate    25  f =      -582.79  |proj g|=        2.7551
At iterate    26  f =      -584.72  |proj g|=         2.553
At iterate    27  f =      -584.72  |proj g|=         2.551
At iterate    28  f =      -584.72  |proj g|=        2.5496
At iterate    29  f =      -584.72  |proj g|=        2.5508
At iterate    30  f =      -584.72  |proj g|=        2.5497
At iterate    31  f =      -584.75  |proj g|=        2.5649
At iterate    32  f =      -584.89  |proj g|=         2.582
At iterate    33  f =      -585.06  |proj g|=        2.5662
At iterate    34  f =      -585.13  |proj g|=        2.5253
At iterate    35  f =      -585.15  |proj g|=        2.4924
At iterate    36  f =      -585.15  |proj g|=          2.48
At iterate    37  f =      -585.15  |proj g|=        2.4795
At iterate    38  f =      -585.15  |proj g|=        2.4798
At iterate    39  f =      -585.15  |proj g|=        2.4797

iterations 39
function evaluations 53
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.47973
final function value -585.153

F = -585.153
final  value -585.152799 
converged
 
INFO  [02:50:19.914] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:50:19.970] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:50:19.978] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:50:27.074] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:50:33.355] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:50:40.609] [mlr3]  Finished benchmark 
INFO  [02:50:40.714] [bbotk] Result of batch 113: 
INFO  [02:50:40.716] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:50:40.716] [bbotk]              9.082396                 8.399302                       0.3314089 
INFO  [02:50:40.716] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:50:40.716] [bbotk]                     2425         0.96 -0.9533753         <NA>   0.9775028 
INFO  [02:50:40.716] [bbotk]                                 uhash 
INFO  [02:50:40.716] [bbotk]  919e2aca-6c6a-4b89-a140-1266edf77311 
DEBUG [02:50:41.949] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.790151e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80581 15.77119 0.9806764 9590 
  - variance bounds :  1.790151e-05 0.002176891 
  - best initial criterion value(s) :  516.993 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -516.99  |proj g|=       4.2051
At iterate     1  f =      -535.18  |proj g|=         4.781
At iterate     2  f =      -569.71  |proj g|=        4.0549
At iterate     3  f =      -569.94  |proj g|=        4.2143
At iterate     4  f =      -570.16  |proj g|=        4.5279
At iterate     5  f =      -570.18  |proj g|=        4.4924
At iterate     6  f =      -570.23  |proj g|=        4.2129
At iterate     7  f =      -570.23  |proj g|=        4.2646
At iterate     8  f =      -570.23  |proj g|=        4.2584
At iterate     9  f =      -570.23  |proj g|=        4.2568
At iterate    10  f =      -570.23  |proj g|=         4.255
At iterate    11  f =      -570.23  |proj g|=        4.2495
At iterate    12  f =      -570.23  |proj g|=        4.2422
At iterate    13  f =      -570.23  |proj g|=        4.2293
At iterate    14  f =      -570.23  |proj g|=        4.2107
At iterate    15  f =      -570.24  |proj g|=        4.1853
At iterate    16  f =      -570.25  |proj g|=        4.1425
At iterate    17  f =      -570.27  |proj g|=        4.1005
At iterate    18  f =      -570.28  |proj g|=        4.0242
At iterate    19  f =      -570.33  |proj g|=        3.9659
At iterate    20  f =      -570.99  |proj g|=        3.7392
At iterate    21  f =      -590.09  |proj g|=        2.0652
At iterate    22  f =      -595.43  |proj g|=        1.1975
At iterate    23  f =      -596.84  |proj g|=       0.62411
At iterate    24  f =      -596.87  |proj g|=       0.62411
At iterate    25  f =      -596.87  |proj g|=       0.62411
At iterate    26  f =      -596.87  |proj g|=       0.62411
At iterate    27  f =      -596.87  |proj g|=       0.62411
At iterate    28  f =      -596.87  |proj g|=       0.62411
At iterate    29  f =      -596.88  |proj g|=       0.62319
At iterate    30  f =      -596.92  |proj g|=       0.61497
At iterate    31  f =      -596.94  |proj g|=       0.60917
At iterate    32  f =      -596.94  |proj g|=       0.26978
At iterate    33  f =      -596.94  |proj g|=       0.37347
At iterate    34  f =      -596.94  |proj g|=       0.37333
At iterate    35  f =      -596.94  |proj g|=       0.37331

iterations 35
function evaluations 44
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.373308
final function value -596.939

F = -596.939
final  value -596.939077 
converged
 
INFO  [02:50:41.954] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:50:42.008] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:50:42.015] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:50:47.640] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:50:53.880] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:50:59.950] [mlr3]  Finished benchmark 
INFO  [02:51:00.021] [bbotk] Result of batch 114: 
INFO  [02:51:00.023] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:51:00.023] [bbotk]              2.045562                 8.090536                       0.2307454 
INFO  [02:51:00.023] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:51:00.023] [bbotk]                     2205        0.753 -0.9538662         <NA>   0.9583535 
INFO  [02:51:00.023] [bbotk]                                 uhash 
INFO  [02:51:00.023] [bbotk]  02b7d890-31b5-46f7-b7e8-8356a9588f7f 
DEBUG [02:51:01.260] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.782956e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9806764 9590 
  - variance bounds :  1.782956e-05 0.002164911 
  - best initial criterion value(s) :  527.1864 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -527.19  |proj g|=       5.2554
At iterate     1  f =      -532.62  |proj g|=        8.8338
At iterate     2  f =      -547.75  |proj g|=        6.2011
At iterate     3  f =      -556.56  |proj g|=        4.0688
At iterate     4  f =      -566.99  |proj g|=        3.4175
At iterate     5  f =      -570.72  |proj g|=        3.5992
At iterate     6  f =      -570.77  |proj g|=        3.6426
At iterate     7  f =      -570.79  |proj g|=        3.6344
At iterate     8  f =      -570.79  |proj g|=         3.633
At iterate     9  f =      -570.79  |proj g|=         3.633
At iterate    10  f =      -570.79  |proj g|=        3.6329
At iterate    11  f =      -570.79  |proj g|=        3.6327
At iterate    12  f =      -570.79  |proj g|=        3.6324
At iterate    13  f =      -570.79  |proj g|=        3.6319
At iterate    14  f =      -570.79  |proj g|=        3.6315
At iterate    15  f =      -570.79  |proj g|=        3.6312
At iterate    16  f =      -570.79  |proj g|=         3.631
At iterate    17  f =       -570.8  |proj g|=        3.6313
At iterate    18  f =      -570.81  |proj g|=        3.6292
At iterate    19  f =      -570.83  |proj g|=        3.6413
At iterate    20  f =      -570.87  |proj g|=        3.6308
At iterate    21  f =      -571.03  |proj g|=        3.6055
At iterate    22  f =      -571.56  |proj g|=        3.5335
At iterate    23  f =      -572.67  |proj g|=        3.3968
At iterate    24  f =      -574.85  |proj g|=        3.1486
At iterate    25  f =      -577.52  |proj g|=        2.8841
At iterate    26  f =      -578.92  |proj g|=        2.4518
At iterate    27  f =      -581.92  |proj g|=        2.4953
At iterate    28  f =      -582.17  |proj g|=        2.5087
At iterate    29  f =      -582.25  |proj g|=        2.5163
At iterate    30  f =      -582.26  |proj g|=        2.5102
At iterate    31  f =      -582.27  |proj g|=        2.5034
At iterate    32  f =      -582.27  |proj g|=         2.496
At iterate    33  f =      -582.27  |proj g|=        2.4982
At iterate    34  f =      -582.27  |proj g|=        2.4981
At iterate    35  f =      -582.27  |proj g|=        2.4977

iterations 35
function evaluations 41
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.49771
final function value -582.266

F = -582.266
final  value -582.265781 
converged
 
INFO  [02:51:01.264] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:51:01.321] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:51:01.350] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:51:11.333] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:51:22.382] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:51:33.338] [mlr3]  Finished benchmark 
INFO  [02:51:33.408] [bbotk] Result of batch 115: 
INFO  [02:51:33.410] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:51:33.410] [bbotk]              6.164867                 7.182275                       0.4965897 
INFO  [02:51:33.410] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:51:33.410] [bbotk]                     3753        0.768 -0.9585797         <NA>   0.9791344 
INFO  [02:51:33.410] [bbotk]                                 uhash 
INFO  [02:51:33.410] [bbotk]  6f1c0e30-6dea-4e93-b6f1-825be9c2369b 
DEBUG [02:51:34.646] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.780733e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.780733e-05 0.002170198 
  - best initial criterion value(s) :  493.2931 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -493.29  |proj g|=       2.5451
At iterate     1  f =      -506.19  |proj g|=        5.7135
At iterate     2  f =      -506.66  |proj g|=         5.553
At iterate     3  f =      -507.27  |proj g|=         4.904
At iterate     4  f =      -507.48  |proj g|=         5.076
At iterate     5  f =      -507.97  |proj g|=        5.2148
At iterate     6  f =      -509.98  |proj g|=        5.4179
At iterate     7  f =      -511.75  |proj g|=        5.1795
At iterate     8  f =      -514.08  |proj g|=        4.6646
At iterate     9  f =      -515.63  |proj g|=        4.3271
At iterate    10  f =       -515.7  |proj g|=        4.3449
At iterate    11  f =      -515.72  |proj g|=        4.3494
At iterate    12  f =      -515.72  |proj g|=        4.3394
At iterate    13  f =      -515.72  |proj g|=        4.3435
At iterate    14  f =      -515.72  |proj g|=        4.3405
At iterate    15  f =      -515.72  |proj g|=        4.3355
At iterate    16  f =      -515.72  |proj g|=        4.3222
At iterate    17  f =      -515.73  |proj g|=        4.3027
At iterate    18  f =      -515.76  |proj g|=        4.2662
At iterate    19  f =      -515.82  |proj g|=        4.2009
At iterate    20  f =      -515.99  |proj g|=        4.0819
At iterate    21  f =      -516.39  |proj g|=        3.8684
At iterate    22  f =      -517.47  |proj g|=        3.4535
At iterate    23  f =      -517.72  |proj g|=        3.1337
At iterate    24  f =      -520.74  |proj g|=        2.6815
At iterate    25  f =      -525.17  |proj g|=        1.9125
At iterate    26  f =       -526.1  |proj g|=         2.013
At iterate    27  f =      -526.34  |proj g|=        1.9899
At iterate    28  f =      -526.38  |proj g|=        2.0423
At iterate    29  f =      -526.39  |proj g|=        2.0501
At iterate    30  f =      -526.39  |proj g|=        2.0531
At iterate    31  f =      -526.39  |proj g|=         2.053

iterations 31
function evaluations 40
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.05301
final function value -526.388

F = -526.388
final  value -526.388287 
converged
 
INFO  [02:51:34.650] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:51:34.708] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:51:34.715] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:51:44.762] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:51:55.125] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:52:06.188] [mlr3]  Finished benchmark 
INFO  [02:52:06.258] [bbotk] Result of batch 116: 
INFO  [02:52:06.260] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:52:06.260] [bbotk]              2.075654                 6.235984                       0.1722617 
INFO  [02:52:06.260] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:52:06.260] [bbotk]                     3641        0.769 -0.9699395         <NA>    0.959908 
INFO  [02:52:06.260] [bbotk]                                 uhash 
INFO  [02:52:06.260] [bbotk]  30c75d40-d8ff-4f5b-a79f-cc1f98e394e6 
DEBUG [02:52:07.515] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.772045e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.772045e-05 0.002162756 
  - best initial criterion value(s) :  566.435 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -566.43  |proj g|=       12.877
At iterate     1  f =      -582.22  |proj g|=         2.169
At iterate     2  f =      -587.87  |proj g|=        2.4754
At iterate     3  f =      -589.17  |proj g|=        2.4451
At iterate     4  f =      -589.23  |proj g|=        2.4422
At iterate     5  f =      -589.23  |proj g|=        2.4455
At iterate     6  f =      -589.23  |proj g|=        2.4491
At iterate     7  f =      -589.23  |proj g|=        2.4497
At iterate     8  f =      -589.23  |proj g|=        2.4499
At iterate     9  f =      -589.23  |proj g|=        2.4513
At iterate    10  f =      -589.23  |proj g|=        2.4529
At iterate    11  f =      -589.23  |proj g|=        2.4557
At iterate    12  f =      -589.24  |proj g|=        2.4601
At iterate    13  f =      -589.25  |proj g|=        2.4678
At iterate    14  f =      -589.29  |proj g|=        2.4798
At iterate    15  f =      -589.37  |proj g|=         2.497
At iterate    16  f =       -589.5  |proj g|=        2.5109
At iterate    17  f =      -589.52  |proj g|=        2.5311
At iterate    18  f =      -589.72  |proj g|=        2.5368
At iterate    19  f =      -590.64  |proj g|=         2.552
At iterate    20  f =      -593.58  |proj g|=         2.574
At iterate    21  f =      -597.85  |proj g|=        2.5461
At iterate    22  f =      -600.69  |proj g|=        2.4797
At iterate    23  f =      -600.77  |proj g|=        2.5279
At iterate    24  f =      -602.07  |proj g|=        2.4587
At iterate    25  f =      -602.66  |proj g|=         2.451
At iterate    26  f =      -602.74  |proj g|=        2.4615
At iterate    27  f =      -602.75  |proj g|=        2.4632
At iterate    28  f =      -602.75  |proj g|=        2.4657
At iterate    29  f =      -602.75  |proj g|=         2.468
At iterate    30  f =      -602.75  |proj g|=        2.4671
At iterate    31  f =      -602.75  |proj g|=         2.467

iterations 31
function evaluations 36
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.46703
final function value -602.748

F = -602.748
final  value -602.748313 
converged
 
INFO  [02:52:07.519] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:52:07.574] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:52:07.581] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:52:19.313] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:52:33.583] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:52:42.932] [mlr3]  Finished benchmark 
INFO  [02:52:43.044] [bbotk] Result of batch 117: 
INFO  [02:52:43.047] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:52:43.047] [bbotk]               6.31477                  8.74539                       0.3193701 
INFO  [02:52:43.047] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:52:43.047] [bbotk]                     3147        0.802 -0.9570804         <NA>   0.9773777 
INFO  [02:52:43.047] [bbotk]                                 uhash 
INFO  [02:52:43.047] [bbotk]  f7b38c16-8bc7-4c82-829d-69a776b0f64f 
DEBUG [02:52:44.375] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.76721e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.76721e-05 0.002169173 
  - best initial criterion value(s) :  537.5843 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -537.58  |proj g|=       5.0892
At iterate     1  f =      -544.84  |proj g|=        1.5748
At iterate     2  f =      -545.41  |proj g|=         1.516
At iterate     3  f =      -546.84  |proj g|=        1.5323
At iterate     4  f =      -549.21  |proj g|=        1.9781
At iterate     5  f =      -555.47  |proj g|=        1.3324
At iterate     6  f =       -570.7  |proj g|=        1.5506
At iterate     7  f =      -576.35  |proj g|=        2.5623
At iterate     8  f =       -576.5  |proj g|=        2.6611
At iterate     9  f =      -576.55  |proj g|=        2.7469
At iterate    10  f =      -576.55  |proj g|=        2.7592
At iterate    11  f =      -576.55  |proj g|=        2.7659
At iterate    12  f =      -576.55  |proj g|=        2.7823
At iterate    13  f =      -576.57  |proj g|=        2.8056
At iterate    14  f =       -576.6  |proj g|=         2.846
At iterate    15  f =      -576.68  |proj g|=        2.9111
At iterate    16  f =      -576.85  |proj g|=         2.973
At iterate    17  f =      -577.87  |proj g|=        2.9291
At iterate    18  f =      -579.12  |proj g|=        2.8582
At iterate    19  f =      -581.76  |proj g|=        2.4666
At iterate    20  f =      -581.84  |proj g|=        2.3765
At iterate    21  f =      -581.84  |proj g|=        2.3613
At iterate    22  f =      -581.84  |proj g|=        2.3609
At iterate    23  f =      -581.84  |proj g|=        2.3609

iterations 23
function evaluations 28
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 2.36085
final function value -581.844

F = -581.844
final  value -581.844355 
converged
 
INFO  [02:52:44.380] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:52:44.440] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:52:44.447] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:52:46.335] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:52:48.360] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:52:50.397] [mlr3]  Finished benchmark 
INFO  [02:52:50.469] [bbotk] Result of batch 118: 
INFO  [02:52:50.471] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:52:50.471] [bbotk]              2.317373                 8.991016                      0.06391326 
INFO  [02:52:50.471] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:52:50.471] [bbotk]                      591        0.937 -0.9480549         <NA>    0.919975 
INFO  [02:52:50.471] [bbotk]                                 uhash 
INFO  [02:52:50.471] [bbotk]  cb44d52c-354e-40d5-b27a-a85025c73914 
DEBUG [02:52:51.531] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.904383e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.904383e-05 0.002362922 
  - best initial criterion value(s) :  560.9032 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -560.9  |proj g|=       1.2617
At iterate     1  f =      -561.39  |proj g|=        1.2038
At iterate     2  f =      -561.49  |proj g|=        1.2276
At iterate     3  f =      -561.49  |proj g|=          1.23
At iterate     4  f =      -561.49  |proj g|=        1.2301
At iterate     5  f =      -561.49  |proj g|=        1.2301

iterations 5
function evaluations 8
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.23014
final function value -561.492

F = -561.492
final  value -561.492262 
converged
 
INFO  [02:52:51.535] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:52:51.632] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:52:51.644] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:52:55.518] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:52:59.183] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:53:02.885] [mlr3]  Finished benchmark 
INFO  [02:53:02.957] [bbotk] Result of batch 119: 
INFO  [02:53:02.959] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:53:02.959] [bbotk]              3.470574                 9.648757                       0.3775099 
INFO  [02:53:02.959] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:53:02.959] [bbotk]                     1303        0.785 -0.9657228         <NA>   0.9703485 
INFO  [02:53:02.959] [bbotk]                                 uhash 
INFO  [02:53:02.959] [bbotk]  8c3f3807-d36b-41cd-bb98-05b058d32cc7 
DEBUG [02:53:04.094] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.892444e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.892444e-05 0.00233699 
  - best initial criterion value(s) :  577.3472 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -577.35  |proj g|=       1.0064
At iterate     1  f =      -587.11  |proj g|=        2.3108
At iterate     2  f =      -589.19  |proj g|=        1.9945
At iterate     3  f =      -591.47  |proj g|=        1.4894
At iterate     4  f =      -592.88  |proj g|=       0.99432
At iterate     5  f =      -594.62  |proj g|=       0.37943
At iterate     6  f =      -597.87  |proj g|=       0.33321
At iterate     7  f =      -600.66  |proj g|=        0.5949
At iterate     8  f =      -600.75  |proj g|=       0.34512
At iterate     9  f =      -600.76  |proj g|=       0.72748
At iterate    10  f =      -600.76  |proj g|=        0.7253
At iterate    11  f =      -600.76  |proj g|=       0.72535
At iterate    12  f =      -600.76  |proj g|=       0.72536

iterations 12
function evaluations 18
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.725358
final function value -600.761

F = -600.761
final  value -600.760840 
converged
 
INFO  [02:53:04.098] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:53:04.180] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:53:04.191] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:53:05.846] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:53:07.061] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:53:08.234] [mlr3]  Finished benchmark 
INFO  [02:53:08.306] [bbotk] Result of batch 120: 
INFO  [02:53:08.308] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:53:08.308] [bbotk]              3.649643                 5.764284                       0.2659875 
INFO  [02:53:08.308] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:53:08.308] [bbotk]                      301        0.787 -0.9614502         <NA>   0.9530792 
INFO  [02:53:08.308] [bbotk]                                 uhash 
INFO  [02:53:08.308] [bbotk]  cb0f12cb-1249-4a50-8a6c-cfd522e0d3d4 
DEBUG [02:53:09.714] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.892328e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.892328e-05 0.002331105 
  - best initial criterion value(s) :  608.8328 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -608.83  |proj g|=       1.6166
At iterate     1  f =      -612.82  |proj g|=        2.0081
At iterate     2  f =      -614.52  |proj g|=        1.8957
At iterate     3  f =      -615.78  |proj g|=        1.7967
At iterate     4  f =      -616.73  |proj g|=        1.7725
At iterate     5  f =      -616.74  |proj g|=        1.7517
At iterate     6  f =      -616.74  |proj g|=        1.7572
At iterate     7  f =      -616.74  |proj g|=        1.7571
At iterate     8  f =      -616.74  |proj g|=        1.7565
At iterate     9  f =      -616.74  |proj g|=        1.7558
At iterate    10  f =      -616.74  |proj g|=        1.7555
At iterate    11  f =      -616.74  |proj g|=        1.7542
At iterate    12  f =      -616.74  |proj g|=        1.7517
At iterate    13  f =      -616.74  |proj g|=        1.7475
At iterate    14  f =      -616.75  |proj g|=        1.7392
At iterate    15  f =      -616.76  |proj g|=        1.7229
At iterate    16  f =      -616.78  |proj g|=        1.6864
At iterate    17  f =      -616.78  |proj g|=        1.6825
At iterate    18  f =      -616.84  |proj g|=        1.6102
At iterate    19  f =      -617.17  |proj g|=        1.3325
At iterate    20  f =      -619.04  |proj g|=       0.75292
At iterate    21  f =      -619.76  |proj g|=       0.73368
At iterate    22  f =      -619.97  |proj g|=       0.71831
At iterate    23  f =      -619.97  |proj g|=       0.71823
At iterate    24  f =      -619.98  |proj g|=        0.5019
At iterate    25  f =      -619.98  |proj g|=       0.50713
At iterate    26  f =      -619.98  |proj g|=       0.50801
At iterate    27  f =      -619.98  |proj g|=       0.50917
At iterate    28  f =      -619.98  |proj g|=        0.5121
At iterate    29  f =      -619.98  |proj g|=       0.51283
At iterate    30  f =      -619.98  |proj g|=       0.53095
At iterate    31  f =      -619.98  |proj g|=       0.52507
At iterate    32  f =      -619.98  |proj g|=        0.4939
At iterate    33  f =      -619.99  |proj g|=       0.45298
At iterate    34  f =      -620.01  |proj g|=       0.36736
At iterate    35  f =      -620.04  |proj g|=       0.26901
At iterate    36  f =       -620.1  |proj g|=       0.27216
At iterate    37  f =      -620.18  |proj g|=       0.27296
At iterate    38  f =       -620.2  |proj g|=       0.70824
At iterate    39  f =       -620.2  |proj g|=       0.70761
At iterate    40  f =      -620.21  |proj g|=       0.70638
At iterate    41  f =      -620.21  |proj g|=       0.70465
At iterate    42  f =      -620.21  |proj g|=       0.70369
At iterate    43  f =      -620.21  |proj g|=       0.32833
At iterate    44  f =      -620.21  |proj g|=      0.047047
At iterate    45  f =      -620.21  |proj g|=       0.03079
At iterate    46  f =      -620.21  |proj g|=       0.03079

iterations 46
function evaluations 58
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0307897
final function value -620.212

F = -620.212
final  value -620.211768 
converged
 
INFO  [02:53:09.718] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:53:10.013] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:53:10.021] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:53:22.226] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:53:35.757] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:53:48.743] [mlr3]  Finished benchmark 
INFO  [02:53:48.833] [bbotk] Result of batch 121: 
INFO  [02:53:48.835] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:53:48.835] [bbotk]              9.216591                 2.401306                       0.4636281 
INFO  [02:53:48.835] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:53:48.835] [bbotk]                     4278        0.789 -0.9591508         <NA>   0.9782575 
INFO  [02:53:48.835] [bbotk]                                 uhash 
INFO  [02:53:48.835] [bbotk]  d669a319-cc90-4964-9832-a1f1c7331968 
DEBUG [02:53:49.963] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.888542e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.888542e-05 0.002334812 
  - best initial criterion value(s) :  596.067 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -596.07  |proj g|=       4.1045
At iterate     1  f =      -626.64  |proj g|=        2.5522
At iterate     2  f =      -627.29  |proj g|=        2.6473
At iterate     3  f =      -628.03  |proj g|=        2.6867
At iterate     4  f =      -628.31  |proj g|=        2.7283
At iterate     5  f =      -628.35  |proj g|=        2.7059
At iterate     6  f =      -628.36  |proj g|=        2.6989
At iterate     7  f =      -628.36  |proj g|=        2.6998
At iterate     8  f =      -628.36  |proj g|=        2.6998

iterations 8
function evaluations 10
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.69978
final function value -628.357

F = -628.357
final  value -628.356752 
converged
 
INFO  [02:53:49.968] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:53:50.028] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:53:50.035] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:53:57.848] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:54:06.723] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:54:15.657] [mlr3]  Finished benchmark 
INFO  [02:54:15.744] [bbotk] Result of batch 122: 
INFO  [02:54:15.746] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:54:15.746] [bbotk]              5.234483                 4.915171                       0.1677535 
INFO  [02:54:15.746] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [02:54:15.746] [bbotk]                     3039        0.822 -0.955837         <NA>   0.9741293 
INFO  [02:54:15.746] [bbotk]                                 uhash 
INFO  [02:54:15.746] [bbotk]  2834fcd7-7afa-4a9c-ad3f-a369df08ff4b 
DEBUG [02:54:17.505] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.879626e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.879626e-05 0.002331671 
  - best initial criterion value(s) :  601.0408 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -601.04  |proj g|=       4.6432
At iterate     1  f =      -614.19  |proj g|=        2.0668
At iterate     2  f =       -620.7  |proj g|=        1.6163
At iterate     3  f =      -629.55  |proj g|=       0.80458
At iterate     4  f =      -630.68  |proj g|=       0.85407
At iterate     5  f =      -632.05  |proj g|=       0.89381
At iterate     6  f =      -638.67  |proj g|=        1.1588
At iterate     7  f =      -640.12  |proj g|=        1.3115
At iterate     8  f =      -640.24  |proj g|=        1.3124
At iterate     9  f =      -640.77  |proj g|=        1.4457
At iterate    10  f =      -640.84  |proj g|=        1.4989
At iterate    11  f =      -640.84  |proj g|=        1.5112
At iterate    12  f =      -640.84  |proj g|=        1.5128
At iterate    13  f =      -640.84  |proj g|=        1.5126
At iterate    14  f =      -640.84  |proj g|=        1.5127
At iterate    15  f =      -640.84  |proj g|=        1.5129
At iterate    16  f =      -640.84  |proj g|=        1.5132
At iterate    17  f =      -640.84  |proj g|=        1.5139
At iterate    18  f =      -640.84  |proj g|=        1.5152
At iterate    19  f =      -640.84  |proj g|=        1.5182
At iterate    20  f =      -640.85  |proj g|=        1.5241
At iterate    21  f =      -640.86  |proj g|=        1.5335
At iterate    22  f =      -640.86  |proj g|=        1.5296
At iterate    23  f =      -640.88  |proj g|=        1.5023
At iterate    24  f =      -640.92  |proj g|=        1.4519
At iterate    25  f =         -641  |proj g|=        1.3568
At iterate    26  f =      -641.09  |proj g|=        1.2512
At iterate    27  f =      -641.13  |proj g|=        1.2071
At iterate    28  f =      -641.15  |proj g|=        1.2337
At iterate    29  f =      -641.15  |proj g|=        1.2419
At iterate    30  f =      -641.15  |proj g|=        1.2426
At iterate    31  f =      -641.15  |proj g|=        1.2435
At iterate    32  f =      -641.15  |proj g|=        1.2448
At iterate    33  f =      -641.15  |proj g|=        1.2468
At iterate    34  f =      -641.15  |proj g|=        1.2507
At iterate    35  f =      -641.15  |proj g|=        1.2576
At iterate    36  f =      -641.15  |proj g|=        1.2689
At iterate    37  f =      -641.16  |proj g|=        1.2847
At iterate    38  f =      -641.18  |proj g|=        1.3043
At iterate    39  f =      -641.21  |proj g|=        1.3191
At iterate    40  f =      -641.22  |proj g|=        1.3607
At iterate    41  f =      -641.33  |proj g|=        1.3176
At iterate    42  f =      -641.47  |proj g|=        1.2245
At iterate    43  f =      -641.71  |proj g|=       0.98917
At iterate    44  f =      -641.88  |proj g|=       0.77179
At iterate    45  f =      -641.94  |proj g|=       0.68903
At iterate    46  f =      -641.94  |proj g|=       0.72561
At iterate    47  f =      -641.95  |proj g|=       0.73219
At iterate    48  f =      -641.95  |proj g|=       0.72964
At iterate    49  f =      -641.95  |proj g|=       0.72621
At iterate    50  f =      -641.95  |proj g|=       0.73514
At iterate    51  f =      -641.95  |proj g|=       0.71687
At iterate    52  f =      -641.98  |proj g|=       0.66413
At iterate    53  f =      -642.07  |proj g|=       0.66481
At iterate    54  f =       -642.3  |proj g|=       0.67432
At iterate    55  f =      -642.56  |proj g|=       0.67849
At iterate    56  f =      -643.07  |proj g|=       0.66439
At iterate    57  f =      -643.81  |proj g|=       0.62633
At iterate    58  f =      -643.91  |proj g|=       0.37186
At iterate    59  f =      -643.92  |proj g|=       0.37636
At iterate    60  f =      -643.92  |proj g|=       0.37765
At iterate    61  f =      -643.92  |proj g|=       0.37809
At iterate    62  f =      -643.92  |proj g|=        0.3792
At iterate    63  f =      -643.92  |proj g|=        0.3808
At iterate    64  f =      -643.94  |proj g|=       0.38328
At iterate    65  f =      -643.96  |proj g|=       0.38656
At iterate    66  f =      -643.98  |proj g|=       0.38795
At iterate    67  f =      -644.01  |proj g|=       0.38376
At iterate    68  f =      -644.02  |proj g|=       0.37757
At iterate    69  f =      -644.02  |proj g|=       0.26885
At iterate    70  f =      -644.02  |proj g|=      0.001971
At iterate    71  f =      -644.02  |proj g|=     0.0019703

iterations 71
function evaluations 79
segments explored during Cauchy searches 75
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00197035
final function value -644.02

F = -644.02
final  value -644.020401 
converged
 
INFO  [02:54:17.509] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:54:17.568] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:54:17.575] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:54:23.711] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:54:32.875] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:54:39.293] [mlr3]  Finished benchmark 
INFO  [02:54:39.378] [bbotk] Result of batch 123: 
INFO  [02:54:39.380] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:54:39.380] [bbotk]              9.304431                 5.792165                        0.376363 
INFO  [02:54:39.380] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:54:39.380] [bbotk]                     1946        0.975 -0.9530182         <NA>   0.9758877 
INFO  [02:54:39.380] [bbotk]                                 uhash 
INFO  [02:54:39.380] [bbotk]  488d2991-172f-4245-82eb-e966529b1374 
DEBUG [02:54:40.501] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.872644e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.872644e-05 0.002320881 
  - best initial criterion value(s) :  624.4839 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -624.48  |proj g|=      0.84349
At iterate     1  f =      -633.85  |proj g|=        4.3857
At iterate     2  f =      -638.18  |proj g|=          3.65
At iterate     3  f =      -640.74  |proj g|=        2.6318
At iterate     4  f =      -642.23  |proj g|=        1.8665
At iterate     5  f =      -644.01  |proj g|=        1.9105
At iterate     6  f =      -644.04  |proj g|=        2.2922
At iterate     7  f =      -644.08  |proj g|=        2.1407
At iterate     8  f =      -644.08  |proj g|=        2.1193
At iterate     9  f =      -644.08  |proj g|=        2.1212
At iterate    10  f =      -644.08  |proj g|=        2.1213

iterations 10
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.1213
final function value -644.085

F = -644.085
final  value -644.084557 
converged
 
INFO  [02:54:40.505] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:54:40.559] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:54:40.566] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:54:46.990] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:54:53.716] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:54:59.966] [mlr3]  Finished benchmark 
INFO  [02:55:00.036] [bbotk] Result of batch 124: 
INFO  [02:55:00.038] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:55:00.038] [bbotk]              9.866466                 4.400691                       0.2892199 
INFO  [02:55:00.038] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:55:00.038] [bbotk]                     2142        0.795 -0.9591822         <NA>   0.9746275 
INFO  [02:55:00.038] [bbotk]                                 uhash 
INFO  [02:55:00.038] [bbotk]  8b98c05d-36d2-4790-91d9-a2305fc4ba4e 
DEBUG [02:55:01.304] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.864327e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.864327e-05 0.002314989 
  - best initial criterion value(s) :  617.1987 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -617.2  |proj g|=       5.7351
At iterate     1  f =      -628.88  |proj g|=         1.771
At iterate     2  f =      -629.81  |proj g|=        1.7867
At iterate     3  f =      -630.41  |proj g|=        2.2703
At iterate     4  f =      -630.57  |proj g|=        1.8786
At iterate     5  f =      -630.71  |proj g|=        2.0246
At iterate     6  f =      -631.08  |proj g|=        2.1692
At iterate     7  f =      -631.76  |proj g|=        2.1802
At iterate     8  f =      -632.32  |proj g|=        2.1775
At iterate     9  f =      -632.35  |proj g|=        2.2194
At iterate    10  f =      -632.35  |proj g|=        2.2339
At iterate    11  f =      -632.35  |proj g|=        2.2367
At iterate    12  f =      -632.35  |proj g|=        2.2402
At iterate    13  f =      -632.36  |proj g|=         2.249
At iterate    14  f =      -632.39  |proj g|=        2.2571
At iterate    15  f =      -632.41  |proj g|=         2.278
At iterate    16  f =      -632.46  |proj g|=        2.2809
At iterate    17  f =      -632.82  |proj g|=          2.28
At iterate    18  f =      -633.49  |proj g|=        2.2498
At iterate    19  f =      -635.09  |proj g|=        2.0246
At iterate    20  f =       -636.6  |proj g|=        1.5254
At iterate    21  f =      -636.61  |proj g|=        1.5126
At iterate    22  f =      -637.28  |proj g|=        1.2391
At iterate    23  f =      -637.69  |proj g|=        1.0969
At iterate    24  f =       -637.7  |proj g|=        1.1381
At iterate    25  f =       -637.7  |proj g|=        1.1346
At iterate    26  f =       -637.7  |proj g|=        1.1336
At iterate    27  f =       -637.7  |proj g|=        1.1337

iterations 27
function evaluations 35
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.1337
final function value -637.701

F = -637.701
final  value -637.700929 
converged
 
INFO  [02:55:01.308] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:55:01.376] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:55:01.386] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:55:15.892] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:55:31.881] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:55:45.409] [mlr3]  Finished benchmark 
INFO  [02:55:45.479] [bbotk] Result of batch 125: 
INFO  [02:55:45.481] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:55:45.481] [bbotk]              9.517024                 7.626327                       0.1060694 
INFO  [02:55:45.481] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:55:45.481] [bbotk]                     4725        0.793 -0.9599282         <NA>   0.9743708 
INFO  [02:55:45.481] [bbotk]                                 uhash 
INFO  [02:55:45.481] [bbotk]  d1fbfefe-b73a-44c6-ab6f-f1ec5d1ec001 
DEBUG [02:55:46.990] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.85582e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.85582e-05 0.002302439 
  - best initial criterion value(s) :  572.7975 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -572.8  |proj g|=       6.1072
At iterate     1  f =      -599.26  |proj g|=        2.7461
At iterate     2  f =      -605.29  |proj g|=        2.2813
At iterate     3  f =      -614.21  |proj g|=        2.0996
At iterate     4  f =      -617.58  |proj g|=        1.8913
At iterate     5  f =      -627.76  |proj g|=         2.192
At iterate     6  f =      -639.65  |proj g|=        2.2524
At iterate     7  f =      -641.04  |proj g|=        2.3785
At iterate     8  f =      -642.28  |proj g|=        2.6089
At iterate     9  f =      -642.44  |proj g|=        2.6919
At iterate    10  f =      -642.45  |proj g|=        2.7214
At iterate    11  f =      -642.45  |proj g|=        2.7254
At iterate    12  f =      -642.45  |proj g|=        2.7267
At iterate    13  f =      -642.45  |proj g|=        2.7312
At iterate    14  f =      -642.46  |proj g|=        2.7369
At iterate    15  f =      -642.46  |proj g|=         2.747
At iterate    16  f =      -642.48  |proj g|=        2.7624
At iterate    17  f =      -642.52  |proj g|=        2.7867
At iterate    18  f =      -642.62  |proj g|=        2.8101
At iterate    19  f =      -642.87  |proj g|=        2.8099
At iterate    20  f =      -643.48  |proj g|=        2.8093
At iterate    21  f =      -644.75  |proj g|=        2.8082
At iterate    22  f =      -646.08  |proj g|=        2.5952
At iterate    23  f =       -646.7  |proj g|=        2.5689
At iterate    24  f =      -646.74  |proj g|=        2.5182
At iterate    25  f =      -646.74  |proj g|=        2.5165
At iterate    26  f =      -646.74  |proj g|=        2.5172
At iterate    27  f =      -646.74  |proj g|=        2.5175
At iterate    28  f =      -646.74  |proj g|=        2.5178
At iterate    29  f =      -646.74  |proj g|=        2.5183
At iterate    30  f =      -646.74  |proj g|=         2.519
At iterate    31  f =      -646.74  |proj g|=        2.5198
At iterate    32  f =      -646.74  |proj g|=        2.5203
At iterate    33  f =      -646.75  |proj g|=         2.521
At iterate    34  f =      -646.75  |proj g|=        2.5157
At iterate    35  f =      -646.75  |proj g|=        2.5264
At iterate    36  f =      -646.76  |proj g|=        2.5188
At iterate    37  f =      -647.77  |proj g|=        2.2402
At iterate    38  f =      -649.81  |proj g|=        1.0863
At iterate    39  f =      -652.23  |proj g|=       0.45811
At iterate    40  f =       -652.9  |proj g|=       0.58942
At iterate    41  f =      -652.92  |proj g|=        0.1954
At iterate    42  f =      -652.92  |proj g|=     0.0094311
At iterate    43  f =      -652.92  |proj g|=      0.004535

iterations 43
function evaluations 53
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00453502
final function value -652.92

F = -652.92
final  value -652.920348 
converged
 
INFO  [02:55:46.994] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:55:47.051] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:55:47.058] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:55:55.221] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:56:02.724] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:56:09.749] [mlr3]  Finished benchmark 
INFO  [02:56:09.817] [bbotk] Result of batch 126: 
INFO  [02:56:09.819] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:56:09.819] [bbotk]              2.880864                 8.956167                       0.2477746 
INFO  [02:56:09.819] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:56:09.819] [bbotk]                     2681        0.852 -0.9512187         <NA>   0.9682957 
INFO  [02:56:09.819] [bbotk]                                 uhash 
INFO  [02:56:09.819] [bbotk]  27b1a4c4-726c-438c-ba1d-94c7d7500c07 
DEBUG [02:56:11.187] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.844029e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.844029e-05 0.002291217 
  - best initial criterion value(s) :  589.5514 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -589.55  |proj g|=       11.063
At iterate     1  f =      -624.37  |proj g|=        1.7663
At iterate     2  f =      -628.23  |proj g|=        4.0046
At iterate     3  f =      -630.52  |proj g|=        3.4169
At iterate     4  f =      -631.99  |proj g|=        3.3192
At iterate     5  f =       -632.9  |proj g|=        3.4643
At iterate     6  f =      -633.54  |proj g|=        4.1146
At iterate     7  f =      -633.59  |proj g|=        4.4723
At iterate     8  f =      -633.62  |proj g|=        4.3992
At iterate     9  f =      -633.62  |proj g|=        4.3914
At iterate    10  f =      -633.62  |proj g|=        4.3816
At iterate    11  f =      -633.62  |proj g|=        4.3583
At iterate    12  f =      -633.63  |proj g|=        4.3248
At iterate    13  f =      -633.64  |proj g|=        4.2651
At iterate    14  f =      -633.67  |proj g|=        4.1739
At iterate    15  f =      -633.74  |proj g|=         4.015
At iterate    16  f =      -633.91  |proj g|=        3.7786
At iterate    17  f =       -634.3  |proj g|=        3.4257
At iterate    18  f =      -635.27  |proj g|=         2.918
At iterate    19  f =      -635.51  |proj g|=        2.6749
At iterate    20  f =      -637.54  |proj g|=        2.2045
At iterate    21  f =      -656.52  |proj g|=        1.4048
At iterate    22  f =      -663.09  |proj g|=       0.96483
At iterate    23  f =      -664.12  |proj g|=       0.94929
At iterate    24  f =      -664.12  |proj g|=       0.94009
At iterate    25  f =      -664.12  |proj g|=       0.94545
At iterate    26  f =      -664.12  |proj g|=        0.9464
At iterate    27  f =      -664.12  |proj g|=        0.9464

iterations 27
function evaluations 35
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.946397
final function value -664.125

F = -664.125
final  value -664.124740 
converged
 
INFO  [02:56:11.191] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:56:11.248] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:56:11.255] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:56:19.391] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:56:28.063] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:56:37.727] [mlr3]  Finished benchmark 
INFO  [02:56:37.796] [bbotk] Result of batch 127: 
INFO  [02:56:37.797] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:56:37.797] [bbotk]               2.83874                 6.979309                       0.3230337 
INFO  [02:56:37.797] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:56:37.797] [bbotk]                     2885        0.834 -0.9561836         <NA>   0.9697763 
INFO  [02:56:37.797] [bbotk]                                 uhash 
INFO  [02:56:37.797] [bbotk]  5f53c0a5-add3-49ed-b357-177285fd595f 
DEBUG [02:56:39.261] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.832766e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.832766e-05 0.002287221 
  - best initial criterion value(s) :  614.2534 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -614.25  |proj g|=       14.087
At iterate     1  f =      -637.31  |proj g|=        3.7535
At iterate     2  f =      -643.86  |proj g|=        5.1183
At iterate     3  f =      -647.87  |proj g|=        3.6325
At iterate     4  f =      -651.14  |proj g|=        3.0534
At iterate     5  f =      -652.28  |proj g|=        2.5443
At iterate     6  f =      -652.88  |proj g|=        2.5585
At iterate     7  f =       -653.2  |proj g|=        2.8239
At iterate     8  f =      -653.28  |proj g|=        2.6938
At iterate     9  f =      -653.29  |proj g|=        2.8339
At iterate    10  f =      -653.29  |proj g|=        2.8035
At iterate    11  f =      -654.13  |proj g|=        2.5956
At iterate    12  f =      -658.65  |proj g|=         1.952
At iterate    13  f =       -665.2  |proj g|=        1.0335
At iterate    14  f =      -666.66  |proj g|=       0.50184
At iterate    15  f =      -668.93  |proj g|=       0.41587
At iterate    16  f =      -669.54  |proj g|=       0.58784
At iterate    17  f =       -669.8  |proj g|=       0.59407
At iterate    18  f =      -669.81  |proj g|=       0.38364
At iterate    19  f =      -669.81  |proj g|=       0.25543
At iterate    20  f =      -669.81  |proj g|=       0.25545
At iterate    21  f =      -669.81  |proj g|=       0.25545

iterations 21
function evaluations 27
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.255451
final function value -669.813

F = -669.813
final  value -669.813083 
converged
 
INFO  [02:56:39.265] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:56:39.319] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:56:39.326] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:56:47.882] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:56:56.247] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:57:03.782] [mlr3]  Finished benchmark 
INFO  [02:57:03.870] [bbotk] Result of batch 128: 
INFO  [02:57:03.872] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:57:03.872] [bbotk]              5.046705                 5.257964                        0.173083 
INFO  [02:57:03.872] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:57:03.872] [bbotk]                     2987        0.803 -0.9528612         <NA>   0.9740615 
INFO  [02:57:03.872] [bbotk]                                 uhash 
INFO  [02:57:03.872] [bbotk]  5b99a077-41b9-4ac4-b610-30c26d7c0399 
DEBUG [02:57:05.255] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.824274e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.824274e-05 0.002288042 
  - best initial criterion value(s) :  608.0452 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -608.05  |proj g|=       8.4536
At iterate     1  f =      -612.29  |proj g|=        10.892
At iterate     2  f =      -620.79  |proj g|=        6.1761
At iterate     3  f =      -626.44  |proj g|=        5.0768
At iterate     4  f =      -629.49  |proj g|=        4.8188
At iterate     5  f =      -629.73  |proj g|=        4.6652
At iterate     6  f =      -629.74  |proj g|=        4.6312
At iterate     7  f =      -629.74  |proj g|=        4.6247
At iterate     8  f =      -629.74  |proj g|=        4.6214
At iterate     9  f =      -629.74  |proj g|=        4.6153
At iterate    10  f =      -629.74  |proj g|=         4.605
At iterate    11  f =      -629.74  |proj g|=        4.5876
At iterate    12  f =      -629.76  |proj g|=        4.5594
At iterate    13  f =      -629.79  |proj g|=        4.5149
At iterate    14  f =      -629.85  |proj g|=        4.4605
At iterate    15  f =      -629.86  |proj g|=        4.4283
At iterate    16  f =      -629.99  |proj g|=        4.3599
At iterate    17  f =      -643.39  |proj g|=        3.7483
At iterate    18  f =      -670.67  |proj g|=        1.2288
At iterate    19  f =      -670.96  |proj g|=        1.1188
At iterate    20  f =      -671.59  |proj g|=       0.72131
At iterate    21  f =      -671.62  |proj g|=       0.72131
At iterate    22  f =      -671.63  |proj g|=       0.72131
At iterate    23  f =      -671.63  |proj g|=       0.72131
At iterate    24  f =      -671.63  |proj g|=        0.7213
At iterate    25  f =      -671.63  |proj g|=       0.72129
At iterate    26  f =      -671.63  |proj g|=       0.72123
At iterate    27  f =      -671.64  |proj g|=       0.72107
At iterate    28  f =      -671.66  |proj g|=       0.72064
At iterate    29  f =      -671.72  |proj g|=        0.7195
At iterate    30  f =      -671.87  |proj g|=       0.71645
At iterate    31  f =      -672.25  |proj g|=       0.70858
At iterate    32  f =      -673.13  |proj g|=       0.70742
At iterate    33  f =      -674.96  |proj g|=       0.70639
At iterate    34  f =      -676.23  |proj g|=       0.70559
At iterate    35  f =      -676.57  |proj g|=       0.70516
At iterate    36  f =      -676.58  |proj g|=       0.70505
At iterate    37  f =      -676.58  |proj g|=       0.70501
At iterate    38  f =      -676.58  |proj g|=       0.70501

iterations 38
function evaluations 43
segments explored during Cauchy searches 40
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.70501
final function value -676.579

F = -676.579
final  value -676.579169 
converged
 
INFO  [02:57:05.259] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:57:05.317] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:57:05.324] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:57:11.764] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:57:16.494] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:57:21.831] [mlr3]  Finished benchmark 
INFO  [02:57:21.901] [bbotk] Result of batch 129: 
INFO  [02:57:21.902] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:57:21.902] [bbotk]              7.637964                 4.853903                       0.1755099 
INFO  [02:57:21.902] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:57:21.902] [bbotk]                     1658        0.826 -0.9530967         <NA>     0.97214 
INFO  [02:57:21.902] [bbotk]                                 uhash 
INFO  [02:57:21.902] [bbotk]  57ba6cec-cbee-4988-9b90-973747b7d18d 
DEBUG [02:57:23.478] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.814403e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.814403e-05 0.00227131 
  - best initial criterion value(s) :  595.8892 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -595.89  |proj g|=       9.1995
At iterate     1  f =      -641.36  |proj g|=        2.1095
At iterate     2  f =      -653.76  |proj g|=        3.5279
At iterate     3  f =      -657.45  |proj g|=         3.147
At iterate     4  f =      -660.41  |proj g|=        2.3715
At iterate     5  f =      -660.74  |proj g|=        2.1998
At iterate     6  f =      -660.92  |proj g|=        2.2027
At iterate     7  f =      -661.27  |proj g|=        3.0354
At iterate     8  f =      -661.37  |proj g|=        2.9355
At iterate     9  f =      -661.38  |proj g|=         2.958
At iterate    10  f =      -661.38  |proj g|=        2.9816
At iterate    11  f =      -661.38  |proj g|=        2.9898
At iterate    12  f =      -661.38  |proj g|=        2.9925
At iterate    13  f =      -661.38  |proj g|=        2.9997
At iterate    14  f =      -661.38  |proj g|=        3.0099
At iterate    15  f =      -661.38  |proj g|=        3.0268
At iterate    16  f =      -661.38  |proj g|=        3.0526
At iterate    17  f =      -661.39  |proj g|=        3.0907
At iterate    18  f =       -661.4  |proj g|=        3.1392
At iterate    19  f =      -661.43  |proj g|=        3.1719
At iterate    20  f =      -661.49  |proj g|=         3.104
At iterate    21  f =      -661.51  |proj g|=        2.9209
At iterate    22  f =      -661.51  |proj g|=        2.9124
At iterate    23  f =       -662.3  |proj g|=        2.6424
At iterate    24  f =      -668.14  |proj g|=        2.0271
At iterate    25  f =       -676.3  |proj g|=        1.3407
At iterate    26  f =      -677.46  |proj g|=        1.1909
At iterate    27  f =      -677.85  |proj g|=        1.1892
At iterate    28  f =      -679.12  |proj g|=        1.1869
At iterate    29  f =      -679.16  |proj g|=         1.186
At iterate    30  f =      -679.17  |proj g|=        1.1858
At iterate    31  f =      -679.17  |proj g|=        1.1858
At iterate    32  f =      -679.17  |proj g|=        1.1857
At iterate    33  f =      -679.17  |proj g|=        1.1852
At iterate    34  f =      -679.17  |proj g|=        1.1841
At iterate    35  f =      -679.17  |proj g|=        1.1805
At iterate    36  f =      -679.18  |proj g|=        1.1713
At iterate    37  f =      -679.21  |proj g|=        1.1459
At iterate    38  f =      -679.29  |proj g|=        1.0777
At iterate    39  f =      -679.51  |proj g|=       0.89366
At iterate    40  f =      -680.04  |proj g|=       0.42581
At iterate    41  f =      -680.77  |proj g|=       0.43341
At iterate    42  f =       -681.2  |proj g|=       0.43419
At iterate    43  f =      -681.26  |proj g|=        0.4345
At iterate    44  f =      -681.26  |proj g|=       0.43457
At iterate    45  f =      -681.26  |proj g|=       0.43456
At iterate    46  f =      -681.26  |proj g|=       0.43444
At iterate    47  f =      -681.27  |proj g|=       0.43406
At iterate    48  f =      -681.28  |proj g|=       0.43286
At iterate    49  f =      -681.31  |proj g|=       0.42975
At iterate    50  f =      -681.37  |proj g|=       0.42242
At iterate    51  f =      -681.48  |proj g|=       0.57277
At iterate    52  f =      -681.63  |proj g|=       0.59193
At iterate    53  f =      -681.66  |proj g|=       0.57134
At iterate    54  f =      -681.67  |proj g|=       0.11135
At iterate    55  f =      -681.67  |proj g|=      0.017858
At iterate    56  f =      -681.67  |proj g|=     0.0042136

iterations 56
function evaluations 64
segments explored during Cauchy searches 58
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00421358
final function value -681.666

F = -681.666
final  value -681.666157 
converged
 
INFO  [02:57:23.483] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:57:23.540] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:57:23.547] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:57:25.615] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:57:29.980] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:57:31.737] [mlr3]  Finished benchmark 
INFO  [02:57:31.840] [bbotk] Result of batch 130: 
INFO  [02:57:31.842] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:57:31.842] [bbotk]              4.622738                 3.792779                       0.4124834 
INFO  [02:57:31.842] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:57:31.842] [bbotk]                      521        0.827 -0.9519533         <NA>   0.9679975 
INFO  [02:57:31.842] [bbotk]                                 uhash 
INFO  [02:57:31.842] [bbotk]  9f680bc0-4a35-4212-8461-f76c52e31dc3 
DEBUG [02:57:32.999] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.803112e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.803112e-05 0.002239416 
  - best initial criterion value(s) :  625.2016 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -625.2  |proj g|=       2.9132
At iterate     1  f =      -626.04  |proj g|=        1.7403
At iterate     2  f =      -626.51  |proj g|=        1.8789
At iterate     3  f =      -626.94  |proj g|=        2.0547
At iterate     4  f =      -626.97  |proj g|=        1.9428
At iterate     5  f =      -626.97  |proj g|=        1.8936
At iterate     6  f =      -626.97  |proj g|=        1.8901
At iterate     7  f =      -626.97  |proj g|=          1.89

iterations 7
function evaluations 10
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.88997
final function value -626.975

F = -626.975
final  value -626.974958 
converged
 
INFO  [02:57:33.004] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:57:33.061] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:57:33.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:57:44.106] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:57:53.430] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:58:02.343] [mlr3]  Finished benchmark 
INFO  [02:58:02.413] [bbotk] Result of batch 131: 
INFO  [02:58:02.415] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:58:02.415] [bbotk]              2.646955                 9.930119                       0.3469202 
INFO  [02:58:02.415] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:58:02.415] [bbotk]                     3211        0.831 -0.9621299         <NA>   0.9690152 
INFO  [02:58:02.415] [bbotk]                                 uhash 
INFO  [02:58:02.415] [bbotk]  5b419933-b7d4-4396-ba0a-c547d216f5db 
DEBUG [02:58:03.912] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.792135e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.792135e-05 0.002236221 
  - best initial criterion value(s) :  608.1372 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -608.14  |proj g|=       7.0714
At iterate     1  f =      -639.67  |proj g|=        3.2987
At iterate     2  f =      -649.32  |proj g|=         4.747
At iterate     3  f =      -650.03  |proj g|=        4.6354
At iterate     4  f =      -650.65  |proj g|=        4.4635
At iterate     5  f =      -650.92  |proj g|=        4.5945
At iterate     6  f =       -651.1  |proj g|=        4.6934
At iterate     7  f =      -651.15  |proj g|=         4.754
At iterate     8  f =      -651.15  |proj g|=        4.7446
At iterate     9  f =      -651.15  |proj g|=         4.745
At iterate    10  f =      -651.15  |proj g|=        4.7453
At iterate    11  f =      -651.15  |proj g|=         4.746
At iterate    12  f =      -651.15  |proj g|=         4.745
At iterate    13  f =      -651.15  |proj g|=        4.7459
At iterate    14  f =      -651.15  |proj g|=        4.7487
At iterate    15  f =      -651.15  |proj g|=        4.7538
At iterate    16  f =      -651.17  |proj g|=        4.7607
At iterate    17  f =      -651.19  |proj g|=        4.7773
At iterate    18  f =      -651.21  |proj g|=        4.7273
At iterate    19  f =      -651.32  |proj g|=        4.7717
At iterate    20  f =      -651.63  |proj g|=          4.83
At iterate    21  f =      -652.42  |proj g|=        4.8677
At iterate    22  f =      -654.29  |proj g|=        4.7898
At iterate    23  f =      -658.38  |proj g|=        4.4342
At iterate    24  f =      -667.03  |proj g|=        3.4921
At iterate    25  f =      -674.81  |proj g|=         1.458
At iterate    26  f =       -676.3  |proj g|=       0.60037
At iterate    27  f =      -677.22  |proj g|=       0.66478
At iterate    28  f =      -677.85  |proj g|=        1.1798
At iterate    29  f =      -677.94  |proj g|=         1.266
At iterate    30  f =      -677.94  |proj g|=        1.2686
At iterate    31  f =      -677.94  |proj g|=        1.2681

iterations 31
function evaluations 34
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.26808
final function value -677.936

F = -677.936
final  value -677.935603 
converged
 
INFO  [02:58:03.917] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:58:03.973] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:58:03.980] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:58:10.089] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:58:16.120] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:58:21.887] [mlr3]  Finished benchmark 
INFO  [02:58:21.992] [bbotk] Result of batch 132: 
INFO  [02:58:21.995] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:58:21.995] [bbotk]              4.323107                  4.05606                       0.2213086 
INFO  [02:58:21.995] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:58:21.995] [bbotk]                     2096         0.82 -0.9556277         <NA>   0.9725145 
INFO  [02:58:21.995] [bbotk]                                 uhash 
INFO  [02:58:21.995] [bbotk]  36512ece-7337-4720-9ee6-fba15c13fbca 
DEBUG [02:58:23.320] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.782854e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9813886 9590 
  - variance bounds :  1.782854e-05 0.002228521 
  - best initial criterion value(s) :  638.2015 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -638.2  |proj g|=        6.468
At iterate     1  f =       -640.9  |proj g|=        7.7517
At iterate     2  f =      -647.47  |proj g|=        6.3552
At iterate     3  f =      -658.35  |proj g|=        3.9002
At iterate     4  f =      -662.17  |proj g|=        4.4246
At iterate     5  f =      -663.01  |proj g|=        4.5567
At iterate     6  f =      -663.33  |proj g|=        4.4138
At iterate     7  f =      -663.34  |proj g|=        4.3933
At iterate     8  f =      -663.34  |proj g|=        4.3907
At iterate     9  f =      -663.34  |proj g|=        4.3917
At iterate    10  f =      -663.34  |proj g|=        4.3946
At iterate    11  f =      -663.34  |proj g|=        4.3997
At iterate    12  f =      -663.35  |proj g|=        4.4071
At iterate    13  f =      -663.38  |proj g|=        4.4186
At iterate    14  f =      -663.43  |proj g|=        4.4442
At iterate    15  f =      -663.48  |proj g|=        4.3809
At iterate    16  f =      -663.69  |proj g|=        4.4372
At iterate    17  f =      -664.29  |proj g|=        4.5042
At iterate    18  f =      -665.87  |proj g|=        4.5286
At iterate    19  f =      -669.71  |proj g|=        4.3382
At iterate    20  f =      -677.53  |proj g|=        3.5936
At iterate    21  f =      -685.91  |proj g|=        1.4009
At iterate    22  f =      -695.15  |proj g|=        0.3684
At iterate    23  f =      -695.51  |proj g|=       0.35661
At iterate    24  f =      -695.76  |proj g|=       0.28552
At iterate    25  f =      -695.78  |proj g|=       0.65256
At iterate    26  f =      -695.78  |proj g|=       0.17503
At iterate    27  f =      -695.78  |proj g|=        0.1764
At iterate    28  f =      -695.78  |proj g|=       0.17653

iterations 28
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.17653
final function value -695.782

F = -695.782
final  value -695.781837 
converged
 
INFO  [02:58:23.326] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:58:23.385] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:58:23.392] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:58:37.778] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:58:49.820] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:59:01.590] [mlr3]  Finished benchmark 
INFO  [02:59:01.661] [bbotk] Result of batch 133: 
INFO  [02:59:01.663] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:59:01.663] [bbotk]              7.274455                 2.241824                     0.005399197 
INFO  [02:59:01.663] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:59:01.663] [bbotk]                     4128        0.822 -0.9553473         <NA>   0.9390187 
INFO  [02:59:01.663] [bbotk]                                 uhash 
INFO  [02:59:01.663] [bbotk]  76785e10-6bd1-4ad2-a5dc-dd4f5d27c702 
DEBUG [02:59:03.073] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.820201e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9823811 9590 
  - variance bounds :  1.820201e-05 0.002255874 
  - best initial criterion value(s) :  598.7384 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -598.74  |proj g|=       7.3864
At iterate     1  f =      -666.49  |proj g|=        3.6712
At iterate     2  f =      -669.15  |proj g|=        3.4076
At iterate     3  f =      -672.06  |proj g|=        1.9345
At iterate     4  f =      -672.82  |proj g|=        2.5912
At iterate     5  f =       -672.9  |proj g|=        2.4656
At iterate     6  f =      -672.91  |proj g|=        2.4368
At iterate     7  f =      -672.92  |proj g|=        2.4073
At iterate     8  f =      -672.96  |proj g|=        2.3629
At iterate     9  f =      -672.98  |proj g|=        2.4005
At iterate    10  f =      -672.98  |proj g|=        2.3936
At iterate    11  f =      -672.98  |proj g|=        2.3925
At iterate    12  f =      -672.98  |proj g|=        2.3904
At iterate    13  f =      -672.98  |proj g|=        2.3868
At iterate    14  f =      -672.98  |proj g|=        2.3811
At iterate    15  f =      -672.98  |proj g|=        2.3713
At iterate    16  f =      -672.99  |proj g|=        2.3581
At iterate    17  f =      -672.99  |proj g|=        2.3321
At iterate    18  f =         -673  |proj g|=        2.3196
At iterate    19  f =      -673.22  |proj g|=        2.2828
At iterate    20  f =      -675.23  |proj g|=        1.9317
At iterate    21  f =       -677.8  |proj g|=        2.1304
At iterate    22  f =       -678.1  |proj g|=        1.9551
At iterate    23  f =      -678.11  |proj g|=        1.9336
At iterate    24  f =      -678.11  |proj g|=        1.9373
At iterate    25  f =      -678.11  |proj g|=        1.9352
At iterate    26  f =      -678.67  |proj g|=        1.8737
At iterate    27  f =      -678.75  |proj g|=        1.8866
At iterate    28  f =      -678.76  |proj g|=        1.8885
At iterate    29  f =      -678.78  |proj g|=         1.878
At iterate    30  f =      -678.96  |proj g|=        1.8035
At iterate    31  f =      -678.99  |proj g|=        1.9259
At iterate    32  f =      -679.08  |proj g|=         1.814
At iterate    33  f =      -679.08  |proj g|=        1.8031
At iterate    34  f =      -679.08  |proj g|=        1.8042
At iterate    35  f =      -679.08  |proj g|=        1.8039
At iterate    36  f =      -679.08  |proj g|=         1.804

iterations 36
function evaluations 42
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.80402
final function value -679.082

F = -679.082
final  value -679.082428 
converged
 
INFO  [02:59:03.078] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:59:03.134] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:59:03.141] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:59:07.794] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:59:12.399] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:59:17.327] [mlr3]  Finished benchmark 
INFO  [02:59:17.398] [bbotk] Result of batch 134: 
INFO  [02:59:17.400] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:59:17.400] [bbotk]              5.567077                  6.97608                        0.331276 
INFO  [02:59:17.400] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:59:17.400] [bbotk]                     1631        0.828 -0.9494909         <NA>    0.974702 
INFO  [02:59:17.400] [bbotk]                                 uhash 
INFO  [02:59:17.400] [bbotk]  4478c885-57bf-4d36-b7de-887cdbb4d50f 
DEBUG [02:59:18.932] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.812709e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9823811 9590 
  - variance bounds :  1.812709e-05 0.002238292 
  - best initial criterion value(s) :  631.1091 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -631.11  |proj g|=       5.2235
At iterate     1  f =      -653.55  |proj g|=        2.9538
At iterate     2  f =      -658.65  |proj g|=        5.5858
At iterate     3  f =      -659.22  |proj g|=        5.2586
At iterate     4  f =      -659.44  |proj g|=        4.9058
At iterate     5  f =      -659.44  |proj g|=        4.8935
At iterate     6  f =      -659.44  |proj g|=        4.9055
At iterate     7  f =      -659.44  |proj g|=        4.9239
At iterate     8  f =      -659.44  |proj g|=        4.9305
At iterate     9  f =      -659.44  |proj g|=         4.931
At iterate    10  f =      -659.44  |proj g|=        4.9327
At iterate    11  f =      -659.44  |proj g|=        4.9354
At iterate    12  f =      -659.44  |proj g|=        4.9398
At iterate    13  f =      -659.44  |proj g|=        4.9462
At iterate    14  f =      -659.44  |proj g|=        4.9545
At iterate    15  f =      -659.44  |proj g|=        4.9619
At iterate    16  f =      -659.45  |proj g|=        4.9623
At iterate    17  f =      -659.45  |proj g|=        5.0124
At iterate    18  f =      -659.46  |proj g|=        5.0008
At iterate    19  f =      -659.49  |proj g|=        5.3847
At iterate    20  f =      -659.65  |proj g|=        5.0826
At iterate    21  f =      -659.98  |proj g|=        4.5518
At iterate    22  f =      -660.77  |proj g|=         3.795
At iterate    23  f =       -663.5  |proj g|=        2.4624
At iterate    24  f =      -669.26  |proj g|=        1.7499
At iterate    25  f =       -676.3  |proj g|=         1.148
At iterate    26  f =       -680.5  |proj g|=        1.6063
At iterate    27  f =      -682.03  |proj g|=        1.2939
At iterate    28  f =      -683.26  |proj g|=        1.1248
At iterate    29  f =      -684.08  |proj g|=       0.93959
At iterate    30  f =      -684.37  |proj g|=       0.53406
At iterate    31  f =       -684.4  |proj g|=       0.52854
At iterate    32  f =      -684.41  |proj g|=       0.52163
At iterate    33  f =      -684.41  |proj g|=       0.52056
At iterate    34  f =      -684.41  |proj g|=       0.51286
At iterate    35  f =      -684.41  |proj g|=       0.53612
At iterate    36  f =      -684.41  |proj g|=       0.63976
At iterate    37  f =      -684.43  |proj g|=       0.63872
At iterate    38  f =      -684.46  |proj g|=       0.63734
At iterate    39  f =      -684.54  |proj g|=       0.63576
At iterate    40  f =      -684.68  |proj g|=        0.6342
At iterate    41  f =      -684.84  |proj g|=       0.34426
At iterate    42  f =      -684.91  |proj g|=       0.34389
At iterate    43  f =      -684.97  |proj g|=       0.33875
At iterate    44  f =      -685.04  |proj g|=       0.32813
At iterate    45  f =      -685.11  |proj g|=       0.67114
At iterate    46  f =      -685.11  |proj g|=      0.040801
At iterate    47  f =      -685.11  |proj g|=      0.042368
At iterate    48  f =      -685.11  |proj g|=      0.014408

iterations 48
function evaluations 57
segments explored during Cauchy searches 50
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0144082
final function value -685.115

F = -685.115
final  value -685.114987 
converged
 
INFO  [02:59:18.936] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:59:18.994] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:59:19.002] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:59:21.093] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:59:23.157] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:59:25.182] [mlr3]  Finished benchmark 
INFO  [02:59:25.254] [bbotk] Result of batch 135: 
INFO  [02:59:25.256] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:59:25.256] [bbotk]              8.801706                  8.58774                       0.3187529 
INFO  [02:59:25.256] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:59:25.256] [bbotk]                      635        0.839 -0.9531797         <NA>   0.9702784 
INFO  [02:59:25.256] [bbotk]                                 uhash 
INFO  [02:59:25.256] [bbotk]  ea0df99a-5fc3-4459-8f2a-69d0024b5058 
DEBUG [02:59:26.770] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.802357e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9823811 9590 
  - variance bounds :  1.802357e-05 0.002212955 
  - best initial criterion value(s) :  612.3218 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -612.32  |proj g|=       4.5222
At iterate     1  f =      -654.06  |proj g|=        12.558
At iterate     2  f =      -662.41  |proj g|=        12.364
At iterate     3  f =      -676.03  |proj g|=        8.8827
At iterate     4  f =      -676.97  |proj g|=         6.921
At iterate     5  f =         -677  |proj g|=        6.5598
At iterate     6  f =      -677.06  |proj g|=         6.326
At iterate     7  f =      -677.11  |proj g|=        6.1104
At iterate     8  f =      -677.12  |proj g|=        6.1118
At iterate     9  f =      -677.12  |proj g|=        6.1197
At iterate    10  f =      -677.12  |proj g|=        6.1226
At iterate    11  f =      -677.12  |proj g|=        6.1269
At iterate    12  f =      -677.12  |proj g|=        6.1355
At iterate    13  f =      -677.12  |proj g|=        6.1428
At iterate    14  f =      -677.12  |proj g|=        6.1453
At iterate    15  f =      -677.13  |proj g|=        6.1134
At iterate    16  f =      -677.15  |proj g|=        6.1487
At iterate    17  f =       -677.2  |proj g|=        6.0493
At iterate    18  f =      -677.34  |proj g|=        5.9241
At iterate    19  f =       -677.6  |proj g|=         5.053
At iterate    20  f =      -677.82  |proj g|=        4.9812
At iterate    21  f =      -678.83  |proj g|=        5.3085
At iterate    22  f =      -683.31  |proj g|=        5.4545
At iterate    23  f =       -685.1  |proj g|=         2.936
At iterate    24  f =      -685.16  |proj g|=        2.7145
At iterate    25  f =      -685.19  |proj g|=        2.8232
At iterate    26  f =      -685.19  |proj g|=        2.7892
At iterate    27  f =      -685.19  |proj g|=        2.8069
At iterate    28  f =      -685.19  |proj g|=        2.8065

iterations 28
function evaluations 33
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.80654
final function value -685.19

F = -685.19
final  value -685.189922 
converged
 
INFO  [02:59:26.774] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:59:26.832] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:59:26.840] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:59:33.979] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:59:42.214] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:59:47.901] [mlr3]  Finished benchmark 
INFO  [02:59:47.975] [bbotk] Result of batch 136: 
INFO  [02:59:47.977] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:59:47.977] [bbotk]               2.44588                 2.265771                       0.3779584 
INFO  [02:59:47.977] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:59:47.977] [bbotk]                     2099        0.826 -0.9603775         <NA>   0.9643472 
INFO  [02:59:47.977] [bbotk]                                 uhash 
INFO  [02:59:47.977] [bbotk]  7cf1f745-994c-4c18-aa78-514395e68b5d 
DEBUG [02:59:49.304] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.791938e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9823811 9590 
  - variance bounds :  1.791938e-05 0.002202716 
  - best initial criterion value(s) :  653.9081 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -653.91  |proj g|=       13.944
At iterate     1  f =      -679.95  |proj g|=        2.6776
At iterate     2  f =      -683.42  |proj g|=        3.8294
At iterate     3  f =      -685.69  |proj g|=        2.5338
At iterate     4  f =      -686.88  |proj g|=        1.7754
At iterate     5  f =      -687.31  |proj g|=        1.6012
At iterate     6  f =      -687.59  |proj g|=        1.6524
At iterate     7  f =      -687.84  |proj g|=        2.7371
At iterate     8  f =      -687.97  |proj g|=        2.3535
At iterate     9  f =      -687.98  |proj g|=        2.3314
At iterate    10  f =      -687.98  |proj g|=        2.4189
At iterate    11  f =      -687.98  |proj g|=        2.4017
At iterate    12  f =      -687.99  |proj g|=         2.396
At iterate    13  f =      -688.19  |proj g|=        2.2417
At iterate    14  f =      -688.84  |proj g|=        1.9751
At iterate    15  f =      -691.07  |proj g|=         1.401
At iterate    16  f =      -691.26  |proj g|=        1.1488
At iterate    17  f =       -695.7  |proj g|=        0.7951
At iterate    18  f =       -699.5  |proj g|=       0.53189
At iterate    19  f =      -701.93  |proj g|=        0.6103
At iterate    20  f =      -702.11  |proj g|=       0.61152
At iterate    21  f =      -702.11  |proj g|=       0.52794
At iterate    22  f =      -702.11  |proj g|=       0.52797
At iterate    23  f =      -702.11  |proj g|=       0.52796
At iterate    24  f =      -702.11  |proj g|=       0.52796

iterations 24
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.527965
final function value -702.109

F = -702.109
final  value -702.108918 
converged
 
INFO  [02:59:49.308] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:59:49.365] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:59:49.372] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [02:59:51.635] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:59:53.253] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:59:54.980] [mlr3]  Finished benchmark 
INFO  [02:59:55.052] [bbotk] Result of batch 137: 
INFO  [02:59:55.054] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [02:59:55.054] [bbotk]              6.229046                 2.881685                        0.151973 
INFO  [02:59:55.054] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [02:59:55.054] [bbotk]                      501         0.83 -0.9449785         <NA>   0.9589434 
INFO  [02:59:55.054] [bbotk]                                 uhash 
INFO  [02:59:55.054] [bbotk]  54d1da72-5a51-403e-a5a0-5ca5e0a84e8d 
DEBUG [02:59:56.416] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.785107e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9823811 9590 
  - variance bounds :  1.785107e-05 0.002184067 
  - best initial criterion value(s) :  669.5252 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -669.53  |proj g|=       7.6921
At iterate     1  f =      -671.41  |proj g|=        3.8631
At iterate     2  f =      -672.91  |proj g|=        3.7937
At iterate     3  f =      -675.98  |proj g|=        2.8799
At iterate     4  f =      -677.09  |proj g|=        2.9937
At iterate     5  f =      -677.78  |proj g|=        3.1271
At iterate     6  f =      -678.11  |proj g|=        3.2997
At iterate     7  f =      -678.18  |proj g|=        3.7676
At iterate     8  f =      -678.28  |proj g|=        3.5464
At iterate     9  f =      -678.29  |proj g|=         3.594
At iterate    10  f =      -678.29  |proj g|=        3.6372
At iterate    11  f =      -678.29  |proj g|=        3.6464
At iterate    12  f =       -678.3  |proj g|=        3.6702
At iterate    13  f =      -678.31  |proj g|=        3.6836
At iterate    14  f =      -678.33  |proj g|=        3.6692
At iterate    15  f =      -678.37  |proj g|=        3.7325
At iterate    16  f =      -678.46  |proj g|=        3.6542
At iterate    17  f =      -678.66  |proj g|=        3.8094
At iterate    18  f =      -679.02  |proj g|=         3.216
At iterate    19  f =      -679.54  |proj g|=        2.8971
At iterate    20  f =       -683.3  |proj g|=        2.2738
At iterate    21  f =      -698.16  |proj g|=        1.8269
At iterate    22  f =      -704.87  |proj g|=        1.5567
At iterate    23  f =       -705.5  |proj g|=        1.5556
At iterate    24  f =      -705.57  |proj g|=        1.5557
At iterate    25  f =      -705.59  |proj g|=        1.5558
At iterate    26  f =      -705.59  |proj g|=        1.5557
At iterate    27  f =      -705.59  |proj g|=        1.5557
At iterate    28  f =      -705.59  |proj g|=        1.5557

iterations 28
function evaluations 33
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.55575
final function value -705.594

F = -705.594
final  value -705.593575 
converged
 
INFO  [02:59:56.420] [bbotk] Evaluating 1 configuration(s) 
INFO  [02:59:56.479] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [02:59:56.486] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [02:59:57.676] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [02:59:59.005] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:00:00.345] [mlr3]  Finished benchmark 
INFO  [03:00:00.418] [bbotk] Result of batch 138: 
INFO  [03:00:00.420] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:00:00.420] [bbotk]              8.112323                 9.635445                       0.4996574 
INFO  [03:00:00.420] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:00:00.420] [bbotk]                      200        0.831 -0.9434872         <NA>   0.9631973 
INFO  [03:00:00.420] [bbotk]                                 uhash 
INFO  [03:00:00.420] [bbotk]  5d46f690-7257-4370-ba77-c7485965b2aa 
DEBUG [03:00:01.823] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.775333e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.775333e-05 0.00215861 
  - best initial criterion value(s) :  658.217 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -658.22  |proj g|=        2.465
At iterate     1  f =      -684.41  |proj g|=        3.9119
At iterate     2  f =      -684.69  |proj g|=        2.9184
At iterate     3  f =      -684.97  |proj g|=        2.5361
At iterate     4  f =      -685.19  |proj g|=         2.418
At iterate     5  f =       -685.2  |proj g|=        2.4253
At iterate     6  f =       -685.2  |proj g|=        2.4184
At iterate     7  f =       -685.2  |proj g|=        2.4198
At iterate     8  f =       -685.2  |proj g|=        2.4196
At iterate     9  f =       -685.2  |proj g|=        2.4168
At iterate    10  f =       -685.2  |proj g|=         2.416
At iterate    11  f =       -685.2  |proj g|=        2.4114
At iterate    12  f =       -685.2  |proj g|=        2.4043
At iterate    13  f =      -685.21  |proj g|=        2.3924
At iterate    14  f =      -685.23  |proj g|=        2.3761
At iterate    15  f =      -685.24  |proj g|=        2.3178
At iterate    16  f =      -685.29  |proj g|=        2.3061
At iterate    17  f =      -685.48  |proj g|=        2.3206
At iterate    18  f =      -685.91  |proj g|=        2.6239
At iterate    19  f =      -686.96  |proj g|=        3.0685
At iterate    20  f =      -689.54  |proj g|=        3.6813
At iterate    21  f =      -690.79  |proj g|=        3.1979
At iterate    22  f =      -693.43  |proj g|=        2.8091
At iterate    23  f =      -693.77  |proj g|=        2.0608
At iterate    24  f =      -693.96  |proj g|=        3.3325
At iterate    25  f =      -694.06  |proj g|=        2.4977
At iterate    26  f =      -694.08  |proj g|=        2.6083
At iterate    27  f =      -694.08  |proj g|=        2.5894
At iterate    28  f =      -694.08  |proj g|=        2.5995
At iterate    29  f =      -694.08  |proj g|=        2.5975

iterations 29
function evaluations 35
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.59747
final function value -694.078

F = -694.078
final  value -694.077776 
converged
 
INFO  [03:00:01.827] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:00:01.932] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:00:01.942] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:00:03.729] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:00:05.342] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:00:06.991] [mlr3]  Finished benchmark 
INFO  [03:00:07.094] [bbotk] Result of batch 139: 
INFO  [03:00:07.096] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:00:07.096] [bbotk]              4.545614                 3.924807                       0.1555718 
INFO  [03:00:07.096] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:00:07.096] [bbotk]                      393        0.858 -0.9567953         <NA>   0.9531909 
INFO  [03:00:07.096] [bbotk]                                 uhash 
INFO  [03:00:07.096] [bbotk]  10010a68-cf15-4599-b807-4b4b56be5cdc 
DEBUG [03:00:08.696] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.775991e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.775991e-05 0.002159852 
  - best initial criterion value(s) :  639.2465 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -639.25  |proj g|=       14.439
At iterate     1  f =      -674.33  |proj g|=        2.3786
At iterate     2  f =      -674.39  |proj g|=        2.2177
At iterate     3  f =       -674.4  |proj g|=        2.2391
At iterate     4  f =      -674.42  |proj g|=        2.2882
At iterate     5  f =      -674.42  |proj g|=        2.3011
At iterate     6  f =      -674.47  |proj g|=        2.2871
At iterate     7  f =      -674.61  |proj g|=        2.2695
At iterate     8  f =      -675.08  |proj g|=        2.2589
At iterate     9  f =      -676.35  |proj g|=        2.4073
At iterate    10  f =      -692.72  |proj g|=        3.2959
At iterate    11  f =      -693.04  |proj g|=        3.2426
At iterate    12  f =      -693.69  |proj g|=        3.0346
At iterate    13  f =      -693.89  |proj g|=         2.997
At iterate    14  f =      -694.78  |proj g|=        2.9198
At iterate    15  f =      -695.12  |proj g|=        2.9841
At iterate    16  f =      -695.25  |proj g|=        3.1278
At iterate    17  f =      -695.25  |proj g|=        3.1402
At iterate    18  f =      -695.25  |proj g|=        3.1398
At iterate    19  f =      -695.25  |proj g|=        3.1395
At iterate    20  f =      -695.25  |proj g|=        3.1387
At iterate    21  f =      -695.25  |proj g|=        3.1376
At iterate    22  f =      -695.25  |proj g|=        3.1358
At iterate    23  f =      -695.25  |proj g|=        3.1329
At iterate    24  f =      -695.25  |proj g|=        3.1281
At iterate    25  f =      -695.25  |proj g|=        3.1204
At iterate    26  f =      -695.25  |proj g|=        3.1077
At iterate    27  f =      -695.26  |proj g|=        3.0866
At iterate    28  f =      -695.29  |proj g|=        3.0512
At iterate    29  f =      -695.34  |proj g|=        2.9902
At iterate    30  f =      -695.48  |proj g|=        2.8838
At iterate    31  f =      -695.84  |proj g|=        2.6984
At iterate    32  f =       -696.7  |proj g|=        2.3887
At iterate    33  f =      -698.79  |proj g|=         1.516
At iterate    34  f =      -702.19  |proj g|=        0.4817
At iterate    35  f =      -704.59  |proj g|=       0.31262
At iterate    36  f =      -705.37  |proj g|=       0.70626
At iterate    37  f =      -705.38  |proj g|=       0.28582
At iterate    38  f =      -705.38  |proj g|=     0.0046015
At iterate    39  f =      -705.38  |proj g|=     0.0046015

iterations 39
function evaluations 42
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00460145
final function value -705.38

F = -705.38
final  value -705.379950 
converged
 
INFO  [03:00:08.700] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:00:08.778] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:00:08.786] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:00:23.184] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:00:37.687] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:00:53.979] [mlr3]  Finished benchmark 
INFO  [03:00:54.058] [bbotk] Result of batch 140: 
INFO  [03:00:54.060] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:00:54.060] [bbotk]              9.066913                 6.197768                       0.3572002 
INFO  [03:00:54.060] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [03:00:54.060] [bbotk]                     4632        1.003 -0.933807         <NA>   0.9797355 
INFO  [03:00:54.060] [bbotk]                                 uhash 
INFO  [03:00:54.060] [bbotk]  20894dcf-af38-4358-b694-7615866bef33 
DEBUG [03:00:55.302] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.7752e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.7752e-05 0.002163152 
  - best initial criterion value(s) :  670.1896 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -670.19  |proj g|=       1.7048
At iterate     1  f =      -678.56  |proj g|=        3.4532
At iterate     2  f =      -678.93  |proj g|=        3.2159
At iterate     3  f =      -679.26  |proj g|=        2.7747
At iterate     4  f =      -681.45  |proj g|=        2.8483
At iterate     5  f =      -683.02  |proj g|=        2.7383
At iterate     6  f =      -683.11  |proj g|=        2.6263
At iterate     7  f =      -683.16  |proj g|=        2.6787
At iterate     8  f =      -683.16  |proj g|=        2.6715
At iterate     9  f =      -683.16  |proj g|=        2.6712
At iterate    10  f =      -683.16  |proj g|=         2.671

iterations 10
function evaluations 16
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.67104
final function value -683.161

F = -683.161
final  value -683.160521 
converged
 
INFO  [03:00:55.306] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:00:55.364] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:00:55.372] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:01:07.965] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:01:19.555] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:01:30.589] [mlr3]  Finished benchmark 
INFO  [03:01:30.658] [bbotk] Result of batch 141: 
INFO  [03:01:30.660] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:01:30.660] [bbotk]              7.482853                 4.482061                      0.02894299 
INFO  [03:01:30.660] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:01:30.660] [bbotk]                     4103        0.857 -0.9627742         <NA>   0.9649252 
INFO  [03:01:30.660] [bbotk]                                 uhash 
INFO  [03:01:30.660] [bbotk]  8967871e-9f16-46fc-b80e-09afd2a8eb15 
DEBUG [03:01:32.223] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.765059e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.765059e-05 0.002150155 
  - best initial criterion value(s) :  638.3275 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -638.33  |proj g|=       6.1261
At iterate     1  f =      -659.26  |proj g|=        2.9887
At iterate     2  f =       -659.5  |proj g|=        2.9286
At iterate     3  f =      -660.19  |proj g|=         2.714
At iterate     4  f =      -660.76  |proj g|=        2.6462
At iterate     5  f =      -665.09  |proj g|=        2.5058
At iterate     6  f =       -672.9  |proj g|=        2.8844
At iterate     7  f =      -683.87  |proj g|=        3.8491
At iterate     8  f =      -686.37  |proj g|=        4.2442
At iterate     9  f =      -688.21  |proj g|=        4.7808
At iterate    10  f =      -688.54  |proj g|=        5.0152
At iterate    11  f =      -688.58  |proj g|=        5.1088
At iterate    12  f =      -688.58  |proj g|=        5.1259
At iterate    13  f =      -688.58  |proj g|=        5.1286
At iterate    14  f =      -688.58  |proj g|=        5.1407
At iterate    15  f =      -688.59  |proj g|=        5.1555
At iterate    16  f =       -688.6  |proj g|=        5.1824
At iterate    17  f =      -688.62  |proj g|=        5.2239
At iterate    18  f =      -688.68  |proj g|=        5.2915
At iterate    19  f =      -688.85  |proj g|=        5.3978
At iterate    20  f =      -689.27  |proj g|=        5.5599
At iterate    21  f =      -690.32  |proj g|=        5.7684
At iterate    22  f =      -692.74  |proj g|=        5.8679
At iterate    23  f =      -695.78  |proj g|=        4.8282
At iterate    24  f =      -697.86  |proj g|=        4.8042
At iterate    25  f =      -698.26  |proj g|=         4.504
At iterate    26  f =       -698.3  |proj g|=        4.3908
At iterate    27  f =       -698.3  |proj g|=        4.3762
At iterate    28  f =       -698.3  |proj g|=        4.3788
At iterate    29  f =      -698.31  |proj g|=        4.3876
At iterate    30  f =      -698.31  |proj g|=        4.3607
At iterate    31  f =      -698.34  |proj g|=        4.2988
At iterate    32  f =      -698.51  |proj g|=         4.069
At iterate    33  f =      -698.83  |proj g|=        3.7487
At iterate    34  f =      -699.63  |proj g|=        3.2106
At iterate    35  f =      -701.57  |proj g|=        2.4289
At iterate    36  f =      -706.84  |proj g|=        1.5374
At iterate    37  f =      -717.98  |proj g|=       0.39779
At iterate    38  f =      -720.71  |proj g|=       0.35558
At iterate    39  f =      -721.14  |proj g|=       0.66064
At iterate    40  f =      -721.15  |proj g|=       0.65795
At iterate    41  f =      -721.15  |proj g|=       0.65766
At iterate    42  f =      -721.15  |proj g|=     0.0017763
At iterate    43  f =      -721.15  |proj g|=     0.0017764

iterations 43
function evaluations 50
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0017764
final function value -721.154

F = -721.154
final  value -721.153906 
converged
 
INFO  [03:01:32.227] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:01:32.306] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:01:32.313] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:01:45.878] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:01:56.204] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:02:06.710] [mlr3]  Finished benchmark 
INFO  [03:02:06.796] [bbotk] Result of batch 142: 
INFO  [03:02:06.798] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:02:06.798] [bbotk]              4.683685                 7.670487                       0.1593438 
INFO  [03:02:06.798] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [03:02:06.798] [bbotk]                     3647         0.86 -0.936939         <NA>   0.9741794 
INFO  [03:02:06.798] [bbotk]                                 uhash 
INFO  [03:02:06.798] [bbotk]  e4e14f95-2ab2-4088-b623-72eb6cf41515 
DEBUG [03:02:08.411] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.757819e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.757819e-05 0.002148383 
  - best initial criterion value(s) :  669.2878 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -669.29  |proj g|=       6.1067
At iterate     1  f =      -685.28  |proj g|=        7.1317
At iterate     2  f =      -692.08  |proj g|=        5.0741
At iterate     3  f =      -695.93  |proj g|=        1.6848
At iterate     4  f =      -697.28  |proj g|=        2.4033
At iterate     5  f =      -699.34  |proj g|=        2.2953
At iterate     6  f =      -707.42  |proj g|=        1.2285
At iterate     7  f =      -708.44  |proj g|=        1.2352
At iterate     8  f =      -710.39  |proj g|=        1.4674
At iterate     9  f =      -711.45  |proj g|=        1.7187
At iterate    10  f =      -712.07  |proj g|=        1.9676
At iterate    11  f =       -712.3  |proj g|=         1.952
At iterate    12  f =      -712.36  |proj g|=        2.1166
At iterate    13  f =      -712.36  |proj g|=         2.118
At iterate    14  f =      -712.36  |proj g|=        2.1301
At iterate    15  f =      -712.36  |proj g|=        2.1438
At iterate    16  f =      -712.37  |proj g|=        2.1697
At iterate    17  f =      -712.38  |proj g|=        2.2095
At iterate    18  f =      -712.84  |proj g|=        2.3225
At iterate    19  f =      -716.16  |proj g|=        2.8975
At iterate    20  f =      -718.27  |proj g|=        3.0054
At iterate    21  f =      -719.19  |proj g|=        2.6444
At iterate    22  f =       -719.6  |proj g|=        2.7263
At iterate    23  f =      -719.89  |proj g|=         2.659
At iterate    24  f =      -719.92  |proj g|=        2.7681
At iterate    25  f =      -719.92  |proj g|=        2.7531
At iterate    26  f =      -719.92  |proj g|=        2.7535
At iterate    27  f =      -719.92  |proj g|=        2.7567
At iterate    28  f =      -719.92  |proj g|=        2.7619
At iterate    29  f =      -719.93  |proj g|=        2.7777
At iterate    30  f =      -719.93  |proj g|=         2.796
At iterate    31  f =      -719.95  |proj g|=        2.8271
At iterate    32  f =         -720  |proj g|=          2.87
At iterate    33  f =      -720.12  |proj g|=         2.926
At iterate    34  f =      -720.44  |proj g|=        2.9795
At iterate    35  f =      -721.22  |proj g|=        2.9156
At iterate    36  f =      -722.82  |proj g|=        1.6639
At iterate    37  f =      -725.54  |proj g|=       0.68054
At iterate    38  f =      -728.68  |proj g|=       0.68392
At iterate    39  f =      -728.71  |proj g|=       0.68414
At iterate    40  f =      -728.71  |proj g|=       0.68412
At iterate    41  f =      -728.71  |proj g|=       0.68385
At iterate    42  f =      -728.72  |proj g|=       0.68312
At iterate    43  f =      -728.73  |proj g|=       0.68094
At iterate    44  f =      -728.77  |proj g|=       0.41797
At iterate    45  f =      -728.82  |proj g|=       0.32144
At iterate    46  f =      -728.87  |proj g|=       0.65698
At iterate    47  f =      -728.88  |proj g|=       0.52024
At iterate    48  f =      -728.88  |proj g|=     0.0012478
At iterate    49  f =      -728.88  |proj g|=     0.0012474

iterations 49
function evaluations 58
segments explored during Cauchy searches 52
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00124736
final function value -728.879

F = -728.879
final  value -728.878765 
converged
 
INFO  [03:02:08.415] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:02:08.469] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:02:08.476] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:02:18.679] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:02:28.835] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:02:39.631] [mlr3]  Finished benchmark 
INFO  [03:02:39.699] [bbotk] Result of batch 143: 
INFO  [03:02:39.701] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:02:39.701] [bbotk]              3.704267                 5.657236                        0.161132 
INFO  [03:02:39.701] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:02:39.701] [bbotk]                     3641        0.858 -0.9400872         <NA>   0.9721502 
INFO  [03:02:39.701] [bbotk]                                 uhash 
INFO  [03:02:39.701] [bbotk]  4bbd80bf-807e-46e7-9f81-3693b757aa3e 
DEBUG [03:02:41.260] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.749188e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.749188e-05 0.002145343 
  - best initial criterion value(s) :  655.3942 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -655.39  |proj g|=       2.1332
At iterate     1  f =      -682.21  |proj g|=        1.1989
At iterate     2  f =      -693.44  |proj g|=        3.0781
At iterate     3  f =      -702.78  |proj g|=        6.8731
At iterate     4  f =      -710.55  |proj g|=        4.9996
At iterate     5  f =      -712.58  |proj g|=        2.1316
At iterate     6  f =      -715.86  |proj g|=        3.1234
At iterate     7  f =      -716.01  |proj g|=        2.8353
At iterate     8  f =      -716.02  |proj g|=        2.9432
At iterate     9  f =      -716.02  |proj g|=        2.8933
At iterate    10  f =      -716.02  |proj g|=        2.8954
At iterate    11  f =      -716.02  |proj g|=        2.8952

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.8952
final function value -716.018

F = -716.018
final  value -716.017813 
converged
 
INFO  [03:02:41.264] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:02:41.318] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:02:41.325] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:02:51.633] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:03:01.267] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:03:14.534] [mlr3]  Finished benchmark 
INFO  [03:03:14.602] [bbotk] Result of batch 144: 
INFO  [03:03:14.604] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:03:14.604] [bbotk]              3.397216                 4.839824                      0.09910388 
INFO  [03:03:14.604] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:03:14.604] [bbotk]                     3626        1.169 -0.9537953         <NA>   0.9678479 
INFO  [03:03:14.604] [bbotk]                                 uhash 
INFO  [03:03:14.604] [bbotk]  e58f3945-6faa-4166-b4bb-480f6a18180b 
DEBUG [03:03:16.157] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.739175e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.739175e-05 0.002136756 
  - best initial criterion value(s) :  647.9721 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -647.97  |proj g|=       2.5934
At iterate     1  f =       -650.6  |proj g|=        9.5337
At iterate     2  f =      -661.82  |proj g|=        8.8379
At iterate     3  f =      -671.16  |proj g|=        7.1365
At iterate     4  f =      -675.96  |proj g|=        5.2307
At iterate     5  f =      -685.94  |proj g|=        2.7196
At iterate     6  f =       -687.9  |proj g|=        3.3839
At iterate     7  f =      -688.02  |proj g|=        3.3672
At iterate     8  f =      -688.06  |proj g|=        3.3929
At iterate     9  f =      -688.33  |proj g|=        3.5083
At iterate    10  f =       -688.7  |proj g|=        3.6509
At iterate    11  f =      -689.54  |proj g|=        3.8992
At iterate    12  f =      -691.22  |proj g|=        4.1306
At iterate    13  f =      -692.64  |proj g|=        3.8091
At iterate    14  f =       -692.8  |proj g|=        4.0175
At iterate    15  f =      -692.81  |proj g|=        4.0308
At iterate    16  f =      -692.81  |proj g|=        4.0352
At iterate    17  f =      -692.83  |proj g|=        4.0525
At iterate    18  f =      -692.83  |proj g|=        4.0572
At iterate    19  f =      -692.83  |proj g|=        4.0603
At iterate    20  f =      -692.83  |proj g|=         4.061
At iterate    21  f =      -692.83  |proj g|=        4.0611

iterations 21
function evaluations 31
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.06105
final function value -692.827

F = -692.827
final  value -692.826564 
converged
 
INFO  [03:03:16.162] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:03:16.219] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:03:16.226] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:03:27.402] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:03:38.876] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:03:47.160] [mlr3]  Finished benchmark 
INFO  [03:03:47.246] [bbotk] Result of batch 145: 
INFO  [03:03:47.248] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:03:47.248] [bbotk]              5.320761                 7.339225                       0.2791532 
INFO  [03:03:47.248] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:03:47.248] [bbotk]                     3829        0.939 -0.9617996         <NA>   0.9770995 
INFO  [03:03:47.248] [bbotk]                                 uhash 
INFO  [03:03:47.248] [bbotk]  898fd98b-c099-4616-8f98-d9decacf62df 
DEBUG [03:03:49.152] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.735003e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.735003e-05 0.002136337 
  - best initial criterion value(s) :  692.3115 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -692.31  |proj g|=       2.5789
At iterate     1  f =      -707.87  |proj g|=        9.6022
At iterate     2  f =       -710.2  |proj g|=        6.8873
At iterate     3  f =      -710.69  |proj g|=        6.1314
At iterate     4  f =      -711.24  |proj g|=        5.3942
At iterate     5  f =      -711.56  |proj g|=         5.295
At iterate     6  f =      -711.58  |proj g|=        5.9516
At iterate     7  f =      -711.59  |proj g|=          5.76
At iterate     8  f =      -711.59  |proj g|=        5.7412
At iterate     9  f =      -711.59  |proj g|=        5.7207
At iterate    10  f =      -711.59  |proj g|=         5.685
At iterate    11  f =       -711.6  |proj g|=        5.5918
At iterate    12  f =      -711.62  |proj g|=        5.4746
At iterate    13  f =      -711.68  |proj g|=         5.254
At iterate    14  f =      -711.81  |proj g|=        4.9248
At iterate    15  f =      -712.13  |proj g|=        4.4915
At iterate    16  f =      -712.74  |proj g|=        3.9147
At iterate    17  f =      -713.94  |proj g|=        3.2759
At iterate    18  f =      -715.58  |proj g|=           1.3
At iterate    19  f =      -719.69  |proj g|=        1.1325
At iterate    20  f =      -732.28  |proj g|=       0.98655
At iterate    21  f =      -737.87  |proj g|=        2.6839
At iterate    22  f =      -738.17  |proj g|=        2.7951
At iterate    23  f =      -738.83  |proj g|=        2.6424
At iterate    24  f =      -739.14  |proj g|=        2.3153
At iterate    25  f =      -739.19  |proj g|=        2.1056
At iterate    26  f =      -739.19  |proj g|=        2.1566
At iterate    27  f =      -739.19  |proj g|=        2.1523
At iterate    28  f =      -739.19  |proj g|=        2.1548
At iterate    29  f =      -739.19  |proj g|=        2.1645
At iterate    30  f =       -739.2  |proj g|=        2.1776
At iterate    31  f =      -739.21  |proj g|=        2.2013
At iterate    32  f =      -739.24  |proj g|=        2.2239
At iterate    33  f =      -739.31  |proj g|=        2.2489
At iterate    34  f =      -739.49  |proj g|=        2.2415
At iterate    35  f =      -739.93  |proj g|=        2.1651
At iterate    36  f =         -741  |proj g|=        1.8196
At iterate    37  f =      -741.04  |proj g|=       0.66683
At iterate    38  f =      -743.89  |proj g|=        0.6471
At iterate    39  f =      -746.61  |proj g|=       0.67956
At iterate    40  f =      -746.62  |proj g|=       0.66278
At iterate    41  f =      -746.69  |proj g|=       0.66472
At iterate    42  f =      -746.69  |proj g|=       0.66431
At iterate    43  f =      -746.69  |proj g|=       0.39166
At iterate    44  f =      -746.69  |proj g|=      0.093221
At iterate    45  f =      -746.69  |proj g|=     0.0076528
At iterate    46  f =      -746.69  |proj g|=    0.00088004

iterations 46
function evaluations 54
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00088004
final function value -746.693

F = -746.693
final  value -746.693168 
converged
 
INFO  [03:03:49.156] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:03:49.211] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:03:49.218] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:03:56.741] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:04:04.067] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:04:11.292] [mlr3]  Finished benchmark 
INFO  [03:04:11.422] [bbotk] Result of batch 146: 
INFO  [03:04:11.424] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:04:11.424] [bbotk]              3.709621                 7.120155                      0.09025562 
INFO  [03:04:11.424] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:04:11.424] [bbotk]                     3518        1.078 -0.9409531         <NA>   0.9684291 
INFO  [03:04:11.424] [bbotk]                                 uhash 
INFO  [03:04:11.424] [bbotk]  b804e455-2dfa-49ba-a367-27f00b4bcfa8 
DEBUG [03:04:13.625] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.725248e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.725248e-05 0.002127697 
  - best initial criterion value(s) :  668.9353 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -668.94  |proj g|=       5.7007
At iterate     1  f =      -695.07  |proj g|=        1.4296
At iterate     2  f =      -717.27  |proj g|=        4.9633
At iterate     3  f =      -718.41  |proj g|=        3.9733
At iterate     4  f =      -719.79  |proj g|=        3.5691
At iterate     5  f =      -720.42  |proj g|=        3.5549
At iterate     6  f =       -720.7  |proj g|=        4.1217
At iterate     7  f =      -720.71  |proj g|=        4.1118
At iterate     8  f =      -720.71  |proj g|=        4.0641
At iterate     9  f =      -720.71  |proj g|=        4.0753
At iterate    10  f =      -720.71  |proj g|=         4.088
At iterate    11  f =      -720.72  |proj g|=        4.1183
At iterate    12  f =      -720.73  |proj g|=        4.1762
At iterate    13  f =      -720.75  |proj g|=        4.2561
At iterate    14  f =      -720.82  |proj g|=        4.3692
At iterate    15  f =      -720.99  |proj g|=        4.5032
At iterate    16  f =       -721.4  |proj g|=        4.6105
At iterate    17  f =      -722.31  |proj g|=        4.5621
At iterate    18  f =      -723.99  |proj g|=        4.2325
At iterate    19  f =      -727.22  |proj g|=        3.5279
At iterate    20  f =      -728.18  |proj g|=        3.0043
At iterate    21  f =      -728.56  |proj g|=        2.8276
At iterate    22  f =      -728.83  |proj g|=         2.932
At iterate    23  f =      -729.37  |proj g|=        2.8678
At iterate    24  f =      -730.89  |proj g|=        3.3007
At iterate    25  f =      -731.86  |proj g|=        3.7071
At iterate    26  f =      -731.87  |proj g|=         3.561
At iterate    27  f =      -732.52  |proj g|=        3.8188
At iterate    28  f =      -733.24  |proj g|=        3.0023
At iterate    29  f =      -733.51  |proj g|=        3.7108
At iterate    30  f =      -733.52  |proj g|=        3.5763
At iterate    31  f =      -733.52  |proj g|=        3.5703
At iterate    32  f =      -733.52  |proj g|=        3.5817
At iterate    33  f =      -733.52  |proj g|=        3.5785
At iterate    34  f =      -733.52  |proj g|=        3.5783

iterations 34
function evaluations 44
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 3.5783
final function value -733.522

F = -733.522
final  value -733.521787 
converged
 
INFO  [03:04:13.627] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:04:13.679] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:04:13.688] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:04:17.995] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:04:22.420] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:04:26.755] [mlr3]  Finished benchmark 
INFO  [03:04:26.825] [bbotk] Result of batch 147: 
INFO  [03:04:26.827] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:04:26.827] [bbotk]               6.88458                 6.780352                       0.1787818 
INFO  [03:04:26.827] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [03:04:26.827] [bbotk]                     2158        1.401 -0.952993         <NA>   0.9736002 
INFO  [03:04:26.827] [bbotk]                                 uhash 
INFO  [03:04:26.827] [bbotk]  3a9c8bd6-dece-44b5-9daa-6d762c203d69 
DEBUG [03:04:28.404] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.717882e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.717882e-05 0.002120616 
  - best initial criterion value(s) :  691.1892 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -691.19  |proj g|=       14.177
At iterate     1  f =       -700.9  |proj g|=        4.3133
At iterate     2  f =      -712.19  |proj g|=        5.4956
At iterate     3  f =      -717.74  |proj g|=        3.8763
At iterate     4  f =      -724.08  |proj g|=        2.3775
At iterate     5  f =      -728.15  |proj g|=        2.2321
At iterate     6  f =      -730.43  |proj g|=         1.854
At iterate     7  f =      -731.66  |proj g|=        3.4898
At iterate     8  f =      -733.06  |proj g|=         2.631
At iterate     9  f =      -733.57  |proj g|=        2.3116
At iterate    10  f =      -733.76  |proj g|=        2.3184
At iterate    11  f =      -733.85  |proj g|=        2.4225
At iterate    12  f =      -733.86  |proj g|=        2.4775
At iterate    13  f =      -733.87  |proj g|=        2.4817
At iterate    14  f =      -733.87  |proj g|=        2.4862
At iterate    15  f =      -733.87  |proj g|=        2.4956
At iterate    16  f =      -733.87  |proj g|=        2.5122
At iterate    17  f =      -733.87  |proj g|=         2.538
At iterate    18  f =      -733.88  |proj g|=        2.5781
At iterate    19  f =      -733.89  |proj g|=        2.6446
At iterate    20  f =      -733.94  |proj g|=        2.7502
At iterate    21  f =      -734.07  |proj g|=        2.9215
At iterate    22  f =      -734.38  |proj g|=        3.1823
At iterate    23  f =       -735.1  |proj g|=        3.5019
At iterate    24  f =      -736.44  |proj g|=        3.3407
At iterate    25  f =       -736.6  |proj g|=        2.9663
At iterate    26  f =      -736.63  |proj g|=        2.9097
At iterate    27  f =      -736.98  |proj g|=        2.6908
At iterate    28  f =      -740.75  |proj g|=        1.6225
At iterate    29  f =      -745.49  |proj g|=        1.7855
At iterate    30  f =      -749.11  |proj g|=        2.7737
At iterate    31  f =      -749.17  |proj g|=         2.571
At iterate    32  f =      -749.19  |proj g|=        2.6394
At iterate    33  f =      -749.19  |proj g|=        2.6458
At iterate    34  f =      -749.19  |proj g|=        2.6455

iterations 34
function evaluations 40
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.64551
final function value -749.187

F = -749.187
final  value -749.187159 
converged
 
INFO  [03:04:28.408] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:04:28.464] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:04:28.471] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:04:31.027] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:04:33.548] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:04:36.038] [mlr3]  Finished benchmark 
INFO  [03:04:36.138] [bbotk] Result of batch 148: 
INFO  [03:04:36.140] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:04:36.140] [bbotk]              6.624863                 5.907719                       0.4596069 
INFO  [03:04:36.140] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:04:36.140] [bbotk]                     1199        0.906 -0.9455535         <NA>   0.9752257 
INFO  [03:04:36.140] [bbotk]                                 uhash 
INFO  [03:04:36.140] [bbotk]  0ebece52-c48a-46e3-8847-6c3db0a67582 
DEBUG [03:04:37.632] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.711895e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9885163 9596 
  - variance bounds :  1.711895e-05 0.002103074 
  - best initial criterion value(s) :  689.1635 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -689.16  |proj g|=       6.1466
At iterate     1  f =      -733.48  |proj g|=        4.4795
At iterate     2  f =      -739.46  |proj g|=        3.9683
At iterate     3  f =         -749  |proj g|=        2.3473
At iterate     4  f =      -749.54  |proj g|=        1.8148
At iterate     5  f =      -749.65  |proj g|=        1.6938
At iterate     6  f =      -749.85  |proj g|=        1.6115
At iterate     7  f =      -749.91  |proj g|=        1.8426
At iterate     8  f =      -749.95  |proj g|=        1.7114
At iterate     9  f =      -749.95  |proj g|=        1.6943
At iterate    10  f =      -749.95  |proj g|=        1.6947
At iterate    11  f =      -749.95  |proj g|=        1.6991
At iterate    12  f =      -749.96  |proj g|=        1.7196
At iterate    13  f =      -749.98  |proj g|=        1.7427
At iterate    14  f =      -750.04  |proj g|=        1.7704
At iterate    15  f =      -750.18  |proj g|=        1.7235
At iterate    16  f =       -750.2  |proj g|=        1.9065
At iterate    17  f =      -750.52  |proj g|=        1.7023
At iterate    18  f =       -751.4  |proj g|=        1.0582
At iterate    19  f =      -752.86  |proj g|=        0.4397
At iterate    20  f =      -752.97  |proj g|=       0.70521
At iterate    21  f =      -752.97  |proj g|=       0.71862
At iterate    22  f =      -752.97  |proj g|=       0.72027
At iterate    23  f =      -752.97  |proj g|=       0.72098
At iterate    24  f =      -752.97  |proj g|=       0.72101

iterations 24
function evaluations 32
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.721012
final function value -752.972

F = -752.972
final  value -752.971681 
converged
 
INFO  [03:04:37.636] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:04:37.691] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:04:37.698] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:04:40.922] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:04:44.181] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:04:47.444] [mlr3]  Finished benchmark 
INFO  [03:04:47.526] [bbotk] Result of batch 149: 
INFO  [03:04:47.529] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:04:47.529] [bbotk]              7.085822                 6.647618                     0.005320183 
INFO  [03:04:47.529] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:04:47.529] [bbotk]                     1614        0.936 -0.9526331         <NA>   0.9099102 
INFO  [03:04:47.529] [bbotk]                                 uhash 
INFO  [03:04:47.529] [bbotk]  8aca551c-bd8e-4156-a701-f4786ed9d0ac 
DEBUG [03:04:49.692] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.884492e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.884492e-05 0.002255007 
  - best initial criterion value(s) :  684.3466 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -684.35  |proj g|=       11.682
At iterate     1  f =      -704.74  |proj g|=        9.2681
At iterate     2  f =      -714.84  |proj g|=        9.4176
At iterate     3  f =      -718.95  |proj g|=        7.9979
At iterate     4  f =      -721.18  |proj g|=        4.6364
At iterate     5  f =      -722.78  |proj g|=        5.1113
At iterate     6  f =      -723.35  |proj g|=         5.419
At iterate     7  f =      -723.42  |proj g|=        5.2662
At iterate     8  f =      -723.43  |proj g|=        5.2356
At iterate     9  f =      -723.47  |proj g|=        5.1642
At iterate    10  f =      -723.76  |proj g|=        4.9236
At iterate    11  f =      -724.52  |proj g|=        4.5121
At iterate    12  f =      -726.44  |proj g|=        3.8656
At iterate    13  f =       -730.1  |proj g|=        2.6759
At iterate    14  f =      -735.74  |proj g|=        4.1886
At iterate    15  f =      -740.13  |proj g|=        3.9431
At iterate    16  f =      -746.41  |proj g|=        3.3464
At iterate    17  f =      -748.03  |proj g|=        3.4531
At iterate    18  f =      -748.86  |proj g|=        3.6481
At iterate    19  f =      -749.05  |proj g|=        3.8239
At iterate    20  f =      -749.07  |proj g|=        3.9936
At iterate    21  f =      -749.07  |proj g|=        3.9705
At iterate    22  f =      -749.07  |proj g|=        3.9697
At iterate    23  f =      -749.07  |proj g|=        3.9698
At iterate    24  f =      -749.07  |proj g|=        3.9687
At iterate    25  f =      -749.07  |proj g|=        3.9687
At iterate    26  f =      -749.07  |proj g|=        3.9666
At iterate    27  f =      -749.07  |proj g|=        3.9665
At iterate    28  f =      -749.08  |proj g|=        3.9662
At iterate    29  f =       -749.1  |proj g|=        3.9607
At iterate    30  f =      -749.16  |proj g|=        3.9458
At iterate    31  f =      -749.42  |proj g|=        3.8637
At iterate    32  f =      -749.42  |proj g|=        4.0169
At iterate    33  f =      -749.96  |proj g|=        3.7326
At iterate    34  f =      -751.01  |proj g|=        3.2385
At iterate    35  f =      -752.73  |proj g|=        2.5326
At iterate    36  f =      -755.41  |proj g|=        1.7187
At iterate    37  f =      -759.96  |proj g|=       0.90864
At iterate    38  f =      -760.44  |proj g|=       0.34164
At iterate    39  f =      -764.49  |proj g|=       0.31651
At iterate    40  f =      -764.67  |proj g|=       0.55605
At iterate    41  f =      -764.67  |proj g|=       0.14516
At iterate    42  f =      -764.67  |proj g|=     0.0047844
At iterate    43  f =      -764.67  |proj g|=     0.0047846

iterations 43
function evaluations 52
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00478457
final function value -764.67

F = -764.67
final  value -764.669652 
converged
 
INFO  [03:04:49.697] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:04:49.759] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:04:49.797] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:04:51.818] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:04:53.730] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:04:55.690] [mlr3]  Finished benchmark 
INFO  [03:04:55.760] [bbotk] Result of batch 150: 
INFO  [03:04:55.762] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:04:55.762] [bbotk]              6.109895                 6.563135                       0.2242414 
INFO  [03:04:55.762] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:04:55.762] [bbotk]                      872        1.332 -0.9448267         <NA>   0.9687835 
INFO  [03:04:55.762] [bbotk]                                 uhash 
INFO  [03:04:55.762] [bbotk]  e4dfc473-ace9-425d-a8a6-0d5d47818447 
DEBUG [03:04:57.137] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.874229e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.874229e-05 0.002229986 
  - best initial criterion value(s) :  727.2817 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -727.28  |proj g|=      0.87062
At iterate     1  f =       -738.8  |proj g|=        8.2947
At iterate     2  f =      -740.16  |proj g|=        8.2775
At iterate     3  f =      -741.97  |proj g|=        3.7802
At iterate     4  f =      -742.99  |proj g|=        6.2201
At iterate     5  f =      -743.25  |proj g|=        5.5826
At iterate     6  f =      -743.26  |proj g|=        5.3106
At iterate     7  f =      -743.27  |proj g|=        5.5591
At iterate     8  f =      -743.27  |proj g|=        5.5182
At iterate     9  f =      -743.27  |proj g|=        5.5174

iterations 9
function evaluations 12
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 5.51743
final function value -743.272

F = -743.272
final  value -743.271967 
converged
 
INFO  [03:04:57.141] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:04:57.196] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:04:57.203] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:05:08.042] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:05:19.025] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:05:32.399] [mlr3]  Finished benchmark 
INFO  [03:05:32.471] [bbotk] Result of batch 151: 
INFO  [03:05:32.473] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:05:32.473] [bbotk]              4.313697                 9.966152                       0.2570977 
INFO  [03:05:32.473] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:05:32.473] [bbotk]                     4218        0.961 -0.9576558         <NA>   0.9762605 
INFO  [03:05:32.473] [bbotk]                                 uhash 
INFO  [03:05:32.473] [bbotk]  cd7db7ff-53bd-4d8c-a6f5-bd8dbe2081ed 
DEBUG [03:05:34.064] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.868725e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.868725e-05 0.00222822 
  - best initial criterion value(s) :  688.002 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -688  |proj g|=        1.947
At iterate     1  f =      -698.42  |proj g|=        5.9866
At iterate     2  f =      -727.88  |proj g|=         1.061
At iterate     3  f =      -733.59  |proj g|=       0.84543
At iterate     4  f =      -743.73  |proj g|=        1.3431
At iterate     5  f =      -746.17  |proj g|=         1.722
At iterate     6  f =      -747.52  |proj g|=        2.3489
At iterate     7  f =      -748.17  |proj g|=        3.0387
At iterate     8  f =      -748.36  |proj g|=        3.5691
At iterate     9  f =      -748.39  |proj g|=        3.6318
At iterate    10  f =      -748.39  |proj g|=        3.7464
At iterate    11  f =      -748.39  |proj g|=        3.7377
At iterate    12  f =      -748.39  |proj g|=        3.7364
At iterate    13  f =       -748.4  |proj g|=        3.7289
At iterate    14  f =       -748.4  |proj g|=        3.7206
At iterate    15  f =       -748.4  |proj g|=        3.7045
At iterate    16  f =       -748.4  |proj g|=        3.6939
At iterate    17  f =      -748.41  |proj g|=        3.6429
At iterate    18  f =      -748.42  |proj g|=        3.6297
At iterate    19  f =       -748.5  |proj g|=        3.6027
At iterate    20  f =      -749.06  |proj g|=        3.4994
At iterate    21  f =      -754.24  |proj g|=        3.4099
At iterate    22  f =      -754.47  |proj g|=        3.2049
At iterate    23  f =      -754.47  |proj g|=        3.1207
At iterate    24  f =      -754.47  |proj g|=        3.1503
At iterate    25  f =      -754.47  |proj g|=        3.1511
At iterate    26  f =      -754.47  |proj g|=        3.1529
At iterate    27  f =      -754.47  |proj g|=        3.2645
At iterate    28  f =      -754.48  |proj g|=        3.2032
At iterate    29  f =       -754.5  |proj g|=        3.1129
At iterate    30  f =      -754.56  |proj g|=        2.9676
At iterate    31  f =       -754.7  |proj g|=        2.7253
At iterate    32  f =      -755.03  |proj g|=        2.3749
At iterate    33  f =      -755.77  |proj g|=        1.9308
At iterate    34  f =      -757.07  |proj g|=        1.5145
At iterate    35  f =      -758.63  |proj g|=       0.74895
At iterate    36  f =      -762.14  |proj g|=       0.37313
At iterate    37  f =      -769.58  |proj g|=       0.29864
At iterate    38  f =      -769.71  |proj g|=       0.70102
At iterate    39  f =      -769.71  |proj g|=      0.036115
At iterate    40  f =      -769.71  |proj g|=     0.0044664

iterations 40
function evaluations 47
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 3
norm of the final projected gradient 0.00446638
final function value -769.709

F = -769.709
final  value -769.709473 
converged
 
INFO  [03:05:34.068] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:05:34.125] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:05:34.132] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:05:43.109] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:05:52.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:06:01.769] [mlr3]  Finished benchmark 
INFO  [03:06:01.870] [bbotk] Result of batch 152: 
INFO  [03:06:01.872] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:06:01.872] [bbotk]              5.173645                 7.450903                       0.1914984 
INFO  [03:06:01.872] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:06:01.872] [bbotk]                     2704        0.881 -0.9346533         <NA>   0.9741589 
INFO  [03:06:01.872] [bbotk]                                 uhash 
INFO  [03:06:01.872] [bbotk]  b3dacd54-c35d-4971-b017-b412d81b0cd4 
DEBUG [03:06:03.783] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.861324e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.861324e-05 0.002228306 
  - best initial criterion value(s) :  712.2624 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -712.26  |proj g|=       7.1688
At iterate     1  f =      -715.95  |proj g|=        10.124
At iterate     2  f =      -758.79  |proj g|=        1.6519
At iterate     3  f =      -760.53  |proj g|=         2.792
At iterate     4  f =      -762.21  |proj g|=        2.5036
At iterate     5  f =      -769.43  |proj g|=        1.6274
At iterate     6  f =      -770.69  |proj g|=        1.5787
At iterate     7  f =      -771.64  |proj g|=        1.6309
At iterate     8  f =      -772.25  |proj g|=        1.7526
At iterate     9  f =       -772.6  |proj g|=        2.0218
At iterate    10  f =      -772.72  |proj g|=        2.0105
At iterate    11  f =      -772.73  |proj g|=        2.0359
At iterate    12  f =      -772.73  |proj g|=        2.0438
At iterate    13  f =      -772.73  |proj g|=        2.0449
At iterate    14  f =      -772.73  |proj g|=         2.048
At iterate    15  f =      -772.73  |proj g|=        2.0518
At iterate    16  f =      -772.73  |proj g|=        2.0584
At iterate    17  f =      -772.73  |proj g|=        2.0674
At iterate    18  f =      -772.74  |proj g|=        2.0785
At iterate    19  f =      -772.75  |proj g|=        2.0926
At iterate    20  f =      -772.79  |proj g|=        2.1109
At iterate    21  f =       -772.8  |proj g|=        2.1177
At iterate    22  f =       -772.9  |proj g|=        2.0868
At iterate    23  f =      -773.18  |proj g|=        2.0229
At iterate    24  f =      -773.74  |proj g|=        1.9483
At iterate    25  f =      -774.95  |proj g|=        1.9466
At iterate    26  f =      -775.88  |proj g|=        1.9444
At iterate    27  f =       -775.9  |proj g|=        1.9444
At iterate    28  f =         -776  |proj g|=         1.943
At iterate    29  f =         -776  |proj g|=         1.943
At iterate    30  f =      -776.02  |proj g|=        1.9434
At iterate    31  f =      -776.02  |proj g|=        1.9432
At iterate    32  f =      -776.02  |proj g|=        1.9428
At iterate    33  f =      -776.02  |proj g|=        1.9419
At iterate    34  f =      -776.02  |proj g|=        1.9388
At iterate    35  f =      -776.02  |proj g|=         1.938
At iterate    36  f =      -776.04  |proj g|=        1.9302
At iterate    37  f =      -776.06  |proj g|=        1.9081
At iterate    38  f =      -776.14  |proj g|=        1.8521
At iterate    39  f =      -776.31  |proj g|=        1.7131
At iterate    40  f =       -776.7  |proj g|=        1.3787
At iterate    41  f =      -777.54  |proj g|=       0.62705
At iterate    42  f =      -777.76  |proj g|=       0.38625
At iterate    43  f =      -778.27  |proj g|=        0.3782
At iterate    44  f =      -778.97  |proj g|=       0.35803
At iterate    45  f =      -780.16  |proj g|=        0.7007
At iterate    46  f =      -780.39  |proj g|=       0.70033
At iterate    47  f =       -780.4  |proj g|=       0.28885
At iterate    48  f =       -780.4  |proj g|=       0.16194
At iterate    49  f =       -780.4  |proj g|=      0.064871
At iterate    50  f =       -780.4  |proj g|=      0.013416

iterations 50
function evaluations 61
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0134161
final function value -780.404

F = -780.404
final  value -780.404284 
converged
 
INFO  [03:06:03.788] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:06:03.859] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:06:03.867] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:06:11.356] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:06:18.319] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:06:25.914] [mlr3]  Finished benchmark 
INFO  [03:06:25.985] [bbotk] Result of batch 153: 
INFO  [03:06:25.987] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:06:25.987] [bbotk]              7.769056                 7.231226                       0.4558429 
INFO  [03:06:25.987] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:06:25.987] [bbotk]                     2642        1.052 -0.9446042         <NA>   0.9783834 
INFO  [03:06:25.987] [bbotk]                                 uhash 
INFO  [03:06:25.987] [bbotk]  5797f781-dfdc-444a-8af9-151169201dc7 
DEBUG [03:06:27.521] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.85825e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.85825e-05 0.002227592 
  - best initial criterion value(s) :  662.2454 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -662.25  |proj g|=       13.384
At iterate     1  f =      -666.66  |proj g|=         10.67
At iterate     2  f =      -721.39  |proj g|=        8.3438
At iterate     3  f =      -723.94  |proj g|=        6.8849
At iterate     4  f =      -731.46  |proj g|=        3.9351
At iterate     5  f =      -731.92  |proj g|=        3.7687
At iterate     6  f =      -731.94  |proj g|=        3.6761
At iterate     7  f =      -731.95  |proj g|=        3.6882
At iterate     8  f =      -731.95  |proj g|=        3.6867
At iterate     9  f =      -731.95  |proj g|=        3.6855
At iterate    10  f =      -731.95  |proj g|=        3.6817
At iterate    11  f =      -731.95  |proj g|=        3.6767
At iterate    12  f =      -731.95  |proj g|=        3.6673
At iterate    13  f =      -731.95  |proj g|=        3.6528
At iterate    14  f =      -731.95  |proj g|=        3.6475
At iterate    15  f =      -731.96  |proj g|=        3.6201
At iterate    16  f =      -731.99  |proj g|=        3.5861
At iterate    17  f =      -732.06  |proj g|=        3.5158
At iterate    18  f =      -732.22  |proj g|=        3.3793
At iterate    19  f =      -732.64  |proj g|=        3.2024
At iterate    20  f =      -733.66  |proj g|=        3.3953
At iterate    21  f =      -736.05  |proj g|=        3.8696
At iterate    22  f =      -740.41  |proj g|=        4.3125
At iterate    23  f =      -740.72  |proj g|=        5.3858
At iterate    24  f =      -744.44  |proj g|=           4.8
At iterate    25  f =      -746.66  |proj g|=        4.2641
At iterate    26  f =       -747.6  |proj g|=        4.9469
At iterate    27  f =      -747.66  |proj g|=        4.9544
At iterate    28  f =      -747.67  |proj g|=        4.9738
At iterate    29  f =      -747.67  |proj g|=          4.98
At iterate    30  f =      -747.67  |proj g|=        4.9814
At iterate    31  f =      -747.67  |proj g|=        4.9815

iterations 31
function evaluations 41
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 4.98148
final function value -747.665

F = -747.665
final  value -747.665159 
converged
 
INFO  [03:06:27.525] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:06:27.584] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:06:27.617] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:06:39.733] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:06:52.307] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:07:04.689] [mlr3]  Finished benchmark 
INFO  [03:07:04.760] [bbotk] Result of batch 154: 
INFO  [03:07:04.762] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:07:04.762] [bbotk]              4.826971                 3.903293                       0.4007143 
INFO  [03:07:04.762] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [03:07:04.762] [bbotk]                     3955        0.871 -0.960973         <NA>   0.9778849 
INFO  [03:07:04.762] [bbotk]                                 uhash 
INFO  [03:07:04.762] [bbotk]  9cbd614f-2b2b-4799-b2db-7aa401c227de 
DEBUG [03:07:06.232] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.854535e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.854535e-05 0.002229117 
  - best initial criterion value(s) :  737.2267 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -737.23  |proj g|=        5.538
At iterate     1  f =       -738.4  |proj g|=        5.7709
At iterate     2  f =      -739.99  |proj g|=        5.4188
At iterate     3  f =      -743.78  |proj g|=        3.0293
At iterate     4  f =      -744.82  |proj g|=        3.9272
At iterate     5  f =       -745.1  |proj g|=        3.7503
At iterate     6  f =      -745.12  |proj g|=        3.6244
At iterate     7  f =      -745.12  |proj g|=        3.6516
At iterate     8  f =      -745.12  |proj g|=        3.6502
At iterate     9  f =      -745.12  |proj g|=        3.6468
At iterate    10  f =      -745.13  |proj g|=        3.6391
At iterate    11  f =      -745.14  |proj g|=        3.6086
At iterate    12  f =      -745.19  |proj g|=        3.5459
At iterate    13  f =      -745.31  |proj g|=        3.4369
At iterate    14  f =      -745.64  |proj g|=         3.221
At iterate    15  f =      -745.83  |proj g|=        2.6096
At iterate    16  f =      -746.96  |proj g|=        2.5973
At iterate    17  f =      -748.97  |proj g|=        2.3603
At iterate    18  f =      -753.82  |proj g|=        1.7047
At iterate    19  f =      -757.15  |proj g|=        1.3248
At iterate    20  f =      -757.66  |proj g|=        1.5607
At iterate    21  f =      -758.16  |proj g|=         1.242
At iterate    22  f =      -758.32  |proj g|=       0.43669
At iterate    23  f =      -758.43  |proj g|=        0.8369
At iterate    24  f =      -758.44  |proj g|=       0.77165
At iterate    25  f =      -758.44  |proj g|=       0.76072
At iterate    26  f =      -758.44  |proj g|=        0.7611

iterations 26
function evaluations 33
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.761098
final function value -758.439

F = -758.439
final  value -758.438991 
converged
 
INFO  [03:07:06.236] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:07:06.296] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:07:06.304] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:07:11.506] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:07:16.715] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:07:23.154] [mlr3]  Finished benchmark 
INFO  [03:07:23.276] [bbotk] Result of batch 155: 
INFO  [03:07:23.277] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:07:23.277] [bbotk]              8.532572                 6.268038                       0.3512846 
INFO  [03:07:23.277] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:07:23.277] [bbotk]                     1974        0.883 -0.9576821         <NA>   0.9768242 
INFO  [03:07:23.277] [bbotk]                                 uhash 
INFO  [03:07:23.277] [bbotk]  ab642df1-c06f-4e95-bfa9-5678938b4317 
DEBUG [03:07:24.997] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.849619e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.849619e-05 0.002217485 
  - best initial criterion value(s) :  750.5651 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -750.57  |proj g|=        3.818
At iterate     1  f =      -755.15  |proj g|=        4.8797
At iterate     2  f =       -755.5  |proj g|=        4.7759
At iterate     3  f =      -755.59  |proj g|=        4.6633
At iterate     4  f =       -755.6  |proj g|=        4.6848
At iterate     5  f =       -755.6  |proj g|=        4.6949
At iterate     6  f =      -755.63  |proj g|=         4.753
At iterate     7  f =      -755.68  |proj g|=         4.828
At iterate     8  f =      -755.73  |proj g|=        4.9237
At iterate     9  f =      -755.77  |proj g|=        4.9394
At iterate    10  f =      -755.77  |proj g|=        4.9346
At iterate    11  f =      -755.77  |proj g|=        4.9337
At iterate    12  f =      -755.77  |proj g|=        4.9252
At iterate    13  f =      -755.77  |proj g|=        4.9146
At iterate    14  f =      -755.77  |proj g|=        4.8932
At iterate    15  f =      -755.78  |proj g|=        4.8588
At iterate    16  f =       -755.8  |proj g|=        4.7969
At iterate    17  f =      -755.86  |proj g|=        4.6943
At iterate    18  f =      -755.97  |proj g|=        4.5509
At iterate    19  f =      -755.99  |proj g|=        4.4774
At iterate    20  f =      -756.24  |proj g|=        4.2943
At iterate    21  f =      -770.96  |proj g|=        4.4749
At iterate    22  f =      -773.99  |proj g|=        4.8928
At iterate    23  f =      -774.97  |proj g|=        5.1666
At iterate    24  f =      -774.97  |proj g|=        5.1677
At iterate    25  f =      -774.97  |proj g|=        5.1013
At iterate    26  f =      -774.98  |proj g|=        5.1063
At iterate    27  f =      -774.98  |proj g|=        5.1072
At iterate    28  f =      -774.98  |proj g|=        5.1073
At iterate    29  f =      -774.98  |proj g|=        5.1076
At iterate    30  f =      -774.98  |proj g|=        5.1084
At iterate    31  f =      -774.98  |proj g|=        5.1092

iterations 31
function evaluations 38
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 5.1092
final function value -774.979

F = -774.979
final  value -774.979124 
converged
 
INFO  [03:07:25.001] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:07:25.062] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:07:25.069] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:07:27.035] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:07:28.972] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:07:31.090] [mlr3]  Finished benchmark 
INFO  [03:07:31.205] [bbotk] Result of batch 156: 
INFO  [03:07:31.207] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:07:31.207] [bbotk]              2.069749                 9.742519                       0.2786151 
INFO  [03:07:31.207] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:07:31.207] [bbotk]                      656        1.065 -0.9577989         <NA>   0.9483119 
INFO  [03:07:31.207] [bbotk]                                 uhash 
INFO  [03:07:31.207] [bbotk]  dff9a47e-8a99-4b97-a662-b7ae15469f7f 
DEBUG [03:07:32.512] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.858609e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.858609e-05 0.002230545 
  - best initial criterion value(s) :  717.8297 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -717.83  |proj g|=       6.2151
At iterate     1  f =      -736.13  |proj g|=        11.374
At iterate     2  f =      -740.09  |proj g|=        10.475
At iterate     3  f =      -749.15  |proj g|=        7.4241
At iterate     4  f =      -751.13  |proj g|=        5.7638
At iterate     5  f =      -754.33  |proj g|=        5.6637
At iterate     6  f =      -755.87  |proj g|=        7.9763
At iterate     7  f =      -756.18  |proj g|=        6.6725
At iterate     8  f =      -756.19  |proj g|=        6.9193
At iterate     9  f =      -756.19  |proj g|=        6.8826
At iterate    10  f =      -756.19  |proj g|=        6.8791
At iterate    11  f =      -756.19  |proj g|=        6.8793

iterations 11
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 6.87934
final function value -756.189

F = -756.189
final  value -756.188713 
converged
 
INFO  [03:07:32.517] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:07:32.582] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:07:32.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:07:37.335] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:07:42.082] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:07:46.501] [mlr3]  Finished benchmark 
INFO  [03:07:46.586] [bbotk] Result of batch 157: 
INFO  [03:07:46.588] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:07:46.588] [bbotk]              3.482599                 9.895719                       0.1752251 
INFO  [03:07:46.588] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:07:46.588] [bbotk]                     1136        0.893 -0.9618561         <NA>   0.9627699 
INFO  [03:07:46.588] [bbotk]                                 uhash 
INFO  [03:07:46.588] [bbotk]  9ee6764f-7217-4832-ae2f-312276dfb9cf 
DEBUG [03:07:48.571] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.849634e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.849634e-05 0.002214242 
  - best initial criterion value(s) :  768.6723 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -768.67  |proj g|=       2.9953
At iterate     1  f =      -770.25  |proj g|=        8.5949
At iterate     2  f =       -772.7  |proj g|=        7.8554
At iterate     3  f =      -777.68  |proj g|=        5.7137
At iterate     4  f =      -778.62  |proj g|=        4.8562
At iterate     5  f =      -780.52  |proj g|=        4.8954
At iterate     6  f =      -780.77  |proj g|=        6.5104
At iterate     7  f =      -781.14  |proj g|=        5.7414
At iterate     8  f =      -781.15  |proj g|=         5.738
At iterate     9  f =      -781.15  |proj g|=        5.7584
At iterate    10  f =      -781.15  |proj g|=        5.7555
At iterate    11  f =      -781.15  |proj g|=        5.7539
At iterate    12  f =      -781.15  |proj g|=        5.7485
At iterate    13  f =      -781.15  |proj g|=        5.7415
At iterate    14  f =      -781.15  |proj g|=        5.7295
At iterate    15  f =      -781.15  |proj g|=        5.7111
At iterate    16  f =      -781.15  |proj g|=         5.682
At iterate    17  f =      -781.16  |proj g|=        5.6429
At iterate    18  f =      -781.17  |proj g|=        5.6048
At iterate    19  f =      -781.19  |proj g|=        5.5472
At iterate    20  f =      -781.25  |proj g|=        5.5539
At iterate    21  f =      -781.31  |proj g|=        5.1659
At iterate    22  f =      -781.47  |proj g|=         5.258
At iterate    23  f =      -782.51  |proj g|=        5.3836
At iterate    24  f =       -784.8  |proj g|=        5.0538
At iterate    25  f =      -788.31  |proj g|=        4.1976
At iterate    26  f =      -789.09  |proj g|=        4.6854
At iterate    27  f =      -793.33  |proj g|=        2.8865
At iterate    28  f =      -793.41  |proj g|=        3.1422
At iterate    29  f =      -793.42  |proj g|=        3.1149
At iterate    30  f =      -793.42  |proj g|=         3.111
At iterate    31  f =      -793.42  |proj g|=        3.1091
At iterate    32  f =      -793.42  |proj g|=        3.1074
At iterate    33  f =      -793.42  |proj g|=        3.1037
At iterate    34  f =      -793.42  |proj g|=        3.0982
At iterate    35  f =      -793.42  |proj g|=         3.089
At iterate    36  f =      -793.42  |proj g|=        3.0741
At iterate    37  f =      -793.42  |proj g|=         3.049
At iterate    38  f =      -793.43  |proj g|=         3.007
At iterate    39  f =      -793.45  |proj g|=         2.936
At iterate    40  f =      -793.51  |proj g|=        2.8176
At iterate    41  f =      -793.67  |proj g|=        2.6327
At iterate    42  f =         -794  |proj g|=        2.4022
At iterate    43  f =      -794.54  |proj g|=        2.2942
At iterate    44  f =      -794.96  |proj g|=        2.5409
At iterate    45  f =      -795.03  |proj g|=        2.5632
At iterate    46  f =      -795.04  |proj g|=        2.5753
At iterate    47  f =      -795.04  |proj g|=        2.5816
At iterate    48  f =      -795.04  |proj g|=        2.5786
At iterate    49  f =      -795.04  |proj g|=        2.5834
At iterate    50  f =      -795.04  |proj g|=        2.5886
At iterate    51  f =      -795.04  |proj g|=        2.6035
At iterate    52  f =      -795.05  |proj g|=        2.6218
At iterate    53  f =      -795.07  |proj g|=        2.6484
At iterate    54  f =      -795.12  |proj g|=          2.67
At iterate    55  f =      -795.22  |proj g|=        2.6401
At iterate    56  f =      -795.42  |proj g|=        2.4727
At iterate    57  f =      -795.44  |proj g|=        2.5554
At iterate    58  f =      -795.71  |proj g|=        2.3081
At iterate    59  f =      -798.69  |proj g|=        1.6412
At iterate    60  f =      -800.18  |proj g|=        1.0409
At iterate    61  f =      -801.61  |proj g|=       0.70502
At iterate    62  f =      -801.79  |proj g|=        0.2921
At iterate    63  f =       -801.8  |proj g|=        0.7023
At iterate    64  f =       -801.8  |proj g|=       0.56728
At iterate    65  f =       -801.8  |proj g|=      0.012428
At iterate    66  f =       -801.8  |proj g|=      0.012426

iterations 66
function evaluations 77
segments explored during Cauchy searches 69
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0124259
final function value -801.801

F = -801.801
final  value -801.800757 
converged
 
INFO  [03:07:48.575] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:07:48.634] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:07:48.642] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:07:50.863] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:07:52.504] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:07:54.871] [mlr3]  Finished benchmark 
INFO  [03:07:54.949] [bbotk] Result of batch 158: 
INFO  [03:07:54.951] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:07:54.951] [bbotk]              9.630152                 6.372909                       0.2688947 
INFO  [03:07:54.951] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:07:54.951] [bbotk]                      535        0.905 -0.9481183         <NA>   0.9676053 
INFO  [03:07:54.951] [bbotk]                                 uhash 
INFO  [03:07:54.951] [bbotk]  746e491b-0cfd-4f69-ad79-8355c0d61bde 
DEBUG [03:07:56.654] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.839815e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.839815e-05 0.002188201 
  - best initial criterion value(s) :  741.6324 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -741.63  |proj g|=       13.868
At iterate     1  f =      -761.09  |proj g|=        11.765
At iterate     2  f =       -778.1  |proj g|=        9.3638
At iterate     3  f =      -787.58  |proj g|=         5.368
At iterate     4  f =      -791.22  |proj g|=        3.4385
At iterate     5  f =       -792.6  |proj g|=        2.2746
At iterate     6  f =      -793.71  |proj g|=        2.7679
At iterate     7  f =      -793.75  |proj g|=         2.563
At iterate     8  f =      -793.75  |proj g|=        2.5313
At iterate     9  f =      -793.75  |proj g|=        2.4975
At iterate    10  f =      -793.78  |proj g|=         2.386
At iterate    11  f =      -793.86  |proj g|=        2.1837
At iterate    12  f =      -794.06  |proj g|=        1.8542
At iterate    13  f =      -794.58  |proj g|=        1.2763
At iterate    14  f =      -795.82  |proj g|=       0.81966
At iterate    15  f =      -796.38  |proj g|=        1.1046
At iterate    16  f =      -799.41  |proj g|=       0.89404
At iterate    17  f =      -801.47  |proj g|=       0.78017
At iterate    18  f =      -803.78  |proj g|=       0.75185
At iterate    19  f =      -804.83  |proj g|=       0.72877
At iterate    20  f =      -805.18  |proj g|=       0.51417
At iterate    21  f =       -805.2  |proj g|=       0.70974
At iterate    22  f =      -805.24  |proj g|=       0.51424
At iterate    23  f =      -805.25  |proj g|=       0.70281
At iterate    24  f =      -805.25  |proj g|=       0.51374
At iterate    25  f =      -805.25  |proj g|=       0.51373
At iterate    26  f =      -805.25  |proj g|=       0.51371
At iterate    27  f =      -805.25  |proj g|=       0.51371

iterations 27
function evaluations 34
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.513711
final function value -805.25

F = -805.25
final  value -805.249643 
converged
 
INFO  [03:07:56.658] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:07:56.715] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:07:56.722] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:08:03.115] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:08:09.476] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:08:16.025] [mlr3]  Finished benchmark 
INFO  [03:08:16.111] [bbotk] Result of batch 159: 
INFO  [03:08:16.113] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:08:16.113] [bbotk]              6.333631                  6.55992                       0.2679724 
INFO  [03:08:16.113] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:08:16.113] [bbotk]                     2183        1.073 -0.9487359         <NA>   0.9753259 
INFO  [03:08:16.113] [bbotk]                                 uhash 
INFO  [03:08:16.113] [bbotk]  97fe5dfc-b5c2-4e57-bc00-9dfcacbb56a5 
DEBUG [03:08:17.419] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.833721e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.833721e-05 0.002183691 
  - best initial criterion value(s) :  775.9762 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -775.98  |proj g|=        1.779
At iterate     1  f =      -785.69  |proj g|=        3.8949
At iterate     2  f =      -789.55  |proj g|=        3.2692
At iterate     3  f =      -791.83  |proj g|=        2.7161
At iterate     4  f =      -792.18  |proj g|=        2.3184
At iterate     5  f =      -792.32  |proj g|=        2.4568
At iterate     6  f =      -792.44  |proj g|=        2.4861
At iterate     7  f =      -793.15  |proj g|=        2.5749
At iterate     8  f =      -793.38  |proj g|=         2.499
At iterate     9  f =      -793.42  |proj g|=        2.4115
At iterate    10  f =      -793.42  |proj g|=          2.42
At iterate    11  f =      -793.42  |proj g|=        2.4191
At iterate    12  f =      -793.42  |proj g|=        2.4191

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.41905
final function value -793.421

F = -793.421
final  value -793.421332 
converged
 
INFO  [03:08:17.423] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:08:17.481] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:08:17.488] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:08:25.981] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:08:34.322] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:08:43.966] [mlr3]  Finished benchmark 
INFO  [03:08:44.034] [bbotk] Result of batch 160: 
INFO  [03:08:44.036] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:08:44.036] [bbotk]               7.13916                 5.107927                       0.4401193 
INFO  [03:08:44.036] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:08:44.036] [bbotk]                     2878          0.9 -0.9562634         <NA>   0.9783924 
INFO  [03:08:44.036] [bbotk]                                 uhash 
INFO  [03:08:44.036] [bbotk]  2ed1e1a9-a9d0-4746-ad37-24e868cc74b2 
DEBUG [03:08:45.644] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.830803e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.830803e-05 0.002187006 
  - best initial criterion value(s) :  766.7157 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -766.72  |proj g|=       5.0511
At iterate     1  f =      -778.43  |proj g|=        3.3492
At iterate     2  f =      -789.11  |proj g|=        3.4809
At iterate     3  f =      -791.81  |proj g|=        3.1792
At iterate     4  f =      -793.38  |proj g|=        2.9473
At iterate     5  f =      -793.79  |proj g|=        2.9178
At iterate     6  f =      -793.96  |proj g|=        3.0294
At iterate     7  f =      -794.04  |proj g|=        3.4163
At iterate     8  f =      -794.04  |proj g|=        3.4382
At iterate     9  f =      -794.04  |proj g|=        3.4449
At iterate    10  f =      -794.04  |proj g|=        3.4693
At iterate    11  f =      -794.04  |proj g|=        3.4927
At iterate    12  f =      -794.05  |proj g|=        3.5398
At iterate    13  f =      -794.06  |proj g|=        3.6095
At iterate    14  f =      -794.09  |proj g|=        3.7245
At iterate    15  f =      -794.16  |proj g|=        3.9005
At iterate    16  f =      -794.36  |proj g|=        4.1633
At iterate    17  f =      -794.88  |proj g|=          4.48
At iterate    18  f =      -796.17  |proj g|=        4.5105
At iterate    19  f =      -797.24  |proj g|=        3.3471
At iterate    20  f =      -797.25  |proj g|=        3.4523
At iterate    21  f =      -797.27  |proj g|=         3.508
At iterate    22  f =      -797.38  |proj g|=        3.6965
At iterate    23  f =      -797.61  |proj g|=        3.9223
At iterate    24  f =       -798.2  |proj g|=        4.2124
At iterate    25  f =      -799.47  |proj g|=        4.3088
At iterate    26  f =      -800.86  |proj g|=        3.1517
At iterate    27  f =      -802.85  |proj g|=        3.6212
At iterate    28  f =      -814.35  |proj g|=        3.2173
At iterate    29  f =      -814.93  |proj g|=        3.0338
At iterate    30  f =      -816.34  |proj g|=        2.5125
At iterate    31  f =      -816.43  |proj g|=        2.7153
At iterate    32  f =      -816.53  |proj g|=          2.68
At iterate    33  f =      -816.53  |proj g|=        2.6419
At iterate    34  f =      -816.53  |proj g|=        2.6631
At iterate    35  f =      -816.53  |proj g|=        2.6604
At iterate    36  f =      -816.53  |proj g|=        2.6603

iterations 36
function evaluations 40
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.66034
final function value -816.529

F = -816.529
final  value -816.528691 
converged
 
INFO  [03:08:45.648] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:08:45.706] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:08:45.712] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:08:52.108] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:08:58.487] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:09:04.646] [mlr3]  Finished benchmark 
INFO  [03:09:04.715] [bbotk] Result of batch 161: 
INFO  [03:09:04.717] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:09:04.717] [bbotk]              3.526188                 8.801662                       0.1267119 
INFO  [03:09:04.717] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [03:09:04.717] [bbotk]                     2103         0.91 -0.950034         <NA>   0.9660058 
INFO  [03:09:04.717] [bbotk]                                 uhash 
INFO  [03:09:04.717] [bbotk]  4f18e2c5-0823-41c4-973b-baaf78c1818a 
DEBUG [03:09:06.405] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.821281e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.821281e-05 0.002175533 
  - best initial criterion value(s) :  789.0037 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -789  |proj g|=       6.1276
At iterate     1  f =      -798.81  |proj g|=        1.8948
At iterate     2  f =      -799.24  |proj g|=        2.1761
At iterate     3  f =      -799.28  |proj g|=        2.4831
At iterate     4  f =      -799.31  |proj g|=         2.356
At iterate     5  f =      -799.31  |proj g|=        2.3037
At iterate     6  f =      -799.33  |proj g|=        2.2529
At iterate     7  f =      -799.34  |proj g|=        2.1106
At iterate     8  f =      -799.41  |proj g|=        2.1296
At iterate     9  f =      -799.67  |proj g|=        2.1844
At iterate    10  f =      -800.32  |proj g|=        2.2479
At iterate    11  f =      -802.03  |proj g|=        2.2946
At iterate    12  f =      -805.06  |proj g|=        2.2196
At iterate    13  f =      -805.15  |proj g|=        2.2998
At iterate    14  f =      -807.96  |proj g|=        2.0481
At iterate    15  f =         -809  |proj g|=        1.7032
At iterate    16  f =      -809.32  |proj g|=        1.7506
At iterate    17  f =      -809.33  |proj g|=        1.8394
At iterate    18  f =      -809.35  |proj g|=         1.786
At iterate    19  f =      -809.35  |proj g|=        1.7854
At iterate    20  f =      -809.35  |proj g|=        1.7861
At iterate    21  f =      -809.35  |proj g|=        1.7861

iterations 21
function evaluations 30
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.7861
final function value -809.353

F = -809.353
final  value -809.352844 
converged
 
INFO  [03:09:06.409] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:09:06.466] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:09:06.472] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:09:11.522] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:09:15.842] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:09:21.814] [mlr3]  Finished benchmark 
INFO  [03:09:21.901] [bbotk] Result of batch 162: 
INFO  [03:09:21.903] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:09:21.903] [bbotk]              7.563545                 8.507796                       0.1976929 
INFO  [03:09:21.903] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:09:21.903] [bbotk]                     1845        1.091 -0.9514702         <NA>   0.9734719 
INFO  [03:09:21.903] [bbotk]                                 uhash 
INFO  [03:09:21.903] [bbotk]  9456b27c-da66-4974-a6da-ab4a3864a05b 
DEBUG [03:09:23.723] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.813895e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.813895e-05 0.00216159 
  - best initial criterion value(s) :  773.4898 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -773.49  |proj g|=       8.6049
At iterate     1  f =       -804.5  |proj g|=         2.401
At iterate     2  f =      -810.06  |proj g|=        4.4894
At iterate     3  f =      -812.31  |proj g|=        4.1326
At iterate     4  f =      -813.67  |proj g|=        3.6551
At iterate     5  f =      -813.92  |proj g|=         3.564
At iterate     6  f =      -814.05  |proj g|=        3.6367
At iterate     7  f =      -814.15  |proj g|=        3.9171
At iterate     8  f =      -814.15  |proj g|=        3.9912
At iterate     9  f =      -814.15  |proj g|=        4.0013
At iterate    10  f =      -814.15  |proj g|=        4.0031
At iterate    11  f =      -814.15  |proj g|=        4.0103
At iterate    12  f =      -814.15  |proj g|=        4.0199
At iterate    13  f =      -814.15  |proj g|=        4.0344
At iterate    14  f =      -814.16  |proj g|=        4.0568
At iterate    15  f =      -814.16  |proj g|=        4.0955
At iterate    16  f =      -814.17  |proj g|=        4.1536
At iterate    17  f =      -814.19  |proj g|=         4.243
At iterate    18  f =      -814.25  |proj g|=        4.3438
At iterate    19  f =      -814.33  |proj g|=        4.3453
At iterate    20  f =      -814.37  |proj g|=        4.1446
At iterate    21  f =      -814.38  |proj g|=        4.1257
At iterate    22  f =      -814.39  |proj g|=        4.1255
At iterate    23  f =      -814.42  |proj g|=        4.0524
At iterate    24  f =      -814.49  |proj g|=        4.0316
At iterate    25  f =       -814.7  |proj g|=        3.8082
At iterate    26  f =       -815.1  |proj g|=        3.8595
At iterate    27  f =      -815.82  |proj g|=        3.2524
At iterate    28  f =      -817.77  |proj g|=        2.5254
At iterate    29  f =      -823.99  |proj g|=        1.3999
At iterate    30  f =       -824.7  |proj g|=        0.8692
At iterate    31  f =      -831.13  |proj g|=       0.74211
At iterate    32  f =      -834.94  |proj g|=       0.79554
At iterate    33  f =      -834.98  |proj g|=       0.65793
At iterate    34  f =      -834.99  |proj g|=       0.67755
At iterate    35  f =      -834.99  |proj g|=       0.67841
At iterate    36  f =      -834.99  |proj g|=       0.67763
At iterate    37  f =      -834.99  |proj g|=       0.67449
At iterate    38  f =      -834.99  |proj g|=       0.67059
At iterate    39  f =      -834.99  |proj g|=       0.66293
At iterate    40  f =      -834.99  |proj g|=        0.7032
At iterate    41  f =      -834.99  |proj g|=       0.63777
At iterate    42  f =      -834.99  |proj g|=       0.70442
At iterate    43  f =      -835.05  |proj g|=       0.70746
At iterate    44  f =      -835.27  |proj g|=       0.71232
At iterate    45  f =      -835.57  |proj g|=       0.70634
At iterate    46  f =      -835.71  |proj g|=       0.69698
At iterate    47  f =      -835.71  |proj g|=       0.69627
At iterate    48  f =      -835.74  |proj g|=       0.68905
At iterate    49  f =      -835.74  |proj g|=       0.02283
At iterate    50  f =      -835.74  |proj g|=     0.0044767
At iterate    51  f =      -835.74  |proj g|=     0.0044768

iterations 51
function evaluations 58
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00447683
final function value -835.743

F = -835.743
final  value -835.742609 
converged
 
INFO  [03:09:23.727] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:09:23.780] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:09:23.786] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:09:34.156] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:09:45.237] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:09:56.441] [mlr3]  Finished benchmark 
INFO  [03:09:56.515] [bbotk] Result of batch 163: 
INFO  [03:09:56.517] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:09:56.517] [bbotk]              8.642791                 2.832196                       0.1465583 
INFO  [03:09:56.517] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:09:56.517] [bbotk]                     3443        0.914 -0.9437347         <NA>   0.9754115 
INFO  [03:09:56.517] [bbotk]                                 uhash 
INFO  [03:09:56.517] [bbotk]  ea93fc56-1586-41d8-bd3b-bac70b6b6be0 
DEBUG [03:09:58.289] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.808024e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.808024e-05 0.002164455 
  - best initial criterion value(s) :  787.187 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -787.19  |proj g|=       2.4381
At iterate     1  f =      -789.25  |proj g|=        12.503
At iterate     2  f =      -794.48  |proj g|=        12.578
At iterate     3  f =      -800.45  |proj g|=        10.611
At iterate     4  f =      -801.08  |proj g|=        9.9776
At iterate     5  f =      -803.06  |proj g|=        8.2726
At iterate     6  f =      -803.85  |proj g|=        6.7011
At iterate     7  f =      -803.95  |proj g|=        7.6374
At iterate     8  f =      -803.96  |proj g|=        7.3501
At iterate     9  f =      -803.96  |proj g|=        7.3451
At iterate    10  f =      -803.96  |proj g|=        7.3464
At iterate    11  f =      -803.96  |proj g|=        7.3535
At iterate    12  f =      -803.96  |proj g|=        7.3611
At iterate    13  f =      -803.96  |proj g|=        7.3758
At iterate    14  f =      -803.96  |proj g|=        7.3987
At iterate    15  f =      -803.97  |proj g|=        7.4322
At iterate    16  f =      -803.97  |proj g|=        7.4709
At iterate    17  f =      -803.99  |proj g|=        7.4877
At iterate    18  f =      -804.02  |proj g|=        7.4165
At iterate    19  f =      -804.07  |proj g|=        7.2541
At iterate    20  f =      -804.07  |proj g|=        7.3101
At iterate    21  f =      -804.16  |proj g|=        7.0916
At iterate    22  f =      -819.06  |proj g|=        4.1138
At iterate    23  f =      -830.44  |proj g|=        1.9338
At iterate    24  f =      -835.41  |proj g|=         2.157
At iterate    25  f =      -836.46  |proj g|=        2.2026
At iterate    26  f =       -836.5  |proj g|=        2.2011
At iterate    27  f =       -836.6  |proj g|=        2.2183
At iterate    28  f =      -836.62  |proj g|=        2.2227
At iterate    29  f =      -836.62  |proj g|=        2.2235
At iterate    30  f =      -836.62  |proj g|=        2.2235
At iterate    31  f =      -836.62  |proj g|=        2.2235
At iterate    32  f =      -836.62  |proj g|=        2.2235

iterations 32
function evaluations 38
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.22349
final function value -836.619

F = -836.619
final  value -836.619022 
converged
 
INFO  [03:09:58.293] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:09:58.347] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:09:58.354] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:10:04.342] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:10:10.364] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:10:15.083] [mlr3]  Finished benchmark 
INFO  [03:10:15.153] [bbotk] Result of batch 164: 
INFO  [03:10:15.154] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:10:15.154] [bbotk]              3.249178                 3.510605                       0.4743243 
INFO  [03:10:15.154] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:10:15.154] [bbotk]                     1881        1.081 -0.9441454         <NA>   0.9722319 
INFO  [03:10:15.154] [bbotk]                                 uhash 
INFO  [03:10:15.154] [bbotk]  881d10a5-f47d-4b07-b9e2-3498d5eeaac6 
DEBUG [03:10:16.750] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.800012e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.800012e-05 0.002151299 
  - best initial criterion value(s) :  756.521 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -756.52  |proj g|=       3.8865
At iterate     1  f =      -759.31  |proj g|=        4.4865
At iterate     2  f =      -773.97  |proj g|=        3.3645
At iterate     3  f =      -780.51  |proj g|=        2.3866
At iterate     4  f =      -780.81  |proj g|=        2.5197
At iterate     5  f =      -780.81  |proj g|=         2.516
At iterate     6  f =      -780.81  |proj g|=        2.5172
At iterate     7  f =      -780.81  |proj g|=        2.5179
At iterate     8  f =      -780.81  |proj g|=        2.5201
At iterate     9  f =      -780.81  |proj g|=        2.5234
At iterate    10  f =      -780.81  |proj g|=        2.5353
At iterate    11  f =      -780.83  |proj g|=        2.5356
At iterate    12  f =      -780.86  |proj g|=        2.5319
At iterate    13  f =      -780.94  |proj g|=        2.5169
At iterate    14  f =      -781.14  |proj g|=        2.4683
At iterate    15  f =       -781.6  |proj g|=        2.3384
At iterate    16  f =      -782.49  |proj g|=         2.156
At iterate    17  f =      -782.88  |proj g|=        1.7948
At iterate    18  f =      -784.23  |proj g|=        1.5418
At iterate    19  f =      -787.19  |proj g|=        1.0485
At iterate    20  f =      -789.86  |proj g|=       0.49259
At iterate    21  f =      -789.93  |proj g|=       0.49662
At iterate    22  f =      -789.99  |proj g|=       0.50137
At iterate    23  f =      -790.02  |proj g|=       0.63408
At iterate    24  f =      -790.02  |proj g|=       0.64197
At iterate    25  f =      -790.02  |proj g|=       0.64013
At iterate    26  f =      -790.02  |proj g|=       0.64015

iterations 26
function evaluations 37
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.64015
final function value -790.023

F = -790.023
final  value -790.022854 
converged
 
INFO  [03:10:16.755] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:10:16.810] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:10:16.817] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:10:18.313] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:10:20.340] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:10:21.813] [mlr3]  Finished benchmark 
INFO  [03:10:21.913] [bbotk] Result of batch 165: 
INFO  [03:10:21.915] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:10:21.915] [bbotk]              8.277802                 4.173278                       0.1918333 
INFO  [03:10:21.915] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:10:21.915] [bbotk]                      444        0.915 -0.9584603         <NA>   0.9614201 
INFO  [03:10:21.915] [bbotk]                                 uhash 
INFO  [03:10:21.915] [bbotk]  d2f7d96a-bc0e-4646-87d8-fb2937ef7a2b 
DEBUG [03:10:23.774] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.79249e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.79249e-05 0.002134431 
  - best initial criterion value(s) :  795.9616 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -795.96  |proj g|=       6.9463
At iterate     1  f =      -796.35  |proj g|=          7.25
At iterate     2  f =      -802.36  |proj g|=         7.396
At iterate     3  f =       -806.7  |proj g|=        7.1048
At iterate     4  f =      -806.98  |proj g|=        6.7437
At iterate     5  f =      -807.32  |proj g|=        6.7251
At iterate     6  f =      -807.78  |proj g|=         6.426
At iterate     7  f =      -808.08  |proj g|=        5.9926
At iterate     8  f =      -810.33  |proj g|=           5.2
At iterate     9  f =      -821.54  |proj g|=        3.5899
At iterate    10  f =      -826.91  |proj g|=        3.1106
At iterate    11  f =      -831.84  |proj g|=        2.2113
At iterate    12  f =      -832.18  |proj g|=        2.3724
At iterate    13  f =      -832.18  |proj g|=        2.4253
At iterate    14  f =      -832.18  |proj g|=        2.4127
At iterate    15  f =      -832.18  |proj g|=        2.4325
At iterate    16  f =      -832.18  |proj g|=         2.435
At iterate    17  f =      -832.18  |proj g|=        2.4356
At iterate    18  f =      -832.18  |proj g|=        2.4391
At iterate    19  f =      -832.18  |proj g|=        2.4462
At iterate    20  f =      -832.19  |proj g|=        2.4616
At iterate    21  f =      -832.19  |proj g|=        2.4732
At iterate    22  f =       -832.2  |proj g|=        2.5745
At iterate    23  f =      -832.23  |proj g|=        2.5379
At iterate    24  f =      -832.33  |proj g|=         2.403
At iterate    25  f =      -832.51  |proj g|=        2.2015
At iterate    26  f =      -832.95  |proj g|=           1.8
At iterate    27  f =      -833.65  |proj g|=        1.6155
At iterate    28  f =      -833.76  |proj g|=        1.5442
At iterate    29  f =       -834.7  |proj g|=        1.7974
At iterate    30  f =      -835.23  |proj g|=        2.1586
At iterate    31  f =      -835.31  |proj g|=        2.1313
At iterate    32  f =      -835.32  |proj g|=        2.1266
At iterate    33  f =      -835.39  |proj g|=         2.117
At iterate    34  f =      -835.61  |proj g|=        2.0611
At iterate    35  f =      -836.24  |proj g|=        1.8622
At iterate    36  f =      -837.28  |proj g|=        1.1989
At iterate    37  f =      -838.46  |proj g|=        1.1157
At iterate    38  f =      -839.19  |proj g|=       0.75983
At iterate    39  f =      -839.83  |proj g|=       0.31613
At iterate    40  f =      -839.97  |proj g|=       0.31706
At iterate    41  f =         -840  |proj g|=       0.31497
At iterate    42  f =      -840.03  |proj g|=       0.31141
At iterate    43  f =      -840.18  |proj g|=       0.29723
At iterate    44  f =      -840.26  |proj g|=       0.28838
At iterate    45  f =      -840.28  |proj g|=       0.48377
At iterate    46  f =      -840.28  |proj g|=      0.028664
At iterate    47  f =      -840.28  |proj g|=      0.021154
At iterate    48  f =      -840.28  |proj g|=      0.021154

iterations 48
function evaluations 60
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0211542
final function value -840.279

F = -840.279
final  value -840.278523 
converged
 
INFO  [03:10:23.779] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:10:23.834] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:10:23.841] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:10:29.382] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:10:33.588] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:10:39.325] [mlr3]  Finished benchmark 
INFO  [03:10:39.395] [bbotk] Result of batch 166: 
INFO  [03:10:39.397] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:10:39.397] [bbotk]              3.372151                 4.907111                       0.3967729 
INFO  [03:10:39.397] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:10:39.397] [bbotk]                     1538        0.906 -0.9496702         <NA>    0.970951 
INFO  [03:10:39.397] [bbotk]                                 uhash 
INFO  [03:10:39.397] [bbotk]  570286e4-8d08-45c9-8123-fcb332f8e2cd 
DEBUG [03:10:41.127] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.784068e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.784068e-05 0.002120474 
  - best initial criterion value(s) :  774.8241 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -774.82  |proj g|=       1.9107
At iterate     1  f =      -785.31  |proj g|=        1.4518
At iterate     2  f =      -785.36  |proj g|=        1.4163
At iterate     3  f =      -785.38  |proj g|=        1.3825
At iterate     4  f =      -785.38  |proj g|=        1.3783
At iterate     5  f =      -785.38  |proj g|=        1.3783
At iterate     6  f =      -785.38  |proj g|=        1.3785
At iterate     7  f =      -785.38  |proj g|=        1.3789
At iterate     8  f =      -785.38  |proj g|=        1.3793
At iterate     9  f =      -785.38  |proj g|=        1.3802
At iterate    10  f =      -785.38  |proj g|=        1.3805
At iterate    11  f =      -785.38  |proj g|=        1.3832
At iterate    12  f =      -785.38  |proj g|=        1.3833
At iterate    13  f =      -785.38  |proj g|=        1.3824
At iterate    14  f =      -785.46  |proj g|=        1.3659
At iterate    15  f =      -785.74  |proj g|=        1.3005
At iterate    16  f =      -786.65  |proj g|=         1.059
At iterate    17  f =      -786.66  |proj g|=        1.0244
At iterate    18  f =      -787.75  |proj g|=       0.26974
At iterate    19  f =      -788.28  |proj g|=       0.25683
At iterate    20  f =      -788.71  |proj g|=       0.77083
At iterate    21  f =      -788.75  |proj g|=       0.54004
At iterate    22  f =      -788.75  |proj g|=       0.58503
At iterate    23  f =      -788.75  |proj g|=       0.58621
At iterate    24  f =      -788.75  |proj g|=       0.58642
At iterate    25  f =      -788.75  |proj g|=        0.5863

iterations 25
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.586299
final function value -788.753

F = -788.753
final  value -788.753021 
converged
 
INFO  [03:10:41.131] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:10:41.188] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:10:41.217] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:10:48.083] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:10:54.921] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:11:00.490] [mlr3]  Finished benchmark 
INFO  [03:11:00.559] [bbotk] Result of batch 167: 
INFO  [03:11:00.561] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:11:00.561] [bbotk]              5.397875                 5.255067                       0.3027421 
INFO  [03:11:00.561] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:11:00.561] [bbotk]                     2290         1.08 -0.9601109         <NA>   0.9755291 
INFO  [03:11:00.561] [bbotk]                                 uhash 
INFO  [03:11:00.561] [bbotk]  06e9ed15-fca6-41af-96f9-4b899e4ec68a 
DEBUG [03:11:02.320] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.778518e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.778518e-05 0.002115304 
  - best initial criterion value(s) :  796.827 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -796.83  |proj g|=       6.3976
At iterate     1  f =      -840.21  |proj g|=        4.1867
At iterate     2  f =      -843.84  |proj g|=         3.472
At iterate     3  f =      -847.48  |proj g|=        2.5026
At iterate     4  f =      -848.19  |proj g|=        2.6607
At iterate     5  f =      -849.55  |proj g|=        2.7049
At iterate     6  f =      -852.84  |proj g|=        2.5907
At iterate     7  f =      -855.36  |proj g|=        2.4096
At iterate     8  f =      -855.89  |proj g|=        2.3169
At iterate     9  f =      -855.98  |proj g|=        2.2753
At iterate    10  f =         -856  |proj g|=        2.2712
At iterate    11  f =      -856.01  |proj g|=        2.2593
At iterate    12  f =      -856.01  |proj g|=        2.2586
At iterate    13  f =      -856.01  |proj g|=        2.2579
At iterate    14  f =      -856.01  |proj g|=        2.2561
At iterate    15  f =      -856.01  |proj g|=        2.2533
At iterate    16  f =      -856.01  |proj g|=        2.2488
At iterate    17  f =      -856.02  |proj g|=        2.2406
At iterate    18  f =      -856.04  |proj g|=        2.2258
At iterate    19  f =      -856.09  |proj g|=        2.2025
At iterate    20  f =       -856.2  |proj g|=        2.1501
At iterate    21  f =      -856.22  |proj g|=        2.1482
At iterate    22  f =      -856.46  |proj g|=        2.0823
At iterate    23  f =      -858.86  |proj g|=        1.9912
At iterate    24  f =       -859.9  |proj g|=        1.9844
At iterate    25  f =      -860.19  |proj g|=        1.9871
At iterate    26  f =      -860.25  |proj g|=        1.9865
At iterate    27  f =      -860.25  |proj g|=        1.9863
At iterate    28  f =      -860.25  |proj g|=        1.9864
At iterate    29  f =      -860.25  |proj g|=        1.9864

iterations 29
function evaluations 33
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.98639
final function value -860.248

F = -860.248
final  value -860.248353 
converged
 
INFO  [03:11:02.324] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:11:02.394] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:11:02.401] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:11:07.263] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:11:13.579] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:11:19.050] [mlr3]  Finished benchmark 
INFO  [03:11:19.165] [bbotk] Result of batch 168: 
INFO  [03:11:19.167] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:11:19.167] [bbotk]              9.901358                 9.251776                      0.01626497 
INFO  [03:11:19.167] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:11:19.167] [bbotk]                     1867        1.083 -0.9411593         <NA>    0.946419 
INFO  [03:11:19.167] [bbotk]                                 uhash 
INFO  [03:11:19.167] [bbotk]  ea7bef15-944f-49c5-b084-760dccca3d76 
DEBUG [03:11:21.101] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.791318e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.89138 15.77119 0.9886744 9596 
  - variance bounds :  1.791318e-05 0.002121819 
  - best initial criterion value(s) :  785.4694 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -785.47  |proj g|=       11.657
At iterate     1  f =      -793.54  |proj g|=          10.6
At iterate     2  f =      -803.91  |proj g|=        9.2443
At iterate     3  f =      -815.16  |proj g|=        4.2627
At iterate     4  f =       -819.8  |proj g|=        4.9485
At iterate     5  f =      -820.51  |proj g|=        4.6269
At iterate     6  f =      -820.75  |proj g|=        4.3132
At iterate     7  f =      -820.76  |proj g|=        4.3633
At iterate     8  f =      -820.76  |proj g|=        4.3579
At iterate     9  f =      -820.76  |proj g|=        4.3572
At iterate    10  f =      -820.76  |proj g|=        4.3525
At iterate    11  f =      -820.76  |proj g|=        4.3471
At iterate    12  f =      -820.76  |proj g|=         4.337
At iterate    13  f =      -820.77  |proj g|=        4.3216
At iterate    14  f =      -820.79  |proj g|=        4.2954
At iterate    15  f =      -820.83  |proj g|=        4.2506
At iterate    16  f =      -820.96  |proj g|=        4.1684
At iterate    17  f =      -821.31  |proj g|=        4.0103
At iterate    18  f =      -822.32  |proj g|=        3.6905
At iterate    19  f =      -825.17  |proj g|=        3.0372
At iterate    20  f =      -832.32  |proj g|=        1.8866
At iterate    21  f =      -842.56  |proj g|=        1.7932
At iterate    22  f =      -848.26  |proj g|=       0.41324
At iterate    23  f =      -851.46  |proj g|=       0.94689
At iterate    24  f =      -852.19  |proj g|=        1.6214
At iterate    25  f =       -852.3  |proj g|=        1.9138
At iterate    26  f =      -852.31  |proj g|=         1.986
At iterate    27  f =      -852.32  |proj g|=        2.0309
At iterate    28  f =      -852.33  |proj g|=        2.0821
At iterate    29  f =       -852.4  |proj g|=        2.2263
At iterate    30  f =      -852.53  |proj g|=        2.4067
At iterate    31  f =       -852.8  |proj g|=        2.6356
At iterate    32  f =      -853.18  |proj g|=         2.788
At iterate    33  f =      -853.75  |proj g|=        1.9334
At iterate    34  f =      -853.82  |proj g|=        2.2334
At iterate    35  f =      -853.82  |proj g|=        2.2319
At iterate    36  f =      -853.82  |proj g|=        2.2317
At iterate    37  f =      -853.82  |proj g|=        2.2317
At iterate    38  f =      -853.82  |proj g|=        2.2265
At iterate    39  f =      -853.83  |proj g|=        2.2267
At iterate    40  f =      -854.06  |proj g|=        2.1777
At iterate    41  f =      -854.97  |proj g|=         1.893
At iterate    42  f =      -856.94  |proj g|=        1.1725
At iterate    43  f =      -858.78  |proj g|=       0.63053
At iterate    44  f =      -858.85  |proj g|=       0.40774
At iterate    45  f =      -860.26  |proj g|=       0.31724
At iterate    46  f =      -860.37  |proj g|=       0.39012
At iterate    47  f =      -860.38  |proj g|=       0.30179
At iterate    48  f =      -860.38  |proj g|=       0.21453
At iterate    49  f =      -860.38  |proj g|=     0.0041237
At iterate    50  f =      -860.38  |proj g|=     0.0041241

iterations 50
function evaluations 58
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00412411
final function value -860.381

F = -860.381
final  value -860.380840 
converged
 
INFO  [03:11:21.105] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:11:21.163] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:11:21.170] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:11:26.945] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:11:32.545] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:11:37.780] [mlr3]  Finished benchmark 
INFO  [03:11:37.853] [bbotk] Result of batch 169: 
INFO  [03:11:37.855] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:11:37.855] [bbotk]              9.313594                  5.12265                       0.4726413 
INFO  [03:11:37.855] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:11:37.855] [bbotk]                     1854        0.944 -0.9436423         <NA>   0.9760615 
INFO  [03:11:37.855] [bbotk]                                 uhash 
INFO  [03:11:37.855] [bbotk]  345b2372-41bd-48ea-8d4b-4a57992b80ef 
DEBUG [03:11:37.926] [bbotk]  
INFO  [03:11:37.939] [bbotk] Finished optimizing after 200 evaluation(s) 
INFO  [03:11:37.940] [bbotk] Result: 
INFO  [03:11:37.943] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:11:37.943] [bbotk]              9.066913                 6.197768                       0.3572002 
INFO  [03:11:37.943] [bbotk]  ps_cboost_anneal1.mstop learner_param_vals  x_domain classif.auc 
INFO  [03:11:37.943] [bbotk]                     4632         <list[18]> <list[4]>   0.9797355 
INFO  [03:11:56.873] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1.tuned' on task 'spam' (iter 5/5) 
INFO  [03:11:56.968] [bbotk] Starting to optimize 4 parameter(s) with '<OptimizerInterMBO>' and '<TerminatorEvals> [n_evals=200]' 
DEBUG [03:11:57.036] [bbotk]  
INFO  [03:11:57.043] [bbotk] Evaluating 32 configuration(s) 
INFO  [03:11:58.471] [mlr3]  Running benchmark with 96 resampling iterations 
INFO  [03:11:58.483] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:12:11.481] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:12:13.488] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:12:16.782] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:12:30.127] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:12:39.858] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:12:48.541] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:12:51.700] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:13:06.019] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:13:17.740] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:13:32.346] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:13:47.618] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:13:49.190] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:13:53.670] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:14:00.406] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:14:02.701] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:14:18.578] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:14:19.858] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:14:22.562] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:14:31.873] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:14:40.688] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:14:54.453] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:15:05.577] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:15:09.156] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:15:15.155] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:15:24.312] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:15:27.717] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:15:29.405] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:15:35.914] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:15:43.904] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:15:45.081] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:15:47.395] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:15:52.095] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:15:54.791] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:16:09.063] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:16:13.442] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:16:20.052] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:16:31.447] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:16:33.994] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:16:43.204] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:16:51.885] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:16:59.450] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:17:02.286] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:17:12.959] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:17:23.925] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:17:29.002] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:17:32.873] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:17:37.486] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:17:50.458] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:17:55.478] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:18:06.848] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:18:16.107] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:18:21.225] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:18:36.353] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:18:42.430] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:18:54.463] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:19:07.233] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:19:16.725] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:19:25.325] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:19:27.167] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:19:32.449] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:19:41.015] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:19:50.681] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:20:00.432] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:20:11.417] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:20:16.605] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:20:23.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:20:32.863] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:20:38.279] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:20:48.014] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:20:52.755] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:20:58.739] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:21:05.641] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:21:18.364] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:21:21.948] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:21:26.613] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:21:34.700] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:21:35.881] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:21:41.051] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:21:46.966] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:21:54.032] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:22:02.361] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:22:16.657] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:22:18.552] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:22:25.004] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:22:39.551] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:22:44.561] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:22:58.234] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:23:09.693] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:23:19.330] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:23:31.030] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:23:39.133] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:23:52.663] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:23:57.007] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:24:13.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:24:17.169] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:24:22.939] [mlr3]  Finished benchmark 
INFO  [03:24:24.719] [bbotk] Result of batch 1: 
INFO  [03:24:24.722] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:24:24.722] [bbotk]              3.050434                 6.558666                      0.38083517 
INFO  [03:24:24.722] [bbotk]              5.000799                 4.916522                      0.26718202 
INFO  [03:24:24.722] [bbotk]              6.246932                 8.450404                      0.30159283 
INFO  [03:24:24.722] [bbotk]              3.446836                 3.660809                      0.18410118 
INFO  [03:24:24.722] [bbotk]              7.659943                 5.206991                      0.41183430 
INFO  [03:24:24.722] [bbotk]              4.906970                 6.055770                      0.08426489 
INFO  [03:24:24.722] [bbotk]              5.531788                 6.483234                      0.45928555 
INFO  [03:24:24.722] [bbotk]              6.579098                 3.316453                      0.16899680 
INFO  [03:24:24.722] [bbotk]              6.443999                 3.996970                      0.21090999 
INFO  [03:24:24.722] [bbotk]              8.710547                 7.353447                      0.10050570 
INFO  [03:24:24.722] [bbotk]              4.660330                 4.678327                      0.36913313 
INFO  [03:24:24.722] [bbotk]              2.305486                 6.939133                      0.25036374 
INFO  [03:24:24.722] [bbotk]              6.974033                 7.957716                      0.32606005 
INFO  [03:24:24.722] [bbotk]              2.597172                 7.173216                      0.28214073 
INFO  [03:24:24.722] [bbotk]              2.881245                 9.057623                      0.06338811 
INFO  [03:24:24.722] [bbotk]              5.334284                 2.818901                      0.03810875 
INFO  [03:24:24.722] [bbotk]              7.245441                 2.724526                      0.34151231 
INFO  [03:24:24.722] [bbotk]              9.378711                 8.782053                      0.49295153 
INFO  [03:24:24.722] [bbotk]              5.964647                 8.543203                      0.21965937 
INFO  [03:24:24.722] [bbotk]              9.978018                 5.832453                      0.19258562 
INFO  [03:24:24.722] [bbotk]              8.134658                 3.012926                      0.39690976 
INFO  [03:24:24.722] [bbotk]              8.499265                 9.398248                      0.42859722 
INFO  [03:24:24.722] [bbotk]              8.798469                 5.372406                      0.12498091 
INFO  [03:24:24.722] [bbotk]              4.399094                 5.721503                      0.05016621 
INFO  [03:24:24.722] [bbotk]              3.872151                 4.237967                      0.26152316 
INFO  [03:24:24.722] [bbotk]              7.907476                 8.021870                      0.01306494 
INFO  [03:24:24.722] [bbotk]              4.146068                 7.696949                      0.47412836 
INFO  [03:24:24.722] [bbotk]              7.319096                 2.219189                      0.01857396 
INFO  [03:24:24.722] [bbotk]              9.023775                 9.859678                      0.15306263 
INFO  [03:24:24.722] [bbotk]              3.665234                 2.259186                      0.34868620 
INFO  [03:24:24.722] [bbotk]              9.544419                 4.448098                      0.44715316 
INFO  [03:24:24.722] [bbotk]              2.118372                 9.732961                      0.14021233 
INFO  [03:24:24.722] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:24:24.722] [bbotk]  ps_cboost_anneal1.mstop classif.auc                                uhash 
INFO  [03:24:24.722] [bbotk]                     3247   0.9687612 3385e01e-3022-4809-9ac4-8220b89bd465 
INFO  [03:24:24.722] [bbotk]                     1091   0.9683126 bd3d9aae-66a9-4019-9021-db77eccf36b3 
INFO  [03:24:24.722] [bbotk]                     2140   0.9729859 ef25602e-541f-446f-b12f-117146c32866 
INFO  [03:24:24.722] [bbotk]                     3858   0.9685187 e031042b-610e-45aa-beac-720546e7a254 
INFO  [03:24:24.722] [bbotk]                     3401   0.9754371 5dadd128-b82a-467f-b931-7e20ffac67ac 
INFO  [03:24:24.722] [bbotk]                     1381   0.9590231 a6f751c5-5218-46f8-87bd-aae01877bf70 
INFO  [03:24:24.722] [bbotk]                      497   0.9672253 e43d1f24-c170-4c24-a61c-52ebb185442d 
INFO  [03:24:24.722] [bbotk]                      889   0.9637253 f458bd34-1af9-4e8b-8d54-f9a9506ed925 
INFO  [03:24:24.722] [bbotk]                     3715   0.9736904 eae620f0-49b4-4d83-a3f4-c018648c6bbb 
INFO  [03:24:24.722] [bbotk]                     2898   0.9697730 4ada3ab7-f18c-4f22-9c7a-9b39d1c94dac 
INFO  [03:24:24.722] [bbotk]                     2560   0.9733234 068cde0e-abf5-4e95-9685-55847419b24a 
INFO  [03:24:24.722] [bbotk]                     1927   0.9548863 d7133828-442d-40f8-928c-7cced777dac5 
INFO  [03:24:24.722] [bbotk]                     3158   0.9746147 0d76e9a0-12a7-4d0a-8550-82aa696796b6 
INFO  [03:24:24.722] [bbotk]                     4059   0.9647460 023a55f5-3008-4ac2-baa8-0f80e3e3f685 
INFO  [03:24:24.722] [bbotk]                     4633   0.9578624 28564cfb-7c40-4b1c-a225-9634db7809c7 
INFO  [03:24:24.722] [bbotk]                     4507   0.9641088 0960a11c-2f6c-42e6-b0ec-45e37c10901d 
INFO  [03:24:24.722] [bbotk]                     2345   0.9738837 edc3ebc8-7b9a-4111-90b4-b307501451c1 
INFO  [03:24:24.722] [bbotk]                     3597   0.9731231 a77cbfa8-1d1c-47ae-91d9-13352e7bd62b 
INFO  [03:24:24.722] [bbotk]                      236   0.9503656 2cf1d882-38da-4e9e-8023-27f7f58367b3 
INFO  [03:24:24.722] [bbotk]                      593   0.9626897 b1488d76-93e1-4317-95cb-2b6e0ac6e54f 
INFO  [03:24:24.722] [bbotk]                     4826   0.9748695 143b0c89-65c9-4ea9-92bc-a3564536138c 
INFO  [03:24:24.722] [bbotk]                     1457   0.9729424 6cd12031-9782-43e9-8c0e-3b4f68130f0d 
INFO  [03:24:24.722] [bbotk]                     4221   0.9722818 44bf12e8-8467-4d7b-a9c9-fcbfe65bf3a7 
INFO  [03:24:24.722] [bbotk]                     2991   0.9604937 a3634c6b-61db-4852-b99c-68bdebd98f01 
INFO  [03:24:24.722] [bbotk]                      756   0.9616784 ef3459f5-dd47-42e0-8b01-ed914053dda2 
INFO  [03:24:24.722] [bbotk]                     1575   0.9348509 e38dd46b-020b-4e53-b59f-23caf9ac5f8d 
INFO  [03:24:24.722] [bbotk]                     2623   0.9732706 4c74ccb2-78d9-4e19-957a-ca6512ab7cdb 
INFO  [03:24:24.722] [bbotk]                     2233   0.9486812 51fe0581-4e80-4458-8245-4580d24d46e6 
INFO  [03:24:24.722] [bbotk]                     4965   0.9726106 653764fc-ed4b-4235-94aa-0093dcd4158c 
INFO  [03:24:24.722] [bbotk]                     4348   0.9727463 c22a0a94-4701-4c8a-b674-fc9a676215ff 
INFO  [03:24:24.722] [bbotk]                     1197   0.9720586 3a85ac69-505f-4a00-be0d-41802e55a3f4 
INFO  [03:24:24.722] [bbotk]                     1820   0.9483690 9dd03e1a-953d-472d-a8dd-cbe5137bd7a5 
INFO  [03:24:24.722] [bbotk]  ps_cboost_anneal1.mstop classif.auc                                uhash 
DEBUG [03:24:25.455] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.512575e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  9.512575e-06 0.0009884616 
  - best initial criterion value(s) :  111.9052 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -111.91  |proj g|=      0.90782
At iterate     1  f =      -116.47  |proj g|=       0.35143
At iterate     2  f =      -117.49  |proj g|=       0.73106
At iterate     3  f =      -118.26  |proj g|=       0.78537
At iterate     4  f =      -118.43  |proj g|=       0.78441
At iterate     5  f =      -118.44  |proj g|=       0.19678
At iterate     6  f =      -118.45  |proj g|=       0.18734
At iterate     7  f =      -118.45  |proj g|=       0.13889
At iterate     8  f =      -118.45  |proj g|=       0.13871
At iterate     9  f =      -118.45  |proj g|=       0.13872

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.138719
final function value -118.452

F = -118.452
final  value -118.452189 
converged
 
INFO  [03:24:25.459] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:24:25.519] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:24:25.526] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:24:27.670] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:24:31.313] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:24:33.471] [mlr3]  Finished benchmark 
INFO  [03:24:33.542] [bbotk] Result of batch 2: 
INFO  [03:24:33.544] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:24:33.544] [bbotk]              3.729656                 8.694644                       0.4517033 
INFO  [03:24:33.544] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [03:24:33.544] [bbotk]                      559        0.479 -0.968469         <NA>   0.9633902 
INFO  [03:24:33.544] [bbotk]                                 uhash 
INFO  [03:24:33.544] [bbotk]  080d0255-714a-4410-839c-83cc3febd9d1 
DEBUG [03:24:34.177] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.23126e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  9.23126e-06 0.0009452075 
  - best initial criterion value(s) :  119.1256 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -119.13  |proj g|=      0.89062
At iterate     1  f =      -120.71  |proj g|=        0.2026
At iterate     2  f =      -121.66  |proj g|=       0.80002
At iterate     3  f =      -121.69  |proj g|=        0.7964
At iterate     4  f =      -121.71  |proj g|=       0.41098
At iterate     5  f =      -121.71  |proj g|=       0.41044
At iterate     6  f =      -121.71  |proj g|=       0.40946
At iterate     7  f =      -121.71  |proj g|=       0.40926
At iterate     8  f =      -121.71  |proj g|=       0.40926

iterations 8
function evaluations 11
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.40926
final function value -121.706

F = -121.706
final  value -121.705618 
converged
 
INFO  [03:24:34.182] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:24:34.277] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:24:34.287] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:24:47.736] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:25:00.581] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:25:16.236] [mlr3]  Finished benchmark 
INFO  [03:25:16.317] [bbotk] Result of batch 3: 
INFO  [03:25:16.319] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:25:16.319] [bbotk]              4.206592                 3.054504                       0.3289048 
INFO  [03:25:16.319] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:25:16.319] [bbotk]                     4552        0.456 -0.9700005         <NA>     0.97382 
INFO  [03:25:16.319] [bbotk]                                 uhash 
INFO  [03:25:16.319] [bbotk]  b4ab82a6-9065-4493-a685-237e6b26f73f 
DEBUG [03:25:16.968] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.149524e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  9.149524e-06 0.000958767 
  - best initial criterion value(s) :  118.3793 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -118.38  |proj g|=       1.0625
At iterate     1  f =      -120.64  |proj g|=       0.87002
At iterate     2  f =      -121.29  |proj g|=       0.82237
At iterate     3  f =      -121.33  |proj g|=        0.8153
At iterate     4  f =      -121.38  |proj g|=       0.81384
At iterate     5  f =      -121.46  |proj g|=       0.79384
At iterate     6  f =      -121.47  |proj g|=       0.78705
At iterate     7  f =      -121.47  |proj g|=       0.78818
At iterate     8  f =      -121.47  |proj g|=       0.78813
At iterate     9  f =      -121.47  |proj g|=       0.78813

iterations 9
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.788127
final function value -121.467

F = -121.467
final  value -121.467219 
converged
 
INFO  [03:25:16.972] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:25:17.029] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:25:17.037] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:25:28.388] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:25:37.101] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:25:46.865] [mlr3]  Finished benchmark 
INFO  [03:25:46.932] [bbotk] Result of batch 4: 
INFO  [03:25:46.934] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:25:46.934] [bbotk]              9.373363                  8.78602                       0.4371709 
INFO  [03:25:46.934] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:25:46.934] [bbotk]                     3197        0.461 -0.9710726         <NA>   0.9726456 
INFO  [03:25:46.934] [bbotk]                                 uhash 
INFO  [03:25:46.934] [bbotk]  8a912b43-c744-4091-9fe6-fc748c5eb666 
DEBUG [03:25:47.675] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.012113e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  9.012113e-06 0.0009618901 
  - best initial criterion value(s) :  121.9173 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -121.92  |proj g|=      0.79565
At iterate     1  f =       -124.1  |proj g|=        1.0743
At iterate     2  f =      -130.33  |proj g|=        0.8528
At iterate     3  f =      -131.67  |proj g|=         0.833
At iterate     4  f =      -131.69  |proj g|=       0.83257
At iterate     5  f =      -131.77  |proj g|=       0.82912
At iterate     6  f =      -132.12  |proj g|=       0.80612
At iterate     7  f =      -132.31  |proj g|=       0.78259
At iterate     8  f =      -132.36  |proj g|=       0.73772
At iterate     9  f =      -132.36  |proj g|=       0.72835
At iterate    10  f =      -132.36  |proj g|=       0.72163
At iterate    11  f =      -132.36  |proj g|=       0.71945
At iterate    12  f =      -132.36  |proj g|=       0.71953

iterations 12
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.719531
final function value -132.36

F = -132.36
final  value -132.359907 
converged
 
INFO  [03:25:47.679] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:25:47.734] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:25:47.741] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:25:53.797] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:25:59.067] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:26:06.558] [mlr3]  Finished benchmark 
INFO  [03:26:06.626] [bbotk] Result of batch 5: 
INFO  [03:26:06.628] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:26:06.628] [bbotk]              9.316056                 6.579562                       0.1188854 
INFO  [03:26:06.628] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:26:06.628] [bbotk]                     2085        0.533 -0.9697678         <NA>   0.9686367 
INFO  [03:26:06.628] [bbotk]                                 uhash 
INFO  [03:26:06.628] [bbotk]  e75ef41d-fdf5-4c10-8c9e-2ec670a2258e 
DEBUG [03:26:07.329] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.773204e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  8.773204e-06 0.0009297168 
  - best initial criterion value(s) :  134.9986 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -135  |proj g|=       0.1253
At iterate     1  f =      -136.09  |proj g|=       0.84731
At iterate     2  f =      -136.15  |proj g|=       0.84638
At iterate     3  f =      -136.18  |proj g|=       0.84483
At iterate     4  f =      -136.25  |proj g|=       0.84116
At iterate     5  f =      -136.53  |proj g|=       0.82557
At iterate     6  f =      -136.78  |proj g|=       0.41374
At iterate     7  f =      -136.86  |proj g|=       0.49064
At iterate     8  f =      -136.88  |proj g|=       0.52865
At iterate     9  f =      -136.88  |proj g|=       0.54027
At iterate    10  f =      -136.88  |proj g|=       0.54152
At iterate    11  f =      -136.88  |proj g|=       0.54159

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.54159
final function value -136.879

F = -136.879
final  value -136.879118 
converged
 
INFO  [03:26:07.333] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:26:07.408] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:26:07.415] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:26:14.059] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:26:19.439] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:26:25.874] [mlr3]  Finished benchmark 
INFO  [03:26:25.940] [bbotk] Result of batch 6: 
INFO  [03:26:25.942] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:26:25.942] [bbotk]              8.088468                 5.299261                       0.1544269 
INFO  [03:26:25.942] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:26:25.942] [bbotk]                     2091        0.484 -0.9696193         <NA>   0.9702831 
INFO  [03:26:25.942] [bbotk]                                 uhash 
INFO  [03:26:25.942] [bbotk]  e5e3163e-0eb3-4d9e-af73-f802fdc9ad7a 
DEBUG [03:26:26.659] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.576294e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  8.576294e-06 0.0008932478 
  - best initial criterion value(s) :  133.4516 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -133.45  |proj g|=       2.0476
At iterate     1  f =      -133.57  |proj g|=         1.864
At iterate     2  f =      -133.91  |proj g|=        2.0286
At iterate     3  f =      -134.59  |proj g|=         2.199
At iterate     4  f =      -134.65  |proj g|=        2.1989
At iterate     5  f =      -134.65  |proj g|=         2.203
At iterate     6  f =      -134.65  |proj g|=        2.2016
At iterate     7  f =      -134.65  |proj g|=        2.2005
At iterate     8  f =      -134.65  |proj g|=        2.2007
At iterate     9  f =      -134.65  |proj g|=         2.201
At iterate    10  f =      -134.65  |proj g|=        2.2015
At iterate    11  f =      -134.65  |proj g|=        2.2019
At iterate    12  f =      -134.65  |proj g|=        2.2059
At iterate    13  f =      -134.65  |proj g|=        2.1936
At iterate    14  f =      -134.66  |proj g|=        2.1982
At iterate    15  f =      -134.71  |proj g|=        2.2043
At iterate    16  f =      -134.84  |proj g|=        2.1913
At iterate    17  f =      -135.15  |proj g|=        2.1123
At iterate    18  f =      -135.76  |proj g|=        1.8814
At iterate    19  f =      -136.62  |proj g|=        1.4225
At iterate    20  f =      -137.01  |proj g|=        1.1284
At iterate    21  f =      -137.13  |proj g|=        1.0553
At iterate    22  f =      -137.34  |proj g|=        1.0045
At iterate    23  f =      -137.59  |proj g|=        1.0184
At iterate    24  f =      -138.04  |proj g|=        1.0298
At iterate    25  f =       -139.1  |proj g|=       0.97435
At iterate    26  f =       -140.2  |proj g|=       0.81315
At iterate    27  f =      -140.89  |proj g|=       0.76938
At iterate    28  f =      -141.58  |proj g|=       0.76253
At iterate    29  f =      -142.02  |proj g|=       0.47034
At iterate    30  f =      -143.07  |proj g|=       0.55358
At iterate    31  f =      -143.21  |proj g|=       0.57714
At iterate    32  f =      -143.22  |proj g|=       0.56922
At iterate    33  f =      -143.22  |proj g|=         0.564
At iterate    34  f =      -143.22  |proj g|=       0.56498
At iterate    35  f =      -143.22  |proj g|=       0.56497

iterations 35
function evaluations 46
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.56497
final function value -143.217

F = -143.217
final  value -143.216778 
converged
 
INFO  [03:26:26.664] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:26:26.719] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:26:26.726] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:26:29.324] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:26:32.341] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:26:35.493] [mlr3]  Finished benchmark 
INFO  [03:26:35.561] [bbotk] Result of batch 7: 
INFO  [03:26:35.563] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:26:35.563] [bbotk]              9.225051                  5.84137                       0.4844177 
INFO  [03:26:35.563] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:26:35.563] [bbotk]                     1000        0.477 -0.9687366         <NA>    0.971572 
INFO  [03:26:35.563] [bbotk]                                 uhash 
INFO  [03:26:35.563] [bbotk]  f7a0bc67-65b0-49ee-917c-f6375e741320 
DEBUG [03:26:36.438] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.419466e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  8.419466e-06 0.0008543017 
  - best initial criterion value(s) :  136.3519 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -136.35  |proj g|=      0.92261
At iterate     1  f =         -147  |proj g|=       0.51746
At iterate     2  f =      -147.19  |proj g|=       0.62312
At iterate     3  f =      -147.64  |proj g|=       0.59302
At iterate     4  f =       -148.4  |proj g|=       0.47819
At iterate     5  f =      -148.59  |proj g|=       0.73706
At iterate     6  f =      -148.59  |proj g|=       0.50057
At iterate     7  f =       -148.6  |proj g|=       0.49187
At iterate     8  f =       -148.6  |proj g|=       0.49175
At iterate     9  f =       -148.6  |proj g|=       0.49175

iterations 9
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.491746
final function value -148.597

F = -148.597
final  value -148.596906 
converged
 
INFO  [03:26:36.442] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:26:36.500] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:26:36.507] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:26:44.355] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:26:51.590] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:26:58.049] [mlr3]  Finished benchmark 
INFO  [03:26:58.118] [bbotk] Result of batch 8: 
INFO  [03:26:58.120] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:26:58.120] [bbotk]              6.112798                 5.711164                        0.344983 
INFO  [03:26:58.120] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:26:58.120] [bbotk]                     2377        0.676 -0.9671585         <NA>   0.9738125 
INFO  [03:26:58.120] [bbotk]                                 uhash 
INFO  [03:26:58.120] [bbotk]  e6a03d23-b22a-4b56-9447-66fb43268a3c 
DEBUG [03:26:58.792] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.339732e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  8.339732e-06 0.0008354242 
  - best initial criterion value(s) :  147.6479 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -147.65  |proj g|=       1.0877
At iterate     1  f =       -150.7  |proj g|=        1.7466
At iterate     2  f =      -150.78  |proj g|=        1.7194
At iterate     3  f =      -150.82  |proj g|=        1.6527
At iterate     4  f =      -150.83  |proj g|=        1.6661
At iterate     5  f =      -150.84  |proj g|=        1.6387
At iterate     6  f =      -150.85  |proj g|=        1.5715
At iterate     7  f =      -150.85  |proj g|=        1.5802
At iterate     8  f =      -150.85  |proj g|=        1.5797
At iterate     9  f =      -150.85  |proj g|=        1.5792
At iterate    10  f =      -150.85  |proj g|=        1.5782
At iterate    11  f =      -150.85  |proj g|=        1.5767
At iterate    12  f =      -150.85  |proj g|=        1.5742
At iterate    13  f =      -150.85  |proj g|=        1.5701
At iterate    14  f =      -150.86  |proj g|=        1.5635
At iterate    15  f =      -150.86  |proj g|=        1.5531
At iterate    16  f =      -150.86  |proj g|=        1.5358
At iterate    17  f =      -150.86  |proj g|=        1.5287
At iterate    18  f =      -150.87  |proj g|=        1.5083
At iterate    19  f =      -151.25  |proj g|=        1.3527
At iterate    20  f =      -154.05  |proj g|=       0.49329
At iterate    21  f =      -154.63  |proj g|=       0.26474
At iterate    22  f =      -154.92  |proj g|=       0.29569
At iterate    23  f =      -154.93  |proj g|=       0.30742
At iterate    24  f =      -154.98  |proj g|=       0.31763
At iterate    25  f =      -154.99  |proj g|=       0.32049
At iterate    26  f =      -154.99  |proj g|=        0.3208
At iterate    27  f =      -154.99  |proj g|=        0.3199
At iterate    28  f =      -154.99  |proj g|=       0.31966
At iterate    29  f =      -154.99  |proj g|=       0.31962

iterations 29
function evaluations 37
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.319624
final function value -154.989

F = -154.989
final  value -154.988922 
converged
 
INFO  [03:26:58.796] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:26:58.853] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:26:58.860] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:27:14.038] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:27:28.774] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:27:42.053] [mlr3]  Finished benchmark 
INFO  [03:27:42.122] [bbotk] Result of batch 9: 
INFO  [03:27:42.124] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:27:42.124] [bbotk]               2.68873                 3.361623                       0.1906598 
INFO  [03:27:42.124] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:27:42.124] [bbotk]                     4693        0.474 -0.9671254         <NA>   0.9641466 
INFO  [03:27:42.124] [bbotk]                                 uhash 
INFO  [03:27:42.124] [bbotk]  1f2361e6-6e58-434e-abfb-c1cc8edd2b6e 
DEBUG [03:27:42.815] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.140525e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  8.140525e-06 0.0008205861 
  - best initial criterion value(s) :  152.7978 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -152.8  |proj g|=      0.87652
At iterate     1  f =      -155.27  |proj g|=       0.64559
At iterate     2  f =      -155.95  |proj g|=       0.64674
At iterate     3  f =      -157.56  |proj g|=       0.74308
At iterate     4  f =      -157.79  |proj g|=       0.49434
At iterate     5  f =      -157.84  |proj g|=        0.4662
At iterate     6  f =      -157.84  |proj g|=        0.4665
At iterate     7  f =      -157.84  |proj g|=       0.46567
At iterate     8  f =      -157.84  |proj g|=       0.46585
At iterate     9  f =      -157.84  |proj g|=       0.46583

iterations 9
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.465826
final function value -157.839

F = -157.839
final  value -157.838742 
converged
 
INFO  [03:27:42.819] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:27:42.877] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:27:42.907] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:27:53.983] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:28:04.974] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:28:18.571] [mlr3]  Finished benchmark 
INFO  [03:28:18.639] [bbotk] Result of batch 10: 
INFO  [03:28:18.641] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:28:18.641] [bbotk]              4.143478                 8.803066                       0.1676096 
INFO  [03:28:18.641] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:28:18.641] [bbotk]                     4104          0.5 -0.9670537         <NA>   0.9710986 
INFO  [03:28:18.641] [bbotk]                                 uhash 
INFO  [03:28:18.641] [bbotk]  2149cd5a-082f-40a1-8689-333fcd6fa070 
DEBUG [03:28:19.347] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.98847e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  7.98847e-06 0.0008178719 
  - best initial criterion value(s) :  152.6095 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -152.61  |proj g|=       1.9841
At iterate     1  f =      -153.28  |proj g|=        2.2155
At iterate     2  f =      -153.89  |proj g|=        2.0227
At iterate     3  f =      -154.18  |proj g|=         1.627
At iterate     4  f =      -154.39  |proj g|=        1.8419
At iterate     5  f =       -154.4  |proj g|=        1.8018
At iterate     6  f =       -154.4  |proj g|=        1.7907
At iterate     7  f =       -154.4  |proj g|=        1.7916
At iterate     8  f =       -154.4  |proj g|=        1.7916
At iterate     9  f =       -154.4  |proj g|=        1.7913
At iterate    10  f =       -154.4  |proj g|=        1.7909
At iterate    11  f =       -154.4  |proj g|=        1.7902
At iterate    12  f =       -154.4  |proj g|=        1.7891
At iterate    13  f =      -154.41  |proj g|=        1.7874
At iterate    14  f =      -154.41  |proj g|=        1.7844
At iterate    15  f =      -154.41  |proj g|=        1.7787
At iterate    16  f =      -154.41  |proj g|=        1.7676
At iterate    17  f =      -154.42  |proj g|=        1.7447
At iterate    18  f =      -154.46  |proj g|=        1.6991
At iterate    19  f =      -154.51  |proj g|=        1.6236
At iterate    20  f =      -154.57  |proj g|=        1.5696
At iterate    21  f =      -154.57  |proj g|=        1.5817
At iterate    22  f =      -154.57  |proj g|=        1.5913
At iterate    23  f =      -154.58  |proj g|=        1.5984
At iterate    24  f =      -154.61  |proj g|=        1.6204
At iterate    25  f =      -154.68  |proj g|=        1.6383
At iterate    26  f =      -154.86  |proj g|=        1.6415
At iterate    27  f =      -155.26  |proj g|=        1.5977
At iterate    28  f =      -155.82  |proj g|=        1.2468
At iterate    29  f =      -156.81  |proj g|=        1.0967
At iterate    30  f =      -158.33  |proj g|=       0.80964
At iterate    31  f =       -160.1  |proj g|=       0.58386
At iterate    32  f =      -161.83  |proj g|=       0.38855
At iterate    33  f =      -162.17  |proj g|=       0.28439
At iterate    34  f =      -162.22  |proj g|=       0.27182
At iterate    35  f =      -162.33  |proj g|=       0.26289
At iterate    36  f =      -162.58  |proj g|=       0.23012
At iterate    37  f =      -162.58  |proj g|=       0.51688
At iterate    38  f =      -162.58  |proj g|=      0.033453
At iterate    39  f =      -162.58  |proj g|=      0.034607
At iterate    40  f =      -162.58  |proj g|=      0.034272
At iterate    41  f =      -162.58  |proj g|=      0.034272

iterations 41
function evaluations 50
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.034272
final function value -162.583

F = -162.583
final  value -162.583107 
converged
 
INFO  [03:28:19.351] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:28:19.408] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:28:19.415] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:28:20.936] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:28:22.636] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:28:24.658] [mlr3]  Finished benchmark 
INFO  [03:28:24.726] [bbotk] Result of batch 11: 
INFO  [03:28:24.728] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:28:24.728] [bbotk]              8.784155                 3.852118                        0.337161 
INFO  [03:28:24.728] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:28:24.728] [bbotk]                      430        0.475 -0.9661815         <NA>   0.9645409 
INFO  [03:28:24.728] [bbotk]                                 uhash 
INFO  [03:28:24.728] [bbotk]  0be32052-fbb0-4466-bf97-757e407be053 
DEBUG [03:28:25.537] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.803895e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.28098 0.9597732 9458 
  - variance bounds :  7.803895e-06 0.0007852855 
  - best initial criterion value(s) :  153.2985 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -153.3  |proj g|=      0.90695
At iterate     1  f =      -163.79  |proj g|=       0.56538
At iterate     2  f =      -164.16  |proj g|=       0.64853
At iterate     3  f =      -164.33  |proj g|=       0.62167
At iterate     4  f =      -164.61  |proj g|=       0.55776
At iterate     5  f =      -164.72  |proj g|=        0.4958
At iterate     6  f =      -164.76  |proj g|=       0.52116
At iterate     7  f =      -164.76  |proj g|=       0.51838
At iterate     8  f =      -164.76  |proj g|=       0.51834
At iterate     9  f =      -164.76  |proj g|=       0.51833

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.518334
final function value -164.764

F = -164.764
final  value -164.763676 
converged
 
INFO  [03:28:25.541] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:28:25.623] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:28:25.630] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:28:27.607] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:28:29.716] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:28:31.568] [mlr3]  Finished benchmark 
INFO  [03:28:31.636] [bbotk] Result of batch 12: 
INFO  [03:28:31.638] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:28:31.638] [bbotk]               3.47412                 2.182683                       0.2629216 
INFO  [03:28:31.638] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [03:28:31.638] [bbotk]                      652        0.609 -0.964457         <NA>   0.9573212 
INFO  [03:28:31.638] [bbotk]                                 uhash 
INFO  [03:28:31.638] [bbotk]  72c53e8b-4588-49ac-bea6-947e3b0d3cd9 
DEBUG [03:28:32.326] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 7.816933e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9597732 9458 
  - variance bounds :  7.816933e-06 0.0007966316 
  - best initial criterion value(s) :  159.9327 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -159.93  |proj g|=       1.2625
At iterate     1  f =      -168.15  |proj g|=       0.77803
At iterate     2  f =      -168.69  |proj g|=       0.77021
At iterate     3  f =      -169.23  |proj g|=       0.74407
At iterate     4  f =      -169.33  |proj g|=       0.74734
At iterate     5  f =      -169.38  |proj g|=       0.74448
At iterate     6  f =      -169.64  |proj g|=        0.7158
At iterate     7  f =      -169.69  |proj g|=       0.62566
At iterate     8  f =      -169.69  |proj g|=       0.63246
At iterate     9  f =      -169.69  |proj g|=       0.63164
At iterate    10  f =      -169.69  |proj g|=       0.63133
At iterate    11  f =      -169.69  |proj g|=       0.63132

iterations 11
function evaluations 13
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.631321
final function value -169.694

F = -169.694
final  value -169.694046 
converged
 
INFO  [03:28:32.330] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:28:32.388] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:28:32.395] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:28:41.885] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:28:50.015] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:28:57.523] [mlr3]  Finished benchmark 
INFO  [03:28:57.704] [bbotk] Result of batch 13: 
INFO  [03:28:57.706] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:28:57.706] [bbotk]              5.608394                 5.438572                      0.01080575 
INFO  [03:28:57.706] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:28:57.706] [bbotk]                     2757        0.498 -0.9637859         <NA>   0.9405258 
INFO  [03:28:57.706] [bbotk]                                 uhash 
INFO  [03:28:57.706] [bbotk]  b51304a4-7138-47a8-8403-a543044eec6e 
DEBUG [03:28:58.370] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.151143e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.913479e-06 0.0009151143 
  - best initial criterion value(s) :  165.9552 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -165.96  |proj g|=       0.8812
At iterate     1  f =      -166.36  |proj g|=       0.32872
At iterate     2  f =      -169.22  |proj g|=       0.75295
At iterate     3  f =       -169.6  |proj g|=       0.40445
At iterate     4  f =      -170.32  |proj g|=       0.20549
At iterate     5  f =      -170.51  |proj g|=       0.17242
At iterate     6  f =       -170.6  |proj g|=       0.81026
At iterate     7  f =       -170.6  |proj g|=       0.13184
At iterate     8  f =       -170.6  |proj g|=       0.13003
At iterate     9  f =       -170.6  |proj g|=       0.13013
At iterate    10  f =       -170.6  |proj g|=       0.13013

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.130127
final function value -170.599

F = -170.599
final  value -170.598692 
converged
 
INFO  [03:28:58.374] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:28:58.431] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:28:58.438] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:29:05.624] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:29:14.770] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:29:21.114] [mlr3]  Finished benchmark 
INFO  [03:29:21.184] [bbotk] Result of batch 14: 
INFO  [03:29:21.186] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:29:21.186] [bbotk]              6.292662                  5.95964                       0.1520871 
INFO  [03:29:21.186] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:29:21.186] [bbotk]                     2468        0.481 -0.9658616         <NA>   0.9706159 
INFO  [03:29:21.186] [bbotk]                                 uhash 
INFO  [03:29:21.186] [bbotk]  7d98ded6-6700-4217-8084-e58b1fdba7ab 
DEBUG [03:29:21.869] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.995434e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.74023e-06 0.0008995434 
  - best initial criterion value(s) :  167.7357 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -167.74  |proj g|=       0.9113
At iterate     1  f =      -172.24  |proj g|=       0.31889
At iterate     2  f =      -173.49  |proj g|=        0.4553
At iterate     3  f =      -174.98  |proj g|=       0.32752
At iterate     4  f =      -175.63  |proj g|=       0.20609
At iterate     5  f =      -176.16  |proj g|=       0.16985
At iterate     6  f =      -176.16  |proj g|=        0.4524
At iterate     7  f =      -176.16  |proj g|=       0.15712
At iterate     8  f =      -176.16  |proj g|=       0.15648
At iterate     9  f =      -176.16  |proj g|=       0.15652

iterations 9
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.156515
final function value -176.163

F = -176.163
final  value -176.163071 
converged
 
INFO  [03:29:21.873] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:29:21.971] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:29:21.979] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:29:25.453] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:29:28.929] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:29:32.901] [mlr3]  Finished benchmark 
INFO  [03:29:32.970] [bbotk] Result of batch 15: 
INFO  [03:29:32.972] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:29:32.972] [bbotk]              6.030433                 7.745572                       0.3868106 
INFO  [03:29:32.972] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:29:32.972] [bbotk]                     1197        0.495 -0.9647606         <NA>   0.9716555 
INFO  [03:29:32.972] [bbotk]                                 uhash 
INFO  [03:29:32.972] [bbotk]  1b5f12df-b2e6-4c07-bbd4-5de7943fd724 
DEBUG [03:29:33.646] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.868207e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.517979e-06 0.0008868207 
  - best initial criterion value(s) :  175.2681 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -175.27  |proj g|=      0.40171
At iterate     1  f =      -178.14  |proj g|=        1.1352
At iterate     2  f =      -178.96  |proj g|=       0.98905
At iterate     3  f =      -179.44  |proj g|=       0.79523
At iterate     4  f =      -179.46  |proj g|=       0.68809
At iterate     5  f =      -179.46  |proj g|=       0.71076
At iterate     6  f =      -179.46  |proj g|=       0.71184
At iterate     7  f =      -179.47  |proj g|=       0.72003
At iterate     8  f =      -179.47  |proj g|=       0.72076
At iterate     9  f =      -179.47  |proj g|=       0.72085

iterations 9
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.720853
final function value -179.467

F = -179.467
final  value -179.466646 
converged
 
INFO  [03:29:33.650] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:29:33.707] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:29:33.714] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:29:42.803] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:29:51.758] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:30:01.928] [mlr3]  Finished benchmark 
INFO  [03:30:01.998] [bbotk] Result of batch 16: 
INFO  [03:30:02.000] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:30:02.000] [bbotk]              8.810062                 4.427457                       0.4428684 
INFO  [03:30:02.000] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:30:02.000] [bbotk]                     3254        0.492 -0.9671195         <NA>   0.9731264 
INFO  [03:30:02.000] [bbotk]                                 uhash 
INFO  [03:30:02.000] [bbotk]  b5363f4d-8d35-49e4-9cb8-894151d9c1f5 
DEBUG [03:30:02.821] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.783492e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.609072e-06 0.0008783492 
  - best initial criterion value(s) :  182.5061 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -182.51  |proj g|=      0.88347
At iterate     1  f =      -183.21  |proj g|=       0.37589
At iterate     2  f =      -183.87  |proj g|=       0.54524
At iterate     3  f =      -184.69  |proj g|=       0.47902
At iterate     4  f =      -185.55  |proj g|=       0.30709
At iterate     5  f =      -185.87  |proj g|=       0.25621
At iterate     6  f =      -185.89  |proj g|=       0.27743
At iterate     7  f =      -185.89  |proj g|=       0.27466
At iterate     8  f =      -185.89  |proj g|=       0.27302
At iterate     9  f =      -185.89  |proj g|=         0.273

iterations 9
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.272996
final function value -185.89

F = -185.89
final  value -185.890484 
converged
 
INFO  [03:30:02.826] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:30:02.888] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:30:02.895] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:30:12.308] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:30:21.215] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:30:29.336] [mlr3]  Finished benchmark 
INFO  [03:30:29.406] [bbotk] Result of batch 17: 
INFO  [03:30:29.408] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:30:29.408] [bbotk]              8.376863                 2.464354                       0.4569418 
INFO  [03:30:29.408] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:30:29.408] [bbotk]                     3022        0.597 -0.9646025         <NA>    0.973698 
INFO  [03:30:29.408] [bbotk]                                 uhash 
INFO  [03:30:29.408] [bbotk]  79b5521a-0d71-4a26-8892-3773c176076e 
DEBUG [03:30:30.361] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.715266e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.57284e-06 0.0008715266 
  - best initial criterion value(s) :  174.9101 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -174.91  |proj g|=       4.2546
At iterate     1  f =      -177.16  |proj g|=        4.2331
At iterate     2  f =      -180.77  |proj g|=         2.892
At iterate     3  f =      -182.48  |proj g|=        2.6936
At iterate     4  f =      -184.61  |proj g|=        1.3059
At iterate     5  f =      -184.68  |proj g|=        1.2213
At iterate     6  f =      -184.69  |proj g|=        1.3125
At iterate     7  f =      -184.69  |proj g|=        1.2898
At iterate     8  f =      -184.69  |proj g|=        1.2791
At iterate     9  f =       -184.7  |proj g|=        1.2694
At iterate    10  f =       -184.7  |proj g|=        1.2474
At iterate    11  f =       -184.7  |proj g|=        1.2356
At iterate    12  f =      -184.72  |proj g|=        1.1919
At iterate    13  f =      -184.76  |proj g|=        1.1221
At iterate    14  f =      -184.89  |proj g|=       0.95769
At iterate    15  f =       -185.2  |proj g|=       0.85817
At iterate    16  f =      -185.94  |proj g|=       0.85361
At iterate    17  f =      -187.03  |proj g|=       0.84671
At iterate    18  f =      -187.74  |proj g|=       0.85561
At iterate    19  f =      -188.12  |proj g|=         0.883
At iterate    20  f =      -188.23  |proj g|=       0.88279
At iterate    21  f =      -188.26  |proj g|=       0.91606
At iterate    22  f =       -188.3  |proj g|=       0.90869
At iterate    23  f =      -188.45  |proj g|=       0.96374
At iterate    24  f =      -188.46  |proj g|=       0.95438
At iterate    25  f =      -188.46  |proj g|=        0.9573
At iterate    26  f =      -188.46  |proj g|=       0.95907
At iterate    27  f =      -188.46  |proj g|=        0.9593
At iterate    28  f =      -188.46  |proj g|=        0.9609
At iterate    29  f =      -188.46  |proj g|=       0.96263
At iterate    30  f =      -188.46  |proj g|=       0.96509
At iterate    31  f =      -188.46  |proj g|=       0.96728
At iterate    32  f =      -188.46  |proj g|=       0.97103
At iterate    33  f =      -188.47  |proj g|=       0.97197
At iterate    34  f =      -188.48  |proj g|=       0.97135
At iterate    35  f =       -188.5  |proj g|=       0.96167
At iterate    36  f =      -188.51  |proj g|=       0.95481
At iterate    37  f =      -188.51  |proj g|=       0.95205
At iterate    38  f =      -188.52  |proj g|=       0.94964
At iterate    39  f =      -188.53  |proj g|=       0.91735
At iterate    40  f =       -188.7  |proj g|=       0.87072
At iterate    41  f =      -189.26  |proj g|=       0.79472
At iterate    42  f =       -190.8  |proj g|=       0.77571
At iterate    43  f =      -190.87  |proj g|=       0.79269
At iterate    44  f =      -191.73  |proj g|=       0.77662
At iterate    45  f =      -191.77  |proj g|=       0.76939
At iterate    46  f =      -191.78  |proj g|=       0.18913
At iterate    47  f =      -191.78  |proj g|=        0.1919
At iterate    48  f =      -191.78  |proj g|=      0.023719
At iterate    49  f =      -191.78  |proj g|=     0.0015261

iterations 49
function evaluations 63
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00152611
final function value -191.78

F = -191.78
final  value -191.780291 
converged
 
INFO  [03:30:30.365] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:30:30.464] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:30:30.476] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:30:43.091] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:30:55.456] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:31:09.198] [mlr3]  Finished benchmark 
INFO  [03:31:09.270] [bbotk] Result of batch 18: 
INFO  [03:31:09.272] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:31:09.272] [bbotk]              3.661929                 2.734028                       0.0233963 
INFO  [03:31:09.272] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [03:31:09.272] [bbotk]                     4165        0.662 -0.963775         <NA>    0.951807 
INFO  [03:31:09.272] [bbotk]                                 uhash 
INFO  [03:31:09.272] [bbotk]  fb32bd3d-a698-496d-a96f-34d89fc678b4 
DEBUG [03:31:10.207] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.962857e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.649225e-06 0.0008962857 
  - best initial criterion value(s) :  176.9999 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -177  |proj g|=       4.2462
At iterate     1  f =      -178.84  |proj g|=         3.914
At iterate     2  f =       -179.6  |proj g|=        3.7211
At iterate     3  f =      -180.54  |proj g|=        2.9592
At iterate     4  f =      -181.74  |proj g|=        2.7302
At iterate     5  f =      -182.29  |proj g|=        2.0557
At iterate     6  f =      -182.29  |proj g|=        2.1051
At iterate     7  f =      -182.29  |proj g|=        2.1091
At iterate     8  f =      -182.29  |proj g|=        2.1046
At iterate     9  f =       -182.3  |proj g|=        2.0923
At iterate    10  f =      -182.31  |proj g|=        2.0764
At iterate    11  f =      -182.36  |proj g|=        2.0408
At iterate    12  f =      -182.47  |proj g|=        1.9732
At iterate    13  f =      -182.79  |proj g|=        1.8278
At iterate    14  f =      -183.68  |proj g|=        1.5254
At iterate    15  f =      -186.17  |proj g|=       0.93976
At iterate    16  f =      -190.38  |proj g|=       0.52921
At iterate    17  f =      -193.18  |proj g|=        0.8589
At iterate    18  f =      -193.72  |proj g|=       0.85517
At iterate    19  f =      -193.84  |proj g|=       0.85561
At iterate    20  f =      -193.92  |proj g|=       0.85509
At iterate    21  f =         -194  |proj g|=       0.85316
At iterate    22  f =      -194.16  |proj g|=       0.84753
At iterate    23  f =      -194.35  |proj g|=       0.83814
At iterate    24  f =      -194.55  |proj g|=       0.82468
At iterate    25  f =       -194.7  |proj g|=       0.82095
At iterate    26  f =      -194.75  |proj g|=        0.8099
At iterate    27  f =      -194.76  |proj g|=       0.16001
At iterate    28  f =      -194.76  |proj g|=      0.065084
At iterate    29  f =      -194.76  |proj g|=      0.065186

iterations 29
function evaluations 35
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.065186
final function value -194.757

F = -194.757
final  value -194.757339 
converged
 
INFO  [03:31:10.211] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:31:10.445] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:31:10.453] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:31:19.881] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:31:28.299] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:31:38.775] [mlr3]  Finished benchmark 
INFO  [03:31:38.843] [bbotk] Result of batch 19: 
INFO  [03:31:38.845] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:31:38.845] [bbotk]              5.780013                 5.533716                       0.3898588 
INFO  [03:31:38.845] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:31:38.845] [bbotk]                     3141        0.655 -0.9643261         <NA>   0.9749527 
INFO  [03:31:38.845] [bbotk]                                 uhash 
INFO  [03:31:38.845] [bbotk]  e1255dac-e7ca-470a-8b7b-09419358d67d 
DEBUG [03:31:39.776] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.9398e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.772033e-06 0.00089398 
  - best initial criterion value(s) :  179.5695 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -179.57  |proj g|=       0.9462
At iterate     1  f =      -193.57  |proj g|=       0.69419
At iterate     2  f =      -193.85  |proj g|=        1.8895
At iterate     3  f =      -194.54  |proj g|=        1.7731
At iterate     4  f =       -195.5  |proj g|=         1.292
At iterate     5  f =       -195.5  |proj g|=        1.4002
At iterate     6  f =      -195.52  |proj g|=        1.3519
At iterate     7  f =      -195.52  |proj g|=        1.3465
At iterate     8  f =      -195.52  |proj g|=        1.3445
At iterate     9  f =      -195.52  |proj g|=         1.342
At iterate    10  f =      -195.52  |proj g|=        1.3419
At iterate    11  f =      -195.52  |proj g|=        1.3477
At iterate    12  f =      -195.52  |proj g|=         1.347
At iterate    13  f =      -195.52  |proj g|=         1.347

iterations 13
function evaluations 17
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.34696
final function value -195.519

F = -195.519
final  value -195.519325 
converged
 
INFO  [03:31:39.780] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:31:39.849] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:31:39.856] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:31:42.326] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:31:45.533] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:31:48.759] [mlr3]  Finished benchmark 
INFO  [03:31:48.844] [bbotk] Result of batch 20: 
INFO  [03:31:48.846] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:31:48.846] [bbotk]              7.655281                 4.666764                       0.4894984 
INFO  [03:31:48.846] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:31:48.846] [bbotk]                      909        0.669 -0.9670152         <NA>   0.9717229 
INFO  [03:31:48.846] [bbotk]                                 uhash 
INFO  [03:31:48.846] [bbotk]  6dc526ae-abe3-4728-8992-b17b1520c8ea 
DEBUG [03:31:49.742] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.821005e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.57184e-06 0.0008821005 
  - best initial criterion value(s) :  203.0976 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -203.1  |proj g|=      0.19348
At iterate     1  f =      -203.99  |proj g|=       0.83654
At iterate     2  f =      -203.99  |proj g|=       0.83625
At iterate     3  f =      -203.99  |proj g|=       0.83571
At iterate     4  f =         -204  |proj g|=       0.83483
At iterate     5  f =      -204.01  |proj g|=       0.83204
At iterate     6  f =      -204.04  |proj g|=       0.32267
At iterate     7  f =      -204.05  |proj g|=       0.82083
At iterate     8  f =      -204.07  |proj g|=       0.82061
At iterate     9  f =      -204.07  |proj g|=       0.35675
At iterate    10  f =      -204.07  |proj g|=       0.37047
At iterate    11  f =      -204.07  |proj g|=       0.36784

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.367843
final function value -204.07

F = -204.07
final  value -204.069529 
converged
 
INFO  [03:31:49.746] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:31:49.802] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:31:49.809] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:32:02.466] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:32:17.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:32:29.540] [mlr3]  Finished benchmark 
INFO  [03:32:29.607] [bbotk] Result of batch 21: 
INFO  [03:32:29.609] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:32:29.609] [bbotk]              2.709194                 2.279421                      0.09918331 
INFO  [03:32:29.609] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:32:29.609] [bbotk]                     4207         0.65 -0.9653203         <NA>    0.958925 
INFO  [03:32:29.609] [bbotk]                                 uhash 
INFO  [03:32:29.609] [bbotk]  9eab7888-9411-4f54-8824-09a8787f4864 
DEBUG [03:32:30.535] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.75263e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.379224e-06 0.000875263 
  - best initial criterion value(s) :  188.7213 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -188.72  |proj g|=       1.7935
At iterate     1  f =      -205.18  |proj g|=        1.2569
At iterate     2  f =      -205.49  |proj g|=        1.2369
At iterate     3  f =      -205.87  |proj g|=        1.1376
At iterate     4  f =      -205.91  |proj g|=        1.1633
At iterate     5  f =         -206  |proj g|=        1.1524
At iterate     6  f =      -206.06  |proj g|=        1.0879
At iterate     7  f =      -206.08  |proj g|=        1.1218
At iterate     8  f =      -206.08  |proj g|=        1.1156
At iterate     9  f =      -206.08  |proj g|=        1.1144
At iterate    10  f =      -206.08  |proj g|=        1.1144

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.11443
final function value -206.082

F = -206.082
final  value -206.082235 
converged
 
INFO  [03:32:30.539] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:32:30.597] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:32:30.604] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:32:31.988] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:32:33.493] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:32:34.840] [mlr3]  Finished benchmark 
INFO  [03:32:34.908] [bbotk] Result of batch 22: 
INFO  [03:32:34.910] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:32:34.910] [bbotk]              9.019144                 4.463338                      0.09465829 
INFO  [03:32:34.910] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:32:34.910] [bbotk]                      398        0.683 -0.9638829         <NA>   0.9473348 
INFO  [03:32:34.910] [bbotk]                                 uhash 
INFO  [03:32:34.910] [bbotk]  9529b813-56cf-4174-84f1-f4dc0e065229 
DEBUG [03:32:35.824] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.252809e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  9.187191e-06 0.0009252809 
  - best initial criterion value(s) :  199.0918 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -199.09  |proj g|=      0.96779
At iterate     1  f =      -203.26  |proj g|=       0.89385
At iterate     2  f =      -204.15  |proj g|=        0.8449
At iterate     3  f =      -204.61  |proj g|=       0.83182
At iterate     4  f =      -204.77  |proj g|=       0.83542
At iterate     5  f =       -204.8  |proj g|=       0.83409
At iterate     6  f =      -204.96  |proj g|=       0.82384
At iterate     7  f =      -205.15  |proj g|=       0.75572
At iterate     8  f =      -205.44  |proj g|=       0.91598
At iterate     9  f =      -205.46  |proj g|=       0.92683
At iterate    10  f =      -205.46  |proj g|=       0.93064
At iterate    11  f =      -205.46  |proj g|=       0.93083
At iterate    12  f =      -205.46  |proj g|=       0.93087

iterations 12
function evaluations 14
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.930869
final function value -205.462

F = -205.462
final  value -205.461666 
converged
 
INFO  [03:32:35.828] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:32:35.902] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:32:35.908] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:32:47.113] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:32:58.713] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:33:09.680] [mlr3]  Finished benchmark 
INFO  [03:33:09.746] [bbotk] Result of batch 23: 
INFO  [03:33:09.748] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:33:09.748] [bbotk]              2.475674                 2.634745                       0.4567965 
INFO  [03:33:09.748] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:33:09.748] [bbotk]                     4101        0.684 -0.9615866         <NA>   0.9667669 
INFO  [03:33:09.748] [bbotk]                                 uhash 
INFO  [03:33:09.748] [bbotk]  1b779b54-e61d-43e5-ac96-dd34e964b519 
DEBUG [03:33:10.476] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.079949e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  9.054038e-06 0.0009079949 
  - best initial criterion value(s) :  203.9548 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -203.95  |proj g|=       1.4313
At iterate     1  f =      -203.97  |proj g|=        1.5359
At iterate     2  f =      -204.26  |proj g|=        1.4013
At iterate     3  f =      -204.82  |proj g|=        1.1552
At iterate     4  f =      -204.83  |proj g|=         1.189
At iterate     5  f =      -204.83  |proj g|=        1.1783
At iterate     6  f =      -204.83  |proj g|=        1.1797
At iterate     7  f =      -204.83  |proj g|=        1.1796

iterations 7
function evaluations 12
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.17959
final function value -204.832

F = -204.832
final  value -204.831917 
converged
 
INFO  [03:33:10.480] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:33:10.536] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:33:10.543] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:33:26.123] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:33:39.558] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:33:52.436] [mlr3]  Finished benchmark 
INFO  [03:33:52.504] [bbotk] Result of batch 24: 
INFO  [03:33:52.506] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:33:52.506] [bbotk]              9.052842                 8.732031                      0.01513383 
INFO  [03:33:52.506] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:33:52.506] [bbotk]                     4468        0.533 -0.9687017         <NA>   0.9551503 
INFO  [03:33:52.506] [bbotk]                                 uhash 
INFO  [03:33:52.506] [bbotk]  d91eccd1-f33d-4c6c-afad-d00c8ee8d138 
DEBUG [03:33:53.252] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.11881e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  9.04577e-06 0.000911881 
  - best initial criterion value(s) :  206.1619 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -206.16  |proj g|=       1.0082
At iterate     1  f =      -208.47  |proj g|=       0.97661
At iterate     2  f =      -209.64  |proj g|=        0.9038
At iterate     3  f =      -210.12  |proj g|=       0.84049
At iterate     4  f =      -210.39  |proj g|=       0.84462
At iterate     5  f =      -210.44  |proj g|=       0.84301
At iterate     6  f =      -210.81  |proj g|=       0.82857
At iterate     7  f =      -211.27  |proj g|=       0.80975
At iterate     8  f =      -212.08  |proj g|=        1.0295
At iterate     9  f =      -212.16  |proj g|=         1.066
At iterate    10  f =      -212.16  |proj g|=        1.0763
At iterate    11  f =      -212.17  |proj g|=        1.0915
At iterate    12  f =      -212.17  |proj g|=        1.0936
At iterate    13  f =      -212.17  |proj g|=        1.0948
At iterate    14  f =      -212.17  |proj g|=        1.0959
At iterate    15  f =      -212.17  |proj g|=        1.0981
At iterate    16  f =      -212.17  |proj g|=        1.0988
At iterate    17  f =      -212.18  |proj g|=        1.1082
At iterate    18  f =      -212.19  |proj g|=        1.1062
At iterate    19  f =      -212.24  |proj g|=        1.0911
At iterate    20  f =      -212.39  |proj g|=        1.0431
At iterate    21  f =      -212.68  |proj g|=       0.92479
At iterate    22  f =      -212.98  |proj g|=       0.77883
At iterate    23  f =      -212.98  |proj g|=       0.75975
At iterate    24  f =      -213.18  |proj g|=       0.72723
At iterate    25  f =      -213.29  |proj g|=       0.75024
At iterate    26  f =      -213.29  |proj g|=       0.74429
At iterate    27  f =      -213.29  |proj g|=       0.74494
At iterate    28  f =      -213.29  |proj g|=       0.74445
At iterate    29  f =      -213.29  |proj g|=       0.74412

iterations 29
function evaluations 37
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.744123
final function value -213.291

F = -213.291
final  value -213.291097 
converged
 
INFO  [03:33:53.256] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:33:53.329] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:33:53.335] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:34:03.734] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:34:13.719] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:34:23.819] [mlr3]  Finished benchmark 
INFO  [03:34:23.888] [bbotk] Result of batch 25: 
INFO  [03:34:23.890] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:34:23.890] [bbotk]              5.678044                 7.976646                        0.429516 
INFO  [03:34:23.890] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:34:23.890] [bbotk]                     3448         0.52 -0.9640727         <NA>   0.9754094 
INFO  [03:34:23.890] [bbotk]                                 uhash 
INFO  [03:34:23.890] [bbotk]  9f0e4125-83dd-43fb-91f2-77578d2c0f32 
DEBUG [03:34:24.621] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.123917e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  9.123916e-06 0.00091937 
  - best initial criterion value(s) :  205.5763 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -205.58  |proj g|=       2.3314
At iterate     1  f =      -206.13  |proj g|=        2.3379
At iterate     2  f =      -206.17  |proj g|=        2.3409
At iterate     3  f =      -206.17  |proj g|=        2.3361
At iterate     4  f =      -206.17  |proj g|=        2.3403
At iterate     5  f =      -206.17  |proj g|=        2.3387
At iterate     6  f =      -206.17  |proj g|=        2.3387

iterations 6
function evaluations 9
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.33869
final function value -206.171

F = -206.171
final  value -206.171175 
converged
 
INFO  [03:34:24.625] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:34:24.683] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:34:24.690] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:34:27.068] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:34:31.135] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:34:33.183] [mlr3]  Finished benchmark 
INFO  [03:34:33.252] [bbotk] Result of batch 26: 
INFO  [03:34:33.254] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:34:33.254] [bbotk]              9.779932                  5.12228                       0.2605741 
INFO  [03:34:33.254] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:34:33.254] [bbotk]                      648        0.533 -0.9690394         <NA>   0.9660944 
INFO  [03:34:33.254] [bbotk]                                 uhash 
INFO  [03:34:33.254] [bbotk]  aca09b89-3688-47c2-b4c2-e8be09af8dfd 
DEBUG [03:34:34.000] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.96114e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.9642916 9458 
  - variance bounds :  8.96114e-06 0.0008974717 
  - best initial criterion value(s) :  220.3232 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -220.32  |proj g|=      0.65163
At iterate     1  f =       -220.4  |proj g|=       0.82092
At iterate     2  f =       -220.4  |proj g|=       0.81566
At iterate     3  f =       -220.4  |proj g|=       0.81377
At iterate     4  f =       -220.4  |proj g|=       0.80958
At iterate     5  f =       -220.4  |proj g|=       0.80447
At iterate     6  f =       -220.4  |proj g|=       0.80152
At iterate     7  f =       -220.4  |proj g|=        0.8027
At iterate     8  f =       -220.4  |proj g|=       0.81236
At iterate     9  f =       -220.4  |proj g|=       0.81204
At iterate    10  f =       -220.4  |proj g|=       0.80295
At iterate    11  f =      -220.42  |proj g|=       0.80048
At iterate    12  f =      -220.48  |proj g|=       0.66178
At iterate    13  f =      -220.61  |proj g|=       0.63441
At iterate    14  f =      -220.92  |proj g|=       0.58838
At iterate    15  f =      -221.46  |proj g|=       0.53384
At iterate    16  f =      -221.63  |proj g|=       0.42731
At iterate    17  f =       -222.7  |proj g|=       0.39373
At iterate    18  f =      -224.22  |proj g|=       0.81527
At iterate    19  f =      -224.35  |proj g|=       0.21867
At iterate    20  f =      -224.43  |proj g|=       0.17016
At iterate    21  f =      -224.45  |proj g|=       0.17296
At iterate    22  f =      -224.45  |proj g|=       0.10764
At iterate    23  f =      -224.45  |proj g|=        0.1068
At iterate    24  f =      -224.45  |proj g|=       0.10682

iterations 24
function evaluations 33
segments explored during Cauchy searches 26
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.106817
final function value -224.448

F = -224.448
final  value -224.448022 
converged
 
INFO  [03:34:34.004] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:34:34.094] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:34:34.102] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:34:41.168] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:34:49.422] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:34:56.839] [mlr3]  Finished benchmark 
INFO  [03:34:56.908] [bbotk] Result of batch 27: 
INFO  [03:34:56.910] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:34:56.910] [bbotk]              6.204289                 7.796098                       0.4932943 
INFO  [03:34:56.910] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:34:56.910] [bbotk]                     2650        0.548 -0.9631101         <NA>   0.9752662 
INFO  [03:34:56.910] [bbotk]                                 uhash 
INFO  [03:34:56.910] [bbotk]  c4ba925d-c2f5-4fe8-903e-8d4d7fd4ec07 
DEBUG [03:34:57.665] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.958217e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.964977 9458 
  - variance bounds :  8.947656e-06 0.0008958217 
  - best initial criterion value(s) :  227.1971 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -227.2  |proj g|=      0.82055
At iterate     1  f =      -228.75  |proj g|=       0.96646
At iterate     2  f =      -228.75  |proj g|=       0.92749
At iterate     3  f =      -228.76  |proj g|=       0.90902
At iterate     4  f =      -228.76  |proj g|=       0.90709
At iterate     5  f =      -228.76  |proj g|=       0.90809
At iterate     6  f =      -228.76  |proj g|=       0.90771

iterations 6
function evaluations 9
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.907714
final function value -228.756

F = -228.756
final  value -228.755514 
converged
 
INFO  [03:34:57.667] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:34:57.713] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:34:57.720] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:35:01.656] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:35:05.731] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:35:09.640] [mlr3]  Finished benchmark 
INFO  [03:35:09.759] [bbotk] Result of batch 28: 
INFO  [03:35:09.762] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:35:09.762] [bbotk]              6.260693                 9.519692                       0.1744609 
INFO  [03:35:09.762] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:35:09.762] [bbotk]                     1342        0.564 -0.9650785         <NA>   0.9678741 
INFO  [03:35:09.762] [bbotk]                                 uhash 
INFO  [03:35:09.762] [bbotk]  068a40eb-ab3c-4e3d-bd67-a85567cee9e0 
DEBUG [03:35:10.719] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.809914e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.964977 9458 
  - variance bounds :  8.741463e-06 0.0008809914 
  - best initial criterion value(s) :  210.9393 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -210.94  |proj g|=       2.5159
At iterate     1  f =      -219.82  |proj g|=         2.008
At iterate     2  f =      -220.76  |proj g|=        1.9711
At iterate     3  f =      -222.42  |proj g|=        1.7632
At iterate     4  f =      -222.73  |proj g|=        1.5493
At iterate     5  f =      -223.42  |proj g|=        1.5779
At iterate     6  f =      -224.67  |proj g|=        1.3036
At iterate     7  f =      -224.75  |proj g|=        1.3507
At iterate     8  f =      -224.75  |proj g|=        1.3523
At iterate     9  f =      -224.75  |proj g|=        1.3486
At iterate    10  f =      -224.75  |proj g|=        1.3497
At iterate    11  f =      -224.75  |proj g|=        1.3497

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.34967
final function value -224.75

F = -224.75
final  value -224.749986 
converged
 
INFO  [03:35:10.723] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:35:10.779] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:35:10.786] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:35:14.499] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:35:17.347] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:35:20.952] [mlr3]  Finished benchmark 
INFO  [03:35:21.021] [bbotk] Result of batch 29: 
INFO  [03:35:21.023] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:35:21.023] [bbotk]              4.974739                 4.380571                       0.1062948 
INFO  [03:35:21.023] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:35:21.023] [bbotk]                     1031        0.699 -0.9666233         <NA>   0.9583735 
INFO  [03:35:21.023] [bbotk]                                 uhash 
INFO  [03:35:21.023] [bbotk]  1b303093-ac54-44e5-9072-7d50af472023 
DEBUG [03:35:21.965] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.757577e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.964977 9458 
  - variance bounds :  8.7191e-06 0.0008757577 
  - best initial criterion value(s) :  229.9595 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -229.96  |proj g|=       0.8883
At iterate     1  f =      -232.47  |proj g|=       0.95289
At iterate     2  f =      -233.51  |proj g|=        1.2525
At iterate     3  f =      -234.38  |proj g|=        1.1018
At iterate     4  f =      -234.58  |proj g|=        1.1755
At iterate     5  f =      -234.59  |proj g|=        1.1463
At iterate     6  f =      -234.59  |proj g|=        1.1566
At iterate     7  f =      -234.59  |proj g|=        1.1568
At iterate     8  f =      -234.59  |proj g|=        1.1562
At iterate     9  f =      -234.59  |proj g|=        1.1563

iterations 9
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.15628
final function value -234.593

F = -234.593
final  value -234.592518 
converged
 
INFO  [03:35:21.969] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:35:22.025] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:35:22.032] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:35:35.806] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:35:47.408] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:36:01.733] [mlr3]  Finished benchmark 
INFO  [03:36:01.849] [bbotk] Result of batch 30: 
INFO  [03:36:01.851] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:36:01.851] [bbotk]              5.416464                 4.417359                       0.2885662 
INFO  [03:36:01.851] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:36:01.851] [bbotk]                     4407        0.698 -0.9623003         <NA>    0.974845 
INFO  [03:36:01.851] [bbotk]                                 uhash 
INFO  [03:36:01.851] [bbotk]  aff8bbbf-bda1-49e4-8510-d649fd6ea39d 
DEBUG [03:36:02.645] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.743532e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.964977 9458 
  - variance bounds :  8.743532e-06 0.0008846612 
  - best initial criterion value(s) :  235.6932 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -235.69  |proj g|=       2.8854
At iterate     1  f =      -236.08  |proj g|=        2.8818
At iterate     2  f =      -236.75  |proj g|=        1.9717
At iterate     3  f =      -237.51  |proj g|=        2.2117
At iterate     4  f =      -237.58  |proj g|=        2.4724
At iterate     5  f =      -237.62  |proj g|=         2.502
At iterate     6  f =      -237.64  |proj g|=        2.5001
At iterate     7  f =      -237.64  |proj g|=        2.4927
At iterate     8  f =      -237.64  |proj g|=        2.4929
At iterate     9  f =      -237.64  |proj g|=        2.4925
At iterate    10  f =      -237.64  |proj g|=        2.4926
At iterate    11  f =      -237.64  |proj g|=        2.4913
At iterate    12  f =      -237.64  |proj g|=        2.4877
At iterate    13  f =      -237.64  |proj g|=        2.4944
At iterate    14  f =      -237.64  |proj g|=        2.4868
At iterate    15  f =      -237.64  |proj g|=        2.4636
At iterate    16  f =      -237.65  |proj g|=        2.4306
At iterate    17  f =      -237.67  |proj g|=        2.3703
At iterate    18  f =      -237.71  |proj g|=        2.2665
At iterate    19  f =      -237.81  |proj g|=        2.0994
At iterate    20  f =         -238  |proj g|=        1.6521
At iterate    21  f =      -238.38  |proj g|=         1.414
At iterate    22  f =       -239.2  |proj g|=       0.40802
At iterate    23  f =      -242.29  |proj g|=        0.2504
At iterate    24  f =      -242.85  |proj g|=       0.24193
At iterate    25  f =      -243.25  |proj g|=       0.31263
At iterate    26  f =      -243.27  |proj g|=       0.76169
At iterate    27  f =      -243.27  |proj g|=       0.28877
At iterate    28  f =      -243.27  |proj g|=       0.29079
At iterate    29  f =      -243.27  |proj g|=       0.29067

iterations 29
function evaluations 34
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.290667
final function value -243.275

F = -243.275
final  value -243.274997 
converged
 
INFO  [03:36:02.649] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:36:02.707] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:36:02.714] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:36:05.707] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:36:09.091] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:36:12.242] [mlr3]  Finished benchmark 
INFO  [03:36:12.385] [bbotk] Result of batch 31: 
INFO  [03:36:12.387] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:36:12.387] [bbotk]              3.248555                 4.301086                       0.2876883 
INFO  [03:36:12.387] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:36:12.387] [bbotk]                     1474        0.564 -0.9628132         <NA>   0.9646652 
INFO  [03:36:12.387] [bbotk]                                 uhash 
INFO  [03:36:12.387] [bbotk]  020fbe53-289e-4184-8fb2-e714781ddfca 
DEBUG [03:36:13.172] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.603163e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.71929 15.35399 0.964977 9458 
  - variance bounds :  8.603163e-06 0.0008660489 
  - best initial criterion value(s) :  243.7596 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -243.76  |proj g|=      0.25204
At iterate     1  f =      -245.43  |proj g|=       0.86225
At iterate     2  f =      -245.49  |proj g|=       0.83854
At iterate     3  f =      -245.75  |proj g|=        0.8262
At iterate     4  f =      -246.11  |proj g|=       0.80698
At iterate     5  f =      -246.69  |proj g|=       0.85567
At iterate     6  f =      -247.01  |proj g|=        1.0296
At iterate     7  f =      -247.12  |proj g|=        1.1562
At iterate     8  f =      -247.14  |proj g|=        1.2151
At iterate     9  f =      -247.14  |proj g|=          1.23
At iterate    10  f =      -247.14  |proj g|=        1.2317
At iterate    11  f =      -247.14  |proj g|=        1.2316

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.2316
final function value -247.136

F = -247.136
final  value -247.135992 
converged
 
INFO  [03:36:13.176] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:36:13.235] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:36:13.242] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:36:17.654] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:36:22.144] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:36:26.476] [mlr3]  Finished benchmark 
INFO  [03:36:26.547] [bbotk] Result of batch 32: 
INFO  [03:36:26.549] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:36:26.549] [bbotk]              2.077107                 5.924013                       0.1255595 
INFO  [03:36:26.549] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:36:26.549] [bbotk]                     2108        0.563 -0.9636393         <NA>   0.9487413 
INFO  [03:36:26.549] [bbotk]                                 uhash 
INFO  [03:36:26.549] [bbotk]  c07699b8-28e0-4e25-8907-acfb7bb1d84f 
DEBUG [03:36:27.504] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.937188e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.80182 15.35399 0.964977 9458 
  - variance bounds :  8.898158e-06 0.0008937188 
  - best initial criterion value(s) :  244.9924 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -244.99  |proj g|=       3.0766
At iterate     1  f =      -245.45  |proj g|=         3.329
At iterate     2  f =      -246.11  |proj g|=        2.8249
At iterate     3  f =      -246.47  |proj g|=        1.8829
At iterate     4  f =      -246.55  |proj g|=        2.2493
At iterate     5  f =      -246.56  |proj g|=         2.164
At iterate     6  f =      -246.56  |proj g|=          2.15
At iterate     7  f =      -246.56  |proj g|=        2.1493
At iterate     8  f =      -246.56  |proj g|=        2.1507
At iterate     9  f =      -246.56  |proj g|=        2.1546
At iterate    10  f =      -246.56  |proj g|=        2.1649
At iterate    11  f =      -246.56  |proj g|=         2.179
At iterate    12  f =      -246.56  |proj g|=        2.2041
At iterate    13  f =      -246.57  |proj g|=        2.2092
At iterate    14  f =      -246.59  |proj g|=        2.2673
At iterate    15  f =      -246.68  |proj g|=        2.2643
At iterate    16  f =      -246.86  |proj g|=         2.345
At iterate    17  f =      -247.89  |proj g|=        2.4244
At iterate    18  f =      -249.62  |proj g|=        2.1102
At iterate    19  f =      -250.14  |proj g|=        2.2383
At iterate    20  f =      -251.48  |proj g|=         1.661
At iterate    21  f =       -252.3  |proj g|=        1.1946
At iterate    22  f =      -254.45  |proj g|=        0.7453
At iterate    23  f =      -254.57  |proj g|=       0.33635
At iterate    24  f =      -255.07  |proj g|=       0.68802
At iterate    25  f =      -255.14  |proj g|=       0.26479
At iterate    26  f =      -255.15  |proj g|=       0.42552
At iterate    27  f =      -255.15  |proj g|=       0.15591
At iterate    28  f =      -255.15  |proj g|=      0.062637
At iterate    29  f =      -255.15  |proj g|=      0.062517

iterations 29
function evaluations 39
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.0625174
final function value -255.149

F = -255.149
final  value -255.148914 
converged
 
INFO  [03:36:27.508] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:36:27.581] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:36:27.589] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:36:30.484] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:36:33.548] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:36:36.764] [mlr3]  Finished benchmark 
INFO  [03:36:36.882] [bbotk] Result of batch 33: 
INFO  [03:36:36.885] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:36:36.885] [bbotk]              9.982777                 3.986169                       0.4310392 
INFO  [03:36:36.885] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:36:36.885] [bbotk]                     1372        0.639 -0.9594024         <NA>   0.9727797 
INFO  [03:36:36.885] [bbotk]                                 uhash 
INFO  [03:36:36.885] [bbotk]  08424eda-ab05-40c4-80b4-53874845858a 
DEBUG [03:36:37.712] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.873074e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.721064e-06 0.0008873073 
  - best initial criterion value(s) :  237.9801 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -237.98  |proj g|=       1.9507
At iterate     1  f =      -245.05  |proj g|=        2.4914
At iterate     2  f =      -247.77  |proj g|=         3.027
At iterate     3  f =      -247.93  |proj g|=        2.9713
At iterate     4  f =      -247.96  |proj g|=        2.9394
At iterate     5  f =      -247.98  |proj g|=        2.9232
At iterate     6  f =      -248.02  |proj g|=        2.8919
At iterate     7  f =      -248.02  |proj g|=        2.8986
At iterate     8  f =      -248.02  |proj g|=         2.901
At iterate     9  f =      -248.02  |proj g|=        2.9009

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.90091
final function value -248.025

F = -248.025
final  value -248.024694 
converged
 
INFO  [03:36:37.717] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:36:37.783] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:36:37.792] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:36:40.255] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:36:42.631] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:36:45.096] [mlr3]  Finished benchmark 
INFO  [03:36:45.259] [bbotk] Result of batch 34: 
INFO  [03:36:45.261] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:36:45.261] [bbotk]              5.569574                 8.055411                       0.4906857 
INFO  [03:36:45.261] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:36:45.261] [bbotk]                     1077        0.607 -0.9601433         <NA>   0.9719936 
INFO  [03:36:45.261] [bbotk]                                 uhash 
INFO  [03:36:45.261] [bbotk]  b59290b8-50cd-43c1-8431-2de1acf772ee 
DEBUG [03:36:46.169] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.792763e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.572857e-06 0.0008792763 
  - best initial criterion value(s) :  255.1262 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -255.13  |proj g|=      0.79878
At iterate     1  f =      -255.79  |proj g|=        1.3688
At iterate     2  f =      -257.14  |proj g|=        1.1942
At iterate     3  f =       -257.6  |proj g|=        1.1171
At iterate     4  f =      -257.63  |proj g|=        1.0959
At iterate     5  f =      -257.71  |proj g|=        1.0973
At iterate     6  f =      -258.08  |proj g|=        1.1546
At iterate     7  f =      -258.21  |proj g|=        1.2232
At iterate     8  f =      -258.23  |proj g|=        1.2472
At iterate     9  f =      -258.23  |proj g|=        1.2558
At iterate    10  f =      -258.23  |proj g|=        1.2566
At iterate    11  f =      -258.23  |proj g|=        1.2566

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.25659
final function value -258.231

F = -258.231
final  value -258.230598 
converged
 
INFO  [03:36:46.172] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:36:46.234] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:36:46.244] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:36:49.995] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:36:53.822] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:36:57.657] [mlr3]  Finished benchmark 
INFO  [03:36:57.749] [bbotk] Result of batch 35: 
INFO  [03:36:57.751] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:36:57.751] [bbotk]              6.751362                 4.166252                      0.02621438 
INFO  [03:36:57.751] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [03:36:57.751] [bbotk]                     1784        0.704  -0.96429         <NA>   0.9499219 
INFO  [03:36:57.751] [bbotk]                                 uhash 
INFO  [03:36:57.751] [bbotk]  aa04c6ea-d35d-4ef5-80eb-c43f6aaefe32 
DEBUG [03:36:58.791] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.045798e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.823429e-06 0.0009045798 
  - best initial criterion value(s) :  259.5245 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -259.52  |proj g|=      0.84816
At iterate     1  f =      -259.67  |proj g|=        1.0831
At iterate     2  f =      -259.82  |proj g|=       0.92908
At iterate     3  f =      -259.82  |proj g|=       0.91349
At iterate     4  f =      -259.82  |proj g|=       0.91449
At iterate     5  f =      -259.82  |proj g|=       0.91448

iterations 5
function evaluations 8
segments explored during Cauchy searches 7
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.914475
final function value -259.821

F = -259.821
final  value -259.821025 
converged
 
INFO  [03:36:58.796] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:36:58.861] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:36:58.870] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:37:05.370] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:37:12.295] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:37:18.829] [mlr3]  Finished benchmark 
INFO  [03:37:18.905] [bbotk] Result of batch 36: 
INFO  [03:37:18.907] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:37:18.907] [bbotk]              9.481556                 5.675065                        0.375144 
INFO  [03:37:18.907] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:37:18.907] [bbotk]                     3097        0.742 -0.9663283         <NA>   0.9727338 
INFO  [03:37:18.907] [bbotk]                                 uhash 
INFO  [03:37:18.907] [bbotk]  f41b5a44-cc07-4d66-8455-2f13d5562928 
DEBUG [03:37:19.688] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.982831e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.767393e-06 0.0008982831 
  - best initial criterion value(s) :  255.8139 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -255.81  |proj g|=       2.1495
At iterate     1  f =      -266.82  |proj g|=        1.1446
At iterate     2  f =      -267.85  |proj g|=        1.1278
At iterate     3  f =      -268.66  |proj g|=        1.0403
At iterate     4  f =      -268.87  |proj g|=         1.086
At iterate     5  f =       -268.9  |proj g|=        1.0861
At iterate     6  f =      -269.05  |proj g|=        1.1059
At iterate     7  f =      -269.16  |proj g|=        1.1457
At iterate     8  f =      -269.18  |proj g|=        1.1691
At iterate     9  f =      -269.19  |proj g|=        1.1732
At iterate    10  f =      -269.19  |proj g|=        1.1742
At iterate    11  f =      -269.19  |proj g|=        1.1742

iterations 11
function evaluations 13
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.17419
final function value -269.187

F = -269.187
final  value -269.186539 
converged
 
INFO  [03:37:19.693] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:37:19.752] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:37:19.760] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:37:26.470] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:37:31.620] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:37:37.896] [mlr3]  Finished benchmark 
INFO  [03:37:37.965] [bbotk] Result of batch 37: 
INFO  [03:37:37.967] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:37:37.967] [bbotk]              8.437227                 4.543379                      0.06609324 
INFO  [03:37:37.967] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [03:37:37.967] [bbotk]                     1769        0.582     -0.96         <NA>   0.9624271 
INFO  [03:37:37.967] [bbotk]                                 uhash 
INFO  [03:37:37.967] [bbotk]  55dc3620-4f92-4c91-a2f6-d8b7ff0cc911 
DEBUG [03:37:38.751] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.865424e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.667502e-06 0.0008865424 
  - best initial criterion value(s) :  255.3118 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -255.31  |proj g|=       0.2261
At iterate     1  f =      -255.94  |proj g|=       0.29566
At iterate     2  f =      -255.96  |proj g|=       0.29152
At iterate     3  f =       -256.1  |proj g|=       0.25757
At iterate     4  f =      -256.24  |proj g|=        0.2411
At iterate     5  f =      -256.62  |proj g|=       0.21546
At iterate     6  f =      -256.73  |proj g|=       0.23521
At iterate     7  f =      -256.73  |proj g|=       0.23893
At iterate     8  f =      -256.73  |proj g|=       0.30993
At iterate     9  f =      -256.73  |proj g|=       0.28231

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.282307
final function value -256.727

F = -256.727
final  value -256.727305 
converged
 
INFO  [03:37:38.755] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:37:38.809] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:37:38.816] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:37:41.899] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:37:45.103] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:37:48.267] [mlr3]  Finished benchmark 
INFO  [03:37:48.336] [bbotk] Result of batch 38: 
INFO  [03:37:48.338] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:37:48.338] [bbotk]              8.006394                 4.213109                       0.4645745 
INFO  [03:37:48.338] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:37:48.338] [bbotk]                      948        0.586 -0.9695718         <NA>   0.9717129 
INFO  [03:37:48.338] [bbotk]                                 uhash 
INFO  [03:37:48.338] [bbotk]  83c2357b-c851-4e90-bfe5-e9c251188241 
DEBUG [03:37:49.245] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.786687e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.520397e-06 0.0008786687 
  - best initial criterion value(s) :  269.0711 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -269.07  |proj g|=        4.387
At iterate     1  f =      -269.93  |proj g|=        3.7693
At iterate     2  f =      -270.36  |proj g|=         3.655
At iterate     3  f =      -270.64  |proj g|=        3.4121
At iterate     4  f =      -270.68  |proj g|=        3.3631
At iterate     5  f =      -270.69  |proj g|=        3.3609
At iterate     6  f =      -270.69  |proj g|=        3.3655
At iterate     7  f =      -270.69  |proj g|=        3.3672
At iterate     8  f =      -270.69  |proj g|=        3.3669
At iterate     9  f =      -270.69  |proj g|=        3.3666
At iterate    10  f =      -270.69  |proj g|=        3.3637
At iterate    11  f =      -270.69  |proj g|=        3.3606
At iterate    12  f =      -270.69  |proj g|=        3.3546
At iterate    13  f =      -270.69  |proj g|=        3.3415
At iterate    14  f =      -270.69  |proj g|=        3.3627
At iterate    15  f =       -270.7  |proj g|=        3.3319
At iterate    16  f =      -270.72  |proj g|=        3.2354
At iterate    17  f =      -270.76  |proj g|=          3.11
At iterate    18  f =      -270.88  |proj g|=        2.8886
At iterate    19  f =      -271.17  |proj g|=        2.5499
At iterate    20  f =      -271.78  |proj g|=        1.9388
At iterate    21  f =      -272.96  |proj g|=        1.5074
At iterate    22  f =      -276.64  |proj g|=       0.51248
At iterate    23  f =      -280.56  |proj g|=       0.78745
At iterate    24  f =      -280.69  |proj g|=       0.73108
At iterate    25  f =      -280.73  |proj g|=       0.73331
At iterate    26  f =      -280.74  |proj g|=       0.73611
At iterate    27  f =      -280.74  |proj g|=       0.73791
At iterate    28  f =      -280.74  |proj g|=       0.74257
At iterate    29  f =      -280.74  |proj g|=       0.74311
At iterate    30  f =      -280.74  |proj g|=       0.74319

iterations 30
function evaluations 35
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.743188
final function value -280.742

F = -280.742
final  value -280.742127 
converged
 
INFO  [03:37:49.249] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:37:49.323] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:37:49.330] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:37:57.976] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:38:06.214] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:38:14.737] [mlr3]  Finished benchmark 
INFO  [03:38:14.805] [bbotk] Result of batch 39: 
INFO  [03:38:14.807] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:38:14.807] [bbotk]              5.149098                 9.190973                       0.2490879 
INFO  [03:38:14.807] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:38:14.807] [bbotk]                     2755        0.664 -0.9622393         <NA>   0.9726886 
INFO  [03:38:14.807] [bbotk]                                 uhash 
INFO  [03:38:14.807] [bbotk]  84100f95-a24b-4229-981d-3f7df4324432 
DEBUG [03:38:15.646] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.726536e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.433496e-06 0.0008726536 
  - best initial criterion value(s) :  246.4853 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -246.49  |proj g|=       0.7349
At iterate     1  f =       -256.2  |proj g|=       0.68667
At iterate     2  f =      -257.04  |proj g|=       0.65308
At iterate     3  f =      -259.12  |proj g|=       0.50695
At iterate     4  f =      -259.85  |proj g|=       0.42019
At iterate     5  f =      -261.59  |proj g|=       0.48916
At iterate     6  f =      -262.96  |proj g|=       0.53451
At iterate     7  f =      -263.11  |proj g|=       0.37427
At iterate     8  f =      -263.16  |proj g|=       0.78013
At iterate     9  f =      -263.16  |proj g|=       0.41743
At iterate    10  f =      -263.16  |proj g|=       0.60783
At iterate    11  f =      -263.16  |proj g|=       0.61359

iterations 11
function evaluations 16
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.613587
final function value -263.164

F = -263.164
final  value -263.163862 
converged
 
INFO  [03:38:15.650] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:38:15.705] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:38:15.712] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:38:24.923] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:38:32.017] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:38:39.610] [mlr3]  Finished benchmark 
INFO  [03:38:39.678] [bbotk] Result of batch 40: 
INFO  [03:38:39.680] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:38:39.680] [bbotk]              8.039971                 5.876608                       0.1250327 
INFO  [03:38:39.680] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:38:39.680] [bbotk]                     2697        0.614 -0.9702134         <NA>   0.9704907 
INFO  [03:38:39.680] [bbotk]                                 uhash 
INFO  [03:38:39.680] [bbotk]  4020c1a3-c848-486a-8aae-3212b81dd109 
DEBUG [03:38:40.719] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.631189e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.360568e-06 0.0008631189 
  - best initial criterion value(s) :  275.6727 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -275.67  |proj g|=       2.6576
At iterate     1  f =      -280.03  |proj g|=        2.7131
At iterate     2  f =      -280.08  |proj g|=         2.711
At iterate     3  f =      -280.13  |proj g|=        2.6935
At iterate     4  f =      -280.16  |proj g|=        2.6762
At iterate     5  f =      -280.38  |proj g|=        2.4574
At iterate     6  f =      -280.47  |proj g|=        2.3591
At iterate     7  f =      -280.48  |proj g|=        2.3329
At iterate     8  f =      -280.48  |proj g|=        2.3344
At iterate     9  f =      -280.51  |proj g|=        2.3578
At iterate    10  f =      -280.64  |proj g|=        2.4067
At iterate    11  f =      -281.03  |proj g|=        2.4457
At iterate    12  f =       -281.9  |proj g|=        2.3502
At iterate    13  f =      -281.94  |proj g|=        2.2552
At iterate    14  f =      -283.99  |proj g|=        1.8277
At iterate    15  f =      -284.87  |proj g|=        1.3641
At iterate    16  f =      -285.71  |proj g|=        1.3016
At iterate    17  f =      -286.98  |proj g|=         1.053
At iterate    18  f =      -288.22  |proj g|=        1.4419
At iterate    19  f =      -288.49  |proj g|=        1.5206
At iterate    20  f =      -288.52  |proj g|=        1.4194
At iterate    21  f =      -288.52  |proj g|=        1.4371
At iterate    22  f =      -288.52  |proj g|=        1.4307
At iterate    23  f =      -288.52  |proj g|=        1.4117
At iterate    24  f =      -288.52  |proj g|=        1.4139
At iterate    25  f =      -288.52  |proj g|=        1.4155
At iterate    26  f =      -288.52  |proj g|=        1.4155

iterations 26
function evaluations 35
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.41555
final function value -288.524

F = -288.524
final  value -288.524097 
converged
 
INFO  [03:38:40.723] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:38:40.798] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:38:40.805] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:38:56.890] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:39:10.078] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:39:24.970] [mlr3]  Finished benchmark 
INFO  [03:39:25.038] [bbotk] Result of batch 41: 
INFO  [03:39:25.040] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:39:25.040] [bbotk]              8.582778                 6.016805                       0.2612926 
INFO  [03:39:25.040] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:39:25.040] [bbotk]                     4609        0.768 -0.9643135         <NA>   0.9733815 
INFO  [03:39:25.040] [bbotk]                                 uhash 
INFO  [03:39:25.040] [bbotk]  6ee00960-c555-4e49-9a18-113409f09e34 
DEBUG [03:39:26.039] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.58545e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.348656e-06 0.000858545 
  - best initial criterion value(s) :  292.037 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -292.04  |proj g|=       0.4988
At iterate     1  f =      -293.56  |proj g|=       0.84496
At iterate     2  f =      -293.59  |proj g|=       0.84435
At iterate     3  f =      -293.84  |proj g|=       0.83802
At iterate     4  f =      -294.11  |proj g|=       0.83091
At iterate     5  f =      -294.89  |proj g|=       0.89153
At iterate     6  f =       -295.7  |proj g|=        1.3605
At iterate     7  f =      -295.77  |proj g|=        1.3753
At iterate     8  f =      -295.78  |proj g|=        1.3829
At iterate     9  f =      -295.78  |proj g|=        1.3854
At iterate    10  f =      -295.78  |proj g|=        1.3864
At iterate    11  f =      -295.78  |proj g|=        1.3866

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.3866
final function value -295.775

F = -295.775
final  value -295.775458 
converged
 
INFO  [03:39:26.043] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:39:26.098] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:39:26.105] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:39:32.932] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:39:39.838] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:39:47.392] [mlr3]  Finished benchmark 
INFO  [03:39:47.461] [bbotk] Result of batch 42: 
INFO  [03:39:47.463] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:39:47.463] [bbotk]              9.917549                 4.544062                        0.492369 
INFO  [03:39:47.463] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:39:47.463] [bbotk]                     2670         0.78 -0.9621964         <NA>   0.9726608 
INFO  [03:39:47.463] [bbotk]                                 uhash 
INFO  [03:39:47.463] [bbotk]  5304f6c8-0c14-481a-ab46-6a23ff717082 
DEBUG [03:39:48.223] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.525258e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.267931e-06 0.0008525258 
  - best initial criterion value(s) :  249.7246 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -249.72  |proj g|=       0.9584
At iterate     1  f =      -279.44  |proj g|=        3.3115
At iterate     2  f =      -301.82  |proj g|=        1.2938
At iterate     3  f =      -302.07  |proj g|=        1.3001
At iterate     4  f =      -302.81  |proj g|=        1.3213
At iterate     5  f =      -302.83  |proj g|=        1.3229
At iterate     6  f =      -302.84  |proj g|=        1.3234
At iterate     7  f =      -302.84  |proj g|=        1.3246
At iterate     8  f =      -302.84  |proj g|=        1.3285
At iterate     9  f =      -302.84  |proj g|=        1.3285
At iterate    10  f =      -302.84  |proj g|=        1.3285

iterations 10
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.32847
final function value -302.836

F = -302.836
final  value -302.836270 
converged
 
INFO  [03:39:48.227] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:39:48.316] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:39:48.323] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:39:54.945] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:39:58.722] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:40:02.693] [mlr3]  Finished benchmark 
INFO  [03:40:02.762] [bbotk] Result of batch 43: 
INFO  [03:40:02.764] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:40:02.764] [bbotk]                7.1692                 7.886977                       0.1785786 
INFO  [03:40:02.764] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:40:02.764] [bbotk]                     1438        0.561 -0.9571781         <NA>   0.9688999 
INFO  [03:40:02.764] [bbotk]                                 uhash 
INFO  [03:40:02.764] [bbotk]  0ec03446-f7fa-45e2-9d24-121f7c82f2d5 
DEBUG [03:40:03.517] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.418433e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.155057e-06 0.0008418433 
  - best initial criterion value(s) :  291.1489 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -291.15  |proj g|=      0.89916
At iterate     1  f =      -298.86  |proj g|=        0.3572
At iterate     2  f =      -299.59  |proj g|=        1.0727
At iterate     3  f =      -299.87  |proj g|=       0.93374
At iterate     4  f =      -299.95  |proj g|=        0.6941
At iterate     5  f =      -299.97  |proj g|=       0.79062
At iterate     6  f =      -299.97  |proj g|=       0.77549
At iterate     7  f =      -299.97  |proj g|=        0.7736
At iterate     8  f =      -299.97  |proj g|=       0.77341
At iterate     9  f =      -299.97  |proj g|=       0.77446
At iterate    10  f =      -299.97  |proj g|=       0.77568
At iterate    11  f =      -299.97  |proj g|=        0.7758

iterations 11
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.775804
final function value -299.974

F = -299.974
final  value -299.974412 
converged
 
INFO  [03:40:03.521] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:40:03.579] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:40:03.586] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:40:11.188] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:40:17.463] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:40:25.985] [mlr3]  Finished benchmark 
INFO  [03:40:26.090] [bbotk] Result of batch 44: 
INFO  [03:40:26.092] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:40:26.092] [bbotk]              4.914034                 5.683415                       0.4704302 
INFO  [03:40:26.092] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:40:26.092] [bbotk]                     2235        0.562 -0.9654777         <NA>   0.9738765 
INFO  [03:40:26.092] [bbotk]                                 uhash 
INFO  [03:40:26.092] [bbotk]  5c20971b-2db9-4593-a885-0a31caf7a98f 
DEBUG [03:40:26.920] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.382795e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.121249e-06 0.0008382795 
  - best initial criterion value(s) :  292.5909 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -292.59  |proj g|=       5.5741
At iterate     1  f =      -297.17  |proj g|=        4.5525
At iterate     2  f =      -298.41  |proj g|=         4.437
At iterate     3  f =      -299.39  |proj g|=        3.8595
At iterate     4  f =      -299.57  |proj g|=         3.701
At iterate     5  f =      -299.64  |proj g|=        3.6684
At iterate     6  f =      -299.66  |proj g|=        3.6966
At iterate     7  f =      -299.66  |proj g|=        3.7254
At iterate     8  f =      -299.66  |proj g|=        3.7255
At iterate     9  f =      -299.66  |proj g|=        3.7261
At iterate    10  f =      -299.66  |proj g|=         3.727
At iterate    11  f =      -299.66  |proj g|=        3.7315
At iterate    12  f =      -299.66  |proj g|=        3.7374
At iterate    13  f =      -299.66  |proj g|=        3.7474
At iterate    14  f =      -299.66  |proj g|=        3.7656
At iterate    15  f =      -299.67  |proj g|=        3.7895
At iterate    16  f =      -299.67  |proj g|=        3.8284
At iterate    17  f =      -299.69  |proj g|=         3.876
At iterate    18  f =      -299.77  |proj g|=        3.9234
At iterate    19  f =      -300.11  |proj g|=        3.9907
At iterate    20  f =      -300.82  |proj g|=        3.9091
At iterate    21  f =      -302.86  |proj g|=        3.0937
At iterate    22  f =      -303.14  |proj g|=        2.7542
At iterate    23  f =      -307.01  |proj g|=        1.6652
At iterate    24  f =      -311.14  |proj g|=          1.13
At iterate    25  f =      -312.79  |proj g|=        1.1098
At iterate    26  f =      -313.29  |proj g|=        1.1182
At iterate    27  f =      -313.55  |proj g|=        1.1314
At iterate    28  f =      -313.67  |proj g|=        1.1941
At iterate    29  f =      -313.75  |proj g|=        1.1944
At iterate    30  f =      -313.76  |proj g|=        1.1997
At iterate    31  f =      -313.77  |proj g|=        1.2031
At iterate    32  f =      -313.77  |proj g|=         1.205
At iterate    33  f =      -313.77  |proj g|=        1.2056
At iterate    34  f =      -313.77  |proj g|=        1.2056

iterations 34
function evaluations 42
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.20561
final function value -313.768

F = -313.768
final  value -313.768257 
converged
 
INFO  [03:40:26.922] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:40:26.968] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:40:26.975] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:40:37.586] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:40:47.258] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:40:54.270] [mlr3]  Finished benchmark 
INFO  [03:40:54.339] [bbotk] Result of batch 45: 
INFO  [03:40:54.341] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:40:54.341] [bbotk]              4.454856                 6.786498                       0.1172826 
INFO  [03:40:54.341] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:40:54.341] [bbotk]                     3536        0.569 -0.9584191         <NA>   0.9694963 
INFO  [03:40:54.341] [bbotk]                                 uhash 
INFO  [03:40:54.341] [bbotk]  ca032ce0-4349-4552-8d28-c047c2168971 
DEBUG [03:40:55.185] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.284267e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9458 
  - variance bounds :  8.064546e-06 0.0008284266 
  - best initial criterion value(s) :  294.4941 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -294.49  |proj g|=       4.2905
At iterate     1  f =      -294.76  |proj g|=        4.1976
At iterate     2  f =      -295.78  |proj g|=        3.9248
At iterate     3  f =       -298.4  |proj g|=        2.9582
At iterate     4  f =      -298.77  |proj g|=        2.3399
At iterate     5  f =      -298.83  |proj g|=        2.5172
At iterate     6  f =      -298.83  |proj g|=        2.5009
At iterate     7  f =      -298.83  |proj g|=        2.4975
At iterate     8  f =      -298.83  |proj g|=        2.4973
At iterate     9  f =      -298.83  |proj g|=        2.4969
At iterate    10  f =      -298.83  |proj g|=        2.4964
At iterate    11  f =      -298.83  |proj g|=        2.4953
At iterate    12  f =      -298.83  |proj g|=        2.4934
At iterate    13  f =      -298.83  |proj g|=        2.4899
At iterate    14  f =      -298.83  |proj g|=        2.4834
At iterate    15  f =      -298.83  |proj g|=        2.4736
At iterate    16  f =      -298.83  |proj g|=         2.473
At iterate    17  f =      -298.83  |proj g|=        2.4605
At iterate    18  f =      -299.31  |proj g|=        2.2547
At iterate    19  f =      -302.87  |proj g|=        1.3516
At iterate    20  f =      -307.57  |proj g|=       0.84198
At iterate    21  f =      -310.53  |proj g|=       0.81859
At iterate    22  f =      -310.54  |proj g|=       0.81834
At iterate    23  f =      -310.64  |proj g|=       0.81431
At iterate    24  f =      -310.84  |proj g|=       0.79798
At iterate    25  f =      -310.85  |proj g|=       0.46472
At iterate    26  f =      -310.85  |proj g|=       0.47099
At iterate    27  f =      -310.85  |proj g|=       0.47166
At iterate    28  f =      -310.85  |proj g|=       0.47174

iterations 28
function evaluations 37
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.471739
final function value -310.851

F = -310.851
final  value -310.851151 
converged
 
INFO  [03:40:55.189] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:40:55.272] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:40:55.283] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:41:05.365] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:41:15.486] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:41:26.646] [mlr3]  Finished benchmark 
INFO  [03:41:26.758] [bbotk] Result of batch 46: 
INFO  [03:41:26.760] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:41:26.760] [bbotk]              6.154457                 4.024338                        0.376388 
INFO  [03:41:26.760] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:41:26.760] [bbotk]                     4999        0.567 -0.9651137         <NA>    0.976204 
INFO  [03:41:26.760] [bbotk]                                 uhash 
INFO  [03:41:26.760] [bbotk]  b2039395-977d-4bcd-896d-0b9770dd9d6b 
DEBUG [03:41:27.610] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.300968e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.964977 9526 
  - variance bounds :  8.129448e-06 0.0008300968 
  - best initial criterion value(s) :  296.9204 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -296.92  |proj g|=       2.9769
At iterate     1  f =      -302.28  |proj g|=        3.6717
At iterate     2  f =       -304.2  |proj g|=        4.0956
At iterate     3  f =      -304.37  |proj g|=         4.099
At iterate     4  f =      -304.82  |proj g|=        4.0179
At iterate     5  f =      -304.84  |proj g|=        3.9835
At iterate     6  f =      -304.84  |proj g|=        4.0029
At iterate     7  f =      -304.84  |proj g|=        3.9995
At iterate     8  f =      -304.84  |proj g|=        3.9995
At iterate     9  f =      -304.84  |proj g|=        3.9992
At iterate    10  f =      -304.84  |proj g|=        3.9979
At iterate    11  f =      -304.84  |proj g|=        3.9955
At iterate    12  f =      -304.84  |proj g|=        3.9908
At iterate    13  f =      -304.85  |proj g|=        3.9847
At iterate    14  f =      -304.85  |proj g|=        3.9754
At iterate    15  f =      -304.86  |proj g|=        3.9651
At iterate    16  f =      -304.91  |proj g|=        3.9268
At iterate    17  f =      -305.07  |proj g|=        3.8235
At iterate    18  f =      -305.55  |proj g|=        3.5709
At iterate    19  f =      -306.89  |proj g|=        2.9982
At iterate    20  f =      -307.52  |proj g|=        2.5699
At iterate    21  f =      -310.94  |proj g|=        1.8973
At iterate    22  f =       -316.8  |proj g|=        2.3785
At iterate    23  f =      -319.19  |proj g|=        2.8203
At iterate    24  f =      -319.45  |proj g|=        2.9175
At iterate    25  f =       -319.5  |proj g|=        2.9835
At iterate    26  f =      -319.51  |proj g|=        3.0133
At iterate    27  f =      -319.51  |proj g|=        3.0292
At iterate    28  f =      -319.51  |proj g|=        3.0304
At iterate    29  f =      -319.51  |proj g|=        3.0304

iterations 29
function evaluations 37
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 3.03045
final function value -319.515

F = -319.515
final  value -319.514800 
converged
 
INFO  [03:41:27.614] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:41:27.674] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:41:27.682] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:41:37.218] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:41:46.822] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:41:56.555] [mlr3]  Finished benchmark 
INFO  [03:41:56.628] [bbotk] Result of batch 47: 
INFO  [03:41:56.630] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:41:56.630] [bbotk]              5.401928                 5.238549                     0.003892507 
INFO  [03:41:56.630] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:41:56.630] [bbotk]                     4455        0.581 -0.9614744         <NA>   0.9270275 
INFO  [03:41:56.630] [bbotk]                                 uhash 
INFO  [03:41:56.630] [bbotk]  ce9288e1-1163-4466-a0a3-6953afeaee79 
DEBUG [03:41:57.522] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.019003e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.019003e-05 0.001030089 
  - best initial criterion value(s) :  294.2927 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -294.29  |proj g|=       0.3545
At iterate     1  f =       -297.4  |proj g|=        1.7118
At iterate     2  f =      -297.45  |proj g|=        1.6419
At iterate     3  f =      -297.47  |proj g|=        1.5566
At iterate     4  f =      -297.56  |proj g|=        1.4245
At iterate     5  f =       -297.7  |proj g|=        1.1349
At iterate     6  f =      -297.72  |proj g|=        1.2363
At iterate     7  f =      -297.72  |proj g|=        1.2299
At iterate     8  f =      -297.72  |proj g|=        1.2304
At iterate     9  f =      -297.72  |proj g|=        1.2306
At iterate    10  f =      -297.72  |proj g|=        1.2318
At iterate    11  f =      -297.72  |proj g|=        1.2335
At iterate    12  f =      -297.72  |proj g|=        1.2358
At iterate    13  f =      -297.72  |proj g|=         1.237
At iterate    14  f =      -297.72  |proj g|=        1.2401
At iterate    15  f =      -298.01  |proj g|=        1.1886
At iterate    16  f =      -298.87  |proj g|=       0.80327
At iterate    17  f =      -299.64  |proj g|=        0.4268
At iterate    18  f =       -300.1  |proj g|=       0.18782
At iterate    19  f =      -300.13  |proj g|=       0.27387
At iterate    20  f =      -300.32  |proj g|=        0.1606
At iterate    21  f =      -300.36  |proj g|=       0.16532
At iterate    22  f =      -300.38  |proj g|=       0.16434
At iterate    23  f =      -300.38  |proj g|=       0.16234
At iterate    24  f =      -300.38  |proj g|=       0.21848
At iterate    25  f =      -300.38  |proj g|=      0.088056
At iterate    26  f =      -300.38  |proj g|=      0.093452
At iterate    27  f =      -300.38  |proj g|=      0.090529
At iterate    28  f =      -300.38  |proj g|=      0.090358

iterations 28
function evaluations 42
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.0903578
final function value -300.385

F = -300.385
final  value -300.384850 
converged
 
INFO  [03:41:57.527] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:41:57.619] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:41:57.631] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:42:04.520] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:42:11.801] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:42:18.200] [mlr3]  Finished benchmark 
INFO  [03:42:18.271] [bbotk] Result of batch 48: 
INFO  [03:42:18.273] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:42:18.273] [bbotk]              3.585351                 3.666285                       0.1914349 
INFO  [03:42:18.273] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:42:18.273] [bbotk]                     2546          0.6 -0.9646379         <NA>   0.9673494 
INFO  [03:42:18.273] [bbotk]                                 uhash 
INFO  [03:42:18.273] [bbotk]  c781ae8a-b720-4eef-a1cf-b4015a751ab7 
DEBUG [03:42:19.094] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.006174e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.006174e-05 0.001018002 
  - best initial criterion value(s) :  280.5729 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -280.57  |proj g|=       2.4077
At iterate     1  f =      -290.17  |proj g|=        2.5472
At iterate     2  f =      -292.09  |proj g|=        2.2655
At iterate     3  f =      -294.55  |proj g|=        1.5514
At iterate     4  f =      -294.71  |proj g|=         1.012
At iterate     5  f =      -295.09  |proj g|=          1.32
At iterate     6  f =      -295.62  |proj g|=        1.4986
At iterate     7  f =      -297.53  |proj g|=        1.6944
At iterate     8  f =      -297.89  |proj g|=        1.4223
At iterate     9  f =         -298  |proj g|=         1.049
At iterate    10  f =      -298.06  |proj g|=        1.2979
At iterate    11  f =      -298.08  |proj g|=        1.2531
At iterate    12  f =      -298.08  |proj g|=         1.234
At iterate    13  f =      -298.08  |proj g|=        1.2375
At iterate    14  f =      -298.08  |proj g|=        1.2374

iterations 14
function evaluations 19
segments explored during Cauchy searches 16
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.23744
final function value -298.077

F = -298.077
final  value -298.077207 
converged
 
INFO  [03:42:19.098] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:42:19.157] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:42:19.354] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:42:28.927] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:42:35.499] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:42:42.610] [mlr3]  Finished benchmark 
INFO  [03:42:42.677] [bbotk] Result of batch 49: 
INFO  [03:42:42.679] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:42:42.679] [bbotk]              8.615666                 9.251496                        0.100415 
INFO  [03:42:42.679] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:42:42.679] [bbotk]                     2253        0.586 -0.9692667         <NA>   0.9682739 
INFO  [03:42:42.679] [bbotk]                                 uhash 
INFO  [03:42:42.679] [bbotk]  3277a9b5-da05-4c7b-a850-6deeddee38ba 
DEBUG [03:42:43.530] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.940814e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.940814e-06 0.001012116 
  - best initial criterion value(s) :  293.1672 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -293.17  |proj g|=       0.9678
At iterate     1  f =      -300.42  |proj g|=        2.2942
At iterate     2  f =      -300.77  |proj g|=         2.221
At iterate     3  f =      -301.05  |proj g|=        1.9608
At iterate     4  f =      -301.11  |proj g|=        2.0574
At iterate     5  f =      -301.18  |proj g|=        2.0282
At iterate     6  f =      -301.49  |proj g|=         1.961
At iterate     7  f =      -302.03  |proj g|=        1.9469
At iterate     8  f =      -302.65  |proj g|=        2.1324
At iterate     9  f =      -302.84  |proj g|=        2.3381
At iterate    10  f =      -302.91  |proj g|=        2.4639
At iterate    11  f =      -302.92  |proj g|=        2.5115
At iterate    12  f =      -302.92  |proj g|=        2.5195
At iterate    13  f =      -302.92  |proj g|=          2.52

iterations 13
function evaluations 17
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.51999
final function value -302.925

F = -302.925
final  value -302.924527 
converged
 
INFO  [03:42:43.535] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:42:43.591] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:42:43.598] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:42:46.970] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:42:51.612] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:42:55.134] [mlr3]  Finished benchmark 
INFO  [03:42:55.203] [bbotk] Result of batch 50: 
INFO  [03:42:55.205] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:42:55.205] [bbotk]              8.911222                  2.37409                       0.4848802 
INFO  [03:42:55.205] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:42:55.205] [bbotk]                     1198        0.624 -0.9654993         <NA>   0.9727073 
INFO  [03:42:55.205] [bbotk]                                 uhash 
INFO  [03:42:55.205] [bbotk]  25358add-dab6-483e-b91b-17bd3e9cad2d 
DEBUG [03:42:56.081] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.871548e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.871548e-06 0.001001906 
  - best initial criterion value(s) :  300.7284 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -300.73  |proj g|=       2.3006
At iterate     1  f =      -305.96  |proj g|=       0.91697
At iterate     2  f =       -306.1  |proj g|=       0.91644
At iterate     3  f =      -306.24  |proj g|=        1.0655
At iterate     4  f =      -306.54  |proj g|=        1.1191
At iterate     5  f =      -308.61  |proj g|=         1.133
At iterate     6  f =      -310.43  |proj g|=        0.9298
At iterate     7  f =      -311.29  |proj g|=       0.83854
At iterate     8  f =      -311.66  |proj g|=       0.82399
At iterate     9  f =      -311.84  |proj g|=       0.81937
At iterate    10  f =      -311.86  |proj g|=       0.81668
At iterate    11  f =      -311.86  |proj g|=       0.81668
At iterate    12  f =      -311.86  |proj g|=       0.81668
At iterate    13  f =      -311.86  |proj g|=       0.81667
At iterate    14  f =      -311.86  |proj g|=       0.81667
At iterate    15  f =      -311.86  |proj g|=       0.81667
At iterate    16  f =      -311.91  |proj g|=        0.8139
At iterate    17  f =      -312.08  |proj g|=       0.79602
At iterate    18  f =      -312.08  |proj g|=        0.3374
At iterate    19  f =      -312.08  |proj g|=       0.33398
At iterate    20  f =      -312.08  |proj g|=        0.3337
At iterate    21  f =      -312.08  |proj g|=       0.33366

iterations 21
function evaluations 31
segments explored during Cauchy searches 23
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.333659
final function value -312.082

F = -312.082
final  value -312.081533 
converged
 
INFO  [03:42:56.085] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:42:56.154] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:42:56.161] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:43:11.513] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:43:25.789] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:43:42.549] [mlr3]  Finished benchmark 
INFO  [03:43:42.615] [bbotk] Result of batch 51: 
INFO  [03:43:42.617] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:43:42.617] [bbotk]              8.168047                 3.776342                       0.2924682 
INFO  [03:43:42.617] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:43:42.617] [bbotk]                     4935        0.602 -0.9637795         <NA>   0.9743583 
INFO  [03:43:42.617] [bbotk]                                 uhash 
INFO  [03:43:42.617] [bbotk]  0c27cc0a-8006-4b4d-bb7c-5a7caea09f66 
DEBUG [03:43:43.443] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.832535e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.832535e-06 0.0009958128 
  - best initial criterion value(s) :  313.9937 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -313.99  |proj g|=       1.0443
At iterate     1  f =      -317.84  |proj g|=       0.16027
At iterate     2  f =      -318.42  |proj g|=       0.83113
At iterate     3  f =      -318.53  |proj g|=       0.82328
At iterate     4  f =      -318.54  |proj g|=       0.47335
At iterate     5  f =      -318.54  |proj g|=       0.36982
At iterate     6  f =      -318.54  |proj g|=       0.37289
At iterate     7  f =      -318.54  |proj g|=       0.37466
At iterate     8  f =      -318.54  |proj g|=       0.37509

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.375094
final function value -318.54

F = -318.54
final  value -318.539602 
converged
 
INFO  [03:43:43.447] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:43:43.504] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:43:43.511] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:43:46.041] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:43:48.451] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:43:51.259] [mlr3]  Finished benchmark 
INFO  [03:43:51.326] [bbotk] Result of batch 52: 
INFO  [03:43:51.328] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:43:51.328] [bbotk]              5.445909                  6.98222                       0.2009769 
INFO  [03:43:51.328] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [03:43:51.328] [bbotk]                      810        0.601 -0.964787         <NA>   0.9636437 
INFO  [03:43:51.328] [bbotk]                                 uhash 
INFO  [03:43:51.328] [bbotk]  cca450e9-6964-447a-994a-d8f7eb869598 
DEBUG [03:43:52.164] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.720598e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.720598e-06 0.0009782849 
  - best initial criterion value(s) :  299.0059 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -299.01  |proj g|=       2.1865
At iterate     1  f =      -304.55  |proj g|=        4.9249
At iterate     2  f =      -304.65  |proj g|=        4.8267
At iterate     3  f =      -304.94  |proj g|=        4.3874
At iterate     4  f =      -305.79  |proj g|=        3.7763
At iterate     5  f =      -308.51  |proj g|=        2.9296
At iterate     6  f =      -309.15  |proj g|=        2.5903
At iterate     7  f =      -309.21  |proj g|=         2.859
At iterate     8  f =      -309.22  |proj g|=        2.7486
At iterate     9  f =      -309.23  |proj g|=        2.7502
At iterate    10  f =      -309.23  |proj g|=          2.75
At iterate    11  f =      -309.23  |proj g|=          2.75

iterations 11
function evaluations 16
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.74996
final function value -309.225

F = -309.225
final  value -309.225080 
converged
 
INFO  [03:43:52.168] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:43:52.223] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:43:52.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:44:04.815] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:44:17.404] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:44:32.845] [mlr3]  Finished benchmark 
INFO  [03:44:32.931] [bbotk] Result of batch 53: 
INFO  [03:44:32.933] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:44:32.933] [bbotk]              4.686224                 2.888134                       0.4497752 
INFO  [03:44:32.933] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:44:32.933] [bbotk]                     4557        0.607 -0.9691494         <NA>   0.9751256 
INFO  [03:44:32.933] [bbotk]                                 uhash 
INFO  [03:44:32.933] [bbotk]  5d141153-4834-4c1d-8b58-1e537b583c36 
DEBUG [03:44:33.783] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.698643e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.698642e-06 0.0009819483 
  - best initial criterion value(s) :  305.3395 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -305.34  |proj g|=       7.4911
At iterate     1  f =      -317.41  |proj g|=       0.77361
At iterate     2  f =      -318.46  |proj g|=        1.0899
At iterate     3  f =      -318.89  |proj g|=       0.90184
At iterate     4  f =      -318.94  |proj g|=       0.90345
At iterate     5  f =      -318.95  |proj g|=       0.90311
At iterate     6  f =      -318.95  |proj g|=       0.90315
At iterate     7  f =      -318.95  |proj g|=       0.90315

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.903149
final function value -318.949

F = -318.949
final  value -318.949449 
converged
 
INFO  [03:44:33.787] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:44:33.842] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:44:33.849] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:44:44.581] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:44:56.032] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:45:12.462] [mlr3]  Finished benchmark 
INFO  [03:45:12.531] [bbotk] Result of batch 54: 
INFO  [03:45:12.533] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:45:12.533] [bbotk]              2.286899                 3.829066                       0.1951304 
INFO  [03:45:12.533] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:45:12.533] [bbotk]                     4198        0.624 -0.9693294         <NA>   0.9593633 
INFO  [03:45:12.533] [bbotk]                                 uhash 
INFO  [03:45:12.533] [bbotk]  b81290ad-7a3f-49a5-8297-32b1f7851208 
DEBUG [03:45:13.784] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.639652e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.639651e-06 0.0009680114 
  - best initial criterion value(s) :  313.9405 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -313.94  |proj g|=       1.5864
At iterate     1  f =       -316.5  |proj g|=        1.1666
At iterate     2  f =      -318.55  |proj g|=       0.90706
At iterate     3  f =      -319.57  |proj g|=       0.84963
At iterate     4  f =      -319.65  |proj g|=       0.84636
At iterate     5  f =      -319.68  |proj g|=       0.84619
At iterate     6  f =      -319.77  |proj g|=       0.84325
At iterate     7  f =       -319.9  |proj g|=       0.83554
At iterate     8  f =      -320.01  |proj g|=       0.82487
At iterate     9  f =      -320.03  |proj g|=       0.82451
At iterate    10  f =      -320.04  |proj g|=       0.81961
At iterate    11  f =      -320.04  |proj g|=       0.81898
At iterate    12  f =      -320.04  |proj g|=       0.81856
At iterate    13  f =      -320.04  |proj g|=       0.81821
At iterate    14  f =      -320.04  |proj g|=       0.81743
At iterate    15  f =      -320.04  |proj g|=       0.81699
At iterate    16  f =      -320.05  |proj g|=       0.81595
At iterate    17  f =      -320.05  |proj g|=       0.51024
At iterate    18  f =      -320.07  |proj g|=       0.50804
At iterate    19  f =      -320.12  |proj g|=       0.50267
At iterate    20  f =      -320.23  |proj g|=       0.48774
At iterate    21  f =      -320.45  |proj g|=       0.44159
At iterate    22  f =      -320.46  |proj g|=        0.4762
At iterate    23  f =      -320.65  |proj g|=       0.38696
At iterate    24  f =       -320.9  |proj g|=       0.51071
At iterate    25  f =      -321.05  |proj g|=       0.82545
At iterate    26  f =      -321.08  |proj g|=       0.75685
At iterate    27  f =      -321.08  |proj g|=       0.71801
At iterate    28  f =      -321.08  |proj g|=       0.74454
At iterate    29  f =      -321.08  |proj g|=       0.74231
At iterate    30  f =      -321.08  |proj g|=       0.74177
At iterate    31  f =      -321.08  |proj g|=       0.74231

iterations 31
function evaluations 38
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.742311
final function value -321.08

F = -321.08
final  value -321.080131 
converged
 
INFO  [03:45:13.788] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:45:13.844] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:45:13.851] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:45:18.483] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:45:23.540] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:45:27.325] [mlr3]  Finished benchmark 
INFO  [03:45:27.433] [bbotk] Result of batch 55: 
INFO  [03:45:27.434] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:45:27.434] [bbotk]              3.904158                 9.552648                       0.3527277 
INFO  [03:45:27.434] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:45:27.434] [bbotk]                     1781        0.735 -0.9676788         <NA>   0.9700109 
INFO  [03:45:27.434] [bbotk]                                 uhash 
INFO  [03:45:27.434] [bbotk]  339fc517-156f-4acd-9923-bfa708c5926b 
DEBUG [03:45:28.312] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.543043e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.543043e-06 0.0009631497 
  - best initial criterion value(s) :  307.576 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -307.58  |proj g|=      0.89168
At iterate     1  f =      -319.58  |proj g|=        4.1439
At iterate     2  f =         -322  |proj g|=        3.9074
At iterate     3  f =      -325.29  |proj g|=        3.0761
At iterate     4  f =       -325.4  |proj g|=        2.7325
At iterate     5  f =      -325.47  |proj g|=        2.8496
At iterate     6  f =      -325.55  |proj g|=        2.9097
At iterate     7  f =      -325.86  |proj g|=        3.0048
At iterate     8  f =      -326.17  |proj g|=        2.9813
At iterate     9  f =      -326.29  |proj g|=        2.7361
At iterate    10  f =      -326.33  |proj g|=        2.7561
At iterate    11  f =      -326.33  |proj g|=        2.7542
At iterate    12  f =      -326.33  |proj g|=        2.7555
At iterate    13  f =      -326.33  |proj g|=        2.7558
At iterate    14  f =      -326.33  |proj g|=        2.7564
At iterate    15  f =      -326.33  |proj g|=        2.7572
At iterate    16  f =      -326.33  |proj g|=        2.7584
At iterate    17  f =      -326.33  |proj g|=          2.76
At iterate    18  f =      -326.33  |proj g|=        2.7614
At iterate    19  f =      -326.33  |proj g|=        2.7614
At iterate    20  f =      -326.34  |proj g|=        2.7632
At iterate    21  f =      -326.34  |proj g|=        2.7472
At iterate    22  f =      -326.34  |proj g|=        2.7833
At iterate    23  f =      -326.36  |proj g|=        2.7507
At iterate    24  f =      -326.39  |proj g|=        2.6801
At iterate    25  f =       -326.5  |proj g|=         2.549
At iterate    26  f =      -326.81  |proj g|=        2.2827
At iterate    27  f =      -327.53  |proj g|=        1.7992
At iterate    28  f =      -328.75  |proj g|=         1.196
At iterate    29  f =      -331.08  |proj g|=        1.0718
At iterate    30  f =      -336.65  |proj g|=       0.45484
At iterate    31  f =      -341.01  |proj g|=       0.77813
At iterate    32  f =      -341.48  |proj g|=       0.31391
At iterate    33  f =       -341.8  |proj g|=       0.22039
At iterate    34  f =      -341.81  |proj g|=       0.24001
At iterate    35  f =      -341.81  |proj g|=       0.23293
At iterate    36  f =      -341.81  |proj g|=       0.22841
At iterate    37  f =      -341.81  |proj g|=       0.22848

iterations 37
function evaluations 45
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.228477
final function value -341.811

F = -341.811
final  value -341.810515 
converged
 
INFO  [03:45:28.316] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:45:28.370] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:45:28.377] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:45:33.148] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:45:37.818] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:45:42.609] [mlr3]  Finished benchmark 
INFO  [03:45:42.689] [bbotk] Result of batch 56: 
INFO  [03:45:42.691] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:45:42.691] [bbotk]              2.623916                  7.87812                      0.09643512 
INFO  [03:45:42.691] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:45:42.691] [bbotk]                     2282        0.592 -0.9609721         <NA>   0.9500216 
INFO  [03:45:42.691] [bbotk]                                 uhash 
INFO  [03:45:42.691] [bbotk]  4e436b10-be4f-4c61-a7e4-3ed12ed56c1b 
DEBUG [03:45:43.543] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.734944e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.723781e-06 0.0009734944 
  - best initial criterion value(s) :  324.8728 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -324.87  |proj g|=        1.328
At iterate     1  f =      -331.02  |proj g|=       0.17228
At iterate     2  f =      -331.79  |proj g|=       0.84574
At iterate     3  f =      -331.89  |proj g|=       0.84657
At iterate     4  f =      -331.91  |proj g|=       0.52528
At iterate     5  f =      -331.91  |proj g|=       0.54466
At iterate     6  f =      -331.91  |proj g|=       0.54356
At iterate     7  f =      -331.91  |proj g|=       0.54349

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.543488
final function value -331.909

F = -331.909
final  value -331.909353 
converged
 
INFO  [03:45:43.548] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:45:43.611] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:45:43.620] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:45:47.221] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:45:50.778] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:45:54.230] [mlr3]  Finished benchmark 
INFO  [03:45:54.304] [bbotk] Result of batch 57: 
INFO  [03:45:54.306] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:45:54.306] [bbotk]              7.409657                 7.769982                       0.1744317 
INFO  [03:45:54.306] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:45:54.306] [bbotk]                     1690        0.637 -0.9681873         <NA>   0.9697693 
INFO  [03:45:54.306] [bbotk]                                 uhash 
INFO  [03:45:54.306] [bbotk]  7118d058-a202-4a3e-a0ed-f1591803fd6a 
DEBUG [03:45:55.221] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.63862e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.63862e-06 0.0009680508 
  - best initial criterion value(s) :  293.6512 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -293.65  |proj g|=       3.0285
At iterate     1  f =       -319.4  |proj g|=        6.1928
At iterate     2  f =      -324.98  |proj g|=        3.2947
At iterate     3  f =      -327.09  |proj g|=        4.1662
At iterate     4  f =      -330.07  |proj g|=        3.0795
At iterate     5  f =      -331.01  |proj g|=        2.3469
At iterate     6  f =      -331.05  |proj g|=        2.1738
At iterate     7  f =      -331.06  |proj g|=        2.2401
At iterate     8  f =      -331.06  |proj g|=        2.2297
At iterate     9  f =      -331.06  |proj g|=        2.2312
At iterate    10  f =      -331.06  |proj g|=        2.2313

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.23131
final function value -331.057

F = -331.057
final  value -331.056535 
converged
 
INFO  [03:45:55.226] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:45:55.281] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:45:55.289] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:46:01.317] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:46:07.289] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:46:12.731] [mlr3]  Finished benchmark 
INFO  [03:46:12.822] [bbotk] Result of batch 58: 
INFO  [03:46:12.825] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:46:12.825] [bbotk]              3.405472                 8.745993                       0.4858849 
INFO  [03:46:12.825] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:46:12.825] [bbotk]                     3059        0.679 -0.9685222         <NA>   0.9717378 
INFO  [03:46:12.825] [bbotk]                                 uhash 
INFO  [03:46:12.825] [bbotk]  d3d25cee-2996-446c-96d7-9fa0b276b18f 
DEBUG [03:46:13.817] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.564681e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.564681e-06 0.0009588625 
  - best initial criterion value(s) :  323.3169 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -323.32  |proj g|=       4.4904
At iterate     1  f =      -327.68  |proj g|=        5.6982
At iterate     2  f =      -329.53  |proj g|=        5.7558
At iterate     3  f =      -332.72  |proj g|=        4.7327
At iterate     4  f =      -332.98  |proj g|=        4.1735
At iterate     5  f =      -333.29  |proj g|=        3.7462
At iterate     6  f =       -333.3  |proj g|=        3.6691
At iterate     7  f =      -335.34  |proj g|=        3.1792
At iterate     8  f =      -347.22  |proj g|=        1.2174
At iterate     9  f =      -349.85  |proj g|=        1.5992
At iterate    10  f =      -350.77  |proj g|=        1.8969
At iterate    11  f =      -350.82  |proj g|=        2.0738
At iterate    12  f =      -351.08  |proj g|=         2.257
At iterate    13  f =      -351.55  |proj g|=        2.2509
At iterate    14  f =       -351.8  |proj g|=        1.4398
At iterate    15  f =      -351.88  |proj g|=        1.9351
At iterate    16  f =      -351.91  |proj g|=        1.8207
At iterate    17  f =      -351.91  |proj g|=        1.7805
At iterate    18  f =      -351.91  |proj g|=         1.785
At iterate    19  f =      -351.91  |proj g|=        1.7866
At iterate    20  f =      -351.91  |proj g|=        1.7856
At iterate    21  f =      -351.91  |proj g|=         1.779
At iterate    22  f =      -351.92  |proj g|=        1.7273
At iterate    23  f =      -351.95  |proj g|=        1.6563
At iterate    24  f =      -352.04  |proj g|=        1.5148
At iterate    25  f =      -352.05  |proj g|=        1.5565
At iterate    26  f =      -352.27  |proj g|=        1.2944
At iterate    27  f =      -352.83  |proj g|=        0.8782
At iterate    28  f =      -354.18  |proj g|=       0.85753
At iterate    29  f =      -356.29  |proj g|=       0.82623
At iterate    30  f =      -357.63  |proj g|=       0.29583
At iterate    31  f =       -358.1  |proj g|=       0.78425
At iterate    32  f =      -358.28  |proj g|=       0.77705
At iterate    33  f =      -358.28  |proj g|=       0.77705
At iterate    34  f =      -358.28  |proj g|=       0.77705
At iterate    35  f =      -358.29  |proj g|=       0.77674
At iterate    36  f =      -358.29  |proj g|=       0.77674
At iterate    37  f =      -358.29  |proj g|=       0.77674
At iterate    38  f =      -358.43  |proj g|=       0.77157
At iterate    39  f =      -358.43  |proj g|=       0.77145
At iterate    40  f =      -358.81  |proj g|=        0.7427
At iterate    41  f =      -358.81  |proj g|=       0.74269
At iterate    42  f =      -358.82  |proj g|=       0.53307
At iterate    43  f =      -358.82  |proj g|=     0.0043653
At iterate    44  f =      -358.82  |proj g|=     0.0010346

iterations 44
function evaluations 60
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00103465
final function value -358.823

F = -358.823
final  value -358.822905 
converged
 
INFO  [03:46:13.822] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:46:13.885] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:46:13.892] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:46:20.148] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:46:27.046] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:46:34.787] [mlr3]  Finished benchmark 
INFO  [03:46:34.856] [bbotk] Result of batch 59: 
INFO  [03:46:34.858] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:46:34.858] [bbotk]              8.151778                 5.537242                      0.04966219 
INFO  [03:46:34.858] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:46:34.858] [bbotk]                     3616        0.648 -0.9591467         <NA>    0.966237 
INFO  [03:46:34.858] [bbotk]                                 uhash 
INFO  [03:46:34.858] [bbotk]  09b7c146-2528-417e-8e3c-3dba079a8536 
DEBUG [03:46:35.684] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.457218e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.457217e-06 0.0009497809 
  - best initial criterion value(s) :  324.2358 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -324.24  |proj g|=       2.7107
At iterate     1  f =       -334.3  |proj g|=        2.4309
At iterate     2  f =      -349.68  |proj g|=        1.4435
At iterate     3  f =      -358.25  |proj g|=        1.4698
At iterate     4  f =      -360.55  |proj g|=        1.2196
At iterate     5  f =       -360.7  |proj g|=        1.0752
At iterate     6  f =      -360.77  |proj g|=         1.043
At iterate     7  f =       -360.9  |proj g|=        0.8403
At iterate     8  f =      -360.91  |proj g|=       0.89273
At iterate     9  f =      -360.91  |proj g|=       0.88171
At iterate    10  f =      -360.91  |proj g|=       0.88157
At iterate    11  f =      -360.91  |proj g|=       0.88178

iterations 11
function evaluations 13
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.881783
final function value -360.91

F = -360.91
final  value -360.910141 
converged
 
INFO  [03:46:35.688] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:46:35.747] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:46:35.754] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:46:44.266] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:46:53.478] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:47:02.306] [mlr3]  Finished benchmark 
INFO  [03:47:02.421] [bbotk] Result of batch 60: 
INFO  [03:47:02.423] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:47:02.423] [bbotk]               9.33094                 5.501091                        0.139392 
INFO  [03:47:02.423] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:47:02.423] [bbotk]                     3258        0.606 -0.9615338         <NA>   0.9713997 
INFO  [03:47:02.423] [bbotk]                                 uhash 
INFO  [03:47:02.423] [bbotk]  7577bc01-031b-42cb-af4a-7a4eddade427 
DEBUG [03:47:03.292] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.382151e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.382151e-06 0.0009426448 
  - best initial criterion value(s) :  337.9822 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -337.98  |proj g|=       2.1399
At iterate     1  f =      -348.96  |proj g|=       0.82476
At iterate     2  f =       -350.4  |proj g|=       0.81851
At iterate     3  f =      -351.65  |proj g|=       0.21279
At iterate     4  f =      -351.83  |proj g|=       0.16443
At iterate     5  f =      -351.93  |proj g|=       0.16211
At iterate     6  f =      -352.26  |proj g|=        0.1497
At iterate     7  f =      -352.58  |proj g|=       0.84951
At iterate     8  f =      -352.64  |proj g|=       0.85551
At iterate     9  f =      -352.65  |proj g|=       0.85208
At iterate    10  f =      -352.65  |proj g|=       0.85257
At iterate    11  f =      -352.65  |proj g|=       0.85261
At iterate    12  f =      -352.65  |proj g|=       0.85261

iterations 12
function evaluations 15
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.852609
final function value -352.649

F = -352.649
final  value -352.649479 
converged
 
INFO  [03:47:03.296] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:47:03.355] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:47:03.362] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:47:18.378] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:47:33.069] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:47:47.938] [mlr3]  Finished benchmark 
INFO  [03:47:48.042] [bbotk] Result of batch 61: 
INFO  [03:47:48.044] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:47:48.044] [bbotk]               7.61897                 3.881913                       0.1242131 
INFO  [03:47:48.044] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:47:48.044] [bbotk]                     4933        0.639 -0.9677111         <NA>    0.972973 
INFO  [03:47:48.044] [bbotk]                                 uhash 
INFO  [03:47:48.044] [bbotk]  5e9bc9a4-b8c0-41aa-bdc1-a4af2bd09179 
DEBUG [03:47:48.896] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.328457e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.328457e-06 0.0009345691 
  - best initial criterion value(s) :  351.5708 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -351.57  |proj g|=       1.5252
At iterate     1  f =      -353.15  |proj g|=          3.29
At iterate     2  f =      -353.82  |proj g|=         3.936
At iterate     3  f =      -353.85  |proj g|=        3.8529
At iterate     4  f =      -353.88  |proj g|=         3.472
At iterate     5  f =      -353.88  |proj g|=        3.5933
At iterate     6  f =      -353.88  |proj g|=        3.5746
At iterate     7  f =      -353.88  |proj g|=        3.5732
At iterate     8  f =      -353.88  |proj g|=        3.5727

iterations 8
function evaluations 14
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.57267
final function value -353.884

F = -353.884
final  value -353.883900 
converged
 
INFO  [03:47:48.901] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:47:48.958] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:47:48.965] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:47:59.742] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:48:10.307] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:48:22.344] [mlr3]  Finished benchmark 
INFO  [03:48:22.450] [bbotk] Result of batch 62: 
INFO  [03:48:22.453] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:48:22.453] [bbotk]              6.509348                 7.895184                      0.09736864 
INFO  [03:48:22.453] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:48:22.453] [bbotk]                     3964        0.622 -0.9689602         <NA>   0.9708339 
INFO  [03:48:22.453] [bbotk]                                 uhash 
INFO  [03:48:22.453] [bbotk]  e01417d7-c717-40cb-8a18-4b134f360ada 
DEBUG [03:48:23.475] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.249122e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.249122e-06 0.0009288465 
  - best initial criterion value(s) :  350.4787 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -350.48  |proj g|=       1.2912
At iterate     1  f =      -353.07  |proj g|=        3.8119
At iterate     2  f =      -356.07  |proj g|=        3.6513
At iterate     3  f =       -358.6  |proj g|=        3.1816
At iterate     4  f =       -358.7  |proj g|=        2.9845
At iterate     5  f =      -358.76  |proj g|=        3.0594
At iterate     6  f =      -358.85  |proj g|=         3.142
At iterate     7  f =      -359.13  |proj g|=        3.3507
At iterate     8  f =      -359.41  |proj g|=         3.577
At iterate     9  f =      -359.59  |proj g|=        3.6236
At iterate    10  f =      -359.59  |proj g|=        3.6293
At iterate    11  f =      -359.59  |proj g|=        3.6306
At iterate    12  f =      -359.59  |proj g|=        3.6312
At iterate    13  f =      -359.59  |proj g|=        3.6342
At iterate    14  f =      -359.59  |proj g|=        3.6426
At iterate    15  f =      -359.59  |proj g|=        3.6477
At iterate    16  f =      -359.59  |proj g|=        3.6685
At iterate    17  f =       -359.6  |proj g|=        3.7062
At iterate    18  f =      -359.61  |proj g|=        3.7384
At iterate    19  f =      -359.65  |proj g|=        3.8481
At iterate    20  f =      -359.73  |proj g|=         3.878
At iterate    21  f =      -359.94  |proj g|=        3.9633
At iterate    22  f =      -360.45  |proj g|=        3.8229
At iterate    23  f =      -361.44  |proj g|=        3.2396
At iterate    24  f =       -362.3  |proj g|=        2.5549
At iterate    25  f =      -363.26  |proj g|=        2.7488
At iterate    26  f =      -363.56  |proj g|=        2.5003
At iterate    27  f =      -363.64  |proj g|=        2.3869
At iterate    28  f =      -363.77  |proj g|=        2.6633
At iterate    29  f =      -363.81  |proj g|=         2.739
At iterate    30  f =      -363.81  |proj g|=         2.736
At iterate    31  f =      -363.81  |proj g|=        2.7391
At iterate    32  f =      -363.81  |proj g|=        2.7399
At iterate    33  f =      -363.81  |proj g|=        2.7622
At iterate    34  f =      -363.81  |proj g|=        2.7536
At iterate    35  f =      -363.82  |proj g|=        2.7439
At iterate    36  f =      -363.82  |proj g|=        2.7151
At iterate    37  f =      -363.84  |proj g|=        2.6711
At iterate    38  f =      -363.88  |proj g|=        2.5886
At iterate    39  f =         -364  |proj g|=        2.4351
At iterate    40  f =      -364.32  |proj g|=        2.1365
At iterate    41  f =      -365.18  |proj g|=        1.5842
At iterate    42  f =      -367.36  |proj g|=       0.79602
At iterate    43  f =      -371.14  |proj g|=       0.42575
At iterate    44  f =       -374.6  |proj g|=        0.5313
At iterate    45  f =       -376.1  |proj g|=       0.49776
At iterate    46  f =      -376.98  |proj g|=       0.75599
At iterate    47  f =      -377.04  |proj g|=       0.82356
At iterate    48  f =      -377.06  |proj g|=       0.88476
At iterate    49  f =      -377.06  |proj g|=       0.89172
At iterate    50  f =      -377.18  |proj g|=       0.92426
At iterate    51  f =      -377.35  |proj g|=       0.92017
At iterate    52  f =      -377.35  |proj g|=       0.91095
At iterate    53  f =      -377.35  |proj g|=       0.90861
At iterate    54  f =      -377.35  |proj g|=       0.90809
At iterate    55  f =      -377.35  |proj g|=       0.90791

iterations 55
function evaluations 65
segments explored during Cauchy searches 57
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.907907
final function value -377.352

F = -377.352
final  value -377.351813 
converged
 
INFO  [03:48:23.481] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:48:23.549] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:48:23.557] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:48:33.407] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:48:44.108] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:48:54.020] [mlr3]  Finished benchmark 
INFO  [03:48:54.111] [bbotk] Result of batch 63: 
INFO  [03:48:54.113] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:48:54.113] [bbotk]              5.298439                 9.687109                       0.1452407 
INFO  [03:48:54.113] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:48:54.113] [bbotk]                     3282        0.641 -0.9568548         <NA>   0.9714152 
INFO  [03:48:54.113] [bbotk]                                 uhash 
INFO  [03:48:54.113] [bbotk]  1459497b-f327-44d5-8e5e-969ee1c7ee4f 
DEBUG [03:48:55.059] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.176931e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.176931e-06 0.0009246412 
  - best initial criterion value(s) :  322.1133 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -322.11  |proj g|=       7.2062
At iterate     1  f =      -348.74  |proj g|=        7.3472
At iterate     2  f =      -348.98  |proj g|=        7.4252
At iterate     3  f =      -349.25  |proj g|=        7.1237
At iterate     4  f =       -349.7  |proj g|=        6.0956
At iterate     5  f =      -349.78  |proj g|=         5.725
At iterate     6  f =       -349.8  |proj g|=        5.5537
At iterate     7  f =       -349.8  |proj g|=        5.5343
At iterate     8  f =       -349.8  |proj g|=        5.5443
At iterate     9  f =       -349.8  |proj g|=        5.5465
At iterate    10  f =       -349.8  |proj g|=        5.5471
At iterate    11  f =       -349.8  |proj g|=        5.5502
At iterate    12  f =       -349.8  |proj g|=        5.5537
At iterate    13  f =       -349.8  |proj g|=        5.5601
At iterate    14  f =      -349.81  |proj g|=        5.5702
At iterate    15  f =      -349.81  |proj g|=        5.5888
At iterate    16  f =      -349.81  |proj g|=        5.6234
At iterate    17  f =      -349.81  |proj g|=        5.6853
At iterate    18  f =      -349.81  |proj g|=        5.7696
At iterate    19  f =      -349.81  |proj g|=        5.7786
At iterate    20  f =      -349.82  |proj g|=        5.8589
At iterate    21  f =      -355.14  |proj g|=        4.8964
At iterate    22  f =      -362.43  |proj g|=        3.3252
At iterate    23  f =      -366.72  |proj g|=        2.2845
At iterate    24  f =      -368.66  |proj g|=        1.2246
At iterate    25  f =      -372.48  |proj g|=       0.93579
At iterate    26  f =      -372.85  |proj g|=       0.98224
At iterate    27  f =      -372.95  |proj g|=        1.2271
At iterate    28  f =      -372.99  |proj g|=        1.1694
At iterate    29  f =         -373  |proj g|=        1.1669
At iterate    30  f =         -373  |proj g|=        1.1714
At iterate    31  f =         -373  |proj g|=        1.1722

iterations 31
function evaluations 39
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.1722
final function value -372.995

F = -372.995
final  value -372.995034 
converged
 
INFO  [03:48:55.063] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:48:55.121] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:48:55.129] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:49:07.431] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:49:19.229] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:49:32.203] [mlr3]  Finished benchmark 
INFO  [03:49:32.270] [bbotk] Result of batch 64: 
INFO  [03:49:32.272] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:49:32.272] [bbotk]              3.320778                 9.426714                       0.1260427 
INFO  [03:49:32.272] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:49:32.272] [bbotk]                     4176        0.637 -0.9679041         <NA>   0.9661604 
INFO  [03:49:32.272] [bbotk]                                 uhash 
INFO  [03:49:32.272] [bbotk]  c0ffd253-04e6-4026-9b52-dbf536d860e6 
DEBUG [03:49:33.198] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.079368e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.079368e-06 0.0009130404 
  - best initial criterion value(s) :  357.4849 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -357.48  |proj g|=       5.7534
At iterate     1  f =      -358.44  |proj g|=        6.2204
At iterate     2  f =      -363.72  |proj g|=        3.8459
At iterate     3  f =      -368.25  |proj g|=        2.8376
At iterate     4  f =      -369.26  |proj g|=        2.6575
At iterate     5  f =      -369.27  |proj g|=        2.6312
At iterate     6  f =      -369.27  |proj g|=        2.6358
At iterate     7  f =      -369.27  |proj g|=        2.6363
At iterate     8  f =      -369.27  |proj g|=        2.6401
At iterate     9  f =      -369.27  |proj g|=        2.6419
At iterate    10  f =      -369.28  |proj g|=        2.6535
At iterate    11  f =      -369.29  |proj g|=        2.6613
At iterate    12  f =      -369.31  |proj g|=        2.6806
At iterate    13  f =      -369.38  |proj g|=        2.6998
At iterate    14  f =      -369.53  |proj g|=        2.7506
At iterate    15  f =      -369.91  |proj g|=        2.7678
At iterate    16  f =      -370.32  |proj g|=        3.0812
At iterate    17  f =      -372.19  |proj g|=        2.9963
At iterate    18  f =      -374.91  |proj g|=         2.682
At iterate    19  f =      -376.74  |proj g|=        2.2427
At iterate    20  f =      -380.47  |proj g|=        1.7866
At iterate    21  f =      -382.63  |proj g|=        1.7442
At iterate    22  f =      -384.09  |proj g|=        1.2415
At iterate    23  f =      -384.43  |proj g|=       0.90331
At iterate    24  f =      -384.43  |proj g|=       0.90046
At iterate    25  f =      -384.43  |proj g|=       0.90032

iterations 25
function evaluations 31
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.900323
final function value -384.435

F = -384.435
final  value -384.434831 
converged
 
INFO  [03:49:33.203] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:49:33.256] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:49:33.263] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:49:39.833] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:49:44.385] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:49:48.914] [mlr3]  Finished benchmark 
INFO  [03:49:48.981] [bbotk] Result of batch 65: 
INFO  [03:49:48.983] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:49:48.983] [bbotk]              9.134569                 9.154869                       0.4816643 
INFO  [03:49:48.983] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:49:48.983] [bbotk]                     1718        0.643 -0.9587105         <NA>   0.9722825 
INFO  [03:49:48.983] [bbotk]                                 uhash 
INFO  [03:49:48.983] [bbotk]  b58c0366-1d08-47b4-8bfd-78f5e30fbed1 
DEBUG [03:49:50.117] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 9.019789e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  9.019789e-06 0.0009075636 
  - best initial criterion value(s) :  361.4218 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -361.42  |proj g|=       3.4591
At iterate     1  f =      -365.55  |proj g|=        4.3508
At iterate     2  f =      -365.72  |proj g|=        4.2962
At iterate     3  f =      -365.91  |proj g|=        4.1454
At iterate     4  f =      -366.32  |proj g|=        3.9964
At iterate     5  f =      -367.22  |proj g|=        3.2181
At iterate     6  f =      -367.34  |proj g|=        3.4268
At iterate     7  f =      -367.35  |proj g|=        3.3932
At iterate     8  f =      -367.35  |proj g|=        3.3896
At iterate     9  f =      -367.35  |proj g|=        3.3902
At iterate    10  f =      -367.35  |proj g|=        3.3872
At iterate    11  f =      -367.35  |proj g|=        3.3813
At iterate    12  f =      -367.35  |proj g|=        3.3698
At iterate    13  f =      -367.36  |proj g|=        3.3521
At iterate    14  f =      -367.37  |proj g|=        3.3208
At iterate    15  f =      -367.39  |proj g|=        3.2704
At iterate    16  f =      -367.43  |proj g|=        3.1866
At iterate    17  f =      -367.53  |proj g|=        3.0713
At iterate    18  f =      -367.76  |proj g|=        2.9789
At iterate    19  f =      -369.46  |proj g|=        2.4188
At iterate    20  f =      -372.64  |proj g|=        1.7268
At iterate    21  f =      -379.95  |proj g|=        1.1472
At iterate    22  f =      -380.77  |proj g|=        1.1686
At iterate    23  f =       -385.8  |proj g|=        1.3813
At iterate    24  f =      -386.26  |proj g|=        1.1575
At iterate    25  f =      -388.25  |proj g|=       0.87455
At iterate    26  f =      -390.19  |proj g|=       0.85131
At iterate    27  f =      -390.88  |proj g|=       0.30277
At iterate    28  f =      -391.09  |proj g|=         0.549
At iterate    29  f =      -391.13  |proj g|=       0.67128
At iterate    30  f =      -391.14  |proj g|=       0.71473
At iterate    31  f =      -391.14  |proj g|=       0.82017
At iterate    32  f =      -391.14  |proj g|=       0.72839
At iterate    33  f =      -391.14  |proj g|=       0.72794

iterations 33
function evaluations 40
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.727941
final function value -391.14

F = -391.14
final  value -391.140455 
converged
 
INFO  [03:49:50.120] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:49:50.176] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:49:50.183] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:50:04.149] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:50:14.065] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:50:24.112] [mlr3]  Finished benchmark 
INFO  [03:50:24.189] [bbotk] Result of batch 66: 
INFO  [03:50:24.191] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:50:24.191] [bbotk]              9.576726                 3.900087                       0.1708675 
INFO  [03:50:24.191] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:50:24.191] [bbotk]                     4777        0.824 -0.9642617         <NA>   0.9721394 
INFO  [03:50:24.191] [bbotk]                                 uhash 
INFO  [03:50:24.191] [bbotk]  ddc9215f-caca-4d60-8183-066704caee37 
DEBUG [03:50:25.233] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.959023e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  8.959023e-06 0.0008986369 
  - best initial criterion value(s) :  376.9026 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -376.9  |proj g|=      0.72841
At iterate     1  f =      -384.15  |proj g|=         4.225
At iterate     2  f =      -385.51  |proj g|=        3.9676
At iterate     3  f =      -386.05  |proj g|=        2.9621
At iterate     4  f =      -386.36  |proj g|=        3.4909
At iterate     5  f =      -386.39  |proj g|=        3.3888
At iterate     6  f =       -386.4  |proj g|=        3.3381
At iterate     7  f =      -386.42  |proj g|=        3.2452
At iterate     8  f =      -386.46  |proj g|=        3.0893
At iterate     9  f =      -386.48  |proj g|=        2.9859
At iterate    10  f =      -386.49  |proj g|=        2.9981
At iterate    11  f =      -386.49  |proj g|=        3.0116
At iterate    12  f =      -386.49  |proj g|=        3.0134
At iterate    13  f =      -386.49  |proj g|=        3.0142
At iterate    14  f =      -386.49  |proj g|=        3.0166
At iterate    15  f =      -386.49  |proj g|=        3.0207
At iterate    16  f =      -386.49  |proj g|=        3.0271
At iterate    17  f =      -386.49  |proj g|=        3.0375
At iterate    18  f =      -386.49  |proj g|=        3.0545
At iterate    19  f =      -386.49  |proj g|=        3.0803
At iterate    20  f =       -386.5  |proj g|=        3.1175
At iterate    21  f =      -386.51  |proj g|=         3.168
At iterate    22  f =      -386.51  |proj g|=        3.1939
At iterate    23  f =      -386.53  |proj g|=        3.2504
At iterate    24  f =      -389.46  |proj g|=        2.5629
At iterate    25  f =      -394.52  |proj g|=        1.2687
At iterate    26  f =      -394.64  |proj g|=        1.2937
At iterate    27  f =      -394.66  |proj g|=        1.3253
At iterate    28  f =      -394.67  |proj g|=        1.3767
At iterate    29  f =      -394.67  |proj g|=        1.3896
At iterate    30  f =      -394.67  |proj g|=        1.3903

iterations 30
function evaluations 34
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.39034
final function value -394.666

F = -394.666
final  value -394.666139 
converged
 
INFO  [03:50:25.237] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:50:25.299] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:50:25.307] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:50:31.854] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:50:38.510] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:50:45.847] [mlr3]  Finished benchmark 
INFO  [03:50:45.940] [bbotk] Result of batch 67: 
INFO  [03:50:45.942] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:50:45.942] [bbotk]              8.969751                 5.738962                      0.03647303 
INFO  [03:50:45.942] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:50:45.942] [bbotk]                     3279        0.747 -0.9647507         <NA>   0.9627229 
INFO  [03:50:45.942] [bbotk]                                 uhash 
INFO  [03:50:45.942] [bbotk]  fdc970af-58f2-4639-b24f-25f6728f06f6 
DEBUG [03:50:46.848] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.881404e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  8.881404e-06 0.000891163 
  - best initial criterion value(s) :  351.108 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -351.11  |proj g|=       10.737
At iterate     1  f =      -372.42  |proj g|=        2.1972
At iterate     2  f =      -374.92  |proj g|=        3.0414
At iterate     3  f =      -375.78  |proj g|=          2.82
At iterate     4  f =      -375.96  |proj g|=        2.5533
At iterate     5  f =      -375.98  |proj g|=        2.6223
At iterate     6  f =      -375.98  |proj g|=        2.6124
At iterate     7  f =      -375.98  |proj g|=         2.612
At iterate     8  f =      -375.98  |proj g|=        2.6119

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.61187
final function value -375.978

F = -375.978
final  value -375.978278 
converged
 
INFO  [03:50:46.853] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:50:46.914] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:50:46.923] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:50:52.609] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:50:57.764] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:51:03.200] [mlr3]  Finished benchmark 
INFO  [03:51:03.269] [bbotk] Result of batch 68: 
INFO  [03:51:03.271] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:51:03.271] [bbotk]              4.254093                 2.770409                       0.2556582 
INFO  [03:51:03.271] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:51:03.271] [bbotk]                     2881        0.664 -0.9683122         <NA>   0.9716532 
INFO  [03:51:03.271] [bbotk]                                 uhash 
INFO  [03:51:03.271] [bbotk]  d4f307cc-90c8-47bf-92b8-7d330d9149db 
DEBUG [03:51:04.228] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 8.817756e-13 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  8.817756e-06 0.0008865977 
  - best initial criterion value(s) :  355.5434 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -355.54  |proj g|=       9.1684
At iterate     1  f =      -372.77  |proj g|=        7.6502
At iterate     2  f =      -376.06  |proj g|=        6.7197
At iterate     3  f =      -376.44  |proj g|=        6.2053
At iterate     4  f =      -376.58  |proj g|=        5.6576
At iterate     5  f =      -376.58  |proj g|=        5.6108
At iterate     6  f =      -376.58  |proj g|=        5.5878
At iterate     7  f =      -376.58  |proj g|=        5.5774
At iterate     8  f =      -376.58  |proj g|=        5.5781
At iterate     9  f =      -376.58  |proj g|=        5.5794
At iterate    10  f =      -376.58  |proj g|=        5.5828
At iterate    11  f =      -376.58  |proj g|=        5.5868
At iterate    12  f =      -376.58  |proj g|=        5.5925
At iterate    13  f =      -376.59  |proj g|=        5.5989
At iterate    14  f =      -376.59  |proj g|=        5.6027
At iterate    15  f =       -376.6  |proj g|=        5.5916
At iterate    16  f =      -376.64  |proj g|=        5.5295
At iterate    17  f =      -376.72  |proj g|=        5.3303
At iterate    18  f =      -376.87  |proj g|=        4.8719
At iterate    19  f =      -376.97  |proj g|=        4.6365
At iterate    20  f =      -377.01  |proj g|=        4.2188
At iterate    21  f =       -377.1  |proj g|=        4.1457
At iterate    22  f =      -377.91  |proj g|=        3.5904
At iterate    23  f =       -379.3  |proj g|=        2.7387
At iterate    24  f =      -385.16  |proj g|=       0.63732
At iterate    25  f =      -388.42  |proj g|=       0.82425
At iterate    26  f =      -388.64  |proj g|=       0.83905
At iterate    27  f =       -389.5  |proj g|=       0.29344
At iterate    28  f =      -389.63  |proj g|=       0.13742
At iterate    29  f =      -390.56  |proj g|=       0.31333
At iterate    30  f =      -390.59  |proj g|=       0.87858
At iterate    31  f =      -390.61  |proj g|=       0.39226
At iterate    32  f =      -390.61  |proj g|=       0.40288
At iterate    33  f =      -390.61  |proj g|=       0.40271
At iterate    34  f =      -390.61  |proj g|=       0.40278

iterations 34
function evaluations 39
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.402779
final function value -390.609

F = -390.609
final  value -390.609280 
converged
 
INFO  [03:51:04.232] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:51:04.314] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:51:04.322] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:51:09.760] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:51:14.977] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:51:25.003] [mlr3]  Finished benchmark 
INFO  [03:51:25.071] [bbotk] Result of batch 69: 
INFO  [03:51:25.073] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:51:25.073] [bbotk]              2.121848                 6.842269                      0.01850611 
INFO  [03:51:25.073] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:51:25.073] [bbotk]                     2915        0.651 -0.9676819         <NA>   0.9209057 
INFO  [03:51:25.073] [bbotk]                                 uhash 
INFO  [03:51:25.073] [bbotk]  303de3a3-c11d-41e2-9c83-87273ea65e75 
DEBUG [03:51:25.973] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.081093e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.052321e-05 0.001081093 
  - best initial criterion value(s) :  371.4741 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -371.47  |proj g|=       13.794
At iterate     1  f =      -382.02  |proj g|=        9.1274
At iterate     2  f =      -385.88  |proj g|=        8.1569
At iterate     3  f =      -388.16  |proj g|=        6.3248
At iterate     4  f =      -388.95  |proj g|=        7.0467
At iterate     5  f =      -390.83  |proj g|=        5.1811
At iterate     6  f =      -391.54  |proj g|=        4.2403
At iterate     7  f =      -396.18  |proj g|=        3.8149
At iterate     8  f =      -400.88  |proj g|=        2.8661
At iterate     9  f =      -404.57  |proj g|=        1.7808
At iterate    10  f =       -407.6  |proj g|=       0.71859
At iterate    11  f =      -408.07  |proj g|=       0.75611
At iterate    12  f =      -408.35  |proj g|=       0.73293
At iterate    13  f =      -408.45  |proj g|=       0.26198
At iterate    14  f =      -408.46  |proj g|=       0.26167
At iterate    15  f =      -408.46  |proj g|=       0.26167

iterations 15
function evaluations 21
segments explored during Cauchy searches 20
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.261675
final function value -408.456

F = -408.456
final  value -408.455519 
converged
 
INFO  [03:51:25.977] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:51:26.032] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:51:26.039] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:51:29.456] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:51:32.284] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:51:34.753] [mlr3]  Finished benchmark 
INFO  [03:51:34.822] [bbotk] Result of batch 70: 
INFO  [03:51:34.824] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:51:34.824] [bbotk]              9.054762                 3.664553                       0.2905245 
INFO  [03:51:34.824] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:51:34.824] [bbotk]                      951        0.644 -0.9567652         <NA>   0.9694425 
INFO  [03:51:34.824] [bbotk]                                 uhash 
INFO  [03:51:34.824] [bbotk]  46a52c04-b930-4f2e-a72b-c06e90e0ed46 
DEBUG [03:51:35.792] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.071401e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.043546e-05 0.001071401 
  - best initial criterion value(s) :  365.2473 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -365.25  |proj g|=       14.247
At iterate     1  f =      -369.58  |proj g|=        5.1767
At iterate     2  f =      -390.96  |proj g|=        1.2219
At iterate     3  f =      -391.12  |proj g|=       0.93437
At iterate     4  f =      -391.14  |proj g|=       0.95971
At iterate     5  f =      -391.14  |proj g|=        1.0752
At iterate     6  f =      -391.15  |proj g|=        1.1128
At iterate     7  f =      -391.15  |proj g|=        1.1341
At iterate     8  f =      -391.15  |proj g|=        1.1537
At iterate     9  f =      -391.15  |proj g|=        1.1933
At iterate    10  f =      -391.16  |proj g|=        1.2569
At iterate    11  f =      -391.17  |proj g|=        1.3636
At iterate    12  f =      -391.21  |proj g|=        1.5247
At iterate    13  f =       -391.3  |proj g|=        1.7638
At iterate    14  f =      -391.51  |proj g|=        2.0846
At iterate    15  f =      -391.96  |proj g|=        2.4724
At iterate    16  f =      -392.72  |proj g|=        3.0615
At iterate    17  f =      -393.85  |proj g|=         2.763
At iterate    18  f =       -396.8  |proj g|=        1.3414
At iterate    19  f =      -397.54  |proj g|=        0.7233
At iterate    20  f =         -398  |proj g|=       0.22838
At iterate    21  f =      -398.07  |proj g|=        0.3514
At iterate    22  f =      -398.18  |proj g|=       0.26878
At iterate    23  f =      -398.18  |proj g|=       0.57024
At iterate    24  f =      -398.18  |proj g|=       0.26053
At iterate    25  f =      -398.18  |proj g|=       0.26156
At iterate    26  f =      -398.18  |proj g|=       0.26159

iterations 26
function evaluations 31
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.26159
final function value -398.183

F = -398.183
final  value -398.183389 
converged
 
INFO  [03:51:35.796] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:51:35.877] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:51:35.886] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:51:38.020] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:51:42.048] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:51:44.061] [mlr3]  Finished benchmark 
INFO  [03:51:44.166] [bbotk] Result of batch 71: 
INFO  [03:51:44.168] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:51:44.168] [bbotk]              5.133312                 6.303354                       0.2204178 
INFO  [03:51:44.168] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [03:51:44.168] [bbotk]                      622        0.669 -0.964082         <NA>   0.9613397 
INFO  [03:51:44.168] [bbotk]                                 uhash 
INFO  [03:51:44.168] [bbotk]  d0021fd4-cc75-4201-81a3-747fe17c87c6 
DEBUG [03:51:45.120] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.063028e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.036028e-05 0.001063028 
  - best initial criterion value(s) :  384.6221 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -384.62  |proj g|=       4.2668
At iterate     1  f =       -392.7  |proj g|=        5.4704
At iterate     2  f =      -394.24  |proj g|=        5.4699
At iterate     3  f =      -397.72  |proj g|=        4.7191
At iterate     4  f =      -398.47  |proj g|=        3.2854
At iterate     5  f =       -400.1  |proj g|=        3.0755
At iterate     6  f =      -400.19  |proj g|=        2.5806
At iterate     7  f =      -400.22  |proj g|=        2.6943
At iterate     8  f =      -400.27  |proj g|=        2.7959
At iterate     9  f =      -400.28  |proj g|=        2.8698
At iterate    10  f =      -400.43  |proj g|=        3.0384
At iterate    11  f =      -400.77  |proj g|=        3.2239
At iterate    12  f =       -401.6  |proj g|=        3.3564
At iterate    13  f =      -403.14  |proj g|=        3.1678
At iterate    14  f =      -405.03  |proj g|=        2.5574
At iterate    15  f =      -405.27  |proj g|=        2.7037
At iterate    16  f =      -406.96  |proj g|=        2.2244
At iterate    17  f =      -408.96  |proj g|=        2.0017
At iterate    18  f =      -412.28  |proj g|=        1.7909
At iterate    19  f =      -412.93  |proj g|=        1.9448
At iterate    20  f =      -413.44  |proj g|=        2.0261
At iterate    21  f =      -413.62  |proj g|=        2.0447
At iterate    22  f =      -413.63  |proj g|=        2.1224
At iterate    23  f =      -413.65  |proj g|=        2.1149
At iterate    24  f =      -413.65  |proj g|=        2.1181
At iterate    25  f =      -413.65  |proj g|=        2.1189
At iterate    26  f =      -413.65  |proj g|=        2.1191

iterations 26
function evaluations 33
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.1191
final function value -413.649

F = -413.649
final  value -413.649248 
converged
 
INFO  [03:51:45.124] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:51:45.183] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:51:45.190] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:51:58.721] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:52:12.572] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:52:25.811] [mlr3]  Finished benchmark 
INFO  [03:52:25.880] [bbotk] Result of batch 72: 
INFO  [03:52:25.882] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:52:25.882] [bbotk]              9.610731                  7.84469                     0.007702672 
INFO  [03:52:25.882] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:52:25.882] [bbotk]                     4346        0.653 -0.9568663         <NA>   0.9457828 
INFO  [03:52:25.882] [bbotk]                                 uhash 
INFO  [03:52:25.882] [bbotk]  46af44da-54d6-4f55-8d1e-2d6d8a083e7b 
DEBUG [03:52:26.915] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.092555e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.066032e-05 0.001092555 
  - best initial criterion value(s) :  381.5678 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -381.57  |proj g|=       8.5152
At iterate     1  f =       -392.9  |proj g|=        7.0301
At iterate     2  f =       -401.8  |proj g|=        4.5439
At iterate     3  f =      -402.82  |proj g|=        3.3395
At iterate     4  f =      -403.55  |proj g|=        2.4671
At iterate     5  f =      -403.55  |proj g|=        2.4557
At iterate     6  f =      -403.55  |proj g|=        2.4585
At iterate     7  f =      -403.58  |proj g|=        2.5211
At iterate     8  f =      -403.72  |proj g|=        2.7367
At iterate     9  f =      -404.11  |proj g|=        3.0588
At iterate    10  f =      -405.11  |proj g|=        3.4545
At iterate    11  f =      -406.08  |proj g|=        4.5037
At iterate    12  f =      -409.47  |proj g|=        3.8957
At iterate    13  f =      -412.05  |proj g|=        3.0357
At iterate    14  f =      -415.27  |proj g|=        1.9222
At iterate    15  f =      -419.14  |proj g|=       0.87753
At iterate    16  f =      -420.88  |proj g|=        1.0017
At iterate    17  f =      -421.66  |proj g|=        1.2191
At iterate    18  f =      -421.76  |proj g|=        1.0463
At iterate    19  f =      -421.89  |proj g|=        1.0721
At iterate    20  f =      -421.93  |proj g|=        1.1355
At iterate    21  f =      -421.93  |proj g|=        1.1147
At iterate    22  f =      -421.93  |proj g|=        1.1136
At iterate    23  f =      -421.93  |proj g|=        1.1139
At iterate    24  f =      -421.93  |proj g|=        1.1142
At iterate    25  f =      -421.93  |proj g|=        1.1157
At iterate    26  f =      -421.93  |proj g|=        1.1164
At iterate    27  f =      -421.93  |proj g|=         1.122
At iterate    28  f =      -421.93  |proj g|=        1.1212
At iterate    29  f =      -421.93  |proj g|=        1.1148
At iterate    30  f =      -421.93  |proj g|=        1.1049
At iterate    31  f =      -421.94  |proj g|=        1.0953
At iterate    32  f =      -421.94  |proj g|=        1.0881
At iterate    33  f =      -421.94  |proj g|=        1.0819
At iterate    34  f =      -421.95  |proj g|=         1.064
At iterate    35  f =      -421.95  |proj g|=        1.0372
At iterate    36  f =      -421.98  |proj g|=         1.016
At iterate    37  f =      -422.07  |proj g|=       0.94189
At iterate    38  f =      -422.24  |proj g|=       0.81287
At iterate    39  f =      -422.56  |proj g|=       0.74811
At iterate    40  f =      -422.85  |proj g|=       0.74131
At iterate    41  f =      -423.33  |proj g|=        0.7311
At iterate    42  f =      -423.52  |proj g|=       0.26046
At iterate    43  f =      -423.54  |proj g|=       0.26459
At iterate    44  f =      -423.57  |proj g|=       0.26346
At iterate    45  f =      -423.57  |proj g|=       0.13178
At iterate    46  f =      -423.57  |proj g|=       0.18101
At iterate    47  f =      -423.57  |proj g|=       0.19178
At iterate    48  f =      -423.57  |proj g|=      0.047182
At iterate    49  f =      -423.57  |proj g|=      0.028644
At iterate    50  f =      -423.57  |proj g|=      0.014124

iterations 50
function evaluations 62
segments explored during Cauchy searches 52
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0141241
final function value -423.572

F = -423.572
final  value -423.572236 
converged
 
INFO  [03:52:26.919] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:52:26.976] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:52:26.983] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:52:43.291] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:52:57.088] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:53:12.523] [mlr3]  Finished benchmark 
INFO  [03:53:12.593] [bbotk] Result of batch 73: 
INFO  [03:53:12.595] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:53:12.595] [bbotk]              3.680677                 9.014448                       0.3903903 
INFO  [03:53:12.595] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:53:12.595] [bbotk]                     4898        0.649 -0.9549318         <NA>   0.9732373 
INFO  [03:53:12.595] [bbotk]                                 uhash 
INFO  [03:53:12.595] [bbotk]  f009f0a3-190f-4db0-8630-934bee6e2255 
DEBUG [03:53:13.623] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.087166e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.052591e-05 0.001087166 
  - best initial criterion value(s) :  384.854 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -384.85  |proj g|=       2.8044
At iterate     1  f =      -386.74  |proj g|=        3.6249
At iterate     2  f =      -386.95  |proj g|=        3.5358
At iterate     3  f =      -387.23  |proj g|=        3.3473
At iterate     4  f =      -387.51  |proj g|=        3.2707
At iterate     5  f =      -389.88  |proj g|=        2.1983
At iterate     6  f =      -391.47  |proj g|=         1.824
At iterate     7  f =      -391.72  |proj g|=         1.943
At iterate     8  f =      -391.73  |proj g|=        1.8934
At iterate     9  f =      -391.73  |proj g|=        1.9159
At iterate    10  f =      -391.73  |proj g|=        1.9163
At iterate    11  f =      -391.73  |proj g|=        1.9194
At iterate    12  f =      -391.73  |proj g|=        1.9219
At iterate    13  f =      -391.73  |proj g|=         1.927
At iterate    14  f =      -391.73  |proj g|=        1.9348
At iterate    15  f =      -391.73  |proj g|=        1.9479
At iterate    16  f =      -391.74  |proj g|=        1.9701
At iterate    17  f =      -391.76  |proj g|=         2.009
At iterate    18  f =      -391.82  |proj g|=         2.077
At iterate    19  f =      -391.94  |proj g|=         2.184
At iterate    20  f =      -392.17  |proj g|=        2.2982
At iterate    21  f =       -392.3  |proj g|=        2.1762
At iterate    22  f =      -392.39  |proj g|=        2.2591
At iterate    23  f =      -392.73  |proj g|=        2.1998
At iterate    24  f =      -394.12  |proj g|=        1.7399
At iterate    25  f =      -395.69  |proj g|=        1.0823
At iterate    26  f =      -397.12  |proj g|=       0.50201
At iterate    27  f =      -397.23  |proj g|=       0.63167
At iterate    28  f =         -398  |proj g|=       0.16508
At iterate    29  f =      -398.14  |proj g|=       0.15408
At iterate    30  f =      -398.15  |proj g|=       0.15293
At iterate    31  f =      -398.15  |proj g|=       0.10446
At iterate    32  f =      -398.15  |proj g|=       0.10614
At iterate    33  f =      -398.15  |proj g|=       0.10622

iterations 33
function evaluations 42
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.106215
final function value -398.147

F = -398.147
final  value -398.146806 
converged
 
INFO  [03:53:13.627] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:53:13.683] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:53:13.691] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:53:19.086] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:53:24.766] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:53:31.449] [mlr3]  Finished benchmark 
INFO  [03:53:31.562] [bbotk] Result of batch 74: 
INFO  [03:53:31.564] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:53:31.564] [bbotk]               2.63214                 9.023641                       0.4129896 
INFO  [03:53:31.564] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:53:31.564] [bbotk]                     1950        0.686 -0.9665475         <NA>   0.9629801 
INFO  [03:53:31.564] [bbotk]                                 uhash 
INFO  [03:53:31.564] [bbotk]  d1ccca11-2bb6-44d6-bf3f-cdf67945064b 
DEBUG [03:53:32.707] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.077547e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.05409e-05 0.001077547 
  - best initial criterion value(s) :  395.1625 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -395.16  |proj g|=        6.916
At iterate     1  f =      -408.03  |proj g|=        6.0931
At iterate     2  f =      -409.07  |proj g|=        6.1075
At iterate     3  f =      -411.77  |proj g|=        5.0273
At iterate     4  f =      -412.07  |proj g|=        3.8734
At iterate     5  f =      -412.31  |proj g|=        3.9462
At iterate     6  f =      -412.31  |proj g|=        3.8481
At iterate     7  f =      -412.31  |proj g|=        3.8394
At iterate     8  f =      -412.32  |proj g|=        3.7895
At iterate     9  f =      -412.32  |proj g|=        3.7417
At iterate    10  f =      -412.34  |proj g|=        3.6414
At iterate    11  f =      -412.39  |proj g|=        3.4809
At iterate    12  f =      -412.52  |proj g|=        3.1966
At iterate    13  f =      -412.82  |proj g|=        2.7692
At iterate    14  f =      -413.54  |proj g|=        2.1466
At iterate    15  f =      -415.11  |proj g|=        1.4362
At iterate    16  f =      -416.11  |proj g|=        1.4075
At iterate    17  f =      -419.19  |proj g|=       0.88991
At iterate    18  f =      -422.99  |proj g|=       0.84604
At iterate    19  f =      -424.71  |proj g|=       0.82906
At iterate    20  f =      -426.55  |proj g|=       0.80166
At iterate    21  f =      -427.17  |proj g|=       0.78559
At iterate    22  f =      -427.31  |proj g|=       0.78935
At iterate    23  f =      -427.57  |proj g|=       0.93754
At iterate    24  f =      -427.59  |proj g|=        1.0094
At iterate    25  f =      -427.61  |proj g|=         1.178
At iterate    26  f =      -427.65  |proj g|=        1.1325
At iterate    27  f =      -427.65  |proj g|=        1.1301
At iterate    28  f =      -427.65  |proj g|=        1.1302
At iterate    29  f =      -427.65  |proj g|=        1.1304

iterations 29
function evaluations 36
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.13037
final function value -427.651

F = -427.651
final  value -427.650775 
converged
 
INFO  [03:53:32.711] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:53:32.768] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:53:32.775] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:53:38.344] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:53:44.799] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:53:50.038] [mlr3]  Finished benchmark 
INFO  [03:53:50.284] [bbotk] Result of batch 75: 
INFO  [03:53:50.286] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:53:50.286] [bbotk]              7.938781                  5.57551                       0.2993981 
INFO  [03:53:50.286] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:53:50.286] [bbotk]                     1615        0.818 -0.9585447         <NA>   0.9720817 
INFO  [03:53:50.286] [bbotk]                                 uhash 
INFO  [03:53:50.286] [bbotk]  33c46c5b-fa9e-4ea7-8b9d-1db76e27b176 
DEBUG [03:53:51.255] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.070875e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.044142e-05 0.001070875 
  - best initial criterion value(s) :  395.8562 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -395.86  |proj g|=       3.2503
At iterate     1  f =      -399.95  |proj g|=        4.6559
At iterate     2  f =      -401.14  |proj g|=         4.149
At iterate     3  f =      -401.32  |proj g|=        4.0524
At iterate     4  f =      -401.43  |proj g|=        4.0129
At iterate     5  f =      -401.44  |proj g|=        4.0516
At iterate     6  f =      -401.44  |proj g|=        4.0436
At iterate     7  f =      -401.44  |proj g|=        4.0437
At iterate     8  f =      -401.44  |proj g|=        4.0433
At iterate     9  f =      -401.44  |proj g|=        4.0423
At iterate    10  f =      -401.44  |proj g|=        4.0404
At iterate    11  f =      -401.44  |proj g|=        4.0374
At iterate    12  f =      -401.44  |proj g|=        4.0325
At iterate    13  f =      -401.44  |proj g|=        4.0249
At iterate    14  f =      -401.44  |proj g|=        4.0146
At iterate    15  f =      -401.45  |proj g|=        4.0004
At iterate    16  f =      -401.46  |proj g|=        3.9725
At iterate    17  f =       -401.5  |proj g|=        3.9537
At iterate    18  f =      -401.54  |proj g|=        3.7445
At iterate    19  f =      -401.64  |proj g|=        3.7225
At iterate    20  f =       -402.4  |proj g|=        3.3524
At iterate    21  f =       -403.5  |proj g|=        2.6629
At iterate    22  f =      -404.67  |proj g|=        1.8495
At iterate    23  f =      -405.62  |proj g|=        1.3044
At iterate    24  f =      -406.24  |proj g|=       0.83408
At iterate    25  f =      -406.74  |proj g|=       0.68224
At iterate    26  f =      -406.77  |proj g|=         0.561
At iterate    27  f =      -406.79  |proj g|=       0.83476
At iterate    28  f =      -406.79  |proj g|=       0.55236
At iterate    29  f =      -406.79  |proj g|=       0.55305
At iterate    30  f =      -406.79  |proj g|=       0.55321

iterations 30
function evaluations 37
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.553205
final function value -406.793

F = -406.793
final  value -406.792839 
converged
 
INFO  [03:53:51.260] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:53:51.318] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:53:51.325] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:53:56.696] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:54:04.873] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:54:10.048] [mlr3]  Finished benchmark 
INFO  [03:54:10.166] [bbotk] Result of batch 76: 
INFO  [03:54:10.168] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:54:10.168] [bbotk]              8.289682                 9.659146                       0.1635048 
INFO  [03:54:10.168] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:54:10.168] [bbotk]                     1982        0.647 -0.9665565         <NA>   0.9703157 
INFO  [03:54:10.168] [bbotk]                                 uhash 
INFO  [03:54:10.168] [bbotk]  98914998-c54f-436f-8bc5-4e404ec253d7 
DEBUG [03:54:11.309] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.062536e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.037786e-05 0.001062536 
  - best initial criterion value(s) :  412.1036 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -412.1  |proj g|=       2.4635
At iterate     1  f =      -419.04  |proj g|=        2.4911
At iterate     2  f =      -420.49  |proj g|=        4.0447
At iterate     3  f =      -421.85  |proj g|=        3.8492
At iterate     4  f =       -423.7  |proj g|=        3.2536
At iterate     5  f =      -424.69  |proj g|=        3.3766
At iterate     6  f =         -425  |proj g|=        3.7524
At iterate     7  f =      -425.01  |proj g|=        3.7039
At iterate     8  f =      -425.02  |proj g|=        3.7128
At iterate     9  f =      -425.02  |proj g|=        3.7111
At iterate    10  f =      -425.02  |proj g|=        3.7109
At iterate    11  f =      -425.02  |proj g|=        3.7107
At iterate    12  f =      -425.02  |proj g|=        3.7104
At iterate    13  f =      -425.02  |proj g|=        3.7086
At iterate    14  f =      -425.02  |proj g|=        3.7086
At iterate    15  f =      -425.02  |proj g|=        3.7086
At iterate    16  f =      -425.02  |proj g|=        3.7076
At iterate    17  f =      -425.04  |proj g|=        3.7006
At iterate    18  f =      -425.09  |proj g|=        3.6685
At iterate    19  f =      -425.09  |proj g|=        3.6951
At iterate    20  f =      -425.26  |proj g|=        3.5681
At iterate    21  f =       -425.6  |proj g|=        3.3248
At iterate    22  f =      -426.59  |proj g|=        2.7561
At iterate    23  f =      -429.02  |proj g|=        2.2703
At iterate    24  f =      -432.45  |proj g|=        2.5301
At iterate    25  f =      -432.54  |proj g|=        2.7021
At iterate    26  f =      -433.87  |proj g|=        2.7654
At iterate    27  f =      -434.24  |proj g|=        2.7539
At iterate    28  f =      -434.41  |proj g|=        2.7115
At iterate    29  f =      -434.51  |proj g|=        2.6599
At iterate    30  f =      -434.54  |proj g|=        2.6437
At iterate    31  f =      -434.57  |proj g|=        2.5104
At iterate    32  f =      -434.61  |proj g|=        2.4563
At iterate    33  f =      -434.61  |proj g|=        2.4677
At iterate    34  f =      -434.61  |proj g|=        2.4664
At iterate    35  f =      -434.61  |proj g|=        2.4659
At iterate    36  f =      -434.61  |proj g|=        2.4653
At iterate    37  f =      -434.61  |proj g|=        2.4647
At iterate    38  f =      -434.61  |proj g|=        2.4592
At iterate    39  f =      -434.61  |proj g|=        2.4615
At iterate    40  f =      -434.61  |proj g|=         2.465
At iterate    41  f =      -434.61  |proj g|=        2.4707
At iterate    42  f =      -434.61  |proj g|=        2.4796
At iterate    43  f =      -434.62  |proj g|=        2.4928
At iterate    44  f =      -434.62  |proj g|=        2.5119
At iterate    45  f =      -434.63  |proj g|=        2.5387
At iterate    46  f =      -434.65  |proj g|=        2.5739
At iterate    47  f =      -434.72  |proj g|=        2.6138
At iterate    48  f =      -434.89  |proj g|=        2.6339
At iterate    49  f =      -435.34  |proj g|=        2.5533
At iterate    50  f =      -436.37  |proj g|=        2.1993
At iterate    51  f =      -438.45  |proj g|=        1.3506
At iterate    52  f =      -439.51  |proj g|=       0.80328
At iterate    53  f =      -439.89  |proj g|=       0.80366
At iterate    54  f =      -440.78  |proj g|=       0.79408
At iterate    55  f =       -442.7  |proj g|=       0.75793
At iterate    56  f =      -442.75  |proj g|=       0.75793
At iterate    57  f =      -442.76  |proj g|=       0.75793
At iterate    58  f =      -442.76  |proj g|=       0.75793
At iterate    59  f =      -442.76  |proj g|=       0.75792
At iterate    60  f =      -442.76  |proj g|=       0.75792
At iterate    61  f =      -442.76  |proj g|=       0.75781
At iterate    62  f =      -442.77  |proj g|=       0.75747
At iterate    63  f =      -442.83  |proj g|=       0.75553
At iterate    64  f =      -442.95  |proj g|=       0.75116
At iterate    65  f =      -443.17  |proj g|=         0.741
At iterate    66  f =      -443.47  |proj g|=       0.72538
At iterate    67  f =      -443.72  |proj g|=       0.72427
At iterate    68  f =      -443.81  |proj g|=       0.71015
At iterate    69  f =      -443.81  |proj g|=       0.17112
At iterate    70  f =      -443.81  |proj g|=       0.17021
At iterate    71  f =      -443.81  |proj g|=       0.17023

iterations 71
function evaluations 85
segments explored during Cauchy searches 76
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.170227
final function value -443.812

F = -443.812
final  value -443.811628 
converged
 
INFO  [03:54:11.313] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:54:11.371] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:54:11.379] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:54:14.748] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:54:17.138] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:54:19.776] [mlr3]  Finished benchmark 
INFO  [03:54:19.853] [bbotk] Result of batch 77: 
INFO  [03:54:19.854] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:54:19.854] [bbotk]              9.792858                 4.637302                        0.171412 
INFO  [03:54:19.854] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [03:54:19.854] [bbotk]                      794         0.65 -0.952906         <NA>   0.9642699 
INFO  [03:54:19.854] [bbotk]                                 uhash 
INFO  [03:54:19.854] [bbotk]  259b993d-3c57-4d2f-9a32-e3af1700a5e0 
DEBUG [03:54:20.797] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.052887e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.81134 15.35399 0.9788035 9526 
  - variance bounds :  1.028697e-05 0.001052887 
  - best initial criterion value(s) :  396.3928 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -396.39  |proj g|=       5.2721
At iterate     1  f =      -428.07  |proj g|=        2.0317
At iterate     2  f =      -438.25  |proj g|=        1.1602
At iterate     3  f =      -441.38  |proj g|=         1.079
At iterate     4  f =      -441.66  |proj g|=        0.9748
At iterate     5  f =      -442.18  |proj g|=       0.44072
At iterate     6  f =      -442.39  |proj g|=       0.48921
At iterate     7  f =      -442.43  |proj g|=       0.76407
At iterate     8  f =      -442.43  |proj g|=       0.76197
At iterate     9  f =      -442.43  |proj g|=       0.76213
At iterate    10  f =      -442.43  |proj g|=       0.76213

iterations 10
function evaluations 12
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.762134
final function value -442.434

F = -442.434
final  value -442.434359 
converged
 
INFO  [03:54:20.801] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:54:20.857] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:54:20.865] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:54:31.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:54:40.541] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:54:49.333] [mlr3]  Finished benchmark 
INFO  [03:54:49.400] [bbotk] Result of batch 78: 
INFO  [03:54:49.402] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:54:49.402] [bbotk]              2.063984                 6.578666                      0.05533505 
INFO  [03:54:49.402] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:54:49.402] [bbotk]                     4159          0.7 -0.9582809         <NA>   0.9468596 
INFO  [03:54:49.402] [bbotk]                                 uhash 
INFO  [03:54:49.402] [bbotk]  ff85a940-886a-4ac8-9d7b-81799b9344a0 
DEBUG [03:54:50.577] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.076734e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.049961e-05 0.001076734 
  - best initial criterion value(s) :  426.6976 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -426.7  |proj g|=       2.7884
At iterate     1  f =      -428.94  |proj g|=       0.64192
At iterate     2  f =      -430.87  |proj g|=        3.2946
At iterate     3  f =      -437.86  |proj g|=        2.4798
At iterate     4  f =      -438.98  |proj g|=        2.2212
At iterate     5  f =       -440.5  |proj g|=        1.6772
At iterate     6  f =      -440.74  |proj g|=        1.6183
At iterate     7  f =      -440.76  |proj g|=        1.7318
At iterate     8  f =      -440.79  |proj g|=         1.722
At iterate     9  f =      -440.79  |proj g|=        1.7246
At iterate    10  f =      -440.79  |proj g|=        1.7247
At iterate    11  f =      -440.79  |proj g|=         1.725
At iterate    12  f =      -440.79  |proj g|=        1.7257
At iterate    13  f =       -440.8  |proj g|=        1.7155
At iterate    14  f =       -440.8  |proj g|=        1.7261
At iterate    15  f =       -440.8  |proj g|=        1.7308
At iterate    16  f =      -440.83  |proj g|=        1.7601
At iterate    17  f =      -440.89  |proj g|=        1.7822
At iterate    18  f =      -441.05  |proj g|=        1.7929
At iterate    19  f =      -441.39  |proj g|=        1.7288
At iterate    20  f =       -441.9  |proj g|=        1.4958
At iterate    21  f =      -441.97  |proj g|=        1.3817
At iterate    22  f =       -442.2  |proj g|=        1.0447
At iterate    23  f =      -442.27  |proj g|=        1.0803
At iterate    24  f =      -442.29  |proj g|=        1.1686
At iterate    25  f =      -442.29  |proj g|=        1.1418
At iterate    26  f =      -442.29  |proj g|=        1.1413
At iterate    27  f =      -442.29  |proj g|=        1.1417
At iterate    28  f =      -442.29  |proj g|=        1.1432
At iterate    29  f =      -442.29  |proj g|=        1.1435
At iterate    30  f =      -442.29  |proj g|=        1.1435
At iterate    31  f =      -442.29  |proj g|=        1.1435
At iterate    32  f =      -442.29  |proj g|=        1.1435
At iterate    33  f =      -442.29  |proj g|=        1.1435
At iterate    34  f =      -442.29  |proj g|=        1.1459
At iterate    35  f =      -442.29  |proj g|=        1.1401
At iterate    36  f =      -442.29  |proj g|=         1.144
At iterate    37  f =      -442.29  |proj g|=        1.1526
At iterate    38  f =       -442.3  |proj g|=         1.164
At iterate    39  f =      -442.31  |proj g|=        1.1671
At iterate    40  f =      -442.34  |proj g|=         1.138
At iterate    41  f =      -442.34  |proj g|=        1.1462
At iterate    42  f =      -442.35  |proj g|=        1.0967
At iterate    43  f =      -442.35  |proj g|=        1.0666
At iterate    44  f =      -442.35  |proj g|=        1.0617
At iterate    45  f =      -442.35  |proj g|=        1.0598
At iterate    46  f =      -442.35  |proj g|=        1.0533
At iterate    47  f =      -442.35  |proj g|=        1.0294
At iterate    48  f =      -442.35  |proj g|=         1.036
At iterate    49  f =      -442.36  |proj g|=        1.0414
At iterate    50  f =      -442.37  |proj g|=        1.0462
At iterate    51  f =      -442.39  |proj g|=        1.0438
At iterate    52  f =      -442.44  |proj g|=        1.0094
At iterate    53  f =      -442.56  |proj g|=       0.96762
At iterate    54  f =      -442.82  |proj g|=       0.81459
At iterate    55  f =      -443.22  |proj g|=       0.75951
At iterate    56  f =      -443.43  |proj g|=       0.75906
At iterate    57  f =      -444.05  |proj g|=       0.75176
At iterate    58  f =      -444.45  |proj g|=       0.22601
At iterate    59  f =      -444.51  |proj g|=       0.22857
At iterate    60  f =      -444.52  |proj g|=       0.22816
At iterate    61  f =      -444.52  |proj g|=       0.22808
At iterate    62  f =      -444.52  |proj g|=         0.228
At iterate    63  f =      -444.52  |proj g|=       0.22799
At iterate    64  f =      -444.52  |proj g|=       0.22792
At iterate    65  f =      -444.53  |proj g|=       0.22655
At iterate    66  f =      -444.59  |proj g|=        0.2215
At iterate    67  f =      -444.66  |proj g|=       0.21681
At iterate    68  f =      -444.75  |proj g|=       0.77476
At iterate    69  f =      -444.75  |proj g|=       0.77477
At iterate    70  f =      -444.75  |proj g|=       0.19512
At iterate    71  f =      -444.75  |proj g|=       0.11446
At iterate    72  f =      -444.75  |proj g|=      0.014538
At iterate    73  f =      -444.75  |proj g|=      0.015195

iterations 73
function evaluations 88
segments explored during Cauchy searches 75
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.0151952
final function value -444.749

F = -444.749
final  value -444.749302 
converged
 
INFO  [03:54:50.581] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:54:50.635] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:54:50.641] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:54:51.919] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:54:53.146] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:54:54.491] [mlr3]  Finished benchmark 
INFO  [03:54:54.559] [bbotk] Result of batch 79: 
INFO  [03:54:54.560] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:54:54.560] [bbotk]              8.451888                  4.74871                       0.2377236 
INFO  [03:54:54.560] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:54:54.560] [bbotk]                      480        0.672 -0.9576852         <NA>   0.9621165 
INFO  [03:54:54.560] [bbotk]                                 uhash 
INFO  [03:54:54.560] [bbotk]  877d4427-e5bc-4588-b382-b568b43a3a74 
DEBUG [03:54:55.566] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.068103e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.040794e-05 0.001068103 
  - best initial criterion value(s) :  423.3907 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -423.39  |proj g|=       1.1613
At iterate     1  f =      -435.28  |proj g|=         4.358
At iterate     2  f =       -436.2  |proj g|=        4.1828
At iterate     3  f =       -437.4  |proj g|=        3.0441
At iterate     4  f =      -438.17  |proj g|=        3.5692
At iterate     5  f =      -438.77  |proj g|=        3.4532
At iterate     6  f =      -439.86  |proj g|=        3.0364
At iterate     7  f =      -439.95  |proj g|=        2.8282
At iterate     8  f =      -439.96  |proj g|=        2.9211
At iterate     9  f =      -439.96  |proj g|=        2.9063
At iterate    10  f =      -439.96  |proj g|=        2.9068
At iterate    11  f =      -439.96  |proj g|=        2.9072
At iterate    12  f =      -439.96  |proj g|=         2.908
At iterate    13  f =      -439.97  |proj g|=        2.9098
At iterate    14  f =      -439.97  |proj g|=         2.912
At iterate    15  f =      -439.97  |proj g|=        2.9152
At iterate    16  f =      -439.99  |proj g|=        2.9113
At iterate    17  f =      -440.02  |proj g|=        2.8993
At iterate    18  f =       -440.1  |proj g|=          2.85
At iterate    19  f =      -440.27  |proj g|=        2.8561
At iterate    20  f =      -440.68  |proj g|=        2.7067
At iterate    21  f =      -442.36  |proj g|=        2.4427
At iterate    22  f =      -445.52  |proj g|=        1.6797
At iterate    23  f =      -451.08  |proj g|=        0.7349
At iterate    24  f =      -451.21  |proj g|=       0.73395
At iterate    25  f =      -451.47  |proj g|=       0.74975
At iterate    26  f =      -451.51  |proj g|=       0.75773
At iterate    27  f =      -451.53  |proj g|=       0.75542
At iterate    28  f =      -451.53  |proj g|=       0.52271
At iterate    29  f =      -451.53  |proj g|=       0.17236
At iterate    30  f =      -451.53  |proj g|=       0.17184

iterations 30
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.171838
final function value -451.534

F = -451.534
final  value -451.533612 
converged
 
INFO  [03:54:55.570] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:54:55.626] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:54:55.633] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:54:59.726] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:55:04.210] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:55:08.374] [mlr3]  Finished benchmark 
INFO  [03:55:08.462] [bbotk] Result of batch 80: 
INFO  [03:55:08.464] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:55:08.464] [bbotk]               4.65647                 7.150371                      0.03596921 
INFO  [03:55:08.464] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:55:08.464] [bbotk]                     2194        0.674 -0.9562784         <NA>   0.9533511 
INFO  [03:55:08.464] [bbotk]                                 uhash 
INFO  [03:55:08.464] [bbotk]  cb7f2155-770f-4f16-8f5f-d917aa04487c 
DEBUG [03:55:09.457] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.072324e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.043646e-05 0.001072324 
  - best initial criterion value(s) :  421.2012 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -421.2  |proj g|=       1.0821
At iterate     1  f =      -440.46  |proj g|=       0.49035
At iterate     2  f =      -442.32  |proj g|=        2.7421
At iterate     3  f =      -443.28  |proj g|=        2.4928
At iterate     4  f =      -444.27  |proj g|=        1.9048
At iterate     5  f =      -444.29  |proj g|=        1.6518
At iterate     6  f =      -444.31  |proj g|=        1.7641
At iterate     7  f =      -444.31  |proj g|=        1.7545
At iterate     8  f =      -444.31  |proj g|=        1.7393
At iterate     9  f =      -444.31  |proj g|=        1.7387
At iterate    10  f =      -444.31  |proj g|=        1.7402
At iterate    11  f =      -444.31  |proj g|=        1.7405

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.74045
final function value -444.31

F = -444.31
final  value -444.309850 
converged
 
INFO  [03:55:09.461] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:55:09.516] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:55:09.523] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:55:12.667] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:55:15.809] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:55:18.862] [mlr3]  Finished benchmark 
INFO  [03:55:18.932] [bbotk] Result of batch 81: 
INFO  [03:55:18.934] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:55:18.934] [bbotk]              8.063556                 7.463161                       0.4920062 
INFO  [03:55:18.934] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:55:18.934] [bbotk]                     1603        0.719 -0.9627034         <NA>   0.9729782 
INFO  [03:55:18.934] [bbotk]                                 uhash 
INFO  [03:55:18.934] [bbotk]  01edaf7b-a08b-423b-9481-e003d0be7318 
DEBUG [03:55:20.073] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.067427e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.035716e-05 0.001067427 
  - best initial criterion value(s) :  434.9963 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -435  |proj g|=       5.3395
At iterate     1  f =      -435.42  |proj g|=        3.9979
At iterate     2  f =      -435.66  |proj g|=        5.0099
At iterate     3  f =       -437.4  |proj g|=        4.9132
At iterate     4  f =      -438.22  |proj g|=        4.8391
At iterate     5  f =      -438.52  |proj g|=        5.1624
At iterate     6  f =      -438.52  |proj g|=        5.2078
At iterate     7  f =      -438.52  |proj g|=        5.2088
At iterate     8  f =      -438.52  |proj g|=        5.2058
At iterate     9  f =      -438.52  |proj g|=        5.2061
At iterate    10  f =      -438.52  |proj g|=        5.2068
At iterate    11  f =      -438.52  |proj g|=        5.2093
At iterate    12  f =      -438.52  |proj g|=        5.2124
At iterate    13  f =      -438.53  |proj g|=         5.218
At iterate    14  f =      -438.53  |proj g|=        5.2255
At iterate    15  f =      -438.53  |proj g|=        5.2433
At iterate    16  f =      -438.54  |proj g|=        5.2546
At iterate    17  f =      -438.54  |proj g|=        5.2879
At iterate    18  f =      -438.57  |proj g|=        5.2934
At iterate    19  f =       -438.8  |proj g|=        5.2286
At iterate    20  f =      -439.99  |proj g|=        4.6674
At iterate    21  f =      -442.42  |proj g|=         3.667
At iterate    22  f =      -448.53  |proj g|=        1.7507
At iterate    23  f =      -448.64  |proj g|=        1.5562
At iterate    24  f =      -450.92  |proj g|=        0.8285
At iterate    25  f =      -451.78  |proj g|=       0.68132
At iterate    26  f =      -452.15  |proj g|=       0.85523
At iterate    27  f =      -452.29  |proj g|=       0.93014
At iterate    28  f =      -452.29  |proj g|=       0.89067
At iterate    29  f =       -452.3  |proj g|=       0.82255
At iterate    30  f =      -452.34  |proj g|=       0.87359
At iterate    31  f =      -452.34  |proj g|=       0.89854
At iterate    32  f =      -452.34  |proj g|=        0.9018
At iterate    33  f =      -452.34  |proj g|=       0.90191

iterations 33
function evaluations 44
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.901908
final function value -452.342

F = -452.342
final  value -452.341925 
converged
 
INFO  [03:55:20.074] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:55:20.120] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:55:20.126] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:55:29.826] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:55:39.187] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:55:52.272] [mlr3]  Finished benchmark 
INFO  [03:55:52.341] [bbotk] Result of batch 82: 
INFO  [03:55:52.343] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:55:52.343] [bbotk]              3.751332                 7.195503                       0.3912887 
INFO  [03:55:52.343] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:55:52.343] [bbotk]                     4973        0.784 -0.9620755         <NA>   0.9733725 
INFO  [03:55:52.343] [bbotk]                                 uhash 
INFO  [03:55:52.343] [bbotk]  6e0082fd-aebd-416f-baf3-d211e5af4292 
DEBUG [03:55:53.558] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.063052e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.032867e-05 0.001063052 
  - best initial criterion value(s) :  437.3053 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -437.31  |proj g|=       3.7091
At iterate     1  f =      -446.37  |proj g|=        3.1702
At iterate     2  f =      -451.66  |proj g|=        2.7356
At iterate     3  f =      -459.02  |proj g|=        1.1367
At iterate     4  f =      -459.29  |proj g|=       0.85101
At iterate     5  f =      -459.69  |proj g|=       0.84798
At iterate     6  f =      -462.09  |proj g|=       0.91278
At iterate     7  f =      -462.69  |proj g|=       0.89507
At iterate     8  f =      -462.96  |proj g|=        1.0362
At iterate     9  f =         -463  |proj g|=        1.0392
At iterate    10  f =         -463  |proj g|=        1.0897
At iterate    11  f =      -463.01  |proj g|=        1.0469
At iterate    12  f =      -463.01  |proj g|=        1.0486
At iterate    13  f =      -463.01  |proj g|=        1.0528
At iterate    14  f =      -463.01  |proj g|=        1.0625
At iterate    15  f =      -463.01  |proj g|=          1.08
At iterate    16  f =      -463.02  |proj g|=        1.1018
At iterate    17  f =      -463.05  |proj g|=        1.1274
At iterate    18  f =      -463.12  |proj g|=        1.1428
At iterate    19  f =      -463.28  |proj g|=        1.1042
At iterate    20  f =      -463.64  |proj g|=       0.91929
At iterate    21  f =      -464.34  |proj g|=       0.76164
At iterate    22  f =      -464.69  |proj g|=       0.21856
At iterate    23  f =      -464.71  |proj g|=       0.21879
At iterate    24  f =      -464.71  |proj g|=       0.21883
At iterate    25  f =      -464.71  |proj g|=       0.21885
At iterate    26  f =      -464.71  |proj g|=       0.21882
At iterate    27  f =      -464.71  |proj g|=       0.21882
At iterate    28  f =      -464.71  |proj g|=       0.21808
At iterate    29  f =      -464.71  |proj g|=       0.21624
At iterate    30  f =      -464.72  |proj g|=       0.21433
At iterate    31  f =      -464.72  |proj g|=       0.14772
At iterate    32  f =      -464.72  |proj g|=       0.14555
At iterate    33  f =      -464.72  |proj g|=       0.14538

iterations 33
function evaluations 38
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.145378
final function value -464.717

F = -464.717
final  value -464.717403 
converged
 
INFO  [03:55:53.562] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:55:53.637] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:55:53.644] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:55:56.876] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:55:59.690] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:56:02.607] [mlr3]  Finished benchmark 
INFO  [03:56:02.676] [bbotk] Result of batch 83: 
INFO  [03:56:02.677] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:56:02.677] [bbotk]              2.744088                 9.533778                       0.2365775 
INFO  [03:56:02.677] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:56:02.677] [bbotk]                     1027        0.861 -0.9568841         <NA>   0.9534219 
INFO  [03:56:02.677] [bbotk]                                 uhash 
INFO  [03:56:02.677] [bbotk]  f73651b9-4c57-4219-83ab-25b7bfc881f7 
DEBUG [03:56:03.853] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.0671e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.03551e-05 0.0010671 
  - best initial criterion value(s) :  427.3341 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -427.33  |proj g|=       14.005
At iterate     1  f =      -431.56  |proj g|=        5.0136
At iterate     2  f =      -450.11  |proj g|=        2.7482
At iterate     3  f =      -451.52  |proj g|=        1.1383
At iterate     4  f =       -451.7  |proj g|=        1.9316
At iterate     5  f =      -451.78  |proj g|=        1.7315
At iterate     6  f =      -451.78  |proj g|=        1.6983
At iterate     7  f =      -451.78  |proj g|=        1.7057
At iterate     8  f =      -451.78  |proj g|=        1.7692
At iterate     9  f =      -451.78  |proj g|=        1.7891
At iterate    10  f =      -451.79  |proj g|=        1.8796
At iterate    11  f =      -451.81  |proj g|=        2.0074
At iterate    12  f =      -451.87  |proj g|=        2.2137
At iterate    13  f =      -451.87  |proj g|=        2.3039
At iterate    14  f =      -452.01  |proj g|=        2.5758
At iterate    15  f =      -455.25  |proj g|=        2.6071
At iterate    16  f =       -463.9  |proj g|=        1.0444
At iterate    17  f =       -466.2  |proj g|=       0.25669
At iterate    18  f =      -466.86  |proj g|=        0.1728
At iterate    19  f =      -467.25  |proj g|=         0.805
At iterate    20  f =      -467.55  |proj g|=       0.24267
At iterate    21  f =       -467.6  |proj g|=       0.24691
At iterate    22  f =      -467.61  |proj g|=       0.26203
At iterate    23  f =      -467.61  |proj g|=       0.27188
At iterate    24  f =      -467.61  |proj g|=       0.27364
At iterate    25  f =      -467.61  |proj g|=       0.27372

iterations 25
function evaluations 34
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.273719
final function value -467.611

F = -467.611
final  value -467.610706 
converged
 
INFO  [03:56:03.857] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:56:03.915] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:56:03.922] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:56:14.056] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:56:23.466] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:56:35.331] [mlr3]  Finished benchmark 
INFO  [03:56:35.427] [bbotk] Result of batch 84: 
INFO  [03:56:35.429] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:56:35.429] [bbotk]              3.124335                 2.459364                      0.05902401 
INFO  [03:56:35.429] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:56:35.429] [bbotk]                     3657        0.849 -0.9584021         <NA>   0.9572074 
INFO  [03:56:35.429] [bbotk]                                 uhash 
INFO  [03:56:35.429] [bbotk]  fb046016-afbc-4bb8-8547-1172699141c4 
DEBUG [03:56:36.394] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.064009e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.036027e-05 0.001064009 
  - best initial criterion value(s) :  448.4397 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -448.44  |proj g|=       4.3014
At iterate     1  f =      -455.27  |proj g|=        1.9223
At iterate     2  f =      -473.15  |proj g|=        1.3286
At iterate     3  f =      -473.45  |proj g|=        1.2107
At iterate     4  f =      -473.87  |proj g|=       0.82464
At iterate     5  f =      -474.03  |proj g|=       0.72404
At iterate     6  f =      -474.18  |proj g|=       0.77446
At iterate     7  f =      -474.18  |proj g|=       0.77095
At iterate     8  f =      -474.18  |proj g|=       0.77114
At iterate     9  f =      -474.18  |proj g|=       0.77122
At iterate    10  f =      -474.18  |proj g|=        0.7712

iterations 10
function evaluations 13
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.7712
final function value -474.185

F = -474.185
final  value -474.184861 
converged
 
INFO  [03:56:36.398] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:56:36.481] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:56:36.490] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:56:50.712] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:57:05.433] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:57:19.935] [mlr3]  Finished benchmark 
INFO  [03:57:20.007] [bbotk] Result of batch 85: 
INFO  [03:57:20.009] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:57:20.009] [bbotk]              5.059231                 3.772018                       0.3873378 
INFO  [03:57:20.009] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:57:20.009] [bbotk]                     3920        0.698 -0.9573203         <NA>   0.9749904 
INFO  [03:57:20.009] [bbotk]                                 uhash 
INFO  [03:57:20.009] [bbotk]  379e69c3-bc54-48bb-9a5a-8c0798c564f7 
DEBUG [03:57:21.011] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.062319e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.03565e-05 0.001062319 
  - best initial criterion value(s) :  442.705 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -442.7  |proj g|=       5.6259
At iterate     1  f =      -457.12  |proj g|=       0.94849
At iterate     2  f =      -471.02  |proj g|=        2.6118
At iterate     3  f =      -473.72  |proj g|=        2.3983
At iterate     4  f =      -475.13  |proj g|=        1.7673
At iterate     5  f =      -475.33  |proj g|=        1.4023
At iterate     6  f =      -475.33  |proj g|=        1.3864
At iterate     7  f =      -475.33  |proj g|=        1.3867
At iterate     8  f =      -475.33  |proj g|=        1.3878
At iterate     9  f =      -475.33  |proj g|=        1.3877

iterations 9
function evaluations 13
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.38769
final function value -475.333

F = -475.333
final  value -475.333073 
converged
 
INFO  [03:57:21.015] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:57:21.073] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:57:21.081] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:57:30.361] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:57:40.192] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:57:50.280] [mlr3]  Finished benchmark 
INFO  [03:57:50.365] [bbotk] Result of batch 86: 
INFO  [03:57:50.367] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:57:50.367] [bbotk]              3.951106                 5.645053                        0.214084 
INFO  [03:57:50.367] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:57:50.367] [bbotk]                     2647        0.726 -0.9595392         <NA>   0.9697018 
INFO  [03:57:50.367] [bbotk]                                 uhash 
INFO  [03:57:50.367] [bbotk]  a714336f-59a4-4885-a532-fec7fdf9a05f 
DEBUG [03:57:51.414] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.054526e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.027016e-05 0.001054526 
  - best initial criterion value(s) :  425.1469 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -425.15  |proj g|=       12.357
At iterate     1  f =      -446.28  |proj g|=        7.4542
At iterate     2  f =      -452.27  |proj g|=        7.9023
At iterate     3  f =      -454.92  |proj g|=        6.7955
At iterate     4  f =      -457.88  |proj g|=        4.1962
At iterate     5  f =      -458.03  |proj g|=         4.185
At iterate     6  f =      -458.51  |proj g|=        4.2553
At iterate     7  f =       -458.6  |proj g|=        4.2273
At iterate     8  f =      -458.62  |proj g|=        4.1825
At iterate     9  f =      -458.63  |proj g|=        4.1807
At iterate    10  f =      -458.63  |proj g|=         4.173
At iterate    11  f =      -458.63  |proj g|=        4.1953
At iterate    12  f =      -458.63  |proj g|=        4.1683
At iterate    13  f =      -458.64  |proj g|=        4.1237
At iterate    14  f =      -458.67  |proj g|=         4.013
At iterate    15  f =      -458.75  |proj g|=        3.8486
At iterate    16  f =      -458.96  |proj g|=        3.5441
At iterate    17  f =      -459.48  |proj g|=        3.0381
At iterate    18  f =      -460.74  |proj g|=        2.4413
At iterate    19  f =      -462.99  |proj g|=        2.2037
At iterate    20  f =      -463.22  |proj g|=        1.9293
At iterate    21  f =      -466.82  |proj g|=        1.6518
At iterate    22  f =      -478.33  |proj g|=        2.5832
At iterate    23  f =      -479.72  |proj g|=        2.2257
At iterate    24  f =      -480.71  |proj g|=        2.1923
At iterate    25  f =      -481.03  |proj g|=        2.1607
At iterate    26  f =      -481.04  |proj g|=        2.2261
At iterate    27  f =      -481.04  |proj g|=        2.2259

iterations 27
function evaluations 36
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.22592
final function value -481.044

F = -481.044
final  value -481.043704 
converged
 
INFO  [03:57:51.418] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:57:51.475] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:57:51.482] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:58:00.274] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:58:08.640] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:58:17.542] [mlr3]  Finished benchmark 
INFO  [03:58:17.614] [bbotk] Result of batch 87: 
INFO  [03:58:17.616] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:58:17.616] [bbotk]              5.374789                 4.946771                       0.1257115 
INFO  [03:58:17.616] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:58:17.616] [bbotk]                     3135        0.697 -0.9550733         <NA>   0.9704959 
INFO  [03:58:17.616] [bbotk]                                 uhash 
INFO  [03:58:17.616] [bbotk]  e161185d-3025-43b0-8e65-909dbfe0d72a 
DEBUG [03:58:18.712] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.04743e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.016672e-05 0.00104743 
  - best initial criterion value(s) :  434.6612 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -434.66  |proj g|=       13.336
At iterate     1  f =      -448.15  |proj g|=        6.9117
At iterate     2  f =      -454.95  |proj g|=        5.3453
At iterate     3  f =      -459.64  |proj g|=         3.727
At iterate     4  f =      -460.46  |proj g|=        3.2554
At iterate     5  f =      -461.06  |proj g|=        2.7123
At iterate     6  f =      -461.15  |proj g|=        2.5595
At iterate     7  f =      -461.15  |proj g|=        2.6184
At iterate     8  f =      -461.15  |proj g|=        2.6131
At iterate     9  f =      -461.15  |proj g|=         2.611
At iterate    10  f =      -461.15  |proj g|=        2.6045
At iterate    11  f =      -461.15  |proj g|=        2.5962
At iterate    12  f =      -461.16  |proj g|=        2.5819
At iterate    13  f =      -461.16  |proj g|=        2.5599
At iterate    14  f =      -461.18  |proj g|=         2.522
At iterate    15  f =      -461.22  |proj g|=        2.4534
At iterate    16  f =      -461.34  |proj g|=        2.3225
At iterate    17  f =      -461.65  |proj g|=        2.0758
At iterate    18  f =      -462.41  |proj g|=        1.6711
At iterate    19  f =      -463.68  |proj g|=        1.2569
At iterate    20  f =      -464.21  |proj g|=        1.1063
At iterate    21  f =      -464.31  |proj g|=        1.0987
At iterate    22  f =      -464.35  |proj g|=         1.132
At iterate    23  f =      -464.36  |proj g|=        1.1687
At iterate    24  f =      -464.39  |proj g|=        1.1856
At iterate    25  f =      -464.46  |proj g|=        1.2186
At iterate    26  f =      -464.65  |proj g|=        1.2475
At iterate    27  f =      -465.13  |proj g|=         1.256
At iterate    28  f =      -466.47  |proj g|=        1.2606
At iterate    29  f =      -470.18  |proj g|=        2.2001
At iterate    30  f =      -479.32  |proj g|=       0.45486
At iterate    31  f =      -484.21  |proj g|=        1.9499
At iterate    32  f =      -484.54  |proj g|=        2.0029
At iterate    33  f =      -485.05  |proj g|=        2.2362
At iterate    34  f =      -485.13  |proj g|=        2.3778
At iterate    35  f =      -485.17  |proj g|=        2.5086
At iterate    36  f =      -485.18  |proj g|=        2.5816
At iterate    37  f =      -485.18  |proj g|=        2.6021
At iterate    38  f =      -485.18  |proj g|=        2.6032
At iterate    39  f =      -485.18  |proj g|=        2.6032

iterations 39
function evaluations 42
segments explored during Cauchy searches 42
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.60316
final function value -485.183

F = -485.183
final  value -485.183337 
converged
 
INFO  [03:58:18.716] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:58:18.810] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:58:18.818] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:58:27.798] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:58:35.600] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:58:44.544] [mlr3]  Finished benchmark 
INFO  [03:58:44.655] [bbotk] Result of batch 88: 
INFO  [03:58:44.657] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:58:44.657] [bbotk]              7.407039                 9.156517                       0.2270711 
INFO  [03:58:44.657] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:58:44.657] [bbotk]                     2835        0.705 -0.9597048         <NA>   0.9731683 
INFO  [03:58:44.657] [bbotk]                                 uhash 
INFO  [03:58:44.657] [bbotk]  514b278e-67e3-4090-8a3d-3b10992cc461 
DEBUG [03:58:45.734] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.04314e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9526 
  - variance bounds :  1.013562e-05 0.00104314 
  - best initial criterion value(s) :  458.677 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -458.68  |proj g|=       5.7023
At iterate     1  f =      -471.32  |proj g|=        2.3083
At iterate     2  f =      -476.04  |proj g|=        2.1026
At iterate     3  f =      -482.06  |proj g|=        1.3425
At iterate     4  f =      -482.81  |proj g|=        1.3576
At iterate     5  f =      -487.01  |proj g|=        1.5406
At iterate     6  f =      -490.56  |proj g|=        1.3353
At iterate     7  f =      -492.07  |proj g|=         1.167
At iterate     8  f =      -492.71  |proj g|=        1.0978
At iterate     9  f =      -492.91  |proj g|=        1.2735
At iterate    10  f =      -492.93  |proj g|=        1.3281
At iterate    11  f =      -492.93  |proj g|=        1.3374
At iterate    12  f =      -492.93  |proj g|=        1.3395
At iterate    13  f =      -492.93  |proj g|=        1.3384
At iterate    14  f =      -492.93  |proj g|=          1.33
At iterate    15  f =      -492.94  |proj g|=        1.3038
At iterate    16  f =      -492.97  |proj g|=         1.262
At iterate    17  f =      -493.05  |proj g|=        1.1999
At iterate    18  f =      -493.23  |proj g|=        1.1195
At iterate    19  f =      -493.58  |proj g|=        1.0621
At iterate    20  f =      -494.05  |proj g|=        1.1459
At iterate    21  f =      -494.22  |proj g|=         1.264
At iterate    22  f =      -494.25  |proj g|=        1.3315
At iterate    23  f =      -494.25  |proj g|=        1.3521
At iterate    24  f =      -494.25  |proj g|=        1.3542
At iterate    25  f =      -494.25  |proj g|=        1.3543

iterations 25
function evaluations 30
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.35427
final function value -494.254

F = -494.254
final  value -494.254116 
converged
 
INFO  [03:58:45.738] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:58:45.799] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:58:45.806] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:58:48.098] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:58:49.599] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:58:50.997] [mlr3]  Finished benchmark 
INFO  [03:58:51.068] [bbotk] Result of batch 89: 
INFO  [03:58:51.070] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:58:51.070] [bbotk]              9.744848                 6.608469                      0.03864298 
INFO  [03:58:51.070] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:58:51.070] [bbotk]                      229         0.73 -0.9551475         <NA>   0.9141098 
INFO  [03:58:51.070] [bbotk]                                 uhash 
INFO  [03:58:51.070] [bbotk]  68f91dd8-cf01-42de-b571-8b48d4929b2d 
DEBUG [03:58:52.163] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.257394e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.257394e-05 0.001329928 
  - best initial criterion value(s) :  468.8443 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -468.84  |proj g|=       3.3789
At iterate     1  f =      -473.33  |proj g|=        2.6091
At iterate     2  f =      -475.08  |proj g|=        3.5269
At iterate     3  f =      -475.24  |proj g|=        3.5931
At iterate     4  f =       -475.3  |proj g|=        3.6633
At iterate     5  f =       -475.3  |proj g|=        3.6765
At iterate     6  f =       -475.3  |proj g|=        3.6791
At iterate     7  f =       -475.3  |proj g|=        3.6799
At iterate     8  f =       -475.3  |proj g|=        3.6806
At iterate     9  f =       -475.3  |proj g|=        3.6816
At iterate    10  f =       -475.3  |proj g|=        3.6832
At iterate    11  f =       -475.3  |proj g|=        3.6859
At iterate    12  f =       -475.3  |proj g|=        3.6899
At iterate    13  f =       -475.3  |proj g|=        3.6956
At iterate    14  f =       -475.3  |proj g|=        3.7014
At iterate    15  f =      -475.31  |proj g|=        3.7035
At iterate    16  f =      -475.31  |proj g|=        3.7087
At iterate    17  f =      -475.31  |proj g|=        3.7104
At iterate    18  f =      -480.74  |proj g|=        2.1721
At iterate    19  f =      -485.66  |proj g|=       0.74514
At iterate    20  f =      -487.25  |proj g|=       0.50237
At iterate    21  f =      -487.76  |proj g|=       0.47714
At iterate    22  f =      -487.81  |proj g|=       0.76806
At iterate    23  f =      -487.98  |proj g|=       0.76522
At iterate    24  f =      -488.03  |proj g|=       0.76012
At iterate    25  f =      -488.06  |proj g|=       0.75398
At iterate    26  f =      -488.06  |proj g|=       0.51018
At iterate    27  f =      -488.07  |proj g|=       0.50982
At iterate    28  f =      -488.07  |proj g|=       0.50765
At iterate    29  f =      -488.07  |proj g|=       0.50925
At iterate    30  f =      -488.07  |proj g|=       0.50948

iterations 30
function evaluations 38
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.509479
final function value -488.071

F = -488.071
final  value -488.070988 
converged
 
INFO  [03:58:52.168] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:58:52.262] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:58:52.272] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:59:01.805] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:59:10.275] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:59:18.705] [mlr3]  Finished benchmark 
INFO  [03:59:18.798] [bbotk] Result of batch 90: 
INFO  [03:59:18.801] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:59:18.801] [bbotk]              7.997839                 2.381905                       0.3186981 
INFO  [03:59:18.801] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:59:18.801] [bbotk]                     4160        0.722 -0.9547285         <NA>   0.9749846 
INFO  [03:59:18.801] [bbotk]                                 uhash 
INFO  [03:59:18.801] [bbotk]  74f5bbec-66cf-4a83-b86f-d8a8eb5e36f8 
DEBUG [03:59:19.813] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.254491e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.254491e-05 0.001328095 
  - best initial criterion value(s) :  429.8279 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -429.83  |proj g|=        3.346
At iterate     1  f =      -474.65  |proj g|=       0.86972
At iterate     2  f =      -475.13  |proj g|=        2.6403
At iterate     3  f =      -480.53  |proj g|=        2.1383
At iterate     4  f =      -481.94  |proj g|=        1.2911
At iterate     5  f =      -482.92  |proj g|=        1.4656
At iterate     6  f =      -486.09  |proj g|=        1.2045
At iterate     7  f =      -486.99  |proj g|=       0.81594
At iterate     8  f =      -487.44  |proj g|=       0.80557
At iterate     9  f =      -487.45  |proj g|=       0.30028
At iterate    10  f =      -487.45  |proj g|=        0.8053
At iterate    11  f =      -487.45  |proj g|=       0.80546
At iterate    12  f =      -487.45  |proj g|=       0.80542

iterations 12
function evaluations 16
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.805424
final function value -487.453

F = -487.453
final  value -487.453006 
converged
 
INFO  [03:59:19.818] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:59:19.892] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:59:19.900] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:59:22.923] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:59:25.910] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:59:29.498] [mlr3]  Finished benchmark 
INFO  [03:59:29.634] [bbotk] Result of batch 91: 
INFO  [03:59:29.636] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:59:29.636] [bbotk]              5.097732                 5.751896                       0.1803997 
INFO  [03:59:29.636] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:59:29.636] [bbotk]                     1490        0.733 -0.9588875         <NA>   0.9678961 
INFO  [03:59:29.636] [bbotk]                                 uhash 
INFO  [03:59:29.636] [bbotk]  5ac6353f-0376-4181-9c57-4b67db8c442b 
DEBUG [03:59:30.873] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.244597e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.244597e-05 0.001315948 
  - best initial criterion value(s) :  444.1469 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -444.15  |proj g|=       5.3658
At iterate     1  f =      -465.02  |proj g|=        6.7914
At iterate     2  f =      -467.04  |proj g|=        6.8691
At iterate     3  f =      -474.59  |proj g|=        5.5956
At iterate     4  f =      -476.21  |proj g|=        4.0077
At iterate     5  f =       -477.9  |proj g|=        3.9135
At iterate     6  f =      -478.33  |proj g|=        3.2764
At iterate     7  f =      -478.34  |proj g|=        3.2896
At iterate     8  f =      -478.34  |proj g|=        3.2893
At iterate     9  f =      -478.34  |proj g|=        3.2889
At iterate    10  f =      -478.34  |proj g|=        3.2881
At iterate    11  f =      -478.34  |proj g|=        3.2872
At iterate    12  f =      -478.34  |proj g|=        3.2858
At iterate    13  f =      -478.34  |proj g|=        3.2813
At iterate    14  f =      -478.35  |proj g|=        3.2711
At iterate    15  f =      -478.35  |proj g|=        3.2516
At iterate    16  f =      -478.37  |proj g|=        3.2064
At iterate    17  f =      -478.41  |proj g|=        3.1943
At iterate    18  f =      -478.49  |proj g|=        3.1024
At iterate    19  f =      -478.67  |proj g|=        3.1407
At iterate    20  f =      -479.24  |proj g|=        2.7731
At iterate    21  f =      -480.96  |proj g|=        1.9452
At iterate    22  f =      -482.78  |proj g|=        1.3423
At iterate    23  f =      -483.84  |proj g|=        1.4754
At iterate    24  f =      -483.97  |proj g|=        1.4625
At iterate    25  f =      -483.97  |proj g|=        1.4882
At iterate    26  f =      -483.98  |proj g|=        1.4762
At iterate    27  f =      -483.98  |proj g|=        1.4806
At iterate    28  f =      -483.98  |proj g|=        1.4795
At iterate    29  f =      -483.98  |proj g|=        1.4796

iterations 29
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.47956
final function value -483.98

F = -483.98
final  value -483.979933 
converged
 
INFO  [03:59:30.877] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:59:30.939] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:59:30.947] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:59:34.140] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:59:37.469] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:59:40.599] [mlr3]  Finished benchmark 
INFO  [03:59:40.667] [bbotk] Result of batch 92: 
INFO  [03:59:40.669] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:59:40.669] [bbotk]              4.479351                 9.043192                      0.08634107 
INFO  [03:59:40.669] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:59:40.669] [bbotk]                     1564         0.68 -0.9619388         <NA>   0.9595078 
INFO  [03:59:40.669] [bbotk]                                 uhash 
INFO  [03:59:40.669] [bbotk]  ce3ca14b-70e5-4827-bd20-506bc2f1f114 
DEBUG [03:59:42.069] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.237325e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.237325e-05 0.001306547 
  - best initial criterion value(s) :  430.421 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -430.42  |proj g|=       5.3591
At iterate     1  f =      -445.84  |proj g|=        9.0934
At iterate     2  f =      -446.23  |proj g|=        9.0245
At iterate     3  f =      -447.13  |proj g|=        7.6781
At iterate     4  f =      -447.42  |proj g|=        7.8081
At iterate     5  f =      -447.59  |proj g|=         7.461
At iterate     6  f =      -447.65  |proj g|=        7.1212
At iterate     7  f =      -447.67  |proj g|=        7.0028
At iterate     8  f =      -447.68  |proj g|=        6.9769
At iterate     9  f =      -447.73  |proj g|=        6.8441
At iterate    10  f =       -447.9  |proj g|=        6.6553
At iterate    11  f =       -448.7  |proj g|=        6.0856
At iterate    12  f =      -450.22  |proj g|=        5.5408
At iterate    13  f =      -454.02  |proj g|=        3.8371
At iterate    14  f =      -455.34  |proj g|=        5.4372
At iterate    15  f =      -462.81  |proj g|=        4.2759
At iterate    16  f =      -476.77  |proj g|=         2.647
At iterate    17  f =      -481.21  |proj g|=        1.3332
At iterate    18  f =      -483.61  |proj g|=        6.4578
At iterate    19  f =      -485.66  |proj g|=        4.2585
At iterate    20  f =      -486.43  |proj g|=        3.6088
At iterate    21  f =      -486.76  |proj g|=         3.209
At iterate    22  f =      -486.79  |proj g|=        3.2172
At iterate    23  f =       -486.8  |proj g|=        3.2494
At iterate    24  f =      -486.82  |proj g|=         3.337
At iterate    25  f =      -486.82  |proj g|=        3.4232
At iterate    26  f =      -486.82  |proj g|=        3.4173
At iterate    27  f =      -486.82  |proj g|=        3.4194
At iterate    28  f =      -486.82  |proj g|=        3.4213
At iterate    29  f =      -486.82  |proj g|=        3.4314
At iterate    30  f =      -486.83  |proj g|=        3.4353
At iterate    31  f =      -486.83  |proj g|=        3.4603
At iterate    32  f =      -486.83  |proj g|=        3.4615
At iterate    33  f =      -486.84  |proj g|=        3.4614
At iterate    34  f =      -486.88  |proj g|=        3.4434
At iterate    35  f =      -486.97  |proj g|=        3.3586
At iterate    36  f =      -487.12  |proj g|=          3.17
At iterate    37  f =      -487.29  |proj g|=        3.0917
At iterate    38  f =       -487.4  |proj g|=        2.6686
At iterate    39  f =       -487.5  |proj g|=        2.6908
At iterate    40  f =      -487.54  |proj g|=        2.6906
At iterate    41  f =      -487.54  |proj g|=        2.6975
At iterate    42  f =      -487.54  |proj g|=        2.6989
At iterate    43  f =      -487.54  |proj g|=        2.7036
At iterate    44  f =      -487.54  |proj g|=        2.7134
At iterate    45  f =      -487.54  |proj g|=        2.7053
At iterate    46  f =      -487.54  |proj g|=        2.7215
At iterate    47  f =      -487.55  |proj g|=        2.7497
At iterate    48  f =      -487.56  |proj g|=        2.7822
At iterate    49  f =      -487.58  |proj g|=        2.8143
At iterate    50  f =      -487.68  |proj g|=        2.9062
At iterate    51  f =      -487.89  |proj g|=        2.9959
At iterate    52  f =      -488.47  |proj g|=        3.1876
At iterate    53  f =      -489.58  |proj g|=        2.7072
At iterate    54  f =      -491.78  |proj g|=        3.4991
At iterate    55  f =      -493.08  |proj g|=        2.9901
At iterate    56  f =      -496.03  |proj g|=        1.9673
At iterate    57  f =       -497.6  |proj g|=        1.4897
At iterate    58  f =       -497.9  |proj g|=        1.6229
At iterate    59  f =      -497.91  |proj g|=        1.5582
At iterate    60  f =      -497.91  |proj g|=        1.5454
At iterate    61  f =      -497.91  |proj g|=        1.5368
At iterate    62  f =      -497.91  |proj g|=        1.5174
At iterate    63  f =      -497.92  |proj g|=        1.4784
At iterate    64  f =      -497.93  |proj g|=        1.4183
At iterate    65  f =      -497.97  |proj g|=        1.3159
At iterate    66  f =      -498.06  |proj g|=        1.1481
At iterate    67  f =      -498.29  |proj g|=       0.88363
At iterate    68  f =      -498.85  |proj g|=       0.50261
At iterate    69  f =      -500.24  |proj g|=       0.31658
At iterate    70  f =      -502.89  |proj g|=       0.33688
At iterate    71  f =      -503.31  |proj g|=       0.25783
At iterate    72  f =       -503.5  |proj g|=       0.24396
At iterate    73  f =      -503.51  |proj g|=       0.22341
At iterate    74  f =      -503.51  |proj g|=      0.013814
At iterate    75  f =      -503.51  |proj g|=     0.0028285

iterations 75
function evaluations 85
segments explored during Cauchy searches 78
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00282855
final function value -503.508

F = -503.508
final  value -503.508238 
converged
 
INFO  [03:59:42.074] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:59:42.128] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:59:42.135] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [03:59:46.832] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [03:59:51.713] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [03:59:56.443] [mlr3]  Finished benchmark 
INFO  [03:59:56.511] [bbotk] Result of batch 93: 
INFO  [03:59:56.512] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [03:59:56.512] [bbotk]              6.346433                  8.67941                      0.06616352 
INFO  [03:59:56.512] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [03:59:56.512] [bbotk]                     2451        0.821 -0.9455539         <NA>   0.9643506 
INFO  [03:59:56.512] [bbotk]                                 uhash 
INFO  [03:59:56.512] [bbotk]  901c7443-6763-4d4f-a422-d49b26db65e4 
DEBUG [03:59:57.469] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.227365e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.227365e-05 0.001298044 
  - best initial criterion value(s) :  427.1794 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -427.18  |proj g|=       7.6749
At iterate     1  f =         -473  |proj g|=        3.3757
At iterate     2  f =      -490.04  |proj g|=        1.7666
At iterate     3  f =      -490.88  |proj g|=         1.275
At iterate     4  f =      -490.89  |proj g|=        1.2323
At iterate     5  f =       -490.9  |proj g|=        1.2028
At iterate     6  f =      -490.95  |proj g|=        1.1175
At iterate     7  f =         -491  |proj g|=        1.0868
At iterate     8  f =      -491.02  |proj g|=        1.1047
At iterate     9  f =      -491.02  |proj g|=        1.1203
At iterate    10  f =      -491.02  |proj g|=        1.1236
At iterate    11  f =      -491.02  |proj g|=        1.1238

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.12381
final function value -491.022

F = -491.022
final  value -491.022191 
converged
 
INFO  [03:59:57.473] [bbotk] Evaluating 1 configuration(s) 
INFO  [03:59:57.528] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [03:59:57.535] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:00:03.414] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:00:13.848] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:00:22.102] [mlr3]  Finished benchmark 
INFO  [04:00:22.171] [bbotk] Result of batch 94: 
INFO  [04:00:22.173] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:00:22.173] [bbotk]              9.187959                 6.406377                       0.4126648 
INFO  [04:00:22.173] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:00:22.173] [bbotk]                     3012        0.699 -0.960163         <NA>   0.9723665 
INFO  [04:00:22.173] [bbotk]                                 uhash 
INFO  [04:00:22.173] [bbotk]  74e28e85-6fdb-4d38-9251-ab2cac7a583a 
DEBUG [04:00:23.302] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.221291e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.221291e-05 0.00129313 
  - best initial criterion value(s) :  465.4065 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -465.41  |proj g|=       4.6689
At iterate     1  f =      -479.98  |proj g|=        3.3418
At iterate     2  f =      -481.04  |proj g|=        3.2178
At iterate     3  f =      -482.38  |proj g|=        2.9071
At iterate     4  f =      -482.54  |proj g|=        2.7126
At iterate     5  f =      -482.61  |proj g|=        2.7544
At iterate     6  f =      -483.05  |proj g|=        2.9118
At iterate     7  f =      -483.92  |proj g|=        3.1409
At iterate     8  f =      -485.18  |proj g|=        3.4134
At iterate     9  f =      -486.26  |proj g|=        3.4264
At iterate    10  f =      -486.35  |proj g|=        3.4184
At iterate    11  f =      -486.35  |proj g|=        3.4242
At iterate    12  f =      -486.35  |proj g|=        3.4301
At iterate    13  f =      -486.35  |proj g|=        3.4301
At iterate    14  f =      -486.35  |proj g|=        3.4301
At iterate    15  f =      -486.35  |proj g|=        3.4301
At iterate    16  f =      -486.35  |proj g|=          3.43
At iterate    17  f =      -486.35  |proj g|=        3.4298
At iterate    18  f =      -486.35  |proj g|=        3.4296
At iterate    19  f =      -486.36  |proj g|=        3.4349
At iterate    20  f =      -486.37  |proj g|=        3.3852
At iterate    21  f =      -486.39  |proj g|=        3.4069
At iterate    22  f =      -486.56  |proj g|=         3.495
At iterate    23  f =      -486.91  |proj g|=        3.5877
At iterate    24  f =      -487.66  |proj g|=        3.6623
At iterate    25  f =      -488.93  |proj g|=        3.6021
At iterate    26  f =      -490.01  |proj g|=        3.1207
At iterate    27  f =      -490.22  |proj g|=        3.2051
At iterate    28  f =       -490.8  |proj g|=        2.9149
At iterate    29  f =       -491.5  |proj g|=        2.4151
At iterate    30  f =      -491.61  |proj g|=        2.4578
At iterate    31  f =      -491.61  |proj g|=        2.4897
At iterate    32  f =      -491.61  |proj g|=        2.4791
At iterate    33  f =      -491.61  |proj g|=        2.4806
At iterate    34  f =      -491.61  |proj g|=        2.4806

iterations 34
function evaluations 41
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.48061
final function value -491.614

F = -491.614
final  value -491.614377 
converged
 
INFO  [04:00:23.307] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:00:23.362] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:00:23.369] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:00:27.808] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:00:32.673] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:00:38.068] [mlr3]  Finished benchmark 
INFO  [04:00:38.135] [bbotk] Result of batch 95: 
INFO  [04:00:38.137] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:00:38.137] [bbotk]              4.278869                  2.29211                       0.1391721 
INFO  [04:00:38.137] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:00:38.137] [bbotk]                     1726        0.713 -0.9627226         <NA>   0.9652597 
INFO  [04:00:38.137] [bbotk]                                 uhash 
INFO  [04:00:38.137] [bbotk]  63e988dc-13fc-4f19-8d52-049be4eb8bbc 
DEBUG [04:00:39.359] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.211526e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.211526e-05 0.001283664 
  - best initial criterion value(s) :  459.9869 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -459.99  |proj g|=       3.3016
At iterate     1  f =      -473.29  |proj g|=        2.8462
At iterate     2  f =      -473.57  |proj g|=        2.6026
At iterate     3  f =      -474.31  |proj g|=        2.3178
At iterate     4  f =      -474.89  |proj g|=        2.2845
At iterate     5  f =      -480.59  |proj g|=        2.0398
At iterate     6  f =      -488.28  |proj g|=        1.9172
At iterate     7  f =      -492.36  |proj g|=        3.6763
At iterate     8  f =      -496.69  |proj g|=        3.9798
At iterate     9  f =      -496.93  |proj g|=        4.1212
At iterate    10  f =      -496.98  |proj g|=         4.234
At iterate    11  f =      -497.03  |proj g|=        4.4496
At iterate    12  f =      -497.03  |proj g|=        4.4417
At iterate    13  f =      -497.06  |proj g|=        4.4263
At iterate    14  f =      -497.17  |proj g|=        4.3763
At iterate    15  f =       -497.4  |proj g|=        4.2759
At iterate    16  f =      -497.87  |proj g|=        4.1237
At iterate    17  f =      -498.17  |proj g|=        3.1546
At iterate    18  f =      -498.78  |proj g|=        3.5625
At iterate    19  f =       -498.9  |proj g|=        3.6452
At iterate    20  f =      -498.93  |proj g|=        3.7204
At iterate    21  f =      -498.93  |proj g|=        3.7309
At iterate    22  f =      -498.93  |proj g|=        3.7297
At iterate    23  f =      -498.93  |proj g|=        3.7293
At iterate    24  f =      -498.93  |proj g|=        3.7289
At iterate    25  f =      -498.93  |proj g|=        3.7345
At iterate    26  f =      -498.93  |proj g|=        3.7552
At iterate    27  f =      -498.94  |proj g|=        3.7763
At iterate    28  f =      -498.96  |proj g|=        3.8182
At iterate    29  f =      -499.01  |proj g|=        3.8679
At iterate    30  f =      -499.11  |proj g|=        4.0621
At iterate    31  f =      -499.31  |proj g|=        4.0935
At iterate    32  f =      -501.81  |proj g|=        4.4607
At iterate    33  f =      -503.53  |proj g|=        4.0904
At iterate    34  f =      -504.26  |proj g|=         3.782
At iterate    35  f =      -504.63  |proj g|=        3.5356
At iterate    36  f =      -504.75  |proj g|=        3.4373
At iterate    37  f =      -504.94  |proj g|=        3.4548
At iterate    38  f =      -505.02  |proj g|=        3.5072
At iterate    39  f =      -505.39  |proj g|=        3.6143
At iterate    40  f =      -505.84  |proj g|=        3.5765
At iterate    41  f =      -507.13  |proj g|=         3.308
At iterate    42  f =      -509.24  |proj g|=        2.7786
At iterate    43  f =      -510.62  |proj g|=        2.3963
At iterate    44  f =      -512.34  |proj g|=        1.9166
At iterate    45  f =       -517.9  |proj g|=       0.92879
At iterate    46  f =       -518.8  |proj g|=       0.31039
At iterate    47  f =       -518.8  |proj g|=       0.16557
At iterate    48  f =       -518.8  |proj g|=       0.11976
At iterate    49  f =       -518.8  |proj g|=       0.11979

iterations 49
function evaluations 63
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.119786
final function value -518.799

F = -518.799
final  value -518.798864 
converged
 
INFO  [04:00:39.363] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:00:39.417] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:00:39.424] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:00:41.688] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:00:44.275] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:00:46.740] [mlr3]  Finished benchmark 
INFO  [04:00:46.810] [bbotk] Result of batch 96: 
INFO  [04:00:46.812] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:00:46.812] [bbotk]              8.324284                 3.777619                        0.135615 
INFO  [04:00:46.812] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:00:46.812] [bbotk]                      708        0.713 -0.9447037         <NA>    0.959641 
INFO  [04:00:46.812] [bbotk]                                 uhash 
INFO  [04:00:46.812] [bbotk]  c54eed02-ae75-48a3-93d2-73ab0daa3dfc 
DEBUG [04:00:47.912] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.204618e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.204618e-05 0.001278446 
  - best initial criterion value(s) :  468.9143 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -468.91  |proj g|=       6.3448
At iterate     1  f =      -491.84  |proj g|=        2.6816
At iterate     2  f =      -498.47  |proj g|=        5.9622
At iterate     3  f =       -498.7  |proj g|=         5.616
At iterate     4  f =      -498.73  |proj g|=        5.4481
At iterate     5  f =      -498.73  |proj g|=         5.447
At iterate     6  f =      -498.73  |proj g|=         5.438
At iterate     7  f =      -498.73  |proj g|=        5.4381
At iterate     8  f =      -498.73  |proj g|=        5.4388
At iterate     9  f =      -498.74  |proj g|=        5.4393
At iterate    10  f =      -498.74  |proj g|=        5.4341
At iterate    11  f =      -498.75  |proj g|=         5.456
At iterate    12  f =      -498.76  |proj g|=         5.448
At iterate    13  f =      -498.83  |proj g|=        5.3997
At iterate    14  f =      -498.96  |proj g|=        5.2975
At iterate    15  f =      -499.26  |proj g|=         5.069
At iterate    16  f =      -499.79  |proj g|=         4.373
At iterate    17  f =      -500.48  |proj g|=        4.0918
At iterate    18  f =      -501.23  |proj g|=        3.7211
At iterate    19  f =      -506.39  |proj g|=        2.3757
At iterate    20  f =      -512.44  |proj g|=        2.2161
At iterate    21  f =      -514.32  |proj g|=         3.125
At iterate    22  f =      -514.86  |proj g|=        2.7413
At iterate    23  f =      -514.99  |proj g|=        2.7268
At iterate    24  f =      -515.22  |proj g|=        2.8307
At iterate    25  f =      -515.22  |proj g|=        2.7827
At iterate    26  f =      -515.23  |proj g|=        2.8366
At iterate    27  f =      -515.23  |proj g|=         2.828
At iterate    28  f =      -515.23  |proj g|=        2.8278

iterations 28
function evaluations 33
segments explored during Cauchy searches 31
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.82781
final function value -515.228

F = -515.228
final  value -515.228075 
converged
 
INFO  [04:00:47.916] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:00:47.996] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:00:48.008] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:01:00.638] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:01:14.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:01:28.963] [mlr3]  Finished benchmark 
INFO  [04:01:29.038] [bbotk] Result of batch 97: 
INFO  [04:01:29.040] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:01:29.040] [bbotk]              9.310445                 2.741847                       0.1998146 
INFO  [04:01:29.040] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:01:29.040] [bbotk]                     4335        0.727 -0.9562777         <NA>   0.9722366 
INFO  [04:01:29.040] [bbotk]                                 uhash 
INFO  [04:01:29.040] [bbotk]  f916ba8a-85e4-480d-a309-c5d051d9f5cd 
DEBUG [04:01:30.315] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.198722e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.198722e-05 0.001275488 
  - best initial criterion value(s) :  497.1158 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -497.12  |proj g|=       2.5169
At iterate     1  f =      -499.21  |proj g|=        4.1114
At iterate     2  f =      -499.58  |proj g|=        3.8833
At iterate     3  f =      -499.66  |proj g|=        3.6404
At iterate     4  f =      -499.67  |proj g|=        3.6946
At iterate     5  f =      -499.69  |proj g|=        3.6212
At iterate     6  f =      -499.73  |proj g|=        3.3548
At iterate     7  f =      -499.73  |proj g|=        3.3687
At iterate     8  f =      -499.73  |proj g|=        3.3838
At iterate     9  f =      -499.73  |proj g|=        3.4006
At iterate    10  f =      -499.74  |proj g|=         3.431
At iterate    11  f =      -499.74  |proj g|=        3.4457
At iterate    12  f =      -499.74  |proj g|=        3.4796
At iterate    13  f =       -499.8  |proj g|=        3.5396
At iterate    14  f =      -500.36  |proj g|=         3.713
At iterate    15  f =      -502.72  |proj g|=        3.1243
At iterate    16  f =      -506.44  |proj g|=        1.5365
At iterate    17  f =      -506.76  |proj g|=        1.7826
At iterate    18  f =      -508.23  |proj g|=       0.79433
At iterate    19  f =      -508.79  |proj g|=       0.70929
At iterate    20  f =      -509.03  |proj g|=       0.72339
At iterate    21  f =      -509.13  |proj g|=       0.88219
At iterate    22  f =      -509.18  |proj g|=       0.80834
At iterate    23  f =      -509.18  |proj g|=       0.79893
At iterate    24  f =      -509.18  |proj g|=       0.80182
At iterate    25  f =      -509.18  |proj g|=        0.8022
At iterate    26  f =      -509.18  |proj g|=       0.80215

iterations 26
function evaluations 35
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.802153
final function value -509.182

F = -509.182
final  value -509.181723 
converged
 
INFO  [04:01:30.319] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:01:30.373] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:01:30.380] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:01:36.683] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:01:42.882] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:01:50.909] [mlr3]  Finished benchmark 
INFO  [04:01:51.002] [bbotk] Result of batch 98: 
INFO  [04:01:51.004] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:01:51.004] [bbotk]               4.42583                 8.439385                      0.04720236 
INFO  [04:01:51.004] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:01:51.004] [bbotk]                     1928        0.712 -0.9613819         <NA>   0.9545222 
INFO  [04:01:51.004] [bbotk]                                 uhash 
INFO  [04:01:51.004] [bbotk]  d5f3d47b-95ac-42cb-8164-e01af935ee4c 
DEBUG [04:01:52.177] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.19872e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.19872e-05 0.001272997 
  - best initial criterion value(s) :  486.3239 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -486.32  |proj g|=       5.6179
At iterate     1  f =      -508.29  |proj g|=        3.2745
At iterate     2  f =      -517.73  |proj g|=        4.7892
At iterate     3  f =      -518.23  |proj g|=        4.5576
At iterate     4  f =      -518.63  |proj g|=        4.1107
At iterate     5  f =      -518.64  |proj g|=        4.0646
At iterate     6  f =      -518.64  |proj g|=        4.0597
At iterate     7  f =      -518.64  |proj g|=         4.068
At iterate     8  f =      -518.64  |proj g|=        4.0756
At iterate     9  f =      -518.64  |proj g|=        4.0765
At iterate    10  f =      -518.64  |proj g|=        4.0827
At iterate    11  f =      -518.64  |proj g|=        4.0896
At iterate    12  f =      -518.64  |proj g|=         4.102
At iterate    13  f =      -518.64  |proj g|=        4.1195
At iterate    14  f =      -518.65  |proj g|=        4.1451
At iterate    15  f =      -518.67  |proj g|=        4.1769
At iterate    16  f =      -518.73  |proj g|=        4.2027
At iterate    17  f =      -518.87  |proj g|=        4.1741
At iterate    18  f =      -519.18  |proj g|=        3.9688
At iterate    19  f =      -519.77  |proj g|=        3.2974
At iterate    20  f =      -519.87  |proj g|=        2.9688
At iterate    21  f =      -519.87  |proj g|=        2.9291
At iterate    22  f =      -519.87  |proj g|=        2.9317
At iterate    23  f =      -519.87  |proj g|=        2.9354
At iterate    24  f =      -519.87  |proj g|=        2.9088
At iterate    25  f =      -519.88  |proj g|=        2.9254
At iterate    26  f =      -519.88  |proj g|=        2.9488
At iterate    27  f =      -519.89  |proj g|=        2.9857
At iterate    28  f =      -519.92  |proj g|=        3.0369
At iterate    29  f =      -519.98  |proj g|=        3.1131
At iterate    30  f =      -520.14  |proj g|=        3.2049
At iterate    31  f =       -520.5  |proj g|=        3.2819
At iterate    32  f =      -521.26  |proj g|=        3.2654
At iterate    33  f =      -522.73  |proj g|=        3.0157
At iterate    34  f =      -525.27  |proj g|=        2.1981
At iterate    35  f =      -525.45  |proj g|=         2.001
At iterate    36  f =      -525.47  |proj g|=        2.0214
At iterate    37  f =      -525.52  |proj g|=        1.8791
At iterate    38  f =      -525.86  |proj g|=        1.7572
At iterate    39  f =      -526.82  |proj g|=        1.5264
At iterate    40  f =      -529.29  |proj g|=        1.0618
At iterate    41  f =      -531.45  |proj g|=        1.3425
At iterate    42  f =      -531.51  |proj g|=        1.4388
At iterate    43  f =      -531.51  |proj g|=        1.3918
At iterate    44  f =      -531.51  |proj g|=        1.3878
At iterate    45  f =      -531.51  |proj g|=        1.3879

iterations 45
function evaluations 54
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.38791
final function value -531.514

F = -531.514
final  value -531.514429 
converged
 
INFO  [04:01:52.182] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:01:52.246] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:01:52.253] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:01:55.588] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:01:58.243] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:02:01.191] [mlr3]  Finished benchmark 
INFO  [04:02:01.260] [bbotk] Result of batch 99: 
INFO  [04:02:01.261] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:02:01.261] [bbotk]              3.146699                 2.946876                       0.4622421 
INFO  [04:02:01.261] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:02:01.261] [bbotk]                      867        0.719 -0.9571274         <NA>   0.9636009 
INFO  [04:02:01.261] [bbotk]                                 uhash 
INFO  [04:02:01.261] [bbotk]  4433e06b-e783-4af4-bf85-af54eee54499 
DEBUG [04:02:02.354] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.189684e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.189684e-05 0.001264368 
  - best initial criterion value(s) :  470.7572 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -470.76  |proj g|=       11.762
At iterate     1  f =      -511.05  |proj g|=        3.6955
At iterate     2  f =      -511.44  |proj g|=        3.5771
At iterate     3  f =      -512.33  |proj g|=        3.6648
At iterate     4  f =      -513.24  |proj g|=        4.0962
At iterate     5  f =      -513.57  |proj g|=        4.9806
At iterate     6  f =      -513.58  |proj g|=        4.8901
At iterate     7  f =      -513.59  |proj g|=        4.8758
At iterate     8  f =      -513.68  |proj g|=         4.844
At iterate     9  f =      -513.89  |proj g|=        4.7315
At iterate    10  f =      -514.48  |proj g|=        4.3447
At iterate    11  f =      -516.09  |proj g|=        3.4287
At iterate    12  f =      -520.39  |proj g|=         2.074
At iterate    13  f =      -520.46  |proj g|=        1.7509
At iterate    14  f =      -524.75  |proj g|=        2.8272
At iterate    15  f =      -525.84  |proj g|=        3.3446
At iterate    16  f =      -526.53  |proj g|=        3.6601
At iterate    17  f =      -526.54  |proj g|=        3.5782
At iterate    18  f =      -526.86  |proj g|=        3.6872
At iterate    19  f =      -526.91  |proj g|=        3.9062
At iterate    20  f =      -526.91  |proj g|=        3.8938
At iterate    21  f =      -526.91  |proj g|=        3.9195
At iterate    22  f =      -526.91  |proj g|=        3.9223
At iterate    23  f =      -526.91  |proj g|=        3.9214

iterations 23
function evaluations 31
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.92141
final function value -526.908

F = -526.908
final  value -526.908304 
converged
 
INFO  [04:02:02.358] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:02:02.414] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:02:02.421] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:02:08.066] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:02:13.029] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:02:18.306] [mlr3]  Finished benchmark 
INFO  [04:02:18.376] [bbotk] Result of batch 100: 
INFO  [04:02:18.378] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:02:18.378] [bbotk]              3.774722                  5.17572                       0.4130594 
INFO  [04:02:18.378] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:02:18.378] [bbotk]                     1620        0.722 -0.9610876         <NA>   0.9698781 
INFO  [04:02:18.378] [bbotk]                                 uhash 
INFO  [04:02:18.378] [bbotk]  7725a600-bd1a-4676-a5d0-e65d6313243b 
DEBUG [04:02:19.652] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.182054e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.35399 0.9788035 9540 
  - variance bounds :  1.182054e-05 0.001251775 
  - best initial criterion value(s) :  501.3635 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -501.36  |proj g|=       4.7924
At iterate     1  f =       -514.2  |proj g|=        6.2002
At iterate     2  f =      -521.38  |proj g|=        5.3497
At iterate     3  f =      -530.71  |proj g|=        2.9891
At iterate     4  f =      -531.41  |proj g|=        1.7777
At iterate     5  f =      -532.19  |proj g|=        2.0563
At iterate     6  f =      -535.37  |proj g|=        2.1323
At iterate     7  f =      -539.12  |proj g|=        1.4397
At iterate     8  f =       -540.9  |proj g|=        1.3802
At iterate     9  f =       -541.4  |proj g|=       0.99942
At iterate    10  f =      -541.48  |proj g|=       0.89918
At iterate    11  f =       -541.5  |proj g|=        1.0222
At iterate    12  f =      -541.51  |proj g|=       0.95448
At iterate    13  f =      -541.52  |proj g|=        0.9508
At iterate    14  f =      -541.52  |proj g|=       0.95103
At iterate    15  f =      -541.52  |proj g|=       0.95351
At iterate    16  f =      -541.53  |proj g|=       0.95575
At iterate    17  f =      -541.55  |proj g|=       0.94386
At iterate    18  f =      -541.59  |proj g|=       0.99619
At iterate    19  f =      -541.66  |proj g|=       0.94707
At iterate    20  f =      -541.75  |proj g|=        1.0732
At iterate    21  f =      -542.08  |proj g|=        1.0207
At iterate    22  f =       -542.4  |proj g|=       0.94559
At iterate    23  f =      -543.36  |proj g|=        0.7897
At iterate    24  f =      -544.48  |proj g|=       0.89444
At iterate    25  f =      -545.86  |proj g|=       0.93337
At iterate    26  f =      -545.87  |proj g|=       0.97249
At iterate    27  f =      -545.87  |proj g|=       0.97034
At iterate    28  f =      -545.87  |proj g|=       0.97149
At iterate    29  f =      -545.87  |proj g|=       0.97263
At iterate    30  f =       -545.9  |proj g|=        1.0091
At iterate    31  f =      -545.92  |proj g|=       0.99979
At iterate    32  f =      -545.92  |proj g|=       0.99921
At iterate    33  f =      -545.92  |proj g|=       0.99929
At iterate    34  f =      -545.92  |proj g|=        0.9993
At iterate    35  f =      -545.92  |proj g|=        1.0012
At iterate    36  f =      -545.92  |proj g|=       0.99985
At iterate    37  f =      -545.92  |proj g|=       0.99864
At iterate    38  f =      -545.92  |proj g|=        0.9952
At iterate    39  f =      -545.92  |proj g|=       0.99047
At iterate    40  f =      -545.92  |proj g|=       0.98239
At iterate    41  f =      -545.93  |proj g|=       0.96934
At iterate    42  f =      -545.94  |proj g|=       0.94714
At iterate    43  f =      -545.97  |proj g|=       0.90964
At iterate    44  f =      -546.05  |proj g|=       0.82961
At iterate    45  f =      -546.26  |proj g|=       0.42579
At iterate    46  f =      -546.61  |proj g|=       0.44365
At iterate    47  f =      -546.78  |proj g|=       0.74246
At iterate    48  f =      -546.79  |proj g|=       0.74152
At iterate    49  f =      -546.89  |proj g|=       0.24859
At iterate    50  f =      -546.92  |proj g|=       0.25388
At iterate    51  f =      -546.93  |proj g|=       0.25593
At iterate    52  f =      -546.93  |proj g|=       0.19176
At iterate    53  f =      -546.93  |proj g|=      0.086343
At iterate    54  f =      -546.93  |proj g|=      0.086419

iterations 54
function evaluations 63
segments explored during Cauchy searches 57
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0864189
final function value -546.93

F = -546.93
final  value -546.930176 
converged
 
INFO  [04:02:19.656] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:02:19.715] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:02:19.722] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:02:21.641] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:02:23.742] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:02:25.462] [mlr3]  Finished benchmark 
INFO  [04:02:25.532] [bbotk] Result of batch 101: 
INFO  [04:02:25.534] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:02:25.534] [bbotk]              7.158305                 2.087699                      0.09236835 
INFO  [04:02:25.534] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:02:25.534] [bbotk]                      514        0.738 -0.9485337         <NA>   0.9505799 
INFO  [04:02:25.534] [bbotk]                                 uhash 
INFO  [04:02:25.534] [bbotk]  93d62194-3090-4097-b566-c35a0ba7839e 
DEBUG [04:02:26.788] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.189776e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.189776e-05 0.001266719 
  - best initial criterion value(s) :  487.9222 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -487.92  |proj g|=       12.781
At iterate     1  f =      -506.24  |proj g|=        6.6107
At iterate     2  f =      -509.47  |proj g|=        4.9251
At iterate     3  f =      -511.55  |proj g|=        2.5582
At iterate     4  f =      -511.84  |proj g|=        2.8224
At iterate     5  f =      -511.88  |proj g|=        2.7749
At iterate     6  f =      -511.89  |proj g|=        2.7588
At iterate     7  f =      -511.89  |proj g|=        2.7654
At iterate     8  f =      -511.89  |proj g|=        2.7655
At iterate     9  f =       -511.9  |proj g|=        2.7655
At iterate    10  f =      -511.92  |proj g|=         2.771
At iterate    11  f =      -511.98  |proj g|=        2.7694
At iterate    12  f =      -512.01  |proj g|=        2.8303
At iterate    13  f =      -512.17  |proj g|=         2.813
At iterate    14  f =      -513.25  |proj g|=        2.7793
At iterate    15  f =      -524.07  |proj g|=         2.589
At iterate    16  f =      -534.57  |proj g|=        1.9441
At iterate    17  f =      -536.83  |proj g|=        1.6161
At iterate    18  f =      -538.14  |proj g|=        2.3011
At iterate    19  f =      -538.14  |proj g|=         2.286
At iterate    20  f =      -538.14  |proj g|=        2.2774
At iterate    21  f =      -538.14  |proj g|=        2.2855
At iterate    22  f =      -538.14  |proj g|=        2.2811
At iterate    23  f =      -538.15  |proj g|=         2.262
At iterate    24  f =      -538.16  |proj g|=        2.2375
At iterate    25  f =      -538.22  |proj g|=         2.164
At iterate    26  f =      -538.35  |proj g|=        2.0669
At iterate    27  f =       -538.7  |proj g|=        1.9023
At iterate    28  f =      -539.41  |proj g|=        1.7037
At iterate    29  f =      -540.47  |proj g|=        1.6138
At iterate    30  f =      -541.22  |proj g|=        1.8692
At iterate    31  f =      -541.22  |proj g|=        1.8569
At iterate    32  f =      -541.22  |proj g|=        1.8521
At iterate    33  f =      -541.22  |proj g|=        1.8518
At iterate    34  f =      -541.22  |proj g|=        1.8506
At iterate    35  f =      -541.22  |proj g|=        1.8487
At iterate    36  f =      -541.22  |proj g|=        1.8457
At iterate    37  f =      -541.22  |proj g|=        1.8406
At iterate    38  f =      -541.22  |proj g|=        1.8324
At iterate    39  f =      -541.22  |proj g|=        1.8192
At iterate    40  f =      -541.23  |proj g|=        1.7972
At iterate    41  f =      -541.24  |proj g|=        1.7607
At iterate    42  f =      -541.26  |proj g|=        1.6989
At iterate    43  f =      -541.34  |proj g|=        1.5928
At iterate    44  f =      -541.51  |proj g|=        1.4118
At iterate    45  f =      -541.93  |proj g|=        1.1197
At iterate    46  f =      -542.94  |proj g|=        0.7191
At iterate    47  f =      -545.71  |proj g|=       0.68113
At iterate    48  f =      -547.06  |proj g|=       0.49103
At iterate    49  f =      -548.07  |proj g|=       0.73478
At iterate    50  f =      -548.08  |proj g|=        0.2481
At iterate    51  f =      -548.08  |proj g|=      0.096459
At iterate    52  f =      -548.08  |proj g|=      0.096413

iterations 52
function evaluations 60
segments explored during Cauchy searches 55
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.0964128
final function value -548.082

F = -548.082
final  value -548.082182 
converged
 
INFO  [04:02:26.792] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:02:26.851] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:02:26.858] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:02:28.682] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:02:30.768] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:02:32.687] [mlr3]  Finished benchmark 
INFO  [04:02:32.927] [bbotk] Result of batch 102: 
INFO  [04:02:32.929] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:02:32.929] [bbotk]              5.461873                 5.019471                      0.05743076 
INFO  [04:02:32.929] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:02:32.929] [bbotk]                      577        0.739 -0.9463651         <NA>   0.9423366 
INFO  [04:02:32.929] [bbotk]                                 uhash 
INFO  [04:02:32.929] [bbotk]  fc1ea83d-14e0-46a9-819c-1e43abe5f4db 
DEBUG [04:02:34.356] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.220529e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.220529e-05 0.001311554 
  - best initial criterion value(s) :  498.0962 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -498.1  |proj g|=       3.0184
At iterate     1  f =      -522.49  |proj g|=       0.27629
At iterate     2  f =      -539.78  |proj g|=        4.8271
At iterate     3  f =      -540.53  |proj g|=        4.6946
At iterate     4  f =      -541.97  |proj g|=        4.1638
At iterate     5  f =      -542.12  |proj g|=        4.0228
At iterate     6  f =      -542.17  |proj g|=        4.0046
At iterate     7  f =      -542.25  |proj g|=        4.3718
At iterate     8  f =      -542.26  |proj g|=        4.3374
At iterate     9  f =      -542.26  |proj g|=        4.3446
At iterate    10  f =      -542.26  |proj g|=        4.3475
At iterate    11  f =      -542.26  |proj g|=         4.349
At iterate    12  f =      -542.26  |proj g|=        4.3519
At iterate    13  f =      -542.26  |proj g|=        4.3553
At iterate    14  f =      -542.26  |proj g|=        4.3614
At iterate    15  f =      -542.27  |proj g|=        4.3691
At iterate    16  f =      -542.27  |proj g|=        4.3758
At iterate    17  f =      -542.27  |proj g|=        4.3805
At iterate    18  f =      -542.28  |proj g|=        4.4122
At iterate    19  f =       -542.3  |proj g|=        4.4005
At iterate    20  f =       -542.3  |proj g|=        4.4799
At iterate    21  f =      -542.36  |proj g|=        4.4256
At iterate    22  f =      -542.83  |proj g|=        4.1856
At iterate    23  f =      -546.34  |proj g|=        2.6343
At iterate    24  f =      -547.98  |proj g|=        2.1734
At iterate    25  f =      -549.16  |proj g|=        2.3291
At iterate    26  f =      -549.25  |proj g|=        2.0674
At iterate    27  f =      -549.36  |proj g|=        2.0215
At iterate    28  f =      -549.41  |proj g|=        2.0299
At iterate    29  f =      -549.41  |proj g|=        2.0231
At iterate    30  f =      -549.41  |proj g|=        2.0234
At iterate    31  f =      -549.42  |proj g|=        2.0372
At iterate    32  f =      -549.43  |proj g|=          1.96
At iterate    33  f =      -549.48  |proj g|=         2.026
At iterate    34  f =      -549.63  |proj g|=        2.0904
At iterate    35  f =      -550.15  |proj g|=        2.0712
At iterate    36  f =      -551.15  |proj g|=        1.7729
At iterate    37  f =      -553.57  |proj g|=        1.0302
At iterate    38  f =      -553.74  |proj g|=       0.74655
At iterate    39  f =      -554.85  |proj g|=       0.70268
At iterate    40  f =      -554.85  |proj g|=       0.70704
At iterate    41  f =      -555.05  |proj g|=       0.70602
At iterate    42  f =      -555.07  |proj g|=       0.27658
At iterate    43  f =      -555.07  |proj g|=      0.055026
At iterate    44  f =      -555.07  |proj g|=      0.086091

iterations 44
function evaluations 57
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0860909
final function value -555.068

F = -555.068
final  value -555.067514 
converged
 
INFO  [04:02:34.360] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:02:34.416] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:02:34.423] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:02:39.286] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:02:43.966] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:02:49.693] [mlr3]  Finished benchmark 
INFO  [04:02:49.769] [bbotk] Result of batch 103: 
INFO  [04:02:49.771] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:02:49.771] [bbotk]              2.302823                  8.62279                       0.2430573 
INFO  [04:02:49.771] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:02:49.771] [bbotk]                     1578        0.909 -0.9475181         <NA>   0.9523828 
INFO  [04:02:49.771] [bbotk]                                 uhash 
INFO  [04:02:49.771] [bbotk]  7f616314-7880-424d-85cd-5d7bff37b9dc 
DEBUG [04:02:50.931] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.223539e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.223539e-05 0.001314227 
  - best initial criterion value(s) :  521.1785 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -521.18  |proj g|=       6.8053
At iterate     1  f =      -526.16  |proj g|=        4.8375
At iterate     2  f =       -529.2  |proj g|=        5.0091
At iterate     3  f =      -530.25  |proj g|=        4.7058
At iterate     4  f =      -530.71  |proj g|=        4.5146
At iterate     5  f =      -530.85  |proj g|=         4.481
At iterate     6  f =      -530.89  |proj g|=        4.5205
At iterate     7  f =       -530.9  |proj g|=        4.6023
At iterate     8  f =       -530.9  |proj g|=        4.5868
At iterate     9  f =      -531.36  |proj g|=         4.689
At iterate    10  f =      -535.71  |proj g|=        4.5607
At iterate    11  f =      -541.19  |proj g|=        3.5051
At iterate    12  f =       -549.7  |proj g|=        1.3534
At iterate    13  f =      -554.11  |proj g|=        1.5214
At iterate    14  f =      -555.98  |proj g|=        1.0869
At iterate    15  f =      -556.23  |proj g|=       0.98536
At iterate    16  f =       -556.3  |proj g|=       0.87747
At iterate    17  f =       -556.3  |proj g|=       0.87564
At iterate    18  f =       -556.3  |proj g|=       0.87626
At iterate    19  f =       -556.3  |proj g|=       0.87565
At iterate    20  f =       -556.3  |proj g|=       0.87605
At iterate    21  f =       -556.3  |proj g|=       0.87727
At iterate    22  f =       -556.3  |proj g|=       0.88107
At iterate    23  f =      -556.31  |proj g|=       0.88746
At iterate    24  f =      -556.31  |proj g|=       0.89766
At iterate    25  f =      -556.31  |proj g|=       0.91347
At iterate    26  f =      -556.33  |proj g|=       0.93507
At iterate    27  f =      -556.35  |proj g|=       0.95488
At iterate    28  f =      -556.38  |proj g|=       0.93991
At iterate    29  f =      -556.39  |proj g|=       0.91073
At iterate    30  f =      -556.39  |proj g|=       0.90845
At iterate    31  f =      -556.39  |proj g|=       0.90814
At iterate    32  f =      -556.39  |proj g|=        0.9081

iterations 32
function evaluations 39
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.908096
final function value -556.39

F = -556.39
final  value -556.389787 
converged
 
INFO  [04:02:50.935] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:02:50.992] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:02:50.999] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:02:58.104] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:03:04.366] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:03:09.660] [mlr3]  Finished benchmark 
INFO  [04:03:09.729] [bbotk] Result of batch 104: 
INFO  [04:03:09.731] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:03:09.731] [bbotk]              2.390969                 9.837377                        0.242106 
INFO  [04:03:09.731] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:03:09.731] [bbotk]                     1955        0.744 -0.951979         <NA>   0.9554419 
INFO  [04:03:09.731] [bbotk]                                 uhash 
INFO  [04:03:09.731] [bbotk]  b6548ee4-5e95-4ce9-b670-01bb1638c811 
DEBUG [04:03:11.080] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.221269e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.221269e-05 0.001310812 
  - best initial criterion value(s) :  479.6511 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -479.65  |proj g|=       3.9122
At iterate     1  f =      -534.59  |proj g|=        3.2331
At iterate     2  f =      -536.58  |proj g|=        3.7202
At iterate     3  f =      -550.55  |proj g|=        3.0337
At iterate     4  f =      -554.75  |proj g|=          1.62
At iterate     5  f =      -554.94  |proj g|=        1.9118
At iterate     6  f =         -555  |proj g|=        1.8662
At iterate     7  f =      -555.21  |proj g|=        1.7037
At iterate     8  f =      -555.35  |proj g|=        1.6965
At iterate     9  f =      -555.42  |proj g|=        1.8314
At iterate    10  f =      -555.43  |proj g|=        1.8045
At iterate    11  f =      -555.43  |proj g|=        1.8057
At iterate    12  f =      -555.43  |proj g|=         1.806
At iterate    13  f =      -555.43  |proj g|=        1.8085
At iterate    14  f =      -555.43  |proj g|=        1.8117
At iterate    15  f =      -555.43  |proj g|=        1.8172
At iterate    16  f =      -555.43  |proj g|=        1.8257
At iterate    17  f =      -555.43  |proj g|=        1.8398
At iterate    18  f =      -555.44  |proj g|=        1.8617
At iterate    19  f =      -555.46  |proj g|=        1.8939
At iterate    20  f =      -555.49  |proj g|=        1.9282
At iterate    21  f =      -555.54  |proj g|=        1.9256
At iterate    22  f =      -555.56  |proj g|=        1.8866
At iterate    23  f =      -555.57  |proj g|=        1.8558
At iterate    24  f =      -555.57  |proj g|=        1.8426
At iterate    25  f =      -555.58  |proj g|=        1.8205
At iterate    26  f =       -555.6  |proj g|=         1.786
At iterate    27  f =      -555.64  |proj g|=         1.735
At iterate    28  f =      -555.75  |proj g|=        1.6644
At iterate    29  f =      -555.96  |proj g|=        1.6025
At iterate    30  f =      -556.22  |proj g|=        1.5908
At iterate    31  f =      -556.51  |proj g|=        1.5825
At iterate    32  f =      -556.64  |proj g|=        1.8203
At iterate    33  f =      -556.93  |proj g|=        1.8032
At iterate    34  f =       -557.2  |proj g|=        1.8578
At iterate    35  f =      -557.47  |proj g|=        2.0745
At iterate    36  f =      -557.53  |proj g|=        1.9815
At iterate    37  f =      -557.53  |proj g|=        1.9803
At iterate    38  f =      -557.53  |proj g|=        1.9776
At iterate    39  f =      -557.53  |proj g|=         1.979
At iterate    40  f =      -557.53  |proj g|=        1.9789

iterations 40
function evaluations 45
segments explored during Cauchy searches 43
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.97891
final function value -557.53

F = -557.53
final  value -557.530069 
converged
 
INFO  [04:03:11.084] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:03:11.158] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:03:11.164] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:03:21.359] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:03:30.072] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:03:39.286] [mlr3]  Finished benchmark 
INFO  [04:03:39.363] [bbotk] Result of batch 105: 
INFO  [04:03:39.365] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:03:39.365] [bbotk]              3.428399                 8.398865                       0.3186632 
INFO  [04:03:39.365] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:03:39.365] [bbotk]                     4554         0.88 -0.9494641         <NA>   0.9717804 
INFO  [04:03:39.365] [bbotk]                                 uhash 
INFO  [04:03:39.365] [bbotk]  44ec74e0-d8cd-4050-9bb8-1613e0824ca4 
DEBUG [04:03:40.728] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.215608e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.215608e-05 0.001307302 
  - best initial criterion value(s) :  496.9648 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -496.96  |proj g|=        12.16
At iterate     1  f =      -544.25  |proj g|=        6.4436
At iterate     2  f =      -545.98  |proj g|=        5.5011
At iterate     3  f =      -547.16  |proj g|=        4.0586
At iterate     4  f =      -548.72  |proj g|=        3.0004
At iterate     5  f =      -548.78  |proj g|=        2.6448
At iterate     6  f =      -548.78  |proj g|=        2.6531
At iterate     7  f =      -548.78  |proj g|=        2.6685
At iterate     8  f =      -548.79  |proj g|=        2.6887
At iterate     9  f =      -548.79  |proj g|=        2.7221
At iterate    10  f =      -548.81  |proj g|=        2.7712
At iterate    11  f =      -548.85  |proj g|=        2.8429
At iterate    12  f =      -548.97  |proj g|=        2.9335
At iterate    13  f =      -549.26  |proj g|=        3.0134
At iterate    14  f =      -550.05  |proj g|=        2.9611
At iterate    15  f =      -552.07  |proj g|=         2.808
At iterate    16  f =      -558.58  |proj g|=        2.3788
At iterate    17  f =      -559.69  |proj g|=        2.3018
At iterate    18  f =      -560.17  |proj g|=        2.2703
At iterate    19  f =       -560.2  |proj g|=        2.1454
At iterate    20  f =      -560.24  |proj g|=        2.2217
At iterate    21  f =      -560.25  |proj g|=          2.28
At iterate    22  f =      -560.25  |proj g|=        2.2857
At iterate    23  f =      -560.25  |proj g|=        2.2794
At iterate    24  f =      -560.25  |proj g|=        2.2829
At iterate    25  f =      -560.25  |proj g|=        2.2965
At iterate    26  f =      -560.26  |proj g|=        2.3179
At iterate    27  f =      -560.29  |proj g|=        2.3663
At iterate    28  f =      -560.35  |proj g|=        2.4274
At iterate    29  f =      -560.51  |proj g|=        2.5048
At iterate    30  f =      -560.82  |proj g|=        2.5629
At iterate    31  f =      -561.26  |proj g|=         2.484
At iterate    32  f =      -561.75  |proj g|=        2.1861
At iterate    33  f =      -561.81  |proj g|=        2.0975
At iterate    34  f =      -561.82  |proj g|=        2.0231
At iterate    35  f =      -561.82  |proj g|=        2.0216
At iterate    36  f =      -561.82  |proj g|=        2.0214

iterations 36
function evaluations 42
segments explored during Cauchy searches 39
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 2.02142
final function value -561.819

F = -561.819
final  value -561.819074 
converged
 
INFO  [04:03:40.732] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:03:40.792] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:03:40.800] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:03:49.487] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:03:58.257] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:04:07.170] [mlr3]  Finished benchmark 
INFO  [04:04:07.239] [bbotk] Result of batch 106: 
INFO  [04:04:07.241] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:04:07.241] [bbotk]              3.948615                 6.059631                        0.147851 
INFO  [04:04:07.241] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:04:07.241] [bbotk]                     4288        0.876 -0.9474983         <NA>   0.9702101 
INFO  [04:04:07.241] [bbotk]                                 uhash 
INFO  [04:04:07.241] [bbotk]  1729127d-5a69-4f9a-b617-104b9da2e17d 
DEBUG [04:04:08.566] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.208618e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.208618e-05 0.001301086 
  - best initial criterion value(s) :  502.6802 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -502.68  |proj g|=       7.7411
At iterate     1  f =      -508.69  |proj g|=        3.1502
At iterate     2  f =      -537.86  |proj g|=        1.7494
At iterate     3  f =      -538.62  |proj g|=        2.2558
At iterate     4  f =      -538.75  |proj g|=        2.3152
At iterate     5  f =      -539.87  |proj g|=         2.542
At iterate     6  f =      -540.52  |proj g|=        2.4047
At iterate     7  f =      -540.79  |proj g|=         2.125
At iterate     8  f =      -540.81  |proj g|=        2.0533
At iterate     9  f =      -540.81  |proj g|=        2.0399
At iterate    10  f =      -540.81  |proj g|=        2.0313
At iterate    11  f =      -540.81  |proj g|=        2.0358
At iterate    12  f =      -540.96  |proj g|=        2.1397
At iterate    13  f =      -541.59  |proj g|=        2.3296
At iterate    14  f =       -543.4  |proj g|=        2.5455
At iterate    15  f =      -546.62  |proj g|=        2.4745
At iterate    16  f =      -549.63  |proj g|=        2.0898
At iterate    17  f =         -551  |proj g|=        1.7144
At iterate    18  f =      -551.55  |proj g|=        1.4182
At iterate    19  f =       -551.7  |proj g|=         1.414
At iterate    20  f =      -551.71  |proj g|=        1.4563
At iterate    21  f =      -551.71  |proj g|=        1.4779
At iterate    22  f =      -551.71  |proj g|=        1.4706
At iterate    23  f =      -551.71  |proj g|=        1.4706

iterations 23
function evaluations 31
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.4706
final function value -551.714

F = -551.714
final  value -551.714269 
converged
 
INFO  [04:04:08.570] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:04:08.627] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:04:08.634] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:04:13.403] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:04:17.920] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:04:22.239] [mlr3]  Finished benchmark 
INFO  [04:04:22.326] [bbotk] Result of batch 107: 
INFO  [04:04:22.328] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:04:22.328] [bbotk]               7.09784                 4.165084                       0.1497652 
INFO  [04:04:22.328] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:04:22.328] [bbotk]                     2503        0.873 -0.9578246         <NA>   0.9709224 
INFO  [04:04:22.328] [bbotk]                                 uhash 
INFO  [04:04:22.328] [bbotk]  9632d93f-34dc-4daa-b9e1-361bcfced3ec 
DEBUG [04:04:23.369] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.202267e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.202267e-05 0.001295229 
  - best initial criterion value(s) :  544.3372 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -544.34  |proj g|=      0.65673
At iterate     1  f =      -557.67  |proj g|=        5.7651
At iterate     2  f =      -558.26  |proj g|=        5.5171
At iterate     3  f =       -558.7  |proj g|=        4.6275
At iterate     4  f =       -558.8  |proj g|=        4.9754
At iterate     5  f =       -558.8  |proj g|=        4.9185
At iterate     6  f =       -558.8  |proj g|=        4.9128
At iterate     7  f =       -558.8  |proj g|=         4.911
At iterate     8  f =       -558.8  |proj g|=        4.9071
At iterate     9  f =       -558.8  |proj g|=        4.9092
At iterate    10  f =       -558.8  |proj g|=        4.9235
At iterate    11  f =       -558.8  |proj g|=        4.9484
At iterate    12  f =       -558.8  |proj g|=        4.9476
At iterate    13  f =       -558.8  |proj g|=        4.9476

iterations 13
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.9476
final function value -558.804

F = -558.804
final  value -558.803726 
converged
 
INFO  [04:04:23.373] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:04:23.428] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:04:23.434] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:04:29.546] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:04:36.063] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:04:44.927] [mlr3]  Finished benchmark 
INFO  [04:04:44.995] [bbotk] Result of batch 108: 
INFO  [04:04:44.997] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:04:44.997] [bbotk]              8.549474                  8.17796                       0.1328697 
INFO  [04:04:44.997] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:04:44.997] [bbotk]                     3287        0.747  -0.96257         <NA>   0.9716496 
INFO  [04:04:44.997] [bbotk]                                 uhash 
INFO  [04:04:44.997] [bbotk]  f23c1f96-40f3-414d-bcdd-e0c027982e15 
DEBUG [04:04:46.289] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.196617e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.196617e-05 0.001288743 
  - best initial criterion value(s) :  553.1351 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -553.14  |proj g|=       4.8236
At iterate     1  f =      -563.67  |proj g|=        1.3474
At iterate     2  f =       -566.2  |proj g|=        1.1481
At iterate     3  f =      -567.53  |proj g|=        2.1317
At iterate     4  f =       -567.9  |proj g|=        1.7246
At iterate     5  f =      -568.46  |proj g|=        1.6371
At iterate     6  f =      -569.73  |proj g|=        1.4208
At iterate     7  f =      -569.81  |proj g|=         1.107
At iterate     8  f =      -569.85  |proj g|=        1.1658
At iterate     9  f =      -569.87  |proj g|=         1.266
At iterate    10  f =      -569.87  |proj g|=         1.257
At iterate    11  f =      -569.87  |proj g|=        1.2585
At iterate    12  f =      -569.87  |proj g|=        1.2578
At iterate    13  f =      -569.87  |proj g|=        1.2565
At iterate    14  f =      -569.87  |proj g|=        1.2459
At iterate    15  f =      -569.88  |proj g|=        1.2337
At iterate    16  f =      -569.88  |proj g|=        1.2101
At iterate    17  f =      -569.89  |proj g|=        1.1732
At iterate    18  f =      -569.92  |proj g|=        1.1117
At iterate    19  f =         -570  |proj g|=        1.0165
At iterate    20  f =      -570.16  |proj g|=       0.96142
At iterate    21  f =      -570.43  |proj g|=       0.90563
At iterate    22  f =      -570.57  |proj g|=        0.9404
At iterate    23  f =      -570.57  |proj g|=       0.94868
At iterate    24  f =      -570.57  |proj g|=       0.94703
At iterate    25  f =      -570.57  |proj g|=       0.94681

iterations 25
function evaluations 28
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.946805
final function value -570.575

F = -570.575
final  value -570.574888 
converged
 
INFO  [04:04:46.293] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:04:46.350] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:04:46.357] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:04:51.449] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:04:56.273] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:05:00.887] [mlr3]  Finished benchmark 
INFO  [04:05:00.955] [bbotk] Result of batch 109: 
INFO  [04:05:00.957] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:05:00.957] [bbotk]              2.869071                 7.743487                       0.4697092 
INFO  [04:05:00.957] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:05:00.957] [bbotk]                     1509        0.911 -0.9557166         <NA>   0.9644102 
INFO  [04:05:00.957] [bbotk]                                 uhash 
INFO  [04:05:00.957] [bbotk]  9a52f610-6a6a-46ac-b19b-25680e5df037 
DEBUG [04:05:02.061] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.18805e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.18805e-05 0.001278959 
  - best initial criterion value(s) :  548.6865 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -548.69  |proj g|=       5.3097
At iterate     1  f =      -568.53  |proj g|=        2.5239
At iterate     2  f =      -583.09  |proj g|=        2.5543
At iterate     3  f =         -587  |proj g|=        1.5288
At iterate     4  f =      -587.06  |proj g|=        1.6454
At iterate     5  f =      -587.07  |proj g|=          1.67
At iterate     6  f =      -587.08  |proj g|=          1.68
At iterate     7  f =      -587.09  |proj g|=        1.6305
At iterate     8  f =      -587.09  |proj g|=        1.6398
At iterate     9  f =       -587.1  |proj g|=        1.6413
At iterate    10  f =       -587.1  |proj g|=        1.6438
At iterate    11  f =      -587.11  |proj g|=        1.6492
At iterate    12  f =      -587.15  |proj g|=         1.658
At iterate    13  f =      -587.22  |proj g|=        1.6292
At iterate    14  f =      -587.25  |proj g|=        1.7915
At iterate    15  f =       -587.4  |proj g|=        1.7088
At iterate    16  f =      -587.67  |proj g|=        1.6129
At iterate    17  f =      -588.04  |proj g|=         1.556
At iterate    18  f =      -588.38  |proj g|=        1.6366
At iterate    19  f =      -588.39  |proj g|=        1.7068
At iterate    20  f =      -588.42  |proj g|=        1.7174
At iterate    21  f =      -588.42  |proj g|=         1.718
At iterate    22  f =      -588.42  |proj g|=        1.7171
At iterate    23  f =      -588.42  |proj g|=         1.717

iterations 23
function evaluations 30
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.71703
final function value -588.416

F = -588.416
final  value -588.416295 
converged
 
INFO  [04:05:02.065] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:05:02.123] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:05:02.131] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:05:16.096] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:05:29.937] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:05:41.467] [mlr3]  Finished benchmark 
INFO  [04:05:41.536] [bbotk] Result of batch 110: 
INFO  [04:05:41.538] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:05:41.538] [bbotk]              6.554627                 6.948203                       0.1802185 
INFO  [04:05:41.538] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:05:41.538] [bbotk]                     3787        0.737 -0.9497352         <NA>   0.9732576 
INFO  [04:05:41.538] [bbotk]                                 uhash 
INFO  [04:05:41.538] [bbotk]  020409be-8039-4e00-962b-c50a9333e12c 
DEBUG [04:05:42.738] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.184207e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.184207e-05 0.001277353 
  - best initial criterion value(s) :  542.1086 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -542.11  |proj g|=       1.5447
At iterate     1  f =      -546.69  |proj g|=        1.2352
At iterate     2  f =      -547.02  |proj g|=         1.504
At iterate     3  f =      -547.06  |proj g|=         1.455
At iterate     4  f =      -547.06  |proj g|=        1.4403
At iterate     5  f =      -547.06  |proj g|=        1.4417
At iterate     6  f =      -547.06  |proj g|=        1.4417

iterations 6
function evaluations 10
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.44166
final function value -547.057

F = -547.057
final  value -547.057339 
converged
 
INFO  [04:05:42.742] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:05:42.798] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:05:42.805] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:05:47.698] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:05:51.850] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:05:55.128] [mlr3]  Finished benchmark 
INFO  [04:05:55.199] [bbotk] Result of batch 111: 
INFO  [04:05:55.201] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:05:55.201] [bbotk]              7.505799                 9.479473                      0.05925582 
INFO  [04:05:55.201] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:05:55.201] [bbotk]                     1588        0.922 -0.9656568         <NA>   0.9589536 
INFO  [04:05:55.201] [bbotk]                                 uhash 
INFO  [04:05:55.201] [bbotk]  6f7232c6-75e6-4aa1-9db0-0302195d9cc5 
DEBUG [04:05:56.574] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.178577e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.178577e-05 0.001271124 
  - best initial criterion value(s) :  565.8356 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -565.84  |proj g|=       2.0009
At iterate     1  f =      -568.66  |proj g|=        5.7498
At iterate     2  f =       -571.8  |proj g|=        5.3326
At iterate     3  f =      -574.29  |proj g|=        4.3891
At iterate     4  f =      -574.71  |proj g|=        3.8812
At iterate     5  f =      -575.43  |proj g|=        3.6242
At iterate     6  f =      -576.97  |proj g|=        2.9101
At iterate     7  f =      -577.26  |proj g|=        3.1096
At iterate     8  f =      -577.29  |proj g|=        2.9861
At iterate     9  f =      -577.29  |proj g|=        2.9728
At iterate    10  f =      -577.29  |proj g|=        2.9711
At iterate    11  f =      -577.29  |proj g|=        2.9718
At iterate    12  f =      -577.29  |proj g|=         2.974
At iterate    13  f =      -577.29  |proj g|=        2.9857
At iterate    14  f =       -577.3  |proj g|=         3.001
At iterate    15  f =      -577.31  |proj g|=        3.0252
At iterate    16  f =      -577.33  |proj g|=        3.0896
At iterate    17  f =      -577.35  |proj g|=        3.0204
At iterate    18  f =      -577.42  |proj g|=        3.0863
At iterate    19  f =      -577.72  |proj g|=         3.188
At iterate    20  f =      -578.35  |proj g|=        3.1928
At iterate    21  f =      -579.72  |proj g|=         2.923
At iterate    22  f =      -582.28  |proj g|=        2.3525
At iterate    23  f =      -582.69  |proj g|=        2.7272
At iterate    24  f =      -585.86  |proj g|=        1.9605
At iterate    25  f =      -588.13  |proj g|=        1.5053
At iterate    26  f =      -589.72  |proj g|=        1.8758
At iterate    27  f =      -590.75  |proj g|=        1.3467
At iterate    28  f =      -590.89  |proj g|=        1.3354
At iterate    29  f =      -590.91  |proj g|=        1.2848
At iterate    30  f =      -590.94  |proj g|=        1.2762
At iterate    31  f =      -590.94  |proj g|=        1.2651
At iterate    32  f =      -590.94  |proj g|=         1.269
At iterate    33  f =      -590.94  |proj g|=         1.269

iterations 33
function evaluations 43
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.26896
final function value -590.937

F = -590.937
final  value -590.936950 
converged
 
INFO  [04:05:56.578] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:05:56.671] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:05:56.678] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:06:04.066] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:06:11.595] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:06:18.899] [mlr3]  Finished benchmark 
INFO  [04:06:18.969] [bbotk] Result of batch 112: 
INFO  [04:06:18.971] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:06:18.971] [bbotk]              4.001699                 3.495765                        0.406777 
INFO  [04:06:18.971] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:06:18.971] [bbotk]                     3516        0.857 -0.9544618         <NA>   0.9733384 
INFO  [04:06:18.971] [bbotk]                                 uhash 
INFO  [04:06:18.971] [bbotk]  44e4d342-9183-4d21-92bc-bb44195b2ae3 
DEBUG [04:06:20.515] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.174932e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.174932e-05 0.001269594 
  - best initial criterion value(s) :  544.287 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -544.29  |proj g|=       2.9956
At iterate     1  f =      -576.59  |proj g|=        2.8703
At iterate     2  f =      -589.34  |proj g|=        6.9723
At iterate     3  f =      -589.43  |proj g|=         6.815
At iterate     4  f =      -589.63  |proj g|=        6.3743
At iterate     5  f =      -589.78  |proj g|=         6.008
At iterate     6  f =      -589.86  |proj g|=         5.964
At iterate     7  f =      -589.86  |proj g|=        6.0788
At iterate     8  f =      -589.86  |proj g|=        6.0285
At iterate     9  f =      -589.86  |proj g|=        6.0281
At iterate    10  f =      -589.86  |proj g|=        6.0271
At iterate    11  f =      -589.86  |proj g|=        6.0255
At iterate    12  f =      -589.86  |proj g|=        6.0232
At iterate    13  f =      -589.86  |proj g|=        6.0206
At iterate    14  f =      -589.86  |proj g|=        6.0177
At iterate    15  f =      -589.86  |proj g|=        6.0167
At iterate    16  f =      -589.86  |proj g|=        6.0202
At iterate    17  f =      -589.87  |proj g|=        5.9608
At iterate    18  f =      -589.87  |proj g|=         5.994
At iterate    19  f =      -589.89  |proj g|=        6.0793
At iterate    20  f =      -589.93  |proj g|=        6.1756
At iterate    21  f =      -590.04  |proj g|=         6.309
At iterate    22  f =      -590.29  |proj g|=        6.4131
At iterate    23  f =      -590.86  |proj g|=        6.5229
At iterate    24  f =      -592.09  |proj g|=        6.0331
At iterate    25  f =      -592.49  |proj g|=        6.0665
At iterate    26  f =      -594.98  |proj g|=        4.6361
At iterate    27  f =      -595.98  |proj g|=        4.1297
At iterate    28  f =      -600.45  |proj g|=        1.7618
At iterate    29  f =      -604.07  |proj g|=        1.1468
At iterate    30  f =      -605.54  |proj g|=        1.2674
At iterate    31  f =      -605.83  |proj g|=         1.406
At iterate    32  f =      -606.12  |proj g|=        1.4328
At iterate    33  f =      -606.18  |proj g|=        1.3242
At iterate    34  f =      -606.18  |proj g|=        1.3386
At iterate    35  f =      -606.18  |proj g|=        1.3405
At iterate    36  f =      -606.18  |proj g|=        1.3406
At iterate    37  f =      -606.18  |proj g|=        1.3411
At iterate    38  f =      -606.18  |proj g|=        1.3417
At iterate    39  f =      -606.18  |proj g|=        1.3377
At iterate    40  f =      -606.18  |proj g|=        1.3469
At iterate    41  f =      -606.19  |proj g|=         1.345
At iterate    42  f =       -606.2  |proj g|=        1.3343
At iterate    43  f =      -606.21  |proj g|=        1.3362
At iterate    44  f =      -606.21  |proj g|=        1.3506
At iterate    45  f =      -606.22  |proj g|=        1.3707
At iterate    46  f =      -606.23  |proj g|=        1.3849
At iterate    47  f =      -606.25  |proj g|=        1.3997
At iterate    48  f =      -606.29  |proj g|=        1.4716
At iterate    49  f =      -606.36  |proj g|=        1.4629
At iterate    50  f =      -606.84  |proj g|=        1.4424
At iterate    51  f =         -607  |proj g|=        1.2557
At iterate    52  f =      -607.22  |proj g|=        1.3016
At iterate    53  f =      -607.22  |proj g|=        1.3008
At iterate    54  f =      -607.22  |proj g|=        1.3017
At iterate    55  f =      -607.22  |proj g|=        1.3008
At iterate    56  f =      -607.22  |proj g|=        1.3015
At iterate    57  f =      -607.22  |proj g|=        1.3008
At iterate    58  f =      -607.22  |proj g|=        1.2989
At iterate    59  f =      -607.23  |proj g|=        1.2872
At iterate    60  f =      -607.23  |proj g|=        1.2721
At iterate    61  f =      -607.24  |proj g|=         1.248
At iterate    62  f =      -607.26  |proj g|=        1.2222
At iterate    63  f =      -607.26  |proj g|=        1.2267
At iterate    64  f =      -607.26  |proj g|=        1.2354
At iterate    65  f =      -607.26  |proj g|=        1.2361
At iterate    66  f =      -607.26  |proj g|=        1.2363

iterations 66
function evaluations 76
segments explored during Cauchy searches 69
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 1.23628
final function value -607.264

F = -607.264
final  value -607.264222 
converged
 
INFO  [04:06:20.520] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:06:20.578] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:06:20.585] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:06:24.216] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:06:27.982] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:06:31.733] [mlr3]  Finished benchmark 
INFO  [04:06:31.803] [bbotk] Result of batch 113: 
INFO  [04:06:31.805] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:06:31.805] [bbotk]              7.682753                 4.426857                       0.4342599 
INFO  [04:06:31.805] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:06:31.805] [bbotk]                     1776        0.794 -0.9461114         <NA>   0.9737506 
INFO  [04:06:31.805] [bbotk]                                 uhash 
INFO  [04:06:31.805] [bbotk]  7931647f-cc9e-46ce-8d56-6e335c392a1e 
DEBUG [04:06:32.986] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.17175e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9540 
  - variance bounds :  1.17175e-05 0.001265897 
  - best initial criterion value(s) :  552.2365 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -552.24  |proj g|=       3.2343
At iterate     1  f =      -556.47  |proj g|=        1.4152
At iterate     2  f =      -556.73  |proj g|=        1.5842
At iterate     3  f =      -556.84  |proj g|=         1.786
At iterate     4  f =      -557.47  |proj g|=        1.7062
At iterate     5  f =      -558.73  |proj g|=        1.6126
At iterate     6  f =      -558.79  |proj g|=        1.4505
At iterate     7  f =      -558.89  |proj g|=        1.4765
At iterate     8  f =       -558.9  |proj g|=        1.4778
At iterate     9  f =      -559.16  |proj g|=        1.3983
At iterate    10  f =      -560.12  |proj g|=        1.3849
At iterate    11  f =      -562.03  |proj g|=        1.4937
At iterate    12  f =      -562.29  |proj g|=        1.2143
At iterate    13  f =      -563.02  |proj g|=        1.2004
At iterate    14  f =      -563.55  |proj g|=        1.2317
At iterate    15  f =      -563.56  |proj g|=        1.3085
At iterate    16  f =      -563.57  |proj g|=        1.2685
At iterate    17  f =      -563.57  |proj g|=        1.2777
At iterate    18  f =      -563.57  |proj g|=        1.2782
At iterate    19  f =      -563.57  |proj g|=        1.2777

iterations 19
function evaluations 32
segments explored during Cauchy searches 21
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.27767
final function value -563.568

F = -563.568
final  value -563.568317 
converged
 
INFO  [04:06:32.990] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:06:33.072] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:06:33.083] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:06:44.010] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:06:54.872] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:07:05.536] [mlr3]  Finished benchmark 
INFO  [04:07:05.606] [bbotk] Result of batch 114: 
INFO  [04:07:05.608] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:07:05.608] [bbotk]              6.006146                 6.367724                       0.2174397 
INFO  [04:07:05.608] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:07:05.608] [bbotk]                     5000        0.768 -0.9647655         <NA>   0.9746997 
INFO  [04:07:05.608] [bbotk]                                 uhash 
INFO  [04:07:05.608] [bbotk]  da53edc3-1be4-429d-862d-d47626013e58 
DEBUG [04:07:07.258] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.169712e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.169712e-05 0.00126408 
  - best initial criterion value(s) :  585.1334 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -585.13  |proj g|=       2.6769
At iterate     1  f =      -589.32  |proj g|=        5.5441
At iterate     2  f =      -591.55  |proj g|=        5.2284
At iterate     3  f =      -592.62  |proj g|=        4.7911
At iterate     4  f =       -592.7  |proj g|=        4.5506
At iterate     5  f =      -592.73  |proj g|=        4.5819
At iterate     6  f =      -592.81  |proj g|=        4.5856
At iterate     7  f =      -592.89  |proj g|=         4.493
At iterate     8  f =      -592.94  |proj g|=        4.3191
At iterate     9  f =      -592.94  |proj g|=        4.3102
At iterate    10  f =      -592.94  |proj g|=        4.3106
At iterate    11  f =      -592.94  |proj g|=        4.3104
At iterate    12  f =      -592.94  |proj g|=          4.31
At iterate    13  f =      -592.94  |proj g|=         4.309
At iterate    14  f =      -592.95  |proj g|=        4.3059
At iterate    15  f =      -592.97  |proj g|=        4.3097
At iterate    16  f =      -593.01  |proj g|=         4.279
At iterate    17  f =      -593.11  |proj g|=        4.2846
At iterate    18  f =      -593.26  |proj g|=         3.902
At iterate    19  f =      -593.63  |proj g|=         3.996
At iterate    20  f =      -595.29  |proj g|=         3.923
At iterate    21  f =      -598.46  |proj g|=        3.3231
At iterate    22  f =      -602.95  |proj g|=        2.9031
At iterate    23  f =      -604.18  |proj g|=        1.8915
At iterate    24  f =       -611.7  |proj g|=        2.0132
At iterate    25  f =      -615.75  |proj g|=        2.0875
At iterate    26  f =      -615.81  |proj g|=         1.975
At iterate    27  f =      -615.86  |proj g|=        1.7592
At iterate    28  f =      -615.87  |proj g|=        1.7818
At iterate    29  f =      -615.87  |proj g|=        1.7863
At iterate    30  f =      -615.87  |proj g|=        1.7841
At iterate    31  f =      -615.87  |proj g|=        1.7833
At iterate    32  f =      -615.87  |proj g|=        1.7819
At iterate    33  f =      -615.87  |proj g|=        1.7806
At iterate    34  f =      -615.87  |proj g|=         1.778
At iterate    35  f =      -615.87  |proj g|=        1.7741
At iterate    36  f =      -615.87  |proj g|=        1.7676
At iterate    37  f =      -615.87  |proj g|=        1.7584
At iterate    38  f =      -615.87  |proj g|=        1.7478
At iterate    39  f =      -615.87  |proj g|=         1.741
At iterate    40  f =      -615.87  |proj g|=        1.7326
At iterate    41  f =      -615.87  |proj g|=        1.7235
At iterate    42  f =      -616.47  |proj g|=        1.5292
At iterate    43  f =      -619.29  |proj g|=       0.37799
At iterate    44  f =      -619.75  |proj g|=       0.23354
At iterate    45  f =      -619.87  |proj g|=        0.2443
At iterate    46  f =      -619.89  |proj g|=       0.73493
At iterate    47  f =      -619.91  |proj g|=       0.24811
At iterate    48  f =      -619.91  |proj g|=       0.24896
At iterate    49  f =      -619.91  |proj g|=       0.24899
At iterate    50  f =      -619.91  |proj g|=       0.24878
At iterate    51  f =      -619.91  |proj g|=      0.025887
At iterate    52  f =      -619.91  |proj g|=      0.089259
At iterate    53  f =      -619.91  |proj g|=      0.054579
At iterate    54  f =      -619.91  |proj g|=      0.024272
At iterate    55  f =      -619.91  |proj g|=     0.0022157

iterations 55
function evaluations 64
segments explored during Cauchy searches 58
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00221568
final function value -619.913

F = -619.913
final  value -619.912892 
converged
 
INFO  [04:07:07.262] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:07:07.319] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:07:07.326] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:07:14.307] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:07:19.521] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:07:25.238] [mlr3]  Finished benchmark 
INFO  [04:07:25.310] [bbotk] Result of batch 115: 
INFO  [04:07:25.312] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:07:25.312] [bbotk]              6.546848                 3.389425                      0.04191001 
INFO  [04:07:25.312] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:07:25.312] [bbotk]                     1926        0.955 -0.9494911         <NA>   0.9563355 
INFO  [04:07:25.312] [bbotk]                                 uhash 
INFO  [04:07:25.312] [bbotk]  caed8c5c-51e4-4d7a-a615-394be3efae85 
DEBUG [04:07:26.707] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.167224e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.167224e-05 0.001263996 
  - best initial criterion value(s) :  560.7054 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -560.71  |proj g|=       2.1865
At iterate     1  f =      -561.83  |proj g|=        9.5655
At iterate     2  f =      -592.85  |proj g|=         5.073
At iterate     3  f =      -593.04  |proj g|=        6.0667
At iterate     4  f =      -593.91  |proj g|=        5.6557
At iterate     5  f =      -596.19  |proj g|=        4.5002
At iterate     6  f =      -598.14  |proj g|=        3.8019
At iterate     7  f =      -600.25  |proj g|=        3.5166
At iterate     8  f =      -601.05  |proj g|=        3.3787
At iterate     9  f =      -601.54  |proj g|=        3.4863
At iterate    10  f =      -601.72  |proj g|=        3.5081
At iterate    11  f =      -601.76  |proj g|=        3.5944
At iterate    12  f =      -601.77  |proj g|=        3.5087
At iterate    13  f =      -601.77  |proj g|=         3.544
At iterate    14  f =      -601.77  |proj g|=        3.5361
At iterate    15  f =      -601.77  |proj g|=        3.5354
At iterate    16  f =      -601.77  |proj g|=        3.5311
At iterate    17  f =      -601.77  |proj g|=        3.5258
At iterate    18  f =      -601.77  |proj g|=        3.5164
At iterate    19  f =      -601.77  |proj g|=        3.5031
At iterate    20  f =      -601.78  |proj g|=        3.4861
At iterate    21  f =       -601.8  |proj g|=        3.4739
At iterate    22  f =      -601.83  |proj g|=        3.4926
At iterate    23  f =       -601.9  |proj g|=        3.5634
At iterate    24  f =      -601.91  |proj g|=        3.4415
At iterate    25  f =       -602.1  |proj g|=         3.522
At iterate    26  f =      -606.28  |proj g|=        3.1628
At iterate    27  f =      -615.08  |proj g|=        1.9626
At iterate    28  f =      -620.79  |proj g|=       0.76414
At iterate    29  f =      -620.89  |proj g|=       0.76763
At iterate    30  f =       -620.9  |proj g|=       0.68622
At iterate    31  f =       -620.9  |proj g|=       0.68577
At iterate    32  f =       -620.9  |proj g|=        0.6857

iterations 32
function evaluations 38
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.685705
final function value -620.901

F = -620.901
final  value -620.900665 
converged
 
INFO  [04:07:26.711] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:07:26.769] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:07:26.776] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:07:33.741] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:07:42.123] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:07:49.887] [mlr3]  Finished benchmark 
INFO  [04:07:49.957] [bbotk] Result of batch 116: 
INFO  [04:07:49.959] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:07:49.959] [bbotk]               5.80898                 3.718239                        0.213808 
INFO  [04:07:49.959] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:07:49.959] [bbotk]                     2453        0.764 -0.9533357         <NA>   0.9720853 
INFO  [04:07:49.959] [bbotk]                                 uhash 
INFO  [04:07:49.959] [bbotk]  7d13703f-8df5-4d3f-a56e-08b5bd06b9d2 
DEBUG [04:07:51.186] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.162362e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.162362e-05 0.001259162 
  - best initial criterion value(s) :  575.5001 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -575.5  |proj g|=       4.7022
At iterate     1  f =      -595.23  |proj g|=        3.1023
At iterate     2  f =      -596.07  |proj g|=         4.185
At iterate     3  f =      -596.26  |proj g|=        3.9649
At iterate     4  f =      -596.31  |proj g|=        3.7783
At iterate     5  f =      -596.32  |proj g|=        3.7891
At iterate     6  f =      -596.32  |proj g|=        3.7959
At iterate     7  f =      -596.32  |proj g|=        3.7964
At iterate     8  f =      -596.32  |proj g|=        3.7968
At iterate     9  f =      -596.32  |proj g|=        3.7974
At iterate    10  f =      -596.32  |proj g|=        3.7981
At iterate    11  f =      -596.32  |proj g|=        3.8005
At iterate    12  f =      -596.32  |proj g|=        3.8024
At iterate    13  f =      -596.32  |proj g|=        3.8059
At iterate    14  f =      -596.32  |proj g|=        3.8077
At iterate    15  f =      -596.32  |proj g|=        3.8362
At iterate    16  f =      -596.32  |proj g|=        3.8321
At iterate    17  f =      -596.39  |proj g|=        3.9932
At iterate    18  f =      -596.52  |proj g|=        3.9057
At iterate    19  f =      -597.26  |proj g|=        3.4487
At iterate    20  f =      -598.47  |proj g|=        2.7687
At iterate    21  f =      -601.29  |proj g|=         1.745
At iterate    22  f =       -606.5  |proj g|=       0.71031
At iterate    23  f =       -606.7  |proj g|=       0.59272
At iterate    24  f =      -608.47  |proj g|=       0.96451
At iterate    25  f =      -608.86  |proj g|=       0.77353
At iterate    26  f =      -608.92  |proj g|=       0.70419
At iterate    27  f =      -608.93  |proj g|=       0.72648
At iterate    28  f =      -608.93  |proj g|=       0.73918
At iterate    29  f =      -608.93  |proj g|=       0.73935
At iterate    30  f =      -608.93  |proj g|=        0.7393

iterations 30
function evaluations 36
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.7393
final function value -608.927

F = -608.927
final  value -608.927236 
converged
 
INFO  [04:07:51.190] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:07:51.246] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:07:51.252] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:07:55.329] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:08:00.240] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:08:03.225] [mlr3]  Finished benchmark 
INFO  [04:08:03.292] [bbotk] Result of batch 117: 
INFO  [04:08:03.294] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:08:03.294] [bbotk]              6.366998                 6.053317                       0.4178509 
INFO  [04:08:03.294] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:08:03.294] [bbotk]                     1104        0.774 -0.9575472         <NA>   0.9716122 
INFO  [04:08:03.294] [bbotk]                                 uhash 
INFO  [04:08:03.294] [bbotk]  d4ecf534-1f49-4033-b768-40de63783c7c 
DEBUG [04:08:04.562] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.157109e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.157109e-05 0.001250195 
  - best initial criterion value(s) :  595.4061 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -595.41  |proj g|=        7.983
At iterate     1  f =      -599.96  |proj g|=         5.484
At iterate     2  f =       -604.5  |proj g|=        6.0905
At iterate     3  f =      -606.18  |proj g|=        5.7426
At iterate     4  f =       -607.2  |proj g|=        5.3476
At iterate     5  f =      -607.53  |proj g|=        5.2074
At iterate     6  f =      -607.65  |proj g|=        5.2034
At iterate     7  f =      -607.69  |proj g|=        5.4383
At iterate     8  f =      -607.69  |proj g|=        5.3551
At iterate     9  f =      -607.69  |proj g|=        5.3637
At iterate    10  f =      -607.69  |proj g|=        5.3684
At iterate    11  f =      -607.69  |proj g|=        5.3743
At iterate    12  f =      -607.69  |proj g|=        5.3849
At iterate    13  f =      -607.69  |proj g|=         5.401
At iterate    14  f =       -607.7  |proj g|=        5.4259
At iterate    15  f =       -607.7  |proj g|=        5.4619
At iterate    16  f =      -607.71  |proj g|=        5.5124
At iterate    17  f =      -607.73  |proj g|=        5.5919
At iterate    18  f =      -607.78  |proj g|=        5.6132
At iterate    19  f =      -607.84  |proj g|=        5.9754
At iterate    20  f =      -608.48  |proj g|=        5.2692
At iterate    21  f =      -610.17  |proj g|=        4.1751
At iterate    22  f =      -616.05  |proj g|=          1.94
At iterate    23  f =      -620.19  |proj g|=        1.0436
At iterate    24  f =      -623.63  |proj g|=       0.70305
At iterate    25  f =      -623.88  |proj g|=        1.0304
At iterate    26  f =      -623.98  |proj g|=       0.97144
At iterate    27  f =         -624  |proj g|=       0.95858
At iterate    28  f =         -624  |proj g|=        0.9547
At iterate    29  f =         -624  |proj g|=        0.9682
At iterate    30  f =         -624  |proj g|=       0.97116
At iterate    31  f =         -624  |proj g|=       0.97209
At iterate    32  f =         -624  |proj g|=       0.97211

iterations 32
function evaluations 41
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.972107
final function value -624.003

F = -624.003
final  value -624.003384 
converged
 
INFO  [04:08:04.566] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:08:04.622] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:08:04.629] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:08:11.335] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:08:16.848] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:08:23.130] [mlr3]  Finished benchmark 
INFO  [04:08:23.197] [bbotk] Result of batch 118: 
INFO  [04:08:23.199] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:08:23.199] [bbotk]              7.568012                 8.075979                       0.2635393 
INFO  [04:08:23.199] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:08:23.199] [bbotk]                     2096        0.778 -0.9550581         <NA>   0.9725513 
INFO  [04:08:23.199] [bbotk]                                 uhash 
INFO  [04:08:23.199] [bbotk]  a460fd73-0ece-44d9-8cd6-024b5e649dd2 
DEBUG [04:08:24.299] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.152735e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.152735e-05 0.001250283 
  - best initial criterion value(s) :  577.2618 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -577.26  |proj g|=       1.9205
At iterate     1  f =      -584.23  |proj g|=        8.5374
At iterate     2  f =      -590.87  |proj g|=        8.0519
At iterate     3  f =      -600.63  |proj g|=        6.3089
At iterate     4  f =      -601.43  |proj g|=        5.5997
At iterate     5  f =      -601.48  |proj g|=        5.4538
At iterate     6  f =      -601.57  |proj g|=        5.3885
At iterate     7  f =      -601.79  |proj g|=        5.3198
At iterate     8  f =      -601.86  |proj g|=        5.4743
At iterate     9  f =      -601.87  |proj g|=        5.5513
At iterate    10  f =      -601.87  |proj g|=        5.5511

iterations 10
function evaluations 14
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 5.55107
final function value -601.871

F = -601.871
final  value -601.871309 
converged
 
INFO  [04:08:24.303] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:08:24.378] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:08:24.384] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:08:25.536] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:08:26.721] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:08:27.825] [mlr3]  Finished benchmark 
INFO  [04:08:27.891] [bbotk] Result of batch 119: 
INFO  [04:08:27.893] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:08:27.893] [bbotk]               2.14211                 4.370862                         0.27961 
INFO  [04:08:27.893] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:08:27.893] [bbotk]                      434        0.781 -0.9622875         <NA>   0.9369375 
INFO  [04:08:27.893] [bbotk]                                 uhash 
INFO  [04:08:27.893] [bbotk]  8bd8d7f9-ee81-4ee9-ab9c-1ac8b8fa8419 
DEBUG [04:08:29.213] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.199141e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.19914e-05 0.001313714 
  - best initial criterion value(s) :  560.0537 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -560.05  |proj g|=       13.114
At iterate     1  f =      -597.87  |proj g|=         4.587
At iterate     2  f =      -597.87  |proj g|=        4.5043
At iterate     3  f =      -597.93  |proj g|=         4.458
At iterate     4  f =      -598.05  |proj g|=        4.2245
At iterate     5  f =      -598.07  |proj g|=        4.2359
At iterate     6  f =      -598.14  |proj g|=        4.2722
At iterate     7  f =      -598.21  |proj g|=        4.2847
At iterate     8  f =       -598.4  |proj g|=        4.0393
At iterate     9  f =      -598.49  |proj g|=        4.3785
At iterate    10  f =      -598.77  |proj g|=        4.0653
At iterate    11  f =      -599.44  |proj g|=        3.5975
At iterate    12  f =       -602.6  |proj g|=        3.1779
At iterate    13  f =      -619.85  |proj g|=        2.6608
At iterate    14  f =      -624.06  |proj g|=         2.204
At iterate    15  f =      -626.43  |proj g|=        1.8783
At iterate    16  f =      -633.61  |proj g|=       0.56576
At iterate    17  f =      -633.64  |proj g|=       0.76233
At iterate    18  f =      -633.66  |proj g|=       0.76342
At iterate    19  f =      -633.67  |proj g|=       0.37521
At iterate    20  f =      -633.67  |proj g|=       0.38269
At iterate    21  f =      -633.67  |proj g|=       0.38232

iterations 21
function evaluations 31
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.382319
final function value -633.672

F = -633.672
final  value -633.671687 
converged
 
INFO  [04:08:29.217] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:08:29.271] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:08:29.278] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:08:30.480] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:08:31.707] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:08:32.919] [mlr3]  Finished benchmark 
INFO  [04:08:32.988] [bbotk] Result of batch 120: 
INFO  [04:08:32.989] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:08:32.989] [bbotk]              9.323488                 8.704347                       0.4171815 
INFO  [04:08:32.989] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:08:32.989] [bbotk]                      455        0.892 -0.953816         <NA>   0.9667878 
INFO  [04:08:32.989] [bbotk]                                 uhash 
INFO  [04:08:32.989] [bbotk]  0fbae56d-11bc-467d-b7ad-0b3f68a935c4 
DEBUG [04:08:34.560] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.191304e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.191304e-05 0.001299835 
  - best initial criterion value(s) :  556.1404 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -556.14  |proj g|=       3.2524
At iterate     1  f =      -574.69  |proj g|=        13.453
At iterate     2  f =      -585.37  |proj g|=        13.271
At iterate     3  f =      -602.76  |proj g|=        12.891
At iterate     4  f =      -604.97  |proj g|=        10.491
At iterate     5  f =      -608.07  |proj g|=        10.084
At iterate     6  f =      -618.51  |proj g|=        5.4637
At iterate     7  f =      -622.86  |proj g|=        4.5103
At iterate     8  f =      -625.89  |proj g|=        3.4532
At iterate     9  f =      -627.54  |proj g|=        3.4261
At iterate    10  f =      -628.32  |proj g|=         4.391
At iterate    11  f =      -628.35  |proj g|=        4.5734
At iterate    12  f =      -628.36  |proj g|=        4.6281
At iterate    13  f =      -628.36  |proj g|=        4.6317
At iterate    14  f =      -628.36  |proj g|=        4.6363
At iterate    15  f =      -628.36  |proj g|=        4.6443
At iterate    16  f =      -628.36  |proj g|=        4.6568
At iterate    17  f =      -628.36  |proj g|=        4.6771
At iterate    18  f =      -628.36  |proj g|=        4.7096
At iterate    19  f =      -628.37  |proj g|=        4.7616
At iterate    20  f =      -628.39  |proj g|=        4.8445
At iterate    21  f =      -628.44  |proj g|=        4.9738
At iterate    22  f =      -628.59  |proj g|=        5.1644
At iterate    23  f =      -628.94  |proj g|=        5.4087
At iterate    24  f =      -629.74  |proj g|=        5.6147
At iterate    25  f =      -631.35  |proj g|=        5.3082
At iterate    26  f =         -632  |proj g|=        4.6237
At iterate    27  f =      -632.21  |proj g|=        4.0508
At iterate    28  f =      -632.25  |proj g|=        4.3016
At iterate    29  f =      -632.25  |proj g|=        4.2579
At iterate    30  f =      -632.25  |proj g|=        4.2595
At iterate    31  f =      -632.25  |proj g|=        4.2589
At iterate    32  f =      -632.25  |proj g|=        4.2665
At iterate    33  f =      -632.25  |proj g|=        4.2653
At iterate    34  f =      -632.26  |proj g|=        4.2581
At iterate    35  f =      -632.33  |proj g|=        4.1849
At iterate    36  f =      -632.47  |proj g|=        4.0785
At iterate    37  f =      -632.93  |proj g|=        3.7748
At iterate    38  f =      -632.93  |proj g|=         3.685
At iterate    39  f =      -634.05  |proj g|=        3.0784
At iterate    40  f =      -637.24  |proj g|=        1.4192
At iterate    41  f =      -641.94  |proj g|=       0.82824
At iterate    42  f =      -645.06  |proj g|=       0.70297
At iterate    43  f =      -645.13  |proj g|=       0.69707
At iterate    44  f =      -645.13  |proj g|=       0.69652
At iterate    45  f =      -645.13  |proj g|=       0.69636
At iterate    46  f =      -645.14  |proj g|=        0.6949
At iterate    47  f =      -645.14  |proj g|=       0.36105
At iterate    48  f =      -645.14  |proj g|=       0.28543
At iterate    49  f =      -645.14  |proj g|=       0.28572
At iterate    50  f =      -645.14  |proj g|=       0.18546
At iterate    51  f =      -645.14  |proj g|=      0.014288
At iterate    52  f =      -645.14  |proj g|=    0.00062816

iterations 52
function evaluations 62
segments explored during Cauchy searches 57
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.000628161
final function value -645.141

F = -645.141
final  value -645.140940 
converged
 
INFO  [04:08:34.564] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:08:34.620] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:08:34.627] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:08:42.947] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:08:50.990] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:08:59.247] [mlr3]  Finished benchmark 
INFO  [04:08:59.316] [bbotk] Result of batch 121: 
INFO  [04:08:59.318] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:08:59.318] [bbotk]              3.942942                 8.150065                       0.2088504 
INFO  [04:08:59.318] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:08:59.318] [bbotk]                     3832        0.779 -0.9466143         <NA>    0.971329 
INFO  [04:08:59.318] [bbotk]                                 uhash 
INFO  [04:08:59.318] [bbotk]  138b924b-4081-4a08-9370-68cbc8725fac 
DEBUG [04:09:00.428] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.185841e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.185841e-05 0.001297137 
  - best initial criterion value(s) :  613.2176 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -613.22  |proj g|=       0.1536
At iterate     1  f =      -623.28  |proj g|=        4.7065
At iterate     2  f =      -623.54  |proj g|=        4.4603
At iterate     3  f =      -623.69  |proj g|=        4.0209
At iterate     4  f =       -623.7  |proj g|=         4.093
At iterate     5  f =      -623.72  |proj g|=        4.1546
At iterate     6  f =      -623.78  |proj g|=        4.3149
At iterate     7  f =      -623.88  |proj g|=        4.4907
At iterate     8  f =         -624  |proj g|=        4.6132
At iterate     9  f =      -624.06  |proj g|=        4.3905
At iterate    10  f =      -624.08  |proj g|=        4.4679
At iterate    11  f =      -624.08  |proj g|=        4.4733
At iterate    12  f =      -624.08  |proj g|=         4.474
At iterate    13  f =      -624.08  |proj g|=        4.4743

iterations 13
function evaluations 17
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.47431
final function value -624.081

F = -624.081
final  value -624.081179 
converged
 
INFO  [04:09:00.432] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:09:00.517] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:09:00.526] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:09:07.733] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:09:14.830] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:09:21.942] [mlr3]  Finished benchmark 
INFO  [04:09:22.010] [bbotk] Result of batch 122: 
INFO  [04:09:22.012] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:09:22.012] [bbotk]              3.128537                 5.507683                       0.3183089 
INFO  [04:09:22.012] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:09:22.012] [bbotk]                     3458        0.771 -0.9604492         <NA>   0.9687257 
INFO  [04:09:22.012] [bbotk]                                 uhash 
INFO  [04:09:22.012] [bbotk]  3793fd3e-1ff5-4252-8bec-03a135ecc6db 
DEBUG [04:09:23.296] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.178809e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.178809e-05 0.001289377 
  - best initial criterion value(s) :  578.6466 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -578.65  |proj g|=       12.853
At iterate     1  f =      -605.88  |proj g|=        8.0106
At iterate     2  f =       -609.9  |proj g|=        6.8089
At iterate     3  f =      -610.55  |proj g|=        5.6677
At iterate     4  f =      -610.66  |proj g|=        5.1398
At iterate     5  f =      -610.67  |proj g|=        5.0505
At iterate     6  f =      -610.68  |proj g|=        5.0341
At iterate     7  f =      -610.68  |proj g|=        5.0568
At iterate     8  f =      -610.68  |proj g|=        5.0649
At iterate     9  f =      -610.68  |proj g|=        5.0664
At iterate    10  f =      -610.68  |proj g|=        5.0779
At iterate    11  f =      -610.68  |proj g|=        5.0908
At iterate    12  f =      -610.68  |proj g|=        5.1153
At iterate    13  f =      -610.69  |proj g|=        5.1537
At iterate    14  f =      -610.69  |proj g|=        5.2216
At iterate    15  f =       -610.7  |proj g|=        5.3302
At iterate    16  f =      -610.73  |proj g|=        5.4815
At iterate    17  f =      -610.79  |proj g|=        5.7146
At iterate    18  f =      -610.93  |proj g|=        5.9779
At iterate    19  f =      -611.03  |proj g|=         6.242
At iterate    20  f =      -611.56  |proj g|=        6.5355
At iterate    21  f =       -612.9  |proj g|=        6.5104
At iterate    22  f =      -615.28  |proj g|=        5.8577
At iterate    23  f =      -623.28  |proj g|=        2.9597
At iterate    24  f =      -626.01  |proj g|=         1.577
At iterate    25  f =       -629.9  |proj g|=         2.246
At iterate    26  f =      -632.61  |proj g|=         2.146
At iterate    27  f =      -634.81  |proj g|=        1.7405
At iterate    28  f =      -635.38  |proj g|=        1.1812
At iterate    29  f =      -635.43  |proj g|=       0.90543
At iterate    30  f =      -635.44  |proj g|=        1.0008
At iterate    31  f =      -635.44  |proj g|=       0.98848
At iterate    32  f =      -635.44  |proj g|=       0.98882
At iterate    33  f =      -635.44  |proj g|=       0.98867

iterations 33
function evaluations 38
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.988671
final function value -635.442

F = -635.442
final  value -635.442074 
converged
 
INFO  [04:09:23.300] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:09:23.358] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:09:23.365] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:09:30.807] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:09:38.385] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:09:49.237] [mlr3]  Finished benchmark 
INFO  [04:09:49.340] [bbotk] Result of batch 123: 
INFO  [04:09:49.343] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:09:49.343] [bbotk]               4.83969                 4.079796                      0.03861018 
INFO  [04:09:49.343] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:09:49.343] [bbotk]                     3573        0.797 -0.958296         <NA>     0.96073 
INFO  [04:09:49.343] [bbotk]                                 uhash 
INFO  [04:09:49.343] [bbotk]  21338ed8-2b28-441f-87a2-62ce4daf253a 
DEBUG [04:09:50.557] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.172471e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.172471e-05 0.001283042 
  - best initial criterion value(s) :  589.0247 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -589.02  |proj g|=       6.6462
At iterate     1  f =      -631.62  |proj g|=        3.4294
At iterate     2  f =      -632.47  |proj g|=        3.1044
At iterate     3  f =      -633.82  |proj g|=       0.90146
At iterate     4  f =      -634.22  |proj g|=        1.7879
At iterate     5  f =      -634.31  |proj g|=        1.6644
At iterate     6  f =      -634.74  |proj g|=        1.1402
At iterate     7  f =      -635.38  |proj g|=        0.6819
At iterate     8  f =      -636.65  |proj g|=       0.41867
At iterate     9  f =       -637.3  |proj g|=        1.3558
At iterate    10  f =      -638.18  |proj g|=       0.61451
At iterate    11  f =       -638.3  |proj g|=       0.43052
At iterate    12  f =      -638.33  |proj g|=       0.41168
At iterate    13  f =      -638.34  |proj g|=       0.44184
At iterate    14  f =      -638.34  |proj g|=       0.46441
At iterate    15  f =      -638.34  |proj g|=       0.46908
At iterate    16  f =      -638.34  |proj g|=       0.46938

iterations 16
function evaluations 20
segments explored during Cauchy searches 19
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.469378
final function value -638.345

F = -638.345
final  value -638.344557 
converged
 
INFO  [04:09:50.562] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:09:50.618] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:09:50.626] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:10:06.609] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:10:22.191] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:10:37.935] [mlr3]  Finished benchmark 
INFO  [04:10:38.006] [bbotk] Result of batch 124: 
INFO  [04:10:38.008] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:10:38.008] [bbotk]              3.267925                 8.140316                       0.3193929 
INFO  [04:10:38.008] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:10:38.008] [bbotk]                     4883        0.828 -0.9574206         <NA>   0.9712821 
INFO  [04:10:38.008] [bbotk]                                 uhash 
INFO  [04:10:38.008] [bbotk]  10fd259d-c47c-425c-8f30-723f91423efd 
DEBUG [04:10:39.206] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.167175e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.167175e-05 0.001275299 
  - best initial criterion value(s) :  589.6826 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -589.68  |proj g|=       3.6461
At iterate     1  f =       -603.5  |proj g|=        8.3386
At iterate     2  f =      -605.04  |proj g|=        7.4972
At iterate     3  f =      -606.79  |proj g|=        6.0311
At iterate     4  f =      -609.85  |proj g|=        5.1197
At iterate     5  f =      -617.43  |proj g|=        4.5529
At iterate     6  f =      -617.62  |proj g|=        4.8434
At iterate     7  f =      -617.66  |proj g|=         4.816
At iterate     8  f =      -617.67  |proj g|=        4.7962
At iterate     9  f =      -617.67  |proj g|=        4.8023
At iterate    10  f =      -617.67  |proj g|=         4.802

iterations 10
function evaluations 15
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.80204
final function value -617.666

F = -617.666
final  value -617.666251 
converged
 
INFO  [04:10:39.210] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:10:39.268] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:10:39.275] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:10:43.250] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:10:48.036] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:10:52.690] [mlr3]  Finished benchmark 
INFO  [04:10:52.760] [bbotk] Result of batch 125: 
INFO  [04:10:52.762] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:10:52.762] [bbotk]              3.721259                 2.805706                      0.06291445 
INFO  [04:10:52.762] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:10:52.762] [bbotk]                     1400         0.83 -0.9634555         <NA>   0.9508507 
INFO  [04:10:52.762] [bbotk]                                 uhash 
INFO  [04:10:52.762] [bbotk]  fafacc52-2606-449a-af9e-48a2faae57a4 
DEBUG [04:10:54.426] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.173078e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.173078e-05 0.001282737 
  - best initial criterion value(s) :  570.9377 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -570.94  |proj g|=       3.1194
At iterate     1  f =      -571.51  |proj g|=        7.2882
At iterate     2  f =      -578.41  |proj g|=        6.4951
At iterate     3  f =      -585.79  |proj g|=         4.459
At iterate     4  f =      -586.32  |proj g|=         3.784
At iterate     5  f =      -588.94  |proj g|=        3.2315
At iterate     6  f =      -590.81  |proj g|=        4.1605
At iterate     7  f =      -590.82  |proj g|=        4.8569
At iterate     8  f =      -591.39  |proj g|=        4.3963
At iterate     9  f =      -591.46  |proj g|=        4.2561
At iterate    10  f =      -591.48  |proj g|=        4.3699
At iterate    11  f =      -591.48  |proj g|=        4.3499
At iterate    12  f =      -591.48  |proj g|=        4.3493
At iterate    13  f =      -591.48  |proj g|=        4.3486
At iterate    14  f =      -591.48  |proj g|=        4.3545
At iterate    15  f =      -591.48  |proj g|=        4.3523
At iterate    16  f =      -591.49  |proj g|=        4.3351
At iterate    17  f =      -591.49  |proj g|=         4.316
At iterate    18  f =      -591.52  |proj g|=        4.2757
At iterate    19  f =      -591.57  |proj g|=        4.2112
At iterate    20  f =       -591.7  |proj g|=        4.1115
At iterate    21  f =      -591.98  |proj g|=         3.792
At iterate    22  f =      -592.61  |proj g|=        3.5558
At iterate    23  f =      -592.89  |proj g|=        3.0496
At iterate    24  f =      -595.17  |proj g|=        2.5057
At iterate    25  f =       -605.4  |proj g|=        1.0448
At iterate    26  f =      -607.27  |proj g|=       0.81322
At iterate    27  f =      -608.91  |proj g|=       0.19325
At iterate    28  f =      -608.94  |proj g|=       0.85094
At iterate    29  f =      -608.95  |proj g|=       0.12798
At iterate    30  f =      -608.96  |proj g|=       0.20827
At iterate    31  f =      -608.96  |proj g|=      0.049192
At iterate    32  f =      -608.96  |proj g|=      0.049191

iterations 32
function evaluations 43
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.049191
final function value -608.956

F = -608.956
final  value -608.955886 
converged
 
INFO  [04:10:54.430] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:10:54.490] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:10:54.497] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:11:02.574] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:11:10.550] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:11:18.410] [mlr3]  Finished benchmark 
INFO  [04:11:18.493] [bbotk] Result of batch 126: 
INFO  [04:11:18.495] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:11:18.495] [bbotk]              3.406926                 4.765123                       0.1776756 
INFO  [04:11:18.495] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:11:18.495] [bbotk]                     3895         1.11 -0.9642131         <NA>   0.9681936 
INFO  [04:11:18.495] [bbotk]                                 uhash 
INFO  [04:11:18.495] [bbotk]  d5a09a85-f3e7-4c7e-94b0-d00024d19151 
DEBUG [04:11:19.696] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.166116e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.166116e-05 0.001275834 
  - best initial criterion value(s) :  618.2824 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -618.28  |proj g|=       2.5398
At iterate     1  f =      -627.44  |proj g|=        1.6899
At iterate     2  f =      -627.46  |proj g|=         1.649
At iterate     3  f =      -627.49  |proj g|=        1.5743
At iterate     4  f =      -627.52  |proj g|=        1.5372
At iterate     5  f =      -627.62  |proj g|=        1.4688
At iterate     6  f =      -627.74  |proj g|=        1.4779
At iterate     7  f =      -627.87  |proj g|=        1.6153
At iterate     8  f =       -627.9  |proj g|=        1.7139
At iterate     9  f =       -627.9  |proj g|=        1.7213
At iterate    10  f =       -627.9  |proj g|=        1.7217
At iterate    11  f =       -627.9  |proj g|=        1.7218

iterations 11
function evaluations 15
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.72176
final function value -627.9

F = -627.9
final  value -627.900122 
converged
 
INFO  [04:11:19.701] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:11:19.765] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:11:19.774] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:11:22.621] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:11:25.355] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:11:28.441] [mlr3]  Finished benchmark 
INFO  [04:11:28.513] [bbotk] Result of batch 127: 
INFO  [04:11:28.515] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:11:28.515] [bbotk]              9.236118                 3.118109                       0.1869664 
INFO  [04:11:28.515] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:11:28.515] [bbotk]                     1305        0.829 -0.9619414         <NA>    0.968455 
INFO  [04:11:28.515] [bbotk]                                 uhash 
INFO  [04:11:28.515] [bbotk]  a0d39e8c-a83c-4e89-bfb0-a735a211f4ae 
DEBUG [04:11:30.250] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.159338e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.159338e-05 0.001266189 
  - best initial criterion value(s) :  630.896 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -630.9  |proj g|=       6.3398
At iterate     1  f =      -635.83  |proj g|=        6.4403
At iterate     2  f =      -644.07  |proj g|=        6.1928
At iterate     3  f =      -652.74  |proj g|=        4.9756
At iterate     4  f =      -653.36  |proj g|=        4.6366
At iterate     5  f =      -654.77  |proj g|=        4.7069
At iterate     6  f =      -657.66  |proj g|=          5.87
At iterate     7  f =      -658.41  |proj g|=        5.8587
At iterate     8  f =      -658.49  |proj g|=        5.8477
At iterate     9  f =      -658.49  |proj g|=        5.8502
At iterate    10  f =      -658.49  |proj g|=        5.8529
At iterate    11  f =      -658.49  |proj g|=        5.8585
At iterate    12  f =      -658.49  |proj g|=        5.8644
At iterate    13  f =      -658.49  |proj g|=        5.8181
At iterate    14  f =      -658.53  |proj g|=        5.8517
At iterate    15  f =      -660.89  |proj g|=        5.2054
At iterate    16  f =      -661.56  |proj g|=        4.6173
At iterate    17  f =      -661.61  |proj g|=        4.7741
At iterate    18  f =      -661.62  |proj g|=         4.765
At iterate    19  f =      -661.62  |proj g|=        4.7637
At iterate    20  f =      -661.62  |proj g|=        4.7637
At iterate    21  f =      -661.62  |proj g|=        4.7643
At iterate    22  f =      -661.62  |proj g|=        4.7653
At iterate    23  f =      -661.62  |proj g|=        4.7675
At iterate    24  f =      -661.62  |proj g|=        4.7674
At iterate    25  f =      -661.62  |proj g|=        4.7661
At iterate    26  f =      -661.63  |proj g|=        4.8078
At iterate    27  f =      -661.63  |proj g|=        4.7458
At iterate    28  f =      -661.66  |proj g|=         4.773
At iterate    29  f =      -661.87  |proj g|=        4.8834
At iterate    30  f =      -662.28  |proj g|=        4.9171
At iterate    31  f =      -663.17  |proj g|=        4.5237
At iterate    32  f =      -664.66  |proj g|=        3.8379
At iterate    33  f =       -664.7  |proj g|=        4.0195
At iterate    34  f =       -664.7  |proj g|=        4.0153
At iterate    35  f =       -664.7  |proj g|=        4.0195
At iterate    36  f =       -664.7  |proj g|=        4.0163
At iterate    37  f =      -664.72  |proj g|=        4.0364
At iterate    38  f =      -664.72  |proj g|=        4.0465
At iterate    39  f =      -664.96  |proj g|=         4.063
At iterate    40  f =      -664.97  |proj g|=        4.1696
At iterate    41  f =      -664.97  |proj g|=        4.1454
At iterate    42  f =      -664.97  |proj g|=        4.1453
At iterate    43  f =      -664.97  |proj g|=        4.1446
At iterate    44  f =      -664.97  |proj g|=        4.1434
At iterate    45  f =      -664.98  |proj g|=        4.1356
At iterate    46  f =      -664.98  |proj g|=        4.1243
At iterate    47  f =         -665  |proj g|=         4.114
At iterate    48  f =      -665.01  |proj g|=        4.0467
At iterate    49  f =      -665.05  |proj g|=        4.0266
At iterate    50  f =      -665.24  |proj g|=         3.939
At iterate    51  f =      -665.57  |proj g|=        3.7581
At iterate    52  f =      -665.57  |proj g|=         3.778
At iterate    53  f =      -665.57  |proj g|=        3.7833
At iterate    54  f =      -665.57  |proj g|=        3.7769
At iterate    55  f =      -665.57  |proj g|=        3.7802
At iterate    56  f =      -665.57  |proj g|=        3.7835
At iterate    57  f =      -665.87  |proj g|=        3.7506
At iterate    58  f =      -666.15  |proj g|=        3.6352
At iterate    59  f =      -666.16  |proj g|=        3.6332
At iterate    60  f =      -666.16  |proj g|=        3.6367
At iterate    61  f =      -666.16  |proj g|=        3.6378
At iterate    62  f =      -666.16  |proj g|=         3.638

iterations 62
function evaluations 83
segments explored during Cauchy searches 65
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.638
final function value -666.16

F = -666.16
final  value -666.160128 
converged
 
INFO  [04:11:30.254] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:11:30.310] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:11:30.318] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:11:33.887] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:11:37.440] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:11:41.179] [mlr3]  Finished benchmark 
INFO  [04:11:41.250] [bbotk] Result of batch 128: 
INFO  [04:11:41.252] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:11:41.252] [bbotk]              4.584693                  9.58101                         0.28722 
INFO  [04:11:41.252] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:11:41.252] [bbotk]                     1741        0.814 -0.950422         <NA>   0.9706835 
INFO  [04:11:41.252] [bbotk]                                 uhash 
INFO  [04:11:41.252] [bbotk]  33e89d2d-aaed-481a-af93-08a2e11b4e60 
DEBUG [04:11:42.381] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.153841e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.153841e-05 0.00126176 
  - best initial criterion value(s) :  634.9242 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -634.92  |proj g|=       1.7864
At iterate     1  f =      -643.77  |proj g|=        3.4487
At iterate     2  f =      -644.54  |proj g|=        3.1292
At iterate     3  f =      -645.02  |proj g|=        1.8908
At iterate     4  f =      -645.22  |proj g|=        2.4441
At iterate     5  f =      -645.25  |proj g|=        2.3113
At iterate     6  f =      -645.26  |proj g|=        2.2258
At iterate     7  f =      -645.26  |proj g|=        2.2303
At iterate     8  f =      -645.26  |proj g|=        2.2354
At iterate     9  f =      -645.26  |proj g|=        2.2354

iterations 9
function evaluations 12
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.23542
final function value -645.262

F = -645.262
final  value -645.261666 
converged
 
INFO  [04:11:42.385] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:11:42.442] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:11:42.449] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:11:48.190] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:11:53.508] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:11:58.811] [mlr3]  Finished benchmark 
INFO  [04:11:58.890] [bbotk] Result of batch 129: 
INFO  [04:11:58.892] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:11:58.892] [bbotk]              7.288737                 2.170416                       0.2037974 
INFO  [04:11:58.892] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:11:58.892] [bbotk]                     2573        0.801 -0.961794         <NA>   0.9723824 
INFO  [04:11:58.892] [bbotk]                                 uhash 
INFO  [04:11:58.892] [bbotk]  2c382188-5315-4e36-8e3f-0ced99836c7b 
DEBUG [04:12:00.043] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.149713e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.149713e-05 0.001261155 
  - best initial criterion value(s) :  641.1651 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -641.17  |proj g|=       3.5714
At iterate     1  f =      -673.55  |proj g|=       0.63796
At iterate     2  f =      -678.17  |proj g|=        2.2251
At iterate     3  f =      -681.59  |proj g|=       0.43507
At iterate     4  f =      -682.87  |proj g|=         1.199
At iterate     5  f =      -683.25  |proj g|=        1.3601
At iterate     6  f =      -683.33  |proj g|=         1.237
At iterate     7  f =      -683.33  |proj g|=        1.2389
At iterate     8  f =      -683.33  |proj g|=         1.242
At iterate     9  f =      -683.33  |proj g|=        1.2417

iterations 9
function evaluations 13
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.24172
final function value -683.328

F = -683.328
final  value -683.328244 
converged
 
INFO  [04:12:00.048] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:12:00.133] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:12:00.141] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:12:07.571] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:12:19.095] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:12:29.873] [mlr3]  Finished benchmark 
INFO  [04:12:29.963] [bbotk] Result of batch 130: 
INFO  [04:12:29.965] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:12:29.965] [bbotk]              7.497188                 2.619104                       0.2499633 
INFO  [04:12:29.965] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:12:29.965] [bbotk]                     3458        0.814 -0.9540654         <NA>   0.9741397 
INFO  [04:12:29.965] [bbotk]                                 uhash 
INFO  [04:12:29.965] [bbotk]  8b9507a0-cabc-46a1-a79c-2df89836e552 
DEBUG [04:12:31.510] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.147324e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.147324e-05 0.001259762 
  - best initial criterion value(s) :  641.6723 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -641.67  |proj g|=        13.24
At iterate     1  f =      -653.72  |proj g|=        7.7769
At iterate     2  f =      -666.67  |proj g|=        7.4984
At iterate     3  f =      -670.32  |proj g|=        6.2193
At iterate     4  f =      -673.54  |proj g|=        4.8652
At iterate     5  f =      -674.97  |proj g|=        4.2626
At iterate     6  f =      -675.97  |proj g|=        4.0107
At iterate     7  f =      -676.25  |proj g|=         6.202
At iterate     8  f =      -677.23  |proj g|=        4.6907
At iterate     9  f =       -677.3  |proj g|=        4.4921
At iterate    10  f =      -677.32  |proj g|=        4.6255
At iterate    11  f =      -677.33  |proj g|=        4.4971
At iterate    12  f =      -677.33  |proj g|=        4.4891
At iterate    13  f =      -677.33  |proj g|=        4.4743
At iterate    14  f =      -677.34  |proj g|=        4.4589
At iterate    15  f =      -677.35  |proj g|=        4.4279
At iterate    16  f =      -677.37  |proj g|=        4.2519
At iterate    17  f =      -677.38  |proj g|=         4.362
At iterate    18  f =      -677.47  |proj g|=         4.234
At iterate    19  f =      -677.64  |proj g|=        4.0388
At iterate    20  f =      -677.94  |proj g|=        3.7683
At iterate    21  f =      -679.67  |proj g|=        2.5645
At iterate    22  f =      -683.15  |proj g|=        1.2113
At iterate    23  f =      -689.09  |proj g|=       0.31729
At iterate    24  f =      -691.57  |proj g|=       0.83799
At iterate    25  f =      -693.65  |proj g|=        1.4341
At iterate    26  f =       -693.8  |proj g|=         1.296
At iterate    27  f =      -693.86  |proj g|=        1.2817
At iterate    28  f =      -693.87  |proj g|=        1.2926
At iterate    29  f =      -693.88  |proj g|=        1.3056
At iterate    30  f =      -693.88  |proj g|=        1.3124
At iterate    31  f =      -693.88  |proj g|=         1.313
At iterate    32  f =      -693.88  |proj g|=         1.313

iterations 32
function evaluations 37
segments explored during Cauchy searches 35
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.31297
final function value -693.877

F = -693.877
final  value -693.876562 
converged
 
INFO  [04:12:31.514] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:12:31.570] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:12:31.577] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:12:33.902] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:12:36.254] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:12:38.345] [mlr3]  Finished benchmark 
INFO  [04:12:38.413] [bbotk] Result of batch 131: 
INFO  [04:12:38.414] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:12:38.414] [bbotk]              4.019059                 3.237391                      0.05967796 
INFO  [04:12:38.414] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:12:38.414] [bbotk]                      668        0.995 -0.949844         <NA>   0.9382667 
INFO  [04:12:38.414] [bbotk]                                 uhash 
INFO  [04:12:38.414] [bbotk]  650ab03e-29d0-4525-b903-1faad7e3183e 
DEBUG [04:12:39.756] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.185664e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9542 
  - variance bounds :  1.185664e-05 0.001310685 
  - best initial criterion value(s) :  632.7045 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -632.7  |proj g|=       12.846
At iterate     1  f =      -659.77  |proj g|=        6.0139
At iterate     2  f =       -661.5  |proj g|=        5.8691
At iterate     3  f =      -662.38  |proj g|=        4.8486
At iterate     4  f =      -662.55  |proj g|=        4.5436
At iterate     5  f =      -662.59  |proj g|=        4.5212
At iterate     6  f =       -662.6  |proj g|=         4.544
At iterate     7  f =       -662.6  |proj g|=        4.5564
At iterate     8  f =       -662.6  |proj g|=        4.5577
At iterate     9  f =       -662.6  |proj g|=        4.5606
At iterate    10  f =       -662.6  |proj g|=        4.5645
At iterate    11  f =       -662.6  |proj g|=         4.571
At iterate    12  f =       -662.6  |proj g|=        4.5808
At iterate    13  f =       -662.6  |proj g|=        4.5948
At iterate    14  f =       -662.6  |proj g|=        4.6118
At iterate    15  f =      -662.61  |proj g|=        4.6226
At iterate    16  f =      -662.64  |proj g|=        4.5939
At iterate    17  f =      -662.68  |proj g|=        4.4523
At iterate    18  f =      -662.72  |proj g|=        4.2109
At iterate    19  f =      -662.73  |proj g|=        4.1292
At iterate    20  f =      -662.94  |proj g|=        3.9431
At iterate    21  f =       -665.4  |proj g|=        2.8469
At iterate    22  f =      -671.14  |proj g|=         1.604
At iterate    23  f =      -677.43  |proj g|=        1.9909
At iterate    24  f =      -677.72  |proj g|=        1.6867
At iterate    25  f =       -677.8  |proj g|=        1.7043
At iterate    26  f =      -677.86  |proj g|=        1.5507
At iterate    27  f =      -677.88  |proj g|=        1.6328
At iterate    28  f =      -677.88  |proj g|=         1.633
At iterate    29  f =      -677.88  |proj g|=         1.633

iterations 29
function evaluations 37
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.63303
final function value -677.875

F = -677.875
final  value -677.875305 
converged
 
INFO  [04:12:39.760] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:12:39.816] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:12:39.823] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:12:40.794] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:12:41.810] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:12:42.801] [mlr3]  Finished benchmark 
INFO  [04:12:42.887] [bbotk] Result of batch 132: 
INFO  [04:12:42.889] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:12:42.889] [bbotk]                4.7893                  5.92538                       0.1783016 
INFO  [04:12:42.889] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:12:42.889] [bbotk]                      224        0.822 -0.9539575         <NA>   0.9433566 
INFO  [04:12:42.889] [bbotk]                                 uhash 
INFO  [04:12:42.889] [bbotk]  dd5a2a9d-38aa-49c4-be9d-1eb0ff6af863 
DEBUG [04:12:44.247] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.20772e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.20772e-05 0.0013452 
  - best initial criterion value(s) :  666.9823 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -666.98  |proj g|=       1.9748
At iterate     1  f =      -668.63  |proj g|=        3.1901
At iterate     2  f =      -668.65  |proj g|=        3.1582
At iterate     3  f =      -668.76  |proj g|=        2.8573
At iterate     4  f =      -668.86  |proj g|=        2.6682
At iterate     5  f =      -669.05  |proj g|=         2.425
At iterate     6  f =      -669.09  |proj g|=        2.5645
At iterate     7  f =       -669.1  |proj g|=        2.5416
At iterate     8  f =       -669.1  |proj g|=        2.5401
At iterate     9  f =       -669.1  |proj g|=        2.5389
At iterate    10  f =       -669.1  |proj g|=        2.5372
At iterate    11  f =       -669.1  |proj g|=        2.5344
At iterate    12  f =       -669.1  |proj g|=        2.5402
At iterate    13  f =       -669.1  |proj g|=        2.5126
At iterate    14  f =      -669.12  |proj g|=        2.5604
At iterate    15  f =      -669.22  |proj g|=        2.6741
At iterate    16  f =      -669.52  |proj g|=         2.825
At iterate    17  f =      -670.25  |proj g|=        2.9392
At iterate    18  f =      -672.05  |proj g|=        2.8477
At iterate    19  f =      -676.29  |proj g|=        2.0953
At iterate    20  f =      -678.96  |proj g|=       0.93567
At iterate    21  f =      -679.32  |proj g|=        1.0106
At iterate    22  f =       -679.6  |proj g|=       0.83083
At iterate    23  f =      -679.91  |proj g|=       0.94413
At iterate    24  f =      -681.12  |proj g|=        1.1947
At iterate    25  f =      -682.08  |proj g|=        1.0555
At iterate    26  f =      -682.29  |proj g|=       0.83779
At iterate    27  f =      -682.31  |proj g|=       0.76107
At iterate    28  f =      -682.31  |proj g|=       0.74561
At iterate    29  f =      -682.31  |proj g|=       0.75488
At iterate    30  f =      -682.31  |proj g|=       0.75519

iterations 30
function evaluations 38
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.755186
final function value -682.307

F = -682.307
final  value -682.307225 
converged
 
INFO  [04:12:44.251] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:12:44.307] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:12:44.313] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:12:51.970] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:12:59.154] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:13:07.439] [mlr3]  Finished benchmark 
INFO  [04:13:07.514] [bbotk] Result of batch 133: 
INFO  [04:13:07.516] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:13:07.516] [bbotk]              3.011233                  9.45173                       0.3175595 
INFO  [04:13:07.516] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:13:07.516] [bbotk]                     2418        0.824 -0.9527695         <NA>   0.9660424 
INFO  [04:13:07.516] [bbotk]                                 uhash 
INFO  [04:13:07.516] [bbotk]  abd9c9d4-2736-434d-af9c-0736e1a8eec6 
DEBUG [04:13:09.331] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.200365e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.200365e-05 0.00133902 
  - best initial criterion value(s) :  640.0127 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -640.01  |proj g|=        6.646
At iterate     1  f =      -666.81  |proj g|=        9.2494
At iterate     2  f =      -669.12  |proj g|=        9.0789
At iterate     3  f =      -670.78  |proj g|=        7.9165
At iterate     4  f =       -671.3  |proj g|=        8.5466
At iterate     5  f =      -671.34  |proj g|=        8.4631
At iterate     6  f =      -671.36  |proj g|=        8.4583
At iterate     7  f =       -671.4  |proj g|=        8.5367
At iterate     8  f =      -671.44  |proj g|=        8.7863
At iterate     9  f =      -671.44  |proj g|=        8.8177
At iterate    10  f =      -671.44  |proj g|=        8.8224
At iterate    11  f =      -671.44  |proj g|=         8.827
At iterate    12  f =      -671.45  |proj g|=        8.8342
At iterate    13  f =      -671.45  |proj g|=         8.846
At iterate    14  f =      -671.45  |proj g|=        8.8637
At iterate    15  f =      -671.45  |proj g|=         8.891
At iterate    16  f =      -671.46  |proj g|=        8.9312
At iterate    17  f =       -671.5  |proj g|=        8.9874
At iterate    18  f =      -671.59  |proj g|=        9.0541
At iterate    19  f =      -671.82  |proj g|=        9.0951
At iterate    20  f =      -672.41  |proj g|=        8.9944
At iterate    21  f =       -673.7  |proj g|=        8.5072
At iterate    22  f =      -676.14  |proj g|=        7.3669
At iterate    23  f =       -679.9  |proj g|=        4.5163
At iterate    24  f =      -679.96  |proj g|=        5.2185
At iterate    25  f =      -680.05  |proj g|=        4.9736
At iterate    26  f =      -680.06  |proj g|=        4.9257
At iterate    27  f =      -680.06  |proj g|=        4.9362
At iterate    28  f =      -680.06  |proj g|=        4.9902
At iterate    29  f =      -680.08  |proj g|=        5.0532
At iterate    30  f =      -680.12  |proj g|=        5.1521
At iterate    31  f =      -680.15  |proj g|=        5.2937
At iterate    32  f =      -680.27  |proj g|=        5.4009
At iterate    33  f =      -681.77  |proj g|=        5.4893
At iterate    34  f =       -683.8  |proj g|=        5.1513
At iterate    35  f =      -684.11  |proj g|=        4.9824
At iterate    36  f =      -684.13  |proj g|=        5.0211
At iterate    37  f =      -684.13  |proj g|=         5.046
At iterate    38  f =      -684.13  |proj g|=        5.0312
At iterate    39  f =      -684.13  |proj g|=        5.0185
At iterate    40  f =      -684.13  |proj g|=        5.0105
At iterate    41  f =      -684.14  |proj g|=        5.0078
At iterate    42  f =      -684.14  |proj g|=        5.0032
At iterate    43  f =      -684.14  |proj g|=        4.9798
At iterate    44  f =      -684.14  |proj g|=        4.9672
At iterate    45  f =      -684.16  |proj g|=        4.9027
At iterate    46  f =       -684.2  |proj g|=        4.8786
At iterate    47  f =      -684.33  |proj g|=         4.835
At iterate    48  f =      -684.57  |proj g|=         4.866
At iterate    49  f =      -684.59  |proj g|=        4.7504
At iterate    50  f =         -685  |proj g|=        4.8258
At iterate    51  f =      -685.29  |proj g|=        5.8688
At iterate    52  f =      -685.73  |proj g|=        5.4118
At iterate    53  f =      -685.93  |proj g|=        5.2641
At iterate    54  f =      -687.49  |proj g|=        4.3177
At iterate    55  f =      -687.62  |proj g|=        3.9214
At iterate    56  f =      -689.89  |proj g|=        3.0033
At iterate    57  f =      -690.32  |proj g|=        2.9018
At iterate    58  f =      -697.53  |proj g|=        1.6045
At iterate    59  f =      -698.19  |proj g|=        1.9717
At iterate    60  f =      -704.99  |proj g|=        1.5124
At iterate    61  f =       -707.4  |proj g|=       0.55279
At iterate    62  f =      -708.02  |proj g|=        0.2689
At iterate    63  f =      -708.06  |proj g|=       0.70852
At iterate    64  f =      -708.08  |proj g|=       0.70495
At iterate    65  f =      -708.08  |proj g|=       0.70183
At iterate    66  f =      -708.09  |proj g|=      0.081738
At iterate    67  f =      -708.09  |proj g|=       0.69878
At iterate    68  f =      -708.09  |proj g|=       0.51709
At iterate    69  f =       -708.1  |proj g|=       0.11027
At iterate    70  f =       -708.1  |proj g|=      0.021833
At iterate    71  f =       -708.1  |proj g|=     0.0043492

iterations 71
function evaluations 84
segments explored during Cauchy searches 73
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00434921
final function value -708.095

F = -708.095
final  value -708.095103 
converged
 
INFO  [04:13:09.335] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:13:09.392] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:13:09.399] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:13:23.954] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:13:37.344] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:13:50.790] [mlr3]  Finished benchmark 
INFO  [04:13:50.860] [bbotk] Result of batch 134: 
INFO  [04:13:50.862] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:13:50.862] [bbotk]              3.715901                 4.718512                       0.1997076 
INFO  [04:13:50.862] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:13:50.862] [bbotk]                     4542        0.892 -0.9464904         <NA>   0.9710779 
INFO  [04:13:50.862] [bbotk]                                 uhash 
INFO  [04:13:50.862] [bbotk]  9cd0cc47-035f-4c5f-a389-6cb9ec4a66d4 
DEBUG [04:13:52.523] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.195204e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.195204e-05 0.001335112 
  - best initial criterion value(s) :  629.2143 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -629.21  |proj g|=       7.7143
At iterate     1  f =      -679.34  |proj g|=        5.0805
At iterate     2  f =       -679.7  |proj g|=        5.8324
At iterate     3  f =      -679.71  |proj g|=        5.7707
At iterate     4  f =      -679.73  |proj g|=         5.696
At iterate     5  f =      -679.73  |proj g|=        5.7004
At iterate     6  f =      -679.73  |proj g|=        5.7074
At iterate     7  f =      -679.73  |proj g|=        5.7117
At iterate     8  f =      -679.73  |proj g|=        5.7151
At iterate     9  f =      -679.74  |proj g|=        5.7201
At iterate    10  f =      -679.75  |proj g|=        5.7109
At iterate    11  f =      -679.78  |proj g|=         5.663
At iterate    12  f =      -679.83  |proj g|=        5.5467
At iterate    13  f =      -679.83  |proj g|=        5.6425
At iterate    14  f =      -679.94  |proj g|=         5.444
At iterate    15  f =      -680.97  |proj g|=        5.0434
At iterate    16  f =      -694.12  |proj g|=        3.0134
At iterate    17  f =      -702.53  |proj g|=        2.9183
At iterate    18  f =      -708.76  |proj g|=        2.0495
At iterate    19  f =      -713.26  |proj g|=        1.1139
At iterate    20  f =      -713.34  |proj g|=        1.1138
At iterate    21  f =      -713.57  |proj g|=        1.1134
At iterate    22  f =      -713.89  |proj g|=        1.1135
At iterate    23  f =       -713.9  |proj g|=        1.1135
At iterate    24  f =       -713.9  |proj g|=        1.1135
At iterate    25  f =      -713.92  |proj g|=        1.1135
At iterate    26  f =      -713.92  |proj g|=         1.112
At iterate    27  f =      -713.93  |proj g|=        1.1091
At iterate    28  f =      -713.93  |proj g|=        1.1026
At iterate    29  f =      -713.95  |proj g|=        1.0819
At iterate    30  f =      -713.96  |proj g|=        1.0598
At iterate    31  f =         -714  |proj g|=        1.0016
At iterate    32  f =      -714.14  |proj g|=       0.81528
At iterate    33  f =      -714.42  |proj g|=       0.45959
At iterate    34  f =      -714.76  |proj g|=       0.34766
At iterate    35  f =      -714.99  |proj g|=       0.33998
At iterate    36  f =      -715.34  |proj g|=       0.67099
At iterate    37  f =      -715.36  |proj g|=       0.67609
At iterate    38  f =      -715.36  |proj g|=       0.13192
At iterate    39  f =      -715.36  |proj g|=       0.13247
At iterate    40  f =      -715.37  |proj g|=       0.57098
At iterate    41  f =      -715.41  |proj g|=       0.29268
At iterate    42  f =      -715.42  |proj g|=       0.68552
At iterate    43  f =      -715.43  |proj g|=       0.63465
At iterate    44  f =      -715.43  |proj g|=     0.0042766
At iterate    45  f =      -715.43  |proj g|=     0.0020926

iterations 45
function evaluations 57
segments explored during Cauchy searches 48
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0020926
final function value -715.427

F = -715.427
final  value -715.426901 
converged
 
INFO  [04:13:52.527] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:13:52.584] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:13:52.591] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:14:06.289] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:14:21.041] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:14:30.638] [mlr3]  Finished benchmark 
INFO  [04:14:30.708] [bbotk] Result of batch 135: 
INFO  [04:14:30.710] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:14:30.710] [bbotk]              2.854888                 8.208306                       0.2894927 
INFO  [04:14:30.710] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:14:30.710] [bbotk]                     4570        0.822 -0.9447534         <NA>   0.9676543 
INFO  [04:14:30.710] [bbotk]                                 uhash 
INFO  [04:14:30.710] [bbotk]  57fde267-dffb-49ed-ad70-b792ab2c0efb 
DEBUG [04:14:32.234] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.188339e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.188339e-05 0.001326516 
  - best initial criterion value(s) :  637.1896 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -637.19  |proj g|=       9.0697
At iterate     1  f =      -672.96  |proj g|=        10.393
At iterate     2  f =      -677.15  |proj g|=        9.0346
At iterate     3  f =      -693.13  |proj g|=        3.4167
At iterate     4  f =       -693.5  |proj g|=        3.1367
At iterate     5  f =      -693.63  |proj g|=        3.5725
At iterate     6  f =      -693.69  |proj g|=        3.3999
At iterate     7  f =       -693.7  |proj g|=        3.3907
At iterate     8  f =       -693.7  |proj g|=        3.3969
At iterate     9  f =       -693.7  |proj g|=        3.3965
At iterate    10  f =       -693.7  |proj g|=        3.3952
At iterate    11  f =       -693.7  |proj g|=        3.3934
At iterate    12  f =       -693.7  |proj g|=        3.3903
At iterate    13  f =       -693.7  |proj g|=        3.3853
At iterate    14  f =       -693.7  |proj g|=        3.3781
At iterate    15  f =       -693.7  |proj g|=        3.3679
At iterate    16  f =       -693.7  |proj g|=         3.354
At iterate    17  f =      -693.71  |proj g|=        3.3385
At iterate    18  f =      -693.73  |proj g|=        3.2412
At iterate    19  f =      -693.76  |proj g|=        3.2624
At iterate    20  f =      -693.96  |proj g|=        3.3353
At iterate    21  f =      -694.33  |proj g|=        3.4244
At iterate    22  f =      -695.16  |proj g|=        3.5548
At iterate    23  f =       -696.4  |proj g|=        3.6315
At iterate    24  f =      -696.47  |proj g|=        4.0436
At iterate    25  f =      -697.68  |proj g|=        3.8948
At iterate    26  f =      -698.58  |proj g|=        3.7873
At iterate    27  f =       -699.1  |proj g|=        3.6026
At iterate    28  f =      -699.13  |proj g|=        3.5862
At iterate    29  f =      -699.13  |proj g|=        3.5791
At iterate    30  f =      -699.13  |proj g|=        3.5768
At iterate    31  f =      -699.13  |proj g|=        3.5763
At iterate    32  f =      -699.13  |proj g|=        3.5762
At iterate    33  f =      -699.13  |proj g|=        3.5759
At iterate    34  f =      -699.13  |proj g|=        3.5752
At iterate    35  f =      -699.13  |proj g|=        3.5741
At iterate    36  f =      -699.13  |proj g|=        3.5766
At iterate    37  f =      -699.13  |proj g|=        3.5676
At iterate    38  f =      -699.13  |proj g|=        3.5707
At iterate    39  f =      -699.14  |proj g|=        3.5749
At iterate    40  f =      -699.23  |proj g|=        3.5563
At iterate    41  f =      -699.68  |proj g|=        3.4781
At iterate    42  f =      -700.28  |proj g|=         3.288
At iterate    43  f =      -700.29  |proj g|=        3.6931
At iterate    44  f =      -703.13  |proj g|=        2.4194
At iterate    45  f =      -703.14  |proj g|=         2.369
At iterate    46  f =      -703.14  |proj g|=        2.3385
At iterate    47  f =      -703.14  |proj g|=        2.3395
At iterate    48  f =      -703.14  |proj g|=        2.3393

iterations 48
function evaluations 58
segments explored during Cauchy searches 50
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.33926
final function value -703.14

F = -703.14
final  value -703.140245 
converged
 
INFO  [04:14:32.238] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:14:32.293] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:14:32.300] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:14:33.763] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:14:35.296] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:14:36.797] [mlr3]  Finished benchmark 
INFO  [04:14:36.879] [bbotk] Result of batch 136: 
INFO  [04:14:36.881] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:14:36.881] [bbotk]              8.520588                 9.320553                      0.03598605 
INFO  [04:14:36.881] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:14:36.881] [bbotk]                      526         0.82 -0.9491122         <NA>   0.9338758 
INFO  [04:14:36.881] [bbotk]                                 uhash 
INFO  [04:14:36.881] [bbotk]  92cecbbc-0fb3-4fa5-a4ed-932983a51dd2 
DEBUG [04:14:38.247] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.23979e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.23979e-05 0.001400325 
  - best initial criterion value(s) :  676.9991 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         -677  |proj g|=       5.7107
At iterate     1  f =      -684.04  |proj g|=        8.0392
At iterate     2  f =      -685.43  |proj g|=         7.876
At iterate     3  f =      -686.16  |proj g|=        6.9139
At iterate     4  f =      -686.46  |proj g|=         7.222
At iterate     5  f =      -686.56  |proj g|=         7.079
At iterate     6  f =      -686.89  |proj g|=        6.2489
At iterate     7  f =       -686.9  |proj g|=        6.2708
At iterate     8  f =       -686.9  |proj g|=        6.2699
At iterate     9  f =       -686.9  |proj g|=        6.2672
At iterate    10  f =       -686.9  |proj g|=        6.2623
At iterate    11  f =       -686.9  |proj g|=        6.2544
At iterate    12  f =       -686.9  |proj g|=        6.2368
At iterate    13  f =      -686.91  |proj g|=        6.2048
At iterate    14  f =      -686.94  |proj g|=        6.1349
At iterate    15  f =         -687  |proj g|=        6.0804
At iterate    16  f =      -687.16  |proj g|=        5.8484
At iterate    17  f =      -687.23  |proj g|=        6.0084
At iterate    18  f =       -687.7  |proj g|=        5.5875
At iterate    19  f =      -693.13  |proj g|=        4.1875
At iterate    20  f =      -703.85  |proj g|=        2.9181
At iterate    21  f =      -705.66  |proj g|=        3.4468
At iterate    22  f =       -707.2  |proj g|=        4.4316
At iterate    23  f =      -707.31  |proj g|=        4.2637
At iterate    24  f =       -707.8  |proj g|=         5.219
At iterate    25  f =      -707.86  |proj g|=        5.3162
At iterate    26  f =      -707.94  |proj g|=        5.2646
At iterate    27  f =      -707.95  |proj g|=        5.1794
At iterate    28  f =      -707.95  |proj g|=        5.1456
At iterate    29  f =      -707.95  |proj g|=         5.147
At iterate    30  f =      -707.95  |proj g|=        5.1475

iterations 30
function evaluations 35
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 5.14752
final function value -707.952

F = -707.952
final  value -707.951678 
converged
 
INFO  [04:14:38.251] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:14:38.366] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:14:38.375] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:14:40.840] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:14:43.147] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:14:45.528] [mlr3]  Finished benchmark 
INFO  [04:14:45.598] [bbotk] Result of batch 137: 
INFO  [04:14:45.600] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:14:45.600] [bbotk]              8.961981                  7.94121                       0.4253839 
INFO  [04:14:45.600] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:14:45.600] [bbotk]                     1076        0.833 -0.9550385         <NA>   0.9717705 
INFO  [04:14:45.600] [bbotk]                                 uhash 
INFO  [04:14:45.600] [bbotk]  fd6ce6ad-48ad-4817-b902-d7701f87d071 
DEBUG [04:14:46.932] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.235116e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.235115e-05 0.001390075 
  - best initial criterion value(s) :  671.5451 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -671.55  |proj g|=       5.1463
At iterate     1  f =       -695.2  |proj g|=         10.42
At iterate     2  f =      -702.14  |proj g|=        8.6123
At iterate     3  f =      -708.16  |proj g|=        3.2314
At iterate     4  f =      -709.86  |proj g|=        4.6632
At iterate     5  f =      -711.23  |proj g|=        4.7918
At iterate     6  f =         -718  |proj g|=        3.7176
At iterate     7  f =      -718.87  |proj g|=        3.7078
At iterate     8  f =      -718.89  |proj g|=        3.8152
At iterate     9  f =      -718.89  |proj g|=        3.8531
At iterate    10  f =      -718.89  |proj g|=        3.8547
At iterate    11  f =      -718.89  |proj g|=        3.8551

iterations 11
function evaluations 13
segments explored during Cauchy searches 13
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 3.85513
final function value -718.889

F = -718.889
final  value -718.888575 
converged
 
INFO  [04:14:46.937] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:14:46.994] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:14:47.001] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:14:50.783] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:14:54.463] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:14:58.839] [mlr3]  Finished benchmark 
INFO  [04:14:58.913] [bbotk] Result of batch 138: 
INFO  [04:14:58.915] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:14:58.915] [bbotk]              5.893008                 3.718813                       0.2504589 
INFO  [04:14:58.915] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:14:58.915] [bbotk]                     1855        0.951 -0.9522619         <NA>   0.9716452 
INFO  [04:14:58.915] [bbotk]                                 uhash 
INFO  [04:14:58.915] [bbotk]  e8b72f0b-60d2-4054-ab21-e71d93981dd6 
DEBUG [04:15:00.739] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.230365e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.230365e-05 0.00138324 
  - best initial criterion value(s) :  661.182 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -661.18  |proj g|=       4.4699
At iterate     1  f =      -683.79  |proj g|=        8.0643
At iterate     2  f =      -687.13  |proj g|=        7.3879
At iterate     3  f =      -689.79  |proj g|=        6.2732
At iterate     4  f =      -690.07  |proj g|=        5.4874
At iterate     5  f =       -690.2  |proj g|=        5.7611
At iterate     6  f =      -690.33  |proj g|=        5.8937
At iterate     7  f =      -690.85  |proj g|=        6.2474
At iterate     8  f =      -691.06  |proj g|=        6.1639
At iterate     9  f =      -691.08  |proj g|=         6.038
At iterate    10  f =      -691.08  |proj g|=        6.0222
At iterate    11  f =      -691.08  |proj g|=        6.0219
At iterate    12  f =      -691.08  |proj g|=        6.0222
At iterate    13  f =      -691.08  |proj g|=        6.0227
At iterate    14  f =      -691.08  |proj g|=        6.0235
At iterate    15  f =      -691.08  |proj g|=        6.0402
At iterate    16  f =      -691.08  |proj g|=        6.0306
At iterate    17  f =      -691.08  |proj g|=        6.0203
At iterate    18  f =       -691.1  |proj g|=        5.9811
At iterate    19  f =      -691.13  |proj g|=         5.925
At iterate    20  f =      -691.23  |proj g|=        5.8033
At iterate    21  f =      -691.49  |proj g|=        5.5922
At iterate    22  f =      -692.14  |proj g|=        5.2375
At iterate    23  f =      -693.42  |proj g|=        4.5381
At iterate    24  f =      -694.06  |proj g|=        4.8027
At iterate    25  f =      -695.28  |proj g|=        4.1079
At iterate    26  f =      -696.15  |proj g|=        3.6635
At iterate    27  f =      -696.19  |proj g|=        3.8286
At iterate    28  f =      -696.39  |proj g|=        3.6949
At iterate    29  f =      -696.49  |proj g|=        3.6626
At iterate    30  f =       -696.5  |proj g|=        3.7113
At iterate    31  f =       -696.5  |proj g|=        3.6839
At iterate    32  f =       -696.5  |proj g|=        3.6873
At iterate    33  f =       -696.5  |proj g|=        3.6902
At iterate    34  f =       -696.5  |proj g|=        3.6906

iterations 34
function evaluations 41
segments explored during Cauchy searches 36
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.69058
final function value -696.505

F = -696.505
final  value -696.504954 
converged
 
INFO  [04:15:00.744] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:15:00.801] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:15:00.836] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:15:06.234] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:15:11.506] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:15:16.839] [mlr3]  Finished benchmark 
INFO  [04:15:16.923] [bbotk] Result of batch 139: 
INFO  [04:15:16.925] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:15:16.925] [bbotk]               7.85564                 8.359898                      0.07113578 
INFO  [04:15:16.925] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:15:16.925] [bbotk]                     2635        0.918 -0.9551693         <NA>   0.9665491 
INFO  [04:15:16.925] [bbotk]                                 uhash 
INFO  [04:15:16.925] [bbotk]  5cc0e44b-eaf2-4be5-a314-83542892a54d 
DEBUG [04:15:18.236] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.223217e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.223217e-05 0.001377617 
  - best initial criterion value(s) :  668.3983 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -668.4  |proj g|=       11.597
At iterate     1  f =      -686.21  |proj g|=        9.3449
At iterate     2  f =       -692.1  |proj g|=        7.4374
At iterate     3  f =      -705.39  |proj g|=       0.58073
At iterate     4  f =      -705.77  |proj g|=        1.7614
At iterate     5  f =      -706.16  |proj g|=        1.1121
At iterate     6  f =      -706.18  |proj g|=       0.93625
At iterate     7  f =      -706.18  |proj g|=       0.94934
At iterate     8  f =      -706.18  |proj g|=       0.94843
At iterate     9  f =      -706.18  |proj g|=       0.94835

iterations 9
function evaluations 11
segments explored during Cauchy searches 11
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.948355
final function value -706.179

F = -706.179
final  value -706.178716 
converged
 
INFO  [04:15:18.240] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:15:18.295] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:15:18.302] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:15:26.981] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:15:35.615] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:15:47.881] [mlr3]  Finished benchmark 
INFO  [04:15:47.952] [bbotk] Result of batch 140: 
INFO  [04:15:47.954] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:15:47.954] [bbotk]              8.222632                 3.599676                        0.468425 
INFO  [04:15:47.954] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:15:47.954] [bbotk]                     4178        0.944 -0.9589272         <NA>   0.9743501 
INFO  [04:15:47.954] [bbotk]                                 uhash 
INFO  [04:15:47.954] [bbotk]  d36aaf8f-9c9d-4cdc-a48b-474ab33506cf 
DEBUG [04:15:49.294] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.221066e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.221066e-05 0.001376921 
  - best initial criterion value(s) :  686.4453 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -686.45  |proj g|=       8.0811
At iterate     1  f =      -707.79  |proj g|=        4.1146
At iterate     2  f =      -708.66  |proj g|=        6.9741
At iterate     3  f =      -710.11  |proj g|=        5.6564
At iterate     4  f =      -710.16  |proj g|=        5.6243
At iterate     5  f =      -710.33  |proj g|=        5.5866
At iterate     6  f =      -710.37  |proj g|=        5.7437
At iterate     7  f =      -710.37  |proj g|=        5.7962
At iterate     8  f =      -710.37  |proj g|=        5.7973
At iterate     9  f =      -710.37  |proj g|=        5.8032
At iterate    10  f =      -710.37  |proj g|=        5.8086
At iterate    11  f =      -710.39  |proj g|=        5.8166
At iterate    12  f =      -710.41  |proj g|=        5.8782
At iterate    13  f =      -710.42  |proj g|=        5.7813
At iterate    14  f =       -710.5  |proj g|=         5.828
At iterate    15  f =      -726.98  |proj g|=        5.8603
At iterate    16  f =      -731.56  |proj g|=        4.1702
At iterate    17  f =      -733.33  |proj g|=        4.5753
At iterate    18  f =      -734.04  |proj g|=        4.6964
At iterate    19  f =      -734.34  |proj g|=        4.0971
At iterate    20  f =      -734.37  |proj g|=        4.1443
At iterate    21  f =      -734.37  |proj g|=        4.1004
At iterate    22  f =      -734.37  |proj g|=        4.1057
At iterate    23  f =      -734.37  |proj g|=        4.1046

iterations 23
function evaluations 28
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 4.10459
final function value -734.373

F = -734.373
final  value -734.372963 
converged
 
INFO  [04:15:49.298] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:15:49.355] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:15:49.362] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:15:52.741] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:15:54.988] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:15:56.962] [mlr3]  Finished benchmark 
INFO  [04:15:57.036] [bbotk] Result of batch 141: 
INFO  [04:15:57.038] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:15:57.038] [bbotk]              8.421978                 9.740284                       0.4859691 
INFO  [04:15:57.038] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:15:57.038] [bbotk]                      726        0.849 -0.9529608         <NA>   0.9707774 
INFO  [04:15:57.038] [bbotk]                                 uhash 
INFO  [04:15:57.038] [bbotk]  31b72809-0757-47ee-8220-dccc7ef73827 
DEBUG [04:15:58.407] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.215788e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.215788e-05 0.001366463 
  - best initial criterion value(s) :  654.1774 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -654.18  |proj g|=       10.471
At iterate     1  f =      -673.41  |proj g|=        9.3536
At iterate     2  f =      -721.88  |proj g|=        4.0383
At iterate     3  f =      -723.33  |proj g|=        3.2986
At iterate     4  f =      -727.93  |proj g|=        2.1939
At iterate     5  f =      -730.22  |proj g|=        3.3835
At iterate     6  f =      -732.82  |proj g|=        2.5215
At iterate     7  f =      -733.07  |proj g|=        2.2331
At iterate     8  f =      -733.08  |proj g|=        2.1316
At iterate     9  f =      -733.09  |proj g|=        2.1476
At iterate    10  f =      -733.09  |proj g|=        2.1471
At iterate    11  f =      -733.09  |proj g|=        2.1423
At iterate    12  f =      -733.09  |proj g|=        2.1314
At iterate    13  f =      -733.09  |proj g|=        2.1104
At iterate    14  f =       -733.1  |proj g|=        2.0791
At iterate    15  f =      -733.11  |proj g|=         2.032
At iterate    16  f =      -733.15  |proj g|=        1.9787
At iterate    17  f =      -733.21  |proj g|=         1.962
At iterate    18  f =      -733.24  |proj g|=        2.1055
At iterate    19  f =      -733.25  |proj g|=        2.0823
At iterate    20  f =      -733.25  |proj g|=        2.0823
At iterate    21  f =      -733.25  |proj g|=        2.0825

iterations 21
function evaluations 28
segments explored during Cauchy searches 24
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.08245
final function value -733.252

F = -733.252
final  value -733.251892 
converged
 
INFO  [04:15:58.411] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:15:58.466] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:15:58.473] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:16:02.278] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:16:06.944] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:16:13.327] [mlr3]  Finished benchmark 
INFO  [04:16:13.394] [bbotk] Result of batch 142: 
INFO  [04:16:13.396] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:16:13.396] [bbotk]              6.566913                 6.796309                       0.2697492 
INFO  [04:16:13.396] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:16:13.396] [bbotk]                     1354        0.872 -0.9494066         <NA>   0.9705801 
INFO  [04:16:13.396] [bbotk]                                 uhash 
INFO  [04:16:13.396] [bbotk]  4922ee9c-fdec-430c-bf86-19871a60dc1e 
DEBUG [04:16:15.201] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.210424e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.210424e-05 0.001356896 
  - best initial criterion value(s) :  699.3972 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -699.4  |proj g|=       2.0599
At iterate     1  f =      -717.34  |proj g|=        11.502
At iterate     2  f =      -722.27  |proj g|=        10.948
At iterate     3  f =      -726.83  |proj g|=        8.4689
At iterate     4  f =      -726.89  |proj g|=        8.1038
At iterate     5  f =      -727.06  |proj g|=        8.2082
At iterate     6  f =       -727.6  |proj g|=        8.1097
At iterate     7  f =      -727.67  |proj g|=        8.0123
At iterate     8  f =      -727.67  |proj g|=        8.0995
At iterate     9  f =      -727.68  |proj g|=        8.0552
At iterate    10  f =      -727.68  |proj g|=        8.0409
At iterate    11  f =      -727.76  |proj g|=        7.9929
At iterate    12  f =      -728.45  |proj g|=        7.5025
At iterate    13  f =      -730.13  |proj g|=        6.6199
At iterate    14  f =      -730.14  |proj g|=         6.967
At iterate    15  f =      -733.47  |proj g|=        5.2609
At iterate    16  f =      -736.04  |proj g|=        5.1193
At iterate    17  f =      -740.08  |proj g|=        4.3601
At iterate    18  f =      -741.06  |proj g|=        4.1993
At iterate    19  f =       -741.1  |proj g|=        4.3984
At iterate    20  f =       -741.1  |proj g|=        4.3466
At iterate    21  f =       -741.1  |proj g|=        4.3619
At iterate    22  f =       -741.1  |proj g|=        4.3614
At iterate    23  f =       -741.1  |proj g|=        4.3594
At iterate    24  f =       -741.1  |proj g|=        4.3575
At iterate    25  f =       -741.1  |proj g|=        4.3566
At iterate    26  f =       -741.1  |proj g|=         4.347
At iterate    27  f =       -741.1  |proj g|=        4.3468
At iterate    28  f =       -741.1  |proj g|=        4.3443
At iterate    29  f =      -741.11  |proj g|=        4.3406
At iterate    30  f =      -741.12  |proj g|=         4.331
At iterate    31  f =      -741.14  |proj g|=        4.3102
At iterate    32  f =      -741.21  |proj g|=        4.2396
At iterate    33  f =      -741.24  |proj g|=        4.4199
At iterate    34  f =      -741.44  |proj g|=         4.205
At iterate    35  f =       -742.2  |proj g|=        3.5686
At iterate    36  f =      -744.31  |proj g|=        2.4955
At iterate    37  f =      -750.28  |proj g|=       0.80609
At iterate    38  f =      -752.03  |proj g|=       0.24663
At iterate    39  f =      -752.24  |proj g|=       0.72776
At iterate    40  f =       -752.9  |proj g|=       0.70394
At iterate    41  f =      -752.94  |proj g|=       0.28266
At iterate    42  f =      -752.94  |proj g|=       0.28479
At iterate    43  f =      -752.94  |proj g|=       0.28543
At iterate    44  f =      -752.94  |proj g|=      0.026246
At iterate    45  f =      -752.94  |proj g|=      0.022436

iterations 45
function evaluations 58
segments explored during Cauchy searches 47
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0224358
final function value -752.945

F = -752.945
final  value -752.944519 
converged
 
INFO  [04:16:15.206] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:16:15.262] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:16:15.268] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:16:25.719] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:16:35.633] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:16:44.836] [mlr3]  Finished benchmark 
INFO  [04:16:44.905] [bbotk] Result of batch 143: 
INFO  [04:16:44.907] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:16:44.907] [bbotk]              5.491012                 6.918112                       0.2876125 
INFO  [04:16:44.907] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:16:44.907] [bbotk]                     3395         0.84 -0.9469714         <NA>   0.9741407 
INFO  [04:16:44.907] [bbotk]                                 uhash 
INFO  [04:16:44.907] [bbotk]  87a029e1-6fee-4ea9-b9e3-1a93284ef387 
DEBUG [04:16:46.268] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.208041e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.208041e-05 0.001355471 
  - best initial criterion value(s) :  680.4048 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -680.4  |proj g|=       7.8238
At iterate     1  f =      -696.23  |proj g|=        8.7025
At iterate     2  f =      -701.25  |proj g|=        8.8208
At iterate     3  f =      -709.01  |proj g|=         7.735
At iterate     4  f =      -709.13  |proj g|=         7.509
At iterate     5  f =      -709.14  |proj g|=        7.4797
At iterate     6  f =      -709.14  |proj g|=        7.3862
At iterate     7  f =      -709.14  |proj g|=        7.3753
At iterate     8  f =      -709.15  |proj g|=        7.3573
At iterate     9  f =      -709.16  |proj g|=        7.3455
At iterate    10  f =      -709.18  |proj g|=        7.3123
At iterate    11  f =      -709.25  |proj g|=        7.2316
At iterate    12  f =      -709.42  |proj g|=        7.0668
At iterate    13  f =      -709.82  |proj g|=          6.75
At iterate    14  f =      -710.78  |proj g|=        6.1403
At iterate    15  f =      -712.89  |proj g|=        5.3553
At iterate    16  f =      -716.96  |proj g|=        3.4674
At iterate    17  f =      -720.84  |proj g|=        3.2651
At iterate    18  f =      -726.98  |proj g|=        2.9426
At iterate    19  f =      -735.37  |proj g|=        2.6887
At iterate    20  f =      -737.74  |proj g|=        2.5998
At iterate    21  f =      -738.47  |proj g|=        3.1893
At iterate    22  f =      -738.79  |proj g|=        2.7777
At iterate    23  f =      -738.82  |proj g|=        2.7464
At iterate    24  f =      -738.82  |proj g|=        2.7443
At iterate    25  f =      -738.82  |proj g|=        2.7442

iterations 25
function evaluations 29
segments explored during Cauchy searches 28
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.74421
final function value -738.82

F = -738.82
final  value -738.820031 
converged
 
INFO  [04:16:46.272] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:16:46.330] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:16:46.337] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:16:52.483] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:16:59.636] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:17:05.910] [mlr3]  Finished benchmark 
INFO  [04:17:05.978] [bbotk] Result of batch 144: 
INFO  [04:17:05.980] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:17:05.980] [bbotk]              5.824004                 6.020664                       0.1897738 
INFO  [04:17:05.980] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:17:05.980] [bbotk]                     2196         0.85 -0.9551863         <NA>   0.9711485 
INFO  [04:17:05.980] [bbotk]                                 uhash 
INFO  [04:17:05.980] [bbotk]  b44b1a5a-6e94-4509-bc7b-9b6aba872a42 
DEBUG [04:17:07.201] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.203098e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.203098e-05 0.001354821 
  - best initial criterion value(s) :  734.9705 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -734.97  |proj g|=       1.7447
At iterate     1  f =      -735.95  |proj g|=        1.2065
At iterate     2  f =      -736.76  |proj g|=         1.836
At iterate     3  f =      -736.98  |proj g|=         2.122
At iterate     4  f =      -737.01  |proj g|=         2.246
At iterate     5  f =      -737.01  |proj g|=        2.2787
At iterate     6  f =      -737.01  |proj g|=        2.2832
At iterate     7  f =      -737.01  |proj g|=        2.2837

iterations 7
function evaluations 10
segments explored during Cauchy searches 9
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.28372
final function value -737.009

F = -737.009
final  value -737.009086 
converged
 
INFO  [04:17:07.205] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:17:07.264] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:17:07.287] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:17:11.663] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:17:15.024] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:17:18.278] [mlr3]  Finished benchmark 
INFO  [04:17:18.345] [bbotk] Result of batch 145: 
INFO  [04:17:18.347] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:17:18.347] [bbotk]              4.514023                  6.60315                       0.2772589 
INFO  [04:17:18.347] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:17:18.347] [bbotk]                     1252        0.881 -0.9578019         <NA>    0.968645 
INFO  [04:17:18.347] [bbotk]                                 uhash 
INFO  [04:17:18.347] [bbotk]  22f094c0-b343-470e-9a3a-22ba08862573 
DEBUG [04:17:20.163] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.196872e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.196872e-05 0.001345178 
  - best initial criterion value(s) :  685.4697 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -685.47  |proj g|=       12.078
At iterate     1  f =      -715.12  |proj g|=        8.7491
At iterate     2  f =      -727.45  |proj g|=        5.5859
At iterate     3  f =      -729.12  |proj g|=        4.1108
At iterate     4  f =      -730.68  |proj g|=        3.4389
At iterate     5  f =      -731.47  |proj g|=        2.9701
At iterate     6  f =      -731.48  |proj g|=        2.8499
At iterate     7  f =      -731.48  |proj g|=        2.8609
At iterate     8  f =      -731.48  |proj g|=        2.8624
At iterate     9  f =      -731.48  |proj g|=        2.8642
At iterate    10  f =      -731.51  |proj g|=        2.8818
At iterate    11  f =      -731.56  |proj g|=        2.8958
At iterate    12  f =      -731.72  |proj g|=        2.9095
At iterate    13  f =      -732.09  |proj g|=        3.0019
At iterate    14  f =      -732.16  |proj g|=        2.7665
At iterate    15  f =      -732.99  |proj g|=         2.762
At iterate    16  f =      -741.92  |proj g|=        1.1552
At iterate    17  f =      -742.92  |proj g|=        1.2747
At iterate    18  f =      -743.33  |proj g|=        1.9174
At iterate    19  f =      -743.49  |proj g|=        2.0724
At iterate    20  f =      -743.54  |proj g|=          1.87
At iterate    21  f =       -743.6  |proj g|=        1.9371
At iterate    22  f =      -743.62  |proj g|=        1.9016
At iterate    23  f =      -743.66  |proj g|=        1.7822
At iterate    24  f =      -743.66  |proj g|=        1.7884
At iterate    25  f =      -743.66  |proj g|=        1.7914
At iterate    26  f =      -743.66  |proj g|=         1.791
At iterate    27  f =      -743.66  |proj g|=        1.8034
At iterate    28  f =      -743.66  |proj g|=        1.8092
At iterate    29  f =      -743.67  |proj g|=        1.8462
At iterate    30  f =      -743.68  |proj g|=        1.8844
At iterate    31  f =      -743.71  |proj g|=        1.9391
At iterate    32  f =      -743.78  |proj g|=        2.0053
At iterate    33  f =      -743.93  |proj g|=        1.8795
At iterate    34  f =      -743.98  |proj g|=         2.078
At iterate    35  f =      -744.34  |proj g|=        1.8291
At iterate    36  f =       -744.8  |proj g|=        1.1113
At iterate    37  f =      -745.27  |proj g|=       0.90661
At iterate    38  f =      -746.04  |proj g|=       0.21179
At iterate    39  f =      -746.05  |proj g|=       0.21038
At iterate    40  f =      -746.08  |proj g|=       0.21205
At iterate    41  f =      -746.08  |proj g|=        0.1854
At iterate    42  f =      -746.08  |proj g|=      0.023748
At iterate    43  f =      -746.08  |proj g|=      0.023748

iterations 43
function evaluations 54
segments explored during Cauchy searches 46
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0237483
final function value -746.08

F = -746.08
final  value -746.080393 
converged
 
INFO  [04:17:20.167] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:17:20.223] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:17:20.230] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:17:28.689] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:17:37.777] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:17:46.414] [mlr3]  Finished benchmark 
INFO  [04:17:46.513] [bbotk] Result of batch 146: 
INFO  [04:17:46.515] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:17:46.515] [bbotk]              4.369829                 6.273721                       0.2683027 
INFO  [04:17:46.515] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:17:46.515] [bbotk]                     3052        1.071 -0.9549662         <NA>   0.9723561 
INFO  [04:17:46.515] [bbotk]                                 uhash 
INFO  [04:17:46.515] [bbotk]  0cae68e5-56c3-46e1-a15f-2134bbad13ad 
DEBUG [04:17:47.721] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.192896e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.192896e-05 0.001343097 
  - best initial criterion value(s) :  721.9234 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -721.92  |proj g|=       3.5396
At iterate     1  f =      -749.64  |proj g|=        2.2696
At iterate     2  f =      -755.39  |proj g|=        4.6572
At iterate     3  f =      -756.03  |proj g|=        4.3301
At iterate     4  f =      -756.16  |proj g|=        3.6706
At iterate     5  f =      -756.22  |proj g|=        3.9988
At iterate     6  f =      -756.22  |proj g|=        3.9437
At iterate     7  f =      -756.22  |proj g|=        3.9357
At iterate     8  f =      -756.22  |proj g|=        3.9359

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.93586
final function value -756.224

F = -756.224
final  value -756.223804 
converged
 
INFO  [04:17:47.726] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:17:47.789] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:17:47.821] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:17:53.658] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:17:59.869] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:18:06.235] [mlr3]  Finished benchmark 
INFO  [04:18:06.335] [bbotk] Result of batch 147: 
INFO  [04:18:06.337] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:18:06.337] [bbotk]              3.037637                 2.648883                       0.1042076 
INFO  [04:18:06.337] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:18:06.337] [bbotk]                     3060        0.848 -0.9523562         <NA>   0.9606469 
INFO  [04:18:06.337] [bbotk]                                 uhash 
INFO  [04:18:06.337] [bbotk]  1f2e9d24-bd38-410a-904d-c09d84c15c9f 
DEBUG [04:18:07.912] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.187386e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.187386e-05 0.001336573 
  - best initial criterion value(s) :  702.843 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -702.84  |proj g|=       8.4034
At iterate     1  f =      -756.96  |proj g|=       0.86397
At iterate     2  f =      -763.74  |proj g|=        1.5989
At iterate     3  f =      -770.39  |proj g|=         2.842
At iterate     4  f =      -770.43  |proj g|=        2.9501
At iterate     5  f =      -770.45  |proj g|=         2.926
At iterate     6  f =      -770.45  |proj g|=        2.9391
At iterate     7  f =      -770.46  |proj g|=        3.0319
At iterate     8  f =      -770.46  |proj g|=        3.0351
At iterate     9  f =      -770.46  |proj g|=        3.0359
At iterate    10  f =      -770.46  |proj g|=        3.0392
At iterate    11  f =      -770.46  |proj g|=        3.0432
At iterate    12  f =      -770.46  |proj g|=        3.0505
At iterate    13  f =      -770.46  |proj g|=        3.0616
At iterate    14  f =      -770.46  |proj g|=        3.0786
At iterate    15  f =      -770.46  |proj g|=        3.1008
At iterate    16  f =      -770.47  |proj g|=        3.1339
At iterate    17  f =      -770.48  |proj g|=        3.1624
At iterate    18  f =      -770.48  |proj g|=        3.2192
At iterate    19  f =       -770.5  |proj g|=        3.2353
At iterate    20  f =      -770.61  |proj g|=        3.2464
At iterate    21  f =      -771.06  |proj g|=        3.1477
At iterate    22  f =      -772.28  |proj g|=        2.6555
At iterate    23  f =      -774.09  |proj g|=        1.7715
At iterate    24  f =      -774.51  |proj g|=        2.0104
At iterate    25  f =       -776.3  |proj g|=        0.9626
At iterate    26  f =      -777.89  |proj g|=         0.833
At iterate    27  f =      -778.92  |proj g|=        1.1089
At iterate    28  f =      -779.31  |proj g|=        1.3718
At iterate    29  f =      -779.34  |proj g|=        1.3662
At iterate    30  f =      -779.35  |proj g|=        1.3478
At iterate    31  f =      -779.35  |proj g|=        1.3479
At iterate    32  f =      -779.35  |proj g|=        1.3501
At iterate    33  f =      -779.35  |proj g|=        1.3503
At iterate    34  f =      -779.35  |proj g|=        1.3503

iterations 34
function evaluations 39
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.35027
final function value -779.351

F = -779.351
final  value -779.350737 
converged
 
INFO  [04:18:07.916] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:18:07.972] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:18:07.979] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:18:12.421] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:18:17.010] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:18:21.454] [mlr3]  Finished benchmark 
INFO  [04:18:21.524] [bbotk] Result of batch 148: 
INFO  [04:18:21.526] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:18:21.526] [bbotk]              5.332193                 9.001603                       0.1127794 
INFO  [04:18:21.526] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:18:21.526] [bbotk]                     2252        0.908 -0.9439167         <NA>   0.9677469 
INFO  [04:18:21.526] [bbotk]                                 uhash 
INFO  [04:18:21.526] [bbotk]  5451e292-5b02-42a0-b61c-ad498edd27a5 
DEBUG [04:18:23.180] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.18105e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.18105e-05 0.001332794 
  - best initial criterion value(s) :  662.7259 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -662.73  |proj g|=       11.973
At iterate     1  f =      -667.68  |proj g|=         6.714
At iterate     2  f =      -694.89  |proj g|=        9.1702
At iterate     3  f =       -707.4  |proj g|=        8.6262
At iterate     4  f =      -713.77  |proj g|=        5.7924
At iterate     5  f =      -718.01  |proj g|=        3.6077
At iterate     6  f =      -718.34  |proj g|=         2.849
At iterate     7  f =      -718.43  |proj g|=        2.9402
At iterate     8  f =      -718.44  |proj g|=        2.9299
At iterate     9  f =      -718.44  |proj g|=         2.926
At iterate    10  f =      -718.44  |proj g|=        2.9252
At iterate    11  f =      -718.44  |proj g|=        2.9208
At iterate    12  f =      -718.44  |proj g|=        2.9153
At iterate    13  f =      -718.44  |proj g|=        2.9055
At iterate    14  f =      -718.44  |proj g|=        2.8896
At iterate    15  f =      -718.44  |proj g|=        2.8637
At iterate    16  f =      -718.45  |proj g|=         2.827
At iterate    17  f =      -718.46  |proj g|=        2.7655
At iterate    18  f =       -718.5  |proj g|=        2.6914
At iterate    19  f =      -718.63  |proj g|=        2.5369
At iterate    20  f =      -718.87  |proj g|=        2.3929
At iterate    21  f =      -719.11  |proj g|=        1.8132
At iterate    22  f =      -719.92  |proj g|=        1.9611
At iterate    23  f =       -721.7  |proj g|=        2.0302
At iterate    24  f =       -724.4  |proj g|=        2.3225
At iterate    25  f =      -725.97  |proj g|=        2.6233
At iterate    26  f =      -726.03  |proj g|=        2.1391
At iterate    27  f =      -726.29  |proj g|=        1.7066
At iterate    28  f =      -726.68  |proj g|=        2.0531
At iterate    29  f =      -726.73  |proj g|=        2.1253
At iterate    30  f =      -726.74  |proj g|=        2.1631
At iterate    31  f =      -726.74  |proj g|=        2.1587
At iterate    32  f =      -726.74  |proj g|=        2.1588

iterations 32
function evaluations 40
segments explored during Cauchy searches 37
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.15882
final function value -726.736

F = -726.736
final  value -726.735556 
converged
 
INFO  [04:18:23.184] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:18:23.241] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:18:23.248] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:18:31.558] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:18:40.022] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:18:48.284] [mlr3]  Finished benchmark 
INFO  [04:18:48.386] [bbotk] Result of batch 149: 
INFO  [04:18:48.387] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:18:48.387] [bbotk]              6.697811                 2.518233                       0.3720328 
INFO  [04:18:48.387] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:18:48.387] [bbotk]                     4123        1.026 -0.9621231         <NA>   0.9758142 
INFO  [04:18:48.387] [bbotk]                                 uhash 
INFO  [04:18:48.387] [bbotk]  2e291593-ec11-4287-a5fc-9c5a9a280eb3 
DEBUG [04:18:49.801] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.180579e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.180579e-05 0.001334506 
  - best initial criterion value(s) :  710.2561 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -710.26  |proj g|=       5.8877
At iterate     1  f =      -724.11  |proj g|=        1.7332
At iterate     2  f =      -724.29  |proj g|=        1.7394
At iterate     3  f =      -724.39  |proj g|=        2.0355
At iterate     4  f =      -724.45  |proj g|=        1.9437
At iterate     5  f =      -724.65  |proj g|=        1.7963
At iterate     6  f =      -724.89  |proj g|=        1.7362
At iterate     7  f =      -724.95  |proj g|=        1.9522
At iterate     8  f =      -724.97  |proj g|=        1.8649
At iterate     9  f =      -724.97  |proj g|=        1.8545
At iterate    10  f =      -724.97  |proj g|=        1.8534
At iterate    11  f =      -724.97  |proj g|=        1.8561
At iterate    12  f =      -724.97  |proj g|=        1.8625
At iterate    13  f =      -724.97  |proj g|=        1.8763
At iterate    14  f =      -724.98  |proj g|=        1.8917
At iterate    15  f =         -725  |proj g|=        1.9081
At iterate    16  f =      -725.05  |proj g|=        1.9514
At iterate    17  f =      -725.18  |proj g|=        1.9425
At iterate    18  f =      -725.38  |proj g|=        2.1656
At iterate    19  f =      -725.81  |proj g|=        1.9667
At iterate    20  f =      -727.45  |proj g|=        1.1122
At iterate    21  f =      -728.22  |proj g|=       0.99487
At iterate    22  f =      -728.52  |proj g|=        1.0388
At iterate    23  f =      -728.66  |proj g|=        1.0491
At iterate    24  f =       -728.7  |proj g|=        1.1405
At iterate    25  f =      -728.72  |proj g|=         1.092
At iterate    26  f =      -728.72  |proj g|=        1.0911
At iterate    27  f =      -728.72  |proj g|=        1.0966
At iterate    28  f =      -728.72  |proj g|=        1.0961

iterations 28
function evaluations 35
segments explored during Cauchy searches 30
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.09613
final function value -728.716

F = -728.716
final  value -728.716206 
converged
 
INFO  [04:18:49.806] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:18:49.879] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:18:49.886] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:18:54.392] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:19:01.495] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:19:06.694] [mlr3]  Finished benchmark 
INFO  [04:19:06.807] [bbotk] Result of batch 150: 
INFO  [04:19:06.809] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:19:06.809] [bbotk]              7.835925                 7.797354                       0.1350365 
INFO  [04:19:06.809] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:19:06.809] [bbotk]                     1926        0.855 -0.961174         <NA>   0.9691366 
INFO  [04:19:06.809] [bbotk]                                 uhash 
INFO  [04:19:06.809] [bbotk]  503057a3-6a00-4137-9b71-8e23eb1e08df 
DEBUG [04:19:08.365] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.174803e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.174803e-05 0.001330736 
  - best initial criterion value(s) :  727.423 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -727.42  |proj g|=       11.709
At iterate     1  f =       -736.4  |proj g|=        6.5927
At iterate     2  f =      -737.96  |proj g|=        6.5904
At iterate     3  f =      -738.84  |proj g|=        5.8562
At iterate     4  f =      -739.08  |proj g|=        5.4967
At iterate     5  f =      -739.13  |proj g|=        5.4238
At iterate     6  f =      -739.14  |proj g|=        5.4505
At iterate     7  f =      -739.15  |proj g|=        5.4888
At iterate     8  f =      -739.15  |proj g|=        5.4922
At iterate     9  f =      -739.15  |proj g|=        5.4929
At iterate    10  f =      -739.15  |proj g|=        5.4965
At iterate    11  f =      -739.15  |proj g|=        5.5003
At iterate    12  f =      -739.15  |proj g|=        5.5061
At iterate    13  f =      -739.15  |proj g|=        5.5115
At iterate    14  f =      -739.15  |proj g|=         5.512
At iterate    15  f =      -739.15  |proj g|=        5.4954
At iterate    16  f =      -739.15  |proj g|=        5.4426
At iterate    17  f =      -739.16  |proj g|=        5.3513
At iterate    18  f =      -739.16  |proj g|=        5.3428
At iterate    19  f =      -739.16  |proj g|=        5.2899
At iterate    20  f =      -739.17  |proj g|=        5.2235
At iterate    21  f =      -739.18  |proj g|=        5.0995
At iterate    22  f =      -739.23  |proj g|=        4.9096
At iterate    23  f =      -739.33  |proj g|=        4.6251
At iterate    24  f =      -739.52  |proj g|=        4.0308
At iterate    25  f =      -739.94  |proj g|=        3.6406
At iterate    26  f =      -740.29  |proj g|=        2.2982
At iterate    27  f =      -743.03  |proj g|=         1.646
At iterate    28  f =      -747.31  |proj g|=       0.83337
At iterate    29  f =      -751.72  |proj g|=        1.2183
At iterate    30  f =      -751.77  |proj g|=        1.1054
At iterate    31  f =      -751.79  |proj g|=        1.0863
At iterate    32  f =       -751.8  |proj g|=        1.0901
At iterate    33  f =       -751.8  |proj g|=         1.093
At iterate    34  f =       -751.8  |proj g|=        1.0949
At iterate    35  f =       -751.8  |proj g|=         1.094
At iterate    36  f =       -751.8  |proj g|=         1.094

iterations 36
function evaluations 41
segments explored during Cauchy searches 38
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.094
final function value -751.801

F = -751.801
final  value -751.801146 
converged
 
INFO  [04:19:08.367] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:19:08.413] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:19:08.420] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:19:17.398] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:19:26.013] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:19:31.682] [mlr3]  Finished benchmark 
INFO  [04:19:31.753] [bbotk] Result of batch 151: 
INFO  [04:19:31.755] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:19:31.755] [bbotk]              6.040253                 7.726511                       0.4825786 
INFO  [04:19:31.755] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:19:31.755] [bbotk]                     2050        0.876 -0.9582275         <NA>   0.9744569 
INFO  [04:19:31.755] [bbotk]                                 uhash 
INFO  [04:19:31.755] [bbotk]  70891898-fe32-427d-a408-7ff8b5a45879 
DEBUG [04:19:33.462] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.172828e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.172828e-05 0.001329697 
  - best initial criterion value(s) :  702.8743 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -702.87  |proj g|=       14.066
At iterate     1  f =      -708.12  |proj g|=        9.3326
At iterate     2  f =      -750.31  |proj g|=        5.2458
At iterate     3  f =      -751.28  |proj g|=        4.0439
At iterate     4  f =      -752.04  |proj g|=        3.1261
At iterate     5  f =      -752.44  |proj g|=        2.1737
At iterate     6  f =      -752.45  |proj g|=        2.0333
At iterate     7  f =      -752.45  |proj g|=        2.0554
At iterate     8  f =      -752.45  |proj g|=        2.0626
At iterate     9  f =      -752.45  |proj g|=        2.1065
At iterate    10  f =      -752.47  |proj g|=        2.1639
At iterate    11  f =       -752.5  |proj g|=        2.2702
At iterate    12  f =      -752.59  |proj g|=        2.4108
At iterate    13  f =      -752.82  |proj g|=        2.7128
At iterate    14  f =      -752.84  |proj g|=        2.5189
At iterate    15  f =      -753.37  |proj g|=        2.8184
At iterate    16  f =      -758.61  |proj g|=        1.3319
At iterate    17  f =      -760.39  |proj g|=        1.2468
At iterate    18  f =      -761.02  |proj g|=        1.1598
At iterate    19  f =       -761.2  |proj g|=        1.2138
At iterate    20  f =      -761.26  |proj g|=        1.3852
At iterate    21  f =       -761.3  |proj g|=        1.3962
At iterate    22  f =       -761.3  |proj g|=        1.4073
At iterate    23  f =       -761.3  |proj g|=        1.4103
At iterate    24  f =       -761.3  |proj g|=        1.4118
At iterate    25  f =       -761.3  |proj g|=        1.4113
At iterate    26  f =       -761.3  |proj g|=        1.4027
At iterate    27  f =       -761.3  |proj g|=        1.4017
At iterate    28  f =       -761.3  |proj g|=        1.3974
At iterate    29  f =       -761.3  |proj g|=         1.396
At iterate    30  f =       -761.3  |proj g|=         1.396

iterations 30
function evaluations 42
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.39604
final function value -761.3

F = -761.3
final  value -761.299948 
converged
 
INFO  [04:19:33.466] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:19:33.523] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:19:33.654] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:19:48.354] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:20:07.062] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:20:20.564] [mlr3]  Finished benchmark 
INFO  [04:20:20.636] [bbotk] Result of batch 152: 
INFO  [04:20:20.638] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:20:20.638] [bbotk]              7.887333                 3.847428                       0.3008466 
INFO  [04:20:20.638] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:20:20.638] [bbotk]                     4446        0.868 -0.9578767         <NA>   0.9751909 
INFO  [04:20:20.638] [bbotk]                                 uhash 
INFO  [04:20:20.638] [bbotk]  49435760-92f1-4a2a-9af5-ba6790838850 
DEBUG [04:20:22.295] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.171577e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.171577e-05 0.001330757 
  - best initial criterion value(s) :  701.6327 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -701.63  |proj g|=       5.1786
At iterate     1  f =      -720.37  |proj g|=         11.11
At iterate     2  f =      -733.61  |proj g|=        10.756
At iterate     3  f =       -751.8  |proj g|=         8.423
At iterate     4  f =       -752.9  |proj g|=        7.2506
At iterate     5  f =      -754.42  |proj g|=        6.3001
At iterate     6  f =      -756.72  |proj g|=        4.6037
At iterate     7  f =      -757.06  |proj g|=        5.2745
At iterate     8  f =       -757.5  |proj g|=        4.5767
At iterate     9  f =       -757.6  |proj g|=        4.2705
At iterate    10  f =      -757.74  |proj g|=        4.2588
At iterate    11  f =      -758.61  |proj g|=        4.2528
At iterate    12  f =      -759.77  |proj g|=        4.0167
At iterate    13  f =      -760.98  |proj g|=        2.3606
At iterate    14  f =      -764.56  |proj g|=        2.3268
At iterate    15  f =      -768.02  |proj g|=        2.0072
At iterate    16  f =      -778.33  |proj g|=        3.1163
At iterate    17  f =      -785.07  |proj g|=        2.0015
At iterate    18  f =      -786.79  |proj g|=        1.5106
At iterate    19  f =       -787.3  |proj g|=       0.73125
At iterate    20  f =       -787.3  |proj g|=       0.75405
At iterate    21  f =       -787.3  |proj g|=       0.74884
At iterate    22  f =       -788.7  |proj g|=       0.91573
At iterate    23  f =      -788.95  |proj g|=        1.1293
At iterate    24  f =      -788.98  |proj g|=        1.0602
At iterate    25  f =      -788.98  |proj g|=        1.0382
At iterate    26  f =      -788.98  |proj g|=        1.0394
At iterate    27  f =      -788.98  |proj g|=        1.0383
At iterate    28  f =      -788.98  |proj g|=        1.0389
At iterate    29  f =      -788.98  |proj g|=        1.0415
At iterate    30  f =      -788.98  |proj g|=        1.0448
At iterate    31  f =      -788.98  |proj g|=        1.0548
At iterate    32  f =      -788.98  |proj g|=        1.0687
At iterate    33  f =      -788.99  |proj g|=         1.093
At iterate    34  f =         -789  |proj g|=        1.1292
At iterate    35  f =      -789.03  |proj g|=        1.1745
At iterate    36  f =      -789.07  |proj g|=        1.1964
At iterate    37  f =      -789.09  |proj g|=        1.0997
At iterate    38  f =      -789.09  |proj g|=        1.1384
At iterate    39  f =      -789.09  |proj g|=        1.1373
At iterate    40  f =      -789.09  |proj g|=        1.1373

iterations 40
function evaluations 52
segments explored during Cauchy searches 44
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.13727
final function value -789.092

F = -789.092
final  value -789.092245 
converged
 
INFO  [04:20:22.299] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:20:22.359] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:20:22.366] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:20:23.521] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:20:24.662] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:20:25.844] [mlr3]  Finished benchmark 
INFO  [04:20:25.915] [bbotk] Result of batch 153: 
INFO  [04:20:25.917] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:20:25.917] [bbotk]              7.715846                  3.60012                      0.04713336 
INFO  [04:20:25.917] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:20:25.917] [bbotk]                      228        0.888 -0.9491311         <NA>   0.9161305 
INFO  [04:20:25.917] [bbotk]                                 uhash 
INFO  [04:20:25.917] [bbotk]  9a0b53b3-7acf-4dcc-b7d3-9de047a1d27f 
DEBUG [04:20:27.382] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.297613e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.297613e-05 0.001514323 
  - best initial criterion value(s) :  645.793 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -645.79  |proj g|=       15.256
At iterate     1  f =      -706.74  |proj g|=        13.866
At iterate     2  f =      -751.62  |proj g|=        9.1373
At iterate     3  f =      -755.42  |proj g|=        7.2152
At iterate     4  f =      -763.38  |proj g|=        3.2227
At iterate     5  f =       -766.3  |proj g|=        1.7987
At iterate     6  f =       -768.5  |proj g|=         1.074
At iterate     7  f =      -772.14  |proj g|=        5.2656
At iterate     8  f =      -774.89  |proj g|=        3.4444
At iterate     9  f =      -776.47  |proj g|=        2.6811
At iterate    10  f =      -776.61  |proj g|=        3.0454
At iterate    11  f =      -776.65  |proj g|=        3.4107
At iterate    12  f =      -776.65  |proj g|=        3.3991
At iterate    13  f =      -776.66  |proj g|=        3.3126
At iterate    14  f =      -776.67  |proj g|=        3.2008
At iterate    15  f =      -776.73  |proj g|=             3
At iterate    16  f =      -776.85  |proj g|=        2.6861
At iterate    17  f =      -777.18  |proj g|=        2.1777
At iterate    18  f =      -777.99  |proj g|=        1.4302
At iterate    19  f =      -780.12  |proj g|=       0.49557
At iterate    20  f =      -786.91  |proj g|=       0.44157
At iterate    21  f =       -797.6  |proj g|=        1.2625
At iterate    22  f =      -798.79  |proj g|=        1.6814
At iterate    23  f =      -799.25  |proj g|=         2.155
At iterate    24  f =      -799.26  |proj g|=        2.1125
At iterate    25  f =      -799.26  |proj g|=        2.1147
At iterate    26  f =      -799.26  |proj g|=        2.1148

iterations 26
function evaluations 32
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 2.11479
final function value -799.259

F = -799.259
final  value -799.258913 
converged
 
INFO  [04:20:27.386] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:20:27.444] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:20:27.451] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:20:38.769] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:20:50.413] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:21:01.524] [mlr3]  Finished benchmark 
INFO  [04:21:01.611] [bbotk] Result of batch 154: 
INFO  [04:21:01.612] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:21:01.612] [bbotk]              8.632721                 8.850417                       0.3620154 
INFO  [04:21:01.612] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:21:01.612] [bbotk]                     3913        0.881 -0.9406051         <NA>   0.9731672 
INFO  [04:21:01.612] [bbotk]                                 uhash 
INFO  [04:21:01.612] [bbotk]  009d6093-8b2f-45d8-a832-a9a99627fe74 
DEBUG [04:21:03.262] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.293969e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.293969e-05 0.001512641 
  - best initial criterion value(s) :  644.2828 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -644.28  |proj g|=        4.411
At iterate     1  f =      -667.77  |proj g|=        3.4207
At iterate     2  f =      -667.98  |proj g|=        3.1964
At iterate     3  f =      -668.17  |proj g|=        3.2738
At iterate     4  f =       -668.3  |proj g|=        3.5562
At iterate     5  f =      -668.32  |proj g|=        3.4934
At iterate     6  f =      -668.33  |proj g|=        3.4984
At iterate     7  f =      -668.33  |proj g|=        3.5005
At iterate     8  f =      -668.33  |proj g|=        3.5002

iterations 8
function evaluations 12
segments explored during Cauchy searches 10
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.50022
final function value -668.325

F = -668.325
final  value -668.325064 
converged
 
INFO  [04:21:03.266] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:21:03.321] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:21:03.328] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:21:08.277] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:21:13.436] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:21:18.351] [mlr3]  Finished benchmark 
INFO  [04:21:18.419] [bbotk] Result of batch 155: 
INFO  [04:21:18.421] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:21:18.421] [bbotk]              4.939408                 8.415922                       0.3391324 
INFO  [04:21:18.421] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:21:18.421] [bbotk]                     2487        1.259 -0.9696716         <NA>   0.9732306 
INFO  [04:21:18.421] [bbotk]                                 uhash 
INFO  [04:21:18.421] [bbotk]  4239c268-7003-4a70-9d0b-d3581665a210 
DEBUG [04:21:20.388] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.290382e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.290382e-05 0.001513038 
  - best initial criterion value(s) :  728.6858 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -728.69  |proj g|=       4.6686
At iterate     1  f =      -769.74  |proj g|=        9.5638
At iterate     2  f =      -770.75  |proj g|=        8.9891
At iterate     3  f =      -772.57  |proj g|=        6.2515
At iterate     4  f =      -773.08  |proj g|=        6.6653
At iterate     5  f =      -775.04  |proj g|=        6.9424
At iterate     6  f =      -780.41  |proj g|=        6.1409
At iterate     7  f =      -788.98  |proj g|=        3.4969
At iterate     8  f =      -792.36  |proj g|=        1.8076
At iterate     9  f =      -792.65  |proj g|=        1.4933
At iterate    10  f =      -794.56  |proj g|=        2.3575
At iterate    11  f =      -794.79  |proj g|=        1.8649
At iterate    12  f =       -794.8  |proj g|=        1.9008
At iterate    13  f =      -794.82  |proj g|=        1.9286
At iterate    14  f =      -794.82  |proj g|=        1.9235
At iterate    15  f =      -794.82  |proj g|=        1.9221
At iterate    16  f =      -794.83  |proj g|=        1.9165
At iterate    17  f =      -794.84  |proj g|=        1.9072
At iterate    18  f =      -794.88  |proj g|=        1.8797
At iterate    19  f =       -794.9  |proj g|=        1.9813
At iterate    20  f =      -794.99  |proj g|=        1.8841
At iterate    21  f =      -795.16  |proj g|=        1.7623
At iterate    22  f =      -795.24  |proj g|=        1.6742
At iterate    23  f =      -795.35  |proj g|=        1.5468
At iterate    24  f =      -795.91  |proj g|=        1.3106
At iterate    25  f =      -797.71  |proj g|=        1.0744
At iterate    26  f =       -799.7  |proj g|=        1.4039
At iterate    27  f =      -801.81  |proj g|=         2.217
At iterate    28  f =      -808.93  |proj g|=        0.9376
At iterate    29  f =      -809.31  |proj g|=       0.33193
At iterate    30  f =      -809.58  |proj g|=       0.74336
At iterate    31  f =       -809.6  |proj g|=       0.69033
At iterate    32  f =       -809.6  |proj g|=        0.6644
At iterate    33  f =       -809.6  |proj g|=       0.66262
At iterate    34  f =       -809.6  |proj g|=        0.6612
At iterate    35  f =       -809.6  |proj g|=       0.73824
At iterate    36  f =       -809.6  |proj g|=       0.73832
At iterate    37  f =       -809.6  |proj g|=       0.73932
At iterate    38  f =      -809.61  |proj g|=       0.74105
At iterate    39  f =      -809.63  |proj g|=       0.74334
At iterate    40  f =      -809.69  |proj g|=       0.74595
At iterate    41  f =      -809.81  |proj g|=        0.7476
At iterate    42  f =      -810.04  |proj g|=       0.74341
At iterate    43  f =      -810.19  |proj g|=       0.73755
At iterate    44  f =      -810.44  |proj g|=       0.72872
At iterate    45  f =      -810.54  |proj g|=        0.7187
At iterate    46  f =      -810.56  |proj g|=       0.26472
At iterate    47  f =      -810.57  |proj g|=       0.26621
At iterate    48  f =      -810.57  |proj g|=        0.2258
At iterate    49  f =      -810.57  |proj g|=      0.015628
At iterate    50  f =      -810.57  |proj g|=     0.0066325

iterations 50
function evaluations 62
segments explored during Cauchy searches 53
BFGS updates skipped 0
active bounds at final generalized Cauchy point 2
norm of the final projected gradient 0.00663248
final function value -810.566

F = -810.566
final  value -810.566467 
converged
 
INFO  [04:21:20.392] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:21:20.447] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:21:20.454] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:21:22.198] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:21:23.995] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:21:25.808] [mlr3]  Finished benchmark 
INFO  [04:21:25.888] [bbotk] Result of batch 156: 
INFO  [04:21:25.890] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:21:25.890] [bbotk]              6.373408                 9.754198                       0.2910247 
INFO  [04:21:25.890] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:21:25.890] [bbotk]                      736            1 -0.9451092         <NA>   0.9671606 
INFO  [04:21:25.890] [bbotk]                                 uhash 
INFO  [04:21:25.890] [bbotk]  74791678-b908-4093-a168-33074eaf5ca5 
DEBUG [04:21:27.370] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.283627e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.283627e-05 0.001498691 
  - best initial criterion value(s) :  761.7108 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -761.71  |proj g|=      0.37431
At iterate     1  f =      -775.48  |proj g|=        5.2864
At iterate     2  f =       -775.9  |proj g|=        4.9773
At iterate     3  f =      -776.14  |proj g|=        4.3392
At iterate     4  f =      -776.16  |proj g|=        4.4765
At iterate     5  f =      -776.21  |proj g|=        4.4339
At iterate     6  f =      -776.37  |proj g|=        4.4348
At iterate     7  f =      -776.39  |proj g|=        4.5655
At iterate     8  f =       -776.4  |proj g|=         4.551
At iterate     9  f =       -776.4  |proj g|=        4.5476
At iterate    10  f =       -776.4  |proj g|=        4.5476

iterations 10
function evaluations 16
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 4.54758
final function value -776.396

F = -776.396
final  value -776.395532 
converged
 
INFO  [04:21:27.374] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:21:27.435] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:21:27.443] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:21:30.115] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:21:32.801] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:21:35.441] [mlr3]  Finished benchmark 
INFO  [04:21:35.547] [bbotk] Result of batch 157: 
INFO  [04:21:35.549] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:21:35.549] [bbotk]              9.865834                 5.414376                       0.2073196 
INFO  [04:21:35.549] [bbotk]  ps_cboost_anneal1.mstop propose.time crit.vals errors.model classif.auc 
INFO  [04:21:35.549] [bbotk]                     1262        1.013  -0.95927         <NA>   0.9692819 
INFO  [04:21:35.549] [bbotk]                                 uhash 
INFO  [04:21:35.549] [bbotk]  b46acdea-337c-4943-aaa3-044384ea37b1 
DEBUG [04:21:37.376] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.277597e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.277597e-05 0.001489244 
  - best initial criterion value(s) :  732.9858 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -732.99  |proj g|=       12.206
At iterate     1  f =      -769.58  |proj g|=        9.9447
At iterate     2  f =      -773.77  |proj g|=        8.5287
At iterate     3  f =      -782.38  |proj g|=        5.3327
At iterate     4  f =      -787.45  |proj g|=        4.7902
At iterate     5  f =      -789.41  |proj g|=        5.2018
At iterate     6  f =      -789.62  |proj g|=        4.7819
At iterate     7  f =      -789.63  |proj g|=        4.7574
At iterate     8  f =      -789.81  |proj g|=        5.8786
At iterate     9  f =      -790.71  |proj g|=        5.5496
At iterate    10  f =      -793.89  |proj g|=        4.1299
At iterate    11  f =      -797.69  |proj g|=         3.925
At iterate    12  f =      -806.48  |proj g|=        4.3331
At iterate    13  f =      -806.58  |proj g|=        4.4756
At iterate    14  f =      -806.83  |proj g|=        4.8336
At iterate    15  f =      -806.94  |proj g|=        4.9657
At iterate    16  f =      -807.01  |proj g|=        4.9839
At iterate    17  f =      -807.03  |proj g|=        4.9276
At iterate    18  f =      -807.03  |proj g|=        4.8789
At iterate    19  f =      -807.03  |proj g|=        4.8619
At iterate    20  f =      -807.03  |proj g|=        4.8599
At iterate    21  f =      -807.03  |proj g|=          4.86

iterations 21
function evaluations 25
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 4.86005
final function value -807.029

F = -807.029
final  value -807.028550 
converged
 
INFO  [04:21:37.381] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:21:37.441] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:21:37.449] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:21:44.705] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:21:51.446] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:21:58.442] [mlr3]  Finished benchmark 
INFO  [04:21:58.530] [bbotk] Result of batch 158: 
INFO  [04:21:58.532] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:21:58.532] [bbotk]              7.754705                 6.145047                       0.1866232 
INFO  [04:21:58.532] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:21:58.532] [bbotk]                     3352        1.251 -0.9546193         <NA>   0.9730324 
INFO  [04:21:58.532] [bbotk]                                 uhash 
INFO  [04:21:58.532] [bbotk]  1ab02c76-4b9e-484b-b331-4237f1db69c1 
DEBUG [04:22:00.144] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.273929e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.273929e-05 0.001488449 
  - best initial criterion value(s) :  746.9411 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -746.94  |proj g|=        12.12
At iterate     1  f =      -753.85  |proj g|=        9.7713
At iterate     2  f =      -758.68  |proj g|=        7.9864
At iterate     3  f =      -760.87  |proj g|=        6.2413
At iterate     4  f =      -761.72  |proj g|=        5.5046
At iterate     5  f =      -762.03  |proj g|=         5.246
At iterate     6  f =      -762.12  |proj g|=        5.2055
At iterate     7  f =      -762.13  |proj g|=        5.2921
At iterate     8  f =      -762.13  |proj g|=        5.2132
At iterate     9  f =      -762.13  |proj g|=        5.2354
At iterate    10  f =      -762.13  |proj g|=         5.291
At iterate    11  f =      -762.14  |proj g|=        5.3531
At iterate    12  f =      -762.15  |proj g|=        5.4718
At iterate    13  f =      -762.19  |proj g|=        5.6179
At iterate    14  f =      -762.22  |proj g|=        5.8962
At iterate    15  f =      -762.32  |proj g|=        6.0079
At iterate    16  f =      -762.92  |proj g|=        6.3995
At iterate    17  f =      -763.95  |proj g|=        6.6551
At iterate    18  f =      -768.62  |proj g|=        6.6116
At iterate    19  f =      -774.12  |proj g|=        6.0484
At iterate    20  f =      -778.19  |proj g|=        4.7294
At iterate    21  f =      -787.56  |proj g|=        1.2702
At iterate    22  f =      -796.17  |proj g|=        1.2393
At iterate    23  f =      -797.78  |proj g|=        1.2893
At iterate    24  f =      -797.88  |proj g|=        1.2384
At iterate    25  f =      -797.93  |proj g|=        1.0957
At iterate    26  f =      -797.95  |proj g|=       0.97897
At iterate    27  f =      -797.95  |proj g|=        0.9758
At iterate    28  f =      -797.95  |proj g|=       0.97655
At iterate    29  f =      -797.95  |proj g|=       0.97648

iterations 29
function evaluations 33
segments explored during Cauchy searches 32
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.976479
final function value -797.947

F = -797.947
final  value -797.946534 
converged
 
INFO  [04:22:00.148] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:22:00.208] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:22:00.216] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:22:02.521] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:22:04.706] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:22:06.925] [mlr3]  Finished benchmark 
INFO  [04:22:06.995] [bbotk] Result of batch 159: 
INFO  [04:22:06.997] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:22:06.997] [bbotk]              9.944041                 2.195744                       0.1073923 
INFO  [04:22:06.997] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:22:06.997] [bbotk]                      983         0.94 -0.9569809         <NA>    0.961823 
INFO  [04:22:06.997] [bbotk]                                 uhash 
INFO  [04:22:06.997] [bbotk]  765b6935-728f-4c1a-bc30-cf4aacae851a 
DEBUG [04:22:08.879] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.267856e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.267856e-05 0.001479972 
  - best initial criterion value(s) :  717.5734 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -717.57  |proj g|=       10.729
At iterate     1  f =      -801.38  |proj g|=        2.6007
At iterate     2  f =      -810.19  |proj g|=        3.0373
At iterate     3  f =      -812.25  |proj g|=        2.7483
At iterate     4  f =      -813.71  |proj g|=        1.7963
At iterate     5  f =      -814.04  |proj g|=        1.3236
At iterate     6  f =      -814.05  |proj g|=         1.366
At iterate     7  f =      -814.05  |proj g|=        1.3468
At iterate     8  f =      -814.05  |proj g|=        1.3483
At iterate     9  f =      -814.05  |proj g|=        1.3495
At iterate    10  f =      -814.05  |proj g|=        1.3517
At iterate    11  f =      -814.05  |proj g|=        1.3549
At iterate    12  f =      -814.05  |proj g|=        1.3602
At iterate    13  f =      -814.05  |proj g|=        1.3684
At iterate    14  f =      -814.05  |proj g|=        1.3806
At iterate    15  f =      -814.05  |proj g|=        1.3972
At iterate    16  f =      -814.06  |proj g|=        1.4137
At iterate    17  f =      -814.09  |proj g|=        1.4106
At iterate    18  f =      -814.14  |proj g|=        1.3358
At iterate    19  f =      -814.21  |proj g|=        1.1049
At iterate    20  f =      -814.23  |proj g|=         1.021
At iterate    21  f =      -814.23  |proj g|=        1.0224
At iterate    22  f =      -814.23  |proj g|=        1.0238
At iterate    23  f =      -814.23  |proj g|=        1.0277
At iterate    24  f =      -814.25  |proj g|=        1.0331
At iterate    25  f =      -814.28  |proj g|=        1.0592
At iterate    26  f =       -814.3  |proj g|=        1.0349
At iterate    27  f =       -814.4  |proj g|=        1.0364
At iterate    28  f =      -814.73  |proj g|=        1.1179
At iterate    29  f =       -815.3  |proj g|=         1.057
At iterate    30  f =      -816.36  |proj g|=       0.72414
At iterate    31  f =      -816.74  |proj g|=       0.66177
At iterate    32  f =      -816.78  |proj g|=       0.76823
At iterate    33  f =      -817.34  |proj g|=       0.40294
At iterate    34  f =      -817.39  |proj g|=       0.30849
At iterate    35  f =       -817.4  |proj g|=       0.28342
At iterate    36  f =       -817.4  |proj g|=       0.27964
At iterate    37  f =       -817.4  |proj g|=       0.28007
At iterate    38  f =       -817.4  |proj g|=       0.28031

iterations 38
function evaluations 48
segments explored during Cauchy searches 41
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.280307
final function value -817.399

F = -817.399
final  value -817.399209 
converged
 
INFO  [04:22:08.884] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:22:08.939] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:22:08.946] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:22:13.980] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:22:19.294] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:22:24.528] [mlr3]  Finished benchmark 
INFO  [04:22:24.597] [bbotk] Result of batch 160: 
INFO  [04:22:24.599] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:22:24.599] [bbotk]              9.755663                 4.667105                       0.1224291 
INFO  [04:22:24.599] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:22:24.599] [bbotk]                     2529        1.021 -0.9510631         <NA>   0.9700072 
INFO  [04:22:24.599] [bbotk]                                 uhash 
INFO  [04:22:24.599] [bbotk]  d727eb45-947a-45c3-8836-5a52538662d5 
DEBUG [04:22:26.589] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.262311e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.262311e-05 0.00147498 
  - best initial criterion value(s) :  778.0375 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -778.04  |proj g|=       6.1857
At iterate     1  f =      -801.71  |proj g|=        4.2142
At iterate     2  f =      -803.11  |proj g|=        4.9738
At iterate     3  f =      -804.71  |proj g|=        5.8508
At iterate     4  f =      -806.08  |proj g|=        5.7602
At iterate     5  f =      -806.21  |proj g|=        5.3491
At iterate     6  f =      -806.21  |proj g|=        5.3936
At iterate     7  f =      -806.21  |proj g|=        5.4058
At iterate     8  f =      -806.21  |proj g|=        5.4066
At iterate     9  f =      -806.22  |proj g|=        5.4249
At iterate    10  f =      -806.24  |proj g|=        5.4498
At iterate    11  f =      -806.34  |proj g|=        5.4841
At iterate    12  f =      -806.57  |proj g|=        5.4472
At iterate    13  f =       -806.6  |proj g|=        5.2151
At iterate    14  f =      -807.23  |proj g|=        5.0844
At iterate    15  f =      -808.48  |proj g|=        4.5739
At iterate    16  f =      -810.26  |proj g|=        3.6269
At iterate    17  f =      -811.25  |proj g|=        3.6685
At iterate    18  f =      -811.35  |proj g|=        3.7912
At iterate    19  f =      -811.36  |proj g|=        3.8805
At iterate    20  f =      -811.36  |proj g|=        3.8169
At iterate    21  f =      -811.36  |proj g|=        3.8003
At iterate    22  f =      -811.36  |proj g|=        3.7975
At iterate    23  f =      -811.36  |proj g|=        3.7967
At iterate    24  f =      -811.36  |proj g|=        3.7956
At iterate    25  f =      -811.36  |proj g|=        3.7941
At iterate    26  f =      -811.36  |proj g|=        3.7833
At iterate    27  f =      -811.36  |proj g|=        3.7889
At iterate    28  f =      -811.36  |proj g|=        3.7834
At iterate    29  f =      -811.37  |proj g|=        3.7453
At iterate    30  f =      -811.38  |proj g|=        3.7275
At iterate    31  f =       -811.4  |proj g|=        3.7525
At iterate    32  f =      -811.42  |proj g|=        3.8719
At iterate    33  f =      -811.48  |proj g|=        4.0184
At iterate    34  f =      -811.54  |proj g|=        4.1341
At iterate    35  f =      -811.58  |proj g|=        4.1318
At iterate    36  f =      -811.76  |proj g|=        4.1489
At iterate    37  f =      -811.99  |proj g|=        3.8468
At iterate    38  f =      -812.56  |proj g|=        3.8273
At iterate    39  f =      -814.45  |proj g|=        3.3091
At iterate    40  f =      -821.87  |proj g|=        2.5726
At iterate    41  f =      -832.29  |proj g|=        1.5391
At iterate    42  f =       -833.7  |proj g|=       0.75648
At iterate    43  f =      -834.45  |proj g|=       0.26936
At iterate    44  f =      -834.62  |proj g|=       0.25704
At iterate    45  f =      -834.64  |proj g|=       0.72363
At iterate    46  f =      -834.64  |proj g|=       0.13334
At iterate    47  f =      -834.64  |proj g|=      0.031658
At iterate    48  f =      -834.64  |proj g|=     0.0094532
At iterate    49  f =      -834.64  |proj g|=     0.0094532

iterations 49
function evaluations 57
segments explored during Cauchy searches 51
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.00945321
final function value -834.641

F = -834.641
final  value -834.640734 
converged
 
INFO  [04:22:26.593] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:22:26.647] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:22:26.654] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:22:42.045] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:22:55.387] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:23:09.094] [mlr3]  Finished benchmark 
INFO  [04:23:09.164] [bbotk] Result of batch 161: 
INFO  [04:23:09.166] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:23:09.166] [bbotk]              5.290135                  8.83443                       0.3615143 
INFO  [04:23:09.166] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:23:09.166] [bbotk]                     4523        0.892 -0.9468515         <NA>   0.9753657 
INFO  [04:23:09.166] [bbotk]                                 uhash 
INFO  [04:23:09.166] [bbotk]  982d6d64-b1f7-4694-8b1e-5f483e59a5a3 
DEBUG [04:23:10.549] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.260886e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.260886e-05 0.001474382 
  - best initial criterion value(s) :  780.343 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -780.34  |proj g|=       2.9712
At iterate     1  f =      -789.14  |proj g|=       0.82012
At iterate     2  f =      -789.28  |proj g|=       0.81939
At iterate     3  f =      -789.33  |proj g|=       0.81856
At iterate     4  f =      -789.33  |proj g|=       0.81858
At iterate     5  f =      -789.33  |proj g|=       0.81849
At iterate     6  f =      -789.34  |proj g|=       0.81797
At iterate     7  f =      -789.35  |proj g|=       0.81675
At iterate     8  f =      -789.36  |proj g|=       0.81449
At iterate     9  f =      -789.37  |proj g|=       0.36531
At iterate    10  f =      -789.37  |proj g|=       0.36552
At iterate    11  f =      -789.37  |proj g|=       0.36546
At iterate    12  f =      -789.37  |proj g|=       0.36543
At iterate    13  f =      -789.37  |proj g|=       0.36543

iterations 13
function evaluations 16
segments explored during Cauchy searches 15
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.36543
final function value -789.369

F = -789.369
final  value -789.369170 
converged
 
INFO  [04:23:10.551] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:23:10.633] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:23:10.641] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:23:27.074] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:23:40.879] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:23:56.345] [mlr3]  Finished benchmark 
INFO  [04:23:56.416] [bbotk] Result of batch 162: 
INFO  [04:23:56.418] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:23:56.418] [bbotk]              4.154616                 2.837957                       0.4527721 
INFO  [04:23:56.418] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:23:56.418] [bbotk]                     4966        0.921 -0.9601662         <NA>   0.9744296 
INFO  [04:23:56.418] [bbotk]                                 uhash 
INFO  [04:23:56.418] [bbotk]  c54d66dd-92e3-40fc-b4f9-406715dedd44 
DEBUG [04:23:58.534] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.258504e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.258504e-05 0.00147233 
  - best initial criterion value(s) :  743.7751 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -743.78  |proj g|=       11.532
At iterate     1  f =      -752.34  |proj g|=        1.6485
At iterate     2  f =      -780.35  |proj g|=        2.7217
At iterate     3  f =      -794.07  |proj g|=        5.1493
At iterate     4  f =      -802.39  |proj g|=        4.7623
At iterate     5  f =      -813.41  |proj g|=        4.6256
At iterate     6  f =      -814.39  |proj g|=        4.0744
At iterate     7  f =       -814.8  |proj g|=         4.623
At iterate     8  f =      -814.81  |proj g|=        4.9587
At iterate     9  f =      -814.82  |proj g|=        4.8378
At iterate    10  f =      -814.82  |proj g|=        4.8351
At iterate    11  f =      -814.82  |proj g|=        4.8329
At iterate    12  f =      -814.82  |proj g|=        4.8217
At iterate    13  f =      -814.82  |proj g|=        4.8087
At iterate    14  f =      -814.83  |proj g|=        4.7842
At iterate    15  f =      -814.83  |proj g|=        4.7461
At iterate    16  f =      -814.84  |proj g|=        4.6829
At iterate    17  f =      -814.85  |proj g|=        4.5844
At iterate    18  f =       -814.9  |proj g|=        4.4296
At iterate    19  f =      -814.91  |proj g|=        4.3242
At iterate    20  f =      -815.02  |proj g|=        4.1242
At iterate    21  f =      -816.72  |proj g|=        3.5776
At iterate    22  f =      -824.21  |proj g|=        2.8743
At iterate    23  f =      -826.18  |proj g|=        2.7339
At iterate    24  f =      -826.85  |proj g|=        3.0213
At iterate    25  f =      -827.01  |proj g|=        3.5867
At iterate    26  f =      -827.09  |proj g|=        3.6346
At iterate    27  f =      -827.09  |proj g|=        3.6489
At iterate    28  f =      -827.09  |proj g|=        3.6501
At iterate    29  f =      -827.09  |proj g|=        3.6508
At iterate    30  f =      -827.09  |proj g|=        3.6518
At iterate    31  f =      -827.09  |proj g|=        3.6536
At iterate    32  f =      -827.09  |proj g|=        3.6557
At iterate    33  f =      -827.09  |proj g|=        3.6565
At iterate    34  f =      -827.09  |proj g|=        3.6514
At iterate    35  f =       -827.1  |proj g|=        3.6373
At iterate    36  f =       -827.1  |proj g|=        3.5873
At iterate    37  f =       -827.1  |proj g|=         3.592
At iterate    38  f =      -827.11  |proj g|=        3.5344
At iterate    39  f =      -827.13  |proj g|=        3.3743
At iterate    40  f =      -827.13  |proj g|=        3.4129
At iterate    41  f =      -827.18  |proj g|=        3.4286
At iterate    42  f =      -827.69  |proj g|=        3.4374
At iterate    43  f =      -828.36  |proj g|=        4.6452
At iterate    44  f =      -829.27  |proj g|=        4.0329
At iterate    45  f =      -830.31  |proj g|=        2.7877
At iterate    46  f =      -830.98  |proj g|=        2.7718
At iterate    47  f =      -832.17  |proj g|=        2.4447
At iterate    48  f =      -832.76  |proj g|=        2.4319
At iterate    49  f =      -837.39  |proj g|=        1.0751
At iterate    50  f =      -838.71  |proj g|=       0.21776
At iterate    51  f =      -839.03  |proj g|=       0.22847
At iterate    52  f =      -839.24  |proj g|=       0.23292
At iterate    53  f =      -839.27  |proj g|=       0.23558
At iterate    54  f =      -839.27  |proj g|=       0.22424
At iterate    55  f =      -839.27  |proj g|=       0.16045
At iterate    56  f =      -839.27  |proj g|=      0.039793
At iterate    57  f =      -839.27  |proj g|=      0.082814

iterations 57
function evaluations 72
segments explored during Cauchy searches 60
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.0828144
final function value -839.274

F = -839.274
final  value -839.274219 
converged
 
INFO  [04:23:58.538] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:23:58.634] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:23:58.642] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:24:14.122] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:24:30.788] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:24:44.523] [mlr3]  Finished benchmark 
INFO  [04:24:44.593] [bbotk] Result of batch 163: 
INFO  [04:24:44.595] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:24:44.595] [bbotk]              8.495425                  9.10003                       0.1683384 
INFO  [04:24:44.595] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:24:44.595] [bbotk]                     4812        0.894 -0.9496652         <NA>   0.9727861 
INFO  [04:24:44.595] [bbotk]                                 uhash 
INFO  [04:24:44.595] [bbotk]  d23f5c0a-8053-4679-9e23-6d1c65249a9b 
DEBUG [04:24:46.208] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.254729e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.254729e-05 0.001467376 
  - best initial criterion value(s) :  799.3237 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -799.32  |proj g|=       4.6301
At iterate     1  f =      -818.77  |proj g|=        5.6663
At iterate     2  f =      -826.76  |proj g|=         4.821
At iterate     3  f =         -835  |proj g|=        2.7614
At iterate     4  f =      -835.32  |proj g|=        2.0936
At iterate     5  f =      -835.54  |proj g|=        2.2213
At iterate     6  f =      -836.82  |proj g|=        2.4917
At iterate     7  f =       -838.8  |proj g|=        2.3233
At iterate     8  f =      -839.79  |proj g|=        1.5506
At iterate     9  f =      -839.91  |proj g|=        1.6473
At iterate    10  f =      -840.07  |proj g|=        1.7661
At iterate    11  f =      -840.09  |proj g|=        1.7775
At iterate    12  f =      -840.09  |proj g|=         1.787
At iterate    13  f =      -840.09  |proj g|=        1.7873
At iterate    14  f =      -840.09  |proj g|=        1.7877
At iterate    15  f =      -840.09  |proj g|=        1.7894
At iterate    16  f =      -840.09  |proj g|=        1.7903
At iterate    17  f =       -840.1  |proj g|=        1.7939
At iterate    18  f =       -840.1  |proj g|=        1.7891
At iterate    19  f =      -840.12  |proj g|=        1.8354
At iterate    20  f =      -840.14  |proj g|=        1.8146
At iterate    21  f =      -840.19  |proj g|=        1.9498
At iterate    22  f =      -840.39  |proj g|=         1.809
At iterate    23  f =      -840.93  |proj g|=        1.5405
At iterate    24  f =      -842.41  |proj g|=         1.139
At iterate    25  f =      -846.68  |proj g|=       0.33124
At iterate    26  f =      -848.33  |proj g|=       0.69881
At iterate    27  f =      -848.81  |proj g|=       0.27646
At iterate    28  f =      -849.03  |proj g|=       0.25662
At iterate    29  f =      -849.03  |proj g|=       0.72374
At iterate    30  f =      -849.03  |proj g|=       0.12866
At iterate    31  f =      -849.03  |proj g|=       0.12837

iterations 31
function evaluations 39
segments explored during Cauchy searches 33
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 0.128365
final function value -849.035

F = -849.035
final  value -849.034639 
converged
 
INFO  [04:24:46.212] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:24:46.269] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:24:46.276] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:24:59.554] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:25:15.307] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:25:31.210] [mlr3]  Finished benchmark 
INFO  [04:25:31.283] [bbotk] Result of batch 164: 
INFO  [04:25:31.285] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:25:31.285] [bbotk]              7.526782                 5.301493                       0.2151685 
INFO  [04:25:31.285] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:25:31.285] [bbotk]                     4677        0.911 -0.9471399         <NA>   0.9745967 
INFO  [04:25:31.285] [bbotk]                                 uhash 
INFO  [04:25:31.285] [bbotk]  82363123-ae3f-4f90-9779-93271040d130 
DEBUG [04:25:32.848] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.252481e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.252481e-05 0.001467782 
  - best initial criterion value(s) :  761.611 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -761.61  |proj g|=       6.9641
At iterate     1  f =      -828.19  |proj g|=        2.6013
At iterate     2  f =       -849.7  |proj g|=        3.4644
At iterate     3  f =      -850.85  |proj g|=        3.2559
At iterate     4  f =      -853.85  |proj g|=        2.4301
At iterate     5  f =      -854.19  |proj g|=        1.9274
At iterate     6  f =      -854.93  |proj g|=         2.463
At iterate     7  f =      -855.07  |proj g|=          2.64
At iterate     8  f =      -855.07  |proj g|=        2.6243
At iterate     9  f =      -855.07  |proj g|=        2.6207
At iterate    10  f =      -855.07  |proj g|=        2.6209

iterations 10
function evaluations 14
segments explored during Cauchy searches 12
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.62089
final function value -855.073

F = -855.073
final  value -855.073021 
converged
 
INFO  [04:25:32.852] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:25:32.908] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:25:32.915] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:25:42.136] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:25:50.419] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:25:58.936] [mlr3]  Finished benchmark 
INFO  [04:25:59.126] [bbotk] Result of batch 165: 
INFO  [04:25:59.128] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:25:59.128] [bbotk]              7.536519                 9.581283                       0.3000786 
INFO  [04:25:59.128] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:25:59.128] [bbotk]                     3042         1.11 -0.9454868         <NA>    0.974314 
INFO  [04:25:59.128] [bbotk]                                 uhash 
INFO  [04:25:59.128] [bbotk]  93dc8c52-1c09-4fbb-9b52-2d91a5eff45c 
DEBUG [04:26:00.698] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.249957e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.249957e-05 0.001466116 
  - best initial criterion value(s) :  776.6051 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -776.61  |proj g|=       8.7078
At iterate     1  f =      -803.32  |proj g|=        3.3057
At iterate     2  f =      -804.16  |proj g|=        3.1506
At iterate     3  f =      -805.01  |proj g|=        3.0828
At iterate     4  f =      -805.17  |proj g|=        2.7583
At iterate     5  f =      -805.54  |proj g|=        2.8504
At iterate     6  f =      -807.26  |proj g|=        3.0805
At iterate     7  f =      -808.74  |proj g|=        3.1097
At iterate     8  f =         -809  |proj g|=         2.988
At iterate     9  f =         -809  |proj g|=        2.9721
At iterate    10  f =         -809  |proj g|=        2.9654
At iterate    11  f =         -809  |proj g|=        2.9673
At iterate    12  f =         -809  |proj g|=        2.9655
At iterate    13  f =         -809  |proj g|=         2.973
At iterate    14  f =      -809.02  |proj g|=        3.0052
At iterate    15  f =      -809.09  |proj g|=        3.0705
At iterate    16  f =      -809.33  |proj g|=        3.1997
At iterate    17  f =      -809.88  |proj g|=        3.3751
At iterate    18  f =      -811.03  |proj g|=        3.5871
At iterate    19  f =      -812.97  |proj g|=        3.7181
At iterate    20  f =      -816.09  |proj g|=        2.7696
At iterate    21  f =      -817.45  |proj g|=        2.8211
At iterate    22  f =      -817.56  |proj g|=        2.6682
At iterate    23  f =      -817.56  |proj g|=         2.662
At iterate    24  f =      -817.56  |proj g|=         2.665
At iterate    25  f =      -817.56  |proj g|=        2.6656

iterations 25
function evaluations 32
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.66563
final function value -817.558

F = -817.558
final  value -817.558358 
converged
 
INFO  [04:26:00.700] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:26:00.747] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:26:00.754] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:26:03.004] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:26:05.302] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:26:08.127] [mlr3]  Finished benchmark 
INFO  [04:26:08.239] [bbotk] Result of batch 166: 
INFO  [04:26:08.241] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:26:08.241] [bbotk]               3.39539                 5.897439                       0.4870768 
INFO  [04:26:08.241] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:26:08.241] [bbotk]                      734        0.937 -0.9548925         <NA>    0.964343 
INFO  [04:26:08.241] [bbotk]                                 uhash 
INFO  [04:26:08.241] [bbotk]  97718d38-eafa-4a14-9b03-06e1617c43a6 
DEBUG [04:26:09.945] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.243662e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.243662e-05 0.001455787 
  - best initial criterion value(s) :  696.2828 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -696.28  |proj g|=       12.615
At iterate     1  f =         -806  |proj g|=        3.4069
At iterate     2  f =      -812.96  |proj g|=         7.768
At iterate     3  f =      -815.33  |proj g|=        6.5807
At iterate     4  f =      -819.76  |proj g|=        4.0038
At iterate     5  f =      -821.65  |proj g|=        3.3048
At iterate     6  f =      -823.62  |proj g|=        4.1312
At iterate     7  f =      -823.74  |proj g|=        4.7322
At iterate     8  f =      -823.75  |proj g|=         4.772
At iterate     9  f =      -823.76  |proj g|=        4.8851
At iterate    10  f =       -823.8  |proj g|=        5.0539
At iterate    11  f =      -823.92  |proj g|=        5.3448
At iterate    12  f =       -824.2  |proj g|=        5.7758
At iterate    13  f =       -824.9  |proj g|=        6.3869
At iterate    14  f =      -832.25  |proj g|=        5.0727
At iterate    15  f =      -855.91  |proj g|=        4.6891
At iterate    16  f =      -860.04  |proj g|=        3.5254
At iterate    17  f =      -861.92  |proj g|=        3.1729
At iterate    18  f =      -861.97  |proj g|=        3.1905
At iterate    19  f =      -861.99  |proj g|=        3.1029
At iterate    20  f =         -862  |proj g|=        3.1332
At iterate    21  f =         -862  |proj g|=        3.1317
At iterate    22  f =         -862  |proj g|=        3.1318

iterations 22
function evaluations 28
segments explored during Cauchy searches 27
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 3.13178
final function value -861.995

F = -861.995
final  value -861.995102 
converged
 
INFO  [04:26:09.949] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:26:10.006] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:26:10.013] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:26:19.572] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:26:28.656] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:26:38.354] [mlr3]  Finished benchmark 
INFO  [04:26:38.423] [bbotk] Result of batch 167: 
INFO  [04:26:38.425] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:26:38.425] [bbotk]               5.56736                 3.028999                     0.009260946 
INFO  [04:26:38.425] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:26:38.425] [bbotk]                     3172        0.928 -0.9462659         <NA>   0.9400755 
INFO  [04:26:38.425] [bbotk]                                 uhash 
INFO  [04:26:38.425] [bbotk]  db2080e3-0c60-438b-82e9-d9fec0969004 
DEBUG [04:26:40.202] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.27028e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.27028e-05 0.001473168 
  - best initial criterion value(s) :  751.566 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -751.57  |proj g|=       3.6103
At iterate     1  f =         -774  |proj g|=        13.152
At iterate     2  f =      -786.85  |proj g|=        12.963
At iterate     3  f =      -805.67  |proj g|=        12.708
At iterate     4  f =      -807.01  |proj g|=        12.647
At iterate     5  f =      -807.26  |proj g|=        12.606
At iterate     6  f =      -809.21  |proj g|=        11.063
At iterate     7  f =      -809.79  |proj g|=        10.604
At iterate     8  f =      -809.93  |proj g|=        11.133
At iterate     9  f =      -809.94  |proj g|=        11.308
At iterate    10  f =      -809.94  |proj g|=        11.328
At iterate    11  f =      -809.94  |proj g|=         11.33
At iterate    12  f =      -809.94  |proj g|=        11.344
At iterate    13  f =      -809.94  |proj g|=        11.361
At iterate    14  f =      -809.94  |proj g|=        11.393
At iterate    15  f =      -809.95  |proj g|=        11.442
At iterate    16  f =      -809.95  |proj g|=        11.521
At iterate    17  f =      -809.97  |proj g|=        11.648
At iterate    18  f =      -810.03  |proj g|=        11.854
At iterate    19  f =      -810.18  |proj g|=        11.972
At iterate    20  f =      -810.58  |proj g|=        11.971
At iterate    21  f =      -811.58  |proj g|=        11.969
At iterate    22  f =      -813.86  |proj g|=        11.964
At iterate    23  f =       -818.7  |proj g|=        11.954
At iterate    24  f =      -823.01  |proj g|=        11.948
At iterate    25  f =      -825.88  |proj g|=        10.322
At iterate    26  f =      -826.37  |proj g|=        10.647
At iterate    27  f =      -826.37  |proj g|=         10.53
At iterate    28  f =      -826.37  |proj g|=        10.568
At iterate    29  f =      -826.37  |proj g|=        10.567
At iterate    30  f =      -826.37  |proj g|=        10.567

iterations 30
function evaluations 37
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 1
norm of the final projected gradient 10.5673
final function value -826.374

F = -826.374
final  value -826.373958 
converged
 
INFO  [04:26:40.206] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:26:40.261] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:26:40.268] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:26:51.438] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:27:03.272] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:27:17.010] [mlr3]  Finished benchmark 
INFO  [04:27:17.082] [bbotk] Result of batch 168: 
INFO  [04:27:17.084] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:27:17.084] [bbotk]              7.929427                 7.322675                       0.4520539 
INFO  [04:27:17.084] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:27:17.084] [bbotk]                     4006        0.917 -0.9618339         <NA>   0.9757666 
INFO  [04:27:17.084] [bbotk]                                 uhash 
INFO  [04:27:17.084] [bbotk]  8dfa526f-3fef-40f0-9d98-bc0af065b26a 
DEBUG [04:27:18.454] [bbotk] 
optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern3_2 
  - nugget : 1.26918e-12 
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  15.83759 15.54396 0.9788035 9552 
  - variance bounds :  1.26918e-05 0.001472971 
  - best initial criterion value(s) :  834.621 

N = 5, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -834.62  |proj g|=      0.94208
At iterate     1  f =      -845.65  |proj g|=        4.3212
At iterate     2  f =      -848.08  |proj g|=        3.8269
At iterate     3  f =      -848.96  |proj g|=         2.788
At iterate     4  f =      -849.23  |proj g|=        3.2289
At iterate     5  f =      -849.26  |proj g|=        3.1672
At iterate     6  f =      -849.31  |proj g|=        3.0923
At iterate     7  f =      -849.41  |proj g|=        3.0154
At iterate     8  f =      -849.56  |proj g|=        2.9808
At iterate     9  f =       -849.7  |proj g|=        3.0832
At iterate    10  f =      -849.73  |proj g|=        3.1896
At iterate    11  f =      -849.73  |proj g|=        3.1956
At iterate    12  f =      -849.73  |proj g|=        3.1961

iterations 12
function evaluations 14
segments explored during Cauchy searches 14
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 3.19606
final function value -849.733

F = -849.733
final  value -849.732784 
converged
 
INFO  [04:27:18.458] [bbotk] Evaluating 1 configuration(s) 
INFO  [04:27:18.515] [mlr3]  Running benchmark with 3 resampling iterations 
INFO  [04:27:18.522] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 2/3) 
INFO  [04:27:20.895] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 3/3) 
INFO  [04:27:22.895] [mlr3]  Applying learner 'removeconstants_before.imputemedian_num.imputemode_fct.collapsefactors.removeconstants_after.ps_cboost_anneal1' on task 'spam' (iter 1/3) 
INFO  [04:27:24.656] [mlr3]  Finished benchmark 
INFO  [04:27:24.744] [bbotk] Result of batch 169: 
INFO  [04:27:24.746] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:27:24.746] [bbotk]              7.578746                 5.107626                       0.1932903 
INFO  [04:27:24.746] [bbotk]  ps_cboost_anneal1.mstop propose.time  crit.vals errors.model classif.auc 
INFO  [04:27:24.746] [bbotk]                      608        0.933 -0.9565356         <NA>   0.9619262 
INFO  [04:27:24.746] [bbotk]                                 uhash 
INFO  [04:27:24.746] [bbotk]  98cf6704-0691-4836-902d-f1a77103b841 
DEBUG [04:27:24.815] [bbotk]  
INFO  [04:27:24.827] [bbotk] Finished optimizing after 200 evaluation(s) 
INFO  [04:27:24.828] [bbotk] Result: 
INFO  [04:27:24.831] [bbotk]  ps_cboost_anneal1.df ps_cboost_anneal1.df_cat ps_cboost_anneal1.learning_rate 
INFO  [04:27:24.831] [bbotk]              6.154457                 4.024338                        0.376388 
INFO  [04:27:24.831] [bbotk]  ps_cboost_anneal1.mstop learner_param_vals  x_domain classif.auc 
INFO  [04:27:24.831] [bbotk]                     4999         <list[18]> <list[4]>    0.976204 
INFO  [04:27:41.052] [mlr3]  Finished benchmark 
